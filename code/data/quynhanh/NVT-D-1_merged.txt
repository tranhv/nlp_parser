On the failure of Spatial Verification 
Overcoming Spatial Verification Failure 
2 0,1,2,3:0,3:para-freeword 4:1:preserved 5:2:preserved

This paper proposes an object-centric boosting technique for visual instance search with more precise than existing ones . 
An object-centric boosting technique for visual instance search that is more precise than existing ones is proposed . 
6 0,1,2,11:8,9,15,16:para-freeword 3:0:preserved 4:1:preserved 5:2:preserved 6:3:preserved 7:4:preserved 8:5:preserved 9:6:preserved 10:7:preserved 12:10:preserved 13:11:preserved 14:12:preserved 15:13:preserved 16:14:preserved 17:17:preserved

A hybrid method is applied to solve the problem of lacking confidence when using standard spatial verification methods . 
A hybrid method is applied to solve the problem of lacking confidence when using standard spatial verification methods . 
7 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved

We classify pairs of verified visual words into three categories discriminative , weak relevant and context inferred pairs based on the relation with . 
We classify pairs of verified visual words into three categories — discriminative , weak relevant , and context - inferred — on the basis of the relation of these words to the object proposal location . 
8 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10,16,15,14:10,20,15,16,17,18,19:typo 11:12:preserved 12:13:preserved 13:14:preserved 17,18,22,19:23,24,27,28,29,30,31,32,33,34,21,22:paraphrase 20:25:preserved 21:26:preserved 23:35:preserved :11:unaligned

In this paper , we use a Deformable Parts Model ( DPM ) detector to demonstrate . 
In this work , we use a deformable parts model ( DPM ) detector to demonstrate the proposed technique . 
9 0:0:preserved 1:1:preserved 2:2:paraphrase 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7,8,9:7,8,9:typo 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15,16,17,18:paraphrase 16:19:preserved

Three corresponding weighting functions are also proposed to compute final similarity score between query topic and shot video . 
Three corresponding weighting functions are also proposed to compute the final similarity score between query topic and shot video . 
10 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved :9:mogrammar-det

We evaluate our method over datasets of TRECVID Instance Search . The experiments show that our method give a better performance on many kinds of query objects . It improve about 29.9% and 22.3% comparing to standard BOW and spatial verification model , respectively .
We evaluate our method using TRECVID Instance Search data sets and find that it performs better than conventional methods on many kinds of query objects , with improvements of about 29.9% and 22.3% compared to standard BOW and the spatial verification model , respectively .
11 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4,5,6:8,9,4:para-freeword 7:5:preserved 8:6:preserved 9:7:preserved 10,11,12,13,14,15,16,17,18,19,20:10,11,12,13,14,15,16,17,18:para-freeword 21:19:preserved 22:20:preserved 23:21:preserved 24:22:preserved 25:23:preserved 26:24:preserved 27,28,29:25,26,27,28:para-freeword 30:29:preserved 31:30:preserved 32:31:preserved 33:32:preserved 34:33:paraphrase 35:34:preserved 36:35:preserved 37:36:preserved 38:37:preserved 39:39:preserved 40:40:preserved 41:41:preserved 42:42:preserved 43:43:preserved 44:44:preserved :38:mogrammar-det

This work is to address the problem of instance search or object retrieval in video databases including hundreds of thousands of shots made up of millions of frames . 
The objective of this work is to address the problem of instance search or object retrieval in video databases that include hundreds of thousands of shots made up of millions of frames . 
16 0,1:0,1,2,3,4:paraphrase 2:5:preserved 3:6:preserved 4:7:preserved 5:8:preserved 6:9:preserved 7:10:preserved 8:11:preserved 9:12:preserved 10:13:preserved 11:14:preserved 12:15:preserved 13:16:preserved 14:17:preserved 15:18:preserved 16:19,20:paraphrase 17:21:preserved 18:22:preserved 19:23:preserved 20:24:preserved 21:25:preserved 22:26:preserved 23:27:preserved 24:28:preserved 25:29:preserved 26:30:preserved 27:31:preserved 28:32:preserved

The term instance search ( INS ) is defined formally by TRECVID \cite : finding video segments of a certain specific object , place or person , given a visual examples from video collection . 
The term instance search ( INS ) is defined formally by TRECVID \cite as “finding video segments of a certain specific object , place , or person after being given visual examples from a video collection” . 
17 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13,14,33:13,14,35:typo 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:25,24:typo 25:26:preserved 26:27,28:paraphrase 27:29:preserved 28:33:preserved 29:30:preserved 30:31:preserved 31:32:preserved 32:34:preserved 34:36:preserved

In practice , INS has many applications such as archive video search , law enforcement , brand-logo protection , personal video organization , surveillance .
In practice , INS has many applications , including archive video searching , law enforcement , brand-logo protection , personal video organization , and surveillance .
18 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7,8:8,7:paraphrase 9:9:preserved 10:10:preserved 11:11:bigrammar-wform 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:23,22:typo 23:24:preserved 24:25:preserved

Most of the state of the art approaches follow the original bag-of-visual-word ( BOW ) model that has been first introduced by Sivic in case of video retrieval \cite . 
Most of the conventional approaches follow the original bag-of-visual-word ( BOW ) model first introduced by Sivic in a case involving video retrieval \cite . 
19 0:0:preserved 1:1:preserved 2:2:preserved 3,4,5,6,7:3,4:paraphrase 8:5:preserved 9:6:preserved 10:7:preserved 11:8:preserved 12:9:preserved 13:10:preserved 14:11:preserved 15:12:preserved 16,17,18,19:13:paraphrase 20:14:preserved 21:15:preserved 22:16:preserved 23:17:preserved 24:19:preserved 25:20:paraphrase 26:21:preserved 27:22:preserved 28:23:preserved 29:24:preserved :18:mogrammar-det

This model relies on the key assumption that two similar image will share significant amount of local patches which can be matched against each other . 
This model relies on the key assumption that two similar images will share a significant amount of local patches that can be matched against each other . 
20 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:bigrammar-nnum 11:11:preserved 12:12:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:para-freeword 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:26:preserved :13:mogrammar-det

Using sparse feature detectors ( e.g. DoG \cite , Hessian Affine \cite , MSER \cite ) are very efficient to find regions of rich textured objects such as buildings , paintings , advertising poster , etc . 
Using sparse feature detectors ( e.g. , DoG \cite , Hessian affine \cite , MSER \cite ) is very efficient in terms of finding regions of richly textured objects such as buildings , paintings , and advertising . 
21 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5,6:typo 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:typo 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:typo 17:18:preserved 18:19:preserved 19,21,22,23,20:20,21,22,23,24,25,26:paraphrase 24:27:preserved 25:28:preserved 26:29:preserved 27:30:preserved 28:31:preserved 29:32:preserved 30:33:preserved 31:34:preserved 32,33,35,34:36,35:paraphrase 36:37:preserved

As reported \cite , \cite , \cite , the mean average precision ( mAP ) evaluated on standard benchmarks such as Oxford buildings , Paris buildings is approaching to 90 percent . 
As reported \cite , \cite , \cite , the mean average precision ( mAP ) evaluated on standard benchmarks such as Oxford buildings and Paris buildings is approaching 90 percent . 
22 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:typo 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28::unaligned 29:28:preserved 30:29:preserved 31:30:preserved

Therefore , searching on this kind of object is to some extent solved problem .
Therefore , searching this kind of object is to some extent a solved problem .
23 0:0:preserved 1:1:preserved 2,3:2:bigrammar-prep 4:3:preserved 5:4:preserved 6:5:preserved 7:6:preserved 8:7:preserved 9:8:preserved 10:9:preserved 11:10:preserved 12:12:preserved 13:13:preserved 14:14:preserved :11:mogrammar-det

For small and fairly texture objects typical feature detectors collect not enough local information , thus invadate the BOW's assumption . 
For small and fairly textured objects , however , conventional feature detectors cannot collect enough local information , thus invalidating the BOW's assumption . 
24 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:bigrammar-wform 5:5:preserved 6,9,10:7,6,8,9,12,13:para-freeword 7:10:preserved 8:11:preserved 11:14:preserved 12:15:preserved 13:16:preserved 14:17:preserved 15:18:preserved 16:19:paraphrase 17:20:preserved 18:21:preserved 19:22:preserved 20:23:preserved

Therefore , the standard BOW and its improvements including spatial re-ranking \cite and query expansion \cite will encounter a lot of difficulties derived from noisy background and complex capturing conditions . 
Therefore , the standard BOW and its improvements , including spatial re-ranking \cite and query expansion \cite , are poised to encounter a lot of difficulties stemming from noisy backgrounds and complex capturing conditions . 
25 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:9,8:typo 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17,18,19,20:paraphrase 17:21:preserved 18:22:preserved 19:23:preserved 20:24:preserved 21:25:preserved 22:26:paraphrase 23:27:preserved 24:28:preserved 25:29:bigrammar-nnum 26:30:preserved 27:31:preserved 28:32:preserved 29:33:preserved 30:34:preserved

After years of exploration in TRECVID competition , most of the state of the art INS systems \cite are based on BOW model but 
After years of exploration in TRECVID competition , most INS systems currently in use \cite are based on the BOW model . 
26 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9,10,11,12,13,14,15,16:9,10,11,12,13:paraphrase 17:14:preserved 18:15:preserved 19:16:preserved 20:17:preserved 21:19:preserved 22:20:preserved 23:21:para-freeword :18:mogrammar-det

reported very low in mAP due to many different types of query object . Hence , there still has a lot of potential challenges to solve . 
However , these have been reported to be very low in mAP due to the many different types of query object , so there are still many challenges that remain to be addressed . 
27 0:0,1,2,3,4,5,6,7:paraphrase 1:8:preserved 2:9:preserved 3:10:preserved 4:11:preserved 5:12:preserved 6::unaligned 7:15:preserved 8:16:preserved 9:17:preserved 10:18:preserved 11:19:preserved 12:20:preserved 15,14,13:22,21:paraphrase 16:23:preserved 17:25,24:typo 18,19,20,21,22,25,26:26,28,29,30,31,32:paraphrase 23:27:preserved 24:13:preserved :14:mogrammar-det

In this paper , we aim at improving the accuracy of the instance search system which focuses on many kinds of realistic objects .
In this paper , we aim at improving the accuracy of an instance search system that focuses on many different realistic objects .
28 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:bigrammar-det 12:12:preserved 13:13:preserved 14:14:preserved 15:15:para-freeword 16:16:preserved 17:17:preserved 18:18:preserved 19,20:19:paraphrase 21:20:preserved 22:21:preserved 23:22:preserved

Many that have been successfully applied on such as : RootSIFT feature \cite , large vocabulary \cite , soft assignment \cite , multiple detectors and features combination at late fusion[x] query-adaptive asymmetrical dissimilarities \cite , topology model for spatial verification \cite , weak geometric consistency ( WGC ) with hamming embedding ( HE ) \cite . 
Several have already been successfully applied , including RootSIFT feature \cite , large vocabulary \cite , soft assignment \cite , multiple detectors and features combination at late fusion[x] query-adaptive asymmetrical dissimilarities \cite , the topology model for spatial verification \cite , and weak geometric consistency ( WGC ) with hamming embedding ( HE ) \cite . 
29 0,1,2,6,7,8,9:0,1,2,7,6:para-freeword 3:3:preserved 4:4:preserved 5:5:preserved 10:8:preserved 11:9:preserved 12:10:preserved 13:11:preserved 14:12:preserved 15:13:preserved 16:14:preserved 17:15:preserved 18:16:preserved 19:17:preserved 20:18:preserved 21:19:preserved 22:20:preserved 23:21:preserved 24:22:preserved 25:23:preserved 26:24:preserved 27:25:preserved 28:26:preserved 29:27:preserved 30:28:preserved 31:29:preserved 32:30:preserved 33:31:preserved 34:32:preserved 35:34:preserved 36:35:preserved 37:36:preserved 38:37:preserved 39:38:preserved 40:39:preserved 41:40,41:typo 42:42:preserved 43:43:preserved 44:44:preserved 45:45:preserved 46:46:preserved 47:47:preserved 48:48:preserved 49:49:preserved 50:50:preserved 51:51:preserved 52:52:preserved 53:53:preserved 54:54:preserved 55:55:preserved :33:mogrammar-det

Spatial consistency checking is not only an important technique to improve the accuracy but also a needed step for query expansion to improve the recall of the system . 
In addition to its importance as a technique to improve accuracy , spatial consistency checking is a step for query expansion to improve the recall of the system . 
30 0,1,2,3,4,5,6,7,13,14,15,16:0,1,2,3,4,5,6,12,13,14,15,16,11:paraphrase 8:7:preserved 9:8:preserved 10:9:preserved 11::mogrammar-det 12:10:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved

However , this approach is not efficient very much for searching different types of query . 
However , this approach is not very efficient for searching different types of query . 
31 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6,7,8:7,6:para-freeword 9:8:preserved 10:9:preserved 11:10:preserved 12:11:preserved 13:12:preserved 14:13:preserved 15:14:preserved

There are three main reasons for the failure of spatial verification : ( i ) lacking of features due to viewpoint and light condition change , ( ii ) existing of confus objects which share similar parts with query object . 
There are three main reasons for the failure of spatial verification : ( i ) the absence of features due to viewpoint and lighting condition changes , ( ii ) the existence of confus objects that share similar parts with the query object . 
32 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15,16:paraphrase 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:bigrammar-wform 23:24:preserved 24:25:bigrammar-nnum 25:26:preserved 26:27:preserved 27:28:preserved 28:29:preserved 29:30,31:bigrammar-wform 30:32:preserved 31:33:preserved 32:34:preserved 33:35:para-freeword 34:36:preserved 35:37:preserved 36:38:preserved 37:39:preserved 38:41:preserved 39:42:preserved 40:43:preserved :40:mogrammar-det

These lead to lacking of high confidence visual words used for re-ranking . 
These lead to a lack of high confidence visual words for re-ranking . 
33 0:0:preserved 1:1:preserved 2:2:preserved 3:3,4:bigrammar-wform 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9::unaligned 10:10:preserved 11:11:preserved 12:12:preserved

Figure \ref gives some examples of scenario that database frames get high similarity score after spatial checking due to the existing of many similar objects which share the same part with the query object and a noisy background .
Figure \ref gives some examples of a scenario in which database frames get a high similarity score after spatial checking due to reasons ( ii ) and ( iii ) above , namely , the existence of many similar objects that share the same part with the query object and a noisy background .
34 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:7:preserved 7:8,9:paraphrase 8:10:preserved 9:11:preserved 10:12:preserved 11:14,13:bigrammar-det 12:15:preserved 13:16:preserved 14:17:preserved 15:18:preserved 16:19:preserved 17:20:preserved 18:21:preserved 19::unaligned 20:22,23,24,25,26,27,28,29,30,31,32,33,34,35:paraphrase 21:36:preserved 22:37:preserved 23:38:preserved 24:39:preserved 25:40:para-freeword 26:41:preserved 27:42:preserved 28:43:preserved 29:44:preserved 30:45:preserved 31:46:preserved 32:47:preserved 33:48:preserved 34:49:preserved 35:6:preserved 36:51:preserved 37:52:preserved 38:53:preserved :50:mogrammar-det

To overcome this difficulty , a typical way is to sampling in ense grid at various scales . 
The typical way of addressing the above issue is to perform sampling in a dense grid on various scales . 
35 0,1,2,3,4,5,6,7:0,1,2,3,4,5,6,7:paraphrase 8:8:preserved 9:9:preserved 10:11,10:typo 11:12:preserved 12:13,14:paraphrase 13:15:preserved 14:16:bigrammar-prep 15:17:preserved 16:18:preserved 17:19:preserved

Object in image will be fully covered by local patches which are aggregated to a single vector and used for spatial verification step . 
in an image is fully covered by local patches that are aggregated to a single vector and used for spatial verification . 
36 0,1,2:0,1,2:paraphrase 3,4:3:bigrammar-vtense 5:4:preserved 6:5:preserved 7:6:preserved 8:7:preserved 9:8:preserved 10:9:para-freeword 11:10:preserved 12:11:preserved 13:12:preserved 14:13:preserved 15:14:preserved 16:15:preserved 17:16:preserved 18:17:preserved 19:18:preserved 20:19:preserved 21,22:20:paraphrase 23:21:preserved

Many research has recently shifted from local feature detection to use denser techniques . It can be listed out here some applications of dense feature on image classification \cite , fine-grained classification \cite , action recognition in videos \cite . 
Much research has recently shifted from local feature detection to the use of denser techniques , some of the applications of which include dense feature on image classification \cite , fine-grained classification \cite , and action recognition in videos \cite . 
37 0:0:typo 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10,11,12:10,11,12,13,14:para-colocation 13,14,15,16,17,19,20,21,18,22:16,17,18,19,15,20,21,22:paraphrase 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:34,33:typo 34:35:preserved 35:36:preserved 36:37:preserved 37:38:preserved 38:39:preserved 39:40:preserved

The dense method , however , need a special treatment to apply in large scale retrieval since it extracts much more patches than sparse ones . Therefore , it is not applicable for large scale data if using per-feature level storage approach . 
The dense method , however , requires a special treatment for application to large - scale retrieval since it extracts many more patches than sparse ones , so it is not applicable for large - scale data if taking a per-feature level storage approach . 
38 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:paraphrase 7:7:preserved 8:8:preserved 9:9:preserved 10,11,12:10,11,12:para-freeword 13,14:13,14,15:typo 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:typo 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25,26:27:para-freeword 27:26:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33,34:33,34,35:typo 35:36:preserved 36:37:preserved 37:38:paraphrase 38:40:preserved 39:41:preserved 40:42:preserved 41:43:preserved 42:44:preserved :39:mogrammar-det

Using a dense feature at the post processing stage instead of at the early stage is more reasonable .
Using a dense feature at the post - processing stage instead of at the early stage is more reasonable .
39 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved :7:bigrammar-others

We use an object detector based on a dense feature like HOG to boost the confidence of a visual word . 
Here , an object detector based on a dense feature such as HOG to boost the confidence of a visual word . 
40 0,1:0,1:paraphrase 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10,11:paraphrase 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved

Which words satisfy both BOW and detection models is used to boost the similarity score at the end . 
Whichever words satisfy both BOW and the detection models are used to boost the similarity score at the end . 
41 0:0:paraphrase 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:7:preserved 7:8:preserved 8:9:typo 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved :6:mogrammar-det

We use DPM ( Deformable Parts Model ) \cite to demonstrate our proposed method since it is one of the state of the algorithms for object detection . 
We use the deformable parts model \cite to demonstrate our proposed method since it is currently one of the best algorithms for object detection . 
42 0:0:preserved 1:1:preserved 2,3,4,5,6,7:4,5,3,2:typo 8:6:preserved 9:7:preserved 10:8:preserved 11:9:preserved 12:10:preserved 13:11:preserved 14:12:preserved 15:13:preserved 16:14:preserved 17,18,19,20,21,22:16,15,17,18,19:paraphrase 23:20:preserved 24:21:preserved 25:22:preserved 26:23:preserved 27:24:preserved

Note that , this detector can be replaced by other detectors easily without changing structure of the system .
This detector could easily be replaced by other detectors without changing the structure of the system .
43 1,2,3,0:0:paraphrase 4:1:preserved 5:2:bigrammar-vtense 6:4:preserved 7:5:preserved 8:6:preserved 9:7:preserved 10:8:preserved 11:3:typo 12:9:preserved 13:10:preserved 14:12:preserved 15:13:preserved 16:14:preserved 17:15:preserved 18:16:preserved :11:mogrammar-det

Contribution : This paper proposes a novel re ranking method such as that exploits object proposal to boost the confidence of visual words . 
Contribution : In this paper , we propose a novel re - ranking method that exploits object proposal to boost the confidence of visual words . 
44 0:0:preserved 1:1:preserved 2,3,4:2,3,4,5,6,7:para-freeword 5:8:preserved 6:9:preserved 7,8:10,11,12:typo 9:13:preserved 10,11,12:14:paraphrase 13:15:preserved 14:16:preserved 15:17:preserved 16:18:preserved 17:19:preserved 18:20:preserved 19:21:preserved 20:22:preserved 21:23:preserved 22:24:preserved 23:25:preserved

The performance of the proposed approach is significantly better than that of other re ranking methods such as geometric consistency checking , multi-features late fusion technique thanks to the following contributions :
The performance of the proposed approach is significantly better than that of other re-ranking methods ( geometric consistency checking , multi-features late fusion technique ) thanks to the following contributions :
45 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13,14:13:typo 15:14:preserved 16,17:15,24:para-freeword 18:16:preserved 19:17:preserved 20:18:preserved 21:19:preserved 22:20:preserved 23:21:preserved 24:22:preserved 25:23:preserved 26:25:preserved 27:26:preserved 28:27:preserved 29:28:preserved 30:29:preserved 31:30:preserved

To our best of knowledge , this is the first time that .
To the best of our knowledge , this is the first time that .
46 0:0:preserved 1,2,3,4:4,1,2,3,5:para-colocation 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved

We propose a new scheme of re - ranking method by combining two complementary models : BOW and object detector using dense feature .
Our new re - ranking method combines two complementary models : BOW and object detector using dense features .
47 0,1,2,3,4,5,6,7,8,9,10,11:0,1,2,3,5,6,4:para-freeword 12:7:preserved 13:8:preserved 14:9:preserved 15:10:preserved 16:11:preserved 17:12:preserved 18:13:preserved 19:14:preserved 20:15:preserved 21:16:preserved 22:17:bigrammar-nnum 23:18:preserved

the proposed detector in our scheme small , texture-less and occluded objects . 
the proposed detector in our scheme small , texture-less , and occluded objects . 
48 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved :9:bigrammar-others

Meanwhile , traditional BOW model is suitable for big and rich textured objects . 
In contrast , conventional BOW is suitable for big and richly textured objects . 
49 0,1,2:0,1,2,3:para-freeword 3,4:4:paraphrase 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:bigrammar-wform 11:11:preserved 12:12:preserved 13:13:preserved

In the experimental section , we will prove the complementary characteristic by using a simple late fusion technique on these methods .
In the experimental section , we will demonstrate how these characteristics complement each other through use of a simple late fusion technique .
50 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7,8,9,10,11,12,18,20,14,13,15,16,17,19:7,8,10,11,12,13,14,15,16,20,21,18,17,19,9:para-freeword 21:22:preserved

We propose a new that takes into account location information of candidate object . 
We propose a new that takes into account the location information of a candidate object . 
51 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:13:preserved 12:14:preserved 13:15:preserved :8:mogrammar-det :12:mogrammar-det

The shared visual words on database frame are classified into four categories based on the relationship between word location and bounding box of DPM algorithm . 
The shared visual words on a database frame are classified into four categories on the basis of the relationship between word location and bounding box of DPM algorithm . 
52 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12,13,14,15:15,17,13,14,18,16:paraphrase 16:19:preserved 17:20:preserved 18:21:preserved 19:22:preserved 20:23:preserved 21:24:preserved 22:25:preserved 23:26:preserved 24:27:preserved 25:28:preserved :5:mogrammar-det

Each class of visual word will contribute to the final score with a boosting function . 
Each class of visual word will contribute to the final score with a boosting function . 
53 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved

Unlike idf as a global weighting , our confidence function is applied for a specific query object .
Unlike idf as a global weighting , our confidence function can be applied for a specific query object .
54 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10,11:paraphrase 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved

The rest of this paper is organized as follows . 
The rest of this paper is organized as follows . 
55 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved

Section dicusses some previous work related to our proposed method \ref . 
Related work is discussed in Section \ref . 
56 1,2,3,5,6,7,8,9,4,0:0,2,3,4,1,5:para-freeword 10:6:preserved 11:7:preserved

Details of our framework are presented in Section \ref . 
The details of our framework are presented in Section \ref . 
57 0:0,1:bigrammar-det 1:2:preserved 2:3:preserved 3:4:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved

Section \ref and section \ref explain why we choose DPM to combine with BOW and propose a location based fusion technique for re ranking . 
Sections \ref and \ref explain why we chose to combine DPM with BOW and propose a location - based fusion technique for re- ranking . 
58 0:0:bigrammar-nnum 1:1:preserved 2:2:preserved 3,4:3:paraphrase 5:4:preserved 6:5:preserved 7:6:preserved 8:7:bigrammar-vtense 9,10,11:10,8,9:para-colocation 12:11:preserved 13:12:preserved 14:13:preserved 15:14:preserved 16:15:preserved 17,18:16,17,18:typo 19:19:preserved 20:20:preserved 21:21:preserved 22,23:23,22:typo 24:24:preserved

Section \ref presents our experimental results on the dataset INS2013 and INS2014 . 
Section \ref presents our experimental results using two datasets ( INS2013 and INS2014 ) . 
59 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6,7,8:6,7,8,9,13:para-freeword 9:10:preserved 10:11:preserved 11:12:preserved 12:14:preserved

Finally , section \ref concludes thí papers .
We conclude the paper with a brief summary in Section \ref .
60 0,1,2,4,5,6,3:0,1,2,3,4,5,6,7,8,9,10:para-freeword 7:11:preserved

BOW is an unstructured model ưhichassumes all visual word are independent in a high dimensional vector . 
BOW is an unstructured model that assumes all visual words are independent in a high dimensional vector . 
65 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5,6:para-freeword 6:7:preserved 7:8:preserved 8:9:bigrammar-nnum 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved

Many researches have bên taken in to account this . 
Many researches have tackled . 
66 0:0:preserved 1:1:preserved 2:2:preserved 3,4,5,6,7,8:3:paraphrase 9:4:preserved

Spatial verification is one of the most effective approaches to improve the accuracy of a retrieval system . 
Spatial verification is one of the most effective approaches to improve the accuracy of retrieval systems . 
67 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14::mogrammar-det 15:14:preserved 16:15:bigrammar-nnum 17:16:preserved

It also be a prerequisite stop for other advanced methods such as query expansion . 
It is also a prerequisite for other advanced methods such as query expansion . 
68 0:0:preserved 1,2:2,1:typo 3:3:preserved 4:4:preserved 5::unaligned 6:5:preserved 7:6:preserved 8:7:preserved 9:8:preserved 10:9:preserved 11:10:preserved 12:11:preserved 13:12:preserved 14:13:preserved

Spatial re-ranking which check the geometric consistency on short list of about 200 to 1000 result returned from BOW model . 
Spatial re-ranking , which checks the geometric consistency in a short list of about 200–1000 results , the BOW model . 
69 0:0:preserved 1:1,2:typo 2:3:preserved 3:4:typo 4:5:preserved 5:6:preserved 6:7:preserved 7:8:bigrammar-prep 8:10:preserved 9:11:preserved 10:12:preserved 11:13:preserved 12,13,14,15,16,17:14,15,16,17:para-freeword 18:18:preserved 19:19:preserved 20:20:preserved :9:mogrammar-det

Using RANSAC with exploiting the local shape of affine covariant region for rigid affine consistency checking is an effective method and first applied by J. Philbin \cite . 
Another effective model , first applied by J. Philbin \cite , uses RANSAC to exploit the local shape of an affine covariant region for rigid affine consistency checking . 
70 0,1,2,3,16,17,18,19,20,21,22,23,24,25,26:0,1,2,3,4,5,6,8,7,9,10,11,12,13,14:para-freeword 4:15:preserved 5:16:preserved 6:17:preserved 7:18:preserved 8:20:preserved 9:21:preserved 10:22:preserved 11:23:preserved 12:24:preserved 13:25:preserved 14:26:preserved 15:27:preserved 27:28:preserved :19:mogrammar-det

Hough Pyramid Matching for spatial re-ranking a hierarchical structure to group matches thus resulting in an algorithm which is only linear in the number of putative correspondences \cite . 
Hough pyramid matching for spatial re-ranking a hierarchical structure to group matches , thus resulting in an algorithm that is only linear in the number of putative correspondences \cite . 
71 0:0:preserved 1,2:1,2:typo 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:13,12:typo 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:para-freeword 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:26:preserved 26:27:preserved 27:28:preserved 28:29:preserved

An elastic spatial checking technique is proposed to emphasizing the topology layouts of the matching points \cite .
An elastic spatial checking technique has been proposed to emphasize the topology layouts of matching points \cite .
72 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5,6:bigrammar-vtense 6:7:preserved 7:8:preserved 8:9:bigrammar-wform 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13::mogrammar-det 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved

Another approach is spatial ranking which proposes to incorporate spatial information at the original ranking stage for more effective .
Another approach is spatial ranking , which incorporates spatial information at the original ranking stage .
73 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5,6:typo 6,7,8:7:paraphrase 9:8:preserved 10:9:preserved 11:10:preserved 12:11:preserved 13:12:preserved 14:13:preserved 15,16,17,18:14:paraphrase 19:15:preserved

Jegou et al. \cite use a Hough-like voting scheme in the space of similarity transformation between query and database image . 
Jegou et al. \cite use a Hough-like voting scheme in the space of similarity transformation between query and database image . 
74 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved

However , this is a weak geometric consistency checking . 
However , this is a weak geometric consistency checking . 
75 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved

Cao et al. propose to use spatial-bag-of-features the spatial ordering of visual words under various linear and circular projections \cite . Shen et al. proposed to transform query ROI by predefined scales \cite . 
Cao et al. proposed using spatial-bag-of-features the spatial ordering of visual words under various linear and circular projections \cite , while Shen et al. proposed transforming query ROI by predefined scales \cite . 
76 0:0:preserved 1:1:preserved 2:2:preserved 3,4,5:3,4:para-colocation 6:5:preserved 7:6:preserved 8:7:preserved 9:8:preserved 10:9:preserved 11:10:preserved 12:11:preserved 13:12:preserved 14:13:preserved 15:14:preserved 16:15:preserved 17:16:preserved 18:17:preserved 19:18:preserved 20:19,20:para-freeword 21:21:preserved 22:22:preserved 23:23:preserved 24,25,26:24,25:para-colocation 27:26:preserved 28:27:preserved 29:28:preserved 30:29:preserved 31:30:preserved 32:31:preserved 33:32:preserved

However , this method is much more computationally expensive than other systems such as BOW or WGC .
However , this latter method is much more computationally expensive than other systems such as BOW or WGC .
77 0:0:preserved 1:1:preserved 2:2:preserved 3:4,3:paraphrase 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved

All of the above methods do not mention or give a systematic solution to handle the failure of spatial re-ranking which caused by low number of feature or confus objects which has with query object . 
None of the above methods consider or provide a systematic solution to handle the failure of spatial re-ranking caused by a low number of features or by the existence of confus objects that have as a query object . 
78 0:0:paraphrase 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5,6,7,9:5,7:paraphrase 8:6:preserved 10:8:preserved 11:9:preserved 12:10:preserved 13:11:preserved 14:12:preserved 15:13:preserved 16:14:preserved 17:15:preserved 18:16:preserved 19:17:preserved 20,21:18:para-freeword 22:19:preserved 23:21:preserved 24:22:preserved 25:23:preserved 26:24:bigrammar-nnum 27:25:preserved 28,29,31,30,32:30,26,27,28,29,31,32,33,34,35:paraphrase 33:36:preserved 34:37:preserved 35:38:preserved :20:mogrammar-det

To the best of our knowledge , this is the first time solve that spatial verification problem .
To the best of our knowledge , this is the first time that the spatial verification problem has been solved .
79 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12,13:12:paraphrase 14:14:preserved 15:15:preserved 16:16,17,18,19:paraphrase 17:20:preserved :13:mogrammar-det

Deformable Part Models ( DPM ) is one of state-of-the-art algorithms in object detection . 
The deformable parts model ( DPM ) is a state-of-the-art algorithm in object detection . 
80 0,1,2:0,1,2,3:typo 3:4:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7,8,10:8,10:paraphrase 9:9:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved

The original version of DPM is very slow , thus it is difficult to apply on large-scale data . 
The original version of DPM is very slow , making it difficult to apply on large-scale data . 
81 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9,11,10:9,10:paraphrase 12:11:preserved 13:12:preserved 14:13:preserved 15:14:preserved 16:15:preserved 17:16:preserved 18:17:preserved

However , many research try to improve the accuracy and speed of DPM such as \cite , and could be applied for detection on large-scale dataset . 
However , due to research on improving the accuracy and speed of DPM \cite , and seems like it could be effective for detection on a large-scale dataset . 
82 0:0:preserved 1:1:preserved 2,4,5,6:2,3,5,6:paraphrase 3:4:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 13,14,12,15:12,13:paraphrase 16:14:preserved 17:15:preserved 18,19,20:19,16,17,18,20,21:paraphrase 21:22:preserved 22:23:preserved 23:24:preserved 24:26:preserved 25:27:preserved 26:28:preserved :25:mogrammar-det

Moreover , combining part filters with root filter , DPM also be an implicit spatial check method for our proposed approach .
Moreover , if we combine part filters with a root filter , DPM could also function as an implicit spatial check method for our proposed approach .
83 0:0:preserved 1:1:preserved 2:2,3,4:para-freeword 3:5:preserved 4:6:preserved 5:7:preserved 6:9:preserved 7:10:preserved 8:11:preserved 9:12:preserved 10,11:14,13,15,16:paraphrase 12:17:preserved 13:18:preserved 14:19:preserved 15:20:preserved 16:21:preserved 17:22:preserved 18:23:preserved 19:24:preserved 20:25:preserved 21:26:preserved :8:mogrammar-det

All systems implemented in the experiment section are based on the following settings . 
All systems implemented in the experiment section are based upon the following settings . 
88 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:bigrammar-prep 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved

Keyframes are extracted from raw videos at the rate of 5 frames per second . 
Keyframes are extracted from raw video at the rate of 5 frames per second . 
89 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:bigrammar-nnum 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved

For feature extraction , we use Hessian affine detector \cite and SIFT descriptor \cite . 
For feature extraction , we use a Hessian affine detector \cite and a SIFT descriptor \cite . 
90 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:13:preserved 12:14:preserved 13:15:preserved 14:16:preserved :6,12:mogrammar-det

To improve the performance of retrieval system , RootSIFT \cite post-processing are applied with out adding storage memory and computational cost . 
To improve the performance of the retrieval system , RootSIFT \cite post-processing is applied , with no additional storage memory or computational cost . 
91 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:typo 12:13:preserved 13:15,14:typo 14,15,18:16,17,20:para-freeword 16:18:preserved 17:19:preserved 19:21:preserved 20:22:preserved 21:23:preserved :5:mogrammar-det

A large vocabulary with 1 million visual words is trained using Approximate K-Means ( AKM ) algorithm \cite . 
A large vocabulary with 1 million visual words is trained using the approximate K-means ( AKM ) algorithm \cite . 
92 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11,12:11,12,13:typo 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved

To reduce quantization errors without adding storage memory , we use hard-assignment on database keyframes and soft-assignment on query images with three nearest neighbors . 
To reduce quantization errors without adding storage memory , we use hard-assignment on database keyframes and soft-assignment on query images with three nearest neighbors . 
93 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved

All frames of a shot are aggregated into one high-dimensional histogram vector using average pooling .
All frames of a shot are aggregated into one high-dimensional histogram vector using average pooling .
94 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved

Each query image of a topic are independently compared to all shots using asymmetrical metric \cite .
Each query image of a topic is independently compared to all shots using asymmetrical metrics \cite .
95 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:typo 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:bigrammar-nnum 15:15:preserved 16:16:preserved

Score of the final relevance between query topic and shot are computed using average fusion of all ranking lists returned from each query example retrieval .
The final relevance score between query topic and shot are computed using the average fusion of all ranking lists returned from each query example retrieval .
96 0,1,2,3,4:0,3,1,2:para-colocation 5:4:preserved 6:5:preserved 7:6:preserved 8:7:preserved 9:8:preserved 10:9:preserved 11:10:preserved 12:11:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved :12:unaligned

For simplicity of notation , we only consider set of query examples and keyframes of a shot in video dataset . 
For simplicity of notation , here we consider only the set of query examples and keyframes of a shot in the video dataset . 
97 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5,6,7:6,5,7,8:paraphrase 8:10:preserved 9:11:preserved 10:12:preserved 11:13:preserved 12:14:preserved 13:15:preserved 14:16:preserved 15:17:preserved 16:18:preserved 17:19:preserved 18:21:preserved 19:22:preserved 20:23:preserved :9,20:mogrammar-det

Other shots are processed similarly . 
Other shots are processed similarly . 
98 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved

Let </Eq> be vector BOW of the k-th query image and the j-th frame of video shot , where </Eq> is size of the codebook . 
Let </Eq> be the vector BOW of the k-th query image and the j-th frame of the video shot , respectively , where </Eq> is the size of the codebook . 
99 0:0:preserved 1:1:preserved 2:2:preserved 3:4:preserved 4:5:preserved 5:6:preserved 6:3:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:7:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:17:preserved 16:18:preserved 17:19:preserved 18:20,21,22:paraphrase 19:23:preserved 20:24:preserved 21:26:preserved 22:27:preserved 23:12:preserved 24:29:preserved 25:30:preserved :16:mogrammar-det :25:mogrammar-det :28:mogrammar-det

To be build inverted index with a compact representation , we use average pooling :
To build an inverted index with a compact representation , we use average pooling :
100 0,1,2:0,1:paraphrase 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved :2:mogrammar-det

where </Eq> is number of keyframes shot . 
where </Eq> is the number of keyframes a shot . 
101 0:0:preserved 1:1:preserved 2:2:preserved 3:4:preserved 4:5:preserved 5:6:preserved 6:8:preserved 7:9:preserved :3,7:mogrammar-det

Similarity score of shot with given query examples is computed by the following formula : 
The similarity score of a shot with given query examples is computed by 
102 0:0,1:bigrammar-det 1:2:preserved 2:3:preserved 3:5:preserved 4:6:preserved 5:7:preserved 6:8:preserved 7:9:preserved 8:10:preserved 9:11:preserved 10,11,12,13,14:12:paraphrase :4:mogrammar-det

where </Eq> is number of query examples and </Eq> is a asymmetrical similarity score . 
where </Eq> is the number of query examples and </Eq> is the asymmetrical similarity score . 
103 0:0:preserved 1:1:preserved 2:2:preserved 3:4:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:bigrammar-det 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved :3:mogrammar-det

Top </Eq> retrieved shots based on </Eq> similarity score are then used for re-ranking stage .
The top </Eq> retrieved shots based on the </Eq> similarity score are then used for the re-ranking .
104 0:0,1:bigrammar-det 1:2:preserved 2:3:preserved 3:4:preserved 4:5:preserved 5:6:preserved 6:8,7:bigrammar-det 7:9:preserved 8:10:preserved 9:11:preserved 10:12:preserved 11:13:preserved 12:14:preserved 14,13:15,16:paraphrase 15:17:preserved

In order to verify the confidence of shared visual words between query and database frames , we propose to use an object detector with denser feature . 
In order to verify the confidence of shared visual words between query and database frames , we propose using an object detector with denser features . 
109 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18,19:18:paraphrase 20:19:preserved 21:20:preserved 22:21:preserved 23:22:preserved 24:23:preserved 25:24:bigrammar-nnum 26:25:preserved

that DPM is one of the state-of-the-art algorithms with part-based representation model . 
that DPM is a state-of-the-art algorithm with a parts-based representation model . 
110 0:0:preserved 1:1:preserved 2:2:preserved 3,4,5:3:paraphrase 6:4:preserved 7:5:bigrammar-nnum 8:6:preserved 9:7,8:bigrammar-det 10:9:preserved 11:10:preserved 12:11:preserved

Histogram of Gradient feature ( HOG ) and latent-SVM was originally designed to handle change of illumination condition and variations in appearance of object .
A histogram of gradient features ( HOG ) and latent-SVM were originally designed to handle changing lighting conditions and variations in the appearance of an object .
111 0:1,0:bigrammar-det 1:2:preserved 2:3:typo 3:4:bigrammar-nnum 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:paraphrase 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14,15,16,17:15,16,17:paraphrase 18:18:preserved 19:19:preserved 20:20:preserved 21:22:preserved 22:23:preserved 23:25:preserved 24:26:preserved :21:mogrammar-det :24:mogrammar-det

DPM take the advantage of shape information : BOW model with SIFT descriptor ( or its extension , rootSIFT ) and DPM model with HOG features both are based on the same idea computing histogram of gradient vector at a group pixel . 
DPM takes advantage of shape information : The BOW model with a SIFT descriptor ( or its extension , rootSIFT ) and the DPM model with HOG features are both based on the idea of computing the histogram of a gradient vector at a group pixel . 
112 0:0:preserved 1:1:paraphrase 2:22:preserved 3:2:preserved 4:3:preserved 5:4:preserved 6:5:preserved 7:6:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:23:preserved 22:24:preserved 23:25:preserved 24:26:preserved 25:27:preserved 26:29:preserved 27:28:preserved 28:30:preserved 29:31:preserved 30:32:preserved 31,32:33,34:para-freeword 33:35:preserved 34:37:preserved 35:38:preserved 36:40:preserved 37:41:preserved 38:42:preserved 39:43:preserved 40:44:preserved 41:45:preserved 42:46:preserved :7:mogrammar-det :11:mogrammar-det :36:mogrammar-det :39:mogrammar-det

The difference is that : BOW use all of features independently while DPM algorithm groups local blocks together to represent a meaningful part . 
The difference is that BOW uses all of the features independently while the DPM algorithm groups local blocks together to represent a meaningful part . 
113 0:0:preserved 1:1:preserved 2:2:preserved 3,4:3:typo 5:4:preserved 6:5:paraphrase 7:6:preserved 8:7:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved :8,12:mogrammar-det

Moreover , feature detector used in standard BOW retrieval system is very sparse and sensitive to light condition or viewpoint while HOG feature of DPM always cover full of object . 
Moreover , the feature detector used in standard BOW retrieval systems is very sparse and sensitive to lighting condition or viewpoint , while the HOG feature of DPM always covers an object in its entirety . 
114 0:0:preserved 1:1:preserved 2:3:preserved 3:4:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:bigrammar-nnum 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:bigrammar-wform 17:18:preserved 18:19:preserved 19:20:preserved 20:21,22:typo 21:24:preserved 22:25:preserved 23:26:preserved 24:27:preserved 25:28:preserved 26:29:typo 27,28,29:30,32,33,34,31:paraphrase 30:35:preserved :2:mogrammar-det :23:mogrammar-det

Figure \ref shows a comparison between Hessian Affine feature used in BOW and HOG feature used in DPM . 
Figure \ref shows a comparison of the Hessian affine feature used in BOW and the HOG feature used in DPM . 
115 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5,6:paraphrase 6:7:preserved 7:8:typo 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:15:preserved 14:16:preserved 15:17:preserved 16:18:preserved 17:19:preserved 18:20:preserved :14:mogrammar-det

We can see that : the distribution of Hessian Affine feature are no uniform across regions within the same image . 
We can clearly see that the distribution of Hessian affine features is not uniform across regions within the same image . 
116 0:0:preserved 1:1:preserved 2:3:preserved 3:4:preserved 4:2:paraphrase 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:typo 10,11:10,11:bigrammar-nnum 12:12:typo 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved

In case of low contrast image , number of feature is very sparse or even no one detected . 
In the case of a low contrast image , the number of features is very sparse or even completely absent . 
117 0:0:preserved 1:2:preserved 2:3:preserved 3:5:preserved 4:6:preserved 5:7:preserved 6:8:preserved 7:10:preserved 8:11:preserved 9:12:bigrammar-nnum 10:13:preserved 11:14:preserved 12:15:preserved 13:16:preserved 14:17:preserved 15,16,17:18,19:paraphrase 18:20:preserved :1:mogrammar-det :4:mogrammar-det :9:mogrammar-det

Meanwhile HOG feature of part filter can always be described in all conditions including case of low contrast .
In contrast , the HOG feature of a part filter can always be described under all conditions , including cases of low contrast .
118 0:0,1,2:paraphrase 1:4:preserved 2:5:preserved 3:6:preserved 4:8:preserved 5:9:preserved 6:10:preserved 7:11:preserved 8:12:preserved 9:13:preserved 10:14:bigrammar-prep 11:15:preserved 12:16:preserved 13:18,17:typo 14:19:bigrammar-nnum 15:20:preserved 16:21:preserved 17:22:preserved 18:23:preserved :3:mogrammar-det :7:mogrammar-det

BOW and DPM are two complementary methods : In fact , there is no good method for all cases . 
BOW and DPM are two complementary methods : In fact , there is no one method that is superior for all cases . 
119 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11,12,13,14,15,16,17,18:11,12,13,14,15,16,17,18,19,20,21:para-freeword 19:22:preserved

For query objects which have dense local features , BOW model work effectively if accompanied with a spatial re-ranking method . 
For query objects that have dense local features , the BOW model is effective if accompanied with a spatial re-ranking method . 
120 0:0:preserved 1:1:preserved 2:2:preserved 3:3:para-freeword 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:10:preserved 10:11:preserved 11,12:12,13:paraphrase 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved :9:mogrammar-det

In case of small and textureless object , when lighting condition changes over time , the extracted features are sparser that makes the failure of spatial verification . 
However , in the case of a small and textureless object , when the lighting condition changes over time , the extracted features are sparser , which leads to spatial verification failure . 
121 0:0,1,2:paraphrase 1:4:preserved 2:5:preserved 3:7:preserved 4:8:preserved 5:9:preserved 6:10:preserved 7:11:preserved 8:12:preserved 9:14:preserved 10:15:preserved 11:16:preserved 12:17:preserved 13:18:preserved 14:19:preserved 15:20:preserved 16:21:preserved 17:22:preserved 18:23:preserved 19:24:preserved 20,21,24,23,25,26,22:25,26,27,28,29,30,31:para-freeword 27:32:preserved :3:mogrammar-det :6:mogrammar-det :13:mogrammar-det

On the other hand DPM algorithm as mentioned above can describe any object in any lighting conditions and take advantage of the shape information more effectively . 
In contrast , the DPM algorithm can describe any object under any lighting condition and is more effective when it comes to taking advantage of shape information . 
122 0,1,2,3:0,1,2,3:para-freeword 4:4:preserved 5:5:preserved 6,7,8,9:6:para-freeword 10:7:preserved 11:8:preserved 12:9:preserved 13:10:bigrammar-prep 14:11:preserved 15:12:preserved 16:13:bigrammar-nnum 17:14:preserved 18,21,25,19,22,23,24,20:15,17,18,19,20,21,22,23,24,25,26,16:para-freeword 26:27:preserved

However , DPM algorithms are generally suitable for detecting generic object which have discriminative curves that makes it significantly different with other ones . This characteristic of DPM algorithm give failures in object with too much texture .
However , DPM algorithms are generally suitable for detecting generic objects that have discriminative curves to show that they are significantly different from other ones , and this characteristic results in failure in objects with too much texture .
123 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:bigrammar-nnum 11:11:para-freeword 12:12:preserved 13:13:preserved 14:14:preserved 15,16,17,18,19,20,21,22:15,16,17,18,19,20,21,22,23,24:para-freeword 23,24:25,26,27:para-freeword 25:28:preserved 26,27,28,29,30,32,33,31:29,31,32,33,30,34:para-freeword 34:35:preserved 35:36:preserved 36:37:preserved 37:38:preserved

In order to show of these two approaches , we use a simple late fusion technique that combines two scores using formula . 
To demonstrate of these two approaches , we use a simple late fusion technique that combines two scores using an formula . 
124 0,1,2,3:0,1:para-freeword 4:2:preserved 5:3:preserved 6:4:preserved 7:5:preserved 8:6:preserved 9:7:preserved 10:8:preserved 11:9:preserved 12:10:preserved 13:11:preserved 14:12:preserved 15:13:preserved 16:14:preserved 17:15:preserved 18:16:preserved 19:17:preserved 20:18:preserved 21:20:preserved 22:21:preserved :19:mogrammar-det

This method will be compared to standard spatial re-ranking in the experiment section . 
This method will be compared to standard spatial re-ranking in the experiment section . 
125 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved

Let </Eq> be a model trained from all query examples and 100 random image crawled from Google image with "things" is the . 
Let </Eq> be a model trained from all query examples and 100 random images crawled from Google Images with "things" as the . 
126 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:bigrammar-nnum 14:14:preserved 15:15:preserved 16:16:preserved 17:17:typo 18:18:preserved 19:19:preserved 20:20:paraphrase 21:21:preserved 22:22:preserved

Similarity score of query topic and in database is compute as following : where </Eq> is a keyframe of video shot . 
The similarity score of the query topic and in the database is computed as where </Eq> is a keyframe of a video shot . 
127 0:0,1:bigrammar-det 1:2:preserved 2:3:preserved 3:5:preserved 4:6:preserved 5:7:preserved 6:8:preserved 7:10:preserved 8:11:preserved 9:12:bigrammar-wform 10:13:preserved 11,12,13:14:paraphrase 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:21:preserved 20:22:preserved 21:23:preserved :4:mogrammar-det :9:mogrammar-det :20:mogrammar-det

The final late fusion similarity of BOW and DPM models is computed using following average normalized formula :	
The final late fusion similarity of the BOW and DPM models is computed using the following average normalized formula :	
128 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:15:preserved 14:16:preserved 15:17:preserved 16:18:preserved 17:19:preserved :6,14:mogrammar-det

where </Eq> are z-score normalized value of </Eq> on top K of rank list , respectively :
where </Eq> are the z-score normalized values of </Eq> on the top K of the rank list , respectively :
129 0:0:preserved 1:1:preserved 2:2:preserved 3:4,3:bigrammar-det 4:5:preserved 5:6:bigrammar-wform 6:7:preserved 7:8:preserved 8:9:preserved 9:11:preserved 10:12:preserved 11:13:preserved 12:15:preserved 13:16:preserved 14:17:preserved 15:18:preserved 16:19:preserved :10,14:mogrammar-det

Note that this is just a simple average fusion technique on normalized scores .We still have a room to further improve on fusion formula xx . 
Note that this is just a simple average fusion technique on normalized scores , and there is still room to improve on fusion formula xx . 
130 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13,15:13,14,15,16:paraphrase 14:17:preserved 16::mogrammar-det 17:18:preserved 18:19:preserved 19,20:20:paraphrase 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved

The value of </Eq> and </Eq> can be estimated adaptively using more information about number of visual words and ROI area given by topic examples .
The values of </Eq> and </Eq> can be estimated adaptively using more information about the number of visual words and ROI area given by topic examples .
131 0:0:preserved 1:1:bigrammar-nnum 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:26:preserved :14:mogrammar-det

In late fusion approach , we simply combined score values of the two methods together without using any other useful information such as shared word and bounding box detected by DPM algorithm . 
In the late fusion approach , we simply combined the score values of the two methods without using any other information such as shared word or bounding box detected by DPM algorithm . 
136 0:0:preserved 1:2:preserved 2:3:preserved 3:4:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:10:preserved 9:11:preserved 10:12:preserved 11:1:preserved 12:14:preserved 13,14:15:paraphrase 15:16:preserved 16:17:preserved 17:18:preserved 18,19:19:paraphrase 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:bigrammar-prep 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved :9:mogrammar-det :13:mogrammar-det

In this section we propose an integrated approach to effectively utilize this information . 
In this section , we propose an integrated approach to effectively utilize this information . 
137 0:0:preserved 1:1:preserved 2:2:preserved 3:4:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved :3:bigrammar-others

Figure \ref describes all cases may happen to the BOW shared words and candidate's bounding box . 
Figure \ref displays all the cases that may occur with the BOW shared words and the candidate's bounding box . 
138 0:0:preserved 1:1:preserved 2:2:paraphrase 3:3:preserved 4:5:preserved 5:7:preserved 6,7:6,8,9:paraphrase 8:10:preserved 9:11:preserved 10:12:preserved 11:13:preserved 12:14:preserved 13:16:preserved 14:17:preserved 15:18:preserved 16:19:preserved :4:mogrammar-det :15:mogrammar-det

The ROI rectangle in the left image is the location of query object when put into the search engine . The object proposal region ( OPR ) rectangle on the right image is the DPM bounding box . 
The ROI rectangle in the left image is the location of a query object when put in the search engine and the object proposal region ( OPR ) rectangle in the right image is the DPM bounding box . 
139 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:bigrammar-prep 16:17:preserved 17:18:preserved 18:19:preserved 19:20:paraphrase 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:26:preserved 26:27:preserved 27:28:preserved 28:29:bigrammar-prep 29:30:preserved 30:31:preserved 31:32:preserved 32:33:preserved 33:34:preserved 34:35:preserved 35:36:preserved 36:37:preserved 37:38:preserved :11:mogrammar-det

Each arrow starts from visual word of query image and ends at visual word of video frame of the database . 
Each arrow starts from the visual word of a query image and ends at the visual word of a video frame the database . 
140 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:9:preserved 8:10:preserved 9:11:preserved 10:12:preserved 11:13:preserved 12:15:preserved 13:16:preserved 14:17:preserved 15:19:preserved 16:20:preserved 17::mogrammar-prep 18:21:preserved 19:22:preserved 20:23:preserved :4:mogrammar-det :8:mogrammar-det :14:mogrammar-det :18:mogrammar-det

All pairs of matching points are divided into the following categories :
All pairs of matching points are divided into the following categories :
141 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved

Type 1 : Outlier shared words are the wrong pair of matched points represented by red arrows . 
Type 1 : Outlier shared words , which are incorrect pairings of matched points represented by red arrows . 
142 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:8:preserved 7,8,9:6,7,9,10:para-freeword 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved

These pairs of points will be removed by RANSAC algorithm , and the rest is the inlier pair of matching points includes three of next types .
These pairs of points will be removed by the RANSAC algorithm , and the remaining pairs are inlier pairs of matching points that fall into one of the next three types .
143 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:8:preserved 13:14,15:paraphrase 14:16:bigrammar-inter 15:13:preserved 16:17:preserved 17:18:bigrammar-nnum 18:19:preserved 19:20:preserved 20:21:preserved 21:22,23,24,25:paraphrase 22:29:preserved 23:26:preserved 24:28:preserved 25:30:preserved 26:31:preserved :27:mogrammar-det

Type 2 : discriminative points are represented by green arrows connecting words in the foreground to words inside DPM bounding box . 
Type 2 : Discriminative points , which are represented by green arrows connecting words in the foreground to words inside the DPM bounding box . 
144 0:0:preserved 1:1:preserved 2:2:preserved 3:3:typo 4:4:preserved 5:5,6,7:paraphrase 6:8:preserved 7:9:preserved 8:10:preserved 9:11:preserved 10:12:preserved 11:13:preserved 12:14:preserved 13:15:preserved 14:16:preserved 15:17:preserved 16:18:preserved 17:19:preserved 18:21:preserved 19:22:preserved 20:23:preserved 21:24:preserved :20:mogrammar-det

These points satisfy both BOW model and DPM algorithm so they contribute to identify accurately query object . 
These points satisfy both the BOW model and the DPM algorithm and thus contribute to the accurate identification of the query object . 
145 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:9:preserved 8:10:preserved 9,10:11,12:para-freeword 11:13:preserved 12:14:preserved 13,14:16,17:para-colocation 15:20:preserved 16:21:preserved 17:22:preserved :4:mogrammar-det :8:mogrammar-det :15:mogrammar-det :18:mogrammar-prep :19:mogrammar-det

Therefore we choose a monotonically increasing function of number of discriminative points </Eq> .
We choose a monotonically increasing function of the number of discriminative points </Eq> .
146 0,1:0:para-freeword 2:1:preserved 3:2:preserved 4:3:preserved 5:4:preserved 6:5:preserved 7:6:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved :7:mogrammar-det

Type 3 : weakly relevant points are represented by the blue arrows connecting point in the foreground to point outside the DPM bounding box . 
Type 3 : Weakly relevant points , which are represented by blue arrows connecting a point in the foreground to a point outside the DPM bounding box . 
147 0:0:preserved 1:1:preserved 2:2:preserved 3:3:typo 4:4:preserved 5:5:preserved 6:8:preserved 7:9:preserved 8:10:preserved 9:17:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:15:preserved 14:16:preserved 15:23:preserved 16:18:preserved 17:19:preserved 18:21:preserved 19:22:preserved 20:20:bigrammar-det 21:24:preserved 22:25:preserved 23:26:preserved 24:27:preserved :6,7:unaligned :14:mogrammar-det

These points show the inconsistency between BOW model and DPM but it still contains valuable information , so we also use a monotonically increasing function of number of weakly relevant points </Eq> .
These points indicate an inconsistency between the BOW model and DPM , but they still contain valuable information , so we also use a monotonically increasing function of the number of weakly relevant points </Eq> .
148 0:0:preserved 1:1:preserved 2:2:paraphrase 3:6:preserved 4:4:preserved 5:5:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:12:preserved 11:13:bigrammar-nnum 12:14:preserved 13:15:bigrammar-inter 14:16:preserved 15:17:preserved 16:18:preserved 17:19:preserved 18:20:preserved 19:21:preserved 20:22:preserved 21:23:preserved 22:24:preserved 23:25:preserved 24:26:preserved 25:27:preserved 26:29:preserved 27:30:preserved 28:31:preserved 29:32:preserved 30:33:preserved 31:34:preserved 32:35:preserved :3:mogrammar-det :28:mogrammar-det

However , this function increases does not as fast as function </Eq> .
This function does not increase as fast as function </Eq> .
149 0,1::unaligned 2:0:preserved 3:1:preserved 4:4:bigrammar-inter 5:2:preserved 6:3:preserved 7:5:preserved 8:6:preserved 9:7:preserved 10:8:preserved 11:9:preserved 12:10:preserved

Type 4 : context information points are represented by black arrows connecting outside points ( background point ) of query image to points outside bounding box . 
Type 4 : Context information points , which are represented by black arrows connecting outside ( background ) points of a query image to points outside the bounding box . 
150 0:0:preserved 1:1:preserved 2:2:preserved 3:3:typo 4:4:preserved 5:5:preserved 6:8:preserved 7:9:preserved 8:10:preserved 9:11:preserved 10:12:preserved 11:13:preserved 12:14:preserved 13:18:preserved 14:15:preserved 15,16:16:paraphrase 17:17:preserved 18:19:preserved 19:21:preserved 20:22:preserved 21:23:preserved 22:24:preserved 23:25:preserved 24:27:preserved 25:28:preserved 26:29:preserved :6,7:unaligned :20:mogrammar-det :26:mogrammar-det

Although the main query object to be searched in the foreground , but the features on the background sometimes gives useful information for detecting objects . 
Although the main query object to be searched in the foreground , the features in the background sometimes provide useful information for detecting objects . 
151 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12::unaligned 13:12:preserved 14:13:preserved 15:14:bigrammar-prep 16:15:preserved 17:16:preserved 18:17:preserved 19:18:paraphrase 20:19:preserved 21:20:preserved 22:21:preserved 23:22:preserved 24:23:preserved 25:24:preserved

For example , the logo of a car company often located next to a car . 
For example , the logo of a car company is often located next to a car . 
152 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved :9:bigrammar-others

Context information can contribute to the final result but not too much so weighting function of context points should be used </Eq> which increases not as fast as functions </Eq> , </Eq> .
Context information can contribute to the final result , albeit slightly , so the weighting function of context points </Eq> should be used , although these do not increase as fast as functions </Eq> , </Eq> .
153 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8,10,11,22,23,9:9,10,11,23,24,25,26,28:para-freeword 12:12:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:20:preserved 19:21:preserved 20:22:preserved 21:19:preserved 24:27:preserved 25:29:preserved 26:30:preserved 27:31:preserved 28:32:preserved 29:33:preserved 30:34:preserved 31:35:preserved 32:36:preserved :8:unaligned :13:mogrammar-det

are wrong cases removed by RANSAC algorithm . Therefore we will not consider them in the final score formula .
are incorrect cases and thus removed by the RANSAC algorithm ; we do not consider them in the final score formula .
154 0:0:preserved 1:1:paraphrase 2:2:preserved 3:5:preserved 4:6:preserved 5:8:preserved 6:9:preserved 7::unaligned 8:3,4,10:para-freeword 9:11:preserved 10:12:bigrammar-vtense 11:13:preserved 12:14:preserved 13:15:preserved 14:16:preserved 15:7:preserved 16:18:preserved 17:19:preserved 18:20:preserved 19:21:preserved :17:mogrammar-det

Let </Eq> is a set of points in image which represent location of the k-th given query example .
Let </Eq> be a set of points in an image that represents the location of the k-th given query example .
155 0:0:preserved 1:1:preserved 2:2:bigrammar-inter 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:9:preserved 9:10:paraphrase 10:11:bigrammar-inter 11:13:preserved 12:14:preserved 13:12:preserved 14:16:preserved 15:17:preserved 16:18:preserved 17:19:preserved 18:20:preserved :8:mogrammar-det :15:mogrammar-det

where </Eq> and </Eq> are spatially verified points belong to Hessian Affine features extracted from query image and video frame which have the same word ID , respectively .
where </Eq> and </Eq> are spatially verified points belonging to the Hessian affine features extracted from the query image and video frame that have the same word ID , respectively .
158 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:paraphrase 9:9:preserved 10:11:preserved 11:12:typo 12:13:preserved 13:14:preserved 14:15:preserved 15:17:preserved 16:18:preserved 17:19:preserved 18:20:preserved 19:21:preserved 20:22:paraphrase 21:23:preserved 22:10:preserved 23:25:preserved 24:26:preserved 25:27:preserved 26:28:preserved 27:29:preserved 28:30:preserved :16:mogrammar-det :24:mogrammar-det

Our goal is not to find the optimal weighting function , we prove that our new method of calculating the score associated with selecting a suitable weighting function can improve accuracy significantly compared with . 
Our goal is not to find the optimal weighting function but rather to prove that our new method of calculating the score associated with selecting a suitable weighting function can improve accuracy significantly compared with . 
159 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10,11:10,11,12:paraphrase 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:26:preserved 26:27:preserved 27:28:preserved 28:29:preserved 29:30:preserved 30:31:preserved 31:32:preserved 32:33:preserved 33:34:preserved 34:35:preserved

The weighting functions must satisfy the following properties :
The weighting functions must satisfy the following properties :
160 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved

Property 1 . for all </Eq> . 
Property 1 . for all </Eq> . 
161 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved

The more verified shared words the more confidence it is .
The greater the number of verified shared words , the higher the confidence is .
162 0:0:preserved 1,6,8:1,3,4,8,9,10,11:paraphrase 2:5:preserved 3:6:preserved 4:7:preserved 5:2:preserved 7:12:preserved 9:13:preserved 10:14:preserved

Property 2 . </Eq> for all </Eq>
Property 2 . </Eq> for all </Eq>
163 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved

This feature aims of each other as well as the average score of component models and </Eq> when number of shared visual words of each type equals to 0 . 
This feature aims and the average score of the component models and </Eq> when the number of shared visual words of each type equals 0 . 
164 0:0:preserved 1:1:preserved 2:2:preserved 3:7:preserved 4:21:preserved 5,6,7,8,23,24:3:paraphrase 9:4:preserved 10:5:preserved 11:6:preserved 12:16:preserved 13:9:preserved 14:10:preserved 15:11:preserved 16:12:preserved 17:13:preserved 18:15:preserved 19:20:preserved 20:17:preserved 21:18:preserved 22:19:preserved 25:22:preserved 26:23:preserved 27::mogrammar-prep 28:24:preserved 29:25:preserved :8:mogrammar-det :14:mogrammar-det

Therefore , in special cases if n = 0 then we are .
Therefore , in special cases , if n = 0 , we are .
165 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:5,10:paraphrase 10:11:preserved 11:12:preserved 12:13:preserved

Property 3 . </Eq> for all </Eq> . 
Property 3 . </Eq> for all </Eq> . 
166 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved

This feature : distinctive points , weak points , and distinctive point bringing context information .
This feature : distinctive points , weak points , and distinctive point bringing context information .
167 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved

For ease of testing , we assume that these functions are in the same class of polynomial function . 
For ease of testing , we assume that these functions are in the same class of polynomial function . 
168 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved

In this paper , we propose three weighting functions as follows :
In this paper , we propose three weighting functions :
169 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9,10::bigrammar-others 11:9:preserved

The final score of the proposed method becomes :
The final score of the proposed method becomes :
170 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved

where </Eq> .
where </Eq> .
171 0:0:preserved 1:1:preserved 2:2:preserved

In this section , a series of experiments were conducted to evaluate the proposed re-ranking method using BOW and an object detector model , where , DPM was chosen to demonstrate our idea . 
In this section , we discuss the series of experiments we performed to evaluate the proposed re-ranking method using BOW and an object detector model , where DPM was chosen to demonstrate our idea . 
176 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4::mogrammar-det 5:7:preserved 6:8:preserved 7:9:preserved 8,9:4,5,10,11:paraphrase 10:12:preserved 11:13:preserved 12:6:preserved 13:15:preserved 14:16:preserved 15:17:preserved 16:18:preserved 17:19:preserved 18:20:preserved 19:21:preserved 20:22:preserved 21:23:preserved 22:24:preserved 24,25,23:26,25:typo 26:27:preserved 27:28:preserved 28:29:preserved 29:30:preserved 30:31:preserved 31:32:preserved 32:33:preserved 33:34:preserved :14:mogrammar-det

First , in order to show the complementary characteristic ; we comparfed BOW and DPM with its average late fusion . 
First , in order to demonstrate the complementary characteristics of BOW and DPM , its average late fusion . 
177 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:paraphrase 6:6:preserved 7:7:preserved 8:8:bigrammar-nnum 9,10,11,15:13:paraphrase 12:10:preserved 13:11:preserved 14:12:preserved 16:14:preserved 17:15:preserved 18:16:preserved 19:17:preserved 20:18:preserved :9:mogrammar-prep

Second , we compare our location-based fusion approach to other state-of-the-art techniques such as : practical spatial re-ranking \cite , Hamming Embeding and Weak Geometric Consistency \cite , multi-features fusion[x] and topology checking \cite . 
Second , we compare our location-based fusion approach with other state-of-the-art techniques : practical spatial re-ranking \cite , Hamming embedding and weak geometric consistency \cite , and multi-features fusion[x] and topology checking \cite . 
178 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:bigrammar-prep 9:9:preserved 10:10:preserved 11:11:preserved 12,13:29:para-freeword 14:12:preserved 15:13:preserved 16:14:preserved 17:15:preserved 18:16:preserved 19:17:preserved 20:18:preserved 21:19:typo 22:20:preserved 23,24,25:21,22,23:typo 26:24:preserved 27:25:preserved 28:27:preserved 29:28:preserved 30:26:preserved 31:30:preserved 32:31:preserved 33:32:preserved 34:33:preserved

Third , we examine the impact of value top </Eq> and contributions of each weighting functions on the performance of whole system . 
Third , we examine the impact of value top </Eq> and the contributions of each weighting function to the performance of the system as a whole . 
179 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:bigrammar-nnum 16:17:bigrammar-prep 17:11:preserved 18:19:preserved 19:20:preserved 20:25:preserved 21:22:preserved 22:26:preserved :18:mogrammar-det :21:mogrammar-det :23:mogrammar-prep :24:mogrammar-det

To demonstrate advantage of the proposed method on multiple types of query , we use TRECVID Instance Search ( INS ) datasets for evaluation . 
To determine the performance of the proposed method with multiple types of query , we use TRECVID Instance Search ( INS ) datasets for evaluation . 
183 0:0:preserved 1,2:1,3,2:paraphrase 3:4:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:bigrammar-prep 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved

We use the TRECVID INS [xx] benchmarks in years 2013 and 2014 which was released in the evaluation campaign organized by NIST . For experiments , we name these as INS2013 and INS2014 , respectively . 
Specifically , we used the TRECVID INS [xx] benchmarks from 2013 and 2014 , which were released in the evaluation campaign organized by NIST , referred to here as INS2013 and INS2014 , respectively . 
184 0:2:preserved 1:3:bigrammar-vtense 2:4:preserved 3:5:preserved 4:6:preserved 5:7:preserved 6:8:preserved 7:9:bigrammar-prep 8,9:10:paraphrase 10:11:preserved 11:12:preserved 12:14:preserved 13:15:bigrammar-inter 14:16:preserved 15:17:preserved 16:18:preserved 17:19:preserved 18:20:preserved 19:21:preserved 20:22:preserved 21:23:preserved 22::unaligned 23,24,27,28,26:0,24,25,26,27,32:para-freeword 25:1:preserved 29:28:preserved 30:29:preserved 31:30:preserved 32:31:preserved 33:13:preserved 34:33:preserved 35:34:preserved

They share the same collection of test video with a master shot reference . 
Both have the same collection of test videos with a master shot reference . 
185 0,1:0,1:paraphrase 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:bigrammar-nnum 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved

The dataset contains approximately 244 video files extracted from the BBC EastEnders program with totally 300 GB in storage and 464 hours in duration . 
The dataset contains approximately 244 video files extracted from the BBC EastEnders program with a total of 300 GB in storage and a duration of 464 hours . 
186 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14,15,16:paraphrase 15:17:preserved 16:18:preserved 17:19:preserved 18:20:preserved 19:21:preserved 20:25:preserved 21,23,22:23,24,26:para-colocation 24:27:preserved :22:mogrammar-det

Each query topic of INS2013 and INS2014 consists of several query images and corresponding masks that delimit an object , place or person entity in some example video ; locate for each topic up to the 1000 shots most likely to contain a recognizable instance of the entity . 
Each query topic of INS2013 and INS2014 consists of several query images and corresponding masks that delimit an object , place , or person entity in an example video and locate for each topic up to 1000 of the shots most likely to contain a recognizable instance of the entity . 
187 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:21:paraphrase 26:27:preserved 27:28:preserved 28:29:paraphrase 29:30:preserved 30:31:preserved 31:32:preserved 32:33:preserved 33:34:preserved 34:35:preserved 35:38:preserved 36:36:preserved 37:39:preserved 38:40:preserved 39:41:preserved 40:42:preserved 41:43:preserved 42:44:preserved 43:45:preserved 44:46:preserved 45:47:preserved 46:48:preserved 47:49:preserved 48:50:preserved :26:mogrammar-det :37:mogrammar-prep

INS datasets are challenging due to containing varieties of query types including small to big objects , rich texture to texture-less objects .
We should point out that INS datasets are quite challenging due to containing a variety of query types including small to big objects and rich texture to texture-less objects .
188 0:5:preserved 1:6:preserved 2:7:preserved 3:9:preserved 4:10:preserved 5:11:preserved 6:12:preserved 7:13,14:bigrammar-nnum 8:15:preserved 9:16:preserved 10:17:preserved 11:18:preserved 12:19:preserved 13:20:preserved 14:21:preserved 15:22:preserved 16:23:paraphrase 17:24:preserved 18:25:preserved 19:26:preserved 20:27:preserved 21:28:preserved 22:29:preserved :0,1,2,3,4,8:unaligned

Evaluation protocol . 
Evaluation protocol . 
189 0:0:preserved 1:1:preserved 2:2:preserved

The ground truth files for each query are created manually and provided by TRECVID organization . 
The ground truth files for each query are created manually and provided by the TRECVID organization . 
190 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:14:preserved 14:15:preserved 15:16:preserved :13:mogrammar-det

To evaluate performance of each system , we use mean average precision as a standard score .
To evaluate the performance of each system , we use the mean average precision as a standard score .
191 0:0:preserved 1:1:preserved 2:3:preserved 3:4:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:11:preserved 10:12:preserved 11:13:preserved 12:14:preserved 13:15:preserved 14:16:preserved 15:17:preserved 16:18:preserved :2,10:mogrammar-det

We first , evaluate the performance of late fusion technique to prove the complementary characteristic of BOW and DPM . 
First , to demonstrate the complementary characteristics of BOW and DPM , we evaluate the performance of the late fusion technique . 
196 0,11:3,11,12:paraphrase 1:0:preserved 2:1:preserved 3:13:preserved 4:4:preserved 5:15:preserved 6:7:preserved 7:18:preserved 8:19:preserved 9:20:preserved 10:2:preserved 12:14:preserved 13:5:preserved 14:6:bigrammar-nnum 15:16:preserved 16:8:preserved 17:9:preserved 18:10:preserved 19:21:preserved :17:mogrammar-det

Top 10 ,000 shots retrieved from standard BOW model are used to re-rank using DPM object detector . 
The top 10 ,000 shots retrieved from the standard BOW model are used for re-ranking using the DPM object detector . 
197 0:1:preserved 1:2:preserved 2:3:preserved 3:4:preserved 4:5:preserved 5:6:preserved 6:8:preserved 7:9:preserved 8:10:preserved 9:11:preserved 10:12:preserved 11:13:bigrammar-prep 12:14:paraphrase 13:15:preserved 14:17:preserved 15:18:preserved 16:19:preserved 17:20:preserved :0:mogrammar-det :7:mogrammar-det :16:mogrammar-det

from all query example to find location of candidate object and its corresponding score value the similarity value for re-ranking . 
from all query example to find the location of the candidate object and its corresponding score value , the similarity value for re-ranking . 
198 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:7:preserved 7:8:preserved 8:10:preserved 9:11:preserved 10:12:preserved 11:13:preserved 12:14:preserved 13:15:preserved 14:16:preserved 15:6:preserved 16:19:preserved 17:20:preserved 18:21:preserved 19:22:preserved 20:23:preserved :9,17,18:mogrammar-det

The score represented for a shot is the highest one of all keyframes ( equation 3 ) , BOW+DPM : average late fusion on normalized scores of BOW and DPM .
The score representing one shot is the highest one of all keyframes ( Eq.3 ) , BOW+DPM : average late fusion on normalized scores of BOW and DPM .
199 0:0:preserved 1:1:preserved 2:2:bigrammar-vtense 3::mogrammar-prep 4:3:paraphrase 5:4:preserved 6:5:preserved 7:6:preserved 8:7:preserved 9:8:preserved 10:9:preserved 11:10:preserved 12:11:preserved 13:12:preserved 14,15:13:paraphrase 16:14:preserved 17:15:preserved 18:16:preserved 19:17:preserved 20:18:preserved 21:19:preserved 22:20:preserved 23:21:preserved 24:22:preserved 25:23:preserved 26:24:preserved 27:25:preserved 28:26:preserved 29:27:preserved 30:28:preserved

Figure \ref shows that , although BOW is state-of-the-art model for image retrieval , in some cases , DPM gives better result such as : 9108 , 9109 , 9114 , 9118 , 9124 , 9125 and 9128 . 
Figure \ref shows that , although BOW is a state-of-the-art model for image retrieval , in some cases , DPM gives a better result : for example , 9108 , 9109 , 9114 , 9118 compared to 9124 , 9125 , 9128 , respectively . 
200 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:22:preserved 21:23:preserved 22,23:25,26,35,36,42,43:paraphrase 24:24:preserved 25:28:preserved 26:27:preserved 27:30:preserved 28:29:preserved 29:32:preserved 30:31:preserved 31:34:preserved 32:33:preserved 33:37:preserved 34:38:preserved 35:39:preserved 36:40:paraphrase 37:41:preserved 38:44:preserved :8:mogrammar-det :21:mogrammar-det

DPM+BOW gives approximate performance with the higher one between DPM and BOW for most of query topics . 
DPM+BOW gives a performance approximately on par with the higher one between DPM and BOW for most query topics . 
201 0:0:preserved 1:1:preserved 2,3:3,4:para-colocation 4:7:preserved 5:8:preserved 6:9:preserved 7:10:preserved 8:11:preserved 9:12:preserved 10:13:preserved 11:14:preserved 12:15:preserved 13:16:preserved 14::mogrammar-prep 15:17:preserved 16:18:preserved 17:19:preserved :2:mogrammar-det :5,6:unaligned

In some cases , such as 9102 , 9103 , 9123 , it is also significantly better than two baseline methods . 
In some cases , e.g. , 9102 , 9103 , 9123 , it is also significantly better than the two baseline methods . 
202 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4,5:4,5:paraphrase 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved :18:mogrammar-det

Therefore , the overall MAP of DPB+BOW is 28.21% and outperform both BOW and DPM ( 25.01% and 21.23% , respectively ) see Table \ref . 
Therefore , the overall MAP of DPB+BOW is 28.21% , which outperforms both BOW and DPM ( 25.01% and 21.23% , respectively ; see Table \ref ) . 
203 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:10:paraphrase 10:11:bigrammar-nnum 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:26:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:27:preserved :9:unaligned :22:unaligned

In this section , we compared the proposed method with other state-of-the-art systems which have reported on INS2013 and INS2014 . 
In this section , we compare the proposed method with other state-of-the-art systems that have been reported on INS2013 and INS2014 . 
208 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:bigrammar-vtense 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:paraphrase 14,15:15,14,16:para-passact 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved

Multi features in the system won on TRECVID INS 2013 competition which combine six pair of feature detectors and descriptors using asymmetrical similarity and late fusion technique [x] .
The winner of the TRECVID INS 2013 competition was the multi-features system , which combines six pairs of feature detectors and descriptors using asymmetrical similarity and late fusion technique [x] .
209 0,1,2,5,6:0,1,8,9,10,12,2:para-freeword 3:3:preserved 4:11:preserved 7:4:preserved 8:5:preserved 9:6:preserved 10:7:preserved 11:13:preserved 12:14:bigrammar-inter 13:15:preserved 14:16:bigrammar-nnum 15:17:preserved 16:18:preserved 17:19:preserved 18:20:preserved 19:21:preserved 20:22:preserved 21:23:preserved 22:24:preserved 23:25:preserved 24:26:preserved 25:27:preserved 26:28:preserved 27:29:preserved 28:30:preserved

Hamming Embedding and Weak Geometric Consistency ( HE+WCG ) votes dominant scale and orientation for fast but geometric checking . 
Hamming embedding and weak geometric consistency ( HE+WCG ) dominant scale and orientation but geometric checking . 
210 0:0:preserved 1:1:typo 2:2:preserved 3,4,5:3,5,4:typo 6:6:preserved 7:7:preserved 8:8:preserved 9,10:9:paraphrase 11:10:preserved 12:11:preserved 13:12:preserved 14::mogrammar-prep 15,16:13:paraphrase 17:14:preserved 18:15:preserved 19:16:preserved

Topology checking ( TC ) approach uses delaunay triangulation to improve the quality of visual matching . However , this method still does overcome problem spatial verification mentioned in this paper . 
The topology checking ( TC ) approach uses Delaunay triangulation to improve the quality of visual matching , but it cannot overcome the problem spatial verification mentioned in this paper . 
211 0:1:preserved 1:2:preserved 2:3:preserved 3:4:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:typo 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16::unaligned 17,20,21,22,19:18,19,20:para-freeword 18:17:preserved 23:21:preserved 24:23:preserved 25:24:preserved 26:25:preserved 27:26:preserved 28:27:preserved 29:28:preserved 30:29:preserved 31:30:preserved :0:mogrammar-det :22:mogrammar-det

Practical spatial re-ranking ( PSC ) apply RANSAC for a representative frame to avoid verifying all images of a shot or query topic .
Practical spatial re-ranking ( PSC ) applies RANSAC for a representative frame to avoid having to verify all images of a shot or query topic .
212 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:bigrammar-inter 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14,15,16:paraphrase 15:17:preserved 16:18:preserved 17:19:preserved 18:20:preserved 19:21:preserved 20:22:preserved 21:23:preserved 22:24:preserved 23:25:preserved

Table \ref shows a comparison of the proposed method with state-of-the-art results . 
Table \ref shows a comparison of the results of the proposed method and the state-of-the-art methods . 
213 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7,8:10,7,8,11:para-colocation 9:12:paraphrase 10:14,15:paraphrase 11::unaligned 12:16:preserved :9:mogrammar-det :13:mogrammar-det

As afore mentioned , the performance of the method is evaluated two benchmarks . 
As stated above , performance is evaluated two benchmarks . 
214 0:0:preserved 1,2,6,7,8:1,2:paraphrase 3:3:preserved 4::mogrammar-det 5:4:preserved 9:5:preserved 10:6:preserved 11:7:preserved 12:8:preserved 13:9:preserved

We can see that , our approach consistently outperform other method , although we use only one pair of feature detector and descriptor . 
As shown in the table , the proposed approach consistently outperforms the other methods , even though we use only one pair of feature detector and descriptor . 
215 0,1,2,3,5,12:0,1,2,3,4,6,7,15,16:para-freeword 4:5:preserved 6:8:preserved 7:9:preserved 8:10:bigrammar-inter 9:12:preserved 10:13:bigrammar-nnum 11:14:preserved 13:17:preserved 14:18:preserved 15:19:preserved 16:20:preserved 17:21:preserved 18:22:preserved 19:23:preserved 20:24:preserved 21:25:preserved 22:26:preserved 23:27:preserved :11:mogrammar-det

Moreover , our late fusion technique BOW+DPM also give an approximate accuracy compared to Multi-features approach with a simple average computation . 
Our late fusion technique BOW+DPM also delivers an approximate accuracy compared to the multi-features approach with a simple average computation . 
216 0,1::unaligned 2:0:preserved 3:1:preserved 4:2:preserved 5:3:preserved 6:4:preserved 7:5:preserved 8:6:paraphrase 9:7:preserved 10:8:preserved 11:9:preserved 12:10:preserved 13:11:preserved 14:13:typo 15:14:preserved 16:15:preserved 17:16:preserved 18:17:preserved 19:18:preserved 20:19:preserved 21:20:preserved :12:mogrammar-det

There is possibly still more room for improvement by adaptively combining BOW and DPM model . 
There is still room for improvement by adaptively combining the BOW and DPM models . 
217 0:0:preserved 1:1:preserved 2,4::unaligned 3:2:preserved 5:3:preserved 6:4:preserved 7:5:preserved 8:6:preserved 9:7:preserved 10:8:preserved 11:10:preserved 12:11:preserved 13:12:preserved 14:13:bigrammar-nnum 15:14:preserved :9:mogrammar-det

Although Multi-features and other spatial re-ranking methods improve performance very much , but they still do not solve the failure of spatial verification . 
Although the multi-features and other spatial re-ranking methods improve performance very much , they cannot resolve the failure of spatial verification . 
218 0:0:preserved 1:2:typo 2:3:preserved 3:4:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12,14,15,16,17:14,15,16:para-freeword 13:13:preserved 18::mogrammar-det 19:17:preserved 20:18:preserved 21:19:preserved 22:20:preserved 23:21:preserved :1:mogrammar-det

The result also shows that , our method is good for not only small and texture-less objects but also big and rich textured ones .
The results also show that our method is effective not only for small and texture-less objects but also for big and richly textured ones .
219 0:0:preserved 1:1:bigrammar-nnum 2:2:preserved 3:3:bigrammar-inter 4:4:preserved 5::unaligned 6:5:preserved 7:6:preserved 8:7:preserved 9:8:paraphrase 10:11:preserved 11:9:preserved 12:10:preserved 13:12:preserved 14:13:preserved 15:14:preserved 16:15:preserved 17:16:preserved 18:17:preserved 19:19:preserved 20:20:preserved 21:21:bigrammar-wform 22:22:preserved 23:23:preserved 24:24:preserved :18:mogrammar-prep

Ipact of parameter </Eq> . 
Effect of parameter </Eq> . 
220 0:0:paraphrase 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved

In this part , we examine the influence of value </Eq> to the final mAP when taking top </Eq> shots as the input of re-ranking stage . 
Here , we briefly examine the effect of value </Eq> on the final mAP when taking top </Eq> shots as input at the re-ranking stage . 
221 0,1,2:0,3:para-freeword 3:1:preserved 4:2:preserved 5:4:preserved 6:5:preserved 7:6:paraphrase 8:7:preserved 9:8:preserved 10:9:preserved 11:10:bigrammar-prep 12:11:preserved 13:12:preserved 14:13:preserved 15:14:preserved 16:15:preserved 17:16:preserved 18:17:preserved 19:18:preserved 20:19:preserved 21:22:preserved 22:20:preserved 23:21:bigrammar-prep 24:23:preserved 25:24:preserved 26:25:preserved

Figure \ref shows that when </Eq> , the accuracy of the proposed algorithm seem to be saturated with no more improvement . 
Figure \ref shows that when </Eq> , the accuracy of the proposed algorithm seem to be saturated with no more improvement . 
222 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved

On the other hand , when </Eq> , there still have many positive shost in the bottom of the rank list returned standard BOW model . 
In contrast , when </Eq> , there are still many positive shots in the bottom of the rank list returned the standard BOW model . 
223 0,2,3:0,1:para-freeword 1:13:preserved 4:2:preserved 5:3:preserved 6:4:preserved 7:5:preserved 8:6:preserved 9:8:preserved 10:7:paraphrase 11:9:preserved 12:10:preserved 13:11:typo 14:12:preserved 15:16:preserved 16:14:preserved 17:15:preserved 18:20:preserved 19:17:preserved 20:18:preserved 21:19:preserved 22:21:preserved 23:22:preserved 24:23:preserved 25:24:preserved

Even in case of the least value </Eq> , the mAP of proposed method is </Eq> and </Eq> ( for INS2013 and INS2014 , respectively ) . 
Even in the case of the least value </Eq> , the mAP of the proposed method is </Eq> and </Eq> ( for INS2013 and INS2014 , respectively ) . 
224 0:0:preserved 1:1:preserved 2:3:preserved 3:4:preserved 4:2:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:5:preserved 10:11:preserved 11:12:preserved 12:14:preserved 13:15:preserved 14:16:preserved 15:17:preserved 16:18:preserved 17:19:preserved 18:20:preserved 19:21:preserved 20:22:preserved 21:23:preserved 22:24:preserved 23:25:preserved 24:26:preserved 25:27:preserved 26:28:preserved :10,13:mogrammar-det

Contribution of each component in late fusion formula . 
Contribution of each component in late fusion formula . 
225 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved

In this part , weighting functions by constant 1 to evaluate the influence of each component on the system performance . 
Here , weighting functions by constant 1 to evaluate the effect of each component on the system performance . 
226 0,1,2:0:para-freeword 3:1:preserved 4:2:preserved 5:3:preserved 6:4:preserved 7:5:preserved 8:6:preserved 9:7:preserved 10:8:preserved 11:9:preserved 12:10:paraphrase 13:11:preserved 14:12:preserved 15:13:preserved 16:14:preserved 17:15:preserved 18:16:preserved 19:17:preserved 20:18:preserved

We conduct a comparison of methods BOW and our final method with the configurations described in Table \ref . The base score mentioned in the table are the average normalized score of BOW and DPM</Eq> .
We compare the BOW methods with our final method using the configurations in Table \ref , where the base score refers to the average normalized score of BOW and DPM</Eq> .
227 0:0:preserved 1,3:1:paraphrase 2:2:bigrammar-det 4::mogrammar-prep 5:4:preserved 6:3:preserved 7:5:paraphrase 8:6:preserved 9:7:preserved 10:8:preserved 11:9:paraphrase 12:10:preserved 13,14:11:paraphrase 15:12:preserved 16:13:preserved 17:14:preserved 18:30:preserved 19:17:preserved 20:18:preserved 21:19:preserved 22:20:paraphrase 23:21:bigrammar-prep 24::mogrammar-det 25,26,35:15,16:paraphrase 27:22:preserved 28:23:preserved 29:24:preserved 30:25:preserved 31:26:preserved 32:27:preserved 33:28:preserved 34:29:preserved

Table \ref shows that removing of any component of the re-ranking formula also decrease the accuracy significantly . 
Table \ref shows that removing any component of the re-ranking formula decreases the accuracy significantly . 
228 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:7:preserved 6:5:preserved 7:6:preserved 8::mogrammar-prep 9:8:preserved 10:9:preserved 11:10:preserved 12,13:11:bigrammar-inter 14:12:preserved 15:13:preserved 16:14:preserved 17:15:preserved

As a result , in the final formula . 
As a result , in the final formula . 
229 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved

Without this component , the performance drop down significantly . 
Without this component , the performance drops significantly . 
230 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6,7:6:paraphrase 8:7:preserved 9:8:preserved

In addition to satisf three properties as mention in Section \ref , </Eq> should not be rapidly increasing functions because . 
In addition to satisfying the three properties mentioned in Section \ref , </Eq> should not be rapidly increasing functions because . 
231 0:0:preserved 1:1:preserved 2:2:preserved 3:3:typo 4:5:preserved 5:6:preserved 6::mogrammar-prep 7:7:bigrammar-vtense 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved :4:mogrammar-det

Therefore , square function for </Eq> . 
Therefore , a square function for </Eq> . 
232 0:0:preserved 1:1:preserved 2:3:preserved 3:4:preserved 4:5:preserved 5:6:preserved 6:7:preserved :2:mogrammar-det

Similarly , the next important components are functions </Eq> respectively . 
Similarly , the next most important components are functions </Eq> . 
233 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:4:paraphrase 10:10:preserved

On the other hand , we also see that verifying pair matching shared word using RANSAC algorithm also help to improve the accuracy very much . 
We can see that verifying the pair matching shared word using the RANSAC algorithm also helps to significantly improve the accuracy . 
234 0,2,3,4,23,24,6:1,17:para-freeword 1::mogrammar-det 5:0:preserved 7:2:preserved 8:3:preserved 9:4:preserved 10:6:preserved 11:7:preserved 12:8:preserved 13:9:preserved 14:10:preserved 15:12:preserved 16:13:preserved 17:14:preserved 18:15:bigrammar-inter 19:16:preserved 20:18:preserved 21:19:preserved 22:20:preserved 25:21:preserved :5:mogrammar-det :11:mogrammar-det

This was shown in configuration Ours\_w/oRANSAC , where the same formula xx are applied without spatial verification step .
This was shown in configuration Ours\_w/oRANSAC , where the same formulae xx are applied without any spatial verification step .
235 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:typo 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved :15:unaligned

In this paper , we address about the failure of spatial verification in instance search or /object retrieval system . 
In this paper , we addressed the failure of spatial verification in instance search/object retrieval systems . 
241 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:bigrammar-vtense 6::mogrammar-prep 7:6:preserved 8:7:preserved 9:8:preserved 10:9:preserved 11:10:preserved 12:11:preserved 13:12:preserved 14,15,16:13:paraphrase 17:14:preserved 18:15:bigrammar-nnum 19:16:preserved

A new hybrid method that takes advantage of the complementary characteristic of BOW and DPM model has been introduced to overcome this challenge . 
A new hybrid method that takes advantage of the complementary characteristics of the BOW and DPM models has been introduced to overcome this challenge . 
242 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:bigrammar-nnum 11:11:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:bigrammar-nnum 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved :12:mogrammar-det

We classify pairs of verified visual words into three types based on the relationship between location of visual words and proposal region . 
We classify pairs of verified visual words into three types based on the relationship between the location of visual words and the region . 
243 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:bigrammar-det 21:22:preserved 22:23:preserved :15:mogrammar-det

Each of this type corresponds to a weighting function which will boost the similarity score in re-ranking step . 
Each of these types corresponds to a weighting function that will boost the similarity score at the time of re-ranking . 
244 0:0:preserved 1:1:preserved 2,3:2,3:bigrammar-nnum 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9,15,17:9,15,16,17,18:paraphrase 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 16:19:preserved 18:20:preserved

Our experimental results show the superiority of our method compared to other state-of-the-art approaches .
Experimental results demonstrate the superiority of our method compared to other state-of-the-art approaches .
245 0::unaligned 1:0:preserved 2:1:preserved 3:2:paraphrase 4:3:preserved 5:4:preserved 6:5:preserved 7:6:preserved 8:7:preserved 9:8:preserved 10:9:preserved 11:10:preserved 12:11:preserved 13:12:preserved 14:13:preserved

Future work will involve exploring adaptive late fusion technique for the base score which combine the normalized BOW and DPM similarity score . 
Our future work will involve exploring adaptive late fusion techniques for the base score that combine the normalized BOW and DPM similarity scores . 
246 0:0,1:para-freeword 1:2:preserved 2:3:preserved 3:4:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:bigrammar-nnum 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:paraphrase 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:bigrammar-nnum 22:23:preserved

Moreover , our scheme enables us to replace DPM byh any other object detectors without changing the structure of the system .
Our scheme enables us to replace the DPM with other object detectors without changing the structure of the system .
247 0,1::unaligned 2:0:preserved 3:1:preserved 4:2:preserved 5:3:preserved 6:4:preserved 7:5:preserved 8:7:preserved 9,10:8:typo 11:9:preserved 12:10:preserved 13:11:preserved 14:12:preserved 15:13:preserved 16:6:preserved 17:15:preserved 18:16:preserved 19:14:preserved 20:18:preserved 21:19:preserved :17:mogrammar-det

