A Multi-Stage Approach to Fast Face Detection
A Multi-Stage Approach to Fast Face Detection
2 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved

A multi-stage approach --- which is fast , robust and easy to train --- for a face-detection system is proposed .
A multi-stage approach that is fast , robust , and easy to train is proposed for a face-detection system .
6 0:0:preserved 1:1:preserved 2:2:preserved 4:3:bigrammar-others 5:4:preserved 6:5:preserved 7:6:preserved 8:7:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18,19:13,14:preserved 20:19:preserved

Motivated by the work of Viola and Jones [1] , this approach uses a cascade of classifiers to yield a coarse-to-fine strategy to reduce significantly detection time while maintaining a high detection rate .
Motivated by the work of Viola and Jones [1] , this approach uses a cascade of classifiers to yield a coarse-to-fine strategy to significantly reduce detection time while maintaining a high detection rate .
7 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:24:preserved 24:23:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved

However , it is distinguished from previous work by two features .
However , our [system / approach?] is distinguished from previous work by two features .
8 0:0:preserved 1:1:preserved 2:2:paraphrase 3:6:preserved 4:7:preserved 5:8:preserved 6:9:preserved 7:10:preserved 8:11:preserved 9:12:preserved 10:13:preserved 11:14:preserved

First , a new stage is added to detect face candidate regions more quickly by using a larger window size and larger moving step size .
First , a new stage has been added to detect face candidate regions more quickly by using a larger window size and larger moving step size .
9 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5,6:5,6,7:bigrammar-vtense 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:26:preserved

Second , SVM classifiers are used instead of AdaBoost classifiers in the last stage , and Haar wavelet features selected by the previous stage are reused for the SVM classifier robustly and efficiently .
Second , support vector machine ( SVM ) classifiers are used instead of AdaBoost classifiers in the last stage , and Haar wavelet features selected by the previous stage are reused for the SVM classifier robustly and efficiently .
10 0:0:preserved 1:1:preserved 2:2,3,4,6:paraphrase 3:8:preserved 4,5,6,7,8,9:9,10,11,12,13,14:preserved 10,11,12,13:18,15,16,17:preserved 16,15,17,18,19,20,21,22,23,24,25,26:20,21,22,23,24,25,26,27,28,29,30,31:preserved 27,28,29,30,31,32:32,33,34,35,36,37:preserved

By combining AdaBoost and SVM classifiers , the final system can achieve both fast and robust detection because most non-face patterns are rejected quickly in earlier layers , while only a small number of promising face patterns is classified robustly in later layers .
By combining AdaBoost and SVM classifiers , the final system can achieve both fast and robust detection because most non-face patterns are rejected quickly in earlier layers , while only a small number of promising face patterns are classified robustly in later layers .
11 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved 35:35:preserved 36:36:preserved 37:37:bigrammar-inter 38:38:preserved 39:39:preserved 40:40:preserved 41:41:preserved 42:42:preserved 43:43:preserved

The proposed multi-stage-based system is shown to run faster than the original AdaBoost-based system while maintaining comparable accuracy .
The proposed multi-stage-based system has been shown to run faster than the original AdaBoost-based system while maintaining comparable accuracy .
12 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4,5:4,5,6:bigrammar-vtense 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved

Face detection is one of the most active research areas in computer vision because of its many interesting applications in fields such as security , surveillance , multimedia retrieval , and human-computer interaction .
Face detection is one of the most active research areas in computer vision because of its many interesting applications in fields such as security , surveillance , multimedia retrieval , and human-computer interaction .
17 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved

For example , face detection is combined with other modules to identify who a person in a video sequence is [2] .
For example , face detection is combined with other modules to identify a person in a video sequence [2] .
18 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 13:12:preserved 14:13:preserved 15:14:preserved 16:15:preserved 17:16:preserved 18:17:preserved 20:18:preserved 21:19:preserved

Face locations , the results of a face detection system , can be used for applications such as face recognition and video indexing [3] .
Face locations , the results of a face detection system , can be used for applications such as face recognition and video indexing [3] .
19 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved

Although it has been studied for more than 30 years , developing a fast and robust face detection system that can handle the variations found in different faces in real applications , such as facial expressions , pose changes , illumination changes , complex backgrounds , and low resolutions , is still a challenging research target [4] .
Although this area has been studied for more than 30 years , developing a fast and robust face detection system that can handle the variations found in different faces in real applications , such as facial expressions , pose changes , illumination changes , complex backgrounds , and low resolutions , is still a challenging research target [4] .
20 0:0:preserved 1:1,2:paraphrase 2:3:preserved 3:4:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:26:preserved 26:27:preserved 27:28:preserved 28:29:preserved 29:30:preserved 30:31:preserved 31:32:preserved 32:33:preserved 33:34:preserved 34:35:preserved 35:36:preserved 36:37:preserved 37:38:preserved 38:39:preserved 39:40:preserved 40:41:preserved 41:42:preserved 42:43:preserved 43:44:preserved 44:45:preserved 45:46:preserved 46:47:preserved 47:48:preserved 48:49:preserved 49:50:preserved 50:51:preserved 51:52:preserved 52:53:preserved 53:54:preserved 54:55:preserved 55:56:preserved 56:57:preserved 57:58:preserved

Recently , with advances in machine learning research , Neural Network [5] ,[6] , Support Vector Machines ( SVM ) [7] ,[8] ,[9] and AdaBoost [1] ,[10] ,[11] ,[12] ,[13] are typical choices for building robust face detectors .
Recently , with advances in machine learning research , neural networks [5] , [6] , support vector machines ( SVM ) [7] , [8] , [9] and AdaBoost [1] , [10] , [11] , [12] , [13] are typical choices for building robust face detectors .
23 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:spelling 11:11:preserved 12:13:preserved 13:12:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 22,21:25,23,24,22:preserved 23:26:preserved 24:27:preserved 25:28:preserved 26,27,28,29:30,29,32,31,34,33,36,35:preserved 30,31,32,33,34,35,36,37:37,38,39,40,41,42,43,44:preserved

Current research is focusing on feature extractions and appropriate structures for combining classifiers .
Current research is focusing on feature extractions and appropriate structures for combining classifiers .
24 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved

Generally , to classify an input pattern of intensities as a face or non-face , features must be extracted and normalized before passing to a classifier [14] .
Generally , to classify an input pattern of intensities as a face or non-face , features must be extracted and normalized before passing [the image / the pattern / the results?] to a classifier [14] .
27 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved

There are many kinds of features that have been used ranging from simple features such as intensity values [7] ,[5] and eigenspace [15] to complex features such as wavelets [16] ,[1] ,[12] , edge orientation histograms [17] ,[18] and Bayesian discriminating features ( BDF ) [19] .
Many kinds of features have been used , ranging from simple ones such as intensity values [7] , [5] and eigenspace [15] to complex ones such as wavelets [16] , [1] , [12] , edge orientation histograms [17] , [18] , and Bayesian discriminating features ( BDF ) [19] .
28 2:0:preserved 3:1:preserved 4:2:preserved 5:3:preserved 6,13:11:paraphrase 7:4:preserved 8:5:preserved 9:6:preserved 10:8:preserved 11:9:preserved 12:10:preserved 14:12:preserved 15:13:preserved 16:14:preserved 17:15:preserved 18:16:preserved 19:18,17:preserved 20:19:preserved 21:20:preserved 22:21:preserved 23:22:preserved 24:23:preserved 25:24:paraphrase 26:25:preserved 27:26:preserved 28:27:preserved 29:28:preserved 30,31:30,31,32:preserved 32:29:preserved 33:34:preserved 34:35:preserved 35:36:preserved 36:37:preserved 37:39,38,40:preserved 38:41:preserved 39:42:preserved 40:43:preserved 41:44:preserved 42:45:preserved 43:46:preserved 44:47:preserved 45:48:preserved 46:49:preserved

Discriminative and informative features usually increase detection rate and reduce complexity of the training procedure [17] .
Discriminative and informative features usually increase detection rates and reduce the complexity of training procedures [17] .
29 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:bigrammar-nnum 8:8:preserved 9:9:preserved 10:11:preserved 11:12:preserved 12:10:preserved 13:13:preserved 14:14:bigrammar-nnum 15:15:preserved 16:16:preserved

In a typical face detector which is scale-free and location-free , the number of analyzed patterns is usually very large ( 160 ,000 patterns for a 320x240 pixel image ) because the face classifier has to scan over the input image at every location and every scale .
In a typical face detector that is scale- and location-free , the number of analyzed patterns is usually very large ( 160 ,000 patterns for a 320x240 pixel image ) because the face classifier has to scan over the input image at every location and every scale .
32 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:bigrammar-others 6:6:preserved 7,8,9:7,8,9:spelling 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved 35:35:preserved 36:36:preserved 37:37:preserved 38:38:preserved 39:39:preserved 40:40:preserved 41:41:preserved 42:42:preserved 43:43:preserved 44:44:preserved 45:45:preserved 46:46:preserved 47:47:preserved

However , the huge majority of the analyzed patterns are non-face .
However , the vast majority of the analyzed patterns are non-face .
33 0:0:preserved 1:1:preserved 2:2:preserved 3:3:paraphrase 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved

Statistics from [9] have shown that the ratio of non-face to face patterns is about 50 ,000 to 1 .
Statistics from [9] have shown that the ratio of non-face to face patterns is about 50 ,000 to 1 .
34 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved

Face detectors based on single classifiers such as SVM [7] ,[8] ,[9] and Neural Network [6] ,[5] are usually slow because they process non-face regions and face regions in the input image equally .
Face detectors based on single classifiers such as SVM [7] , [8] , [9] and neural networks [6] , [5] are usually slow because they equally process non-face and face regions in the input image .
35 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10,11:11,10,12,13:preserved 12:14:preserved 13:15:preserved 14:16:spelling 15:17:preserved 16:19,18:preserved 17:20:preserved 18:21:preserved 19:22:preserved 20:23:preserved 21:24:preserved 22:26:preserved 23:27:preserved 25:28:preserved 26:29:preserved 27:30:preserved 28:31:preserved 29:32:preserved 30:33:preserved 31:34:preserved 32:25:preserved 33:35:preserved

To deal with the problem of processing a large number of patterns , a combination of simple-to-complex classifiers is proposed [8] ,[1] ,[9] ,[20] ,[21] ,[11] .
To deal with the problem of processing a large number of patterns , a combination of simple-to-complex classifiers has been proposed [8] , [1] , [9] , [20] , [21] , [11] .
38 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18,19:18,19,20:bigrammar-vtense 20:21:preserved 23,21,22,24,25:23,22,24,25,26,27,28,29,30,31:preserved

In particular , fast and simple classifiers are used as filters at the earliest stages to quickly reject a large number of non-face patterns and a slower yet more accurate classifier is then used for classifying face-like patterns .
In particular , fast and simple classifiers are [recommended to be?] used as filters at the earliest stages to quickly reject a large number of non-face patterns and a slower yet more accurate classifier is then recommended to be used for classifying face-like patterns .
39 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:11:preserved 9:12:preserved 10:13:preserved 11:14:preserved 12:15:preserved 13:16:preserved 14:17:preserved 15:18:preserved 16:19:preserved 17:20:preserved 18:21:preserved 19:22:preserved 20:23:preserved 21:24:preserved 22:25:preserved 23:26:preserved 24:27:preserved 25:28:preserved 26:29:preserved 27:30:preserved 28:31:preserved 29:32:preserved 30:33:preserved 31:34:preserved 32:35:preserved 33:39,36,37,38:paraphrase 34:40:preserved 35:41:preserved 36:42:preserved 37:43:preserved

By this way , the complexity of classifiers is adapted corresponding to the difficulty in the input patterns .
In this way , the complexity of classifiers can be adapted corresponding to the difficulty in the input patterns . / / [is / can be?]
40 0:0:bigrammar-prep 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8,9:8,9,10:bigrammar-vtense 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved

In [8] , non linear SVM classifiers using pixel-based features are arranged into a sequence with increasing number of support vectors , or in [9] , linear SVM classifiers trained at different resolutions are used for rejection and a reduced set of principle component analysis ( PCA )-based features are used with the non linear SVM at the classification stage in order to reduce computation time .
In [8] , nonlinear SVM classifiers using pixel-based features were arranged into a sequence by increasing the number of support vectors , while in [9] , linear SVM classifiers trained at different resolutions were used for rejection and a reduced set of principle component analysis ( PCA )-based features were used with the nonlinear SVM at the classification stage in order to reduce computation time .
41 0:0:preserved 1:1:preserved 2:2:preserved 3,4:3:spelling 5:4:preserved 6:5:preserved 7:6:preserved 8:7:preserved 9:8:preserved 10,11:9,10:bigrammar-vtense 12:11:preserved 13:12:preserved 14:13:preserved 15:14:bigrammar-prep 16:15:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:paraphrase 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33,34:33,34:bigrammar-vtense 35:35:preserved 36:36:preserved 37:37:preserved 38:38:preserved 39:39:preserved 40:40:preserved 41:41:preserved 42:42:preserved 43:43:preserved 44:44:preserved 45:45:preserved 46:46:preserved 47:47:preserved 48:48:preserved 49,50:49,50:bigrammar-vtense 51:51:preserved 52:52:preserved 53,54:53:spelling 55:54:preserved 56:55:preserved 57:56:preserved 58:57:preserved 59:58:preserved 60:59:preserved 61:60:preserved 62:61:preserved 63:62:preserved 64:63:preserved 65:64:preserved 66:65:preserved

In [1] , AdaBoost based classifiers are arranged in a degeneration decision tree or a cascade .
In [1] , AdaBoost-based classifiers were arranged in a degeneration decision tree or a cascade .
42 0:0:preserved 1:1:preserved 2:2:preserved 3,4:3:spelling 5:4:preserved 6,7:5,6:bigrammar-vtense 8:7:preserved 9:8:preserved 10:9:preserved 11:10:preserved 12:11:preserved 13:12:preserved 14:13:preserved 15:14:preserved 16:15:preserved

Using about 10 features of the first two layers , more than 90\% of non-face patterns are rejected .
Using about 10 features of the first two layers , more than 90\% of non-face patterns were rejected .
43 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16,17:16,17:bigrammar-vtense 18:18:preserved

Recently , boosting chain [20] and nested cascade [11] have also been proposed for improvements .
Recently , a boosting chain [20] and a nested cascade [11] have also been proposed for improvements .
44 0:0:preserved 1:1:preserved 2:3:preserved 3:4:preserved 4:5:preserved 5:6:preserved 6:8:preserved 7:9:preserved 8:10:preserved 9:11:preserved 10:12:preserved 11:13:preserved 12:14:preserved 13:15:preserved 14:16:preserved 15:17:preserved :2:mogrammar-det :7:mogrammar-det

It is believed that the cascade structure of classifiers is the key factor in enhancement of current real-time face detectors .
It is believed that the cascade structure of classifiers is the key factor in enhancement of current real-time face detectors . / / It is believed?This sounds vague?who believes this? " May researchers believe , " for example , would be clearer and sound more believable .]
45 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved

This work is motivated by Viola and Jones [1] who proposed a framework for fast and robust face detection .
This work is motivated by Viola and Jones [1] , who proposed a framework for fast and robust face detection .
48 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved

Their success mainly comes from three contributions :
Their success comes mainly from three contributions :
49 0:0:preserved 1:1:preserved 2:3:preserved 3:2:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved

-Firstly , the cascaded structure of simple-to-complex classifiers reduces computation time dramatically ( as mentioned above ) .
-The cascaded structure of simple-to-complex classifiers reduces computation time dramatically .
52 2::mogrammar-det 3:1:preserved 4:2:preserved 5:3:preserved 6:4:preserved 7:5:preserved 8:6:preserved 9:7:preserved 10:8:preserved 11:9:preserved :0:mogrammar-det

-Secondly , AdaBoost is used to select discriminative and significant features from a pool of a very large number of features and then construct the classifier .
-AdaBoost is used to select discriminative and significant features from a pool of a very large number of features and then construct the classifier .
55 2:0:preserved 3:1:preserved 4:2:preserved 5:3:preserved 6:4:preserved 7:5:preserved 8:6:preserved 9:7:preserved 10:8:preserved 11:9:preserved 12:10:preserved 13:11:preserved 14:12:preserved 15:13:preserved 16:14:preserved 17:15:preserved 18:16:preserved 19:17:preserved 20:18:preserved 21:19:preserved 22:20:preserved 23:21:preserved 24:22:preserved 25:23:preserved 26:24:preserved

The output classifier built from these selected features is very fast and robust in classification .
The output classifier built from these selected features is very fast and robust in classification .
56 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved

Compared to SVM-based classifiers or neural network-based classifiers , AdaBoost based classifiers are hundreds of times faster .
Compared to SVM-based classifiers or neural network-based classifiers , AdaBoost-based classifiers are hundreds of times faster .
57 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9,10:9:spelling 11:10:preserved 12:11:preserved 13:12:preserved 14:13:preserved 15:14:preserved 16:15:preserved 17:16:preserved

-Thirdly , Haar-wavelet features used for all stages are informative [22] and evaluated extremely fast due to the introduction of the integral image .
-Haar wavelet features used for all stages are informative [22] and can be evaluated extremely quickly due to the introduction of the integral image .
60 2:0,1:spelling 3:2:preserved 4:3:preserved 5:4:preserved 6:5:preserved 7:6:preserved 8:7:preserved 9:8:preserved 10:9:preserved 11:10:preserved 12:11,12,13:bigrammar-vtense 13:14:preserved 14:15:paraphrase 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved

However , this framework still has the following problems :
However , this framework still has the following problems :
63 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved

-First , the cascaded classifiers that use AdaBoost and Haar wavelet features are only efficient in quickly rejecting simple non-face patterns .
-First , the cascaded classifiers that use AdaBoost and Haar wavelet features are only efficient in quickly rejecting simple non-face patterns .
66 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved

To robustly classify complex patterns , it is necessary to use a larger number of features and layer classifiers .
To robustly classify complex patterns , it is necessary to use a larger number of features and layer classifiers .
67 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved

This need is apparent when face and non-face patterns become hard to distinguish , weak classifiers are too weak to boost [22] .
This need is apparent because when face and non-face patterns become hard to distinguish , weak classifiers are too weak to boost [22] .
68 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:5,4:paraphrase 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved

With the first several layers in our experiment ( cf. Figure 1 ) , using some 800 weak classifiers , more than \MATH of non-face patterns are rejected .
With the first several layers in our experiment ( cf . Figure 1 ) , using some 800 weak classifiers , more than \MATH of non-face patterns were rejected .
69 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9,10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:26:preserved 26,27:27,28:bigrammar-vtense 28:29:preserved

However , turning the later layers into robustly classifying a smaller number of remaining patterns , it requires a lot more , e.g. , 5 ,660 , weak classifiers , thus making the training task much more complicated .
However , enabling the later layers to robustly classify a smaller number of remaining patterns requires many more weak classifiers ( around 5 ,660 ) , thus making the training task much more complicated .
70 0:0:preserved 1:1:preserved 2:2:paraphrase 3:3:preserved 4:4:preserved 5:5:preserved 6:6:bigrammar-prep 7:7:preserved 8:8:bigrammar-wform 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 17:15:preserved 18,19:16:paraphrase 20:17:preserved 22:21:paraphrase 23:25:preserved 24:22:preserved 25:23:preserved 27,28:18,19:preserved 30,31,32,33,34,35,36,37:26,27,28,29,31,30,33,32:preserved

-Second , the training process is complicated .
-Second , the training process is complicated .
73 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved

Firstly , it requires a long training time because the training time is proportional to the number of features in the input feature set ( which is normally hundreds of thousands ) and the number of training samples ( which is generally tens of thousands ) .
It requires a long time because the training time is proportional to the number of features in the input feature set ( which is normally hundreds of thousands ) and the number of training samples ( which is generally tens of thousands ) .
74 2:0:preserved 3:1:preserved 4:2:preserved 5:3:preserved 6,10,11:7,8:preserved 7:4:preserved 8:5:preserved 9:6:bigrammar-det 12:9:preserved 13:10:preserved 14:11:preserved 15,20:17,12:bigrammar-det 16:13:preserved 17:14:preserved 18:15:preserved 19:16:preserved 21:18:preserved 22:19:preserved 23:20:preserved 24:21:preserved 25:22:preserved 26:23:preserved 27:24:preserved 28:25:preserved 29:26:preserved 30:27:preserved 31:28:preserved 32:29:preserved 33:30:preserved 34:31:preserved 35:32:preserved 36:33:preserved 37:34:preserved 38:35:preserved 39:36:preserved 40:37:preserved 41:38:preserved 42:39:preserved 43:40:preserved 44:41:preserved 45:42:preserved 46:43:preserved

In our experiment , with 20 ,000 training samples and 134 ,736 features , the average training time for choosing one feature associated with the weak classifier is about 30 minutes on a PC ( Pentium 4 , 2 .8 MHz , 512-MB RAM ) .
In our experiment , with 20 ,000 training samples and 134 ,736 features , the average training time for choosing one feature associated with the weak classifier was about 30 minutes on a PC ( Pentium 4 , 2 .8 MHz , 512-MB RAM ) .
75 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:bigrammar-vtense 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved 35:35:preserved 36:36:preserved 37:37:preserved 38:38:preserved 39:39:preserved 40:40:preserved 41:41:preserved 42:42:preserved 43:43:preserved 44:44:preserved 45:45:preserved

Therefore , training a cascade of classifiers with around 6 ,060 features [1] might take in order of several weeks .
Therefore , training a cascade of classifiers with around 6 ,060 features [1] might take on the order of several weeks .
76 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:bigrammar-prep 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved :16:mogrammar-det

Secondly , AdaBoost-based classifiers are constructed by adding features after each round of boosting , so several training parameters must be tuned manually while training .
Another thing that complicates the training process is that AdaBoost-based classifiers are constructed by adding features after each round of boosting , so several training parameters must be tuned manually while training .
77 0:0,1,2,3,4,5,6,7,8:paraphrase 2,3,4,5,6,7,8,9,10,11,12,13:9,10,11,12,13,14,15,16,17,18,19,20:preserved 15,16,17:22,23,24:preserved 22,21,20,19,18:29,28,27,26,25:preserved 23,24:31,30:preserved

In practice , for stopping training a classifier , at least the following three parameters must be determined in advance : minimum detection rate , maximum false positive rate , and maximum number of boosting rounds ( or the number of weak classifiers of each layer ) .
In practice , for stopping training a classifier , at least the following three parameters must be determined in advance : minimum detection rate , maximum false positive rate , and maximum number of boosting rounds ( or the number of weak classifiers of each layer ) .
78 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved 35:35:preserved 36:36:preserved 37:37:preserved 38:38:preserved 39:39:preserved 40:40:preserved 41:41:preserved 42:42:preserved 43:43:preserved 44:44:preserved 45:45:preserved 46:46:preserved 47:47:preserved

Because the complexity of the training sets varies through layers in the cascade , it is undetermined how to choose these parameters automatically and optimally .
Because the complexity of the training sets varies throughout the layers in the cascade , a way to choose these parameters automatically and optimally has not been determined .
79 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:bigrammar-prep 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 16,14,15,17:24,25,26,27,15,16:paraphrase 18:17:preserved 19:18:preserved 20:19:preserved 21:20:preserved 22:21:preserved 23:22:preserved 24:23:preserved 25:28:preserved :9:mogrammar-det

For example , in the first layers , it is quite easy to train a classifier with a minimum detection rate of \MATH and a maximum false-positive rate of \MATH .
For example , in the first layers , it is quite easy to train a classifier with a minimum detection rate of \MATH and a maximum false-positive rate of \MATH .
80 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved

However , in later layers , choosing the detection rate of \MATH will give a false positive rate greater than \MATH [22] .
However , in later layers , choosing the detection rate of \MATH will give a false positive rate greater than \MATH [22] .
81 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved

Adding more features directly increases computation time and might cause over-fitting .
Adding more features directly increases computation time and might cause over-fitting .
82 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved

The authors therefore propose a multi-stage approach to build a face-detection system by adopting the advantages of Viola and Jones' approach and by introducing a method to address the above problems .
The authors therefore propose a multi-stage approach to build a face-detection system by adopting the advantages of Viola and Jones' approach and by introducing a method to address the above problems .
85 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved

Specifically , for quick rejection of non-face patterns , we reuse two key ingredients of Viola and Jones' system , that is , the cascaded structure of simple-to-complex classifiers and AdaBoost trained with Haar-wavelet features .
Specifically , for quick rejection of non-face patterns , we have reused two key ingredients of Viola and Jones' system , that is , the cascaded structure of simple-to-complex classifiers and AdaBoost trained with Haar wavelet features .
86 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:11,10:bigrammar-vtense 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:26:preserved 26:27:preserved 27:28:preserved 28:29:preserved 29:30:preserved 30:31:preserved 31:32:preserved 32:33:preserved 33:34,35:spelling 34:36:preserved 35:37:preserved

Furthermore , for robust classification and simple training , we propose using SVM classifiers for later layers .
Furthermore , for robust classification and simple training , we propose using SVM classifiers for later layers .
87 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved

The contribution of this approach is three fold :
The contribution of this approach is threefold :
88 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 7,6:6:spelling 8:7:preserved

-First , to detect the face candidate regions , a new stage ( using a larger window size and a larger moving step size ) is added .
-First , to detect the face candidate regions , a new stage ( using a larger window size and a larger moving step size ) has been added .
91 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25,26:25,26,27:bigrammar-vtense 27:28:preserved

We use 36 x 36-pixel window-based classifiers with a moving step size of 12 pixels , to quickly estimate the candidate face regions .
We use 36 x 36-pixel window-based classifiers with a moving step size of 12 pixels to quickly estimate the candidate face regions .
92 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 16:15:preserved 17:16:preserved 18:17:preserved 19:18:preserved 20:19:preserved 21:20:preserved 22:21:preserved 23:22:preserved

The idea of using larger windows and moving the step size was adopted in [5] , but it severely degraded performance .
The idea of using larger windows and moving the step size was adopted in [5] , but it severely degraded performance .
93 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved

To improve speed while maintaining high accuracy , our approach takes advantage of the combination of the Haar wavelet features and the AdaBoost learning for fast and robust evaluation
To improve speed while maintaining high accuracy , our approach takes advantage of the combination of the Haar wavelet features and the AdaBoost learning for fast and robust evaluation .
94 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved

Second , how to efficiently reuse the features selected by AdaBoost in the previous stage , for the SVM classifiers of the last stage , is investigated .
Second , we have investigated how to efficiently reuse the features selected by AdaBoost in the previous stage for the SVM classifiers of the last stage .
97 0:0:preserved 1:1:preserved 2:5:preserved 3:6:preserved 4:7:preserved 5:8:preserved 6:9:preserved 7:10:preserved 8:11:preserved 9:12:preserved 10:13:preserved 11:14:preserved 12:15:preserved 13:16:preserved 14:17:preserved 16:18:preserved 17:19:preserved 18:20:preserved 19:21:preserved 20:22:preserved 21:23:preserved 22:24:preserved 23:25:preserved 26,25:2,3,4:paraphrase 27:26:preserved

Reusing these features brings to two advantages : ( i ) Haar wavelet features are very fast in evaluating and normalizing [1] .
Reusing these features brings two advantages : ( i ) Haar wavelet features are very fast in being evaluated and normalized [1] .
98 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4::mogrammar-prep 5:4:preserved 6:5:preserved 7:6:preserved 8:7:preserved 9:8:preserved 10:9:preserved 11:10:preserved 12:11:preserved 13:12:preserved 14:13:preserved 15:14:preserved 16:15:preserved 17:16:preserved 20,18:20,18,17:para-passact 19:19:preserved 21:21:preserved 22:22:preserved

Furthermore , it is unnecessary to re-evaluate these features because they have been previously evaluated .
Furthermore , these features do not need to be re-evaluated because they have already been evaluated .
99 0:0:preserved 1:1:preserved 2,3,4:4,5,6:paraphrase 6,5:7,8,9:paraphrase 7,8:2,3:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:14:preserved 13:13:paraphrase 14:15:preserved 15:16:preserved

( ii ) By using SVM classifiers with powerful generalization , using too many features in the cascade is avoided , therefore importantly training time is saved and over-fitting is avoided .
( ii ) By using SVM classifiers with powerful generalization , using too many features in the cascade is avoided , with the important results of saving training time and avoiding over-fitting .
100 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21,22,25,26,29,30:21,22,23,24,25,26,30:paraphrase 23,24:27,28:preserved 27:29:preserved 28:31:preserved 31:32:preserved

Third , the training time of AdaBoost classifiers is shortened by using simple sampling techniques to reduce the number of features in the feature set .
Third , the training time of AdaBoost classifiers has been shortened by using simple sampling techniques to reduce the number of features in the feature set .
103 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8,9:8,9,10:bigrammar-vtense 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:26:preserved

Experiments will show that for rejection , using a full feature set and a sampled feature set gives the comparable performance .
Experiments showed that for rejection , the performance gained by using a sampled feature set was comparable to that of a full feature set .
104 0:0:preserved 1,2:1:bigrammar-vtense 3:2:preserved 4:3:preserved 5:4:preserved 6:5:preserved 7:10:preserved 8,9,10,11:20,21,22,23:preserved 17,20,12:6,7,8,9,15,17,18,19:paraphrase 13:11:preserved 14:12:preserved 15,16:13,14:preserved 18::mogrammar-det 19:16:preserved 21:24:preserved

Along with using several SVM classifiers instead of many AdaBoost classifiers in later layers , the total training time is reduced significantly .
Along with using several SVM classifiers instead of many AdaBoost classifiers in later layers , the total training time has been significantly reduced .
105 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19,20:19,20,22:bigrammar-vtense 21:21:preserved 22:23:preserved

There have been several studies working on how to handle the drawbacks of Viola and Jones' system .
Several studies have worked on addressing the drawbacks of Viola and Jones' system .
110 5,0,1,2:3,2:para-freeword 3:0:preserved 4:1:preserved 6:4:preserved 7,8,9:5:paraphrase 10,11,12,13,14,15,16:6,7,8,9,10,11,12:preserved

Wu et al. [23] used direct feature selection to reduce training time while maintaining comparable performance .
Wu et al. [23] used direct feature selection to reduce training time while maintaining comparable performance .
111 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved

Their idea is to separate the training process into two stages : feature selection and classifier construction .
Their idea is to separate the training process into two stages : feature selection and classifier construction .
112 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved

In Viola and Jones' work , features are selected by the discriminative performance of their associated weak classifiers through the boosting process .
In Viola and Jones' work , features are selected by the discriminative performance of their associated weak classifiers through the boosting process .
113 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved

It is therefore very time consuming because all weak classifiers must be trained every time one feature is selected .
This process is very time consuming because all weak classifiers must be trained every time one feature is selected .
114 0,1:1,0,2:paraphrase 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved

With their new proposal , weak classifiers are trained only once and features are selected by the direct feature selection method that directly maximizes the learning objective of the output classifier .
With the new proposal of Wu et al. , weak classifiers are trained only once and features are selected by the direct feature selection method , which directly maximizes the learning objective of the output classifier .
115 0:0:preserved 1:1:bigrammar-det 2:2:preserved 3:3:preserved 4:4,5,6,7:paraphrase 5,6,7,8,9,10,11,12,13,14,15:9,10,11,12,13,14,15,16,17,18,19:preserved 16,17,18,19,20:20,21,22,23,24:preserved 21:26:bigrammar-others 22,23,24,25,26,27,28,29,30:27,28,29,30,31,32,33,34,35:preserved

They claim that their method is 100 times faster than Viola and Jones' method .
They claim that their method is 100 times faster than Viola and Jones' method .
116 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved

Another direction is to optimally build the cascade to improve the overall performance of the cascade .
Another direction is to optimally build the cascade to improve its overall performance .
119 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:bigrammar-det 11:11:preserved 12:12:preserved 16:13:preserved

Sun et al. [24] and [25] propose a scheme to optimally tune parameters in layer classifiers .
Sun et al. [24] and [25] proposed a scheme to optimally tune parameters in layer classifiers .
120 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:bigrammar-vtense 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved

However , their approach is somewhat complicated and is not easy to implement .
However , their approach is somewhat complicated and is not easy to implement .
121 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved

Xiao et al. [20] and Huang et al. [11] propose the boosting chain structure in which subsequent layers utilize historical information of previous layers .
Xiao et al. [20] and Huang et al. [11] proposed a boosting chain structure in which subsequent layers utilize the historical information of the previous layers .
122 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:bigrammar-vtense 10:10:bigrammar-det 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:24:preserved 23:25:preserved 24:26:preserved :19:mogrammar-det :23:mogrammar-det

This significantly reduces the number of features used in each layer .
This significantly reduces the number of features used in each layer .
123 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved

Discrete AdaBoost uses a binary weak classifier that is too weak to boost in the case of the hard distinguished dataset .
Discrete AdaBoost uses a binary weak classifier that is too weak to boost in the case of a hard distinguished dataset .
124 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:bigrammar-det 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved

Studies based on RealBoost [26] , such as [12] ,[10] ,[27] ,[11] , introduced new kinds of weak classifiers that are stronger than binary weak classifiers .
Studies based on RealBoost [26] , such as [12] , [10] , [27] , and [11] , introduced new kinds of weak classifiers that are stronger than binary weak classifiers .
125 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9,10,11:10,12,11,15:preserved 12:9,14,13:bigrammar-others 13:17:preserved 14,15,16:18,19,20:preserved 17,18:28,29:preserved 21,20,19,22,23:25,24,23,26,27:preserved 24:21:preserved 25:22:preserved

New real-valued weak classifiers can effectively discriminate face and non-face distributions and , in consequence , the total number of features used also reduces dramatically .
These new real-valued weak classifiers can effectively discriminate face and non-face distributions , so the total number of features used is also reduced dramatically .
126 0:1:preserved 1:2:preserved 2:3:preserved 3:4:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 12:12:preserved 14,13:13:paraphrase 16:14:preserved 17:15:preserved 18:16:preserved 19:17:preserved 20:18:preserved 21:19:preserved 22:21:preserved 23:22,20:paraphrase 24:23:preserved 25:24:preserved :0:mogrammar-det

Face detection systems such as [27] ,[11] only use around 800 features .
Face detection systems such as [27] and [11] only use around 800 features .
127 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6,7:bigrammar-others 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved

However , the main problem with these systems is how to choose the most appropriate number of bins .
However , the main problem with these systems is how to choose the most appropriate number of bins .
128 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved

Small number of bins might not well approximate the real distribution while large number of bins might cause over-fitting , increase computation time and waste storage space .
A small number of bins might not accurately approximate the real distribution , while a large number of bins might cause over-fitting , increase computation time , and waste storage space .
129 0:1:preserved 1:2:preserved 2:3:preserved 3:4:preserved 4:5:preserved 5:6:preserved 6:7:paraphrase 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:13:preserved 12:15:preserved 13:16:preserved 14:17:preserved 15:18:preserved 16:19:preserved 17:20:preserved 18:21:preserved 19:22:preserved 20:23:preserved 21:24:preserved 22:25:preserved 26,25,24,23:27,28,29,30:preserved :0:mogrammar-det :14:mogrammar-det

Actually , our system can benefit from this approach when building the rejection stage and thus also reduce the training time much more .
However , our system can benefit from this approach when building the rejection stage and can thus reduce the training time even further .
130 0:0:paraphrase 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:16:preserved 17:15,17:paraphrase 18:18:preserved 19:19:preserved 20:20:preserved 21,22:21,22:paraphrase 23:23:preserved

The proposed face detection system consists of three stages that classify a 24x24 pixel window as either a face or a non-face .
The proposed face detection system consists of three stages that classify a 24x24-pixel window as either a face or a non-face .
135 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12,13:12:spelling 14:13:preserved 15:14:preserved 16:15:preserved 17:16:preserved 18:17:preserved 19:18:preserved 20:19:preserved 21:20:preserved 22:21:preserved

To detect faces of different sizes and locations , the detector is applied at every location and scale in the input image with a scale factor of 1 .2 , which is similar to the other approaches [5] ,[6] ,[9] .
To detect faces of different sizes and locations , the detector is applied at every location and scale in the input image with a scale factor of 1 .2 , which is similar to other approaches [5] , [6] , [9] .
136 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34::mogrammar-det 35:34:preserved 36:35:preserved 37:36:preserved 38,39:40,39,38,37:typo 40:41:preserved

An outline of this system is given in Figure 2 .
An outline of this system is given in Figure 2 .
137 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved

The first stage is a cascade of classifiers used to estimate face candidate regions by evaluating 36x36 input windows , with a moving step of 12 pixels .
The first stage is a cascade of classifiers used to estimate face candidate regions by evaluating 36x36 input windows , with a moving step of 12 pixels .
140 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved

If a 36x36 window is detected as the existence of a face , 144 ( i.e. 12x12 ) likely face positions are collected and passed to the next stage .
If a 36x36-pixel window is detected as the existence of a face , 144 ( i.e. , 12x12 ) likely face positions are collected and passed to the next stage .
141 0:0:preserved 1:1:preserved 2:2:spelling 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:26:preserved 26:27:preserved 27:28:preserved 28:29:preserved 29:30:preserved

The second stage is a cascade of classifiers used to investigate 24x24 window face candidate locations returned from the previous stage .
The second stage is a cascade of classifiers used to investigate 24x24 window face candidate locations returned from the previous stage .
142 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved

The main purpose of designing these two stages is trying to filter out a large number of non-face patterns as quick as possible before passing complex patterns to the final stage classifier .
The main purpose of designing these two stages is trying to filter out a large number of non-face patterns as quickly as possible before passing complex patterns to the final stage classifier .
145 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:bigrammar-wform 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved

This is done by taking advantages of Viola and Jones' approach [1] , in which Haar wavelet features and the cascaded AdaBoost classifiers are extremely fast in computation .
This is done by taking advantage of Viola and Jones' approach [1] , in which Haar wavelet features and the cascaded AdaBoost classifiers enable extremely fast computation .
146 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:bigrammar-nnum 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:paraphrase 24:24:preserved 25:25:preserved 26::mogrammar-prep 27:26:preserved 28:27:preserved

Although the cascade of \MATH AdaBoost classifiers rejects non-face patterns rapidly , it is still influenced by the large number of \MATH patterns that it must process .
Although the cascade of \MATH AdaBoost classifiers rejects non-face patterns rapidly , it is still influenced by the large number of \MATH patterns that it must process .
149 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved

The reason why the fist stage , which is a cascade of \MATH classifiers , is added is to decrease the number of analyzed patterns .
For this reason , the first stage , which is a cascade of \MATH classifiers , is added is to decrease the number of analyzed patterns .
150 0:1:bigrammar-det 1:2:preserved 3:4:preserved 4:5:typo 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:26:preserved :0:mogrammar-prep

To this end , this stage is trained specially to make the classifiers invariant to small face translations .
To this end , this stage is trained specially to make the classifiers invariant to small face translations .
151 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved

These classifiers can detect faces that are off-center by up to six pixels in any direction .
These classifiers can detect faces that are off-center by up to six pixels in any direction .
152 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved

An illustration of the difference between 24x24 and \MATH face training samples is depicted in Figure 3 .
An illustration of the difference between 24x24 and \MATH face training samples is depicted in Figure 3 .
153 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved

The \MATH window is chosen in accordance with the idea from [5] stated that the classifier can be trained to be invariant to translation by up to \MATH of original window size .
The \MATH window is chosen in accordance with the idea in [5] that the classifier can be trained to be invariant to translation by up to \MATH of the original window size .
154 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:bigrammar-prep 11:11:preserved 13:12:preserved 14:13:preserved 15:14:preserved 16:15:preserved 17:16:preserved 18:17:preserved 19:18:preserved 20:19:preserved 21:20:preserved 22:21:preserved 23:22:preserved 24:23:preserved 25:24:preserved 26:25:preserved 27:26:preserved 28:27:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved :28:mogrammar-det

With this flexible classifier , the moving step size can be increased up to 12 pixels that reduce dramatically number of analyzed patterns .
With this flexible classifier , the moving step size can be increased up to 12 pixels to dramatically reduce the number of analyzed patterns .
155 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:paraphrase 17:18:preserved 18:17:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved :19:mogrammar-det

Efficiency of this stage will be discussed further in section 6 .3 .
The efficiency of this stage will be discussed further in section 6 .3 .
156 0:1:preserved 1:2:preserved 2:3:preserved 3:4:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved :0:mogrammar-det

The last stage is a cascade of non-linear SVM classifiers that reuses features that have been selected by AdaBoost in the second stage classifier .
The last stage is a cascade of nonlinear SVM classifiers that reuses features that have been selected by AdaBoost in the second stage classifier .
159 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:spelling 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved

These feature values are evaluated and scaled to be between 0 and 1 to form a feature vector .
These feature values are evaluated and scaled to be between 0 and 1 to form a feature vector .
160 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved

In our experiments , only 100 features are used and hence it is faster than using any pixel-based SVM classifiers [8] ,[9] .
In our experiments , only 100 features were used , making classification faster than it would have been using pixel-based SVM classifiers [8] , [9] .
161 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7,8:7,8:bigrammar-vtense 9,10,11,12:10,11,14,15,16,17:paraphrase 13:12:preserved 14:13:preserved 15:18:preserved 17:19:preserved 18:20:preserved 19:21:preserved 20:22:preserved 21:24,23:preserved 22:25:preserved

The same feature set as proposed in [1] is used ( cf. Figure 4 ) .
The same feature set proposed in [1] was used ( cf . Figure 4 ) .
167 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4::mogrammar-prep 5:4:preserved 6:5:preserved 7:6:preserved 8:7:bigrammar-vtense 9:8:preserved 10:9:preserved 11:11,10:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved

It consists of four kinds of features modeled from adjacent basic rectangles with the same size and shape .
It consists of four kinds of features modeled from adjacent basic rectangles of the same size and shape .
168 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:bigrammar-prep 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved

The feature value is defined as the difference of sum of the pixels within rectangles .
The feature value is defined as the difference of the sum of the pixels within rectangles .
169 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved :9:mogrammar-det

Each feature is parameterized by four parameters : the position within the window \MATH , width \MATH and height \MATH ( cf. Figure 5 ) .
Each feature is parameterized by four parameters : the position within the window \MATH , the width \MATH , and the height \MATH ( cf . Figure 5 ) .
170 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:16:preserved 16:17:preserved 17:19:preserved 18:21:preserved 19:22:preserved 20:23:preserved 21,22,23,24,25:24,25,26,27,28,29:preserved :15:mogrammar-det :20:mogrammar-det

By using integral image definition [1] , these rectangle feature values can be computed extremely quickly .
By using integral image definition [1] , the feature values of these rectangles can be computed extremely quickly .
173 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8,10,9:8,9,10,11,12:para-colocation 11:13:preserved 12:14:preserved 13:15:preserved 14:16:preserved 15:17:preserved 16:18:preserved

The integral image at location \MATH is defined as \MATH , where \MATH is the integral image and \MATH is the original image .
The integral image at location \MATH is defined as \MATH , where \MATH is the integral image and \MATH is the original image .
174 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved

In practice , \MATH can be computed simply by using the following recurrent function :\MATH , and sum of the pixels within a rectangle can be computed from four integral image values of its vertices , for example , \MATH .
In practice , \MATH can be computed simply by using the following recurrent function :\MATH , and sum of the pixels within a rectangle can be computed from four integral image values of its vertices , for example , \MATH .
175 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved 35:35:preserved 36:36:preserved 37:37:preserved 38:38:preserved 39:39:preserved 40:40:preserved

Boosting is used to improve the classification performance of any given simple learning algorithm [28] .
Boosting is used to improve the classification performance of any given simple learning algorithm [28] .
180 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved

Given \MATH weak classifiers \MATH learned through \MATH rounds of boosting , the strong classifier is formed by a linear combination : \MATH where \MATH are coefficients found in the boosting process .
Given \MATH weak classifiers \MATH learned through \MATH rounds of boosting , the strong classifier is formed by a linear combination : \MATH , where \MATH are coefficients found in the boosting process .
181 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:24:preserved 24:25:preserved 25:26:preserved 26:27:preserved 27:28:preserved 28:29:preserved 29:30:preserved 30:31:preserved 31:32:preserved 32:33:preserved

Each weak classifier \MATH is associated with a feature \MATH and a threshold \MATH such that the number of incorrect classified examples corresponding to this weak classifier is minimized : \MATH , where polarity \MATH indicates the direction of the inequality sign .
Each weak classifier \MATH is associated with a feature \MATH and a threshold \MATH such that the number of incorrectly classified examples corresponding to the weak classifier is minimized : \MATH , where polarity \MATH indicates the direction of the inequality sign .
184 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:bigrammar-wform 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:bigrammar-det 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved 35:35:preserved 36:36:preserved 37:37:preserved 38:38:preserved 39:39:preserved 40:40:preserved 41:41:preserved 42:42:preserved

In each round of boosting , the best weak classifier \MATH that has the lowest error \MATH will be chosen .
In each round of boosting , the best weak classifier \MATH that has the lowest error \MATH will be chosen .
187 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved

The error of each weak classifier is measured with respect to the set of weights over each example of the training set \MATH , where \MATH and \MATH are the weight and the label of the training example \MATH , respectively .
The error of each weak classifier is measured with respect to the set of weights over each example of the training set \MATH , where \MATH and \MATH are the respective weight and label of the training example \MATH .
188 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:31:preserved 31:32:preserved 32::mogrammar-det 33:33:preserved 34:34:preserved 35:35:bigrammar-det 36:36:preserved 37:37:preserved 38:38:preserved 40:30:bigrammar-wform 41:39:preserved

After each round , these weights are updated such that the weak learner will focus much more on the hard examples in the next round .
After each round , these weights are updated such that the weak learner will focus much more on the hard examples in the next round .
189 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved

The main idea of building a cascade of classifiers is to reduce the computation time by giving different treatments to different complexities of input windows ( cf .
The main idea of building a cascade of classifiers is to reduce the computation time by giving different treatments to different complexities of input windows ( cf .
194 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved

Figure 7 ) .
Figure 7 ) .
195 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved

Only input windows that have passed through all layers of the cascade are classified as faces .
Only input windows that have passed through all layers of the cascade are classified as faces .
196 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved

Training cascaded classifiers that can achieve both good detection rate and less computation time is quite complex , because a higher detection rate requires more features , but more features are correspondent to more time for evaluation .
Training cascaded classifiers that can achieve both good detection rates and less computation time is quite complex ; a higher detection rate requires more features , but more features correspond to more time needed for evaluation .
199 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:bigrammar-nnum 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 19:18:preserved 20:19:preserved 21:20:preserved 22:21:preserved 23:22:preserved 24:23:preserved 25:24:preserved 26:25:preserved 27:26:preserved 28:27:preserved 29:28:preserved 31,30:29:paraphrase 32:30:preserved 33:31:preserved 34:32:preserved 35:34:preserved 36:35:preserved 37:36:preserved

To simplify this , the detection rate goal and the false positive rate goal for each layer are usually set beforehand .
To simplify this , the detection rate goal and the false positive rate goal for each layer are usually set beforehand .
200 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved

Viola and Jones [1] stated that , if the layer classifier could achieve the predefined target goals after 200 features are used , the training process will stop and a new layer will be added .
Viola and Jones [1] stated that , if the layer classifier has achieved the predefined target goals after 200 features are used , the training process will stop and a new layer will be added .
201 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11,12:11,12:bigrammar-vtense 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved 35:35:preserved

1 .	<section label= " SVM Classifier " >
1 .	<section label= " SVM Classifier " >
205 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved

The support vector machine is a statistical learning method based on the structure-risk minimization principle .
The support vector machine is a statistical learning method based on the structure-risk minimization principle .
207 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved

It has been very efficiently proved in many pattern recognition applications [29] ,[8] ,[9] .
It has been very efficiently proven in many pattern recognition applications [29] , [8] , [9] .
208 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:spelling 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12,13:13,12,14,15:preserved 14:16:preserved

In the binary classification case , the objective of the SVM is to find the best separating hyperplane with a maximum margin .
In the binary classification case , the objective of the SVM is to find the best separating hyperplane with a maximum margin .
209 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved

The form of SVM classifiers is : \MATH where : \MATH is the d-dimensional vector of an observation example , \MATH is a class label , and \MATH is the vector of the \MATH training example .
The form of SVM classifiers is : \MATH where \MATH is the d-dimensional vector of an observation example , \MATH is a class label , and \MATH is the vector of the \MATH training example .
212 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 10:9:preserved 11:10:preserved 12:11:preserved 13:12:preserved 14:13:preserved 15:14:preserved 16:15:preserved 17:16:preserved 18:17:preserved 19:18:preserved 20:19:preserved 21:20:preserved 22:21:preserved 23:22:preserved 24:23:preserved 25:24:preserved 26:25:preserved 27:26:preserved 28:27:preserved 29:28:preserved 30:29:preserved 31:30:preserved 32:31:preserved 33:32:preserved 34:33:preserved 35:34:preserved 36:35:preserved

All the \MATH corresponding to non-zero \MATH are called support vectors .
All the \MATH corresponding to non-zero \MATH are called support vectors .
213 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved

It is important to choose the appropriate kernel and parameter \MATH in order to to obtain the robust SVM classifier .
It is important to choose the appropriate kernel and parameter \MATH in order to obtain the robust SVM classifier .
216 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 15:14:preserved 16:15:preserved 17:16:preserved 18:17:preserved 19:18:preserved 20:19:preserved

Although many kernels have been introduced by researchers , the following four kernels are commonly used : \MATH where \MATH and \MATH are kernel parameters .
Although many kernels have been introduced by researchers , the following four kernels are commonly used : \MATH where \MATH , and \MATH are kernel parameters .
217 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:26:preserved

Compared to AdaBoost classifiers , SVM classifiers run much slower in running because of the large number of support vectors and heavy kernel computation .
Compared to AdaBoost classifiers , SVM classifiers run much more slowly because of the large number of support vectors and the heavy kernel computation .
220 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9,10,11:9,10:paraphrase 12:11:preserved 13:12:preserved 14:13:preserved 15:14:preserved 16:15:preserved 17:16:preserved 18:17:preserved 19:18:preserved 20:19:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved :20:mogrammar-det

To control the trade-off between the number of support vectors and errors , Scholkopf et al. [30] proposed using a new parameter \MATH instead of the parameter \MATH .
To control the trade-off between the number of support vectors and errors , Scholkopf et al. [30] proposed using a new parameter \MATH instead of the parameter \MATH .
221 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved

They proved that the parameter \MATH is an upper bound of the fraction of margin errors and a lower bound of the fraction of support vectors .
They proved that the parameter \MATH is an upper bound of the fraction of margin errors and a lower bound of the fraction of support vectors .
222 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved

The implementations of \MATH and \MATH are provided by LibSVM [31] .
The implementations of \MATH and \MATH are provided by LibSVM [31] .
223 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved

For training , we collected 7 ,500 , 24x24-size face patterns from the Internet .
For training , we collected 7 ,500 , 24x24-size face patterns from the Internet . / / size / pixel?
229 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved

Non-face patterns were generated at different locations and scales from 8 ,440 images with various subjects , such as rocks , trees , buildings , scenery , and flowers , containing no faces .
Non-face patterns were generated at different locations and scales from 8 ,440 images with various subjects , such as rocks , trees , buildings , scenery , and flowers , containing no faces .
230 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved

Some examples of the collected 24x24 face patterns are shown in Figure 8 .
Some examples of the collected 24x24 face patterns are shown in Figure 8 .
231 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved

Face patterns for training the 36x36 classifiers are generated by selecting 36x36 windows containing the 24x24 face window of the input image .
Face patterns for training the 36x36 classifiers were generated by selecting 36x36 windows containing the 24x24 face window of the input image .
234 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7,8:7,8:bigrammar-vtense 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved

Figure 9 shows some examples of 36x36 face patterns that include various kinds of floating positions and backgrounds .
Figure 9 shows some examples of 36x36 face patterns that include various kinds of floating positions and backgrounds .
235 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved

To train the cascade of 24x24 AdaBoost classifiers used in the rejection stage , the same 7 ,500 face patterns are used for all layers .
To train the cascade of 24x24 AdaBoost classifiers used in the rejection stage , the same 7 ,500 face patterns were used for all layers .
238 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20,21:20,21:bigrammar-vtense 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved

Non-face patterns of the training and the validating sets of the first layer in the cascade are selected randomly .
Non-face patterns of the training and the validating sets of the first layer in the cascade were selected randomly .
239 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16,17:16,17:bigrammar-vtense 18:18:preserved 19:19:preserved

Non-face patterns of the subsequent layer classifiers are false positives collected by the partially trained cascade on the set of non-face images .
Non-face patterns of the subsequent layer classifiers are false positives collected by the partially trained cascade on the set of non-face images .
240 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved

For each layer classifier , 7 ,500 non-face patterns are used for training and 7 ,500 other non-face patterns are used for validating .
For each layer classifier , 7 ,500 non-face patterns were used for training and 7 ,500 other non-face patterns were used for validating .
241 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9,10:9,10:bigrammar-vtense 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19,20:19,20:bigrammar-vtense 21:21:preserved 22:22:preserved 23:23:preserved

To compare the performance of classifiers , we have implemented a fully cascade of classifiers trained by AdaBoost , similar to that used by Viola and Jones [1] .
To compare the performance of classifiers , we implemented a full cascade of classifiers trained by AdaBoost , similar to that used by Viola and Jones [1] .
244 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8,9:8:bigrammar-vtense 10:9:preserved 11:10:bigrammar-wform 12:11:preserved 13:12:preserved 14:13:preserved 15:14:preserved 16:15:preserved 17:16:preserved 18:17:preserved 19:18:preserved 20:19:preserved 21:20:preserved 22:21:preserved 23:22:preserved 24:23:preserved 25:24:preserved 26:25:preserved 27:26:preserved 28:27:preserved

The training parameters of each layer were set as follows .
The training parameters of each layer were set as follows .
245 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved

The minimum of the detection rate is \MATH , the maximum of the false positive rate is \MATH and the maximum of the number of features in each layer is 200 .
The minimum of the detection rate was \MATH , the maximum of the false positive rate was \MATH , and the maximum of the number of features in each layer was 200 .
246 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:bigrammar-vtense 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:bigrammar-vtense 17:17:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:26:preserved 26:27:preserved 27:28:preserved 28:29:preserved 29:30:bigrammar-vtense 30:31:preserved 31:32:preserved

This setting resulted in a face detector that consists of 38 layers with 6 ,360 features .
This setting resulted in a face detector that consists of 38 layers with 6 ,360 features .
247 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved

All experiments were run on a PC ( Pentium 4 , 2 .8 MHz , 512-MB RAM ) .
All experiments were run on a PC ( Pentium 4 , 2 .8 MHz , 512-MB RAM ) .
250 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved

The training process was terminated when no more false positives were found in the non-face images of the data set .
The training process was terminated when no more false positives were found in the non-face images of the data set .
251 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved

If \MATH is the number of Haar wavelet features and \MATH is the number of training patterns , the learning time of AdaBoost to train \MATH weak classifiers is roughly[1] .
If \MATH is the number of Haar wavelet features and \MATH is the number of training patterns , the learning time of AdaBoost to train \MATH weak classifiers is roughly [1] .
256 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29,30:preserved 30:31:preserved

Therefore , if the number of training patterns is fixed , the learning time can be shortened when either the number of features in the feature set or the number of weak classifiers in the final cascade is reduced .
Therefore , if the number of training patterns is fixed , the learning time can be shortened when either the number of features in the feature set or the number of weak classifiers in the final cascade is reduced .
257 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved 35:35:preserved 36:36:preserved 37:37:preserved 38:38:preserved 39:39:preserved

In our approach , the cascaded classifiers are only used for efficient rejection , so we can reduce both these numbers in order to keep training time for the full system reasonable .
In our approach , the cascaded classifiers are only used for efficient rejection , so we can reduce both of these numbers in order to keep the training time for the full system reasonable .
258 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:27:preserved 26:28:preserved 27:29:preserved 28:30:preserved 29:31:preserved 30:32:preserved 31:33:preserved 32:34:preserved :19:mogrammar-prep :26:mogrammar-det

As mentioned in section 4 .1 , each feature is parameterized by a tuple of four parameters \MATH .
As mentioned in section 4 .1 , each feature is parameterized by a tuple of four parameters \MATH . / / If this ( and other places ) do not display with spaces after the commas , spaces must be insert . A comma should always be followed by a space . I recommend checking this carefully throughout .]
261 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved

A set of features is then formed by changing these parameters in correspondent steps \MATH .
A set of features is then formed by changing these parameters in corresponding steps \MATH .
262 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:bigrammar-wform 13:13:preserved 14:14:preserved 15:15:preserved

In the other hand , a feature set is parameterized by \MATH .
A feature set , on the other hand , is parameterized by \MATH .
263 0:4:bigrammar-prep 1,2,3:5,6,7:preserved 4:3:preserved 5,6,7:0,1,2:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved

One of the simplest ways to sub-sample the feature set is to change parameters \MATH , for example , from a full feature set \MATH to a reduced feature set \MATH .
One of the simplest ways to sub-sample the feature set is to change parameters \MATH , for example , from a full feature set \MATH to a reduced feature set \MATH .
264 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved

Because the full feature set is redundant , this sub-sampling is expected not to affect the rejection performance of AdaBoost classifiers significantly .
Because the full feature set is redundant , this sub-sampling is expected not to significantly affect the rejection performance of AdaBoost classifiers .
265 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:14:preserved 22:22:preserved

We carried out experiments to compare the performance of classifiers trained on these two feature sets : the full feature set \MATH containing 134 ,736 features and the reduced feature set \MATH containing 14 ,807 features ( excluding features with the small size ) .
We carried out experiments to compare the performance of classifiers trained on these two feature sets : the full feature set \MATH , containing 134 ,736 features and the reduced feature set \MATH , containing 14 ,807 features ( excluding features of small size ) .
268 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:26:preserved 26:27:preserved 27:28:preserved 28:29:preserved 29:30:preserved 30:31:preserved 31:32:preserved 32:34:preserved 33:35:preserved 34:36:preserved 35:37:preserved 36:38:preserved 37:39:preserved 38:40:preserved 39:41:bigrammar-prep 40::mogrammar-det 41:42:preserved 42:43:preserved 43:44:preserved 44:45:preserved

Two classifiers are trained up to the maximum of 200 features .
Two classifiers were trained up to the maximum of 200 features .
269 0:0:preserved 1:1:preserved 2,3:2,3:bigrammar-vtense 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved

The classifier 's threshold is changed to meet the detection rate of \MATH .
The classifier 's threshold was changed to meet the detection rate of \MATH .
270 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4,5:4,5:bigrammar-vtense 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved

The training set contains 7 ,500 face patterns and 7 ,500 non-face patterns .
The training set contains 7 ,500 face patterns and 7 ,500 non-face patterns .
271 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved

Rejection performance is evaluated through the false positive rate on a validation test set which contains 500 ,000 non-face patterns .
Rejection performance was evaluated through the false positive rate on a validation test set that contains 500 ,000 non-face patterns .
272 0:0:preserved 1:1:preserved 2,3:2,3:bigrammar-vtense 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:bigrammar-others 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved

All non-face patterns are selected randomly from the training set mentioned above .
All non-face patterns were selected randomly from the training set mentioned above .
273 0:0:preserved 1:1:preserved 2:2:preserved 3,4:3,4:bigrammar-vtense 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved

The result shown in Figure 10 indicates that the performances of these two classifiers are no different , especially when the number of features is large enough , for example , more than 50 .
The results shown in Figure 10 indicate that the performances of these two classifiers were no different , especially when the number of features was large enough , for example , more than 50 .
276 0:0:preserved 1,6:1,6:bigrammar-inter 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:bigrammar-vtense 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:bigrammar-vtense 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved

As a result , by using the reduced feature set , the training time can be shortened approximately to one ninth .
As a result , by using the reduced feature set , the training time can be shortened to approximately one-ninth .
277 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:18:preserved 18:17:preserved 20,19:19:spelling 21:20:preserved

Our another experiment has shown that , for similar performance , the AdaBoost classifier trained on the reduced feature set that uses larger sampling step sizes requires more features than that trained on the full feature set .
Another experiment we conducted showed that , for similar performance , an AdaBoost classifier trained on the reduced feature set that uses larger sampling step sizes requires more features than one trained on the full feature set . / / [Do you need a reference here , or is this still talking about the experiments you report in this paper?]
280 3,4,0:2,3,4:paraphrase 1:0:preserved 2:1:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:bigrammar-det 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:paraphrase 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved 35:35:preserved 36:36:preserved 37:37:preserved

Therefore , only the sampling parameter \MATH was used in training the 24x24 AdaBoost classifiers .
Therefore , only the sampling parameter \MATH was used in training the 24x24 AdaBoost classifiers .
281 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved

In our system , the first stage is a cascade of classifiers that processes 36x36 patterns with a moving step size of 12 pixels .
In our system , the first stage is a cascade of classifiers that processes 36x36 patterns with a moving step size of 12 pixels .
286 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved

By taking advantage of simplification in training classifiers only for rejection demonstrated in section 6 .2 , training this cascade only uses the feature set generated from a 36x36 window with sampling parameters \MATH .
By taking advantage of simplification in training classifiers only for rejection , as demonstrated in section 6 .2 , training this cascade only uses the feature set generated from a 36x36 window with sampling parameters \MATH .
287 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:13:preserved 12:14:preserved 13:15:preserved 14:16:preserved 15:17:preserved 16:18:preserved 17:19:preserved 18:20:preserved 19:21:preserved 20:22:preserved 21:23:preserved 22:24:preserved 23:25:preserved 24:26:preserved 25:27:preserved 26:28:preserved 27:29:preserved 28:30:preserved 29:31:preserved 30:32:preserved 31:33:preserved 32:34:preserved 33:35:preserved 34:36:preserved :12:mogrammar-prep

As a result , 12 ,223 features are produced .
As a result , 12 ,223 features are produced .
288 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved

The training set contains 12 ,000 face patterns and 12 ,000 non-face patterns .
The training set contains 12 ,000 face patterns and 12 ,000 non-face patterns .
289 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved

Since a 36x36 face sample contains a lot of background outside the 24x24 face region while the classifier is required to be fast and to keep all possible face regions , training parameters are set as follows : the minimum detection rate of \MATH and maximum of false positive rate of \MATH .
Since a 36x36 face sample contains a large proportion of background outside the 24x24 face region and the classifier is required to be fast and to keep all possible face regions , a minimum detection rate of \MATH and a maximum of false positive rate of \MATH were set as the training parameters .
290 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6,7,8:6,7,8,9:paraphrase 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:paraphrase 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:26:preserved 26:27:preserved 27:28:preserved 28:29:preserved 29:30:preserved 30:31:preserved 31,32:51,52:preserved 33,34:47,48:preserved 38:32:bigrammar-det 39,40,41,42,43,44:33,34,35,36,37,38:preserved 50,49,48,47,46,45:43,44,45,42,41,40:preserved 51:46:preserved 52:53:preserved :39:mogrammar-det :49:mogrammar-prep :50:mogrammar-det

In our experiments , after reaching 50 features , the classifier 's performance does not significantly increase anymore , so the maximum number of features for each layer is set to 50 .
In our experiments , after reaching 50 features , the classifier 's performance did not significantly increase , so the maximum number of features for each layer is set to 50 .
291 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:bigrammar-vtense 14:14:preserved 15:15:preserved 16:16:preserved 18:17:preserved 19:18:preserved 20:19:preserved 21:20:preserved 22:21:preserved 23:22:preserved 24:23:preserved 25:24:preserved 26:25:preserved 27:26:preserved 28:27:preserved 29:28:preserved 30:29:preserved 31:30:preserved 32:31:preserved

To keep a balance between computation speed and robustness , the maximum number of layers is set to three because using more layers would degrade the overall detection rate dramatically .
To keep a balance between computation speed and robustness , the maximum number of layers is set to three because using more layers would degrade the overall detection rate dramatically .
292 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved

Figure 11( a ) shows several features of the first 36x36 layer classifier selected by AdaBoost .
Figure 11( a ) shows several features of the first 36x36 layer classifier selected by AdaBoost .
295 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved

It is somehow similar to features of the first 24x24 layer classifier as shown in Figure 11( b ) .
They are somehow similar to the features of the first 24x24 layer classifier as shown in Figure 11( b ) . / / [somehow?This sounds vague . How are they similar?]
296 0,1:0,1:bigrammar-inter 2:2:preserved 3:3:preserved 4:4:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved :5:mogrammar-det

In addition , Figure 12 shows an example of face candidate regions estimated by using this cascade .
In addition , Figure 12 shows an example of face candidate regions estimated by using this cascade .
297 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved

Two main issues surrounding the reuse of features selected by AdaBoost are : ( i ) which layer whose features will be reused for SVM is the best? and ( ii ) How many features should be used?
Two main issues surrounding the reuse of features selected by AdaBoost are : ( i ) which layerfs features should be reused for SVM and ( ii ) how many features should be used .
302 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 18,17:17:paraphrase 19:18:preserved 20,21,22:19,21,20:bigrammar-vtense 23:22:preserved 24:23:preserved 28:24:preserved 33,32,30,31,29,34,35,36,37:28,29,26,27,25,30,31,32,33:preserved

For comparison of the performance of SVM classifiers , 2 ,450 face patterns and 7 ,500 non-face patterns which are separated from the training set ( section 6 .1 ) were used .
For comparison of the performance of SVM classifiers , 2 ,450 face patterns and 7 ,500 non-face patterns that were separated from the training set ( section 6 .1 ) were used .
305 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:bigrammar-others 19,20:19,20:bigrammar-vtense 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved

The SVM classifiers were trained with a RBF kernel whose parameter \MATH is \MATH .
The SVM classifiers were trained with a RBF kernel whose parameter \MATH is \MATH .
306 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved

The parameter \MATH is set to \MATH .
The parameter \MATH was set to \MATH .
307 0:0:preserved 1:1:preserved 2:2:preserved 3,4:3,4:bigrammar-vtense 5:5:preserved 6:6:preserved 7:7:preserved

These parameters were found by using cross-validation test .
These parameters were found by using a cross-validation test .
308 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:7:preserved 7:8:preserved 8:9:preserved :6:mogrammar-det

Figure 13 compares the performance of classifiers trained on 200-feature sets selected by different layers in the cascade ( layers 14 , 17 , 20 , and 25 ) .
Figure 13 compares the performance of classifiers trained on 200-feature sets selected by different layers in the cascade ( layers 14 , 17 , 20 , and 25 ) .
311 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved

These comparable performances suggest that the second stage ( using AdaBoost ) can be switched to the final stage ( using SVM ) at any time .
These comparable performances suggest that the second stage ( using AdaBoost ) can be switched to the final stage ( using SVM ) at any time .
312 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved

As a result , total training time of the system can be easily controlled .
As a result , the total training time of the system can easily be controlled .
313 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:13:preserved 12:12:preserved 13:14:preserved 14:15:preserved :4:mogrammar-det

To determine how many features is robust enough , we used the 200-feature set selected in layer 17 to generate different subsets of features with different number of features .
To determine the number of features is that would be sufficiently robust , we used the 200-feature set selected in layer 17 to generate different subsets of features with different numbers of features .
316 0:0:preserved 1:1:preserved 2,3,7:2,3,4,10,9,8,7:paraphrase 4:5:preserved 5:6:preserved 6:11:preserved 9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,27,28:13,14,15,16,17,18,19,20,21,22,23,24,25,27,26,28,29,31,32:preserved 26:30:bigrammar-nnum

Features in each set were selected in the order that they were added in the training process .
Features in each set were selected in the order in which they were added in the training process .
317 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:10,9:paraphrase 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved

For example , a 25-feature set consists of first 25 features selected by AdaBoost when training layer 17 .
For example , a 25-feature set consists of the first 25 features selected by AdaBoost when training layer 17 .
318 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved :8:mogrammar-det

The results shown in Figure 14 indicate that with more than 100 features , the performance of classifiers is comparable .
The results shown in Figure 14 indicate that with more than 100 features , the performance of the classifiers was comparable . / / [to what?]
319 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:18:preserved 18:19:bigrammar-vtense 19:20:preserved 20:21:preserved :17:mogrammar-det

Basically , the speed of a SVM classifier is proportional to the number of features used , so the greater number of features used , the slower the classifier will be .
Basically , the speed of a SVM classifier is proportional to the number of features used , so the greater the number of features used , the slower the classifier will be .
322 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:26:preserved 26:27:preserved 27:28:preserved 28:29:preserved 29:30:preserved 30:31:preserved 31:32:preserved :20:mogrammar-det

Figure 15 shows the processing speed of SVM classifiers that uses different subsets of features .
Figure 15 shows the processing speed of SVM classifiers using different subsets of features .
323 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9,10:9:paraphrase 11:10:preserved 12:11:preserved 13:12:preserved 14:13:preserved 15:14:preserved

The SVM classifier using 25 features run fastest while the SVM classifier using 200 features run slowest .
The SVM classifier using 25 features ran the fastest , while the SVM classifier using 200 features was the slowest .
324 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:bigrammar-vtense 7:8:preserved 8:10:preserved 9:11:preserved 10:12:preserved 11:13:preserved 12:14:preserved 13:15:preserved 14:16:preserved 15:17:paraphrase 16:19:preserved 17:20:preserved :7:mogrammar-det :18:mogrammar-det

The speeds of SVM classifiers using 100 , 125 and 175 features are not importantly different because their difference in terms of number of features and number of support vectors is inconsiderable .
The speeds of SVM classifiers using 100 , 125 , and 175 features were not importantly different because their difference in terms of number of features and number of support vectors were not large enough to have a significant impact .
325 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:bigrammar-vtense 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:26:preserved 26:27:preserved 27:28:preserved 28:29:preserved 29:30:preserved 30,31:31,32,33,34,35,36,37,38,39:paraphrase

Therefore , 100 features might be the best trade-off between the speed and the performance .
Therefore , 100 features might be the best trade-off between speed and performance .
326 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10::mogrammar-det 11:10:preserved 12:11:preserved 13::mogrammar-det 14:12:preserved 15:13:preserved

We carried out an experiment to show efficiency of a single SVM classifier over a cascade of AdaBoost classifiers .
We carried out an experiment to show the efficiency of a single SVM classifier over a cascade of AdaBoost classifiers .
331 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved :7:mogrammar-det

In this experiment , 40 ,000 false positives were gathered by running a cascade of 17 AdaBoost classifiers ( CAB17 ) on the set of non-face images mentioned in section 6 .1 .
In this experiment , 40 ,000 false positives were gathered by running a cascade of 17 AdaBoost classifiers ( CAB17 ) on the set of non-face images mentioned in section 6 .1 .
332 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved

These false positives then were used as hard non-face patterns to train and test the performance of two classifiers : a single RBF SVM classifier and a cascade of other 18 AdaBoost classifiers .
These false positives then were used as hard non-face patterns to train and test the performance of two classifiers : a single RBF SVM classifier and a cascade of other 18 AdaBoost classifiers .
333 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved

Of 40 ,000 non-face patterns , 7 ,500 non-face patterns were used along with 7 ,500 face patterns to train these two classifiers .
Of 40 ,000 non-face patterns , 7 ,500 non-face patterns were used along with 7 ,500 face patterns to train these two classifiers .
334 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved

The remaining 34 ,000 non-face patterns and other 2 ,450 face patterns were used to compare the accuracy .
The remaining 34 ,000 non-face patterns and other 2 ,450 face patterns were used to compare the accuracy of the classifiers .
335 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17,18,19,20:paraphrase 18:21:preserved

The cascade of AdaBoost classifiers were trained with the parameters set as in section 6 .1 .
The cascade of AdaBoost classifiers were trained with the parameters set as in section 6 .1 .
336 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved

The RBF SVM classifier reused 100 features selected by the last layer of CAB17 as the feature vector and was trained by a RBF kernel whose parameter \MATH is \MATH .
The RBF SVM classifier reused 100 features selected by the last layer of CAB17 as the feature vector and was trained by an RBF kernel whose parameter \MATH is \MATH .
337 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:bigrammar-det 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved

The parameter \MATH is set to \MATH .
The parameter \MATH was set to \MATH .
338 0:0:preserved 1:1:preserved 2:2:preserved 3,4:3,4:bigrammar-vtense 5:5:preserved 6:6:preserved 7:7:preserved

These parameters are found by using cross-validation test .
These parameters were found by using a cross-validation test .
339 0:0:preserved 1:1:preserved 2,3:2,3:bigrammar-vtense 4:4:preserved 5:5:preserved 6:7:preserved 7:8:preserved 8:9:preserved :6:mogrammar-det

The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters . / / ?NOTE : I believe that I hyphenated this term in your previous document , but after seeing it used here , I would say that it does not need to be hyphenated. My apologies for any confusion . A better way to express this , however , might be " patterns that have been classified as difficult " or " patterns shown to be difficult to classify .]
342 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved 35:35:preserved 36:36:preserved 37:37:preserved 38:38:preserved 39:39:preserved 40:40:preserved 41:41:preserved

Furthermore , the training time of a single SVM ( which takes several hours ) is much smaller than that of a cascade of AdaBoost classifiers ( which might take everal weeks ) .
Furthermore , the training time of a single SVM ( which takes several hours ) is much shorter than that of a cascade of AdaBoost classifiers ( which might take several weeks ) .
343 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:paraphrase 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:typo 31:31:preserved 32:32:preserved 33:33:preserved

The final system consists of three stages .
The final system consists of three stages .
348 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved

In the first stage , the cascaded 36x36 classifiers consist of three layers , making a total number of features used of 120 .
In the first stage , the cascaded 36x36 classifiers consist of three layers , making for a total of 120 features .
349 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:16:preserved 16:17:preserved 18:18:preserved 19:20:preserved 22:19:preserved 23:21:preserved :15:mogrammar-prep

The second stage consists of 17 layers with 2 ,160 features .
The second stage consists of 17 layers with 2 ,160 features .
350 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved

Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and , thus , can save significant training time ( which is approximate 27 times in total ) .
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and can thus save significant training time ; the training time needed using the new system is approximately 27 times shorter / approximately 27 rounds of training are needed in the new system . / / <--I think that the first choice here is your intended meaning , but please check carefully .
351 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 19:19:preserved 21:18:preserved 22:20:preserved 23:21:preserved 24:22:preserved 25:23:preserved

The final stage is a cascade of three SVM classifiers that take 100 features of the last layer in the second stage as the feature vector .
The final stage is a cascade of three SVM classifiers that take 100 features of the last layer in the second stage as the feature vectors .
354 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:bigrammar-nnum 26:26:preserved

Each SVM classifier was trained by using 7 ,500 face patterns and 7 ,500 non-face patterns .
Each SVM classifier was trained by using 7 ,500 face patterns and 7 ,500 non-face patterns .
355 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved

The same 7 ,500 face patterns were used in training all these SVM classifiers .
The same 7 ,500 face patterns were used in training all these SVM classifiers .
356 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved

By running the cascade of AdaBoost classifiers of the second stage on the set of non-face images , 40 ,000 false positives were collected and used as non-face patterns to train the SVM classifiers .
By running the cascade of AdaBoost classifiers of the second stage on the set of non-face images , 40 ,000 false positives were collected and used as non-face patterns to train the SVM classifiers .
357 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved

7 ,500 non-face patterns used to train the first SVM classifier were selected randomly from the 40 ,000 non-face patterns .
The 7 ,500 non-face patterns used to train the first SVM classifier were selected randomly from the 40 ,000 non-face patterns .
358 0:1:preserved 1:2:preserved 2:3:preserved 3:4:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved :0:mogrammar-det

Non-face patterns in the subsequent SVM classifiers were false positives collected by the partially cascaded SVM classifiers on these 40 ,000 non-face patterns .
Non-face patterns in the subsequent SVM classifiers were false positives collected by the partially cascaded SVM classifiers on these 40 ,000 non-face patterns .
359 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved

To control the number of support vectors , the parameter \MATH was used instead of the parameter \MATH .
To control the number of support vectors , the parameter \MATH was used instead of the parameter \MATH .
360 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved

All SVM classifiers were trained by using the RBF kernel with \MATH .
All SVM classifiers were trained by using the RBF kernel with \MATH .
361 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved

All these parameters were found by using cross-validation test tool provided by LibSVM [31]} .
All these parameters were found by using a cross-validation test tool provided by LibSVM [31] . / / ?NOTE : I believe that I hyphenated this term in your previous document , but after seeing it used here , I would say that it does not need to be hyphenated
362 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved :7:mogrammar-det

This training procedure resulted three SVM classifiers whose the numbers of support vectors are 4 ,725 , 5 ,043 , and 4 ,847 respectively .
This training procedure yielded three SVM classifiers whose numbers of support vectors are 4 ,725 , 5 ,043 , and 4 ,847 .
363 0:0:preserved 1:1:preserved 2:2:preserved 3:3:paraphrase 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8::mogrammar-det 9:8:preserved 10:9:preserved 11:10:preserved 12:11:preserved 13:12:preserved 14:13:preserved 15:14:preserved 16:15:preserved 17:16:preserved 18:17:preserved 19:18:preserved 20:19:preserved 21:20:preserved 22:21:preserved 24:22:preserved

The average evaluating speed of a SVM classifier is approximate 610 WPS ( windows per second ) .
The average evaluating speed of a SVM classifier is approximately 610 WPS ( windows per second ) .
364 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:bigrammar-wform 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved

We tested our system on the MIT+CMU frontal-face standard test set [5] which consists of 124 images with 480 frontal faces ( excluding images containing hand-drawn , cartoon and small faces ) .
We tested our system on the MIT+CMU frontal-face standard test set [5] , which consists of 124 images with 480 frontal faces ( excluding images containing hand-drawn , cartoon , and small faces ) .
367 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:26:preserved 26:27:preserved 27:28:preserved 28:30:preserved 29:31:preserved 30:32:preserved 31:33:preserved 32:34:preserved

The configuration and rejection performance of the classifiers are listed in Table 1 and 2 .
The configuration and rejection performance of the classifiers are listed in Tables 1 and 2 .
368 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:bigrammar-nnum 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved

The first row presents the number of features of each layer , and the second row shows the fraction of the remaining patterns after each layer processing .
The first row presents the number of features of each layer and the second row shows the fraction of the remaining patterns after each layer were processed . / / [fraction / percentage?<--Here and after , you use " percentage " in the graph , so you may want to keep the same term here .]
369 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 12:11:preserved 13:12:preserved 14:13:preserved 15:14:preserved 16:15:preserved 17:16:preserved 18:17:preserved 19:18:preserved 20:19:preserved 21:20:preserved 22:21:preserved 23:22:preserved 24:23:preserved 25:24:preserved 26:25,26:paraphrase 27:27:preserved

The last row indicates the fraction of time that each layer consumes .
The last row indicates the fraction of time that each layer consumed . / / [fraction / percentage?]
370 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:bigrammar-vtense 12:12:preserved

All these statistics are extracted from running the classifiers on the MIT+CMU test set .
All these statistics were extracted by running the classifiers on the MIT+CMU test set .
371 0:0:preserved 1:1:preserved 2:2:preserved 3,4:3,4:bigrammar-vtense 5:5:bigrammar-prep 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved

The fraction of the remaining patterns on these two tables indicates that most of the non-face patterns , i.e. , \MATH , are rejected by the first stage , the cascade of 36x36 AdaBoost classifiers .
The fraction of the remaining patterns on these two tables indicates that most of the non-face patterns , i.e. , \MATH , were rejected by the first stage , the cascade of 36x36 AdaBoost classifiers .
374 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22,23:22,23:bigrammar-vtense 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved 35:35:preserved

If the first 24x24 layer classifier is added to the cascade of 36x36 classifiers , this combination rejects 85 .91\% of analyzed patterns compared to \MATH of using only the first layer of the single cascade 24x24 classifiers .
When the first 24x24 layer classifier was added to the cascade of 36x36 classifiers , this combination rejected 85 .91\% of analyzed patterns compared to \MATH of using only the first layer of the single cascade of 24x24 classifiers .
375 0:0:paraphrase 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6,7:6,7:bigrammar-vtense 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:bigrammar-vtense 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved 35:35:preserved 36:37:preserved 37:38:preserved 38:39:preserved :36:mogrammar-prep

Furthermore , the rejection of this very large number of patterns is done extremely quickly , only using \MATH of processing time .
Furthermore , the rejection of this very large number of patterns was done extremely quickly , only using \MATH of the total processing time . / / [the total / the standard?]
376 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11,12:11,12:bigrammar-vtense 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:22:preserved 21:23:preserved 22:24:preserved

It also shows that most of the processing time used by the AdaBoost+SVM system , \MATH , is used for SVM classifiers .
It also shows that most of the processing time used by the AdaBoost+SVM system , \MATH , was used for SVM classifiers .
377 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17,18:17,18:bigrammar-vtense 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved

Detection rate and speed of classifiers with ten false positives are listed in Table 3 .
The detection rate and speed of the classifiers with ten false positives are listed in Table 3 .
380 0:1:preserved 1:2:preserved 2:3:preserved 3:4:preserved 4:5:preserved 5:7:preserved 6:8:preserved 7:9:preserved 8:10:preserved 9:11:preserved 10:12:preserved 11:13:preserved 12:14:preserved 13:15:preserved 14:16:preserved 15:17:preserved :0:mogrammar-det :6:mogrammar-det

It is clear that our multi-stage system runs faster than the single cascade of 24x24 AdaBoost classifiers while detection rates are comparable .
It is clear that our multi-stage system ran faster than the single cascade of 24x24 AdaBoost classifiers while achieving comparable detection rates .
381 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:bigrammar-vtense 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:20:preserved 19:21:preserved 20:18:paraphrase 21:19:preserved 22:22:preserved

This performance is possible because of the three following reasons :
This performance was possible for three reasons .
382 0:0:preserved 1:1:preserved 2:2:bigrammar-vtense 3:3:preserved 4,5:4:paraphrase 6::mogrammar-det 7:5:preserved 9:6:preserved

First , the cascade of 36x36 AdaBoost classifiers rejects a lot of non-face patterns extremely fast while slow SVM classifiers only process a very small number of the remaining patterns .
First , the cascade of 36x36 AdaBoost classifiers rejected many of non-face patterns extremely quickly , while slow SVM classifiers only processed a very small number of the remaining patterns .
383 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:bigrammar-vtense 9,10:9:paraphrase 11:10:preserved 12:11:preserved 13:12:preserved 14:13:preserved 15:14:paraphrase 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:bigrammar-vtense 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved

Second , many images in the MIT+CMU test set contain large portion of background which was mentioned in [9] which said the ratio of non-face to face patterns is about 50 ,000 to 1 .
Second , many images in the MIT+CMU test set contain large portion of background , which [9] mentioned has a ratio of non-face to face patterns of about 50 ,000 to 1 .
384 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:15:preserved 15,17,19,20:18:paraphrase 16:17:preserved 18:16:preserved 21:19:bigrammar-det 22:20:preserved 23:21:preserved 24:22:preserved 25:23:preserved 26:24:preserved 27:25:preserved 28:26:paraphrase 29:27:preserved 30:28:preserved 31:29:preserved 32:30:preserved 33:31:preserved 34:32:preserved

Experimental results showed that the AdaBoost+SVM system runs faster than that of the original AdaBoost on \MATH of total number of images in this test set .
Experimental results showed that the AdaBoost+SVM system ran faster than that of the original AdaBoost on \MATH of the total number of images in this test set .
385 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:bigrammar-vtense 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:26:preserved 26:27:preserved :18:mogrammar-det

Third , at a small number of false positives , some true face candidate regions rejected by 36x36 classifiers do not affect so much in final performance because it might also be rejected by 24x24 classifiers in later layers .
Third , at a small number of false positives , some true face candidate regions rejected by 36x36 classifiers did not severely affect the final performance because they might also be rejected by 24x24 classifiers in later layers .
386 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19,21:19,22:bigrammar-vtense 20:20:preserved 22,23:21:paraphrase 24::mogrammar-prep 25:24:preserved 26:25:preserved 27:26:preserved 28:27:bigrammar-others 29:28:preserved 30:29:preserved 31:30:preserved 32:31:preserved 33:32:preserved 34:33:preserved 35:34:preserved 36:35:preserved 37:36:preserved 38:37:preserved 39:38:preserved :23:mogrammar-det

Some detection results are given in Figure 17 .
Some detection results are given in Figure 17 .
389 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved

We have developed a method to build a fast and robust face detection system based on a multi-stage approach .
We have developed a method to build a fast and robust face detection system based on a multi-stage approach .
395 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved

The cascaded structure of AdaBoost-based classifiers in two first stages allows to best adapt to various complexities of input patterns ,while non linear SVM classifiers at the final stage are robust enough to achieve good results .
The cascaded structure of AdaBoost-based classifiers in the two first stages allows the system to best adapt to various complexities of input patterns , while nonlinear SVM classifiers at the final stage are robust enough to achieve good results .
396 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11,12,13:paraphrase 11:14:preserved 12:15:preserved 13:16:preserved 14:17:preserved 15:18:preserved 16:19:preserved 17:20:preserved 18:21:preserved 19:22:preserved 20:24:preserved 21,22:25:spelling 23:26:preserved 24:27:preserved 25:28:preserved 26:29:preserved 27:30:preserved 28:31:preserved 29:32:preserved 30:33:preserved 31:34:preserved 32:35:preserved 33:36:preserved 34:37:preserved 35:38:preserved 36:39:preserved :7:mogrammar-det

Extensive experiments demonstrated that a significant computation time is devoted to potential face regions because almost all non-face patterns are rejected quickly by the two first stages , and only a very small number of face-like patterns is processed by the slow SVM classifiers .
Extensive experiments demonstrated that a significant computation time is devoted to potential face regions because almost all non-face patterns are rejected quickly by the two first stages , and only a very small number of face-like patterns are processed by the slow SVM classifiers . / / [are / need to be?]
397 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved 35:35:preserved 36:36:preserved 37,38:37,38:bigrammar-inter 39:39:preserved 40:40:preserved 41:41:preserved 42:42:preserved 43:43:preserved 44:44:preserved

Discriminant Haar wavelet features selected from AdaBoost are used for all stage classifier to take advantages from their efficient representation and fast evaluation .
Discriminant Haar wavelet features selected from AdaBoost are used for all stage classifiers to take advantage of their efficient representation and fast evaluation .
398 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:bigrammar-nnum 13:13:preserved 14:14:preserved 15:15:bigrammar-nnum 16:16:bigrammar-prep 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved

