Comparing Diﬀerent Criteria for Vietnamese Word Segmentation
Comparing Diﬀerent Criteria for Vietnamese Word Segmentation
2 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved

The success of corpus based methods has made syntactically annotated corpora important resources for natural language processing . 
Syntactically annotated corpora have become important resources for natural language processing , due in part to the success of corpus-based methods . 
6 0:16:preserved 1:17:preserved 2:18:preserved 3,4:19:typo 5:20:preserved 6,7,8:0,3,4,11,12,13,14,15:paraphrase 9:1:preserved 10:2:preserved 11:5:preserved 12:6:preserved 13:7:preserved 14:8:preserved 15:9:preserved 16:10:preserved 17:21:preserved

Since words are often considered as the primitive units of language structures , the annotation of word segmentation forms the basis of these corpora . 
Since words are often considered as primitive units of language structures , the annotation of word segmentation forms the basis of these corpora . 
7 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:12:preserved 7:6:preserved 8:7:preserved 9:8:preserved 10:9:preserved 11:10:preserved 12:11:preserved 13:18:preserved 14:13:preserved 15:14:preserved 16:15:preserved 17:16:preserved 18:17:preserved 19::mogrammar-det 20:19:preserved 21:20:preserved 22:21:preserved 23:22:preserved 24:23:preserved

This is also a concern of Vietnamese Treebank ( VTB ) , the first and the only publicly available syntactically annotated corpus so far for the Vietnamese language . 
This is also a concern for the Vietnamese Treebank ( VTB ) , which is the first and only publicly available syntactically annotated corpus thus far for the Vietnamese language . 
8 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5::mogrammar-prep 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:13,14,12:paraphrase 12:15:preserved 13:16:preserved 14:17:preserved 15::unaligned 16:18:preserved 17:19:preserved 18:20:preserved 19:21:preserved 20:22:preserved 21:23:preserved 22:24:paraphrase 23:25:preserved 24:26:preserved 25:27:preserved 26:28:preserved 27:29:preserved 28:30:preserved :5:mogrammar-prep :6:mogrammar-det

Although word segmentation is straight-forward for space-delimited languages like English , this is not true for languages like Vietnamese of which no standard criterion for word segmentation exists . 
Although word segmentation is straight-forward for space-delimited languages like English , this is not the case for languages like Vietnamese for which a standard criterion for word segmentation does not exist . 
9 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:15,14:paraphrase 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:bigrammar-prep 20:21:preserved 21:22:bigrammar-det 22:23:preserved 23:24:preserved 24:25:preserved 25:26:preserved 26:27:preserved 27:28,29,30:paraphrase 28:31:preserved

This work explores the challenges of Vietnamese word segmentation through the detection and correction of inconsistency for VTB . 
This work explores the challenges of Vietnamese word segmentation through the detection and correction of inconsistency for VTB . 
10 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved

Then , by combining and splitting the inconsistent annotations detected , we could observe the influence of different word segmentation criteria on automatic word segmentation , and the applications of word segmentation , including text classification and English-Vietnamese statistical machine translation . 
Then , by combining and splitting the inconsistent annotations that were detected , we are able to observe the influence of different word segmentation criteria on automatic word segmentation , and the applications of word segmentation , including text classification and English-Vietnamese statistical machine translation . 
11 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:11,10:para-passact 10:12:preserved 11:13:preserved 12:9,14,15,16:paraphrase 13:17:preserved 14:18:preserved 15:19:preserved 16:20:preserved 17:21:preserved 18:22:preserved 19:23:preserved 20:24:preserved 21:25:preserved 22:26:preserved 23:27:preserved 24:28:preserved 25:29:preserved 26:30:preserved 27:31:preserved 28:32:preserved 29:33:preserved 30:34:preserved 31:35:preserved 32:36:preserved 33:37:preserved 34:38:preserved 35:39:preserved 36:40:preserved 37:41:preserved 38:42:preserved 39:43:preserved 40:44:preserved 41:45:preserved

The analysis and experimental results showed that our methods improved the quality of VTB , which positively affected the performance of its applications .
The analysis and experimental results showed that our methods improved the quality of VTB , which positively affected the performance of its applications .
12 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved

Treebanks , corpora annotated with syntactic structures , have become more and more important for language processing . 
Treebanks , which are corpora annotated with syntactic structures , have become more and more important for language processing . 
17 0:0:preserved 1:1:preserved 2:4:preserved 3:5:preserved 4:6:preserved 5:7:preserved 6:8:preserved 7:9:preserved 8:10:preserved 9:11:preserved 10:12:preserved 11:13:preserved 12:14:preserved 13:15:preserved 14:16:preserved 15:17:preserved 16:18:preserved 17:19:preserved :2,3:bigrammar-others

To strengthen the automatic processing of the Vietnamese language , the Vietnamese treebank ( VTB ) has been built as a part of the national project , " Vietnamese language and speech processing ( VLSP ) " ( Nguyen et al. ,  2009b ) .
In order to strengthen the automatic processing of the Vietnamese language , the Vietnamese Treebank ( VTB ) has been built as a part of the national project , " Vietnamese language and speech processing ( VLSP ) " ( Nguyen et al. ,  2009b ) .
18 0:0,1,2:paraphrase 1:3:preserved 2:4:preserved 3:5:preserved 4:6:preserved 5:7:preserved 6:8:preserved 7:9:preserved 8:10:preserved 9:11:preserved 10:12:preserved 11:13:preserved 12:14:typo 13:15:preserved 14:16:preserved 15:17:preserved 16:18:preserved 17:19:preserved 18:20:preserved 19:21:preserved 20:22:preserved 21:23:preserved 22:24:preserved 23:25:preserved 24:26:preserved 25:27:preserved 26:28:preserved 27:29:preserved 28:30:preserved 29:31:preserved 30:32:preserved 31:33:preserved 32:34:preserved 33:35:preserved 34:36:preserved 35:37:preserved 36:38:preserved 37:39:preserved 38:40:preserved 39:41:preserved 40:42:preserved 41:43:preserved 42:44:preserved 43:45:preserved 44:46:preserved

However , in our preliminary experiment with VTB , when we trained the Berkeley parser  ( Petrov et al. ,  2006 ) and evaluated it using the corpus , the parser achieved only 65.8% in F-score . 
However , in our preliminary experiment with VTB , when we trained the Berkeley parser  ( Petrov et al. ,  2006 ) and evaluated it by using the corpus , the parser achieved only 65.8% in F-score . 
19 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:26:preserved 26:27:preserved 27:28:preserved 28:29:preserved 29:30:preserved 30:31:preserved 31:32:preserved 32:33:preserved 33:34:preserved 34:35:preserved 35:36:preserved 36:37:preserved :25:mogrammar-prep

This performance is far lower than the state-of-the-art performance reported for Berkeley Parser on English Penn Treebank , 90.3% in F-score ( Petrov et al. ,  2006 ) . 
This score is far lower than the state-of-the-art performance reported for the Berkeley Parser on the English Penn Treebank , which reported 90.3% in F-score ( Petrov et al. ,  2006 ) . 
20 0:0:preserved 1:1:paraphrase 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:16:preserved 15:17:preserved 16:18:preserved 17:19,20,21:paraphrase 18:22:preserved 19:23:preserved 20:24:preserved 21:25:preserved 22:26:preserved 23:27:preserved 24:28:preserved 25:29:preserved 26:30:preserved 27:31:preserved 28:32:preserved :11:mogrammar-det :15:mogrammar-det

There are two possible reasons for this . 
There are two possible reasons to explain this outcome . 
21 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5,6,8:paraphrase 6:7:preserved 7:9:preserved

First , the quality of VTB is not good enough to build a good a parser , including the quality of the annotation scheme , the annotation guidelines , and the annotation process . 
One reason for this outcome is the quality of VTB , including the quality of the annotation scheme , the annotation guidelines , and the annotation process . 
22 0,7,8,9,10,11,12,13,14,15:0,1,2,3,4:paraphrase 1:10:preserved 2:6:preserved 3:7:preserved 4:8:preserved 5:9:preserved 6:5:preserved 16::unaligned 17:11:preserved 18:12:preserved 19:13:preserved 20:14:preserved 21:15:preserved 22:16:preserved 23:17:preserved 24:18:preserved 25:19:preserved 26:20:preserved 27:21:preserved 28:22:preserved 29:23:preserved 30:24:preserved 31:25:preserved 32:26:preserved 33:27:preserved

Second , parsing Vietnamese is a difficult problem by its own ; and we need to seek new solutions to the problem .
The second reason is the difficulty of parsing Vietnamese; we need to seek new solutions to address this problem .
23 0:1:preserved 1,5,8,9,10,11,12,21,6:0,2,6,16,5:paraphrase 2:7:preserved 3:8:preserved 4:3:preserved 7:18:preserved 13:9:preserved 14:10:preserved 15:11:preserved 16:12:preserved 17:13:preserved 18:14:preserved 19:15:preserved 20:17:bigrammar-det 22:19:preserved :4:unaligned

VTB is annotated with three layers : word segmentation , POS tagging , and bracketing .
VTB is annotated with three layers : word segmentation , POS tagging , and bracketing .
24 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved

This paper focuses on the word segmentation issues  since the most basic unit of a Treebank is word ( Di Sciullo and Edwin ,  1987 ) , and defining “ What are words ? “ is the first problem that a treebank has to solve ( Xia , 2000b ,a; Sornlertlamvanich et al. ,  1997 , 1999 ) . 
This paper focuses on the word segmentation , since the most basic unit of a treebank are words ( Di Sciullo and Edwin ,  1987 ) , and defining " words " is the first step ( Xia , 2000b ,a; Sornlertlamvanich et al. ,  1997 , 1999 ) . 
25 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:paraphrase 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:typo 16:16:bigrammar-inter 17:17:bigrammar-nnum 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23::unaligned 24:24:preserved 25:25:preserved 26:23:preserved 27:27:preserved 28:28:preserved 29,30,31,32,33,34:29,30,31:paraphrase 35:32:preserved 36:33:preserved 37:34:preserved 38:35:paraphrase 39,40,42,43,44::unaligned 41::unaligned 45:36:preserved 46:37:preserved 47:38:preserved 48:39:preserved 49:40:preserved 50:41:preserved 51:42:preserved 52:43:preserved 53:44:preserved 54:45:preserved 55:46:preserved 56:47:preserved 57:48:preserved 58:49:preserved :26:unaligned

For languages like English , answering this question is almost trivial , because the blank spaces denote word delimiters . 
For languages like English , defining " words " is almost trivial , because the blank spaces denote word delimiters . 
26 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5,6,7:5,6,7,8:paraphrase 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved

However , for an isolating language like Vietnamese , where blank spaces play a role of syllable delimiters , " What are words? " is not a trivial question . 
However , for an isolating language like Vietnamese , for which blank spaces play a role of syllable delimiters , " What are words? " is not a trivial question . 
27 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9,10:para-freeword 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:26:preserved 26:27:preserved 27:28:preserved 28:29:preserved 29:30:preserved

For example , the sentence " Học sinh học sinh học ( students learn biology ) </CITE> " is composed of three words , " học sinh ( student ) " , " học ( learn ) , " and " sinh học ( biology ) " . 
For example , the sentence " Học sinh học sinh học ( students learn biology ) </CITE> " is composed of three words , " học sinh ( student ) " , " học ( learn ) , " and " sinh học ( biology ) " . 
28 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved 35:35:preserved 36:36:preserved 37:37:preserved 38:38:preserved 39:39:preserved 40:40:preserved 41:41:preserved 42:42:preserved 43:43:preserved 44:44:preserved 45:45:preserved 46:46:preserved 47:47:preserved

Word segmentation is expected to break down the sentence at the boundaries of these words , not to split " học sinh ( student ) " and " sinh học ( biology ) . " 
Word segmentation is expected to break down the sentence at the boundaries of these words , instead of splitting " học sinh ( student ) " and " sinh học ( biology ) . " 
29 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16,17,18:16,17,18:para-freeword 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved

Note that the terminology " word segmentation " also refers to the task of extracting words statistically without concerning a gold-standard for segmentation , as in  ( Ha , 2003; Le et al. ,  2010 ) . 
Note that the terminology " word segmentation " also refers to the task of extracting words statistically without concerning a gold-standard for segmentation , as in  ( Ha , 2003; Le et al. ,  2010 ) . 
30 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved 35:35:preserved 36:36:preserved

In such context , the extracted words are more appropriate for building a dictionary than for corpus-based language processing , which are out of the focus of this paper . 
In such a context , the extracted words are more appropriate for building a dictionary , rather than for corpus-based language processing , which are outside of the scope of this paper . 
31 0:0:preserved 1:1:preserved 2:3:preserved 3:4:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15,16,17:para-freeword 15:18:preserved 16:19:preserved 17:20:preserved 18:21:preserved 19:22:preserved 20:23:preserved 21:24:preserved 22:25:paraphrase 23:26:preserved 24:27:preserved 25:28:paraphrase 26:29:preserved 27:30:preserved 28:31:preserved 29:32:preserved :2:mogrammar-det

Establishing a gold standard for Vietnamese word segmentation faces some difficulties coming from the characteristics of the language .
Because of the discussed characteristics of the language , there are challenges in establishing a gold standard for Vietnamese word segmentation .
32 0:13:preserved 1:14:preserved 2:15:preserved 3:16:preserved 4:17:preserved 5:18:preserved 6:19:preserved 7:20:preserved 8,9,10,11,12:0,3,8,9,10,11,12,1,2:para-freeword 13::unaligned 14:4:preserved 15:5:preserved 16:6:preserved 17:7:preserved 18:21:preserved

The difficulties of Vietnamese word segmentation have been recognized by many researchers  ( Ha , 2003; Nguyen et al. ,  2004 , 2006; Le et al. ,  2010 ) . 
The difficulties in Vietnamese word segmentation have been recognized by many researchers  ( Ha , 2003; Nguyen et al. ,  2004 , 2006; Le et al. ,  2010 ) . 
33 0:0:preserved 1:1:preserved 2:2:bigrammar-prep 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved

Although most people agree that the Vietnamese language has two types of words : single and compound , there is little consensus on how to segment a sentence into words . 
Although most people agree that the Vietnamese language has two types of words : single and compound , there is little consensus as to the methodology for segmenting a sentence into words . 
34 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22,23,25,24:22,24,25,26,27,23:para-freeword 26:28:preserved 27:29:preserved 28:30:preserved 29:31:preserved 30:32:preserved

The disagreement is not only because of the different functions of blank spaces as mentioned above but also because Vietnamese is not an inflectional language like English or Japanese where morphological forms can be useful clues for word segmentation . 
The disagreement occurs not only because of the different functions of blank spaces ( as mentioned above ) , but also because Vietnamese is not an inflectional language , as is the case for English or Japanese , for which morphological forms can provide useful clues for word segmentation . 
35 0:0:preserved 1:1:preserved 2:2:paraphrase 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:19:preserved 17:20:preserved 18:21:preserved 19:22:preserved 20:23:preserved 21:24:preserved 22:25:preserved 23:26:preserved 24:27:preserved 25:28,29,30,31,32,33:para-freeword 26:34:preserved 27:35:preserved 28:36:preserved 29:38,39:para-freeword 30:40:preserved 31:41:preserved 32:42:preserved 33:43:paraphrase 34:44:preserved 35:45:preserved 36:46:preserved 37:47:preserved 38:48:preserved 39:49:preserved :37:unaligned

While the similar problems also happen with Chinese word segmentation  ( Xia , 2000b ) , Vietnamese word segmentation may be more difficult because the modern Vietnamese writing system is based on Latin characters , which represents the pronunciation , but not the meaning of words . 
While similar problems also occur with Chinese word segmentation  ( Xia , 2000b ) , Vietnamese word segmentation may be more difficult , because the modern Vietnamese writing system is based on Latin characters , which represent the pronunciation , but not the meaning of words . 
36 0:0:preserved 1::mogrammar-det 2:1:preserved 3:2:preserved 4:3:preserved 5:4:paraphrase 6:5:preserved 7:6:preserved 8:7:preserved 9:8:preserved 10:9:preserved 11:10:preserved 12:11:preserved 13:12:preserved 14:13:preserved 15:14:preserved 16:15:preserved 17:16:preserved 18:17:preserved 19:18:preserved 20:19:preserved 21:20:preserved 22:21:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved 35:35:preserved 36:36:bigrammar-inter 37:37:preserved 38:38:preserved 39:39:preserved 40:40:preserved 41:41:preserved 42:42:preserved 43:43:preserved 44:44:preserved 45:45:preserved 46:46:preserved

All these characteristics make it diﬃcult to perform word segmentation for Vietnamese both manually and automatically , and have resulted in different criteria for word segmenation . 
All of these characteristics make it diﬃcult to perform word segmentation for Vietnamese , both manually and automatically , and have thus resulted in different criteria for word segmentation . 
37 0:0:preserved 1:2:preserved 2:3:preserved 3:4:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:14:preserved 13:15:preserved 14:16:preserved 15:17:preserved 16:18:preserved 17:19:preserved 18:20:preserved 19:22,21:para-freeword 20:23:preserved 21:24:preserved 22:25:preserved 23:26:preserved 24:27:preserved 25:28:typo 26:29:preserved :1:mogrammar-prep

However , so far , there have been few studies on the challenges in word segmentation , and the comparison of different word segmentation criteria .
However , so far , there have been few studies on the challenges in word segmentation , and the comparison of different word segmentation criteria .
38 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved

In this paper , a brief introduction of the Vietnamese treebank VTB and its annotation scheme are given in Section 2 . 
In this paper , a brief introduction of the Vietnamese Treebank VTB and its annotation scheme are provided in Section 2 . 
39 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:typo 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:paraphrase 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved

Then , we described our methods for the detection and correction of the problematic annotations in the VTB corpus ( Section  4.2 ) . 
Then , we described our methods for the detection and correction of the problematic annotations in the VTB corpus ( Section  4.2 ) . 
40 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved

We classified the problematic annotations into several patterns of inconsistency , part of which were manually fixed to improve the quality of the corpus . 
We classified the problematic annotations into several patterns of inconsistency , part of which were manually fixed to improve the quality of the corpus . 
41 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved

The rest , which can be considered as the most difficult and controversial casess of word segmentation , were used to create different versions of the VTB corpus , representing different word segmentation criteria . 
The rest , which can be considered as the most difficult and controversial instances of word segmentation , were used to create different versions of the VTB corpus , representing different word segmentation criteria . 
42 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:spelling 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved

Finally , we evaluated these criteria in automatic word segmentation , and its application in text classification and English-Vietnamese statistical machine translation , in Section 4 .
Finally , we evaluated these criteria in automatic word segmentation , and its application in text classification and English-Vietnamese statistical machine translation , in Section 4 .
43 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved

This study is not only beneficial for the development of computational processing technologies for Vietnamese , a language spoken by over 90 million people , but also for the similar languages such as Thai , Laos , and so on . 
This study is not only beneficial for the development of computational processing technologies for Vietnamese , a language spoken by over 90 million people , but also for similar languages such as Thai , Laos , and so on . 
44 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28::mogrammar-det 29:28:preserved 30:29:preserved 31:30:preserved 32:31:preserved 33:32:preserved 34:33:preserved 35:34:preserved 36:35:preserved 37:36:preserved 38:37:preserved 39:38:preserved 40:39:preserved

This study also promotes the computational linguistic studies on how to transfer methods developed for a popular language , like English , to a language that has not yet intensively studied .
This study also promotes the computational linguistic studies on how to transfer methods developed for a popular language , like English , to a language that has not yet been intensively studied .
45 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:30:preserved 30:31,29:para-passact 31:32:preserved

Word segmentation in VTB aims to found a standard for word segmentation in a context of multi-level language processing . 
Word segmentation in VTB aims at establishing a standard for word segmentation in a context of multi-level language processing . 
50 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:bigrammar-prep 6:6:paraphrase 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved

VTB specifies 12 types of units that should be identified as words ( Table 1 ) ( Nguyen et al. , a ) , which can be divided into three groups : single , compound , and special " words . " 
VTB specifies 12 types of units that should be identified as words ( Table 1 ) ( Nguyen et al. , a ) , which can be divided up into three groups : single , compound , and special " words . " 
51 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:29:preserved 29:30:preserved 30:31:preserved 31:32:preserved 32:33:preserved 33:34:preserved 34:35:preserved 35:36:preserved 36:37:preserved 37:38:preserved 38:39:preserved 39:40:preserved 40:41:preserved 41:42:preserved :28:bigrammar-others

Single words contain only one token . 
Single words contain only one token . 
52 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved

The terminology tokens refers to text spans separated with each other by blank spaces . 
The terminology tokens refers to text spans that are separated from each other by blank spaces . 
53 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:9,7,8:para-freeword 8:10:bigrammar-prep 9:11:preserved 10:12:preserved 11:13:preserved 12:14:preserved 13:15:preserved 14:16:preserved

Compound words have two or more tokens , and are divided into four types : compound words composed by semantic coordination ( semantic-coordinated compound ) , compound words composed by semantic subordination ( semantic-subordinated compound ) , compound words with aﬃx , and reduplicated words . 
Compound words have two or more tokens , and are divided into four types : compound words composed by semantic coordination ( semantic-coordinated compound ) , compound words composed by semantic subordination ( semantic-subordinated compound ) , compound words with an aﬃx , and reduplicated words . 
54 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved 35:35:preserved 36:36:preserved 37:37:preserved 38:38:preserved 39:39:preserved 40:41:preserved 41:42:preserved 42:43:preserved 43:44:preserved 44:45:preserved 45:46:preserved :40:mogrammar-det

Special " words " can be idioms , locutions , proper names , date times , numbers , symbols , sentence marks , foreign words , or abbreviations . 
Special " words " include idioms , locutions , proper names , date times , numbers , symbols , sentence marks , foreign words , or abbreviations . 
55 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4,5:4:paraphrase 6:5:preserved 7:6:preserved 8:7:preserved 9:8:preserved 10:9:preserved 11:10:preserved 12:11:preserved 13:12:preserved 14:13:preserved 15:14:preserved 16:15:preserved 17:16:preserved 18:17:preserved 19:18:preserved 20:19:preserved 21:20:preserved 22:21:preserved 23:22:preserved 24:23:preserved 25:24:preserved 26:25:preserved 27:26:preserved 28:27:preserved

The segmentation of these types of words forms a basis for the POS tagging , with 18 different POS tags shown in Table 2 ( Nguyen et al. , c ) .
The segmentation of these types of words forms a basis for the POS tagging , with 18 different POS tags , as shown in Table 2 ( Nguyen et al. , c ) .
56 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:22:preserved 21:23:preserved 22:24:preserved 23:25:preserved 24:26:preserved 25:27:preserved 26:28:preserved 27:29:preserved 28:20:preserved 29:31:preserved 30:32:preserved 31:33:preserved :21,30:bigrammar-others

Each unit in Table 1 goes with several example words of which English translations are given in parentheses .
Each unit in Table 1 goes with several example words; English translations are provided in parentheses .
57 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9,10,11:9:para-freeword 12:10:preserved 13:11:preserved 14:12:preserved 15:13:paraphrase 16:14:preserved 17:15:preserved 18:16:preserved

Besides , we added a translation for each token , when possible , so that the readers unfamiliar with Vietnamese can have an intuitive idea of how the compound words are formed . 
Furthermore , we added a translation for each token , where possible , so that readers who are unfamiliar with Vietnamese can have an intuitive idea as to how the compound words are formed . 
58 0:0:paraphrase 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:paraphrase 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15::unaligned 16:15:preserved 17:18,16,17:para-freeword 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:26,27:bigrammar-prep 26:28:preserved 27:29:preserved 28:30:preserved 29:31:preserved 30:32:preserved 31:33:preserved 32:34:preserved

The subscript of a token translation is the index of that token in the compound word . 
The subscript of a token translation is the index of that token in the compound word . 
59 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved

However , for some tokens , we could not find any appropriate English translation , so we give it an empty translation , marked with an asterisk . 
However , for some tokens , we could not find any appropriate English translation , so we gave it an empty translation , marked with an asterisk . 
60 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:bigrammar-vtense 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved

Note that a Vietnamese word or a token in context can have other meanings , in addition to the given translations .
Note that a Vietnamese word or a token in context can have other meanings , in addition to the given translations .
61 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved

A special type of words in Vietnamese is noun , denoted by the part-of-speech Nc in Table 2 .
A classifier noun , denoted by the part-of-speech Nc in Table 2 , is a special type of word in Vietnamese .
62 0:14:preserved 1:15:preserved 2:16:preserved 3:17:preserved 4:18:bigrammar-nnum 5:9:preserved 6:20:preserved 7:13:preserved 8:2,1,0:paraphrase 9:3:preserved 10:4:preserved 11:5:preserved 12:6:preserved 13:7:preserved 14:8:preserved 15:19:preserved 16:10:preserved 17:11:preserved 18:21:preserved :12:unaligned

Classifier nouns are specific to several Southeast Asian languages , like Vietnamese and Thai . 
Classifier nouns are specific to several Southeast Asian languages , like Vietnamese and Thai . 
63 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved

One of the functions of classifier nouns is to express the definiteness . 
One of the functions of classifier nouns is to express the definiteness . 
64 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved

For example , the common noun " bàn " means tables in general , while " cái bàn " means a specific table , similar to the table in English .
For example , the common noun " bàn " generally means tables , while " cái bàn " means a specific table , similar to the table in English .
65 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:10:preserved 10:11:preserved 11,12:9:bigrammar-wform 13:12:preserved 14:13:preserved 15:14:preserved 16:15:preserved 17:16:preserved 18:17:preserved 19:18:preserved 20:19:preserved 21:20:preserved 22:21:preserved 23:22:preserved 24:23:preserved 25:24:preserved 26:25:preserved 27:26:preserved 28:27:preserved 29:28:preserved 30:29:preserved

In this section , we analyzed the VTB corpus to know whether the difficulties in Vietnamese word segmentation a ff ected the quality of VTB annotations . 
In this section , we analyzed the VTB corpus to determine whether the difficulties in Vietnamese word segmentation affected the quality of VTB annotations . 
70 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:paraphrase 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18,19,20:18:typo 21:19:preserved 22:20:preserved 23:21:preserved 24:22:preserved 25:23:preserved 26:24:preserved

The analysis results revealed several types of inconsistent annotations , which are also the most problematic cases of Vietnamese word segmentation . 
The analysis revealed several types of inconsistent annotations , which are also problematic for Vietnamese word segmentation . 
71 0:0:preserved 1,2:1:paraphrase 3:2:preserved 4:3:preserved 5:4:preserved 6:5:preserved 7:6:preserved 8:7:preserved 9:8:preserved 10:9:preserved 11:10:preserved 12:11:preserved 13,14,15,16:12:paraphrase 17:13:bigrammar-prep 18:14:preserved 19:15:preserved 20:16:preserved 21:17:preserved

Our analysis is based on two types of inconsistency : variation and structural inconsistency , whose definitions and details are given below .
Our analysis is based on two types of inconsistencies : variation and structural inconsistency , which are defined below .
72 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:bigrammar-nnum 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15,16,17,18,20:15,17:paraphrase 19:16:preserved 21:18:preserved 22:19:preserved

Variation inconsistency : is a sequence of tokens , which has more than one way of segmentation in the corpus . 
Variation inconsistency : is a sequence of tokens , which has more than one way of segmentation in the corpus . 
73 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved

For example , " con gái/girl " can remain as one word , or be segmented into two words , " con " and " gái " . 
For example , " con gái/girl " can remain as one word , or be segmented into two words , " con " and " gái " . 
74 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved

A variation can be an annotation inconsistency , or an ambiguity in Vietnamese . 
A variation can be an annotation inconsistency , or an ambiguity in Vietnamese . 
75 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved

While ambiguity cases reflect the difficulty of the language , annotation inconsistencies are usually caused by the confusion in the decision of annotators , which should be eliminated in annotation . 
While ambiguity cases reflect the difficulty of the language , annotation inconsistencies are usually caused by the confusion in the decision of annotators , which should be eliminated in annotation . 
76 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved

We use the term variation instance to refer a single occurrence of a variation .
We use the term variation instance to refer to a single occurrence of a variation .
77 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved :8:bigrammar-others

Structural inconsistency : happens when di ff erent sequences have similar structures , thus should be splitted in the same way , but are segmented in different ways in the corpus . 
Structural inconsistency : happens when different sequences have similar structures , and thus should be split in the same way , but are segmented in different ways in the corpus . 
78 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5,6,7:5:typo 8:6:preserved 9:7:preserved 10:8:preserved 11:9:preserved 12:10,11:para-freeword 13:12:preserved 14:13:preserved 15:14:preserved 16:15:spelling 17:16:preserved 18:17:preserved 19:18:preserved 20:19:preserved 21:20:preserved 22:21:preserved 23:22:preserved 24:23:preserved 25:24:preserved 26:25:preserved 27:26:preserved 28:27:preserved 29:28:preserved 30:29:preserved 31:30:preserved

For example , " con gái/girl " and " con trai/boy " have similar structures : a combination of a classifier noun and a common noun , Nc + N , so when " con gái/girl " is splitted , and " con trai/boy " is not , it is considered as a structural inconsistency of Nc . 
For example , " con gái/girl " and " con trai/boy " have similar structures : a combination of a classifier noun and a common noun , Nc + N , so when " con gái/girl " is split , and " con trai/boy " is not , it is considered as a structural inconsistency of Nc . 
79 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved 35:35:preserved 36:36:preserved 37:37:preserved 38:38:spelling 39:39:preserved 40:40:preserved 41:41:preserved 42:42:preserved 43:43:preserved 44:44:preserved 45:45:preserved 46:46:preserved 47:47:preserved 48:48:preserved 49:49:preserved 50:50:preserved 51:51:preserved 52:52:preserved 53:53:preserved 54:54:preserved 55:55:preserved 56:56:preserved 57:57:preserved

It is likely that structural inconsistency in word segmentation level makes the higher levels of processing , POS tagging and bracketing , become more complicated .
It is likely that structural inconsistency at the word segmentation level complicates the higher levels of processing , including POS tagging and bracketing .
80 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:bigrammar-prep 7:8:preserved 8:9:preserved 9:10:preserved 10:11:paraphrase 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17,18:paraphrase 17:19:preserved 18:20:preserved 19:21:preserved 20:22:preserved 21,22,23,24::unaligned 25:23:preserved :7:mogrammar-det

The detection method for variation inconsistency is based on N-gram sequences and the phrase structures in VTB treebank , following the definition of variation inconsistency above . 
The detection method for variation inconsistency is based on N-gram sequences and the phrase structures in the VTB , following the definition for variation inconsistency , above . 
86 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16,17:17:paraphrase 18:18:preserved 19:19:preserved 20:16:preserved 21:21:preserved 22:22:bigrammar-prep 23:23:preserved 24:24:preserved 25:26:preserved 26:27:preserved :20:mogrammar-det

In details , we counted N-gram sequences of different lengths in VTB that have two or more ways of word segmentation , satisfying one of the following two conditions :
In detail , we counted N-gram sequences of different lengths in VTB that have two or more ways of word segmentation , satisfying one of the following two conditions :
87 0:0:preserved 1:1:bigrammar-nnum 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved

N tokens are all in the same phrase , and all have the same depth in phrase . 
N tokens are all in the same phrase , and all have the same depth in phrase . 
88 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved

For example , the 3-gram " nhà tình nghĩa ( house of gratitude ) " in this structure " ( NP ( Nc-H căn ) ( N nhà ) ( A tình nghĩa ) ) , " OR N tokens are all in the same phrase , and some tokens can appear in an embedded phrase , which contains only one word . 
For example , the 3-gram " nhà tình nghĩa ( house of gratitude ) " in this structure " ( NP ( Nc-H căn ) ( N nhà ) ( A tình nghĩa ) ) , " OR N tokens are all in the same phrase , and some tokens can appear in an embedded phrase , which contains only one word . 
89 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved 35:35:preserved 36:36:preserved 37:37:preserved 38:38:preserved 39:39:preserved 40:40:preserved 41:41:preserved 42:42:preserved 43:43:preserved 44:44:preserved 45:45:preserved 46:46:preserved 47:47:preserved 48:48:preserved 49:49:preserved 50:50:preserved 51:51:preserved 52:52:preserved 53:53:preserved 54:54:preserved 55:55:preserved 56:56:preserved 57:57:preserved 58:58:preserved 59:59:preserved 60:60:preserved 61:61:preserved 62:62:preserved

For example , " nhà tình nghĩa " in this structure " ( NP ( Nc-H căn ) ( N nhà ) ( ADJP ( A tình nghĩa ) ) ) , " where the ADJP contains only one word .
For example , " nhà tình nghĩa " in this structure " ( NP ( Nc-H căn ) ( N nhà ) ( ADJP ( A tình nghĩa ) ) ) , " where the ADJP contains only one word .
90 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved 35:35:preserved 36:36:preserved 37:37:preserved 38:38:preserved 39:39:preserved 40:40:preserved

Table 3 shows the overall statistics of the variation inconsistency detected by the above method . 
Table 3 shows the overall statistics of the variation inconsistency detected by the method described above . 
95 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13,14:15,13,14:paraphrase 15:16:preserved

Most of the diﬃcult cases of word segmentation lie in two-token variations , occupying the majority of variations ( 92.9% ) . 
Most of the diﬃcult cases of word segmentation occur in two-token variations , occupying the majority of variations ( 92.9% ) . 
96 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:paraphrase 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved

This ratio of 2-gram variations is much higher than the evarage ratio of two-token words in Vietnamese reported in ( Nguyen et al. ,  2009a ) , which is 80% percent . 
This ratio of 2-gram variations is much higher than the average ratio of two-token words in Vietnamese , as reported in ( Nguyen et al. ,  2009a ) , which is 80% . 
97 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:typo 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:19,18:para-freeword 18:20:preserved 19:21:preserved 20:22:preserved 21:23:preserved 22:24:preserved 23:25:preserved 24:26:preserved 25:27:preserved 26:28:preserved 27:29:preserved 28:30:preserved 29:31:preserved 30::unaligned 31:32:preserved

Variations that have lengths of three and four tokens occupy 6.1% and 1.0% , respectively .
Variations that have lengths of three and four tokens occupy 6.1% and 1.0% , respectively .
98 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved

We estimated the precision of our method by randomly selected 130 2-gram variation instances extracted from the above method described , and manually checked whether they are true inconsistency .
We estimated the precision of our method by randomly selecting 130 2-gram variation instances , extracted from the method described above , and manually checked whether the inconsistencies are true .
99 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:bigrammar-vtense 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:20:preserved 18:18:preserved 19:19:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25,28:26,27:para-freeword 26:28:preserved 27:29:preserved 29:30:preserved :14:unaligned

We found that 129 cases occupying 99.2% of all extracted 2-grams are true inconsistencies . 
We found that 129 cases occupying 99.2% of all extracted 2-grams are true inconsistencies . 
100 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved

Only one instance is an ambiguous sequence giá c , which is one word when it means price , and two words giá/price c /all in đàu có giá c /all have ( their own ) price . 
Only one instance of inconsistency was an ambiguous sequence giá c , which is one word when it means price , and two words giá/price c /all in đàu có giá c /all have ( their own ) price . 
101 0:0:preserved 1:1:preserved 2:2:preserved 3:3,4,5:paraphrase 4:6:preserved 5:7:preserved 6:8:preserved 7:9:preserved 8:10:preserved 9:11:preserved 10:12:preserved 11:13:preserved 12:14:preserved 13:15:preserved 14:16:preserved 15:17:preserved 16:18:preserved 17:19:preserved 18:20:preserved 19:21:preserved 20:22:preserved 21:23:preserved 22:24:preserved 23:25:preserved 24:26:preserved 25:27:preserved 26:28:preserved 27:29:preserved 28:30:preserved 29:31:preserved 30:32:preserved 31:33:preserved 32:34:preserved 33:35:preserved 34:36:preserved 35:37:preserved 36:38:preserved 37:39:preserved

The precision of our method is high so we can use the extracted variations to study the insights of word segmentation problem .
The precision for our method is high , so we can use the extracted variations to provide insights on the word segmentation problem .
102 0:0:preserved 1:1:preserved 2:2:bigrammar-prep 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:paraphrase 16:19:preserved 17:17:preserved 18:18:bigrammar-prep 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved :7:unaligned

We further analyzed the 2-gram variations to know what types of 2-grams were most confusing to annotators . 
We further analyzed the 2-gram variations to understand what types of 2-grams were most confusing for annotators . 
107 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:paraphrase 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:bigrammar-prep 16:16:preserved 17:17:preserved

The analysis results showed that compound nouns , compound verbs , and compound adjectives are the top diffcult cases of word segmentation .
The analysis revealed that compound nouns , compound verbs , and compound adjectives are the most difficult cases of word segmentation .
108 0:0:preserved 1:1:preserved 2,3:2:paraphrase 4:3:preserved 5:4:preserved 6:5:preserved 7:6:preserved 8:7:preserved 9:8:preserved 10:9:preserved 11:10:preserved 12:11:preserved 13:12:preserved 14:13:preserved 15:14:preserved 16:15:paraphrase 17:16:preserved 18:17:preserved 19:18:preserved 20:19:preserved 21:20:preserved 22:21:preserved

We classified the 2-gram variations according to their POS sequences in case the tokens in the 2-gram are splitted . 
We classified the 2-gram variations according to their POS sequences in case the tokens in the 2-gram are split . 
109 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:bigrammar-vtense 19:19:preserved

There are 54 patterns of POS sequence , of which . 
There are a total of 54 patterns of POS sequences . 
110 0:0:preserved 1:1:preserved 2:5:preserved 3:6:preserved 4:7:preserved 5:8:preserved 6:9:bigrammar-nnum 8,9,7:2,3,4:para-freeword 10:10:preserved

Top 10 confusing patterns , a long with their counts of 2-gram variations , and examples are shown in Table 4 . 
The top 10 confusing patterns , their counts of 2-gram variations , and examples are depicted in Table 4 . 
111 0:1:preserved 1:2:preserved 2:3:preserved 3:4:preserved 4,5,6,7:5:para-freeword 8:6:preserved 9:7:preserved 10:8:preserved 11:9:preserved 12:10:preserved 13:11:preserved 14:12:preserved 15:13:preserved 16:14:preserved 17:15:paraphrase 18:16:preserved 19:17:preserved 20:18:preserved 21:19:preserved :0:mogrammar-det

Table 5 and Table 6 show the POS patterns which a specific POS tag , appearing at the beginning or ending of the sequence .
Table 5 and Table 6 show the POS patterns that are a specific POS tag , appearing at the beginning or ending of the sequence .
112 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9,10:para-freeword 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved

Investigating the inconsistent 2-grams extracted , we found that most of them are compound words , according to the VTB guidelines ( Section 2 ) . 
Investigating the inconsistent 2-grams extracted , we found that most of them are compound words , according to the VTB guidelines ( Section 2 ) . 
113 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved

One of the reasons why the compound words are sometimes splitted , is because the tokens in those compound words have their own meanings , which seem to contribute to the whole meaning of the compounds . 
One of the reasons why the compound words are sometimes split , is because the tokens in those compound words have their own meanings , which seem to contribute to the overall meaning of the compounds . 
114 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:bigrammar-vtense 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:paraphrase 32:32:preserved 33:33:preserved 34:34:preserved 35:35:preserved 36:36:preserved

This can be seen through the examples given in Table 4 , where the meanings of tokens are given with a subscript . 
This can be seen through the examples provided in Table 4 , where the meanings of tokens are given with a subscript . 
115 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:paraphrase 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved

This problem seems to have caused a lot of trouble for the annotators of VTB .
This scenario has proven to be problematic for the annotators of VTB .
116 0:0:preserved 1,2,4,5,6,7,9:1,2,3,5,6:paraphrase 3:4:preserved 8::unaligned 10:7:preserved 11:8:preserved 12:9:preserved 13:10:preserved 14:11:preserved 15:12:preserved

Furthermore , observing the POS patterns in Table 5 and Table 6 , we can see the potential of structural inconsistency , in particular for closed-set POS tags . 
Furthermore , by observing the POS patterns in Table 5 and Table 6 , we can see the potential for structural inconsistency , particularly for closed-set POS tags . 
117 0:0:preserved 1:1:preserved 2:3:preserved 3:4:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:bigrammar-prep 19:20:preserved 20:21:preserved 21:22:preserved 22,23:23:bigrammar-wform 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved :2:mogrammar-prep

Among them , classifier nouns ( Nc ) and affixes ( S ) are two typical cases of structural inconsistency , which will be used in several settings of our experiments . 
Among them , classifier nouns ( Nc ) and affixes ( S ) are two typical cases of structural inconsistency , which will be used in several settings for our experiments . 
118 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:bigrammar-prep 29:29:preserved 30:30:preserved 31:31:preserved

The same aﬃx or classifier noun can modify different nouns , so when they are sometimes splitted and sometimes combined in the variations , we can conclude that classifier nouns and affixes involve in-structural inconsistency . 
The same aﬃx or classifier noun can modify different nouns , so when they are sometimes split and combined in the variations , we can conclude that classifier nouns and affixes involve in-structural inconsistencies . 
119 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:bigrammar-vtense 17:17:preserved 18,19:18:para-freeword 20:19:preserved 21:20:preserved 22:21:preserved 23:22:preserved 24:23:preserved 25:24:preserved 26:25:preserved 27:26:preserved 28:27:preserved 29:28:preserved 30:29:preserved 31:30:preserved 32:31:preserved 33:32:preserved 34:33:bigrammar-nnum 35:34:preserved

In the following section , we presents our detection method for structural inconsistency for classifier nouns and affixes .
In the following section , we present our detection method for structural inconsistency for classifier nouns and affixes .
120 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:bigrammar-inter 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved

The detection method for structural inconsistency of classifier nouns and affixes is simple . 
The detection method for structural inconsistency of classifier nouns and affixes is simple . 
127 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved

First , we collected all affixes and classifier nouns in the VTB corpus . Then extracted 2-grams containing these affixes or classifier nouns , which also are the structural inconsistencies . 
We collected all affixes and classifier nouns in the VTB corpus , and then extracted 2-grams containing these affixes or classifier nouns , which are also structural inconsistencies . 
128 0::unaligned 1::unaligned 2:0:preserved 3:1:preserved 4:2:preserved 5:3:preserved 6:4:preserved 7:5:preserved 8:6:preserved 9:7:preserved 10:8:preserved 11:9:preserved 12:10:preserved 13,14:12,13,11:para-freeword 15:14:preserved 16:15:preserved 17:16:preserved 18:17:preserved 19:18:preserved 20:19:preserved 21:20:preserved 22:21:preserved 23:22:preserved 24:23:preserved 25:25:preserved 26:24:preserved 27::mogrammar-det 28:26:preserved 29:27:preserved 30:28:preserved

For example , since " con " is tagged as a classifier noun in VTB , we extracted all 2-grams of " con " including both " con gái/girl " and " con trai/boy " .
For example , since " con " is tagged as a classifier noun in VTB , we extracted all 2-grams of " con " including both " con gái/girl " and " con trai/boy " .
129 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved 35:35:preserved

Note that even though the sequence , " con trai " is always splitted into two words throughout the corpus , it can still be an inconsistency , if we consider similar structures such as " con gái " . 
Even though the sequence , " con trai " is always split into two words throughout the corpus , it can still be an inconsistency , if we consider similar structures such as " con gái " . 
130 0,1::unaligned 2:0:preserved 3:1:preserved 4:2:preserved 5:3:preserved 6:4:preserved 7:5:preserved 8:6:preserved 9:7:preserved 10:8:preserved 11:9:preserved 12:10:preserved 13:11:spelling 14:12:preserved 15:13:preserved 16:14:preserved 17:15:preserved 18:16:preserved 19:17:preserved 20:18:preserved 21:19:preserved 22:20:preserved 23:21:preserved 24:22:preserved 25:23:preserved 26:24:preserved 27:25:preserved 28:26:preserved 29:27:preserved 30:28:preserved 31:29:preserved 32:30:preserved 33:31:preserved 34:32:preserved 35:33:preserved 36:34:preserved 37:35:preserved 38:36:preserved 39:37:preserved

In other words , by this method , we extract sequences that may be consistent at the surface level , but are not consistent , if we consider the higher analysis levels , POS tagging .
In other words , by this method , we extract sequences that may be consistent at the surface level , but are not consistent , if we consider the higher analysis levels , POS tagging .
131 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved 35:35:preserved

According to the VTB POS-tagging annotation guidelines ( Nguyen et al. , c ) , classifier nouns should be separated from the words they modify . 
According to the VTB POS-tagging annotation guidelines ( Nguyen et al. , c ) , classifier nouns should be separated from the words that they modify . 
132 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:24:preserved 24:25:preserved 25:26:preserved :23:bigrammar-others

However , in practice it is confusing when the classifier noun can be standalone as a single word . 
However , in practice , it is confusing when the classifier noun can be standalone as a single word . 
133 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved :4:bigrammar-others

For example a classifier noun , e.g. , " con " in " con trai ( boy ) " , or " con gái ( girl ) " , can also be a simple word , which means " I ( first person pronoun used by a child when talking to his/her parents ) " , or part of a complex noun " con cái ( children ) " . 
For example a classifier noun , e.g. , " con " in " con trai ( boy ) " , or " con gái ( girl ) " , can also be a simple word , which means " I ( first person pronoun used by a child when talking to his/her parents ) " , or part of a complex noun " con cái ( children ) " . 
134 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved 35:35:preserved 36:36:preserved 37:37:preserved 38:38:preserved 39:39:preserved 40:40:preserved 41:41:preserved 42:42:preserved 43:43:preserved 44:44:preserved 45:45:preserved 46:46:preserved 47:47:preserved 48:48:preserved 49:49:preserved 50:50:preserved 51:51:preserved 52:52:preserved 53:53:preserved 54:54:preserved 55:55:preserved 56:56:preserved 57:57:preserved 58:58:preserved 59:59:preserved 60:60:preserved 61:61:preserved 62:62:preserved 63:63:preserved 64:64:preserved 65:65:preserved 66:66:preserved 67:67:preserved 68:68:preserved 69:69:preserved

Therefore , in our experiments , we want to evaluate the " splitting " and " combining " of these difficult cases , to see whether the solution is fruitful for applications of the corpus .
Therefore , in our experiments , we want to evaluate the " splitting " and " combining " of these cases , in order to see whether the solution is successful for applications of the corpus .
135 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20,21:20:paraphrase 22:21:preserved 23:24,22,23:para-freeword 24:25:preserved 25:26:preserved 26:27:preserved 27:28:preserved 28:29:preserved 29:30:paraphrase 30:31:preserved 31:32:preserved 32:33:preserved 33:34:preserved 34:35:preserved 35:36:preserved

Examing the variations extracted by the variation inconsistency detection , we found that there are cases when a special character like percentage % in " 30% " , is splitted or combined with " 30 " . 
By examining the variations extracted by the variation inconsistency detection , we found that there are cases when a special character like a percentage ( % ) in " 30% " , is split or combined with " 30 " . 
141 0:1:preserved 1:2:preserved 2:3:preserved 3:4:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:23:preserved 22:25:preserved 23:27:preserved 24:28:preserved 25:29:preserved 26:30:preserved 27:31:preserved 28:32:preserved 29:33:spelling 30:34:preserved 31:35:preserved 32:36:preserved 33:37:preserved 34:38:preserved 35:39:preserved 36:40:preserved :0:mogrammar-prep :22:mogrammar-det :24,26:unaligned

Such inconsistent annotations are manually fixed based on their textual context .
Such inconsistent annotations are manually fixed based on their textual context .
142 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved

Checking structural inconsistency of these special characters , including percentage % , hyphen - , and so on , we found quite a significant amount of inconsistent annotations . 
By checking structural inconsistencies of these special characters , including percentages ( % ) , hyphens ( - ) , and other symbols , we found quite a significant number of inconsistent annotations . 
143 0:1:preserved 1:2:preserved 2:3:bigrammar-nnum 3:4:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:bigrammar-nnum 10:12:preserved 11:14:preserved 12:15:bigrammar-nnum 13:17:preserved 14:19:preserved 15:20:preserved 16,17:21,22:paraphrase 18:23:preserved 19:24:preserved 20:25:preserved 21:26:preserved 22:27:preserved 23:28:preserved 24:29:paraphrase 25:30:preserved 26:31:preserved 27:32:preserved 28:33:preserved :0:mogrammar-prep :11,13,16,18:unaligned

For example , the character % in " 30% " is splitted , but is combined with the number in " 50 % " , which is considered as a structural inconsistency . 
For example , the character , % , in " 30% " is split , but is combined with a number in " 50 % " , which is considered to be a structural inconsistency . 
144 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:6:preserved 6:8:preserved 7:9:preserved 8:10:preserved 9:11:preserved 10:12:preserved 11:13:spelling 12:14:preserved 13:15:preserved 14:16:preserved 15:17:preserved 16:18:preserved 17:19:bigrammar-det 18:20:preserved 19:21:preserved 20:22:preserved 21:23:preserved 22:24:preserved 23:25:preserved 24:26:preserved 25:27:preserved 26:28:preserved 27:29:preserved 28:30,31:bigrammar-prep 29::unaligned 30:33:preserved 31:34:preserved 32:35:preserved :5:unaligned :7:unaligned :32:mogrammar-det

Note that although it can be argued that whether " N% " can be splitted into two words or combined in one word is dependent on the blank space in between N and " % " . 
Note that it can be argued that splitting " N% " into two words or combined in one word is dependent on the blank space in-between N and " % " . 
145 0:0:preserved 1,2:1:paraphrase 3:2:preserved 4:3:preserved 5:4:preserved 6:5:preserved 7:6:preserved 8:7:paraphrase 9:8:preserved 10:9:preserved 11:10:preserved 12,13,14,15:11:paraphrase 16:12:preserved 17:13:preserved 18:14:preserved 19:15:preserved 20:16:preserved 21:17:preserved 22:18:preserved 23:19:preserved 24:20:preserved 25:21:preserved 26:22:preserved 27:23:preserved 28:24:preserved 29,30:25:typo 31:26:preserved 32:27:preserved 33:28:preserved 34:29:preserved 35:30:preserved 36:31:preserved

It does matter higher-levels of annotation such as POS tagging, because we may need one or two different POS tags for different ways of annotation . 
Higher-levels of annotation such as POS tagging is significant , because we may need one or two different POS tags for the different methods of annotation . 
146 0,1,2,3:0,7,8,9:para-freeword 4:1:preserved 5:2:preserved 6:3:preserved 7:4:preserved 8:5:preserved 9:6:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:22:preserved 22:23:paraphrase 23:24:preserved 24:25:preserved 25:26:preserved :21:mogrammar-det

Therefore , we think it is better to carefully preprocess text and segment these special characters in a consistent way .
Therefore , we think that it is better to carefully preprocess text and segment these special characters in a consistent way .
147 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:5,4:para-freeword 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved

To improve the quality of VTB corpus , we extracted the probably problematic sequences using patterns of the special characters , and manually fixed this type of inconsistency . 
To improve the quality of the VTB corpus , we extracted the problematic sequences using patterns of the special characters , and manually fixed this type of inconsistency . 
148 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11::unaligned 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved :5:mogrammar-det

Automatically modification is diﬃcult , since we must check the semantics of the special characters in their contexts . 
Automatically modification is diﬃcult , since we must check the semantics of the special characters in their contexts . 
149 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved

For example , hyphens in date expressions like " 5-4-1975 " , which means the date , "April , 1975 ," are combined with the numbers . 
For example , hyphens in date expressions like " 5-4-1975 " , which refers to the date , "the fifth of April , 1975 ," are combined with the numbers . 
150 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13,14:paraphrase 14:15:preserved 15:16:preserved 16:17:preserved 17:18,19,20,21:paraphrase 18:22:preserved 19:23:preserved 20:24:preserved 21:25:preserved 22:26:preserved 23:27:preserved 24:28:preserved 25:29:preserved 26:30:preserved

However , when the hypen has a meaning of " ( from ) to " or " around ... or " , as in " 2-3 giờ sáng " , meaning " around 2 or 3 o’clock in the morning " , we decided to separate it from the surrounding numbers . 
However , when the hyphen indicates " ( from ) to " or " around ... or " , as in " 2-3 giờ sáng " , meaning " around 2 or 3 o’clock in the morning " , we decided to separate it from the surrounding numbers . 
151 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:typo 5,6,8,7:5:paraphrase 9:6:preserved 10:7:preserved 11:8:preserved 12:9:preserved 13:10:preserved 14:11:preserved 15:12:preserved 16:13:preserved 17:14:preserved 18:15:preserved 19:16:preserved 20:17:preserved 21:18:preserved 22:19:preserved 23:20:preserved 24:21:preserved 25:22:preserved 26:23:preserved 27:24:preserved 28:25:preserved 29:26:preserved 30:27:preserved 31:28:preserved 32:29:preserved 33:30:preserved 34:31:preserved 35:32:preserved 36:33:preserved 37:34:preserved 38:35:preserved 39:36:preserved 40:37:preserved 41:38:preserved 42:39:preserved 43:40:preserved 44:41:preserved 45:42:preserved 46:43:preserved 47:44:preserved 48:45:preserved 49:46:preserved 50:47:preserved 51:48:preserved

As a result , we have fixed 685 inconsistent annotations of 21 special characters in VTB .
As a result , we have fixed 685 inconsistent annotations of 21 special characters in VTB .
152 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved

The variation inconsistency and structural inconsistency found in Section 3 above can also be seen as representatives of different word segmentation criteria for Vietnamese . 
The variation inconsistency and structural inconsistency found in Section 3 can also be seen as representatives of different word segmentation criteria for Vietnamese . 
157 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10,11:10:paraphrase 12:11:preserved 13:12:preserved 14:13:preserved 15:14:preserved 16:15:preserved 17:16:preserved 18:17:preserved 19:18:preserved 20:19:preserved 21:20:preserved 22:21:preserved 23:22:preserved 24:23:preserved

We organized the inconsistency detected in seven configurations of the original VTB corpus . 
We organized the inconsistency detected in seven configurations of the original VTB corpus . 
158 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved

Then , by using these data sets , we could observe the influence of the different word segmentation criteria on three tasks : automatic word segmentation , text classification , and English-Vietnamese statistical machine translation .
Then , by using these data sets , we could observe the influence of the different word segmentation criteria on three tasks : automatic word segmentation , text classification , and English-Vietnamese statistical machine translation .
159 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved 35:35:preserved

Seven data sets corresponding to different segmentation criteria are organized as follows .
Seven data sets corresponding to different segmentation criteria are organized as follows .
163 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved

ORG  : The original VTB corpus . 
ORG  : The original VTB corpus . 
164 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved

BASE  : The original VTB corpus + Manual modification of special characters done in Section 3.3 . 
BASE  : The original VTB corpus + Manual modification of special characters done in Section 3.3 . 
165 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved

VAR_SPLIT  : BASE + split all variations detected in Section  3.1 . 
VAR_SPLIT  : BASE + split all variations detected in Section  3.1 . 
166 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved

VAR_COMB  : BASE + combine all variations detected in Section  3.1 . 
VAR_COMB  : BASE + combine all variations detected in Section  3.1 . 
167 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved

VAR_FREQ  : BASE + select the segmentation with higher frequency among all variations detected in Section  3.1 . 
VAR_FREQ  : BASE + select the segmentation with higher frequency among all variations detected in Section  3.1 . 
168 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved

STRUCT_NC  : BASE + combine all classifier nouns detected in Section 3.2 with the words they modify .
STRUCT_NC  : BASE + combine all classifier nouns detected in Section 3.2 with the words they modify .
169 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved

STRUCT_AFFIX  : BASE + combine all suﬃxes detected in Section 3.2 with the words they modify . 
STRUCT_AFFIX  : BASE + combine all suﬃxes detected in Section 3.2 with the words they modify . 
170 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved

These data sets are used in our experiments , as illustrated in Figure 1 . 
These data sets are used in our experiments , as illustrated in Figure 1 . 
171 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved

The names of the data sets are also used to label our experimental configurations . 
The names of the data sets are also used to label our experimental configurations . 
172 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved

In this section , we briefly describe the task settings and the methods used for word segmentation ( WS ) , text classification ( TC ) , and English-Vietnamese statistical machine translation ( SMT ) .
In this section , we briefly describe the task settings and the methods used for word segmentation ( WS ) , text classification ( TC ) , and English-Vietnamese statistical machine translation ( SMT ) .
177 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved 35:35:preserved

We used YamCha ( Kudo and Matsumoto ,  2003 ) , a multi-purpose chunking tool , to train our word segmentation models . 
We used YamCha ( Kudo and Matsumoto ,  2003 ) , a multi-purpose chunking tool , to train our word segmentation models . 
181 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved

The core of YamCha is the Support Vector Machine ( SVM ) machine learning method , which has been proved to be effective in NLP tasks . 
The core of YamCha is the Support Vector Machine ( SVM ) machine learning method , which has been proven to be effective for NLP tasks . 
182 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:spelling 20:20:preserved 21:21:preserved 22:22:preserved 23:23:bigrammar-prep 24:24:preserved 25:25:preserved 26:26:preserved

For the Vietnamese word segmentation problem , each token is labeled with standard B , I , or O labels , corresponding to beginning , inside , and outside positions , respectively . 
For the Vietnamese word segmentation problem , each token is labeled with standard B , I , or O labels , corresponding to the beginning , inside , and outside positions , respectively . 
183 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:24:preserved 24:25:preserved 25:26:preserved 26:27:preserved 27:28:preserved 28:29:preserved 29:30:preserved 30:31:preserved 31:32:preserved 32:33:preserved :23:mogrammar-det

Label of each token is determined based on the lexical features of two preceding words , and two following words of that token . 
The label of each token is determined based on the lexical features of two preceding words , and the two following words of that token . 
184 0:1:preserved 1:2:preserved 2:3:preserved 3:4:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:19:preserved 18:20:preserved 19:21:preserved 20:22:preserved 21:23:preserved 22:24:preserved 23:25:preserved :0:mogrammar-det :18:mogrammar-det

Since Vietnamese language is not inflectional , we cannot utilize inflection features for word segmentation .
Since the Vietnamese language is not inflectional , we cannot utilize inflection features for word segmentation .
185 0:0:preserved 1:2:preserved 2:3:preserved 3:4:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved :1:mogrammar-det

Each of the seven data sets is splitted into two subsets for training and testing our WS models . 
Each of the seven data sets is split into two subsets for training and testing our WS models . 
186 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:spelling 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved

The training set contains 8443 sentences , and the test set contains 2000 sentences .
The training set contains 8443 sentences , and the test set contains 2000 sentences .
187 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved

Text classification is defined as a task of determining for an input document the most suitable topic from the predefined topics . 
Text classification is defined as a task of determining the most suitable topic from the predefined topics , for an input document . 
192 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:18:preserved 10:19:preserved 11:20:preserved 12:21:preserved 13:9:preserved 14:10:preserved 15:11:preserved 16:12:preserved 17:13:preserved 18:14:preserved 19:15:preserved 20:16:preserved 21:22:preserved :17:bigrammar-others

We implemented a text classification system similar to the system presented in ( Nguyen et al. ,  2012 ) . 
We implemented a text classification system similar to the system presented in ( Nguyen et al. ,  2012 ) . 
193 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved

The difference is that we performed for document level , not for sentence level .
The difference is that we performed the task at the document level , instead of at the sentence level .
194 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6,7,8:paraphrase 7:10:preserved 8:11:preserved 9:12:preserved 10,11:13,14,15:paraphrase 12:17:preserved 13:18:preserved 14:19:preserved :9:mogrammar-det :16:mogrammar-det

Processing of the system is summarized as follows . 
The processing of the system is summarized as follows . 
195 0:1:preserved 1:2:preserved 2:3:preserved 3:4:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved :0:mogrammar-det

An input document is preprocessed with word segmentation and stop-word removals . 
An input document is preprocessed with word segmentation and stop-word removals . 
196 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved

Then , the document is represented in the form of a vector of weighted words appearing in the document . 
Then , the document is represented in the form of a vector of weighted words appearing in the document . 
197 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved

The weight is calculated using standard tf-idf product . 
The weight is calculated using standard tf-idf product . 
198 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved

An SVM-based classifier predicts the most probable topic for the vector , which also is the topic of the input document . 
An SVM-based classifier predicts the most probable topic for the vector , which also is the topic for the input document . 
199 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:bigrammar-prep 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved

In our experiment , for comparison of diﬀerent word segmentation criteria in topic classification , we only vary the word segmentation model used for this task , while fixing other configurations .
In our experiment , for comparison of diﬀerent word segmentation criteria in topic classification , we only vary the word segmentation model used for this task , while fixing other configurations .
200 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved

News articles of five topics : music , stock , entertainment , education , and fashion are used . 
News articles of five topics : music , stock , entertainment , education , and fashion are used . 
201 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved

The sizes of the training and test data sets are summarized in Table 8 .
The sizes of the training and test data sets are summarized in Table 8 .
202 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved

A phrase-based SMT system for English-Vietnamese translation was implemented . 
A phrase-based SMT system for English-Vietnamese translation was implemented . 
207 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved

In this system , we used SRILM  ( Stolcke , 2002 ) to build the language model , GIZA++ ( Och and  Ney , 2003 ) to train the word-aligned model , and Moses ( Holmqvist  et al. ,  2007 ) to train the phrase-based statistical translation model . 
In this system , we used SRILM  ( Stolcke , 2002 ) to build the language model , GIZA++ ( Och and  Ney , 2003 ) to train the word-aligned model , and Moses ( Holmqvist  et al. ,  2007 ) to train the phrase-based statistical translation model . 
208 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved 35:35:preserved 36:36:preserved 37:37:preserved 38:38:preserved 39:39:preserved 40:40:preserved 41:41:preserved 42:42:preserved 43:43:preserved 44:44:preserved 45:45:preserved 46:46:preserved 47:47:preserved 48:48:preserved

Translation results are evaluated using BLUE score ( Papineni  et al. ,  2002 ) . 
Translation results are evaluated using the BLUE score ( Papineni  et al. ,  2002 ) . 
209 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved :5:mogrammar-det

Both training and test data are word-segmented using the word segmentation models achieved . 
Both training and test data are word-segmented using the word segmentation models achieved . 
210 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved

For the experiment , we used the VCL_EVC bilingual corpus , 18000 pairs of sentences for training , and 1000 pairs for testing .
For the experiment , we used the VCL_EVC bilingual corpus , 18000 pairs of sentences for training , and 1000 pairs for testing .
211 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved

According  to  the  result  in  Table  9 ,  the  VAR_SPLIT  criterion  gives  the  highest  WS performance . 
According  to  the  result  in  Table  9 ,  the  VAR_SPLIT  criterion  gives  the  highest  WS performance . 
217 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved

Except for STRUCT_NC , all the modifications to the original VTB corpus increase the performance of WS . 
With the exception of STRUCT_NC , all of the modifications to the original VTB corpus increase the performance of WS . 
218 0,1:0,1,2,3:para-freeword 2:4:preserved 3:5:preserved 4:6:preserved 5:8:preserved 6:9:preserved 7:10:preserved 8:11:preserved 9:12:preserved 10:13:preserved 11:14:preserved 12:15:preserved 13:16:preserved 14:17:preserved 15:18:preserved 16:19:preserved 17:20:preserved :7:mogrammar-prep

However , the word segmentation criterion with higher performance is not necessarily a better criterion , but a criterion should also be judged through applications of word segmentation . 
However , the word segmentation criterion with higher performance is not necessarily a better criterion , but a criterion should also be judged through applications of word segmentation . 
219 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved

In both SMT and TC experiments , the BASE model , which is based on the manually-modified inconsistency of special characters , achieved better results than the ORG model . 
In both SMT and TC experiments , the BASE model , which is based on the manually-modified inconsistency of special characters , achieved better results than the ORG model . 
220 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved

In particular , in the TC experiment , the BASE model achieved 0.66 point higher than ORG , which is a significant improvement . 
In particular , in the TC experiment , the BASE model achieved 0.66 point higher than ORG , which is a significant improvement . 
221 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved

The results support the conclusion that the quality of word-segmentation corpus is very important for building NLP applications .
The results support the conclusion that the quality of the word-segmentation corpus is very important for building NLP applications .
222 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved :9:mogrammar-det

The SMT results show that three out of six augmented models , VAR_SPLIT , VAR_FREQ and BASE , gave higher performance than the ORG configuration . 
The SMT results show that three out of six augmented models , VAR_SPLIT , VAR_FREQ and BASE , performed better than the ORG configuration . 
223 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18,19,20:18,19:para-freeword 21:20:preserved 22:21:preserved 23:22:preserved 24:23:preserved 25:24:preserved

Among them , the best model VAR_SPLIT achieved 36.91 BLEU score , which is 0.55 higher than ORG . 
Among them , the best-performing model , VAR_SPLIT achieved 36.91 BLEU score , which is 0.55 higher than ORG . 
224 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:paraphrase 5:5:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved

In TC results , all six augmented models have higher results than ORG . 
In TC results , all six augmented models achieved higher results than ORG . 
225 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:paraphrase 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved

In general , the augmented models are better than the ORG . 
In general , the augmented models performed better than the ORG . 
226 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:paraphrase 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved

Additionally , because our automatic methods for inconsistency detection could not cover all types of inconsistency in word segmentation annotation , further improvement of corpus quality is demanded .
Additionally , because our automatic methods for inconsistency detection could not cover all of the types of inconsistencies in word segmentation annotation , further improvement of corpus quality is demanded .
227 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:15:preserved 14:16:preserved 15:17:bigrammar-nnum 16:18:preserved 17:19:preserved 18:20:preserved 19:21:preserved 20:22:preserved 21:23:preserved 22:24:preserved 23:25:preserved 24:26:preserved 25:27:preserved 26:28:preserved 27:29:preserved 28:30:preserved :13:mogrammar-prep :14:mogrammar-det

Comparing the results of STRUCT_AFFIX and STRUCT_NC with BASE in WS , TC , and SMT , we can observe that combining aﬃxes with their head nouns resulted in slightly better results for WS , TC , and does not change the performance of SMT . 
Comparing the results of STRUCT_AFFIX and STRUCT_NC with BASE in WS , TC , and SMT , we can observe that combining aﬃxes with their head nouns resulted in slightly better results for WS and TC , and did not change the performance of SMT . 
228 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:paraphrase 35:35:preserved 36:36:preserved 37:37:preserved 38:38:bigrammar-vtense 39:39:preserved 40:40:preserved 41:41:preserved 42:42:preserved 43:43:preserved 44:44:preserved 45:45:preserved

However , the combination of clasifier nouns with their head nouns had negative eﬀects on WS and SMT .
However , the combination of classifier nouns with their head nouns had negative eﬀects on WS and SMT .
229 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:typo 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved

Another intention of our experiment is to compare two solutions for controversial cases of word segmentation , splitting and combining . 
Another part of the scope of our experiment is to compare two solutions for controversial cases of word segmentation , splitting and combining . 
230 0:0:preserved 1:1,2,3,4:paraphrase 2:5:preserved 3:6:preserved 4:7:preserved 5:8:preserved 6:9:preserved 7:10:preserved 8:11:preserved 9:12:preserved 10:13:preserved 11:14:preserved 12:15:preserved 13:16:preserved 14:17:preserved 15:18:preserved 16:19:preserved 17:20:preserved 18:21:preserved 19:22:preserved 20:23:preserved

Splitting and combining variations are reflected by VAR_COMB and VAR_SPLIT , while STRUCT_AFFIX and STRUCT_NC represent the combination of affixes or classifier nouns with the words that they modify . 
Splitting and combining variations are reflected by VAR_COMB and VAR_SPLIT , while STRUCT_AFFIX and STRUCT_NC represent the combination of affixes or classifier nouns with the words that they modify . 
231 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved

STRUCT_AFFIX and STRUCT_NC are contrasted with BASE where aﬃxes and classifier nouns remain untouched . 
STRUCT_AFFIX and STRUCT_NC are contrasted with BASE where aﬃxes and classifier nouns remain untouched . 
232 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved

Comparing VAR_COMB and VAR_SPLIT in both TC experiment and SMT experiment , we see that the VAR_SPLIT results are better in both cases . 
Comparing VAR_COMB and VAR_SPLIT in both the TC experiment and SMT experiment , we see that the VAR_SPLIT results are better in both cases . 
233 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved :6:mogrammar-det

Since the ratio of combined variations in the ORG corpus is 60.9% , it can be observed that splitting seems to be better than combining for WS , TC and SMT .
Since the ratio of combined variations in the ORG corpus is 60.9% , it can be observed that splitting seems to be better than combining for WS , TC and SMT .
234 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved

In this paper , we have showed a quantitative analysis of the difficulties in word segmentation , through the detection of problematic cases in the Vietnamese treebank . 
In this paper , we have provided a quantitative analysis of the difficulties in word segmentation , through the detection of problematic cases in the Vietnamese Treebank . 
240 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:paraphrase 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:typo 27:27:preserved

Based on the analysis , we automatically created data representing the different word segmentation criteria , and evaluated the criteria indirectly through their applications .
Based on the analysis , we automatically created data that represent the different word segmentation criteria , and evaluated the criteria indirectly through their applications .
241 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9,10:bigrammar-wform 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved

Our experimental results showed that manual modification done for annotation of spe cial characters , and most of other word segmentation criteria , significantly improved the performances of automatic word segmentation , text classification and statistical machine translation , comparing with the use of the original VTB corpus . 
Our experimental results showed that manual modification , done for annotation of special characters , and most other word segmentation criteria , significantly improved the performances of automatic word segmentation , text classification and statistical machine translation , in comparison with the use of the original VTB corpus . 
242 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11,12:12:typo 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17::mogrammar-prep 18:17:preserved 19:18:preserved 20:19:preserved 21:20:preserved 22:21:preserved 23:22:preserved 24:23:preserved 25:24:preserved 26:25:preserved 27:26:preserved 28:27:preserved 29:28:preserved 30:29:preserved 31:30:preserved 32:31:preserved 33:32:preserved 34:33:preserved 35:34:preserved 36:35:preserved 37:36:preserved 38:37:preserved 39:39:bigrammar-wform 40:40:preserved 41:41:preserved 42:42:preserved 43:43:preserved 44:44:preserved 45:45:preserved 46:46:preserved 47:47:preserved 48:48:preserved :7:unaligned :38:mogrammar-prep

Since the VTB corpus is the first eﬀort in building a treebank for Vietnamese , and is the only corpus publicly available for NLP research , this study contributes to further improvement of the corpus quality , which is essential for building efficient NLP systems .
Since the VTB corpus is the first eﬀort in building a treebank for Vietnamese , and is the only corpus that is publicly available for NLP research , this study contributes to further improvement of the corpus quality , which is essential for building efficient NLP systems .
243 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:22,20,21:para-freeword 21:23:preserved 22:24:preserved 23:25:preserved 24:26:preserved 25:27:preserved 26:28:preserved 27:29:preserved 28:30:preserved 29:31:preserved 30:32:preserved 31:33:preserved 32:34:preserved 33:35:preserved 34:36:preserved 35:37:preserved 36:38:preserved 37:39:preserved 38:40:preserved 39:41:preserved 40:42:preserved 41:43:preserved 42:44:preserved 43:45:preserved 44:46:preserved 45:47:preserved

