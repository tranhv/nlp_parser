Unsupervised Face Annotation by Mining the Web
Unsupervised Face Annotation by Mining the Web
2 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved

Searching for images of people is an essential task for image and video search engines .
Searching for images of people is an essential task for image and video search engines .
5 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved

However , current search engines have limited capabilities for this task since they rely on text associated with images and video , and such text is likely to return many irrelevant results .
However , current search engines have limited capabilities for this task since they rely on text associated with images and video , and such text is likely to return many irrelevant results .
6 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved

We propose a method to retrieve relevant faces for one person by learning the visual consistency among results retrieved from text-correlation-based search engines .
We propose a method for retrieving relevant faces of one person by learning the visual consistency among results retrieved from text-correlation-based search engines .
7 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4,5:4,5:paraphrase 6:6:preserved 7:7:preserved 8:8:bigrammar-prep 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved

The method consists of two steps .
The method consists of two steps .
8 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved

In the first step , each candidate face obtained from a text-based search engine is ranked by a score that measures the distribution of visual similarities among the faces .
In the first step , each candidate face obtained from a text-based search engine is ranked with a score that measures the distribution of visual similarities among the faces .
9 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:bigrammar-prep 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved

Faces that are possibly very relevant or irrelevant are ranked at the top or bottom of the list .
Faces that are possibly very relevant or irrelevant are ranked at the top or bottom of the list , respectively .
10 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:20,19,18:paraphrase

The second step improves this ranking by treating this problem as a classification problem in which input faces are classified as 'person-$X$' or 'non-person-$X$' ; and the faces are re-ranked according to their relevant score inferred from the classifier 's probability output .
The second step improves this ranking by treating this problem as a classification problem in which input faces are classified as 'person-$X$' or 'non-person-$X$' ; and the faces are re-ranked according to their relevant score inferred from the classifier 's probability output .
11 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved 35:35:preserved 36:36:preserved 37:37:preserved 38:38:preserved 39:39:preserved 40:40:preserved 41:41:preserved 42:42:preserved

To train this classifier , we use a bagging-based framework to combine results from multiple weak classifiers trained using different subsets .
To train this classifier , we use a bagging-based framework to combine results from multiple weak classifiers trained using different subsets .
12 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved

These training subsets are extracted and labeled automatically from the rank list produced from the classifier trained from the previous step .
These training subsets are extracted and labeled automatically from the rank list produced from the classifier trained from the previous step .
13 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved

In this way , the accuracy of the ranked list increases after a number of iterations .
In this way , the accuracy of the ranked list increases after a number of iterations .
14 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved

Experimental results on various face sets retrieved from captions of news photos show that the retrieval performance improved after each iteration , with the final performance being higher than those of the existing algorithms .
Experimental results on various face sets retrieved from captions of news photos show that the retrieval performance improved after each iteration , with the final performance being higher than those of the existing algorithms .
15 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved

With the rapid growth of digital technology , large image and video databases have become more available than ever to users .
With the rapid growth of digital technology , large image and video databases have become more available than ever to users .
19 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved

This trend has shown the need for effective and efficient tools for indexing and retrieving based on visual content .
This trend has shown the need for effective and efficient tools for indexing and retrieving visual content .
20 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 17:15:preserved 18:16:preserved 19:17:preserved

A typical application is searching for a specific person by providing his or her name .
A typical application is searching for a specific person by providing his or her name .
21 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved

Most current search engines use the text associated with images and video as significant clues for returning results .
Most current search engines use the text associated with images and video as significant clues for returning results .
22 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved

However , other un-queried faces and names may appear with the queried ones ( as shown in Figure xx ) , and this significantly lowers retrieval performance .
However , other un-queried faces and names may appear with the queried ones ( Figure xx ) , and this significantly lowers the retrieval performance .
23 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 17:14:preserved 18:15:preserved 19:16:preserved 20:17:preserved 21:18:preserved 22:19:preserved 23:20:preserved 24:21:preserved 25:23:preserved 26:24:preserved 27:25:preserved :22:mogrammar-det

One way to improve the retrieval performance is to take into account visual information present in the retrieved faces .
One way to improve the retrieval performance is to take into account visual information present in the retrieved faces .
24 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved

This task is challenging for the following reasons :
This task is challenging for the following reasons :
25 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved

-Large variations in facial appearance due to pose changes , illumination conditions , occlusions and facial expressions make face recognition difficult even with state-of-the-art techniques\CITE ( see an example in Figure xx ) .
-Large variations in facial appearance due to pose changes , illumination conditions , occlusions , and facial expressions make face recognition difficult even with state-of-the-art techniques\CITE ( see example in Figure xx ) .
28 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:26:preserved 26:27:preserved 27::mogrammar-det 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved

-The fact that the retrieved face set consists of faces of several people with no labels makes supervised and unsupervised learning methods inapplicable .
-The fact that the retrieved face set consists of faces of several people with no labels makes supervised and unsupervised learning methods inapplicable .
31 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved

We propose a method to solve the above problem .
We propose a method for solving the above problem .
34 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4,5:4,5:paraphrase 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved

The main idea is to assume that there is visual consistency among the results returned from text-based search engines ; and then learn this visual consistency through an interactive process .
The main idea is the assumption that there is visual consistency among the results returned from text-based search engines and this visual consistency is then learned through an interactive process .
35 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4,5:4,5:paraphrase 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 20:19:preserved 21:24:preserved 22:25,23:para-passact 23:20:preserved 24:21:preserved 25:22:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved

This method consists of two stages .
This method consists of two stages .
36 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved

In the first stage , we explore the local density of faces to identify potential candidates for relevant faces and irrelevant faces .
In the first stage , we explore the local density of faces to identify potential candidates for relevant faces and irrelevant faces .
37 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved

This stage reflects the fact that the facial images of the queried person tend to form dense clusters , whereas irrelevant facial images are sparse since they look different from each other .
This stage reflects the fact that the facial images of the queried person tend to form dense clusters , whereas irrelevant facial images are sparse since they look different from each other .
38 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved

For each face , we define a score to measure the density of its neighbor set .
For each face , we define a score to measure the density of its neighbor set .
39 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved

This score is used to form a ranked list , in which faces having high density scores are considered relevant and are put at the top of the list .
This score is used to form a ranked list , in which faces with high-density scores are considered relevant and are put at the top .
40 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:paraphrase 14,15:14:typo 16:15:preserved 17:16:preserved 18:17:preserved 19:18:preserved 20:19:preserved 21:20:preserved 22:21:preserved 23:22:preserved 24:23:preserved 25:24:preserved

The above ranking method is weak since dense clusters have no guarantee of containing relevant faces .
The above ranking method is weak since dense clusters have no guarantee of containing relevant faces .
43 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved

Therefore , a second stage is necessary to improve this ranked list .
Therefore , a second stage is necessary to improve this ranked list .
44 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved

We model this problem as a classification problem in which input faces are classified as person-\MATH ( the queried person ) or non-person-\MATH ( the un-queried person ) .
We model this problem as a classification problem in which input faces are classified as person-\MATH ( the queried person ) or non-person-\MATH ( the un-queried person ) .
45 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved

The faces are ranked according to a relevancy score that is inferred from the classifier 's probability output .
The faces are ranked according to a relevancy score that is inferred from the classifier 's probability output .
46 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved

Since annotation data is not available , the rank list from the previous step is used to assign labels for a subset of faces .
Since annotation data is not available , the rank list from the previous step is used to assign labels for a subset of faces .
47 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved

This subset is then used to train a classifier using supervised methods such as support vector machine ( SVM ) .
This subset is then used to train a classifier using supervised methods such as a support vector machine ( SVM ) .
48 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved :14:mogrammar-det

The trained classifier is used to re-rank faces in the original input set .
The trained classifier is used to re-rank faces in the original input set .
49 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved

This step is repeated a number of times to get the final ranked list .
This step is repeated a number of times to get the final ranked list .
50 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved

Since automatically assigning labels from the ranked list is not reliable , the trained classifiers are weak .
Since automatically assigning labels from the ranked list is not reliable , the trained classifiers are weak .
51 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved

To get the final strong classifier , we use the idea of ensemble learning \CITE in which weak classifiers trained on different subsets are combined to improve the stability and classification accuracy of single classifiers .
To obtain the final strong classifier , we use the [idea / concept?] of ensemble learning \CITE in which weak classifiers trained on different subsets are combined to improve the stability and classification accuracy of single classifiers .
52 0:0:preserved 1:1:paraphrase 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10,12,11:preserved 11:13:preserved 12:14:preserved 13:15:preserved 14:16:preserved 15:17:preserved 16:18:preserved 17:19:preserved 18:20:preserved 19:21:preserved 20:22:preserved 21:23:preserved 22:24:preserved 23:25:preserved 24:26:preserved 25:27:preserved 26:28:preserved 27:29:preserved 28:30:preserved 29:31:preserved 30:32:preserved 31:33:preserved 32:34:preserved 33:35:preserved 34:36:preserved 35:37:preserved

The learned classifier can be further used for recognizing new facial images of the queried person .
The learned classifier can be further used for recognizing new facial images of the queried person .
53 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved

The second stage improves the ranked list and recognition performance for the following reasons :
The second stage improves the ranked list and recognition performance for the following reasons :
56 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved

-Supervised learning methods , such as SVM , provide a strong theoretical background for finding the optimal decision boundary even with noisy data .
-Supervised learning methods , such as an SVM , provide a strong theoretical background for finding the optimal decision boundary even with noisy data .
59 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved :6:mogrammar-det

Furthermore , recent studies \CITE suggest that SVM classifiers provide probability outputs that are suitable for ranking .
Furthermore , recent studies \CITE suggest that SVM classifiers provide probability outputs that are suitable for ranking .
60 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved

-The bagging framework helps to leverage noises in the unsupervised labeling process .
-The bagging framework helps to leverage noises in the unsupervised labeling process .
63 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved

Our contribution is two-fold :
Our contribution is two-fold :
66 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved

-We propose a general framework to boost the face retrieval performance of text-based search engines by visual consistency learning .
-We propose a general framework to boost the face retrieval performance of text-based search engines by visual consistency learning .
69 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved

The framework seamlessly integrates data mining techniques such as supervised learning , and unsupervised learning based on bagging .
The framework seamlessly integrates data mining techniques such as supervised learning and unsupervised learning based on bagging .
72 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 12:11:preserved 13:12:preserved 14:13:preserved 15:14:preserved 16:15:preserved 17:16:preserved 18:17:preserved

-Our framework requires only a few parameters and works stably .
-Our framework requires only a few parameters and works stably .
75 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved

We demonstrate its feasibility of a practical web mining application .
We demonstrate its feasibility with a practical web mining application .
78 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:bigrammar-prep 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved

A comprehensive evaluation on a large face dataset of many people was carried out and it confirmed that our approach is promising .
A comprehensive evaluation on a large face dataset of many people was carried out and confirmed that our approach is promising .
81 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 16:15:preserved 17:16:preserved 18:17:preserved 19:18:preserved 20:19:preserved 21:20:preserved 22:21:preserved

There are several approaches for re-ranking and learning models from web images .
There are several approaches for re-ranking and learning models from web images .
86 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved

Their underlying assumption is that text-based search engines return a large fraction of relevant images .
Their underlying assumption is that text-based search engines return a large fraction of relevant images .
87 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved

The challenge is how to model what is common in the relevant images .
The challenge is how to model what is common in the relevant images .
88 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved

One approach is to model this problem in a probabilistic framework in which the returned images are used to learn the parameters of the model .
One approach is to model this problem in a probabilistic framework in which the returned images are used to learn the parameters of the model .
89 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved

For examples , as described in \CITE , [Reference numbers generally should not be grammatically part of the sentence .
For examples , as described by Fergus et al. \CITE , [Reference numbers generally should not be grammatically part of the sentence .
90 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:bigrammar-prep 6:9,6,7,8:paraphrase 7:10:preserved 8:11:preserved 9:12:preserved 10:13:preserved 11:14:preserved 12:15:preserved 13:16:preserved 14:17:preserved 15:18:preserved 16:19:preserved 17:20:preserved 18:21:preserved 19:22:preserved

It is better to use the authors�f names .]objects retrieved by an image search engine are re-ranked by extending the constellation model .
It is better to use the authors�f names .] objects retrieved using an image search engine are re-ranked by extending the constellation model .
91 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8,9:preserved 9:10:preserved 10:11:paraphrase 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved

Another proposal , described in \CITE , uses a non-parametric graphical model and an interactive framework to simultaneously learn object class models and collect object class datasets .
Another proposal , described in \CITE , uses a non-parametric graphical model and an interactive framework to simultaneously learn object class models and collect object class datasets .
92 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved

The main contribution of these approaches are probabilistic models that can be learned with a small number of training images .
The main contribution of these approaches is probabilistic models that can be learned with a small number of training images .
93 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:bigrammar-inter 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved

However , these models are complicated , since they require several hundred parameters for learning , and they are susceptible to over-fitting .
However , these models are complicated since they require several hundred parameters for learning and are susceptible to over-fitting .
94 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 7:6:preserved 8:7:preserved 9:8:preserved 10:9:preserved 11:10:preserved 12:11:preserved 13:12:preserved 14:13:preserved 16:14:preserved 18:15:preserved 19:16:preserved 20:17:preserved 21:18:preserved 22:19:preserved

Furthermore , to obtain robust models , a small amount of supervision is required to select seed images .
Furthermore , to obtain robust models , a small amount of supervision is required to select seed images .
95 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved

Another study \CITE proposed a clustering-based method for associating names and faces in news photos .
Another study \CITE proposed a clustering-based method for associating names and faces in news photos .
98 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved

To solve the problem of ambiguity between several names and one face , a modified \MATH-means clustering process was used in which faces are assigned to the closest cluster ( each cluster corresponding to one name ) after a number of iterations .
To solve the problem of ambiguity between several names and one face , a modified \MATH-means clustering process was used in which faces are assigned to the closest cluster ( each cluster corresponding to one name ) after a number of iterations .
99 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved 35:35:preserved 36:36:preserved 37:37:preserved 38:38:preserved 39:39:preserved 40:40:preserved 41:41:preserved 42:42:preserved

Although the result was impressive , it is not easy to apply it to our problem since it is based on a strong assumption that requires a perfect alignment in the case that the news photo only has one face and its caption only has one name .
Although the result was impressive , it is not easy to apply it to our problem since it is based on a strong assumption that requires a perfect alignment when a news photo only has one face and its caption only has one name .
100 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29,30,31,32,33:29:paraphrase 34:31:preserved 35:32:preserved 36:33:preserved 37:34:preserved 38:35:preserved 39:36:preserved 40:37:preserved 41:38:preserved 42:39:preserved 43:40:preserved 44:41:preserved 45:42:preserved 46:43:preserved 47:44:preserved :30:mogrammar-det

Furthermore , a large number of irrelevant faces ( more than 12\% ) have to be manually eliminated before clustering .
Furthermore , a large number of irrelevant faces ( more than 12\% ) have to be manually eliminated before clustering .
101 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved

A graph-based approach was proposed by \CITE , in which a graph is formed by faces as nodes , and the weights of edges linked between nodes are the similarity of faces , is closely related to our problem .
A graph-based approach was proposed by Ozkan and Duygu \CITE , in which a graph is formed from faces as nodes , and the weights of edges linked between nodes are the similarity of faces , is closely related to our problem .
104 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:9,6,7,8:paraphrase 7:10:preserved 8:11:preserved 9:12:preserved 10:13:preserved 11:14:preserved 12:15:preserved 13:16:preserved 14:17:bigrammar-prep 15:18:preserved 16:19:preserved 17:20:preserved 18:21:preserved 19:22:preserved 20:23:preserved 21:24:preserved 22:25:preserved 23:26:preserved 24:27:preserved 25:28:preserved 26:29:preserved 27:30:preserved 28:31:preserved 29:32:preserved 30:33:preserved 31:34:preserved 32:35:preserved 33:36:preserved 34:37:preserved 35:38:preserved 36:39:preserved 37:40:preserved 38:41:preserved 39:42:preserved

Assuming that the number of faces of the queried person is larger than that of others and that these faces tend to form the most similar subset among the set of retrieved faces , this problem is considered equal to the problem of finding the densest subgraph of a full graph ; and therefore can be solved by taking an available solution .[It might be unclear as to what " available solution " you are talking about .
Assuming that the number of faces of the queried person is larger than that of others and that these faces tend to form the most similar subset among the set of retrieved faces , this problem is considered equal to the problem of finding the densest subgraph of a full graph ; and can therefore , be solved by taking an available solution . //It might be unclear as to what " available solution " you are talking about . You might want to give more detail here .
105 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved 35:35:preserved 36:36:preserved 37:37:preserved 38:38:preserved 39:39:preserved 40:40:preserved 41:41:preserved 42:42:preserved 43:43:preserved 44:44:preserved 45:45:preserved 46:46:preserved 47:47:preserved 48:48:preserved 49:49:preserved 50:50:preserved 51:51:preserved 52:52:preserved 53:54:preserved 54:53:preserved 55:56:preserved 56:57:preserved 57:58:preserved 58:59:preserved 59:60:preserved 60:61:preserved 61:62:preserved 62:64,63:preserved 63:65:preserved 64:66:preserved 65:67:preserved 66:68:preserved 67:69:preserved 68:70:preserved 69:71:preserved 70:72:preserved 71:73:preserved 72:74:preserved 73:75:preserved 74:76:preserved 75:77:preserved 76:78:preserved 77:79:preserved

You might want to give more detail here .] Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person and it is easy to extend for the ranking problem .
Although experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of the relevant faces of the queried person and it is easy to extend for the ranking problem .
106 9:0:preserved 10::unaligned 11:1:preserved 12:2:preserved 13:3:preserved 14:4:preserved 15:5:preserved 16:6:preserved 17:7:preserved 18:8:preserved 19:9:preserved 20:10:preserved 21:11:preserved 22:12:preserved 23:13:preserved 24:14:preserved 25:15:preserved 26:16:preserved 27:17:preserved 28:18:preserved 29:19:preserved 30:20:preserved 31:21:preserved 32:23:preserved 33:24:preserved 34:25:preserved 35:36:preserved 36:27:preserved 37:28:preserved 38:29:preserved 39:30:preserved 40:31:preserved 41:32:preserved 42:33:preserved 43:34:preserved 44:35:preserved 46:37:preserved 47:38:preserved :22:mogrammar-det :26:mogrammar-det

Furthermore , choosing an optimal threshold to convert the initial graph into a binary graph is difficult and rather ad hoc due to the curse of dimensionality .
Furthermore , choosing an optimal threshold to convert the initial graph into a binary one is difficult and rather ad hoc due to dimensionality .
107 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:paraphrase 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 26:23:preserved 27:24:preserved

The good point of the methods \CITE is they are fully unsupervised .
An advantage of these methods \CITE is they are fully unsupervised .
110 0:0:bigrammar-det 1,2:1:paraphrase 3:2:preserved 4:3:bigrammar-det 5:4:preserved 6:5:preserved 7:6:preserved 8:7:preserved 9:8:preserved 10:9:preserved 11:10:preserved 12:11:preserved

However , the bad point is no model is learned to predict new images of the same category .
However , a disadvantage is that no model is learned for predicting new images of the same category .
111 0:0:preserved 1:1:preserved 2:2:bigrammar-det 3,4:3:paraphrase 5:4,5:para-freeword 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10,11:10,11:paraphrase 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved

Furthermore , they perform hard categorization on input images that is [It is not clear if " hard categorization " is inapplicable or if the " input images " are inapplicable .]in applicable for re-ranking .
Furthermore , they are used for performing hard categorization on input images that are inapplicable for re-ranking . //It is not clear if " hard categorization " is inapplicable or if the " input images " are inapplicable .
112 0:0:preserved 1:1:preserved 2:2:preserved 3:3,4,5,6:paraphrase 4:7:preserved 5:8:preserved 6:9:preserved 7:10:preserved 8:11:preserved 9:12:preserved 11:18:preserved 12:19:preserved 13:20:preserved 14:21:preserved 15:22:preserved 16:23:preserved 17:24:preserved 18:25:preserved 19:26:preserved 20:27:preserved 21:28:preserved 22:29:preserved 23:30:preserved 24:31:preserved 25:32:preserved 26:33:preserved 27:34:preserved 28:35:preserved 29:36:preserved 30:37:preserved 31,32:13,14:paraphrase 33:15:preserved 34:16:preserved 35:38:preserved

The balance of recall and precision was not addressed .
The balance of recall and precision was not addressed .
113 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved

Typically , these approaches tend to ignore the recall to obtain high precision .
Typically , these approaches tend to ignore the recall to obtain high precision .
114 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved

This leads the number of collected images is reduced .
This leads to the reduction in the number of collected images .
115 0:0:preserved 1:1:preserved 2:6:preserved 6,5,4,3:10,9,8,7:preserved 8,7:2,3,4,5:paraphrase 9:11:preserved

Our approach combines a number of advances over the existing approaches .
Our approach combines a number of advances over the existing approaches .
118 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved

Specifically , we learn a model for each query from the returned images for purposes such as re-ranking and predicting new images .
Specifically , we learn a model for each query from the returned images for purposes such as re-ranking and predicting new images .
119 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved

However , different from the methods in \cite{xx} , we used an unsupervised method to select training samples automaticallyCITE .
However , we used an unsupervised method to select training samples automatically , which is different from the methods proposed by Fergus et al. and Li et al. \CITE .
120 0:0:preserved 1:12,13,14,1:paraphrase 2:15:preserved 3:16:preserved 4:17:preserved 5:18:preserved 6,7:19,20,21,22,23,24,25,26,27,28:paraphrase 9:2:preserved 10:3:preserved 11:4:preserved 12:5:preserved 13:6:preserved 14:7:preserved 15:8:preserved 16:9:preserved 17:10:preserved 18:11:preserved

This unsupervised method is different from the one in \CITE in its way of modeling the distribution of relevant images .
This unsupervised method is different from the one by Ozkan and Dugyu \CITE in the modeling of the distribution of relevant images .
121 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:bigrammar-prep 9:12,11,9,10:paraphrase 10:13:preserved 11,12,13,14:14,15,16:paraphrase 15:17:preserved 16:18:preserved 17:19:preserved 18:20:preserved 19:21:preserved 20:22:preserved

We use density-based estimation rather than the densest graph .
We use density-based estimation rather than the densest graph .
122 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved

Given a set of images returned by any text-based search engine for a queried person ( e.g. 'George Bush' ) , we perform a ranking process and learning of person |\MATH 's model as follows :
Given a set of images returned by any text-based search engine for a queried person ( e.g. 'George Bush' ) , we perform a ranking process and learning of person |\MATH 's model as follows :
127 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved 35:35:preserved

-Step 1 : Detect faces and eye positions , and then perform face normalizations .
-Step 1 : Detect faces and eye positions , and then perform face normalizations .
130 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved

-Step 2 : Compute an eigenface space and project the input faces into this subspace .
-Step 2 : Compute an eigenface space and project the input faces into this subspace .
133 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved

-Step 3 : Estimate the ranked list of these faces by Rank-By-Local-Density-Score .
-Step 3 : Estimate the ranked list of these faces by rank-by-local-density score .
136 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11,12:typo 12:13:preserved

-Step 4 : Improve this ranked list by Rank-By-Bagging-ProbSVM . //I found not hits for " rank-by-bagging-probSVM " on the Internet . You might want to double check to see if this is a standard term . The same is true for " rank-by-local-density score " . If this is your own term , you might want to specify this at some point .
-Step 4 : Improve this ranked list using rank-by-bagging-probSVM . //I found not hits for " rank-by-bagging-probSVM " on the Internet. You might want to double check to see if this is a standard term . The same is true for " rank-by-local-density score " . If this is your own term , you might want to specify this at some point .
139 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:paraphrase 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 22:21:preserved 23:22:preserved 24:23:preserved 25:24:preserved 26:25:preserved 27:26:preserved 28:27:preserved 29:28:preserved 30:29:preserved 31:30:preserved 32:31:preserved 33:32:preserved 34:33:preserved 35:34:preserved 36:35:preserved 37:36:preserved 38:37:preserved 39:38:preserved 40:39:preserved 41:40:preserved 42:41:preserved 43:42:preserved 44:43:preserved 45:44:preserved 46:45:preserved 47:46:preserved 48:47:preserved 49:48:preserved 50:49:preserved 51:50:preserved 52:51:preserved 53:52:preserved 54:53:preserved 55:54:preserved 56:55:preserved 57:56:preserved 58:57:preserved 59:58:preserved 60:59:preserved 61:60:preserved 62:61:preserved 63:62:preserved

Steps 1 and 2 are typical for any face processing system , and they are described in section \REF .
Steps 1 and 2 are typical for any face processing system , and they are described in section \REF .
142 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved

The algorithms used in Step 3 and Step 4 are described in section \REF and section \REF .
The algorithms used in Steps 3 and 4 are described in section \REF and section \REF , respectively .
143 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4,7:4:paraphrase 5:5:preserved 6:6:preserved 8:7:preserved 9:8:preserved 10:9:preserved 11:10:preserved 12:11:preserved 13:12:preserved 14:13:preserved 15:14:preserved 16:15:preserved 17:17,16,18:paraphrase

Figure \REF illustrates the proposed framework .
Figure \REF illustrates the proposed framework .
144 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved

Among the faces retrieved by the text-based search engines for a query of person-\MATH , as shown in Figure \REF , relevant faces usually look similar and can form the largest cluster .
Among the faces retrieved by text-based search engines for a query of person-\MATH , as shown in Figure \REF , relevant faces usually look similar and forms the largest cluster .
149 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5::mogrammar-det 6:5:preserved 7:6:preserved 8:7:preserved 9:8:preserved 10:9:preserved 11:10:preserved 12:11:preserved 13:12:preserved 14:13:preserved 15:14:preserved 16:15:preserved 17:16:preserved 18:17:preserved 19:18:preserved 20:19:preserved 21:20:preserved 22:21:preserved 23:22:preserved 24:23:preserved 25:24:preserved 26:25:preserved 27,28:26:bigrammar-vtense 29:27:preserved 30:28:preserved 31:29:preserved 32:30:preserved

One approach to re-rank these faces is to do clustering based on visual similarity .
One approach of re-ranking these faces is to cluster based on visual similarity .
150 0:0:preserved 1:1:preserved 2,3:3,2:paraphrase 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8,9:8:paraphrase 10:9:preserved 11:10:preserved 12:11:preserved 13:12:preserved 14:13:preserved

However , to get ideal clustering result is impossible , since these faces are high dimensional data and the clusters are in different shapes , sizes and densities .
However , to obtain ideal clustering results is impossible since these faces are high dimensional data and the clusters are in different shapes , sizes , and densities .
151 0:0:preserved 1:1:preserved 2:2:preserved 3:3:paraphrase 4:4:preserved 5:5:preserved 6:6:bigrammar-nnum 7:7:preserved 8:8:preserved 10:9:preserved 11:10:preserved 12:11:preserved 13:12:preserved 14:13:preserved 15:14:preserved 16:15:preserved 17:16:preserved 18:17:preserved 19:18:preserved 20:19:preserved 21:20:preserved 22:21:preserved 23:22:preserved 24:23:preserved 25:24:preserved 26:26:preserved 27:27:preserved 28:28:preserved

Instead , in \cite{xx} , a graph based approach was proposed CITEin which the nodes are faces and edge weights are the similarities between two faces .
Instead , a graph-based approach was proposed by Ozkan and Dugyu \CITE in which the nodes are faces and edge weights are the similarities between two faces .
152 0:0:preserved 1:1:preserved 3::unaligned 5:2:preserved 6,7:3:typo 8,9,10:4,5,6:preserved 11:12,11,10,7,8,9:paraphrase 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:26:preserved 26:27:preserved

With the observation that the nodes ( faces ) of the queried person are similar to each other and different from other nodes in the graph , the densest component of the full graph ? the set of highly connected nodes in the graph ? will correspond to the face of the queried person .
With the observation that the nodes ( faces ) of the queried person are similar to each other and different from other nodes in the graph , the densest component of the full graph ? the set of highly connected nodes in the graph ? will correspond to the face of the queried person .
153 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved 35:35:preserved 36:36:preserved 37:37:preserved 38:38:preserved 39:39:preserved 40:40:preserved 41:41:preserved 42:42:preserved 43:43:preserved 44:44:preserved 45:45:preserved 46:46:preserved 47:47:preserved 48:48:preserved 49:49:preserved 50:50:preserved 51:51:preserved 52:52:preserved 53:53:preserved 54:54:preserved

The main drawback of this approach is it needs a threshold to convert the initial weighted graph to a binary graph .
The main drawback of this approach is it needs a threshold to convert the initial weighted graph to a binary graph .
154 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved

Choosing this threshold in high dimensional spaces is difficult since different persons might have different optimal thresholds .
Choosing this threshold in high dimensional spaces is difficult since different persons might have different optimal thresholds .
155 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved

We use the idea of density-based clustering described in \CITE to solve this problem .
We use the idea of density-based clustering described by Ester et al. and Breunig et al. \CITE to solve this problem . //idea / concept?
158 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:bigrammar-prep 9:16,11,12,13,14,15,9,10:paraphrase 10,11,12,13:17,18,20,19:preserved

Specifically , we define local density score ( LDS ) of a point \MATH( i.e. a face ) as the average distance to its k-nearest neighbors :
Specifically , we define the local density score ( LDS ) of a point \MATH( i.e. a face ) as the average distance to its k-nearest neighbors .
159 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:26:preserved :4:mogrammar-det

where \MATH is the set of \MATH - neighbors of \MATH , and \MATH is the similarity between \MATH and \MATH .
where \MATH is the set of \MATH - neighbors of \MATH , and \MATH is the similarity between \MATH and \MATH .
162 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved

Since faces are represented in high dimensional feature space , and face clusters might have different sizes , shapes and densities ; we do not use directly the Euclidean distance between two points in this feature space for \MATH .
Since faces are represented in high dimensional feature space , and face clusters might have different sizes , shapes , and densities , we do not directly use the Euclidean distance between two points in this feature space for \MATH .
165 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:20:preserved 20:21:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:27:preserved 26:26:preserved 27:28:preserved 28:29:preserved 29:30:preserved 30:31:preserved 31:32:preserved 32:33:preserved 33:34:preserved 34:35:preserved 35:36:preserved 36:37:preserved 37:38:preserved 38:39:preserved 39:40:preserved

Instead , we use another similarity measure defined by the number of shared neighbors between two points .
Instead , we use another similarity measure defined by the number of shared neighbors between two points .
166 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved

The efficiency of this similarity measure for density-based clustering methods was described . //There is no period here , so it is not clear if there should be a period or there should be more to this sentence that is not here . If the sentence does end here , you might want to go into more detail about who or what " described " this .]
The efficiency of this similarity measure for density-based clustering methods was described . //There is no period here , so it is not clear if there should be a period or there should be more to this sentence that is not here . If the sentence does end here , you might want to go into more detail about who or what " described " this .
167 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved 35:35:preserved 36:36:preserved 37:37:preserved 38:38:preserved 39:39:preserved 40:40:preserved 41:41:preserved 42:42:preserved 43:43:preserved 44:44:preserved 45:45:preserved 46:46:preserved 47:47:preserved 48:48:preserved 49:49:preserved 50:50:preserved 51:51:preserved 52:52:preserved 53:53:preserved 54:54:preserved 55:55:preserved 56:56:preserved 57:57:preserved 58:58:preserved 59:59:preserved 60:60:preserved 61:61:preserved 62:62:preserved 63:63:preserved 64:64:preserved 65:65:preserved

A high value of \MATH indicates a strong association between \MATH and its neighbors .
A high value of \MATH indicates a strong association between \MATH and its neighbors .
170 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved

Therefore , we can use this local density score to rank faces .
Therefore , we can use this local density score to rank faces .
171 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved

Faces with higher scores are considered to be potential candidates that are relevant to person-\MATH , while faces with lower scores are considered as outliers and thus are potential candidates for non-person-\MATH .
Faces with higher scores are considered to be potential candidates that are relevant to person-\MATH , while faces with lower scores are considered as outliers and thus are potential candidates for non-person-\MATH .
172 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved

Algorithm 1 : Rank-By-Local-Density-Score Step 1 : For each face p , compute LDS( p , k ) , where k is the number of neighbors of p and is the input of the ranking process .
Algorithm 1 : Rank-By-Local-Density-Score Step 1 : For each face p , compute LDS( p , k ) , where k is the number of neighbors of p and is the input of the ranking process .
175 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved 35:35:preserved 36:36:preserved

Step 2 : Rank these faces using LDS( p , k ) ( The higher the more relevant ) .
Step 2 : Rank these faces using LDS( p , k ) ( The higher the score the more relevant ) .
176 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:18,17,16:paraphrase 17:19:preserved 18:20:preserved 19:21:preserved

One limitation of the local density score based ranking is it could not handle the case that faces of another person have strong association in \MATH-neighbor set ( for example , many duplicates ) .
One limitation of the local density score based ranking is it cannot handle faces of another person strongly associated in the \MATH-neighbor set ( for example , many duplicates ) .
181 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11,12,13:11,12:bigrammar-vtense 17,18,19,20:13,14,15,16:preserved 21,22,23:17,18:paraphrase 24:19:preserved 25,26:21,22:preserved 27,28,29,30,31,32,33:23,24,25,26,27,28,29:preserved :20:mogrammar-det

Therefore , another step is proposed to handle this case .
Therefore , another step is proposed for handling this case .
182 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6,7:6,7:paraphrase 8:8:preserved 9:9:preserved 10:10:preserved

As a result , we have a model that can be used for both re-ranking current faces and predicting new incoming faces .
As a result , we have a model that can be used for both re-ranking current faces and predicting new incoming faces .
183 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved

The main idea is to use a probabilistic model to measure the relevancy of a face to person-\MATH , \MATH .
The main idea is to use a probabilistic model to measure the relevancy of a face to person-\MATH , \MATH .
187 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved

Since the labels are not available for training , we use the input rank list found from the previous step to extract a subset of faces lying at the top and bottom of the ranked list to form the training set .
Since the labels are not available for training , we use the input rank list found from the previous step to extract a subset of faces lying at the top and bottom of the ranked list to form the training set .
188 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved 35:35:preserved 36:36:preserved 37:37:preserved 38:38:preserved 39:39:preserved 40:40:preserved 41:41:preserved

After that , we use SVM with probabilistic output \CITE implemented in LibSVM \CITE to learn the person-\MATH model .
After that , we use an SVM with probabilistic output \CITE implemented in LibSVM \CITE to learn the person-\MATH model .
189 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved :5:mogrammar-det

This model is applied to faces of the original set and the output probabilistic scores are used to re-rank these faces .
This model is applied to faces of the original set , and the output probabilistic scores are used to re-rank these faces .
190 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved

Since it is not guaranteed that faces lying at two ends of the input rank list correctly correspond to the faces of person-\MATH and faces of non person-\MATH , we adopt the idea of bagging framework \CITE in which randomly selecting subsets to train weak classifiers , and then combining these classifiers help reduce the risk of using noisy training sets .
Since it is not guaranteed that faces lying at two ends of the input rank list correctly correspond to the faces of person-\MATH and faces of non person-\MATH , we adopt the [idea / concept?] of a bagging framework \CITE in which randomly selecting subsets to train weak classifiers , and then combining these classifiers help reduce the risk of using noisy training sets .
191 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 33:35:preserved 34:37:preserved 35:38:preserved 36:39:preserved 37:40:preserved 38:41:preserved 39:42:preserved 40:43:preserved 41:44:preserved 42:45:preserved 43:46:preserved 44:47:preserved 45:48:preserved 46:49:preserved 47:50:preserved 48:51:preserved 49:52:preserved 50:53:preserved 51:54:preserved 52:55:preserved 53:56:preserved 54:57:preserved 55:58:preserved 56:59:preserved 57:60:preserved 58:61:preserved 59:62:preserved 60:63:preserved 61:64:preserved

The details of Rank-By-Bagging-ProbSVM-InnerLoop method , improving an input rank list by combining weak classifiers trained from subsets annotated by that rank list are described in Algorithm 2 .
The details of the Rank-By-Bagging-ProbSVM-InnerLoop method , improving an input rank list by combining weak classifiers trained from subsets annotated by that rank list , are described in Algorithm 2 .
194 0:0:preserved 1:1:preserved 2:2:preserved 3:4:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:25:preserved 24:26:preserved 25:27:preserved 26:28:preserved 27:29:preserved 28:30:preserved :3:mogrammar-det

Step 1 : Train a weak classifier hi .
Step 1 : Train a weak classifier , hi .
199 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:8:preserved 8:9:preserved

Step 1 .1 : Select a set Spos including p% top ranked faces and then randomly select a subset S?pos from Spos .
Step 1 .1 : Select a set Spos including p% of top ranked faces and then randomly select a subset S?pos from Spos .
202 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved :10:mogrammar-prep

Label faces in S?pos as positive samples .
Label faces in S?pos as positive samples .
205 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved

Step 1 .2 : Select a set Sneg including p% bottom ranked faces and then randomly select a subset S? neg from Sneg .
Step 1 .2 : Select a set Sneg including p% of bottom ranked faces and then randomly select a subset S? neg from Sneg .
208 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved :10:mogrammar-prep

Label faces in S? neg as negative samples .
Label faces in S? neg as negative samples .
211 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved

Step 1 .3 : Use S?pos and S? neg to train a weak classifier hj using LibSVM [8] with probability outputs .
Step 1 .3 : Use S?pos and S? neg to train a weak classifier , hj , using LibSVM [8] with probability outputs .
214 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:15:preserved 15:17:preserved 16:18:preserved 17:19:preserved 18:20:preserved 19:21:preserved 20:22:preserved 21:23:preserved

Step 2 : Compute ensemble classifier Hi = Pij=1 hj .
Step 2 : Compute ensemble classifier Hi = Pij=1 hj .
217 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved

Step 3 : Apply Hi to the original face set and form the rank list Ranki by using the output probabilistic scores .
Step 3 : Apply Hi to the original face set and form the rank list , Ranki , using the output probabilistic scores .
220 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:16:preserved 16::mogrammar-prep 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved

Step 4 : Repeat steps from Step 1 to Step 3 until Dist2RankList( Ranki?1 ,Ranki ) <= ? .
Step 4 : Repeat steps 1 to 3 until Dist2RankList( Ranki?1 ,Ranki ) <= ? .
223 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 7:5:preserved 8:6:preserved 10:7:preserved 11:8:preserved 12:9:preserved 13:10:preserved 14:11:preserved 15:12:preserved 16:13:preserved 17:14:preserved 18:15:preserved

Step 5 : Return Hi = Pij=1 hj .
Step 5 : Return Hi = Pij=1 hj .
226 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved

Step 1 : Rankcur = Rank-By-Bagging-ProbSVM-InnerLoop( Rankprev ) .
Step 1 : Rankcur = Rank-By-Bagging-ProbSVM-InnerLoop ( Rankprev ) .
231 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5,6:preserved 6:7:preserved 7:8:preserved 8:9:preserved

Step 2 : dist = Dist2RankList( Rankprev ,Rankcur ) .
Step 2 : dist = Dist2RankList ( Rankprev ,Rankcur ) .
234 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5,6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved

Step 3 : Rankfinal = Rankcur .
Step 3 : Rankfinal = Rankcur .
237 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved

Step 4 : Rankprev = Rankcur .
Step 4 : Rankprev = Rankcur .
240 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved

Step 5 : Repeat steps from Step 1 to Step 4 until dist <= ? .
Step 5 : Repeat steps 1 to 4 until dist <= ? .
243 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 7:5:preserved 8:6:preserved 10:7:preserved 11:8:preserved 12:9:preserved 13:10:preserved 14:11:preserved 15:12:preserved

Step 5 : Return Rankfinal .
Step 6 : Return Rankfinal .
246 0:0:preserved 1:1:typo 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved

Given an input ranked list , Rank-By-Bagging-ProbSVM-InnerLoop is used to improve this rank list .
Given an input ranked list , Rank-By-Bagging-ProbSVM-InnerLoop is used to improve this list .
249 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 13:12:preserved 14:13:preserved

We repeat the process a number of times whereby the ranked list output from the previous step is used as the input ranked list of the next step .
We repeat the process a number of times whereby the ranked list output from the previous step is used as the input ranked list of the next step .
250 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved

In this way , the iterations significantly improve the final ranked list .
In this way , the iterations significantly improve the final ranked list .
251 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved

The details are described in Algorithm 3 .
The details are described in Algorithm 3 .
252 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved

To determine the number of iterations of Rank-By-Bagging-ProbSVM-InnerLoop and Rank-By-Bagging-ProbSVM-OuterLoop , we use the \MATH distance \CITE , which is a metric that counts the number of pairwise disagreements between two lists .
To determine the number of iterations of Rank-By-Bagging-ProbSVM-InnerLoop and Rank-By-Bagging-ProbSVM-OuterLoop , we use the \MATH distance \CITE , which is a metric that counts the number of pairwise disagreements between two lists .
255 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved

The larger the distance , the more dissimilar the two lists are .
The larger the distance , the more dissimilar the two lists are .
256 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved

The \MATH distance between two list \MATH and \MATH is defined as follows :
The \MATH distance between two lists , \MATH and \MATH , is defined as follows :
257 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:bigrammar-nnum 6:7:preserved 7:8:preserved 8:9:preserved 9:11:preserved 10:12:preserved 11:13:preserved 12:14:preserved 13:15:preserved

Since the maximum value of \MATH is \MATH where \MATH is the number of members of the list , the normalized Kendall tau distance can be written as follows :
Since the maximum value of \MATH is \MATH , where \MATH is the number of members of the list , the normalized Kendall tau distance can be written as follows :
260 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:26:preserved 26:27:preserved 27:28:preserved 28:29:preserved 29:30:preserved

Using this measure for checking when the loops stop means that if the ranked list does not change significantly after a number of iterations , it is reasonable to stop .
Using this measure for checking when the loops stop means that if the ranked list does not change significantly after a number of iterations , it is reasonable to stop .
263 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved

We used the dataset described in \CITE for our experiments .
We used the dataset described by Berg et al. \CITE for our experiments .
269 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:bigrammar-prep 6:9,6,7,8:paraphrase 7:10:preserved 8:11:preserved 9:12:preserved 10:13:preserved

This dataset consists of approximately half a million news [pictures / photos?] and captions from Yahoo News collected over a period of roughly two years .
This dataset consists of approximately half a million news pictures and captions from Yahoo News collected over a period of roughly two years .
270 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9,11,10:9:bigrammar-others 12:10:preserved 13:11:preserved 14:12:preserved 15:13:preserved 16:14:preserved 17:15:preserved 18:16:preserved 19:17:preserved 20:18:preserved 21:19:preserved 22:20:preserved 23:21:preserved 24:22:preserved 25:23:preserved

This dataset is better than datasets collected from image search engines such as Google that usually limit the total number of returned images to 1 ,000 .
This dataset is better than datasets collected from image search engines such as Google that usually limit the total number of returned images to 1 ,000 .
271 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved

Furthermore , it has annotations that are valuable for evaluation of methods .
Furthermore , it has annotations that are valuable for evaluation of methods .
272 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved

Note that these annotations are used for evaluation purpose only .
Note that these annotations are used for evaluation purpose only .
273 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved

Our method is fully unsupervised , so it assumes the annotations are not available at running time .
Our method is fully unsupervised , so it assumes the annotations are not available at running time .
274 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved

Only frontal faces were considered since current frontal face detection systems \CITE can work in real time and have accuracies exceeding 95\% .
Only the front of faces were considered since current frontal face detection systems \CITE work in real time and have accuracies exceeding 95\% .
277 0:0:preserved 1:1,2,3:paraphrase 2:4:preserved 3:5:preserved 4:6:preserved 5:7:preserved 6:8:preserved 7:9:preserved 8:10:preserved 9:11:preserved 10:12:preserved 11:13:preserved 12,13:14:bigrammar-vtense 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved

44 ,773 faces were detected and normalized to the size of 86\MATH86 pixels .
44 ,773 faces were detected and normalized to 86\MATH86 pixels .
278 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 11:8:preserved 12:9:preserved 13:10:preserved

We selected fifteen government leaders , including George W. Bush ( US ) , Vladimir Putin ( Russia ) , Ziang Jemin ( China ) , Tony Blair ( UK ) , Junichiro Koizumi ( Japan ) , Roh Moo-hyun ( Korea ) , and Abdullah Gul ( Turkey ) , and other key individuals , such as John Paul II ( the Former Pope ) and Hans Blix ( UN ) , because their images frequently appear in the dataset \CITE .
We selected fifteen government leaders , including George W. Bush ( US ) , Vladimir Putin ( Russia ) , Ziang Jemin ( China ) , Tony Blair ( UK ) , Junichiro Koizumi ( Japan ) , Roh Moo-hyun ( Korea ) , Abdullah Gul ( Turkey ) , and other key individuals , such as John Paul II ( the Former Pope ) and Hans Blix ( UN ) , because their images frequently appear in the dataset \CITE .
281 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved 35:35:preserved 36:36:preserved 37:37:preserved 38:38:preserved 39:39:preserved 40:40:preserved 41:41:preserved 42:42:preserved 43:43:preserved 45:44:preserved 46:45:preserved 47:46:preserved 48:47:preserved 49:48:preserved 50:49:preserved 51:50:preserved 52:51:preserved 53:52:preserved 54:53:preserved 55:54:preserved 56:55:preserved 57:56:preserved 58:57:preserved 59:58:preserved 60:59:preserved 61:60:preserved 62:61:preserved 63:62:preserved 64:63:preserved 65:64:preserved 66:65:preserved 67:66:preserved 68:67:preserved 69:68:preserved 70:69:preserved 71:70:preserved 72:71:preserved 73:72:preserved 74:73:preserved 75:74:preserved 76:75:preserved 77:76:preserved 78:77:preserved 79:78:preserved 80:79:preserved 81:80:preserved 82:81:preserved

The variations in each person 's name were collected .
Variations in each person 's name were collected .
282 0::mogrammar-det 1:0:preserved 2:1:preserved 3:2:preserved 4:3:preserved 5:4:preserved 6:5:preserved 7:6:preserved 8:7:preserved 9:8:preserved

For example , George W. Bush , President Bush , U.S. President , etc. , all refer to the current U.S. president .
For example , George W. Bush , President Bush , U.S. President , etc. , all refer to the current U.S. president .
283 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved

We performed simple string search in captions to check whether a caption contains one of these names .
We performed simple string search in captions to check whether a caption contained one of these names .
286 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:bigrammar-vtense 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved

The faces extracted from the corresponding image associated with this caption were returned .
The faces extracted from the corresponding image associated with this caption were returned .
287 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved

The faces retrieved from the different name queries were merged into one set and used as input for ranking .
The faces retrieved from the different name queries were merged into one set and used as input for ranking .
288 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved

Figure \REF shows the distribution of retrieved faces from this method and the corresponding number of relevant faces for these fifteen individuals .
Figure \REF shows the distribution of retrieved faces from this method and the corresponding number of relevant faces for these fifteen individuals .
291 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved

In total , 5 ,603 faces were retrieved in which 3 ,374 faces were relevant .
In total , 5 ,603 faces were retrieved in which 3 ,374 faces were relevant .
292 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved

On average , the accuracy was 60 .22\% .
On average , the accuracy was 60 .22\% .
293 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved

We used an eye detector to detect the positions of the eyes in the detected faces .
We used an eye detector to detect the positions of the eyes of the detected faces .
298 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:bigrammar-prep 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved

The eye detector , built with the same approach as in \CITE , had an accuracy of more than 95\% .
The eye detector , built with the same approach as that of Viola and jones \CITE , had an accuracy of more than 95\% .
299 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10,11,12,13,14:paraphrase 11:15:preserved 13,14,15,16:17,18,19,20:preserved 17,18:21,22:preserved 19:23:preserved

If the eye positions were not detected , predefined eye locations were assigned .
If the eye positions were not detected , predefined eye locations were assigned .
300 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved

The eye positions were used to align faces to a predefined canonical pose .
The eye positions were used to align faces to a predefined canonical pose .
301 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved

To compensate for illumination effects , the subtraction of the bestfit brightness plane followed by histogram equalization was applied .
To compensate for illumination effects , the subtraction of the best-fit brightness plane followed by histogram equalization was applied .
304 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:typo 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved

This normalization process is shown in Figure \REF .
This normalization process is shown in Figure \REF .
305 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved

We then used principle component analysis \CITE to reduce the number of dimensions of the feature vector for face representation .
We then used principle component analysis \CITE to reduce the number of dimensions of the feature vector for face representation .
308 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved

Eigenfaces were computed from the original face set returned by the text-based query method .
Eigenfaces were computed from the original face set returned using the text-based query method .
309 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:paraphrase 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved

The number of eigenfaces used to form the eigen space was selected so that 97\% of the total energy was retained \CITE .
The number of eigenfaces used to form the eigen space was selected so that 97\% of the total energy was retained \CITE . //It is not clear what you mean by " energy " in this context . This is the first time you mention this term . You might want to specify what kind of energy you are talking about .
310 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved

The number of dimensions of these feature spaces ranged from 80 to 500 .
The number of dimensions of these feature spaces ranged from 80 to 500 .
311 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved

We evaluated the retrieval performance with measures that are commonly used in information retrieval , such as precision , recall , and average precision .
We evaluated the retrieval performance with measures that are commonly used in information retrieval , such as precision , recall , and average precision .
316 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved

Given a queried person and letting \MATH be the total number of faces returned , \MATH the number of relevant faces , and \MATH the total number of relevant faces , recall and precision can be calculated as follows :
Given a queried person and letting \MATH be the total number of faces returned , \MATH the number of relevant faces , and \MATH the total number of relevant faces , recall and precision can be calculated as follows :
317 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved 35:35:preserved 36:36:preserved 37:37:preserved 38:38:preserved 39:39:preserved

Precision and recall only evaluate the quality of an unordered set of retrieved faces .
Precision and recall are only used to evaluate the quality of an unordered set of retrieved faces .
320 0:0:preserved 1:1:preserved 2:2:preserved 3:4:preserved 4:3,5,6,7:paraphrase 5:8:preserved 6:9:preserved 7:10:preserved 8:11:preserved 9:12:preserved 10:13:preserved 11:14:preserved 12:15:preserved 13:16:preserved 14:17:preserved

To evaluate ranked lists in which both recall and precision are taken into account , the average precision is usually used .
To evaluate ranked lists in which both recall and precision are taken into account , average precision is usually used .
321 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15::mogrammar-det 16:15:preserved 17:16:preserved 18:17:preserved 19:18:preserved 20:19:preserved 21:20:preserved

The average precision is computed by taking the average of the interpolated precision measured at the 11 recall levels of 0 .0 , 0 .1 , 0 .2 , . . . , 1 .0 .
The average precision is computed by taking the average of the interpolated precision measured at the 11 recall levels of 0 .0 , 0 .1 , 0 .2 , . . . , 1 .0 .
322 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved 35:35:preserved

The interpolated precision \MATH at a certain recall level \MATH is defined as the highest precision found for any recall level \MATH :
The interpolated precision \MATH at a certain recall level \MATH is defined as the highest precision found for any recall level \MATH :
325 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved

In addition , to evaluate the performance of multiple queries , we used mean average precision , which is the mean of average precisions computed from queries
In addition , to evaluate the performance of multiple queries , we used mean average precision , which is the mean of average precisions computed from queries
328 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved

The parameters of our method include :
The parameters of our method include :
333 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved

-\MATH : the fraction of faces lying at the top and bottom of the ranked list that are used to form a positive set \MATH and negative set \MATH for training weak classifiers in Rank-By-Bagging-ProbSVM-InnerLoop .
-\MATH : the fraction of faces at the top and bottom of the ranked list that are used to form a positive set \MATH and negative set \MATH for training weak classifiers in Rank-By-Bagging-ProbSVM-InnerLoop .
336 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 7:6:preserved 8:7:preserved 9:8:preserved 10:9:preserved 11:10:preserved 12:11:preserved 13:12:preserved 14:13:preserved 15:14:preserved 16:15:preserved 17:16:preserved 18:17:preserved 19:18:preserved 20:19:preserved 21:20:preserved 22:21:preserved 23:22:preserved 24:23:preserved 25:24:preserved 26:25:preserved 27:26:preserved 28:27:preserved 29:28:preserved 30:29:preserved 31:30:preserved 32:31:preserved 33:32:preserved 34:33:preserved 35:34:preserved

We empirically selected \MATH ( i .e 40\% samples of the rank list were used ) since larger \MATH will increase the number of incorrect labels and smaller \MATH will cause over-fitting .
We empirically selected \MATH ( i .e 40\% samples of the rank list were used ) since a larger \MATH will increase the number of incorrect labels , and a smaller \MATH will cause over-fitting .
339 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:26:preserved 26:28:preserved 27:30:preserved 28:31:preserved 29:32:preserved 30:33:preserved 31:34:preserved 32:35:preserved :17:mogrammar-det :29:mogrammar-det

In addition , \MATH consists of \MATH samples that are selected randomly with replacement from \MATH .
In addition , \MATH consists of \MATH samples that are selected randomly with replacement from \MATH .
342 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved

This sampling strategy is adopted from the bagging framework \CITE .
This sampling strategy is adopted from the bagging framework \CITE .
343 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved

The same setting was used for \MATH .
The same setting was used for \MATH .
344 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved

-\MATH : the maximum Kendall tau distance \MATH between two rank lists \MATH and \MATH .
-\MATH : the maximum Kendall tau distance \MATH between two rank lists \MATH and \MATH .
347 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved

This value is used to determine when the inner loop and the outer loop are stopped .
This value is used to determine when the inner loop and the outer loop stop .
350 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14,15:14:para-passact 16:15:preserved

We set \MATH for balance between accuracy and processing time .
We set \MATH for balancing between accuracy and processing time .
351 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:bigrammar-wform 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved

Note that smaller \MATH requires more number of iterations making the system 's speed slower .
Note that a smaller \MATH requires more iterations , making the system 's speed slower .
352 0:0:preserved 1:1:preserved 2:3:preserved 3:4:preserved 4:5:preserved 5:6:preserved 8:7:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved :2:mogrammar-det

-\MATH : the kernel type is used for SVM .
-\MATH : the kernel type is used for the SVM .
355 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:9:preserved 9:10:preserved :8:mogrammar-det

The default is linear kernel that is defined as : \MATH .
The default is a linear kernel that is defined as : \MATH .
356 0:0:preserved 1:1:preserved 2:2:preserved 3:4:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved :3:mogrammar-det

We have tested other kernel types such as RBF or polynomial , the performance did not change so much .
We have tested other kernel types , such as RBF or polynomial , but the performance did not change much .
359 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13,14:paraphrase 13:15:preserved 14:16:preserved 15:17:preserved 16:18:preserved 18:19:preserved 19:20:preserved

Therefore , we used the linear kernel for simplicity .
Therefore , we used the linear kernel for simplicity .
360 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved

We performed a comparison between our proposed method with other existing approaches .
We performed a comparison between our proposed method with other ones .
367 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 11,10:10:paraphrase 12:11:preserved

Text Based Baseline ( TBL ) : Once faces corresponding with images whose captions contain the query name are returned , they are ranked by the time order .
Text Based Baseline ( TBL ) : Once faces corresponding with images whose captions contain the query name are returned , they are ranked in time order .
368 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:bigrammar-prep 25::mogrammar-det 26:25:preserved 27:26:preserved 28:27:preserved

This is very naive method in which no prior knowledge between names and faces is used .
This is a rather naive method in which no prior knowledge between names and faces is used .
369 0:0:preserved 1:1:preserved 2:3:paraphrase 3:4:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved :2:mogrammar-det

Distance-Based Outlier ( DBO ) : We adopted the idea of distance-based outliers detection for ranking \CITE .
Distance-Based Outlier ( DBO ) : We adopted the idea of distance-based outlier detection for ranking \CITE .
372 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:bigrammar-nnum 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved

Given a threshold \MATH , for each point \MATH , we counted the number of points \MATH so that \MATH , where \MATH is the Euclidean distance between \MATH and \MATH in the feature space mentioned in section \REF .
Given a threshold \MATH , for each point \MATH , we counted the number of points \MATH so that \MATH , where \MATH is the Euclidean distance between \MATH and \MATH in the feature space mentioned in section \REF .
373 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved 35:35:preserved 36:36:preserved 37:37:preserved 38:38:preserved 39:39:preserved

This number then was used as the score to rank faces .
This number was then used as the score to rank faces .
374 0:0:preserved 1:1:preserved 2:3:preserved 3:2:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved

We selected a range of \MATH values for experiments : \MATH .}
We selected a range of \MATH values for experiments : \MATH .}
375 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved

Densest Sub-Graph based Method ( DSG ) : We re-implemented the densest sub-graph based method \CITE for ranking .
Densest Sub-Graph based Method ( DSG ) : We re-implemented the densest sub-graph based method \CITE for ranking .
378 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved

Once the densest subgraph was found after an edge elimination process , we counted the number of surviving edge of each node ( i .e face ) and used this number as the score for ranking .
Once the densest subgraph was found after an edge elimination process , we counted the number of surviving edges of each node ( i .e face ) and used this number as the ranking score .
379 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:bigrammar-nnum 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:34:preserved 34::mogrammar-prep 35:33:preserved 36:35:preserved

To form the graph , the Euclidean distance \MATH was used to assign the weight for the edge linked between node $p$ and node \MATH .
To form the graph , the Euclidean distance \MATH was used to assign the weight for the edge linked between node $p$ and node \MATH .
380 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved

DSG require a threshold \MATH to convert the weighted graph to the binary graph before searching for the densest subgraph .
DSG requires a threshold \MATH to convert the weighted graph to the binary graph before searching for the densest subgraph .
381 0:0:preserved 1:1:bigrammar-inter 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved

We selected a range of \MATH values that are the same as the values used in DBO : \MATH .
We selected a range of \MATH values that are the same as the values used in DBO : \MATH .
382 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved

Local Density Score ( LDS ) : This is the first stage of our proposed method .
Local Density Score ( LDS ) : This is the first stage of our proposed method .
385 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved

It requires the input value \MATH to compute the local density score .
It requires the input value \MATH to compute the local density score .
386 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved

Since we do not know the number of returned faces from text based search engines , we used another input value \MATH defined as the fraction of neighbors and estimated \MATH by the formula : \MATH , where \MATH is the number of returned faces .
Since we do not know the number of returned faces from text-based search engines , we used another input value \MATH , defined as the fraction of neighbors , and estimated \MATH by the formula : \MATH , where \MATH is the number of returned faces .
387 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11,12:11:typo 13:12:preserved 14:13:preserved 15:14:preserved 16:15:preserved 17:16:preserved 18:17:preserved 19:18:preserved 20:19:preserved 21:20:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:29:preserved 29:30:preserved 30:31:preserved 31:32:preserved 32:33:preserved 33:34:preserved 34:35:preserved 35:36:preserved 36:37:preserved 37:38:preserved 38:39:preserved 39:40:preserved 40:41:preserved 41:42:preserved 42:43:preserved 43:44:preserved 44:45:preserved 45:46:preserved

We used a range of $fraction$ values for experiments : \MATH .
We used a range of $fraction$ values for experiments : \MATH .
388 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved

In the case of large number of returned faces , we set \MATH to the maximum value of 200 : \MATH .
For a large number of returned faces , we set \MATH to the maximum value of 200 : \MATH .
389 0,1,2,3:0:paraphrase 4:2:preserved 5:3:preserved 6:4:preserved 7:5:preserved 8:6:preserved 9:7:preserved 10:8:preserved 11:9:preserved 12:10:preserved 13:11:preserved 14:12:preserved 15:13:preserved 16:14:preserved 17:15:preserved 18:16:preserved 19:17:preserved 20:18:preserved 21:19:preserved :1:mogrammar-det

Unsupervised Ensemble Learning Using Local Density Score ( UEL-LDS ) : This is a combination of ranking by local density scores and then the ranked list is used for training classifier [Singular or plural?]to boost the rank list .
Unsupervised Ensemble Learning Using Local Density Score ( UEL-LDS ) : This is a combination of ranking by local density scores , and the ranked list is used for training a classifier to boost the rank list .
392 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:31:preserved 34:33:preserved 35:34:preserved 36:35:preserved 37:36:preserved 38:37:preserved :30:mogrammar-det

Supervised Learning ( SVM-SUP ) : We randomly selected a portion \MATH of the data with annotations to train the classifier ; and then used this classifier to re-rank remaining faces .
Supervised Learning ( SVM-SUP ) : We randomly selected a portion \MATH of the data with annotations to train the classifier ; and then used this classifier to re-rank the remaining faces .
395 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:30:preserved 30:31:preserved 31:32:preserved :29:mogrammar-det

This process was repeated five times and the average performance was reported .
This process was repeated five times and the average performance was reported .
396 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved

We used a range of portion \MATH values for experiments : \MATH .
We used a range of portion \MATH values for experiments : \MATH .
397 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved

Figure \REF shows a performance comparison of these methods .
Figure \REF shows a performance comparison of these methods .
400 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved

Our proposed methods ( LDS and UEL-LDS ) outperform other unsupervised methods such as TBL , DBO and DSG .
Our proposed methods ( LDS and UEL-LDS ) outperform other unsupervised methods such as TBL , DBO , and DSG .
403 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:18:preserved 18:19:preserved 19:20:preserved

Furthermore , the performance of methods DBO and DSG are sensitive to the distance threshold ; while the performance of our proposed method is less sensitive .
Furthermore , the DBO and DSG methods are sensitive to the distance threshold , while the performance of our proposed method is less sensitive .
404 0:0:preserved 1:1:preserved 2:2:preserved 5:6:preserved 6:3:preserved 7:4:preserved 8:5:preserved 9:7:preserved 10:8:preserved 11:9:preserved 12:10:preserved 13:11:preserved 14:12:preserved 16:14:preserved 17:15:preserved 18:16:preserved 19:17:preserved 20:18:preserved 21:19:preserved 22:20:preserved 23:21:preserved 24:22:preserved 25:23:preserved 26:24:preserved

It confirms that the similarity measure using shared nearest neighbors is relieable for estimation of the local density score .
It confirms that the similarity measure using shared nearest neighbors is reliable for estimation of the local density score .
405 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:spelling 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved

The performance of UEL-LDS is slightly better than LDS since the training sets labeled automatically from the ranked list are noisy .
The performance of UEL-LDS is slightly better than LDS since the training sets labeled automatically from the ranked list are noisy .
406 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved

However , UEL-LDS improves the performance significantly even when the performance of LDS is poor .
However , UEL-LDS improves significantly even when the performance of LDS is poor .
407 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:7:preserved 5:8:preserved 6:4:preserved 7:5:preserved 8:6:preserved 11:9:preserved 12:10:preserved 13:11:preserved 14:12:preserved 15:13:preserved

These performances are worse than that of SVM-SUP using a small number of labeled samples .
These performances are worse than that of SVM-SUP using a small number of labeled samples .
408 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved

Figure \REF shows an examples of top 50 faces ranked by the methods TBL , DBO , DSG and LDS .
Figure \REF shows an examples of the top 50 faces ranked using the TBL , DBO , DSG , and LDS methods .
411 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10,11,12:11,21:paraphrase 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:19:preserved 19:20:preserved 20:22:preserved :6:mogrammar-det :12:mogrammar-det

The performance of DBO is poor since a low threshold is used .
The performance of DBO is poor since a low threshold is used .
412 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved

This makes irrelevant faces that are near duplicates ( row 2 and row 3 in Figure \REF( b ) ) ranked higher than relevant faces .
This ranks irrelevant faces that are near duplicates ( rows 2 and 3 in Figure \REF( b ) ) higher than relevant faces .
413 0:0:preserved 1:1:paraphrase 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9,12:9:bigrammar-others 10:10:preserved 11:11:preserved 13:12:preserved 14:13:preserved 15:14:preserved 16:15:preserved 17:16:preserved 18:17:preserved 19:18:preserved 21:19:preserved 22:20:preserved 23:21:preserved 24:22:preserved 25:23:preserved

This explains the same situation with DSG .
This explains the same situation with DSG .
414 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved

In Figure \REF , we show the performance of five single classifiers and that of five ensemble classifiers .
In Figure \REF , we show the performance of five single classifiers and that of five ensemble classifiers .
419 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved

The ensemble classifier \MATH is formed by combination of single classifiers from \MATH to \MATH .
The ensemble classifier \MATH is formed by combining single classifiers from \MATH to \MATH .
420 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 8,7:7:paraphrase 9:8:preserved 10:9:preserved 11:10:preserved 12:11:preserved 13:12:preserved 14:13:preserved 15:14:preserved

It clearly indicates that the ensemble classifier is more stable that single weak classifiers .
It clearly indicates that the ensemble classifier is more stable than single weak classifiers . //You use both plural and singular forms of " classifier " here , so it is a bit confusing if you are talking about a single classifier or more than one . I suggest you use the same form throughout if applicable .]
421 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:typo 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved

We conducted another experiment to show the effectiveness of our approach in which learned models can be used to annotate new faces of other databases .
We conducted another experiment to show the effectiveness of our approach in which learned models are used to annotate new faces of other databases .
426 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 17,16,15:16,15:bigrammar-vtense 18:17:preserved 19:18:preserved 20:19:preserved 21:20:preserved 22:21:preserved 23:22:preserved 24:23:preserved 25:24:preserved

For each name in the list , we used it as the query to obtain top 500 images from Google Image Search Engine .
We used each name in the list as a query to obtain the top 500 images from the Google Image Search Engine ( GoogleSE ) .
427 0,7,8,9:0,1:paraphrase 1:2:preserved 2:3:preserved 3:4:preserved 4:5:preserved 5:6:preserved 10:7:preserved 11:8:bigrammar-det 12:9:preserved 13:10:preserved 14:11:preserved 15:13:preserved 16:14:preserved 17:15:preserved 18:16:preserved 19:18:preserved 20:19:preserved 21:20:preserved 22:21:preserved 23:25:preserved :12:mogrammar-det :17:mogrammar-det

Next , these images were processed as the steps described in section \REF : extracting faces , detecting eyes and doing normalization .
Next , these images were processed using the steps described in section \REF : extracting faces , detecting eyes , and doing normalization .
428 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:paraphrase 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved

We projected these faces to the PCA subspace trained for that name and used the learned model to re-rank faces .
We projected these faces to the PCA subspace trained for that name and used the learned model to re-rank faces .
429 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved

There were 4 ,103 faces ( including false positives - non-faces were detected as faces ) detected from 7 ,500 returned images .
There were 4 ,103 faces ( including false positives - non-faces detected as faces ) detected from 7 ,500 returned images .
432 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11,12:11:paraphrase 13:12:preserved 14:13:preserved 15:14:preserved 16:15:preserved 17:16:preserved 18:17:preserved 19:18:preserved 20:19:preserved 21:20:preserved 22:21:preserved

We manually labeled these faces and there were 2 ,342 relevant faces .
We manually labeled these faces and there were 2 ,342 relevant faces .
433 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved

On average , the accuracy of the Google Search Engine ( GoogleSE ) is 57 .08\% .
On average , the accuracy of the GoogleSE is 57 .08\% .
434 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7,8,9,11:7:paraphrase 13,14,15:8,9,10:preserved

In Table \REF , we compare the performance of the methods .
In Table \REF , we compare the performance of the methods .
437 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved

The performance of UEL-LDS was obtained by running the best system , which is shown as the peak of UEL-LDS curve in Figure \REF .
The performance of UEL-LDS was obtained by running the best system , which is shown as the peak of the UEL-LDS curve in Figure \REF .
438 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved :19:mogrammar-det

The performances of SVM-SUP-05 and SVM-SUP-10 correspond to the supervised systems ( cf . section \REF ) that used \MATH of the data set respectively .
The performances of SVM-SUP-05 and SVM-SUP-10 correspond to the supervised systems ( cf . section \REF ) that used \MATH of the data set , respectively .
439 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:25:preserved 25:26:preserved

We evaluated the performance by calculating the precision at top 20 returned faces , which is popular for image search engines ; and recall and precision on all detected faces of the test set .
We evaluated the performance by calculating the precision of the top 20 returned faces , which is common for image search engines and recall and precision on all detected faces of the test set .
440 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:bigrammar-prep 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:paraphrase 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved :9:mogrammar-det

UEL-LDS achieved comparable performance to the supervised methods and outperformed the baseline GoogleSE .
UEL-LDS achieved comparable performance to the supervised methods and outperformed the baseline GoogleSE .
441 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved

The precision at top 20 of SVM-SUP-05 is poorer than that of UEL-LDS is due to small number of training samples .
The precision of the top 20 of SVM-SUP-05 is poorer than that of UEL-LDS due to the small number of training samples .
442 0:0:preserved 1:1:preserved 2::unaligned 3:4:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:16:bigrammar-det 14:14:preserved 15:15:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved :2:mogrammar-prep :3:mogrammar-det

Figure \REF shows top 20 faces ranked by these two methods .
Figure \REF shows top 20 faces ranked using these two methods .
445 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:paraphrase 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved

Our approach works fairly well for well known people , where the main assumption that text-based search engines return a large fraction of relevant images is satisfied .
Our approach works fairly well for well known people , where the main assumption that text-based search engines return a large fraction of relevant images is satisfied .
451 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved

Figure \REF shows an example where this assumption is broken .
Figure \REF shows an example where this assumption is broken .
452 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved

Consequently , as shown in Figure \REF , the model learned by this set obtained poor performance in recognizing new faces returned by GoogleSE .
Consequently , as shown in Figure \REF , the model learned by this set performed poorly in recognizing new faces returned by GoogleSE .
453 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 15,14,16:14,15:paraphrase 17:16:preserved 18:17:preserved 19:18:preserved 20:19:preserved 21:20:preserved 22:21:preserved 23:22:preserved 24:23:preserved

Our approach solely relies on the above assumption , therefore it is not affected by the ranking of text-based search engines .
Our approach solely relies on the above assumption ; therefore , it is not affected by the ranking of text-based search engines .
454 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:10:preserved 9:9:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved

The iteration of bagging SVM classifiers does not guarantee a significant improvement in performance .
The iteration of bagging SVM classifiers does not guarantee a significant improvement in performance .
457 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved

Our future work is to study how to improve the quality of the training sets used in this iteration .
The aim of our future work is to study how to improve the quality of the training sets used in this iteration .
458 0,1,2:3,0,2,1,4,5:paraphrase 3:6:preserved 4:7:preserved 5:8:preserved 6:9:preserved 7:10:preserved 8:11:preserved 9:12:preserved 10:13:preserved 11:14:preserved 12:15:preserved 13:16:preserved 14:17:preserved 15:18:preserved 16:19:preserved 17:20:preserved 18:21:preserved 19:22:preserved

We presented a method for ranking faces retrieved using text-based correlation methods in searches for a specific person .
We presented a method for ranking faces retrieved using text-based correlation methods in searches for a specific person .
463 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved

This method learns the visual consistency among the faces in a two-stage process .
This method learns the visual consistency among faces in a two-stage process .
464 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7::mogrammar-det 8:7:preserved 9:8:preserved 10:9:preserved 11:10:preserved 12:11:preserved 13:12:preserved

In the first stage , a relative density score is used to form a ranked list in which faces ranked at the top or bottom of the list are likely relevant or irrelevant faces .
In the first stage , a relative density score is used to form a ranked list in which faces ranked at the top or bottom of the list are likely to be relevant or irrelevant faces , respectively .
465 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:32,30,31:paraphrase 31:33:preserved 32:34:preserved 33:35:preserved 34:36,37,38:paraphrase

In the second stage , a bagging framework is used to combine weak classifiers trained on subsets labeled from the ranked list into a strong classifier .
In the second stage , a bagging framework is used to combine weak classifiers trained on subsets labeled from the ranked list into a strong classifier .
466 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved

This strong classifier is then applied to the original set to re-rank faces on the basis of the output probabilistic scores .
This strong classifier is then applied to the original set to re-rank faces on the basis of the output probabilistic scores .
467 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved

Experiments on various face sets showed the effectiveness of this method .
Experiments on various face sets showed the effectiveness of this method .
468 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved

Our approach is beneficial in the case multiple faces residing in the returned image as shown in Figure \REF .
Our approach is beneficial when there are several faces in a returned image , as shown in Figure \REF .
469 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4,5,6:4,5,6:paraphrase 7:7:paraphrase 8:8:preserved 9,10:9:paraphrase 11:10:bigrammar-det 12:11:preserved 13:12:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved

