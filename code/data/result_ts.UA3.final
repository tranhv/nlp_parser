# Sentence pair (1) source length 15 target length 14 alignment score : 4.39248e-06
This paper analyzes the effects of structural variation of sentences on parsing performances . 
NULL ({ }) This ({ 1 }) paper ({ 2 }) analyzes ({ 3 }) the ({ 4 }) effect ({ 5 }) of ({ 6 }) the ({ }) structural ({ 7 }) variation ({ 8 }) of ({ 9 }) sentences ({ 10 }) on ({ 11 }) parsing ({ 12 }) performance ({ 13 }) . ({ 14 }) 
# Sentence pair (2) source length 19 target length 19 alignment score : 2.14657e-05
We examined the performances of both shallow and deep parsers for two sentence constructions : imperatives and questions . 
NULL ({ }) We ({ 1 }) examine ({ 2 }) the ({ 3 }) performance ({ 4 }) of ({ 5 }) both ({ 6 }) shallow ({ 7 }) and ({ 8 }) deep ({ 9 }) parsers ({ 10 }) for ({ 11 }) two ({ 12 }) sentence ({ 13 }) constructions ({ 14 }) : ({ 15 }) imperatives ({ 16 }) and ({ 17 }) questions ({ 18 }) . ({ 19 }) 
# Sentence pair (3) source length 17 target length 18 alignment score : 2.67859e-07
The target parsers are adapted to the sentences for these constructions extracted from fiction and query texts . 
NULL ({ 7 }) The ({ 1 }) target ({ 2 }) parsers ({ 3 }) are ({ 4 }) adapted ({ 5 }) to ({ 6 }) sentences ({ 8 }) of ({ 9 }) these ({ 10 }) constructions ({ 11 }) extracted ({ 12 }) from ({ 13 }) fiction ({ 14 }) and ({ 15 }) query ({ 16 }) texts ({ 17 }) . ({ 18 }) 
# Sentence pair (4) source length 26 target length 27 alignment score : 5.70195e-25
The analysis of the experimental results will illustrate the necessity for handling various sentence constructions by fundamental improvement of parsers such as re-construction of feature designs . 
NULL ({ 9 }) Analysis ({ 1 2 }) of ({ 3 }) the ({ 4 }) experimental ({ 5 }) results ({ 6 }) illustrates ({ 7 }) the ({ }) need ({ 8 }) to ({ 11 }) handle ({ 12 }) different ({ 13 }) sentence ({ 14 }) constructions ({ 15 }) through ({ 16 }) fundamental ({ 17 }) improvement ({ 18 }) of ({ 19 }) the ({ }) parsers ({ 20 }) such ({ 21 }) as ({ 22 }) re-construction ({ 10 23 }) of ({ 24 }) feature ({ 25 }) designs ({ 26 }) . ({ 27 }) 
# Sentence pair (5) source length 15 target length 15 alignment score : 0.000176667
Parsing is a fundamental natural language processing task and essential for various NLP applications . 
NULL ({ }) Parsing ({ 1 }) is ({ 2 }) a ({ 3 }) fundamental ({ 4 }) natural ({ 5 }) language ({ 6 }) processing ({ 7 }) task ({ 8 }) and ({ 9 }) essential ({ 10 }) to ({ 11 }) various ({ 12 }) NLP ({ 13 }) applications ({ 14 }) . ({ 15 }) 
# Sentence pair (6) source length 34 target length 34 alignment score : 2.70968e-15
Recent research on parsing technologies has achieved high parsing accuracies on the same domains as the training data , but once we move to unfamiliar domains , the performances decrease at unignorable levels . 
NULL ({ }) Recent ({ 1 }) research ({ 2 }) on ({ 3 }) parsing ({ 4 }) technologies ({ 5 }) has ({ 6 }) achieved ({ 7 }) high ({ 8 }) parsing ({ 9 }) accuracy ({ 10 }) in ({ 11 }) the ({ 12 }) same ({ 13 }) domain ({ 14 }) as ({ 15 }) the ({ 16 }) training ({ 17 }) data ({ 18 }) , ({ 19 }) but ({ 20 }) once ({ 21 }) we ({ 22 }) move ({ 23 }) to ({ 24 }) unfamiliar ({ 25 }) domains ({ 26 }) , ({ 27 }) the ({ 28 }) performance ({ 29 }) decreases ({ 30 }) to ({ }) unignorable ({ 31 32 }) levels ({ 33 }) . ({ 34 }) 
# Sentence pair (7) source length 42 target length 42 alignment score : 4.54517e-11
To address this problem , previous work has mainly focused on adapting lexical or syntactic preferences to the target domain , that is , on adding lexical knowledge or adjusting probabilistic models for the target domain using available in-domain resources \CITE . 
NULL ({ }) To ({ 1 }) address ({ 2 }) this ({ 3 }) problem ({ 4 }) , ({ 5 }) previous ({ 6 }) work ({ 7 }) has ({ 8 }) focused ({ 10 }) mainly ({ 9 }) on ({ 11 }) adapting ({ 12 }) lexical ({ 13 }) or ({ 14 }) syntactic ({ 15 }) preferences ({ 16 }) to ({ 17 }) the ({ 18 }) target ({ 19 }) domain ({ 20 }) , ({ 21 }) that ({ 22 }) is ({ 23 }) , ({ 24 }) on ({ 25 }) adding ({ 26 }) lexical ({ 27 }) knowledge ({ 28 }) or ({ 29 }) adjusting ({ 30 }) probabilistic ({ 31 }) models ({ 32 }) for ({ 33 }) the ({ 34 }) target ({ 35 }) domain ({ 36 }) using ({ 37 }) available ({ 38 }) in-domain ({ 39 }) resources ({ 40 }) \CITE ({ 41 }) . ({ 42 }) 
# Sentence pair (8) source length 40 target length 40 alignment score : 3.74213e-14
Behind their approaches , there seems to be an assumption that grammatical constructions are not largely different among domains or do not affect parsing systems , and therefore the same parsing system can be applied to a novel domain . 
NULL ({ }) Underlying ({ 1 }) these ({ 2 }) approaches ({ 3 }) , ({ 4 }) there ({ 5 }) seems ({ 6 }) to ({ 7 }) be ({ 8 }) the ({ 9 }) assumption ({ 10 }) that ({ 11 }) grammatical ({ 12 }) constructions ({ 13 }) are ({ 14 }) not ({ 15 }) largely ({ 16 }) different ({ 17 }) between ({ 18 }) domains ({ 19 }) or ({ 20 }) do ({ 21 }) not ({ 22 }) affect ({ 23 }) parsing ({ 24 }) systems ({ 25 }) , ({ 26 }) and ({ 27 }) therefore ({ 28 }) the ({ 29 }) same ({ 30 }) parsing ({ 31 }) system ({ 32 }) can ({ 33 }) be ({ 34 }) applied ({ 35 }) to ({ 36 }) a ({ 37 }) novel ({ 38 }) domain ({ 39 }) . ({ 40 }) 
# Sentence pair (9) source length 28 target length 25 alignment score : 2.99299e-12
However , there are some cases where we cannot achieve as high parsing accuracies as parsing the Penn Treebank just by re-training or adaptation . 
NULL ({ }) However ({ 1 }) , ({ 2 }) there ({ 3 }) are ({ 4 }) some ({ 5 }) cases ({ 6 }) where ({ 7 }) we ({ 8 }) cannot ({ 9 }) achieve ({ 10 }) such ({ 11 }) high ({ 12 }) parsing ({ 13 }) accuracy ({ 14 }) as ({ 15 }) parsing ({ 16 }) the ({ 17 }) Penn ({ 18 }) Treebank ({ 19 }) ( ({ }) PTB ({ 20 }) ) ({ }) merely ({ }) by ({ 21 }) re-training ({ 22 }) or ({ 23 }) adaptation ({ 24 }) . ({ 25 }) 
# Sentence pair (10) source length 45 target length 39 alignment score : 1.32748e-14
For example , the parsing accuracy for the Brown corpus is significantly lower than for the WSJ portion of the Penn Treebank , even when re-training the parser with much more in-domain training data than other successful domains . 
NULL ({ }) For ({ 1 }) example ({ 2 }) , ({ 3 }) the ({ 4 }) parsing ({ 5 }) accuracy ({ 6 }) for ({ 7 }) the ({ 8 }) Brown ({ 9 }) corpus ({ 10 }) is ({ 11 }) significantly ({ 12 }) lower ({ 13 }) than ({ 14 }) that ({ }) for ({ 15 }) the ({ 16 }) Wall ({ }) Street ({ }) Journal ({ }) ( ({ }) WSJ ({ 17 }) ) ({ }) portion ({ 18 }) of ({ 19 }) the ({ 20 }) Penn ({ 21 }) Treebank ({ 22 }) , ({ 23 }) even ({ 24 }) when ({ 25 }) re-training ({ 26 }) the ({ 27 }) parser ({ 28 }) with ({ 29 }) much ({ 30 }) more ({ 31 }) in-domain ({ 32 }) training ({ 33 }) data ({ 34 }) than ({ 35 }) other ({ 36 }) successful ({ 37 }) domains ({ 38 }) . ({ 39 }) 
# Sentence pair (11) source length 34 target length 34 alignment score : 1.15696e-13
This research attempts to identify the cause of these difficulties , and focuses on two types of sentence constructions which were not extensively studied in the recent parsing research : imperatives and questions . 
NULL ({ 26 }) This ({ 1 }) research ({ 2 }) attempts ({ 3 }) to ({ 4 }) identify ({ 5 }) the ({ 6 }) cause ({ 7 }) of ({ 8 }) these ({ 9 }) difficulties ({ 10 }) , ({ 11 }) and ({ 12 }) focuses ({ 13 }) on ({ 14 }) two ({ 15 }) types ({ 16 }) of ({ 17 }) sentence ({ 18 }) constructions ({ 19 }) that ({ 20 }) have ({ 21 }) not ({ 22 }) been ({ }) extensively ({ 23 }) studied ({ 24 }) in ({ 25 }) recent ({ 27 }) parsing ({ 28 }) research ({ 29 }) : ({ 30 }) imperatives ({ 31 }) and ({ 32 }) questions ({ 33 }) . ({ 34 }) 
# Sentence pair (12) source length 18 target length 17 alignment score : 1.34405e-07
In these constructions , words in some syntactic positions disappear or the orders of words change . 
NULL ({ }) In ({ 1 }) these ({ 2 }) constructions ({ 3 }) , ({ 4 }) words ({ 5 }) in ({ 6 }) certain ({ 7 }) syntactic ({ 8 }) positions ({ 9 }) disappear ({ 10 }) or ({ 11 }) the ({ 12 }) order ({ 13 }) of ({ 14 }) the ({ }) words ({ 15 }) changes ({ 16 }) . ({ 17 }) 
# Sentence pair (13) source length 22 target length 22 alignment score : 7.04337e-05
We analyze how such sentences affect the parsing behavior and then attempt to clarify the difficulties in parsing imperatives and questions . 
NULL ({ }) We ({ 1 }) analyze ({ 2 }) how ({ 3 }) such ({ 4 }) sentences ({ 5 }) affect ({ 6 }) the ({ 7 }) parsing ({ 8 }) behavior ({ 9 }) and ({ 10 }) then ({ 11 }) attempt ({ 12 }) to ({ 13 }) clarify ({ 14 }) the ({ 15 }) difficulties ({ 16 }) in ({ 17 }) parsing ({ 18 }) imperatives ({ 19 }) and ({ 20 }) questions ({ 21 }) . ({ 22 }) 
# Sentence pair (14) source length 26 target length 27 alignment score : 1.79724e-11
In order to do so , we prepare an annotated corpus for each of the two sentence constructions by borrowing sentences from fiction and query domains . 
NULL ({ 3 }) To ({ 1 }) do ({ 4 }) so ({ 5 }) , ({ 6 }) we ({ 7 }) first ({ 2 }) prepare ({ 8 }) an ({ 9 }) annotated ({ 10 }) corpus ({ 11 }) for ({ 12 }) each ({ 13 }) of ({ 14 }) the ({ 15 }) two ({ 16 }) sentence ({ 17 }) constructions ({ 18 }) by ({ 19 }) borrowing ({ 20 }) sentences ({ 21 }) from ({ 22 }) fiction ({ 23 }) and ({ 24 }) query ({ 25 }) domains ({ 26 }) . ({ 27 }) 
# Sentence pair (15) source length 35 target length 34 alignment score : 4.66676e-17
In the experiments , parsing accuracies of two shallow dependency parsers and a deep parser are examined for imperatives and questions , as well as the accuracies of a part-of-speech tagger for them . 
NULL ({ 32 }) In ({ 1 }) the ({ 2 }) experiments ({ 3 }) , ({ 4 }) parsing ({ 5 }) accuracies ({ 6 }) of ({ 7 }) two ({ 8 }) shallow ({ 9 }) dependency ({ 10 }) parsers ({ 11 }) and ({ 12 }) a ({ 13 }) deep ({ 14 }) parser ({ 15 }) are ({ 16 }) examined ({ 17 }) for ({ 18 }) imperatives ({ 19 }) and ({ 20 }) questions ({ 21 }) , ({ 22 }) as ({ 23 }) well ({ 24 }) as ({ 25 }) the ({ 26 }) accuracy ({ 27 }) of ({ 28 }) their ({ 29 }) part-of-speech ({ 30 }) ( ({ }) POS ({ }) ) ({ 33 }) tagger ({ 31 }) . ({ 34 }) 
# Sentence pair (16) source length 16 target length 16 alignment score : 0.00129573
A conventional supervised adaptation technique was applied to these parsers and to the POS tagger . 
NULL ({ }) A ({ 1 }) conventional ({ 2 }) supervised ({ 3 }) adaptation ({ 4 }) technique ({ 5 }) was ({ 6 }) applied ({ 7 }) to ({ 8 }) these ({ 9 }) parsers ({ 10 }) and ({ 11 }) to ({ 12 }) the ({ 13 }) POS ({ 14 }) tagger ({ 15 }) . ({ 16 }) 
# Sentence pair (17) source length 30 target length 33 alignment score : 8.9579e-22
Since domain adaptation has been an extensive research area in parsing research \CITE , a lot of ideas have been proposed , including un- / semi-supervised approaches \CITE and supervised approaches \CITE . 
NULL ({ 4 15 17 }) Since ({ 1 }) domain ({ 2 }) adaptation ({ 3 }) is ({ 5 }) an ({ 6 }) extensive ({ 7 }) research ({ 8 }) area ({ 9 }) in ({ 10 }) parsing ({ 11 }) research ({ 12 }) \CITE ({ 13 }) , ({ 14 }) many ({ 16 }) ideas ({ 18 }) have ({ 19 }) been ({ 20 }) proposed ({ 21 }) , ({ 22 }) including ({ 23 }) un- ({ 24 }) or ({ }) semi-supervised ({ 25 26 }) approaches ({ 27 }) \CITE ({ 28 }) and ({ 29 }) supervised ({ 30 }) approaches ({ 31 }) \CITE ({ 32 }) . ({ 33 }) 
# Sentence pair (18) source length 42 target length 38 alignment score : 3.57973e-15
Their main focus was on adapting parsing models trained with a specific genre of text ( in most cases Penn Treebank WSJ ) to other genres of text , such as biomedical research papers and broadcast news . 
NULL ({ }) The ({ 1 }) main ({ 2 }) focus ({ 3 }) of ({ }) these ({ }) works ({ 4 }) is ({ }) on ({ 5 }) adapting ({ 6 }) parsing ({ 7 }) models ({ 8 }) trained ({ 9 }) with ({ 10 }) a ({ 11 }) specific ({ 12 }) genre ({ 13 }) of ({ 14 }) text ({ 15 }) ( ({ 16 }) in ({ 17 }) most ({ 18 }) cases ({ 19 }) the ({ }) Penn ({ 20 }) Treebank ({ 21 }) WSJ ({ 22 }) ) ({ 23 }) to ({ 24 }) other ({ 25 }) genres ({ 26 }) of ({ 27 }) text ({ 28 }) , ({ 29 }) such ({ 30 }) as ({ 31 }) biomedical ({ 32 }) research ({ 33 }) papers ({ 34 }) and ({ 35 }) broadcast ({ 36 }) news ({ 37 }) . ({ 38 }) 
# Sentence pair (19) source length 19 target length 21 alignment score : 8.66091e-17
A major problem tackled in such a task setting is the handling of unknown words and domain-specific ways of expressions . 
NULL ({ }) The ({ 1 }) major ({ 2 }) problem ({ 3 }) tackled ({ 4 8 9 }) in ({ 5 }) such ({ 6 }) tasks ({ 7 }) is ({ 10 }) the ({ 11 }) handling ({ 12 }) of ({ 13 }) unknown ({ 14 }) words ({ 15 }) and ({ 16 }) domain-specific ({ 17 }) manners ({ 18 }) of ({ 19 }) expression ({ 20 }) . ({ 21 }) 
# Sentence pair (20) source length 33 target length 33 alignment score : 5.28098e-07
However , parsing imperatives and questions involves a significantly different problem ; even when all words in a sentence are known , the sentence has a very different structure from declarative sentences . 
NULL ({ }) However ({ 1 }) , ({ 2 }) parsing ({ 3 }) imperatives ({ 4 }) and ({ 5 }) questions ({ 6 }) involves ({ 7 }) a ({ 8 }) significantly ({ 9 }) different ({ 10 }) problem ({ 11 }) ; ({ 12 }) even ({ 13 }) when ({ 14 }) all ({ 15 }) words ({ 16 }) in ({ 17 }) a ({ 18 }) sentence ({ 19 }) are ({ 20 }) known ({ 21 }) , ({ 22 }) the ({ 23 }) sentence ({ 24 }) has ({ 25 }) a ({ 26 }) very ({ 27 }) different ({ 28 }) structure ({ 29 }) from ({ 30 }) declarative ({ 31 }) sentences ({ 32 }) . ({ 33 }) 
# Sentence pair (21) source length 16 target length 16 alignment score : 0.000838108
Compared to domain adaptation , structural types of sentences have gained little attention to date . 
NULL ({ }) Compared ({ 1 }) to ({ 2 }) domain ({ 3 }) adaptation ({ 4 }) , ({ 5 }) structural ({ 6 }) types ({ 7 }) of ({ 8 }) sentences ({ 9 }) have ({ 10 }) received ({ 11 }) little ({ 12 }) attention ({ 13 }) to ({ 14 }) date ({ 15 }) . ({ 16 }) 
# Sentence pair (22) source length 10 target length 10 alignment score : 0.00665673
A notable exception is the work on QuestionBank \CITE . 
NULL ({ }) A ({ 1 }) notable ({ 2 }) exception ({ 3 }) is ({ 4 }) the ({ 5 }) work ({ 6 }) on ({ 7 }) QuestionBank ({ 8 }) \CITE ({ 9 }) . ({ 10 }) 
# Sentence pair (23) source length 26 target length 25 alignment score : 9.06853e-11
The work pointed out low accuracy of state-of-the-art parsers on questions , and proposed supervised parser adaptation by manually creating a treebank of questions . 
NULL ({ }) This ({ 1 }) work ({ 2 }) highlighted ({ 3 4 }) the ({ }) low ({ 5 }) accuracy ({ 6 }) of ({ 7 }) state-of-the-art ({ 8 }) parsers ({ 9 }) on ({ 10 }) questions ({ 11 }) , ({ 12 }) and ({ 13 }) proposed ({ 14 }) a ({ }) supervised ({ 15 }) parser ({ 16 }) adaptation ({ 17 }) by ({ 18 }) manually ({ 19 }) creating ({ 20 }) a ({ 21 }) treebank ({ 22 }) of ({ 23 }) questions ({ 24 }) . ({ 25 }) 
# Sentence pair (24) source length 24 target length 24 alignment score : 0.000108362
The question sentences are annotated with phrase structure trees in the Penn Treebank scheme , although function tags and empty categories are omitted . 
NULL ({ }) The ({ 1 }) question ({ 2 }) sentences ({ 3 }) are ({ 4 }) annotated ({ 5 }) with ({ 6 }) phrase ({ 7 }) structure ({ 8 }) trees ({ 9 }) in ({ 10 }) the ({ 11 }) Penn ({ 12 }) Treebank ({ 13 }) scheme ({ 14 }) , ({ 15 }) although ({ 16 }) function ({ 17 }) tags ({ 18 }) and ({ 19 }) empty ({ 20 }) categories ({ 21 }) are ({ 22 }) omitted ({ 23 }) . ({ 24 }) 
# Sentence pair (25) source length 21 target length 21 alignment score : 2.94368e-08
QuestionBank was used for the supervised training of an LFG parser , and achieved a significant improvement in parsing accuracy . 
NULL ({ }) QuestionBank ({ 1 }) was ({ 2 }) used ({ 3 }) for ({ 4 }) the ({ 5 }) supervised ({ 6 }) training ({ 7 }) of ({ 8 }) an ({ 9 }) LFG ({ 10 }) parser ({ 11 }) , ({ 12 }) resulting ({ 13 }) in ({ 14 }) a ({ 15 }) significant ({ 16 }) improvement ({ 17 }) in ({ 18 }) parsing ({ 19 }) accuracy ({ 20 }) . ({ 21 }) 
# Sentence pair (26) source length 21 target length 20 alignment score : 4.27944e-24
They collected question sentences from TREC 9-12 competitions , and annotated these sentences with POSs and CCG lexical categories . 
NULL ({ }) In ({ 1 }) this ({ }) work ({ }) , ({ 9 }) question ({ 3 }) sentences ({ 4 }) were ({ }) collected ({ 2 }) from ({ 5 }) TREC ({ 6 12 13 }) 9-12 ({ 7 }) competitions ({ 8 }) and ({ 10 }) annotated ({ 11 }) with ({ 14 }) POS ({ 15 }) and ({ 16 }) CCG ({ 17 }) lexical ({ 18 }) categories ({ 19 }) . ({ 20 }) 
# Sentence pair (27) source length 14 target length 13 alignment score : 0.000198891
They reported a significant improvement in CCG parsing without phrase structure annotations . 
NULL ({ }) The ({ }) authors ({ 1 }) reported ({ 2 }) a ({ 3 }) significant ({ 4 }) improvement ({ 5 }) in ({ 6 }) CCG ({ 7 }) parsing ({ 8 }) without ({ 9 }) phrase ({ 10 }) structure ({ 11 }) annotations ({ 12 }) . ({ 13 }) 
# Sentence pair (28) source length 17 target length 17 alignment score : 0.000870617
Our work further extends \CITE and \CITE , while covering a wider range of sentence constructions . 
NULL ({ }) Our ({ 1 }) work ({ 2 }) further ({ 3 }) extends ({ 4 }) \CITE ({ 5 }) and ({ 6 }) \CITE ({ 7 }) , ({ 8 }) while ({ 9 }) covering ({ 10 }) a ({ 11 }) wider ({ 12 }) range ({ 13 }) of ({ 14 }) sentence ({ 15 }) constructions ({ 16 }) . ({ 17 }) 
# Sentence pair (29) source length 25 target length 27 alignment score : 8.59086e-11
Although QuestionBank and the resource of \CITE are claimed to be a corpus of questions , they are biased because the sentences come from QA queries . 
NULL ({ 8 12 }) Although ({ 1 }) QuestionBank ({ 2 }) and ({ 3 }) the ({ 4 }) resource ({ 5 }) of ({ 6 }) \CITE ({ 7 }) claim ({ 9 }) to ({ 10 }) be ({ 11 }) corpora ({ 13 }) of ({ 14 }) questions ({ 15 }) , ({ 16 }) they ({ 17 }) are ({ 18 }) biased ({ 19 }) because ({ 20 }) the ({ 21 }) sentences ({ 22 }) come ({ 23 }) from ({ 24 }) QA ({ 25 }) queries ({ 26 }) . ({ 27 }) 
# Sentence pair (30) source length 15 target length 15 alignment score : 0.000107536
For example , such queries rarely include yes / no questions and tag questions . 
NULL ({ }) For ({ 1 }) example ({ 2 }) , ({ 3 }) such ({ 4 }) queries ({ 5 }) rarely ({ 6 }) include ({ 7 }) yes ({ 8 }) / ({ 9 }) no ({ 10 }) questions ({ 11 }) or ({ 12 }) tag ({ 13 }) questions ({ 14 }) . ({ 15 }) 
# Sentence pair (31) source length 24 target length 24 alignment score : 6.05483e-07
In our work , sentences are collected from the Brown corpus , which includes a wider range of types of questions and imperatives . 
NULL ({ }) For ({ 1 }) our ({ 2 }) study ({ 3 }) , ({ 4 }) sentences ({ 5 }) were ({ 6 }) collected ({ 7 }) from ({ 8 }) the ({ 9 }) Brown ({ 10 }) corpus ({ 11 }) , ({ 12 }) which ({ 13 }) includes ({ 14 }) a ({ 15 }) wider ({ 16 }) range ({ 17 }) of ({ 18 }) types ({ 19 }) of ({ 20 }) questions ({ 21 }) and ({ 22 }) imperatives ({ 23 }) . ({ 24 }) 
# Sentence pair (32) source length 11 target length 12 alignment score : 6.32892e-10
In the experiments , we will additionally use QuestionBank for comparison . 
NULL ({ }) In ({ 1 }) the ({ 2 }) experiments ({ 3 }) , ({ 4 }) we ({ 5 }) also ({ 6 7 }) used ({ 8 }) QuestionBank ({ 9 }) for ({ 10 }) comparison ({ 11 }) . ({ 12 }) 
# Sentence pair (33) source length 18 target length 18 alignment score : 0.00193997
We examined the performance of two dependency parsers and a deep parser on the target text sets . 
NULL ({ }) We ({ 1 }) examined ({ 2 }) the ({ 3 }) performance ({ 4 }) of ({ 5 }) two ({ 6 }) dependency ({ 7 }) parsers ({ 8 }) and ({ 9 }) a ({ 10 }) deep ({ 11 }) parser ({ 12 }) on ({ 13 }) the ({ 14 }) target ({ 15 }) text ({ 16 }) sets ({ 17 }) . ({ 18 }) 
# Sentence pair (34) source length 10 target length 10 alignment score : 0.00426473
All parsers assume that the input is already POS-tagged . 
NULL ({ }) All ({ 1 }) parsers ({ 2 }) assumed ({ 3 }) that ({ 4 }) the ({ 5 }) input ({ 6 }) was ({ 7 }) already ({ 8 }) POS-tagged ({ 9 }) . ({ 10 }) 
# Sentence pair (35) source length 7 target length 7 alignment score : 1.21726e-05
We use a tagger in \CITE . 
NULL ({ }) We ({ 1 }) used ({ 2 }) the ({ 3 }) tagger ({ 4 }) in ({ 5 }) \CITE ({ 6 }) . ({ 7 }) 
# Sentence pair (36) source length 27 target length 27 alignment score : 2.54022e-10
The MST parser and Malt parser are dependency parsers that produce non-projective dependency trees , using the spanning tree algorithm \CITE and transition-based algorithm \CITE respectively . 
NULL ({ }) The ({ 1 }) MST ({ 2 3 }) and ({ 4 }) Malt ({ 5 }) parsers ({ 6 }) are ({ 7 }) dependency ({ 8 }) parsers ({ 9 }) that ({ 10 }) produce ({ 11 }) non-projective ({ 12 }) dependency ({ 13 }) trees ({ 14 }) , ({ 15 }) using ({ 16 }) the ({ 17 }) spanning ({ 18 }) tree ({ 19 }) algorithm ({ 20 }) \CITE ({ 21 }) and ({ 22 }) transition-based ({ 23 }) algorithm ({ 24 }) \CITE ({ 25 }) , ({ }) respectively ({ 26 }) . ({ 27 }) 
# Sentence pair (37) source length 45 target length 46 alignment score : 2.34103e-15
Although the publicly available implementation of each parser also has an option to restrict the output to be a projective dependency tree , we used the non-projective version because the dependency structures converted from the question sentences in the Brown corpus included many non-projective dependencies . 
NULL ({ 18 }) Although ({ 1 }) the ({ 2 }) publicly ({ 3 }) available ({ 4 }) implementation ({ 5 }) of ({ 6 }) each ({ 7 }) parser ({ 8 }) also ({ 9 }) has ({ 10 }) the ({ 11 }) option ({ 12 }) to ({ 13 }) restrict ({ 14 }) the ({ 15 }) output ({ 16 }) to ({ 17 }) a ({ 19 }) projective ({ 20 }) dependency ({ 21 }) tree ({ 22 }) , ({ 23 }) we ({ 24 }) used ({ 25 }) the ({ 26 }) non-projective ({ 27 }) versions ({ 28 }) because ({ 29 }) the ({ 30 }) dependency ({ 31 }) structures ({ 32 }) converted ({ 33 }) from ({ 34 }) the ({ 35 }) question ({ 36 }) sentences ({ 37 }) in ({ 38 }) the ({ 39 }) Brown ({ 40 }) corpus ({ 41 }) included ({ 42 }) many ({ 43 }) non-projective ({ 44 }) dependencies ({ 45 }) . ({ 46 }) 
# Sentence pair (38) source length 14 target length 13 alignment score : 0.00015309
We used pennconverter \CITE to convert a PTB-style treebank to dependency trees . 
NULL ({ }) We ({ 1 }) used ({ 2 }) the ({ }) pennconverter ({ 3 }) \CITE ({ 4 }) to ({ 5 }) convert ({ 6 }) a ({ 7 }) PTB-style ({ 8 }) treebank ({ 9 }) into ({ 10 }) dependency ({ 11 }) trees ({ 12 }) . ({ 13 }) 
# Sentence pair (39) source length 19 target length 25 alignment score : 1.37119e-26
For the evaluation of the output from each of the MST and Malt parser , we used the labeled attachment accuracy excluding the punctuations . 
NULL ({ 2 12 23 }) To ({ 1 }) evaluate ({ 4 }) the ({ 5 }) output ({ 6 }) from ({ 7 }) each ({ 8 }) of ({ 9 }) the ({ 10 }) parsers ({ 11 }) , ({ 15 }) we ({ 16 }) used ({ 17 }) the ({ 18 }) labeled ({ 19 }) attachment ({ 20 }) accuracy ({ 21 }) excluding ({ 13 22 }) punctuation ({ 3 14 24 }) . ({ 25 }) 
# Sentence pair (40) source length 21 target length 14 alignment score : 7.60504e-11
The Enju parser \CITE is a deep parser based on the HPSG formalism . 
NULL ({ }) The ({ 1 }) Enju ({ 2 }) parser ({ 3 }) \CITE ({ 4 }) is ({ 5 }) a ({ 6 }) deep ({ 7 }) parser ({ 8 }) based ({ 9 }) on ({ 10 }) the ({ }) HPSG ({ }) ( ({ }) Head ({ }) Driven ({ }) Phrase ({ }) Structure ({ 11 }) Grammar ({ 12 }) ) ({ }) formalism ({ 13 }) . ({ 14 }) 
# Sentence pair (41) source length 29 target length 30 alignment score : 1.43694e-09
It produces an analysis of a sentence that includes the syntactic structure ( i.e. , parse tree ) and the semantic structure represented as a set of predicate-argument dependencies . 
NULL ({ 8 }) It ({ 1 }) produces ({ 2 }) an ({ 3 }) analysis ({ 4 }) of ({ 5 }) a ({ 6 }) sentence ({ 7 }) including ({ 9 }) the ({ 10 }) syntactic ({ 11 }) structure ({ 12 }) ( ({ 13 }) i.e. ({ 14 }) , ({ 15 }) parse ({ 16 }) tree ({ 17 }) ) ({ 18 }) and ({ 19 }) the ({ 20 }) semantic ({ 21 }) structure ({ 22 }) represented ({ 23 }) as ({ 24 }) a ({ 25 }) set ({ 26 }) of ({ 27 }) predicate-argument ({ 28 }) dependencies ({ 29 }) . ({ 30 }) 
# Sentence pair (42) source length 18 target length 18 alignment score : 3.20461e-08
We used a toolkit distributed with the Enju parser for training the parser with a PTB-style treebank . 
NULL ({ 3 }) We ({ 1 }) used ({ 2 }) the ({ }) toolkit ({ 4 }) distributed ({ 5 }) with ({ 6 }) the ({ 7 }) Enju ({ 8 }) parser ({ 9 }) to ({ 10 }) train ({ 11 }) the ({ 12 }) parser ({ 13 }) with ({ 14 }) a ({ 15 }) PTB-style ({ 16 }) treebank ({ 17 }) . ({ 18 }) 
# Sentence pair (43) source length 19 target length 19 alignment score : 2.86501e-07
The toolkit initially converts the PTB-style treebank into an HPSG treebank and then trains the parser on it . 
NULL ({ 5 }) The ({ 1 }) toolkit ({ 2 }) initially ({ 3 }) converts ({ 4 }) a ({ }) PTB-style ({ 6 }) treebank ({ 7 }) into ({ 8 }) an ({ 9 }) HPSG ({ 10 }) treebank ({ 11 }) and ({ 12 }) then ({ 13 }) trains ({ 14 }) the ({ 15 }) parser ({ 16 }) on ({ 17 }) this ({ 18 }) . ({ 19 }) 
# Sentence pair (44) source length 17 target length 17 alignment score : 0.00097925
The HPSG treebank converted from the test section was used as the gold-standard in the evaluation . 
NULL ({ }) The ({ 1 }) HPSG ({ 2 }) treebank ({ 3 }) converted ({ 4 }) from ({ 5 }) the ({ 6 }) test ({ 7 }) section ({ 8 }) was ({ 9 }) used ({ 10 }) as ({ 11 }) the ({ 12 }) gold-standard ({ 13 }) in ({ 14 }) the ({ 15 }) evaluation ({ 16 }) . ({ 17 }) 
# Sentence pair (45) source length 27 target length 28 alignment score : 1.00427e-07
As the evaluation metrics of the Enju parser , we used labeled and unlabeled precision / recall / F-score of the predicate-argument dependencies produced by the parser . 
NULL ({ 2 }) As ({ 1 }) evaluation ({ 3 }) metrics ({ 4 }) for ({ 5 }) the ({ 6 }) Enju ({ 7 }) parser ({ 8 }) , ({ 9 }) we ({ 10 }) used ({ 11 }) labeled ({ 12 }) and ({ 13 }) unlabeled ({ 14 }) precision ({ 15 }) / ({ 16 }) recall ({ 17 }) / ({ 18 }) F-score ({ 19 }) of ({ 20 }) the ({ 21 }) predicate-argument ({ 22 }) dependencies ({ 23 }) produced ({ 24 }) by ({ 25 }) the ({ 26 }) parser ({ 27 }) . ({ 28 }) 
# Sentence pair (46) source length 20 target length 23 alignment score : 3.84884e-12
This section explains how we collected the treebanks of imperatives and questions , which were used in the experiments in Section \REF . 
NULL ({ 13 }) This ({ 1 }) section ({ 2 }) explains ({ 3 }) how ({ 4 }) we ({ 5 }) collected ({ 6 }) the ({ 7 }) treebanks ({ 8 14 15 }) of ({ 9 }) imperatives ({ 10 }) and ({ 11 }) questions ({ 12 }) used ({ 16 }) in ({ 17 }) the ({ 18 }) experiments ({ 19 }) in ({ 20 }) Section ({ 21 }) \REF ({ 22 }) . ({ 23 }) 
# Sentence pair (47) source length 12 target length 11 alignment score : 0.000489383
Penn Treebank 3 contains treebanks of several genres of texts . 
NULL ({ }) The ({ }) Penn ({ 1 }) Treebank ({ 2 }) 3 ({ 3 }) contains ({ 4 }) treebanks ({ 5 }) of ({ 6 }) several ({ 7 }) genres ({ 8 }) of ({ 9 }) texts ({ 10 }) . ({ 11 }) 
# Sentence pair (48) source length 24 target length 29 alignment score : 3.62584e-26
While the Wall Street Journal ( WSJ ) treebank has extensively been used for parsing experiments , we use the treebank of the Brown Corpus in our experiments . 
NULL ({ }) Although ({ 1 }) the ({ 2 }) WSJ ({ 3 7 8 }) treebank ({ 4 9 }) has ({ 10 }) been ({ 12 }) used ({ 13 }) extensively ({ 5 6 11 }) for ({ 14 }) parsing ({ 15 }) experiments ({ 16 }) , ({ 17 }) we ({ 18 }) used ({ 19 }) the ({ 20 }) treebank ({ 21 }) of ({ 22 }) the ({ 23 }) Brown ({ 24 }) Corpus ({ 25 }) in ({ 26 }) our ({ 27 }) experiments ({ 28 }) . ({ 29 }) 
# Sentence pair (49) source length 29 target length 30 alignment score : 6.41359e-14
Because the Brown Corpus portion includes texts of literary works , it is expected that it inherently contains a larger number of imperatives and questions than the WSJ portion . 
NULL ({ 15 }) As ({ 1 }) the ({ 2 }) Brown ({ 3 }) Corpus ({ 4 }) portion ({ 5 }) includes ({ 6 }) texts ({ 7 }) of ({ 8 }) literary ({ 9 }) works ({ 10 }) , ({ 11 }) it ({ 12 }) is ({ 13 }) expected ({ 14 }) to ({ }) contain ({ 16 }) inherently ({ 17 18 }) a ({ 19 }) larger ({ 20 }) number ({ 21 }) of ({ 22 }) imperatives ({ 23 }) and ({ 24 }) questions ({ 25 }) than ({ 26 }) the ({ 27 }) WSJ ({ 28 }) portion ({ 29 }) . ({ 30 }) 
# Sentence pair (50) source length 22 target length 21 alignment score : 2.87986e-05
The Brown Corpus portion of Penn Treebank 3 is annotated with phrase structure trees as in the Penn Treebank WSJ . 
NULL ({ }) The ({ 1 }) Brown ({ 2 }) Corpus ({ 3 }) portion ({ 4 }) of ({ 5 }) the ({ }) Penn ({ 6 }) Treebank ({ 7 }) 3 ({ 8 }) is ({ 9 }) annotated ({ 10 }) with ({ 11 }) phrase ({ 12 }) structure ({ 13 }) trees ({ 14 }) as ({ 15 }) in ({ 16 }) the ({ 17 }) Penn ({ 18 }) Treebank ({ 19 }) WSJ ({ 20 }) . ({ 21 }) 
# Sentence pair (51) source length 33 target length 33 alignment score : 2.14356e-07
Interrogative sentences are annotated with the phrase label " SBARQ " or " SQ " , where " SBARQ " represents wh-questions , while " SQ " denotes yes / no questions . 
NULL ({ }) Interrogative ({ 1 }) sentences ({ 2 }) are ({ 3 }) annotated ({ 4 }) with ({ 5 }) the ({ 6 }) phrase ({ 7 }) label ({ 8 }) " ({ 9 }) SBARQ ({ 10 }) " ({ 11 }) or ({ 12 }) " ({ 13 }) SQ ({ 14 }) " ({ 15 }) , ({ 16 }) where ({ 17 }) " ({ 18 }) SBARQ ({ 19 }) " ({ 20 }) denotes ({ 21 }) wh-questions ({ 22 }) , ({ 23 }) while ({ 24 }) " ({ 25 }) SQ ({ 26 }) " ({ 27 }) denotes ({ 28 }) yes ({ 29 }) / ({ 30 }) no ({ 31 }) questions ({ 32 }) . ({ 33 }) 
# Sentence pair (52) source length 12 target length 12 alignment score : 0.00547869
Imperative sentences are annotated with the phrase label " S-IMP " . 
NULL ({ }) Imperative ({ 1 }) sentences ({ 2 }) are ({ 3 }) annotated ({ 4 }) with ({ 5 }) the ({ 6 }) phrase ({ 7 }) label ({ 8 }) " ({ 9 }) S-IMP ({ 10 }) " ({ 11 }) . ({ 12 }) 
# Sentence pair (53) source length 10 target length 10 alignment score : 5.98274e-11
We extracted those sentences annotated with these phrase labels . 
NULL ({ 3 }) All ({ 1 }) sentences ({ 4 }) annotated ({ 5 }) with ({ 6 }) these ({ 7 }) phrase ({ 8 }) labels ({ 9 }) were ({ }) extracted ({ 2 }) . ({ 10 }) 
# Sentence pair (54) source length 16 target length 17 alignment score : 9.75552e-08
Imperatives and questions appear not only at the top level but also appear as embedded clauses . 
NULL ({ }) Imperatives ({ 1 }) and ({ 2 }) questions ({ 3 }) appear ({ 4 13 }) not ({ 5 }) only ({ 6 }) at ({ 7 }) the ({ 8 }) top ({ 9 }) level ({ 10 }) but ({ 11 }) also ({ 12 }) as ({ 14 }) embedded ({ 15 }) clauses ({ 16 }) . ({ 17 }) 
# Sentence pair (55) source length 10 target length 10 alignment score : 0.0290406
We extracted such embedded questions and imperatives as well . 
NULL ({ }) We ({ 1 }) extracted ({ 2 }) such ({ 3 }) embedded ({ 4 }) questions ({ 5 }) and ({ 6 }) imperatives ({ 7 }) as ({ 8 }) well ({ 9 }) . ({ 10 }) 
# Sentence pair (56) source length 19 target length 17 alignment score : 7.60388e-13
When they are embedded in another imperative or question , we only extracted the outermost one . 
NULL ({ }) However ({ 1 }) , ({ 2 }) is ({ }) these ({ }) were ({ 3 }) embedded ({ 4 }) in ({ 5 }) another ({ 6 }) imperative ({ 7 }) or ({ 8 }) question ({ 9 }) , ({ 10 }) we ({ 11 }) only ({ 12 }) extracted ({ 13 }) the ({ 14 }) outermost ({ 15 }) one ({ 16 }) . ({ 17 }) 
# Sentence pair (57) source length 27 target length 27 alignment score : 6.74801e-33
Extracted sentences are post-processed so that they have natural sentence forms : first characters are capitalized , and question marks or periods are added when appropriate . 
NULL ({ 15 }) Extracted ({ 1 }) sentences ({ 2 }) were ({ 3 }) post-processed ({ 4 5 }) to ({ }) fit ({ 7 8 12 }) the ({ }) natural ({ 9 }) sentence ({ 10 }) form ({ 11 }) ; ({ }) that ({ 6 }) is ({ }) , ({ 17 }) with ({ }) first ({ 13 }) characters ({ 14 }) capitalized ({ 16 }) and ({ 18 }) question ({ 19 }) marks ({ 20 }) or ({ 21 }) periods ({ 22 23 }) added ({ 24 }) as ({ 25 }) appropriate ({ 26 }) . ({ 27 }) 
# Sentence pair (58) source length 19 target length 19 alignment score : 0.000769866
As a result , we extracted 750 imperative sentences and 1 ,241 question sentences from 24 ,243 sentences . 
NULL ({ }) As ({ 1 }) a ({ 2 }) result ({ 3 }) , ({ 4 }) we ({ 5 }) extracted ({ 6 }) 750 ({ 7 }) imperative ({ 8 }) sentences ({ 9 }) and ({ 10 }) 1 ({ 11 }) ,241 ({ 12 }) question ({ 13 }) sentences ({ 14 }) from ({ 15 }) 24 ({ 16 }) ,243 ({ 17 }) sentences ({ 18 }) . ({ 19 }) 
# Sentence pair (59) source length 10 target length 10 alignment score : 0.00836964
Examples of extracted sentences are shown in Figure \REF . 
NULL ({ }) Examples ({ 1 }) of ({ 2 }) extracted ({ 3 }) sentences ({ 4 }) are ({ 5 }) shown ({ 6 }) in ({ 7 }) Figure ({ 8 }) \REF ({ 9 }) . ({ 10 }) 
# Sentence pair (60) source length 13 target length 13 alignment score : 3.44986e-06
The number of sentences for each section is shown in Table \REF . 
NULL ({ }) The ({ 1 }) numbers ({ 2 }) of ({ 3 }) sentences ({ 4 }) for ({ 5 }) each ({ 6 }) section ({ 7 }) are ({ 8 }) given ({ 9 }) in ({ 10 }) Table ({ 11 }) \REF ({ 12 }) . ({ 13 }) 
# Sentence pair (61) source length 21 target length 22 alignment score : 3.24919e-10
Although we also applied a similar method to the WSJ portion , we could obtain only 115 imperatives and 432 questions . 
NULL ({ 14 }) Although ({ 1 }) we ({ 2 }) also ({ 3 }) applied ({ 4 }) a ({ 5 }) similar ({ 6 }) method ({ 7 }) to ({ 8 }) the ({ 9 }) WSJ ({ 10 }) portion ({ 11 }) , ({ 12 }) we ({ 13 }) only ({ 16 }) obtained ({ 15 }) 115 ({ 17 }) imperatives ({ 18 }) and ({ 19 }) 432 ({ 20 }) questions ({ 21 }) . ({ 22 }) 
# Sentence pair (62) source length 9 target length 10 alignment score : 1.737e-13
We will not use this data in the experiments . 
NULL ({ 5 }) This ({ 1 }) data ({ 6 }) was ({ 2 }) not ({ 3 }) used ({ 4 }) in ({ 7 }) the ({ 8 }) experiments ({ 9 }) . ({ 10 }) 
# Sentence pair (63) source length 12 target length 13 alignment score : 1.83948e-16
As we will describe below , we additionally use QuestionBank in experiments . 
NULL ({ 2 }) As ({ 1 }) described ({ 4 }) below ({ 3 5 }) , ({ 6 }) we ({ 7 }) also ({ 8 }) used ({ 9 }) QuestionBank ({ 10 }) in ({ 11 }) the ({ }) experiments ({ 12 }) . ({ 13 }) 
# Sentence pair (64) source length 46 target length 44 alignment score : 1.58433e-19
However , an advantage of using the Brown treebank is that it includes annotations of function tags and empty categories . Therefore , we can apply the Penn Treebank-to-HPSG conversion program of Enju \CITE , which relies on function tags and empty categories . 
NULL ({ 3 21 }) The ({ }) advantage ({ 4 }) , ({ }) however ({ 1 }) , ({ 2 }) of ({ 5 }) using ({ 6 }) the ({ 7 }) Brown ({ 8 }) treebank ({ 9 }) is ({ 10 }) that ({ 11 }) it ({ 12 }) includes ({ 13 }) annotations ({ 14 }) of ({ 15 }) function ({ 16 }) tags ({ 17 }) and ({ 18 }) empty ({ 19 }) categories ({ 20 }) , ({ }) and ({ }) therefore ({ 22 }) , ({ 23 }) we ({ 24 }) can ({ 25 }) apply ({ 26 }) the ({ 27 }) Penn ({ 28 }) Treebank-to-HPSG ({ 29 }) conversion ({ 30 }) program ({ 31 }) of ({ 32 }) Enju ({ 33 }) \CITE ({ 34 }) , ({ 35 }) which ({ 36 }) relies ({ 37 }) on ({ 38 }) function ({ 39 }) tags ({ 40 }) and ({ 41 }) empty ({ 42 }) categories ({ 43 }) . ({ 44 }) 
# Sentence pair (65) source length 14 target length 15 alignment score : 1.10133e-08
Hence , we will show experimental results on Enju only with the Brown data . 
NULL ({ }) Hence ({ 1 }) , ({ 2 }) we ({ 3 }) show ({ 4 5 }) experimental ({ 6 }) results ({ 7 }) for ({ 8 }) Enju ({ 9 }) only ({ 10 }) with ({ 11 }) the ({ 12 }) Brown ({ 13 }) data ({ 14 }) . ({ 15 }) 
# Sentence pair (66) source length 33 target length 32 alignment score : 1.486e-08
It should also be noted that , a constituency-to-dependency converter , pennconverter \CITE , provides more accurate conversion when function tags and empty categories are available ( See footnote 6 ) . 
NULL ({ }) It ({ 1 }) should ({ 2 }) also ({ 3 }) be ({ 4 }) noted ({ 5 }) that ({ 6 }) , ({ 7 }) a ({ 8 }) constituency-to-dependency ({ 9 }) converter ({ 10 }) , ({ 11 }) pennconverter ({ 12 }) \CITE ({ 13 }) , ({ 14 }) provides ({ 15 }) a ({ }) more ({ 16 }) accurate ({ 17 }) conversion ({ 18 }) when ({ 19 }) function ({ 20 }) tags ({ 21 }) and ({ 22 }) empty ({ 23 }) categories ({ 24 }) are ({ 25 }) available ({ 26 }) ( ({ 27 }) see ({ 28 }) footnote ({ 29 }) 6 ({ 30 }) ) ({ 31 }) . ({ 32 }) 
# Sentence pair (67) source length 17 target length 17 alignment score : 0.00180564
QuestionBank consists of question sentences as well as a small number of imperative and declarative sentences . 
NULL ({ }) QuestionBank ({ 1 }) consists ({ 2 }) of ({ 3 }) question ({ 4 }) sentences ({ 5 }) as ({ 6 }) well ({ 7 }) as ({ 8 }) a ({ 9 }) small ({ 10 }) number ({ 11 }) of ({ 12 }) imperative ({ 13 }) and ({ 14 }) declarative ({ 15 }) sentences ({ 16 }) . ({ 17 }) 
# Sentence pair (68) source length 15 target length 17 alignment score : 3.01389e-08
We extracted 3 ,859 sentences that are annotated with " SBARQ " or " SQ " . 
NULL ({ 6 7 }) We ({ 1 }) extracted ({ 2 }) 3 ({ 3 }) ,859 ({ 4 }) sentences ({ 5 }) annotated ({ 8 }) with ({ 9 }) " ({ 10 }) SBARQ ({ 11 }) " ({ 12 }) or ({ 13 }) " ({ 14 }) SQ ({ 15 }) " ({ 16 }) . ({ 17 }) 
# Sentence pair (69) source length 18 target length 16 alignment score : 1.38452e-06
During experiments , we found several annotation errors that caused fatal errors of treebank conversion . 
NULL ({ }) During ({ 1 }) the ({ }) experiments ({ 2 }) , ({ 3 }) we ({ 4 }) found ({ 5 }) several ({ 6 }) annotation ({ 7 }) errors ({ 8 }) that ({ 9 }) caused ({ 10 }) fatal ({ 11 }) errors ({ 12 }) in ({ 13 }) the ({ }) treebank ({ 14 }) conversion ({ 15 }) . ({ 16 }) 
# Sentence pair (70) source length 9 target length 9 alignment score : 4.08911e-09
We therefore corrected annotations of twelve sentences manually . 
NULL ({ }) We ({ 1 }) manually ({ 2 }) corrected ({ 3 }) the ({ }) annotations ({ 4 }) of ({ 5 }) twelve ({ 6 8 }) sentences ({ 7 }) . ({ 9 }) 
# Sentence pair (71) source length 8 target length 9 alignment score : 4.42735e-06
We plan to make these corrections publicly available . 
NULL ({ 3 }) We ({ 1 }) intend ({ 2 }) making ({ 4 }) these ({ 5 }) corrections ({ 6 }) publicly ({ 7 }) available ({ 8 }) . ({ 9 }) 
# Sentence pair (72) source length 16 target length 16 alignment score : 0.00162338
Examples of the annotation errors include brackets enclosing empty words and undefined or empty tags . 
NULL ({ }) Examples ({ 1 }) of ({ 2 }) the ({ 3 }) annotation ({ 4 }) errors ({ 5 }) include ({ 6 }) brackets ({ 7 }) enclosing ({ 8 }) empty ({ 9 }) words ({ 10 }) and ({ 11 }) undefined ({ 12 }) or ({ 13 }) empty ({ 14 }) tags ({ 15 }) . ({ 16 }) 
# Sentence pair (73) source length 57 target length 57 alignment score : 5.35542e-23
We also found and corrected obvious inconsistencies in the corpus : character " ' " replaced by " $<$ " ( 737 sentences ) , token " ? " tagged not with " . " but with " ? " ( 2 ,051 sentences ) , and phrase labels annotated as POS ( one sentence ) . 
NULL ({ }) We ({ 1 }) also ({ 2 }) found ({ 3 }) and ({ 4 }) corrected ({ 5 }) obvious ({ 6 }) inconsistencies ({ 7 }) in ({ 8 }) the ({ 9 }) corpus ({ 10 }) : ({ 11 }) character ({ 12 }) " ({ 13 }) ' ({ 14 }) " ({ 15 }) replaced ({ 16 }) by ({ 17 }) " ({ 18 }) $<$ ({ 19 }) " ({ 20 }) ( ({ 21 }) 737 ({ 22 }) sentences ({ 23 }) ) ({ 24 }) , ({ 25 }) token ({ 26 }) " ({ 27 }) ? ({ 28 }) " ({ 29 }) tagged ({ 30 36 }) with ({ 37 }) " ({ 38 }) ? ({ 39 }) " ({ 40 }) instead ({ 31 }) of ({ 32 }) " ({ 33 }) . ({ 34 }) " ({ 35 }) ( ({ 41 }) 2 ({ 42 }) ,051 ({ 43 }) sentences ({ 44 }) ) ({ 45 }) , ({ 46 }) and ({ 47 }) phrase ({ 48 }) labels ({ 49 }) annotated ({ 50 }) as ({ 51 }) the ({ }) POS ({ 52 }) ( ({ 53 }) one ({ 54 }) sentence ({ 55 }) ) ({ 56 }) . ({ 57 }) 
# Sentence pair (74) source length 22 target length 21 alignment score : 1.77034e-08
We examined performances of the three parsers and the POS tagger for Brown imperatives and questions , and QuestionBank questions . 
NULL ({ }) We ({ 1 }) examined ({ 2 }) the ({ }) performance ({ 3 }) of ({ 4 }) the ({ 5 }) three ({ 6 }) parsers ({ 7 }) and ({ 8 }) the ({ 9 }) POS ({ 10 }) tagger ({ 11 }) with ({ 12 }) Brown ({ 13 }) imperatives ({ 14 }) and ({ 15 }) questions ({ 16 }) , ({ 17 }) and ({ 18 }) QuestionBank ({ 19 }) questions ({ 20 }) . ({ 21 }) 
# Sentence pair (75) source length 26 target length 27 alignment score : 2.6643e-18
By observing the effects of parser or tagger adaptation to each domain , we would like to see the difficulties in parsing imperative and question sentences . 
NULL ({ }) By ({ 1 }) observing ({ 2 15 16 }) the ({ 3 }) effect ({ 4 }) of ({ 5 }) the ({ }) parser ({ 6 }) or ({ 7 }) tagger ({ 8 }) adaptation ({ 9 }) in ({ 10 }) each ({ 11 }) domain ({ 12 }) , ({ 13 }) we ({ 14 }) can ({ 17 }) identify ({ 18 }) the ({ 19 }) difficulties ({ 20 }) in ({ 21 }) parsing ({ 22 }) imperative ({ 23 }) and ({ 24 }) question ({ 25 }) sentences ({ 26 }) . ({ 27 }) 
# Sentence pair (76) source length 21 target length 20 alignment score : 6.05087e-05
We also examined the portability of sentence construction properties between two similar domains : questions in Brown and QuestionBank . 
NULL ({ }) We ({ 1 }) also ({ 2 }) examined ({ 3 }) the ({ 4 }) portability ({ 5 }) of ({ 6 }) sentence ({ 7 }) construction ({ 8 }) properties ({ 9 }) between ({ 10 }) two ({ 11 }) similar ({ 12 }) domains ({ 13 }) : ({ 14 }) questions ({ 15 }) in ({ 16 }) Brown ({ 17 }) and ({ 18 }) in ({ }) QuestionBank ({ 19 }) . ({ 20 }) 
# Sentence pair (77) source length 23 target length 29 alignment score : 4.31315e-25
We made experimental datasets for five domains : Wall Street Journal ( WSJ ) , Brown overall sentences , Brown imperatives , Brown questions , and QuestionBank questions . 
NULL ({ 19 }) We ({ 1 }) created ({ 2 10 11 }) experimental ({ 3 }) datasets ({ 4 }) for ({ 5 }) five ({ 6 }) domains ({ 7 }) : ({ 8 }) WSJ ({ 9 13 14 }) , ({ 15 }) Brown ({ 16 }) overall ({ 12 17 18 }) , ({ }) Brown ({ 20 }) imperatives ({ 21 }) , ({ 22 }) Brown ({ 23 }) questions ({ 24 }) , ({ 25 }) and ({ 26 }) QuestionBank ({ 27 }) questions ({ 28 }) . ({ 29 }) 
# Sentence pair (78) source length 6 target length 6 alignment score : 0.130606
WSJ ( 43 ,948 sentences ) 
NULL ({ }) WSJ ({ 1 }) ( ({ 2 }) 43 ({ 3 }) ,948 ({ 4 }) sentences ({ 5 }) ) ({ 6 }) 
# Sentence pair (79) source length 42 target length 41 alignment score : 1.03591e-07
- Divided into three parts for training ( Section 02 - 21 , 39 ,832 sentences ) , development test ( Section 22 , 1 ,700 sentences ) , and final test ( Section 23 , 2 ,416 sentences ) . 
NULL ({ }) - ({ 1 }) Divided ({ 2 }) into ({ 3 }) three ({ 4 }) parts ({ 5 }) , ({ }) for ({ 6 }) training ({ 7 }) ( ({ 8 }) Section ({ 9 }) 02 ({ 10 }) - ({ 11 }) 21 ({ 12 }) , ({ 13 }) 39 ({ 14 }) ,832 ({ 15 }) sentences ({ 16 }) ) ({ 17 }) , ({ 18 }) development ({ 19 }) test ({ 20 }) ( ({ 21 }) Section ({ 22 }) 22 ({ 23 }) , ({ 24 }) 1 ({ 25 }) ,700 ({ 26 }) sentences ({ 27 }) ) ({ 28 }) , ({ 29 }) and ({ 30 }) final ({ 31 }) test ({ 32 }) ( ({ 33 }) Section ({ 34 }) 23 ({ 35 }) , ({ 36 }) 2 ({ 37 }) ,416 ({ 38 }) sentences ({ 39 }) ) ({ 40 }) . ({ 41 }) 
# Sentence pair (80) source length 7 target length 7 alignment score : 0.0598648
Brown overall ( 24 ,243 sentences ) 
NULL ({ }) Brown ({ 1 }) overall ({ 2 }) ( ({ 3 }) 24 ({ 4 }) ,243 ({ 5 }) sentences ({ 6 }) ) ({ 7 }) 
# Sentence pair (81) source length 31 target length 30 alignment score : 1.48877e-06
- Randomly divided into three parts for training ( 19 ,395 sentences ) , development set ( 2 ,424 sentences ) , and final test ( 2 ,424 sentences ) 
NULL ({ }) - ({ 1 }) Randomly ({ 2 }) divided ({ 3 }) into ({ 4 }) three ({ 5 }) parts ({ 6 }) for ({ 7 }) training ({ 8 }) ( ({ 9 }) 19 ({ 10 }) ,395 ({ 11 }) sentences ({ 12 }) ) ({ 13 }) , ({ 14 }) development ({ 15 }) set ({ 16 }) ( ({ 17 }) 2 ({ 18 }) ,424 ({ 19 }) sentences ({ 20 }) ) ({ 21 }) , ({ 22 }) and ({ 23 }) final ({ 24 }) test ({ 25 }) ( ({ 26 }) 2 ({ 27 }) ,424 ({ 28 }) sentences ({ 29 }) ) ({ 30 }) . ({ }) 
# Sentence pair (82) source length 6 target length 6 alignment score : 0.171186
Brown imperatives ( 750 sentences ) 
NULL ({ }) Brown ({ 1 }) imperatives ({ 2 }) ( ({ 3 }) 750 ({ 4 }) sentences ({ 5 }) ) ({ 6 }) 
# Sentence pair (83) source length 29 target length 28 alignment score : 9.39156e-07
- divided into two parts : one for ten-folds cross validation test ( 65 $\times$ 10 sentences ) and the other for error analysis ( 100 sentences ) 
NULL ({ }) - ({ 1 }) divided ({ 2 }) into ({ 3 }) two ({ 4 }) parts ({ 5 }) : ({ 6 }) one ({ 7 }) for ({ 8 }) ten-fold ({ 9 }) cross ({ 10 }) validation ({ 11 }) test ({ 12 }) ( ({ 13 }) 65 ({ 14 }) $\times$ ({ 15 }) 10 ({ 16 }) sentences ({ 17 }) ) ({ 18 }) and ({ 19 }) the ({ 20 }) other ({ 21 }) for ({ 22 }) error ({ 23 }) analysis ({ 24 }) ( ({ 25 }) 100 ({ 26 }) sentences ({ 27 }) ) ({ 28 }) . ({ }) 
# Sentence pair (84) source length 7 target length 7 alignment score : 0.144139
Brown questions ( 1 ,241 sentences ) 
NULL ({ }) Brown ({ 1 }) questions ({ 2 }) ( ({ 3 }) 1 ({ 4 }) ,241 ({ 5 }) sentences ({ 6 }) ) ({ 7 }) 
# Sentence pair (85) source length 29 target length 28 alignment score : 8.48024e-07
- divided into two parts : one for ten-folds cross validation test ( 112 $\times$ 10 sentences ) and the other for error analysis ( 141 sentences ) 
NULL ({ }) - ({ 1 }) divided ({ 2 }) into ({ 3 }) two ({ 4 }) parts ({ 5 }) : ({ 6 }) one ({ 7 }) for ({ 8 }) ten-fold ({ 9 }) cross ({ 10 }) validation ({ 11 }) test ({ 12 }) ( ({ 13 }) 112 ({ 14 }) $\times$ ({ 15 }) 10 ({ 16 }) sentences ({ 17 }) ) ({ 18 }) and ({ 19 }) the ({ 20 }) other ({ 21 }) for ({ 22 }) error ({ 23 }) analysis ({ 24 }) ( ({ 25 }) 141 ({ 26 }) sentences ({ 27 }) ) ({ 28 }) . ({ }) 
# Sentence pair (86) source length 7 target length 7 alignment score : 0.110571
QuestionBank questions ( 3 ,859 sentences ) 
NULL ({ }) QuestionBank ({ 1 }) questions ({ 2 }) ( ({ 3 }) 3 ({ 4 }) ,859 ({ 5 }) sentences ({ 6 }) ) ({ 7 }) 
# Sentence pair (87) source length 34 target length 33 alignment score : 5.74194e-08
- from the top of the corpus divided into three parts for final test ( 1 ,000 sentences ) , training ( 2 ,560 sentences ) , and analysis ( 299 sentences ) 
NULL ({ }) - ({ 1 }) from ({ 2 }) the ({ 3 }) top ({ 4 }) of ({ 5 }) the ({ 6 }) corpus ({ 7 }) divided ({ 8 }) into ({ 9 }) three ({ 10 }) parts ({ 11 }) for ({ 12 }) final ({ 13 }) test ({ 14 }) ( ({ 15 }) 1 ({ 16 }) ,000 ({ 17 }) sentences ({ 18 }) ) ({ 19 }) , ({ 20 }) training ({ 21 }) ( ({ 22 }) 2 ({ 23 }) ,560 ({ 24 }) sentences ({ 25 }) ) ({ 26 }) , ({ 27 }) and ({ 28 }) analysis ({ 29 }) ( ({ 30 }) 299 ({ 31 }) sentences ({ 32 }) ) ({ 33 }) . ({ }) 
# Sentence pair (88) source length 30 target length 32 alignment score : 1.45312e-21
In order to adapt each parser or POS tagger to a target domain , we trained the parser on combined training data for the target domain and for the original parser . 
NULL ({ 3 28 }) To ({ 1 }) adapt ({ 2 4 7 }) each ({ 5 }) parser ({ 6 }) and ({ }) the ({ }) POS ({ 8 }) tagger ({ 9 }) to ({ 10 }) a ({ 11 }) target ({ 12 }) domain ({ 13 }) , ({ 14 }) we ({ 15 }) trained ({ 16 }) the ({ 17 }) parser ({ 18 }) using ({ 19 }) combined ({ 20 }) training ({ 21 }) data ({ 22 }) for ({ 23 }) the ({ 24 }) target ({ 25 }) domain ({ 26 }) and ({ 27 }) the ({ 29 }) original ({ 30 }) parser ({ 31 }) . ({ 32 }) 
# Sentence pair (89) source length 30 target length 27 alignment score : 2.47277e-19
For a domain which contains only small training data , we replicated the training data for certain times and just utilized the concatenated replicas for training . 
NULL ({ 4 16 }) For ({ 1 }) a ({ 2 }) domain ({ 3 }) containing ({ 5 }) only ({ 6 }) a ({ }) small ({ 7 }) amount ({ }) of ({ }) training ({ 8 }) data ({ 9 }) , ({ 10 }) we ({ 11 }) replicated ({ 12 }) the ({ 13 }) training ({ 14 }) data ({ 15 }) a ({ }) certain ({ 17 }) number ({ 20 }) of ({ }) times ({ 18 }) and ({ 19 }) utilized ({ 21 }) the ({ 22 }) concatenated ({ 23 }) replicas ({ 24 }) for ({ 25 }) training ({ 26 }) . ({ 27 }) 
# Sentence pair (90) source length 2 target length 2 alignment score : 0.60506
POS tagger 
NULL ({ }) POS ({ 1 }) tagger ({ 2 }) 
# Sentence pair (91) source length 23 target length 24 alignment score : 1.15433e-07
- For Brown overall , we trained the model with the combined training data for the target domain and for the original model . 
NULL ({ 20 }) - ({ 1 }) For ({ 2 }) Brown ({ 3 }) overall ({ 4 }) , ({ 5 }) we ({ 6 }) trained ({ 7 }) the ({ 8 }) model ({ 9 }) with ({ 10 }) the ({ 11 }) combined ({ 12 }) training ({ 13 }) data ({ 14 }) for ({ 15 }) the ({ 16 }) target ({ 17 }) domain ({ 18 }) and ({ 19 }) the ({ 21 }) original ({ 22 }) model ({ 23 }) . ({ 24 }) 
# Sentence pair (92) source length 30 target length 28 alignment score : 4.53473e-10
For Brown imperatives / questions and QuestionBank , we replicated the training data for certain times and utilized the concatenated replicas and WSJ training data for training . 
NULL ({ 14 }) For ({ 1 }) Brown ({ 2 }) imperatives ({ 3 }) / ({ 4 }) questions ({ 5 }) and ({ 6 }) QuestionBank ({ 7 }) , ({ 8 }) we ({ 9 }) replicated ({ 10 }) the ({ 11 }) training ({ 12 }) data ({ 13 }) a ({ }) certain ({ 15 }) number ({ }) of ({ }) times ({ 16 }) and ({ 17 }) utilized ({ 18 }) the ({ 19 }) concatenated ({ 20 }) replicas ({ 21 }) and ({ 22 }) WSJ ({ 23 }) training ({ 24 }) data ({ 25 }) for ({ 26 }) training ({ 27 }) . ({ 28 }) 
# Sentence pair (93) source length 52 target length 48 alignment score : 2.50326e-16
For POS tagger , the number of replicas of training data was determined among 1 , 2 , 4 , 8 , 16 , 32 , 64 , and 128 , by testing these numbers on development test sets in three of ten datasets of cross validation . 
NULL ({ }) For ({ 1 }) the ({ }) POS ({ 2 }) tagger ({ 3 }) , ({ 4 }) the ({ 5 }) number ({ 6 }) of ({ 7 }) replicas ({ 8 }) of ({ 9 }) training ({ 10 }) data ({ 11 }) was ({ 12 }) determined ({ 13 }) as ({ }) either ({ 14 }) 1 ({ 15 }) , ({ 16 }) 2 ({ 17 }) , ({ 18 }) 4 ({ 19 }) , ({ 20 }) 8 ({ 21 }) , ({ 22 }) 16 ({ 23 }) , ({ 24 }) 32 ({ 25 }) , ({ 26 }) 64 ({ 27 }) , ({ 28 }) or ({ 29 }) 128 ({ 30 }) , ({ 31 }) by ({ 32 }) testing ({ 33 }) these ({ 34 }) numbers ({ 35 }) on ({ 36 }) the ({ }) development ({ 37 }) test ({ 38 }) sets ({ 39 }) in ({ 40 }) three ({ 41 }) of ({ 42 }) the ({ }) ten ({ 43 }) datasets ({ 44 }) for ({ 45 }) cross ({ 46 }) validation ({ 47 }) . ({ 48 }) 
# Sentence pair (94) source length 4 target length 4 alignment score : 0.181774
MST and Malt parser 
NULL ({ }) MST ({ 1 }) and ({ 2 }) Malt ({ 3 }) parser ({ 4 }) 
# Sentence pair (95) source length 24 target length 25 alignment score : 8.60603e-08
- For Brown overall and QuestionBank questions , we trained the model on combined data for the target domain and for the original model . 
NULL ({ 21 }) - ({ 1 }) For ({ 2 }) Brown ({ 3 }) overall ({ 4 }) and ({ 5 }) QuestionBank ({ 6 }) questions ({ 7 }) , ({ 8 }) we ({ 9 }) trained ({ 10 }) the ({ 11 }) model ({ 12 }) on ({ 13 }) combined ({ 14 }) data ({ 15 }) for ({ 16 }) the ({ 17 }) target ({ 18 }) domain ({ 19 }) and ({ 20 }) the ({ 22 }) original ({ 23 }) model ({ 24 }) . ({ 25 }) 
# Sentence pair (96) source length 25 target length 26 alignment score : 1.81118e-06
For Brown imperatives and questions , we replicated the training data for ten times and utilized the concatenated replicas and WSJ training data for training . 
NULL ({ 12 }) For ({ 1 }) Brown ({ 2 }) imperatives ({ 3 }) and ({ 4 }) questions ({ 5 }) , ({ 6 }) we ({ 7 }) replicated ({ 8 }) the ({ 9 }) training ({ 10 }) data ({ 11 }) ten ({ 13 }) times ({ 14 }) and ({ 15 }) utilized ({ 16 }) the ({ 17 }) concatenated ({ 18 }) replicas ({ 19 }) and ({ 20 }) WSJ ({ 21 }) training ({ 22 }) data ({ 23 }) for ({ 24 }) training ({ 25 }) . ({ 26 }) 
# Sentence pair (97) source length 2 target length 2 alignment score : 0.661089
Enju parser 
NULL ({ }) Enju ({ 1 }) parser ({ 2 }) 
# Sentence pair (98) source length 11 target length 10 alignment score : 2.10596e-06
- We used a toolkit in the Enju parser \CITE 
NULL ({ 4 }) - ({ 1 }) We ({ 2 }) used ({ 3 }) the ({ }) toolkit ({ 5 }) in ({ 6 }) the ({ 7 }) Enju ({ 8 }) parser ({ 9 }) \CITE ({ 10 }) . ({ }) 
# Sentence pair (99) source length 12 target length 12 alignment score : 0.000697922
Table \REF shows the POS tagging accuracies for the target domains . 
NULL ({ }) Table ({ 1 }) \REF ({ 2 }) gives ({ 3 }) the ({ 4 }) POS ({ 5 }) tagging ({ 6 }) accuracy ({ 7 }) for ({ 8 }) the ({ 9 }) target ({ 10 }) domains ({ 11 }) . ({ 12 }) 
# Sentence pair (100) source length 16 target length 17 alignment score : 2.83325e-10
When we applied WSJ tagger to other domains , the tagging accuracy more or less decreased . 
NULL ({ }) When ({ 1 }) we ({ 2 }) applied ({ 3 }) the ({ }) WSJ ({ 4 }) tagger ({ 5 }) to ({ 6 }) other ({ 7 }) domains ({ 8 }) , ({ 9 }) the ({ 10 }) tagging ({ 11 }) accuracy ({ 12 }) basically ({ 13 14 15 }) decreased ({ 16 }) . ({ 17 }) 
# Sentence pair (101) source length 16 target length 17 alignment score : 3.98524e-23
Among them , for Brown overall sentences , the accuracy did not decrease much from WSJ . 
NULL ({ 2 3 4 }) For ({ 1 }) Brown ({ 5 }) overall ({ 6 7 }) , ({ 8 }) compared ({ 15 }) with ({ }) the ({ }) WSJ ({ 16 }) , ({ }) the ({ 9 }) accuracy ({ 10 }) did ({ 11 }) not ({ 12 }) decrease ({ 13 }) much ({ 14 }) . ({ 17 }) 
# Sentence pair (102) source length 14 target length 14 alignment score : 0.00266609
However , for imperatives and questions , the POS tagger accuracy decreased significantly . 
NULL ({ }) However ({ 1 }) , ({ 2 }) for ({ 3 }) imperatives ({ 4 }) and ({ 5 }) questions ({ 6 }) , ({ 7 }) the ({ 8 }) POS ({ 9 }) tagger ({ 10 }) accuracy ({ 11 }) decreased ({ 12 }) significantly ({ 13 }) . ({ 14 }) 
# Sentence pair (103) source length 35 target length 40 alignment score : 3.01894e-45
The table shows the adaptation could improve the tagging accuracy to some extent , while the table also shows that the improved accuracy for the imperatives and questions could not reach eventhe accuracy of adapted tagger for Brown overall . 
NULL ({ 6 16 25 29 }) The ({ 1 }) table ({ 2 17 18 }) shows ({ 3 19 }) that ({ }) the ({ 4 }) adaptation ({ 5 }) improved ({ 7 }) the ({ 8 }) tagging ({ 9 }) accuracy ({ 10 }) to ({ 11 }) some ({ 12 }) extent ({ 13 30 31 }) , ({ 14 }) but ({ 15 }) that ({ 20 }) the ({ 21 }) improved ({ 22 }) accuracy ({ 23 }) for ({ 24 }) imperatives ({ 26 }) and ({ 27 }) questions ({ 28 }) was ({ }) still ({ }) below ({ 32 }) that ({ 33 }) of ({ 34 }) the ({ }) adapted ({ 35 }) tagger ({ 36 }) for ({ 37 }) Brown ({ 38 }) overall ({ 39 }) . ({ 40 }) 
# Sentence pair (104) source length 20 target length 22 alignment score : 1.49544e-13
Figure \REF shows the POS tagging accuracy for the target domains given by changing the size of the target training data . 
NULL ({ 15 }) Figure ({ 1 }) \REF ({ 2 }) shows ({ 3 }) the ({ 4 }) POS ({ 5 }) tagging ({ 6 }) accuracy ({ 7 }) for ({ 8 }) the ({ 9 }) target ({ 10 }) domains ({ 11 }) for ({ }) varying ({ 12 13 14 }) sizes ({ 16 }) of ({ 17 }) the ({ 18 }) target ({ 19 }) training ({ 20 }) data ({ 21 }) . ({ 22 }) 
# Sentence pair (105) source length 31 target length 31 alignment score : 1.38837e-15
This graph shows that for both types of sentences , first 300 training sentences improved the accuracy rapidly , and after that , the effect of adding training corpus declined . 
NULL ({ }) This ({ 1 }) graph ({ 2 }) shows ({ 3 }) that ({ 4 }) for ({ 5 }) both ({ 6 }) types ({ 7 }) of ({ 8 }) sentences ({ 9 }) , ({ 10 }) the ({ }) first ({ 11 }) 300 ({ 12 }) training ({ 13 }) sentences ({ 14 }) greatly ({ 18 }) improved ({ 15 }) the ({ 16 }) accuracy ({ 17 }) , ({ 19 }) but ({ 20 }) thereafter ({ 21 22 }) , ({ 23 }) the ({ 24 }) effect ({ 25 }) of ({ 26 }) adding ({ 27 }) training ({ 28 }) data ({ 29 }) declined ({ 30 }) . ({ 31 }) 
# Sentence pair (106) source length 32 target length 36 alignment score : 1.85174e-26
In order to recover the tagging accuracy of the WSJ tagger for WSJ ( 97 .53\% in Table \REF ) , it would not seem to be enough only to prepare much more training data . 
NULL ({ 3 30 }) To ({ 1 }) match ({ 2 4 }) the ({ 5 }) tagging ({ 6 }) accuracy ({ 7 }) of ({ 8 }) the ({ 9 }) WSJ ({ 10 }) tagger ({ 11 }) for ({ 12 }) the ({ }) WSJ ({ 13 }) ( ({ 14 }) 97 ({ 15 }) .53\% ({ 16 }) in ({ 17 }) Table ({ 18 }) \REF ({ 19 }) ) ({ 20 }) , ({ 21 }) preparing ({ 22 29 31 }) much ({ 32 }) more ({ 33 }) training ({ 34 }) data ({ 35 }) does ({ 23 }) not ({ 24 }) appear ({ 25 }) to ({ 26 }) be ({ 27 }) enough ({ 28 }) . ({ 36 }) 
# Sentence pair (107) source length 11 target length 11 alignment score : 1.0716e-11
Especially , the problem would be more serious for imperatives . 
NULL ({ }) In ({ }) particular ({ 1 }) , ({ 2 }) the ({ 3 }) problem ({ 4 }) is ({ }) more ({ 7 }) serious ({ 5 6 8 }) for ({ 9 }) imperatives ({ 10 }) . ({ 11 }) 
# Sentence pair (108) source length 35 target length 36 alignment score : 7.00703e-39
We then explored the tagging errors in each domain in order to observe what types of errors the WSJ tagger gave and what types of errors were solved or still unsolved by the adapted taggers . 
NULL ({ 10 }) Next ({ 1 }) , ({ }) we ({ 2 }) explored ({ 3 }) the ({ 4 }) tagging ({ 5 }) errors ({ 6 }) in ({ 7 }) each ({ 8 }) domain ({ 9 }) to ({ 12 }) observe ({ 11 13 14 23 }) the ({ }) types ({ 15 }) of ({ 16 }) errors ({ 17 }) from ({ }) the ({ 18 }) WSJ ({ 19 }) tagger ({ 20 }) and ({ 22 }) which ({ }) of ({ 25 }) these ({ 24 }) were ({ 27 }) either ({ 26 }) solved ({ 28 }) by ({ 32 }) the ({ 33 }) adapted ({ 34 }) taggers ({ 21 35 }) or ({ 29 }) remain ({ 30 }) unsolved ({ 31 }) . ({ 36 }) 
# Sentence pair (109) source length 33 target length 32 alignment score : 1.11281e-06
Table \REF , \REF , and \REF show the most frequent tagging errors given by the WSJ tagger / adapted tagger for Brown questions , Brown imperatives , and QuestionBank respectively . 
NULL ({ }) Tables ({ 1 }) \REF ({ 2 }) , ({ 3 }) \REF ({ 4 }) , ({ 5 }) and ({ 6 }) \REF ({ 7 }) show ({ 8 }) the ({ 9 }) most ({ 10 }) frequent ({ 11 }) tagging ({ 12 }) errors ({ 13 }) given ({ 14 }) by ({ 15 }) the ({ 16 }) WSJ ({ 17 }) tagger ({ 18 }) / ({ 19 }) adapted ({ 20 }) tagger ({ 21 }) for ({ 22 }) Brown ({ 23 }) questions ({ 24 }) , ({ 25 }) Brown ({ 26 }) imperatives ({ 27 }) , ({ 28 }) and ({ 29 }) QuestionBank ({ 30 }) , ({ }) respectively ({ 31 }) . ({ 32 }) 
# Sentence pair (110) source length 31 target length 33 alignment score : 6.15357e-22
In the tables , we could find that the major errors of the WSJ tagger for the Brown domains were the mis-tagging to verbs , that is , " VB \SPEC " . 
NULL ({ 7 21 }) From ({ 1 }) the ({ 2 }) results ({ 3 }) , ({ 4 }) we ({ 5 }) found ({ 6 }) that ({ 8 }) the ({ 9 }) main ({ 10 }) errors ({ 11 }) of ({ 12 }) the ({ 13 }) WSJ ({ 14 }) tagger ({ 15 }) for ({ 16 }) the ({ 17 }) Brown ({ 18 }) domains ({ 19 }) were ({ 20 }) mistagging ({ 22 }) of ({ 23 }) verbs ({ 24 }) , ({ 25 }) that ({ 26 }) is ({ 27 }) , ({ 28 }) " ({ 29 }) VB ({ 30 }) \SPEC ({ 31 }) " ({ 32 }) . ({ 33 }) 
# Sentence pair (111) source length 11 target length 11 alignment score : 3.46414e-05
We then analyzed why each of such errors had occurred . 
NULL ({ }) We ({ 1 }) then ({ 2 }) analyzed ({ 3 }) why ({ 4 }) each ({ 5 }) of ({ 6 }) these ({ 7 }) errors ({ 8 }) had ({ 9 }) occurred ({ 10 }) . ({ 11 }) 
# Sentence pair (112) source length 27 target length 27 alignment score : 1.19802e-06
For Brown imperatives , the WSJ tagger gave two major tagging errors : " VB \SPEC NN( P ) " and " VB \SPEC VBP " . 
NULL ({ }) For ({ 1 }) Brown ({ 2 }) imperatives ({ 3 }) , ({ 4 }) the ({ 5 }) WSJ ({ 6 }) tagger ({ 7 }) gave ({ 8 }) two ({ 9 }) main ({ 10 }) tagging ({ 11 }) errors ({ 12 }) : ({ 13 }) " ({ 14 }) VB ({ 15 }) \SPEC ({ 16 }) NN( ({ 17 }) P ({ 18 }) ) ({ 19 }) " ({ 20 }) and ({ 21 }) " ({ 22 }) VB ({ 23 }) \SPEC ({ 24 }) VBP ({ 25 }) " ({ 26 }) . ({ 27 }) 
# Sentence pair (113) source length 22 target length 24 alignment score : 1.86876e-12
These two types of errors would respectively come from the following differences in sentence constructions between WSJ declarative and the Brown imperative sentences . 
NULL ({ 20 }) These ({ 1 }) two ({ 2 }) types ({ 3 }) of ({ 4 }) errors ({ 5 }) arise ({ 6 7 8 }) from ({ 9 }) the ({ 10 }) following ({ 11 }) differences ({ 12 }) in ({ 13 }) sentence ({ 14 }) constructions ({ 15 }) between ({ 16 }) the ({ }) WSJ ({ 17 }) declarative ({ 18 }) and ({ 19 }) Brown ({ 21 }) imperative ({ 22 }) sentences ({ 23 }) . ({ 24 }) 
# Sentence pair (114) source length 23 target length 18 alignment score : 1.42322e-12
Firstly , declarative sentences normally begin with noun phrases while imperative sentences normally begin with verb phrases . 
NULL ({ }) First ({ 1 }) , ({ 2 }) a ({ }) declarative ({ 3 }) sentence ({ 4 }) normally ({ 5 }) begins ({ 6 }) with ({ 7 }) a ({ }) noun ({ 8 }) phrase ({ 9 }) , ({ }) whereas ({ 10 }) an ({ }) imperative ({ 11 }) sentence ({ 12 }) normally ({ 13 }) begins ({ 14 }) with ({ 15 }) a ({ }) verb ({ 16 }) phrase ({ 17 }) . ({ 18 }) 
# Sentence pair (115) source length 41 target length 43 alignment score : 1.47289e-32
The WSJ tagger was trained on the domain mainly consisting of declarative sentences , and the training was based on N-gram sequences of words or POSs . The tagger therefore preferred to give noun phrase-derived tags to the beginning of a sentence . 
NULL ({ 27 }) Since ({ 1 }) The ({ 28 }) WSJ ({ 2 }) tagger ({ 3 }) was ({ 4 }) trained ({ 5 }) on ({ 6 }) a ({ 7 }) domain ({ 8 }) consisting ({ 9 }) mainly ({ 10 }) of ({ 11 }) declarative ({ 12 }) sentences ({ 13 }) , ({ 14 }) with ({ 15 }) the ({ 16 }) training ({ 17 }) based ({ 19 }) on ({ 20 }) N-gram ({ 21 }) sequences ({ 22 }) of ({ 23 }) words ({ 24 }) or ({ 25 }) POSs ({ 26 30 31 33 }) , ({ }) preference ({ 29 }) was ({ 18 }) given ({ }) to ({ 32 }) noun ({ 34 }) phrase-derived ({ 35 }) tags ({ 36 }) at ({ 37 }) the ({ 38 }) beginning ({ 39 }) of ({ 40 }) a ({ 41 }) sentence ({ 42 }) . ({ 43 }) 
# Sentence pair (116) source length 29 target length 23 alignment score : 1.71661e-26
Secondly , main verbs in imperative sentences take base forms while main verbs in declarative sentences take the forms according to tense . 
NULL ({ 21 }) Second ({ 1 }) , ({ 2 }) the ({ }) main ({ 3 }) verb ({ 4 }) in ({ 5 }) an ({ }) imperative ({ 6 }) sentence ({ 7 }) takes ({ 8 }) a ({ }) base ({ 9 }) form ({ 10 }) , ({ }) whereas ({ 11 }) the ({ }) main ({ 12 }) verb ({ 13 }) in ({ 14 }) a ({ }) declarative ({ 15 }) sentence ({ 16 }) takes ({ 17 }) a ({ 18 }) form ({ 19 }) based ({ 20 }) on ({ }) tense ({ 22 }) . ({ 23 }) 
# Sentence pair (117) source length 45 target length 39 alignment score : 6.73721e-23
The problem is that , for present tense except for third person singular , verbs in the declarative sentences always take the same appearances as the base forms , while the tags are different : VBP and VB . 
NULL ({ }) A ({ 1 }) problem ({ 2 }) arises ({ 3 }) in ({ }) that ({ 4 }) , ({ 5 }) for ({ 6 }) the ({ }) present ({ 7 }) tense ({ 8 }) , ({ }) except ({ 9 }) for ({ 10 }) third ({ 11 }) person ({ 12 }) singular ({ 13 }) , ({ 14 }) the ({ }) verb ({ 15 }) in ({ 16 }) a ({ 17 }) declarative ({ 18 }) sentence ({ 19 }) always ({ 20 }) has ({ 21 }) the ({ 22 }) same ({ 23 }) appearance ({ 24 }) as ({ 25 }) the ({ 26 }) base ({ 27 }) form ({ 28 }) , ({ 29 }) although ({ 30 }) the ({ 31 }) tags ({ 32 }) are ({ 33 }) different ({ 34 }) : ({ 35 }) VBP ({ 36 }) and ({ 37 }) VB ({ 38 }) , ({ }) respectively ({ }) . ({ 39 }) 
# Sentence pair (118) source length 21 target length 18 alignment score : 3.28806e-10
The WSJ tagger mainly based on declarative sentences therefore prefer to give VBP tags to main verbs . 
NULL ({ }) Since ({ 1 }) the ({ }) WSJ ({ 2 }) tagger ({ 3 }) is ({ }) predominantly ({ 4 }) based ({ 5 }) on ({ 6 }) declarative ({ 7 }) sentences ({ 8 }) , ({ }) it ({ 9 }) prefers ({ 10 }) to ({ 11 }) give ({ 12 }) VBP ({ 13 }) tags ({ 14 }) to ({ 15 }) main ({ 16 }) verbs ({ 17 }) . ({ 18 }) 
# Sentence pair (119) source length 45 target length 42 alignment score : 4.9405e-11
After adapting the tagger to Brown imperatives , the N-gram model of tagger would have learned that the first word in a sentence tends to be a verb , and the main verb tends to take base form ( VB ) . 
NULL ({ }) After ({ 1 }) adapting ({ 2 }) the ({ 3 }) tagger ({ 4 }) to ({ 5 }) Brown ({ 6 }) imperatives ({ 7 }) , ({ 8 }) the ({ 9 }) N-gram ({ 10 }) model ({ 11 }) of ({ 12 }) the ({ }) tagger ({ 13 }) would ({ 14 }) have ({ 15 }) learned ({ 16 }) that ({ 17 }) the ({ 18 }) first ({ 19 }) word ({ 20 }) in ({ 21 }) a ({ 22 }) sentence ({ 23 }) tends ({ 24 }) to ({ 25 }) be ({ 26 }) a ({ 27 }) verb ({ 28 }) , ({ 29 }) and ({ 30 }) that ({ }) the ({ 31 }) main ({ 32 }) verb ({ 33 }) tends ({ 34 }) to ({ 35 }) take ({ 36 }) the ({ }) base ({ 37 }) form ({ 38 }) ( ({ 39 }) VB ({ 40 }) ) ({ 41 }) . ({ 42 }) 
# Sentence pair (120) source length 26 target length 36 alignment score : 5.14653e-41
Table \REF shows that the above two types of errors did decrease to some extent . However , we can also observe that not a few mis-tags to verbs were still left after the adaptation . 
NULL ({ 20 23 28 34 }) Table ({ 1 }) \REF ({ 2 }) shows ({ 3 }) that ({ 4 }) after ({ 33 }) adaptation ({ 35 }) the ({ 5 }) above ({ 6 }) two ({ 7 }) types ({ 8 }) of ({ 9 }) errors ({ 10 }) decreased ({ 11 12 }) to ({ 13 }) some ({ 14 }) extent ({ 15 16 17 19 }) , ({ 18 }) although ({ 24 }) a ({ 25 }) few ({ 26 }) mistags ({ 21 22 27 }) of ({ }) verbs ({ 29 }) still ({ 31 }) remained ({ 30 32 }) . ({ 36 }) 
# Sentence pair (121) source length 81 target length 81 alignment score : 1.59857e-39
When we observe each of the left errors around VB , we found that several errors still occurred even in simple imperative sentences such as " VB \SPEC NN " for " Charge " in " Charge something for it . " , and that some errors tended to occur after to-infinitive phrase or conjunction , such as " VB \SPEC NN " for " subtract " in " To find estimated net farm income , subtract . . . " 
NULL ({ 5 6 }) By ({ }) investigating ({ 2 }) the ({ }) remaining ({ }) errors ({ 8 }) associated ({ 9 }) with ({ }) VB ({ 10 }) , ({ 11 }) we ({ 12 }) found ({ 13 }) that ({ 14 }) several ({ 15 }) errors ({ 16 }) still ({ 17 }) occurred ({ 18 }) even ({ 19 }) in ({ 20 }) simple ({ 21 }) imperative ({ 22 }) sentences ({ 23 }) such ({ 24 }) as ({ 25 }) " ({ 26 }) VB ({ 27 }) \SPEC ({ 28 }) NN ({ 29 }) " ({ 30 }) for ({ 31 }) " ({ 32 }) Charge ({ 33 }) " ({ 34 }) in ({ 35 }) " ({ 36 }) Charge ({ 1 3 4 37 }) something ({ 7 38 }) for ({ 39 }) it ({ 40 }) " ({ 42 }) , ({ 43 }) and ({ 44 }) that ({ 45 }) some ({ 46 }) errors ({ 47 }) tended ({ 48 }) to ({ 49 }) occur ({ 50 }) after ({ 51 }) a ({ }) to-infinitive ({ 52 }) phrase ({ 53 }) or ({ 54 }) conjunction ({ 55 }) , ({ 56 }) such ({ 57 }) as ({ 58 }) " ({ 59 }) VB ({ 60 }) \SPEC ({ 61 }) NN ({ 62 }) " ({ 63 }) for ({ 64 }) " ({ 65 }) subtract ({ 66 }) " ({ 67 }) in ({ 68 }) " ({ 69 }) To ({ 70 }) find ({ 71 }) the ({ }) estimated ({ 72 }) net ({ 73 }) farm ({ 74 }) income ({ 75 }) , ({ 76 }) subtract ({ 77 }) . ({ 78 }) . ({ 79 }) . ({ 80 }) " ({ 81 }) . ({ 41 }) 
# Sentence pair (122) source length 38 target length 41 alignment score : 3.59772e-33
The former type of errors might be solved by increasing the training data , while the latter type of errors would not be easily solved with the model based on word N-gram which cannot detect the existence of long phrases . 
NULL ({ 4 19 }) The ({ 1 }) former ({ 2 }) type ({ 3 }) could ({ 5 }) be ({ 7 }) solved ({ 6 8 21 }) by ({ 9 }) increasing ({ 10 }) the ({ 11 }) training ({ 12 }) data ({ 13 }) , ({ 14 }) whereas ({ 15 }) the ({ 16 }) latter ({ 17 }) error ({ 20 }) type ({ 18 }) cannot ({ 22 }) easily ({ 24 }) be ({ 23 }) solved ({ 25 }) with ({ 26 }) a ({ 27 }) model ({ 28 }) based ({ 29 }) on ({ 30 }) a ({ }) word ({ 31 }) N-gram ({ 32 }) that ({ 33 }) cannot ({ 34 }) detect ({ 35 }) the ({ 36 }) existence ({ 37 }) of ({ 38 }) long ({ 39 }) phrases ({ 40 }) . ({ 41 }) 
# Sentence pair (123) source length 37 target length 41 alignment score : 1.66646e-26
We also analyzed the errors in Brown questions and QuestionBank , and again found that the WSJ tagger seems to make many errors due to the fact that the tagger was trained on a corpus mainly consisting of declarative sentences . 
NULL ({ 20 29 }) We ({ 1 }) also ({ 2 }) analyzed ({ 3 }) the ({ 4 }) errors ({ 5 }) in ({ 6 }) Brown ({ 7 }) questions ({ 8 }) and ({ 9 }) QuestionBank ({ 10 }) , ({ 11 }) and ({ 12 }) again ({ 13 }) found ({ 14 }) that ({ 15 }) many ({ 22 }) errors ({ 23 }) were ({ }) due ({ 24 }) to ({ 25 }) the ({ 26 }) fact ({ 27 }) that ({ 28 }) the ({ 16 }) WSJ ({ 17 }) tagger ({ 18 30 }) was ({ 31 }) trained ({ 32 }) on ({ 33 }) a ({ 34 }) corpus ({ 35 }) consisting ({ 19 }) mainly ({ 21 36 37 }) of ({ 38 }) declarative ({ 39 }) sentences ({ 40 }) . ({ 41 }) 
# Sentence pair (124) source length 43 target length 45 alignment score : 2.83231e-27
After the adaptation , while some of the errors such as special usage of wh-words , i.e. , " WDT \SPEC WP " , were corrected , we found that some kinds or errors related to the global change of sentence structures still remained . 
NULL ({ 28 30 }) After ({ 1 }) the ({ 2 }) adaptation ({ 3 }) , ({ 4 }) although ({ 5 }) some ({ 6 31 }) of ({ 7 }) the ({ 8 }) errors ({ 9 }) such ({ 10 }) as ({ 11 }) the ({ }) special ({ 12 }) use ({ 13 }) of ({ 14 }) wh-words ({ 15 }) , ({ 16 }) i.e. ({ 17 }) , ({ 18 }) " ({ 19 }) WDT ({ 20 }) \SPEC ({ 21 }) WP ({ 22 }) " ({ 23 }) , ({ 24 }) were ({ 25 }) corrected ({ 26 }) , ({ 27 }) other ({ 29 }) kinds ({ 32 }) or ({ 33 }) errors ({ 34 }) related ({ 35 }) to ({ 36 }) the ({ 37 }) global ({ 38 }) change ({ 39 }) in ({ 40 }) sentence ({ 41 }) structure ({ 42 }) still ({ 43 }) remained ({ 44 }) . ({ 45 }) 
# Sentence pair (125) source length 31 target length 35 alignment score : 1.10371e-22
In order to give correct tags to words both in imperatives and questions , we might have to consider richer information than only N-gram based features , such as long distance dependencies or phrases . 
NULL ({ 3 5 7 }) To ({ 1 }) tag ({ 2 6 }) words ({ 8 }) correctly ({ 4 }) both ({ 9 }) in ({ 10 }) imperatives ({ 11 }) and ({ 12 }) questions ({ 13 }) , ({ 14 }) we ({ 15 }) may ({ 16 }) have ({ 17 }) to ({ 18 }) consider ({ 19 }) richer ({ 20 }) information ({ 21 }) than ({ 22 }) only ({ 23 }) N-gram ({ 24 }) based ({ 25 }) features ({ 26 }) , ({ 27 }) such ({ 28 }) as ({ 29 }) long ({ 30 }) distance ({ 31 }) dependencies ({ 32 }) or ({ 33 }) phrases ({ 34 }) . ({ 35 }) 
# Sentence pair (126) source length 38 target length 34 alignment score : 1.0881e-12
Table \REF shows the parsing accuracies of MST( first order ) , MST( second order ) , Malt , and Enju parser for WSJ , Brown overall , Brown imperatives and Brown questions . 
NULL ({ }) Table ({ 1 }) \REF ({ 2 }) gives ({ 3 }) the ({ 4 }) parsing ({ 5 }) accuracy ({ 6 }) of ({ 7 }) MST ({ 8 }) ( ({ }) first ({ 9 }) order ({ 10 }) ) ({ 11 }) , ({ 12 }) MST ({ 13 }) ( ({ }) second ({ 14 }) order ({ 15 }) ) ({ 16 }) , ({ 17 }) Malt ({ 18 }) , ({ 19 }) and ({ 20 }) the ({ }) Enju ({ 21 }) parser ({ 22 }) for ({ 23 }) WSJ ({ 24 }) , ({ 25 }) Brown ({ 26 }) overall ({ 27 }) , ({ 28 }) Brown ({ 29 }) imperatives ({ 30 }) , ({ }) and ({ 31 }) Brown ({ 32 }) questions ({ 33 }) . ({ 34 }) 
# Sentence pair (127) source length 27 target length 27 alignment score : 8.88805e-06
Figure \REF shows the parsing accuracies against the training data size of the four parsers for WSJ , Brown imperatives , Brown questions , and QuestionBank . 
NULL ({ }) Figure ({ 1 }) \REF ({ 2 }) plots ({ 3 }) the ({ 4 }) parsing ({ 5 }) accuracy ({ 6 }) against ({ 7 }) the ({ 8 }) training ({ 9 }) data ({ 10 }) size ({ 11 }) of ({ 12 }) the ({ 13 }) four ({ 14 }) parsers ({ 15 }) for ({ 16 }) WSJ ({ 17 }) , ({ 18 }) Brown ({ 19 }) imperatives ({ 20 }) , ({ 21 }) Brown ({ 22 }) questions ({ 23 }) , ({ 24 }) and ({ 25 }) QuestionBank ({ 26 }) . ({ 27 }) 
# Sentence pair (128) source length 69 target length 64 alignment score : 6.51065e-22
Note that , since training MST parser ( second order ) on Brown overall , Brown questions , and QuestionBank could not be completed in our experimental environments , the parsing accuracies represented by the bracketed hyphens in Table \REF could not be measured and we could not draw full graphs of second order MST for Brown questions and QuestionBank in Figure \REF . 
NULL ({ 35 }) Note ({ 1 }) that ({ 2 }) , ({ 3 }) since ({ 4 }) the ({ }) training ({ 5 }) of ({ }) the ({ }) MST ({ 6 }) parser ({ 7 }) ( ({ 8 }) second ({ 9 }) order ({ 10 }) ) ({ 11 }) on ({ 12 }) Brown ({ 13 }) overall ({ 14 }) , ({ 15 }) Brown ({ 16 }) questions ({ 17 }) , ({ 18 }) and ({ 19 }) QuestionBank ({ 20 }) could ({ 21 }) not ({ 22 }) be ({ 23 }) completed ({ 24 }) in ({ 25 }) our ({ 26 }) experimental ({ 27 }) environment ({ 28 }) , ({ 29 }) the ({ 30 }) corresponding ({ }) parsing ({ 31 }) accuracies ({ 32 }) denoted ({ 33 }) by ({ 34 }) bracketed ({ 36 }) hyphens ({ 37 }) in ({ 38 }) Table ({ 39 }) \REF ({ 40 }) could ({ 41 }) not ({ 42 }) be ({ 43 }) measured ({ 44 }) , ({ }) Consequently ({ 45 }) , ({ }) we ({ 46 }) could ({ 47 }) not ({ 48 }) plot ({ 49 }) complete ({ 50 }) graphs ({ 51 }) of ({ 52 }) second ({ 53 }) order ({ 54 }) MST ({ 55 }) for ({ 56 }) Brown ({ 57 }) questions ({ 58 }) and ({ 59 }) QuestionBank ({ 60 }) in ({ 61 }) Figure ({ 62 }) \REF ({ 63 }) . ({ 64 }) 
# Sentence pair (129) source length 34 target length 36 alignment score : 4.37005e-27
When we adapted the parser model ( see fifth column in Table \REF ) , the parser could give two to four points higher accuracies for each of the Brown domains than the WSJ parser . 
NULL ({ 4 18 }) After ({ 1 }) adaptation ({ 2 }) ( ({ 7 }) see ({ 8 }) " ({ 5 }) Adapted ({ 3 6 9 }) " ({ }) column ({ 10 }) in ({ 11 }) Table ({ 12 }) \REF ({ 13 }) ) ({ 14 }) , ({ 15 }) the ({ 16 }) parser ({ 17 }) achieved ({ 19 }) two ({ 20 }) to ({ 21 }) four ({ 22 }) percent ({ 23 }) higher ({ 24 }) accuracy ({ 25 }) for ({ 26 }) each ({ 27 }) of ({ 28 }) the ({ 29 }) Brown ({ 30 }) domains ({ 31 }) compared ({ 32 }) to ({ }) the ({ 33 }) WSJ ({ 34 }) parser ({ 35 }) . ({ 36 }) 
# Sentence pair (130) source length 13 target length 13 alignment score : 4.95783e-11
For the QuestionBank , 25 to 35 points accuracy improvements were observed . 
NULL ({ 2 }) For ({ 1 }) QuestionBank ({ 3 }) , ({ 4 }) 25 ({ 5 }) to ({ 6 }) 35 ({ 7 }) percent ({ 8 }) improvement ({ 10 }) in ({ }) accuracy ({ 9 }) was ({ 11 }) observed ({ 12 }) . ({ 13 }) 
# Sentence pair (131) source length 25 target length 26 alignment score : 5.25688e-18
Figure \REF shows that , the improvements increased according to the size of the training data , and the tendencies would not seem to converge . 
NULL ({ 5 17 }) Figure ({ 1 }) \REF ({ 2 }) shows ({ 3 }) that ({ 4 }) the ({ 6 }) improvement ({ 7 }) is ({ }) proportional ({ 8 9 }) to ({ 10 }) the ({ 11 }) size ({ 12 }) of ({ 13 }) the ({ 14 }) training ({ 15 }) data ({ 16 }) and ({ 18 }) that ({ }) this ({ 19 }) tendency ({ 20 }) does ({ 21 }) not ({ 22 }) seem ({ 23 }) to ({ 24 }) converge ({ 25 }) . ({ 26 }) 
# Sentence pair (132) source length 28 target length 23 alignment score : 2.94706e-23
This would suggest that lower accuracies than the WSJ parser for WSJ would be still brought by the lack of training data . 
NULL ({ 18 }) This ({ 1 }) would ({ 2 }) suggest ({ 3 }) that ({ 4 }) lower ({ 5 }) accuracy ({ 6 }) than ({ 7 }) that ({ }) of ({ }) the ({ 8 }) WSJ ({ 9 }) parser ({ 10 }) for ({ 11 }) the ({ }) WSJ ({ 12 }) could ({ 13 }) still ({ 15 }) be ({ 14 }) as ({ }) a ({ }) result ({ }) of ({ 20 }) a ({ }) lack ({ 16 17 19 }) of ({ }) training ({ 21 }) data ({ 22 }) . ({ 23 }) 
# Sentence pair (133) source length 36 target length 39 alignment score : 3.89491e-45
In Figure \REF , when we focus on the QuestionBank where we could use much more training data than Brown questions , the parser accuracies were approaching the accuracies of WSJ parser for WSJ or exceeded the accuracy . 
NULL ({ 6 9 28 37 }) In ({ 1 }) Figure ({ 2 }) \REF ({ 3 }) , ({ 4 }) the ({ 23 }) parser ({ 24 }) accuracy ({ 38 }) for ({ }) QuestionBank ({ 10 }) , ({ }) for ({ 8 }) which ({ }) we ({ 12 }) could ({ 13 }) use ({ 14 }) much ({ 15 }) more ({ 16 }) training ({ 17 }) data ({ 18 }) than ({ 19 }) for ({ }) Brown ({ 20 }) questions ({ 21 }) , ({ 22 }) approaches ({ }) or ({ 35 }) even ({ 5 }) exceeds ({ 7 11 25 26 27 29 36 }) that ({ }) of ({ 30 }) the ({ }) WSJ ({ 31 }) parser ({ 32 }) for ({ 33 }) WSJ ({ 34 }) . ({ 39 }) 
# Sentence pair (134) source length 40 target length 35 alignment score : 3.61569e-32
However , we have no more training data for Brown imperatives and questions . We should prepare more training data or explore approaches to enable us to sufficiently adapt parsers with small training data . 
NULL ({ 14 24 }) However ({ 1 }) , ({ 2 }) as ({ }) there ({ 4 }) is ({ }) no ({ 5 }) more ({ 6 }) training ({ 7 }) data ({ 8 }) for ({ 9 }) Brown ({ 10 }) imperatives ({ 11 }) and ({ 12 }) questions ({ 13 }) , ({ }) we ({ 3 }) need ({ 16 }) to ({ }) either ({ 15 }) prepare ({ 17 }) more ({ 18 }) training ({ 19 }) data ({ 20 }) or ({ 21 }) explore ({ 22 }) approaches ({ 23 }) that ({ }) enable ({ 25 }) the ({ }) parsers ({ 26 }) to ({ 27 }) be ({ }) adapted ({ 30 }) with ({ 31 }) small ({ 32 }) amounts ({ 28 29 }) of ({ }) training ({ 33 }) data ({ 34 }) . ({ 35 }) 
# Sentence pair (135) source length 19 target length 20 alignment score : 4.97857e-16
In order to capture the outline of the adaptation effects , we observed error reduction for the Malt parser . 
NULL ({ 3 5 }) To ({ 1 }) capture ({ 2 4 }) an ({ }) overview ({ 6 }) of ({ 7 }) the ({ 8 }) adaptation ({ 9 }) effects ({ 10 }) , ({ 11 }) we ({ 12 }) observed ({ 13 }) the ({ }) error ({ 14 }) reduction ({ 15 }) in ({ 16 }) the ({ 17 }) Malt ({ 18 }) parser ({ 19 }) . ({ 20 }) 
# Sentence pair (136) source length 27 target length 26 alignment score : 1.80938e-08
Table \REF and \REF show the recall errors on labeled dependencies which were observed more than ten times for 100 analysis sentences of each domain . 
NULL ({ }) Tables ({ 1 }) \REF ({ 2 }) and ({ 3 }) \REF ({ 4 }) give ({ 5 }) the ({ 6 }) recall ({ 7 }) errors ({ 8 }) on ({ 9 }) labeled ({ 10 }) dependencies ({ 11 }) , ({ }) which ({ 12 }) were ({ 13 }) observed ({ 14 }) more ({ 15 }) than ({ 16 }) ten ({ 17 }) times ({ 18 }) for ({ 19 }) 100 ({ 20 }) analysis ({ 21 }) sentences ({ 22 }) in ({ 23 }) each ({ 24 }) domain ({ 25 }) . ({ 26 }) 
# Sentence pair (137) source length 37 target length 35 alignment score : 2.76034e-08
For each dependency shown in the first column , the second and third columns show the number of parsing errors by the WSJ parser with gold tags and the adapted parser with gold tags . 
NULL ({ }) For ({ 1 }) each ({ 2 }) dependency ({ 3 }) shown ({ 4 }) in ({ 5 }) the ({ 6 }) first ({ 7 }) column ({ 8 }) , ({ 9 }) the ({ 10 }) second ({ 11 }) and ({ 12 }) third ({ 13 }) columns ({ 14 }) show ({ 15 }) the ({ 16 }) number ({ 17 }) of ({ 18 }) parsing ({ 19 }) errors ({ 20 }) by ({ 21 }) the ({ 22 }) WSJ ({ 23 }) parser ({ 24 }) with ({ 25 }) gold ({ 26 }) tags ({ 27 }) and ({ 28 }) the ({ 29 }) adapted ({ 30 }) parser ({ 31 }) with ({ 32 }) gold ({ 33 }) tags ({ 34 }) , ({ }) respectively ({ }) . ({ 35 }) 
# Sentence pair (138) source length 28 target length 27 alignment score : 5.61205e-20
Since ROOT dependencies , that is , heads of sentences would be critical to construction of sentences , we mainly focus on that type of errors . 
NULL ({ }) Since ({ 1 }) ROOT ({ 2 }) dependencies ({ 3 }) , ({ 4 }) that ({ 5 }) is ({ 6 }) , ({ 7 }) heads ({ 8 11 12 }) of ({ 9 }) sentences ({ 10 }) , ({ }) are ({ }) critical ({ 13 }) to ({ 14 }) the ({ }) construction ({ 15 }) of ({ 16 }) sentences ({ 17 }) , ({ 18 }) we ({ 19 }) focus ({ 21 }) mainly ({ 20 }) on ({ 22 }) this ({ 23 }) type ({ 24 }) of ({ 25 }) error ({ 26 }) . ({ 27 }) 
# Sentence pair (139) source length 14 target length 18 alignment score : 3.86099e-18
For Brown imperatives and questions , we could observe that the reduction of ROOT dependency was prominent . 
NULL ({ 7 }) For ({ 1 }) Brown ({ 2 }) imperatives ({ 3 }) and ({ 4 }) questions ({ 5 }) , ({ 6 }) the ({ 11 }) reduction ({ 12 }) in ({ 13 }) ROOT ({ 14 }) dependencies ({ 15 }) was ({ 16 }) prominent ({ 8 9 10 17 }) . ({ 18 }) 
# Sentence pair (140) source length 28 target length 37 alignment score : 3.29629e-49
When we focus on this type of errors , we could find that the WSJ parser could often make mistakes in parsing sentences which began or ended with the names of persons who were talk to . 
NULL ({ 2 4 7 12 36 }) On ({ 1 }) investigation ({ 8 }) , ({ 9 }) we ({ 10 }) found ({ 11 }) that ({ 13 }) the ({ 14 }) WSJ ({ 15 }) parser ({ 16 }) often ({ 17 18 }) made ({ 19 }) mistakes ({ 20 }) in ({ 21 }) parsing ({ 22 }) sentences ({ 23 }) which ({ 24 }) began ({ 3 25 32 }) or ({ 26 }) ended ({ 5 6 27 33 }) with ({ 28 }) the ({ 29 }) name ({ 30 }) of ({ 31 }) the ({ }) person ({ }) being ({ 34 }) addressed ({ 35 }) . ({ 37 }) 
# Sentence pair (141) source length 48 target length 45 alignment score : 2.16781e-20
For example in Brown imperatives , for the sentence " See for yourself , Miss Zion . " , the WSJ parser regarded the person name " Zion " as ROOT , and the main verb " See " as modifiers of the name . 
NULL ({ 24 }) For ({ 1 }) example ({ 2 }) , ({ }) in ({ 3 }) Brown ({ 4 }) imperatives ({ 5 }) , ({ 6 }) for ({ 7 }) the ({ 8 }) sentence ({ 9 }) " ({ 10 }) See ({ 11 }) for ({ 12 }) yourself ({ 13 }) , ({ 14 }) Miss ({ 15 }) Zion ({ 16 }) . ({ 17 }) " ({ 18 }) , ({ 19 }) the ({ 20 }) WSJ ({ 21 }) parser ({ 22 }) mistook ({ 23 25 }) the ({ }) name ({ 26 }) " ({ 27 }) Zion ({ 28 }) " ({ 29 }) to ({ }) be ({ 30 }) ROOT ({ 31 }) , ({ 32 }) and ({ 33 }) the ({ 34 }) main ({ 35 }) verb ({ 36 }) " ({ 37 }) See ({ 38 }) " ({ 39 }) to ({ }) be ({ 40 }) a ({ }) modifier ({ 41 }) of ({ 42 }) the ({ 43 }) name ({ 44 }) . ({ 45 }) 
# Sentence pair (142) source length 11 target length 13 alignment score : 4.86256e-11
The adapted parser could then correctly give ROOT to the main verb . 
NULL ({ 4 5 }) The ({ 1 }) adapted ({ 2 }) parser ({ 3 }) correctly ({ 6 }) assigned ({ 7 }) ROOT ({ 8 }) to ({ 9 }) the ({ 10 }) main ({ 11 }) verb ({ 12 }) . ({ 13 }) 
# Sentence pair (143) source length 49 target length 52 alignment score : 2.17558e-28
We could also often find that the WSJ parser could often make mistakes in parsing sentences containing quotation , exclamation , and question marks , such as " " Hang on " !! " " or " Why did you kill it " ? ? " or " " " " . 
NULL ({ 5 }) We ({ 1 }) also ({ 3 }) found ({ 2 }) that ({ 6 }) the ({ 7 }) WSJ ({ 8 }) parser ({ 9 }) often ({ 4 10 11 }) made ({ 12 }) mistakes ({ 13 }) in ({ 14 }) parsing ({ 15 }) sentences ({ 16 }) containing ({ 17 }) quotation ({ 18 }) , ({ 19 }) exclamation ({ 20 }) , ({ 21 }) or ({ 22 }) question ({ 23 }) marks ({ 24 }) , ({ 25 }) such ({ 26 }) as ({ 27 }) " ({ 28 }) " ({ 29 }) Hang ({ 30 }) on ({ 31 }) " ({ 32 }) !! ({ 33 }) " ({ 34 }) " ({ 35 }) or ({ 36 }) " ({ 37 }) Why ({ 38 }) did ({ 39 }) you ({ 40 }) kill ({ 41 }) it ({ 42 }) " ({ 43 }) ? ({ 44 }) ? ({ 45 }) " ({ 46 }) or ({ 47 }) " ({ 48 }) " ({ 49 }) " ({ 50 }) " ({ 51 }) . ({ 52 }) 
# Sentence pair (144) source length 35 target length 35 alignment score : 1.47621e-08
For such sentences , the WSJ parser regarded the first " ! " or " ? " as ROOT , and " Hang " or " did " as the modifier of the marks . 
NULL ({ }) For ({ 1 }) such ({ 2 }) sentences ({ 3 }) , ({ 4 }) the ({ 5 }) WSJ ({ 6 }) parser ({ 7 }) regarded ({ 8 }) the ({ 9 }) first ({ 10 }) " ({ 11 }) ! ({ 12 }) " ({ 13 }) or ({ 14 }) " ({ 15 }) ? ({ 16 }) " ({ 17 }) as ({ 18 }) ROOT ({ 19 }) , ({ 20 }) and ({ 21 }) " ({ 22 }) Hang ({ 23 }) " ({ 24 }) or ({ 25 }) " ({ 26 }) did ({ 27 }) " ({ 28 }) as ({ 29 }) the ({ 30 }) modifier ({ 31 }) of ({ 32 }) the ({ 33 }) punctuation ({ 34 }) . ({ 35 }) 
# Sentence pair (145) source length 27 target length 36 alignment score : 1.14916e-62
We thought that this kind of errors would partly come fromthe Brown corpus itself . The exclamation or question marks should be inside the quotation , while the Brown corpus usually put the marks outside . 
NULL ({ 15 28 33 }) A ({ }) possible ({ }) reason ({ }) for ({ }) this ({ 4 }) type ({ 5 }) of ({ 6 }) error ({ 7 }) could ({ 8 }) be ({ 22 }) that ({ 3 }) the ({ }) Brown ({ 12 29 }) corpus ({ 13 30 }) places ({ 1 9 14 31 }) exclamation ({ 2 10 11 16 17 32 }) or ({ 18 }) question ({ 19 }) marks ({ 20 34 }) outside ({ 35 }) , ({ 26 }) instead ({ 21 }) of ({ }) inside ({ 23 }) the ({ 24 }) quotation ({ 25 27 }) . ({ 36 }) 
# Sentence pair (146) source length 20 target length 23 alignment score : 2.74044e-18
However , the adapted parser could take in such doubtful construction and gave ROOT to the main verbs as the corpus required . 
NULL ({ 2 3 8 }) The ({ 1 }) adapted ({ 4 }) parser ({ 5 }) could ({ 6 }) handle ({ 7 }) this ({ 9 }) dubious ({ 10 }) construction ({ 11 }) and ({ 12 }) assigned ({ 13 }) ROOT ({ 14 }) to ({ 15 }) the ({ 16 }) main ({ 17 }) verbs ({ 18 }) as ({ 19 }) the ({ 20 }) corpus ({ 21 }) required ({ 22 }) . ({ 23 }) 
# Sentence pair (147) source length 18 target length 25 alignment score : 2.28138e-32
On the other hand , we also observed some still unsolved errors . We would show the two kinds of major errors among them . 
NULL ({ 17 25 }) On ({ 1 }) the ({ 2 }) other ({ 3 }) hand ({ 4 }) , ({ 5 }) we ({ 6 }) also ({ 7 }) observed ({ 8 }) some ({ 9 }) unsolved ({ 10 11 21 }) errors ({ 12 22 }) , ({ }) of ({ 20 }) which ({ }) we ({ 14 }) discuss ({ 15 16 19 23 24 }) two ({ 18 }) . ({ 13 }) 
# Sentence pair (148) source length 43 target length 46 alignment score : 7.20019e-25
First , Brown imperatives and questions , include many conversation sentences , and therefore rather flexible constructions could be observed especially for imperatives , such as " Lift , don't shove lift! " , " Come out , come out in the meadow! " , etc. 
NULL ({ 18 19 22 }) First ({ 1 }) , ({ 2 }) Brown ({ 3 }) imperatives ({ 4 }) and ({ 5 }) questions ({ 6 }) , ({ 7 }) include ({ 8 }) many ({ 9 }) colloquial ({ 10 }) sentences ({ 11 }) , ({ 12 }) which ({ 13 }) have ({ 14 }) rather ({ 15 }) flexible ({ 16 }) constructions ({ 17 }) , ({ }) especially ({ 21 }) imperatives ({ 23 }) , ({ 24 }) such ({ 25 }) as ({ 26 }) " ({ 27 }) Lift ({ 28 }) , ({ 29 }) don't ({ 30 }) shove ({ 31 }) lift! ({ 20 32 }) " ({ 33 }) , ({ 34 }) " ({ 35 }) Come ({ 36 }) out ({ 37 }) , ({ 38 }) come ({ 39 }) out ({ 40 }) in ({ 41 }) the ({ 42 }) meadow! ({ 43 }) " ({ 44 }) , ({ 45 }) etc. ({ 46 }) 
# Sentence pair (149) source length 17 target length 15 alignment score : 5.66761e-09
The parsing models based on the plausibility of constructions could hardly capture such sentences . 
NULL ({ }) The ({ 1 }) parsing ({ 2 }) models ({ 3 }) based ({ 4 }) on ({ 5 }) the ({ 6 }) plausibility ({ 7 }) of ({ 8 }) constructions ({ 9 }) were ({ }) not ({ 11 }) able ({ 10 }) to ({ }) capture ({ 12 }) such ({ 13 }) sentences ({ 14 }) . ({ 15 }) 
# Sentence pair (150) source length 32 target length 36 alignment score : 1.13427e-44
Second , when the different constructions of sentences were in one sentence , such as , the case where to-infinitive phrases or subordinate clauses precede imperatives and questions , the parser would often be confused . 
NULL ({ 4 7 17 30 }) Second ({ 1 }) , ({ 2 }) having ({ 3 }) different ({ 5 }) sentence ({ 8 }) constructions ({ 6 }) within ({ 10 }) a ({ }) single ({ 11 }) sentence ({ 12 }) , ({ 13 }) such ({ 14 }) as ({ 15 }) , ({ 16 }) where ({ 18 19 }) a ({ }) to-infinitive ({ 20 }) phrase ({ 21 }) or ({ 22 }) subordinate ({ 23 }) clause ({ 24 }) precedes ({ 9 25 }) an ({ }) imperative ({ 26 }) or ({ 27 }) question ({ 28 }) , ({ 29 }) often ({ 33 }) confused ({ 32 34 35 }) the ({ }) parser ({ 31 }) . ({ 36 }) 
# Sentence pair (151) source length 84 target length 81 alignment score : 7.1106e-29
For example , for the imperative sentence " To find estimated net farm income , subtract estimated annual farming expenditures . . . " , both of the WSJ and adapted parsers regarded " find " as ROOT , because the parsers regarded the words following " find " as a that-clause complement for the " find " , like " To find [ ( that ) estimated net farm income , subtract estimated annual farming . . .] " . 
NULL ({ 27 55 }) For ({ 1 }) example ({ 2 }) , ({ 3 }) for ({ 4 }) the ({ 5 }) imperative ({ 6 }) sentence ({ 7 }) , ({ }) " ({ 8 }) To ({ 9 }) find ({ 10 }) the ({ }) estimated ({ 11 }) net ({ 12 }) farm ({ 13 }) income ({ 14 }) , ({ 15 }) subtract ({ 16 }) the ({ }) estimated ({ 17 }) annual ({ 18 }) farming ({ 19 }) expenditure ({ 20 }) . ({ 21 }) . ({ 22 }) . ({ 23 }) " ({ 24 }) , ({ 25 }) both ({ 26 }) the ({ 28 }) WSJ ({ 29 }) and ({ 30 }) adapted ({ 31 }) parsers ({ 32 }) regarded ({ 33 }) " ({ 34 }) find ({ 35 }) " ({ 36 }) as ({ 37 }) ROOT ({ 38 }) , ({ 39 }) because ({ 40 }) the ({ 41 }) parsers ({ 42 }) regarded ({ 43 }) the ({ 44 }) words ({ 45 }) following ({ 46 }) " ({ 47 }) find ({ 48 }) " ({ 49 }) as ({ 50 }) a ({ 51 }) that-clause ({ 52 }) complementing ({ 53 54 }) " ({ 56 }) find ({ 57 }) " ({ 58 }) , ({ 59 }) as ({ 60 }) in ({ }) " ({ 61 }) To ({ 62 }) find ({ 63 }) [ ({ 64 }) ( ({ 65 }) that ({ 66 }) ) ({ 67 }) the ({ }) estimated ({ 68 }) net ({ 69 }) farm ({ 70 }) income ({ 71 }) , ({ 72 }) subtract ({ 73 }) the ({ }) estimated ({ 74 }) annual ({ 75 }) farming ({ 76 }) . ({ 77 }) . ({ 78 }) .] ({ 79 }) " ({ 80 }) . ({ 81 }) 
# Sentence pair (152) source length 19 target length 18 alignment score : 3.64027e-07
It would be difficult for the parsers to know where the main clause in such complex sentences . 
NULL ({ }) It ({ 1 }) would ({ 2 }) be ({ 3 }) difficult ({ 4 }) for ({ 5 }) the ({ 6 }) parsers ({ 7 }) to ({ 8 }) know ({ 9 }) which ({ 10 }) is ({ }) the ({ 11 }) main ({ 12 }) clause ({ 13 }) in ({ 14 }) such ({ 15 }) complex ({ 16 }) sentences ({ 17 }) . ({ 18 }) 
# Sentence pair (153) source length 14 target length 15 alignment score : 6.01032e-08
This type of errors would hardly be solved only by increasing the training data . 
NULL ({ }) This ({ 1 }) type ({ 2 }) of ({ 3 }) error ({ 4 }) cannot ({ 5 6 }) be ({ 7 }) solved ({ 8 }) merely ({ 9 }) by ({ 10 }) increasing ({ 11 }) the ({ 12 }) training ({ 13 }) data ({ 14 }) . ({ 15 }) 
# Sentence pair (154) source length 26 target length 24 alignment score : 1.62958e-08
Imperatives or questions sentences consist not only of pure imperative or question clause , but also of other constructions of phrases or clauses . 
NULL ({ }) Imperative ({ 1 }) or ({ 2 }) question ({ 3 }) sentences ({ 4 }) typically ({ }) consist ({ 5 }) not ({ 6 }) only ({ 7 }) of ({ 8 }) a ({ }) pure ({ 9 }) imperative ({ 10 }) or ({ 11 }) question ({ 12 }) clause ({ 13 }) , ({ 14 }) but ({ 15 }) also ({ 16 }) of ({ 17 }) other ({ 18 }) constructions ({ 19 }) of ({ 20 }) phrases ({ 21 }) or ({ 22 }) clauses ({ 23 }) . ({ 24 }) 
# Sentence pair (155) source length 22 target length 21 alignment score : 6.08105e-29
The parser would parse such complex sentences without partition into each construction , and therefore it would sometimes be confused . 
NULL ({ }) These ({ 1 }) complex ({ 6 }) sentences ({ 7 }) were ({ }) parsed ({ 5 }) without ({ 8 }) being ({ }) partitioned ({ 9 }) into ({ 10 }) separate ({ 11 }) constructions ({ 12 }) , ({ 13 }) and ({ 14 }) as ({ }) a ({ }) result ({ 15 }) the ({ }) parser ({ 2 }) sometimes ({ 3 17 18 }) became ({ 4 16 19 }) confused ({ 20 }) . ({ 21 }) 
# Sentence pair (156) source length 12 target length 13 alignment score : 5.86012e-11
Both of Brown questions and QuestionBank are in the domain of question . 
NULL ({ 2 11 }) Both ({ 1 }) the ({ }) Brown ({ 3 }) questions ({ 4 }) and ({ 5 }) QuestionBank ({ 6 }) are ({ 7 }) in ({ 8 }) the ({ 9 }) question ({ 12 }) domain ({ 10 }) . ({ 13 }) 
# Sentence pair (157) source length 20 target length 21 alignment score : 1.0345e-09
In this section , we examined whether the parser adapted to one domain would be portable to the other domain . 
NULL ({ 18 }) In ({ 1 }) this ({ 2 }) section ({ 3 }) , ({ 4 }) we ({ 5 }) examine ({ 6 }) whether ({ 7 }) a ({ 8 }) parser ({ 9 }) adapted ({ 10 }) to ({ 11 }) one ({ 12 }) domain ({ 13 }) could ({ 14 }) be ({ 15 }) ported ({ 16 }) to ({ 17 }) another ({ 19 }) domain ({ 20 }) . ({ 21 }) 
# Sentence pair (158) source length 25 target length 24 alignment score : 4.8209e-08
QuestionBankdoes not give function tags , and therefore in training and evaluation of the parsers , abstracted dependencies were extracted from the corpus . 
NULL ({ }) QuestionBank ({ 1 }) does ({ }) not ({ 2 }) provide ({ 3 }) function ({ 4 }) tags ({ 5 }) , ({ 6 }) and ({ 7 }) therefore ({ 8 }) in ({ 9 }) training ({ 10 }) and ({ 11 }) evaluation ({ 12 }) of ({ 13 }) the ({ 14 }) parsers ({ 15 }) , ({ 16 }) abstracted ({ 17 }) dependencies ({ 18 }) were ({ 19 }) extracted ({ 20 }) from ({ 21 }) the ({ 22 }) corpus ({ 23 }) . ({ 24 }) 
# Sentence pair (159) source length 23 target length 22 alignment score : 1.95199e-13
Therefore , the parser adapted to one domain could not give correct dependency labels on such functions for the other domain . 
NULL ({ 16 }) As ({ 1 }) a ({ }) result ({ }) , ({ 2 }) a ({ 3 }) parser ({ 4 }) adapted ({ 5 }) to ({ 6 }) one ({ 7 }) domain ({ 8 }) could ({ 9 }) not ({ 10 }) provide ({ 11 }) correct ({ 12 }) dependency ({ 13 }) labels ({ 14 }) on ({ 15 }) functions ({ 17 }) for ({ 18 }) the ({ 19 }) other ({ 20 }) domain ({ 21 }) . ({ 22 }) 
# Sentence pair (160) source length 40 target length 44 alignment score : 1.67724e-28
However , we would be able to expect that sentence constructions would be basically common and portable between two domains , which would contribute to give correct boundary for phrases and therefore the correct dependencies in phrases would be introduced by the adaptation . 
NULL ({ 7 13 25 }) However ({ 1 }) , ({ 2 }) we ({ 3 }) would ({ 4 }) expect ({ 5 6 8 12 }) that ({ 9 }) sentence ({ 10 }) constructions ({ 11 }) are ({ }) basically ({ 14 }) common ({ 15 }) and ({ 16 }) portable ({ 17 }) between ({ 18 }) two ({ 19 }) domains ({ 20 }) , ({ 21 }) which ({ 22 }) would ({ 23 24 }) provide ({ 26 }) a ({ }) correct ({ 27 }) boundary ({ 28 }) for ({ 29 }) phrases ({ 30 }) and ({ 31 }) therefore ({ 32 }) , ({ }) the ({ 33 }) correct ({ 34 }) dependencies ({ 35 }) in ({ 36 }) phrases ({ 37 }) would ({ 38 }) be ({ 39 }) introduced ({ 40 }) by ({ 41 }) the ({ 42 }) adaptation ({ 43 }) . ({ 44 }) 
# Sentence pair (161) source length 21 target length 21 alignment score : 2.92848e-05
Table \REF shows the parsing or tagging accuracies of each parser and the POS tagger for Brown questions and QuestionBank . 
NULL ({ }) Table ({ 1 }) \REF ({ 2 }) gives ({ 3 }) the ({ 4 }) parsing ({ 5 }) or ({ 6 }) tagging ({ 7 }) accuracy ({ 8 }) of ({ 9 }) each ({ 10 }) parser ({ 11 }) and ({ 12 }) the ({ 13 }) POS ({ 14 }) tagger ({ 15 }) for ({ 16 }) Brown ({ 17 }) questions ({ 18 }) and ({ 19 }) QuestionBank ({ 20 }) . ({ 21 }) 
# Sentence pair (162) source length 23 target length 19 alignment score : 2.33314e-16
the difference from Table \REF was that the parsers and the tagger were adapted to another question domain . 
NULL ({ }) These ({ 1 }) results ({ }) differ ({ 2 }) from ({ 3 }) those ({ }) in ({ }) Table ({ 4 }) \REF ({ 5 }) in ({ 6 }) that ({ 7 }) the ({ 8 }) parsers ({ 9 }) and ({ 10 }) the ({ 11 }) tagger ({ 12 }) have ({ 13 }) been ({ }) adapted ({ 14 }) to ({ 15 }) another ({ 16 }) question ({ 17 }) domain ({ 18 }) . ({ 19 }) 
# Sentence pair (163) source length 28 target length 25 alignment score : 4.72877e-13
The table shows that the parsers adapted to Brown questions improved the parsing accuracies for QuestionBank , while the parsers adapted to QuestionBank decreased . 
NULL ({ }) The ({ 1 }) table ({ 2 }) shows ({ 3 }) that ({ 4 }) the ({ 5 }) parsers ({ 6 }) adapted ({ 7 }) to ({ 8 }) the ({ }) Brown ({ 9 }) questions ({ 10 }) improved ({ 11 }) their ({ 12 }) parsing ({ 13 }) accuracy ({ 14 }) with ({ 15 }) QuestionBank ({ 16 }) , ({ 17 }) whereas ({ 18 }) the ({ 19 }) parsers ({ 20 }) adapted ({ 21 }) to ({ 22 }) QuestionBank ({ 23 }) decreased ({ 24 }) in ({ }) accuracy ({ }) . ({ 25 }) 
# Sentence pair (164) source length 7 target length 7 alignment score : 0.000335952
Table \REF could explain the result . 
NULL ({ }) Table ({ 1 }) \REF ({ 2 }) could ({ 3 }) explain ({ 4 }) this ({ 5 }) result ({ 6 }) . ({ 7 }) 
# Sentence pair (165) source length 41 target length 35 alignment score : 1.81167e-56
With Brown questions , we could learn wh-questions which QuestionBank mainly contain , while with QuestionBank , we could not we could not learn yes-no questions which more than half of Brown corpus contain . 
NULL ({ 5 17 27 }) Using ({ 1 }) Brown ({ 2 }) questions ({ 3 }) , ({ 4 }) many ({ }) wh-questions ({ 8 }) were ({ }) learnt ({ 7 }) , ({ }) which ({ 9 }) is ({ }) what ({ }) QuestionBank ({ 10 }) mainly ({ 11 }) contains ({ }) . ({ }) On ({ }) the ({ }) other ({ 23 }) hand ({ 12 }) , ({ 13 }) despite ({ 14 18 21 }) yes-no ({ 6 15 19 22 25 }) questions ({ 26 }) constituting ({ 24 }) more ({ 28 }) than ({ 29 }) half ({ 30 }) the ({ }) Brown ({ 32 }) corpus ({ 33 }) , ({ }) these ({ }) were ({ }) not ({ 20 }) learnt ({ 34 }) using ({ }) QuestionBank ({ 16 }) for ({ 31 }) training ({ }) . ({ 35 }) 
# Sentence pair (166) source length 13 target length 14 alignment score : 1.07744e-08
A question domain contains various types of questions and gives various sentence constructions . 
NULL ({ }) A ({ 1 }) question ({ 2 }) domain ({ 3 }) contains ({ 4 }) various ({ 5 }) types ({ 6 }) of ({ 7 }) questions ({ 8 }) with ({ 9 }) various ({ 10 11 }) sentence ({ 12 }) constructions ({ 13 }) . ({ 14 }) 
# Sentence pair (167) source length 16 target length 15 alignment score : 1.86916e-07
In order to parse questions correctly , we should capture each of them correctly . 
NULL ({ }) In ({ 1 }) order ({ 2 }) to ({ 3 }) parse ({ 4 }) questions ({ 5 }) correctly ({ 6 }) , ({ 7 }) we ({ 8 }) need ({ 9 }) to ({ }) capture ({ 10 }) each ({ 11 }) of ({ 12 }) these ({ 13 }) correctly ({ 14 }) . ({ 15 }) 
# Sentence pair (168) source length 17 target length 19 alignment score : 1.11155e-15
This type of problem would not be noticed so much when we were working mainly on declarative sentences . 
NULL ({ }) This ({ 1 }) type ({ 2 }) of ({ 3 }) problem ({ 4 }) was ({ 5 }) not ({ 6 }) so ({ 9 }) obvious ({ 7 8 10 }) when ({ 11 }) we ({ 12 }) were ({ 13 }) working ({ 14 }) mainly ({ 15 }) with ({ 16 }) declarative ({ 17 }) sentences ({ 18 }) . ({ 19 }) 
# Sentence pair (169) source length 25 target length 27 alignment score : 4.47949e-18
Through the experiments on various parsers we observed that simple supervised adaptation methods are insufficient to arrive at theparsing accuracy comparable to that of declarative sentences . 
NULL ({ 2 22 }) Through ({ 1 }) experiments ({ 3 }) with ({ 4 }) various ({ 5 }) parsers ({ 6 }) we ({ 7 }) observed ({ 8 }) that ({ 9 }) simple ({ 10 }) supervised ({ 11 }) adaptation ({ 12 }) methods ({ 13 }) are ({ 14 }) insufficient ({ 15 }) to ({ 16 }) achieve ({ 17 }) parsing ({ 19 }) accuracy ({ 20 }) comparable ({ 21 }) with ({ 18 }) that ({ 23 }) of ({ 24 }) declarative ({ 25 }) sentences ({ 26 }) . ({ 27 }) 
# Sentence pair (170) source length 32 target length 31 alignment score : 4.06994e-15
This observation holds both for POS tagging and syntactic parsing , and itindicates that we need fundamental improvement of parsers , such as re-constructing feature designs or changing parsing models . 
NULL ({ 19 }) This ({ 1 }) observation ({ 2 }) holds ({ 3 }) both ({ 4 }) for ({ 5 }) POS ({ 6 }) tagging ({ 7 }) and ({ 8 }) syntactic ({ 9 }) parsing ({ 10 }) , ({ 11 }) and ({ 12 }) indicates ({ 13 }) that ({ 14 }) the ({ }) parsers ({ 15 }) need ({ 16 }) to ({ }) be ({ }) fundamentally ({ 17 18 }) improved ({ 20 }) , ({ 21 }) such ({ 22 }) as ({ 23 }) re-constructing ({ 24 }) feature ({ 25 }) designs ({ 26 }) or ({ 27 }) changing ({ 28 }) parsing ({ 29 }) models ({ 30 }) . ({ 31 }) 
# Sentence pair (171) source length 44 target length 44 alignment score : 8.84308e-26
Following the present work , future work should include investigating parsing frameworks that are robust for sentences with various sentence constructions , and / or methods that can effectively adapt a parser to different sentence constructions including imperatives , questions , and more . 
NULL ({ 2 39 }) Following ({ 1 }) on ({ }) from ({ 3 }) this ({ }) study ({ 4 }) , ({ 5 }) future ({ 6 }) work ({ 7 }) includes ({ 8 }) investigating ({ 9 10 }) parsing ({ 11 }) frameworks ({ 12 }) that ({ 13 }) are ({ 14 }) robust ({ 15 }) for ({ 16 }) sentences ({ 17 }) with ({ 18 }) different ({ 19 }) sentence ({ 20 }) constructions ({ 21 }) , ({ 22 }) and ({ 23 }) / ({ 24 }) or ({ 25 }) methods ({ 26 }) that ({ 27 }) can ({ 28 }) effectively ({ 29 }) adapt ({ 30 }) a ({ 31 }) parser ({ 32 }) to ({ 33 }) different ({ 34 }) sentence ({ 35 }) constructions ({ 36 }) including ({ 37 }) imperatives ({ 38 }) and ({ }) questions ({ 40 }) , ({ 41 }) among ({ 42 }) others ({ 43 }) . ({ 44 }) 
# Sentence pair (172) source length 32 target length 33 alignment score : 4.07121e-30
While word segmentation is a necessary step to process languages like Chinese and Japanese , its effects on Statistical Machine Translation ( SMT ) have not been discussed intensively in such languages . 
NULL ({ 5 8 }) While ({ 1 }) word ({ 2 }) segmentation ({ 3 }) is ({ 4 }) necessary ({ 6 }) for ({ }) processing ({ 7 }) the ({ }) Chinese ({ 9 11 12 }) and ({ 13 }) Japanese ({ 14 }) languages ({ 10 }) , ({ 15 }) its ({ 16 }) effects ({ 17 }) on ({ 18 }) Statistical ({ 19 }) Machine ({ 20 }) Translation ({ 21 }) ( ({ 22 }) SMT ({ 23 }) ) ({ 24 }) have ({ 25 }) not ({ 26 }) yet ({ }) been ({ 27 }) thoroughly ({ 28 }) discussed ({ 29 }) for ({ 30 }) such ({ 31 }) languages ({ 32 }) . ({ 33 }) 
# Sentence pair (173) source length 31 target length 28 alignment score : 1.44157e-07
In this paper , we investigate the effects of word segmentation methods on SMT , by comparing evaluation results of translation outputs while varying word segmentation methods . 
NULL ({ }) In ({ 1 }) this ({ 2 }) paper ({ 3 }) , ({ 4 }) we ({ 5 }) investigate ({ 6 }) the ({ 7 }) effects ({ 8 }) of ({ 9 }) word ({ 10 }) segmentation ({ 11 }) methods ({ 12 }) on ({ 13 }) SMT ({ 14 }) , ({ 15 }) by ({ 16 }) comparing ({ 17 }) the ({ }) evaluation ({ 18 }) results ({ 19 }) of ({ 20 }) the ({ }) translation ({ 21 }) outputs ({ 22 }) , ({ }) while ({ 23 }) varying ({ 24 }) word ({ 25 }) segmentation ({ 26 }) methods ({ 27 }) . ({ 28 }) 
# Sentence pair (174) source length 17 target length 16 alignment score : 0.000242363
Additionally , meta-evaluations of evaluation metrics are also provided to investigate validity of the metrics . 
NULL ({ }) Additionally ({ 1 }) , ({ 2 }) meta-evaluations ({ 3 }) of ({ 4 }) evaluation ({ 5 }) metrics ({ 6 }) are ({ 7 }) also ({ 8 }) provided ({ 9 }) to ({ 10 }) investigate ({ 11 }) the ({ }) validity ({ 12 }) of ({ 13 }) the ({ 14 }) metrics ({ 15 }) . ({ 16 }) 
# Sentence pair (175) source length 26 target length 23 alignment score : 4.55716e-11
The experiments revealed that supervised morphological analyzers were competitive , and considerably better than an unsupervised analyzer and a heuristic segmentation method . 
NULL ({ }) The ({ 1 }) experimental ({ 2 }) results ({ }) confirmed ({ 3 }) that ({ 4 }) supervised ({ 5 }) morphological ({ 6 }) analyzers ({ 7 }) were ({ 8 }) competitive ({ 9 }) with ({ }) , ({ 10 }) and ({ 11 }) performed ({ }) considerably ({ 12 }) better ({ 13 }) than ({ 14 }) an ({ 15 }) unsupervised ({ 16 }) analyzer ({ 17 }) and ({ 18 }) a ({ 19 }) heuristic ({ 20 }) segmentation ({ 21 }) method ({ 22 }) . ({ 23 }) 
# Sentence pair (176) source length 28 target length 28 alignment score : 3.5484e-09
However , a character-based segmentation has achieved 10 .27 positive and 1 .95 negative differences in word-based and character-based BLEU , depending on corpus sizes and domains . 
NULL ({ 6 }) However ({ 1 }) , ({ 2 }) a ({ 3 }) character-based ({ 4 }) segmentation ({ 5 }) achieved ({ 7 }) 10 ({ 8 }) .27 ({ 9 }) positive ({ 10 }) and ({ 11 }) 1 ({ 12 }) .95 ({ 13 }) negative ({ 14 }) differences ({ 15 }) in ({ 16 }) word-based ({ 17 }) and ({ 18 }) character-based ({ 19 }) BLEU ({ 20 }) , ({ 21 }) depending ({ 22 }) on ({ 23 }) the ({ }) corpus ({ 24 }) sizes ({ 25 }) and ({ 26 }) domains ({ 27 }) . ({ 28 }) 
# Sentence pair (177) source length 28 target length 26 alignment score : 1.04813e-17
For this result we discuss the problem of the comparability of evaluation metrics and the possibility of better word segmentation than popular supervised morphological analyzers . 
NULL ({ 15 }) In ({ 1 }) conclusion ({ 2 3 }) , ({ }) we ({ 4 }) discuss ({ 5 }) the ({ 6 }) problem ({ 7 }) of ({ 8 }) the ({ 9 }) comparability ({ 10 }) of ({ 11 }) evaluation ({ 12 }) metrics ({ 13 }) , ({ }) and ({ 14 }) consider ({ 16 }) ways ({ }) of ({ 17 }) improving ({ 18 }) word ({ 19 }) segmentation ({ 20 }) more ({ }) than ({ 21 }) popular ({ 22 }) supervised ({ 23 }) morphological ({ 24 }) analyzers ({ 25 }) . ({ 26 }) 
# Sentence pair (178) source length 20 target length 20 alignment score : 3.50754e-17
Several natural languages like Chinese and Japanese do not have to put spaces between words in their written forms . 
NULL ({ 10 11 }) Several ({ 1 }) languages ({ 2 3 }) , ({ }) including ({ 4 }) Chinese ({ 5 }) and ({ 6 }) Japanese ({ 7 }) , ({ }) do ({ 8 }) not ({ 9 }) require ({ 12 }) spaces ({ 13 }) between ({ 14 }) words ({ 15 }) , ({ }) in ({ 16 }) their ({ 17 }) written ({ 18 }) forms ({ 19 }) . ({ 20 }) 
# Sentence pair (179) source length 14 target length 14 alignment score : 0.00643332
In order to process such languages , we need to tokenize each sentence . 
NULL ({ }) In ({ 1 }) order ({ 2 }) to ({ 3 }) process ({ 4 }) such ({ 5 }) languages ({ 6 }) , ({ 7 }) we ({ 8 }) need ({ 9 }) to ({ 10 }) tokenize ({ 11 }) each ({ 12 }) sentence ({ 13 }) . ({ 14 }) 
# Sentence pair (180) source length 7 target length 7 alignment score : 0.104173
This process is called word segmentation . 
NULL ({ }) This ({ 1 }) process ({ 2 }) is ({ 3 }) called ({ 4 }) word ({ 5 }) segmentation ({ 6 }) . ({ 7 }) 
# Sentence pair (181) source length 28 target length 21 alignment score : 3.95561e-24
Since the process is fundamental and indispensable , we need to explore how word segmentation affects Natural Language Processing applications . 
NULL ({ 2 11 }) Since ({ 1 }) word ({ }) segmentation ({ }) is ({ 4 }) a ({ }) fundamental ({ 5 }) process ({ 3 }) , ({ }) and ({ 6 }) is ({ }) therefore ({ 10 }) indispensable ({ 7 }) , ({ 8 }) it ({ }) is ({ }) important ({ }) that ({ }) we ({ 9 }) explore ({ 12 }) how ({ 13 }) word ({ 14 }) segmentation ({ 15 }) affects ({ 16 }) Natural ({ 17 }) Language ({ 18 }) Processing ({ 19 }) applications ({ 20 }) . ({ 21 }) 
# Sentence pair (182) source length 25 target length 26 alignment score : 8.00841e-10
Therefore , we investigate how Japanese word segmentation affects on SMT between English and Japanese , by comparing various word segmentation methods and evaluation metrics . 
NULL ({ 10 }) Thus ({ 1 }) , ({ 2 }) we ({ 3 }) investigate ({ 4 }) how ({ 5 }) Japanese ({ 6 }) word ({ 7 }) segmentation ({ 8 }) affects ({ 9 }) SMT ({ 11 }) between ({ 12 }) English ({ 13 }) and ({ 14 }) Japanese ({ 15 }) , ({ 16 }) by ({ 17 }) comparing ({ 18 }) various ({ 19 }) word ({ 20 }) segmentation ({ 21 }) methods ({ 22 }) and ({ 23 }) evaluation ({ 24 }) metrics ({ 25 }) . ({ 26 }) 
# Sentence pair (183) source length 15 target length 15 alignment score : 0.00118754
The word segmentation methods includes both standard Japanese morphological analyzers and several heuristic methods . 
NULL ({ }) The ({ 1 }) word ({ 2 }) segmentation ({ 3 }) methods ({ 4 }) include ({ 5 }) both ({ 6 }) standard ({ 7 }) Japanese ({ 8 }) morphological ({ 9 }) analyzers ({ 10 }) and ({ 11 }) several ({ 12 }) heuristic ({ 13 }) methods ({ 14 }) . ({ 15 }) 
# Sentence pair (184) source length 14 target length 11 alignment score : 5.71358e-09
We also examine an unsupervised morphological analyzer and its results . 
NULL ({ }) In ({ 1 }) addition ({ 2 }) , ({ }) we ({ }) examine ({ 3 }) an ({ 4 }) unsupervised ({ 5 }) morphological ({ 6 }) analyzer ({ 7 }) , ({ }) and ({ 8 }) its ({ 9 }) results ({ 10 }) . ({ 11 }) 
# Sentence pair (185) source length 27 target length 30 alignment score : 3.10808e-17
In addition , we focus on the meta-evaluation of the current evaluation metrics and find whether the metrics are consistent or not , when we vary word segmentation methods . 
NULL ({ 3 4 }) We ({ 1 }) focus ({ 2 5 }) on ({ 6 }) the ({ 7 }) meta-evaluation ({ 8 }) of ({ 9 }) the ({ 10 }) current ({ 11 }) evaluation ({ 12 }) metrics ({ 13 }) and ({ 14 }) determine ({ 15 }) whether ({ 16 }) the ({ 17 }) metrics ({ 18 }) are ({ 19 }) consistent ({ 20 }) or ({ 21 }) not ({ 22 }) , ({ 23 }) when ({ 24 }) we ({ 25 }) vary ({ 26 }) word ({ 27 }) segmentation ({ 28 }) methods ({ 29 }) . ({ 30 }) 
# Sentence pair (186) source length 36 target length 35 alignment score : 6.98634e-07
Al-Haj and Lavie ( 2012 ) compared 12 heuristic word segmentation methods based on outputs of a standard Arabic POS tagger , and found the optimum combination in terms of BLEU on English-Arabic SMT . 
NULL ({ }) Al-Haj ({ 1 }) and ({ 2 }) Lavie ({ 3 }) ( ({ 4 }) 2012 ({ 5 }) ) ({ 6 }) compared ({ 7 }) 12 ({ 8 }) heuristic ({ 9 }) word ({ 10 }) segmentation ({ 11 }) methods ({ 12 }) based ({ 13 }) on ({ 14 }) the ({ }) outputs ({ 15 }) of ({ 16 }) a ({ 17 }) standard ({ 18 }) Arabic ({ 19 }) POS ({ 20 }) tagger ({ 21 }) , ({ 22 }) and ({ 23 }) found ({ 24 }) the ({ 25 }) optimum ({ 26 }) combination ({ 27 }) in ({ 28 }) terms ({ 29 }) of ({ 30 }) BLEU ({ 31 }) on ({ 32 }) English-Arabic ({ 33 }) SMT ({ 34 }) . ({ 35 }) 
# Sentence pair (187) source length 15 target length 15 alignment score : 1.71406e-08
They acquired the 2 .3 score improvement from the worst to the best combinations . 
NULL ({ 12 }) They ({ 1 }) acquired ({ 2 }) a ({ 3 }) 2 ({ 4 }) .3 ({ 5 }) score ({ 6 }) improvement ({ 7 }) in ({ }) comparing ({ 8 }) the ({ 9 }) worst ({ 10 }) to ({ 11 }) best ({ 13 }) combinations ({ 14 }) . ({ 15 }) 
# Sentence pair (188) source length 3 target length 3 alignment score : 0.285025
Wang et al. 
NULL ({ }) Wang ({ 1 }) et ({ 2 }) al. ({ 3 }) 
# Sentence pair (189) source length 25 target length 24 alignment score : 3.03046e-05
( 2010 ) suggested a new short unit word segmentation standard in Chinese which defines a more frequent string subset as a word . 
NULL ({ }) ( ({ 1 }) 2010 ({ 2 }) ) ({ 3 }) suggested ({ 4 }) a ({ 5 }) new ({ 6 }) short ({ 7 }) unit ({ 8 }) word ({ 9 }) segmentation ({ 10 }) standard ({ 11 }) in ({ 12 }) Chinese ({ 13 }) , ({ }) which ({ 14 }) defines ({ 15 }) a ({ 16 }) more ({ 17 }) frequent ({ 18 }) string ({ 19 }) subset ({ 20 }) as ({ 21 }) a ({ 22 }) word ({ 23 }) . ({ 24 }) 
# Sentence pair (190) source length 18 target length 24 alignment score : 2.54654e-26
For instance , They separated one word "  globalization " into two words "  global " and "  -lization " . 
NULL ({ }) For ({ 1 }) instance ({ 2 }) , ({ 3 }) one ({ 6 }) word ({ 7 })  ({ 4 }) globalization ({ 9 }) was ({ }) separated ({ 5 }) into ({ 12 }) two ({ 13 }) words ({ 14 })  ({ 17 }) global ({ 16 }) and ({ 19 })  ({ 10 22 }) -lization ({ 8 11 15 18 20 21 23 }) . ({ 24 }) 
# Sentence pair (191) source length 15 target length 15 alignment score : 0.00197056
By this standard , they obtained 1 .0 BLEU score improvement within Chinese-Japanese SMT . 
NULL ({ }) By ({ 1 }) this ({ 2 }) standard ({ 3 }) , ({ 4 }) they ({ 5 }) obtained ({ 6 }) 1 ({ 7 }) .0 ({ 8 }) BLEU ({ 9 }) score ({ 10 }) improvement ({ 11 }) within ({ 12 }) Chinese-Japanese ({ 13 }) SMT ({ 14 }) . ({ 15 }) 
# Sentence pair (192) source length 22 target length 20 alignment score : 7.24584e-13
Though , they have not discussed about BLEU is a good metric for such an evaluation of word segmentation . 
NULL ({ }) However ({ 1 }) , ({ 2 }) it ({ 3 }) has ({ 4 }) not ({ 5 }) yet ({ }) been ({ }) discussed ({ 6 }) whether ({ 7 }) BLEU ({ 8 }) is ({ 9 }) a ({ 10 }) good ({ 11 }) metric ({ 12 }) for ({ 13 }) such ({ 14 }) an ({ 15 }) evaluation ({ 16 }) of ({ 17 }) word ({ 18 }) segmentation ({ 19 }) . ({ 20 }) 
# Sentence pair (193) source length 18 target length 18 alignment score : 1.09857e-09
In addition , comparison of morphological analyzers are necessary because different analyzers produce different outputs to SMT . 
NULL ({ 5 }) In ({ 1 }) addition ({ 2 }) , ({ 3 }) comparing ({ 4 }) morphological ({ 6 }) analyzers ({ 7 }) is ({ 8 }) necessary ({ 9 }) , ({ }) because ({ 10 }) different ({ 11 }) analyzers ({ 12 }) produce ({ 13 }) different ({ 14 }) outputs ({ 15 }) to ({ 16 }) SMT ({ 17 }) . ({ 18 }) 
# Sentence pair (194) source length 11 target length 12 alignment score : 2.54818e-09
Therefore , we conduct several translation tasks between English and Japanese . 
NULL ({ 2 }) We ({ }) therefore ({ 1 }) conduct ({ 3 4 }) several ({ 5 }) translation ({ 6 }) tasks ({ 7 }) between ({ 8 }) English ({ 9 }) and ({ 10 }) Japanese ({ 11 }) . ({ 12 }) 
# Sentence pair (195) source length 17 target length 17 alignment score : 0.00197583
We measure the qualities of Japanese morphological analyzers and compare them with other word segmentation methods . 
NULL ({ }) We ({ 1 }) measure ({ 2 }) the ({ 3 }) qualities ({ 4 }) of ({ 5 }) Japanese ({ 6 }) morphological ({ 7 }) analyzers ({ 8 }) and ({ 9 }) compare ({ 10 }) them ({ 11 }) with ({ 12 }) other ({ 13 }) word ({ 14 }) segmentation ({ 15 }) methods ({ 16 }) . ({ 17 }) 
# Sentence pair (196) source length 12 target length 11 alignment score : 0.00231233
We also investigate consistencies of evaluation metrics by comparing results . 
NULL ({ }) We ({ 1 }) also ({ 2 }) investigate ({ 3 }) consistencies ({ 4 }) of ({ 5 }) evaluation ({ 6 }) metrics ({ 7 }) by ({ 8 }) comparing ({ 9 }) the ({ }) results ({ 10 }) . ({ 11 }) 
# Sentence pair (197) source length 17 target length 16 alignment score : 7.32224e-07
This work aims to empirically compare representative word segmentation methods in terms of SMT quality . 
NULL ({ }) This ({ 1 }) work ({ 2 }) aims ({ 3 }) at ({ 4 }) empirically ({ 5 }) comparing ({ 6 }) representative ({ 7 }) word ({ 8 }) segmentation ({ 9 }) methods ({ 10 }) in ({ 11 }) terms ({ 12 }) of ({ 13 }) the ({ }) SMT ({ 14 }) quality ({ 15 }) . ({ 16 }) 
# Sentence pair (198) source length 12 target length 12 alignment score : 0.00523112
The following experiments are designed in order to answer these questions : 
NULL ({ }) The ({ 1 }) following ({ 2 }) experiments ({ 3 }) are ({ 4 }) designed ({ 5 }) in ({ 6 }) order ({ 7 }) to ({ 8 }) answer ({ 9 }) these ({ 10 }) questions ({ 11 }) : ({ 12 }) 
# Sentence pair (199) source length 34 target length 32 alignment score : 1.36927e-07
- How a variety of word segmentation methods ( supervised morphological analysis , unsupervised segmentation , and heuristic methods ) affect SMT evaluation metrics , depending on corpus sizes and domains . 
NULL ({ }) - ({ 1 }) How ({ 2 }) a ({ 3 }) variety ({ 4 }) of ({ 5 }) word ({ 6 }) segmentation ({ 7 }) methods ({ 8 }) ( ({ 9 }) supervised ({ 10 }) morphological ({ 11 }) analysis ({ 12 }) , ({ 13 }) unsupervised ({ 14 }) segmentation ({ 15 }) , ({ 16 }) and ({ 17 }) heuristic ({ 18 }) methods ({ 19 }) ) ({ 20 }) affects ({ 21 }) the ({ }) SMT ({ 22 }) evaluation ({ 23 }) metrics ({ 24 }) , ({ 25 }) depending ({ 26 }) on ({ 27 }) the ({ }) corpus ({ 28 }) sizes ({ 29 }) and ({ 30 }) domains ({ 31 }) . ({ 32 }) 
# Sentence pair (200) source length 18 target length 17 alignment score : 0.000242056
- Whether or not SMT evaluation metrics provide a consistent measure while varying word segmentation methods . 
NULL ({ }) - ({ 1 }) Whether ({ 2 }) or ({ 3 }) not ({ 4 }) SMT ({ 5 }) evaluation ({ 6 }) metrics ({ 7 }) provide ({ 8 }) a ({ 9 }) consistent ({ 10 }) measure ({ 11 }) , ({ }) while ({ 12 }) varying ({ 13 }) word ({ 14 }) segmentation ({ 15 }) methods ({ 16 }) . ({ 17 }) 
# Sentence pair (201) source length 34 target length 28 alignment score : 1.0865e-14
We setup word segmentation methods , corpora , and evaluation metrics as three parameters of our experiments to see the effects of Japanese word segmentation on SMT . 
NULL ({ }) We ({ 1 }) set ({ }) up ({ 2 }) word ({ 3 }) segmentation ({ 4 }) methods ({ 5 }) , ({ 6 }) corpora ({ 7 }) , ({ 8 }) and ({ 9 }) evaluation ({ 10 }) metrics ({ 11 }) , ({ }) as ({ 12 }) the ({ }) three ({ 13 }) parameters ({ 14 }) for ({ 15 }) our ({ 16 }) experiments ({ 17 }) , ({ }) in ({ }) order ({ }) to ({ 18 }) observe ({ 19 }) the ({ 20 }) effects ({ 21 }) of ({ 22 }) Japanese ({ 23 }) word ({ 24 }) segmentation ({ 25 }) on ({ 26 }) SMT ({ 27 }) . ({ 28 }) 
# Sentence pair (202) source length 26 target length 28 alignment score : 1.34087e-08
As shown in Table 1 , the following word segmentation methods output delimiters ( " | " represents a delimiter ) for a given input character sequence . 
NULL ({ }) As ({ 1 }) shown ({ 2 }) in ({ 3 }) Table ({ 4 }) 1 ({ 5 }) , ({ 6 }) the ({ 7 }) following ({ 8 }) word ({ 9 }) segmentation ({ 10 }) methods ({ 11 }) output ({ 12 }) delimiters ({ 13 }) ( ({ 14 }) | ({ 15 16 17 }) represents ({ 18 }) a ({ 19 }) delimiter ({ 20 }) ) ({ 21 }) for ({ 22 }) a ({ 23 }) given ({ 24 }) input ({ 25 }) character ({ 26 }) sequence ({ 27 }) . ({ 28 }) 
# Sentence pair (203) source length 19 target length 19 alignment score : 0.00151294
The most popular method for Japanese word segmentation is to apply a morphological analyzer to obtain morpheme-based segmentation . 
NULL ({ }) The ({ 1 }) most ({ 2 }) popular ({ 3 }) method ({ 4 }) for ({ 5 }) Japanese ({ 6 }) word ({ 7 }) segmentation ({ 8 }) is ({ 9 }) to ({ 10 }) apply ({ 11 }) a ({ 12 }) morphological ({ 13 }) analyzer ({ 14 }) to ({ 15 }) obtain ({ 16 }) morpheme-based ({ 17 }) segmentation ({ 18 }) . ({ 19 }) 
# Sentence pair (204) source length 17 target length 20 alignment score : 8.41027e-17
It is , however , not clear which analyzer works better for the SMT task than the other analyzers . 
NULL ({ 17 }) It ({ 1 }) is ({ 2 }) ; ({ 3 }) however ({ 4 }) , ({ 5 }) unclear ({ 6 7 16 18 19 }) as ({ }) to ({ }) which ({ 8 }) analyzer ({ 9 }) works ({ 10 }) better ({ 11 }) for ({ 12 }) the ({ 13 }) SMT ({ 14 }) task ({ 15 }) . ({ 20 }) 
# Sentence pair (205) source length 12 target length 12 alignment score : 0.0115563
Therefore , we use four representative morphological analyzers and compare them : 
NULL ({ }) Therefore ({ 1 }) , ({ 2 }) we ({ 3 }) use ({ 4 }) four ({ 5 }) representative ({ 6 }) morphological ({ 7 }) analyzers ({ 8 }) and ({ 9 }) compare ({ 10 }) them ({ 11 }) : ({ 12 }) 
# Sentence pair (206) source length 26 target length 26 alignment score : 9.75526e-05
- KyTea predicts word segmentation delimiters by pointwise prediction ( Neubig et al. , 2011 ) , using linear Support Vector Machine or logistic regression . 
NULL ({ }) - ({ 1 }) KyTea ({ 2 }) predicts ({ 3 }) word ({ 4 }) segmentation ({ 5 }) delimiters ({ 6 }) by ({ 7 }) pointwise ({ 8 }) prediction ({ 9 }) ( ({ 10 }) Neubig ({ 11 }) et ({ 12 }) al. ({ 13 }) , ({ 14 }) 2011 ({ 15 }) ) ({ 16 }) , ({ 17 }) using ({ 18 }) linear ({ 19 }) Support ({ 20 }) Vector ({ 21 }) Machine ({ 22 }) or ({ 23 }) logistic ({ 24 }) regression ({ 25 }) . ({ 26 }) 
# Sentence pair (207) source length 11 target length 11 alignment score : 0.0330602
- MeCab regards word segmentation as a sequence labeling problem . 
NULL ({ }) - ({ 1 }) MeCab ({ 2 }) regards ({ 3 }) word ({ 4 }) segmentation ({ 5 }) as ({ 6 }) a ({ 7 }) sequence ({ 8 }) labeling ({ 9 }) problem ({ 10 }) . ({ 11 }) 
# Sentence pair (208) source length 15 target length 15 alignment score : 0.00360785
It uses Conditional Random Field for learning ( Kudo et al. , 2004 ) . 
NULL ({ }) It ({ 1 }) uses ({ 2 }) Conditional ({ 3 }) Random ({ 4 }) Field ({ 5 }) for ({ 6 }) learning ({ 7 }) ( ({ 8 }) Kudo ({ 9 }) et ({ 10 }) al. ({ 11 }) , ({ 12 }) 2004 ({ 13 }) ) ({ 14 }) . ({ 15 }) 
# Sentence pair (209) source length 38 target length 37 alignment score : 5.31986e-08
- JUMAN also regards word segmentation as a sequence labeling , but it decides the minimum cost paths without machine learning , from segmentation and association costs in human annotated lexicons and automatically generated Web lexicons . 
NULL ({ }) - ({ 1 }) JUMAN ({ 2 }) also ({ 3 }) regards ({ 4 }) word ({ 5 }) segmentation ({ 6 }) as ({ 7 }) a ({ 8 }) sequence ({ 9 }) labeling ({ 10 }) problem ({ }) , ({ 11 }) but ({ 12 }) it ({ 13 }) decides ({ 14 }) the ({ 15 }) minimum ({ 16 }) cost ({ 17 }) paths ({ 18 }) without ({ 19 }) machine ({ 20 }) learning ({ 21 }) , ({ 22 }) from ({ 23 }) segmentation ({ 24 }) and ({ 25 }) association ({ 26 }) costs ({ 27 }) in ({ 28 }) human ({ 29 }) annotated ({ 30 }) lexicons ({ 31 }) and ({ 32 }) automatically ({ 33 }) generated ({ 34 }) Web ({ 35 }) lexicons ({ 36 }) . ({ 37 }) 
# Sentence pair (210) source length 22 target length 22 alignment score : 0.000100776
The accuracy of supervised morphological analyzers KyTea , MeCab , and JUMAN is reported to be over 98\% for news text . 
NULL ({ }) The ({ 1 }) accuracy ({ 2 }) of ({ 3 }) supervised ({ 4 }) morphological ({ 5 }) analyzers ({ 6 }) KyTea ({ 7 }) , ({ 8 }) MeCab ({ 9 }) , ({ 10 }) and ({ 11 }) JUMAN ({ 12 }) is ({ 13 }) reported ({ 14 }) to ({ 15 }) be ({ 16 }) over ({ 17 }) 98% ({ 18 }) for ({ 19 }) news ({ 20 }) texts ({ 21 }) . ({ 22 }) 
# Sentence pair (211) source length 40 target length 38 alignment score : 4.30349e-11
On the other hand , the unsupervised method latticelm achieved 66 .6% accuracy ( Mochihashi et al. , 2009 ) for human annotated news text , while the method does not have any answers of word definitions . 
NULL ({ }) On ({ 1 }) the ({ 2 }) other ({ 3 }) hand ({ 4 }) , ({ 5 }) the ({ 6 }) unsupervised ({ 7 }) method ({ 8 }) , ({ }) latticelm ({ 9 }) , ({ }) achieved ({ 10 }) 66 ({ 11 }) .6% ({ 12 }) accuracy ({ 13 }) ( ({ 14 }) Mochihashi ({ 15 }) et ({ 16 }) al. ({ 17 }) , ({ 18 }) 2009 ({ 19 }) ) ({ 20 }) for ({ 21 }) human ({ 22 }) annotated ({ 23 }) news ({ 24 }) texts ({ 25 }) , ({ 26 }) while ({ 27 }) the ({ 28 }) method ({ 29 }) does ({ 30 }) not ({ 31 }) have ({ 32 }) any ({ 33 }) answers ({ 34 }) for ({ 35 }) word ({ 36 }) definitions ({ 37 }) . ({ 38 }) 
# Sentence pair (212) source length 29 target length 32 alignment score : 2.91472e-27
Therefore , it is not possible to compare such a result with the supervised results . Even though , it is fair to compare it with SMT contribution point of view . 
NULL ({ 10 16 19 30 }) Therefore ({ 1 }) , ({ 2 }) it ({ 3 }) is ({ 4 }) not ({ 5 }) possible ({ 6 }) to ({ 7 }) compare ({ 8 }) its ({ 9 }) result ({ 11 }) with ({ 12 }) the ({ 13 }) supervised ({ 14 }) results ({ 15 }) , ({ }) even ({ 17 }) though ({ 18 }) it ({ 20 }) is ({ 21 }) fair ({ 22 }) to ({ 23 }) compare ({ 24 }) it ({ 25 }) from ({ 26 }) the ({ }) SMT ({ 27 }) contribution ({ 28 }) point-of-view ({ 29 31 }) . ({ 32 }) 
# Sentence pair (213) source length 11 target length 13 alignment score : 1.88186e-13
Furthermore , their policies about word segmentation definitions are very much different . 
NULL ({ }) Furthermore ({ 1 }) , ({ 2 }) their ({ 3 }) policies ({ 4 11 }) concerning ({ 5 12 }) word ({ 6 }) segmentation ({ 7 }) definitions ({ 8 }) vary ({ 9 }) significantly ({ 10 }) . ({ 13 }) 
# Sentence pair (214) source length 49 target length 45 alignment score : 7.83196e-11
While MeCab can change its definitions by external lexicons and JUMAN has its own internal standard , KyTea is based on the short unit standard of Balanced Corpus of Contemporary Written Japanese , which is considered one of the shortest definitions of Japanese words . 
NULL ({ }) While ({ 1 }) MeCab ({ 2 }) can ({ 3 }) change ({ 4 }) its ({ 5 }) definitions ({ 6 }) by ({ 7 }) external ({ 8 }) lexicons ({ 9 }) , ({ }) and ({ 10 }) JUMAN ({ 11 }) has ({ 12 }) its ({ 13 }) own ({ 14 }) internal ({ 15 }) standard ({ 16 }) , ({ 17 }) KyTea ({ 18 }) is ({ 19 }) based ({ 20 }) on ({ 21 }) the ({ 22 }) short ({ 23 }) unit ({ 24 }) standard ({ 25 }) of ({ 26 }) the ({ }) Balanced ({ 27 }) Corpus ({ 28 }) of ({ 29 }) Contemporary ({ 30 }) Written ({ 31 }) Japanese ({ 32 }) , ({ 33 }) which ({ 34 }) is ({ 35 }) considered ({ 36 }) to ({ }) have ({ }) one ({ 37 }) of ({ 38 }) the ({ 39 }) shortest ({ 40 }) definitions ({ 41 }) of ({ 42 }) Japanese ({ 43 }) words ({ 44 }) . ({ 45 }) 
# Sentence pair (215) source length 53 target length 56 alignment score : 2.1185e-27
For example , if we are given a string " ( if someone see ) " , MeCab separates it into two words "  |  " and JUMAN keep the same string , but KyTea outputs it as three words "  |  |  " where every character is a word . 
NULL ({ }) For ({ 1 }) example ({ 2 }) , ({ 3 }) if ({ 4 }) we ({ 5 }) are ({ 6 }) given ({ 7 }) a ({ 8 }) string ({ 9 }) , ({ }) ( ({ 10 11 }) if ({ 12 }) someone ({ 13 }) sees ({ 14 15 }) ) ({ 16 }) , ({ 17 }) MeCab ({ 18 }) separates ({ 19 }) it ({ 20 }) into ({ 21 }) two ({ 22 }) words ({ 23 }) , ({ })  ({ 24 }) | ({ 25 26 27 })  ({ 28 }) and ({ 29 }) JUMAN ({ 30 }) retains ({ 31 }) the ({ 32 }) same ({ 33 }) string ({ 34 }) , ({ 35 }) but ({ 36 }) KyTea ({ 37 }) outputs ({ 38 }) it ({ 39 }) as ({ 40 }) three ({ 41 }) words ({ 42 }) , ({ })  ({ 43 }) | ({ 44 45 })  ({ 46 }) | ({ 47 48 })  ({ 49 }) where ({ 50 }) every ({ 51 }) character ({ 52 }) is ({ 53 }) a ({ 54 }) word ({ 55 }) . ({ 56 }) 
# Sentence pair (216) source length 30 target length 31 alignment score : 3.59848e-16
In the case of latticelm , as it has no supervised definition of words , it uses the expectation maximized length of words for every word depending on training data . 
NULL ({ 2 3 4 }) For ({ 1 }) latticelm ({ 5 }) , ({ 6 }) since ({ 7 }) it ({ 8 }) has ({ 9 }) no ({ 10 }) supervised ({ 11 }) definition ({ 12 }) of ({ 13 }) words ({ 14 }) , ({ 15 }) it ({ 16 }) uses ({ 17 }) the ({ 18 }) expectation ({ 19 }) maximized ({ 20 }) length ({ 21 }) of ({ 22 }) words ({ 23 }) for ({ 24 }) every ({ 25 }) word ({ 26 }) , ({ }) depending ({ 27 }) on ({ 28 }) the ({ }) training ({ 29 }) data ({ 30 }) . ({ 31 }) 
# Sentence pair (217) source length 16 target length 15 alignment score : 5.44548e-14
We also investigate such morphological analysis accuracy and word definition problems in our experiments . 
NULL ({ 12 }) In ({ }) our ({ 13 }) experiments ({ 14 }) , ({ }) we ({ 1 }) further ({ 2 }) investigate ({ 3 }) such ({ 4 }) morphological ({ 5 }) analysis ({ 6 }) accuracies ({ 7 }) and ({ 8 }) word ({ 9 }) definition ({ 10 }) problems ({ 11 }) . ({ 15 }) 
# Sentence pair (218) source length 3 target length 3 alignment score : 0.297849
Chang et al. 
NULL ({ }) Chang ({ 1 }) et ({ 2 }) al. ({ 3 }) 
# Sentence pair (219) source length 17 target length 17 alignment score : 0.00232251
( 2008 ) suggested that word segmentation consistency and granularity can be important factors for SMT . 
NULL ({ }) ( ({ 1 }) 2008 ({ 2 }) ) ({ 3 }) suggested ({ 4 }) that ({ 5 }) word ({ 6 }) segmentation ({ 7 }) consistency ({ 8 }) and ({ 9 }) granularity ({ 10 }) can ({ 11 }) be ({ 12 }) important ({ 13 }) factors ({ 14 }) for ({ 15 }) SMT ({ 16 }) . ({ 17 }) 
# Sentence pair (220) source length 12 target length 12 alignment score : 0.0191511
Therefore , we introduce two heuristic methods for Japanese word segmentation . 
NULL ({ }) Therefore ({ 1 }) , ({ 2 }) we ({ 3 }) introduce ({ 4 }) two ({ 5 }) heuristic ({ 6 }) methods ({ 7 }) for ({ 8 }) Japanese ({ 9 }) word ({ 10 }) segmentation ({ 11 }) . ({ 12 }) 
# Sentence pair (221) source length 22 target length 21 alignment score : 3.4597e-05
One is segmentation by character category ( CAT ) , and the other is segmentation by characters ( CHAR ) . 
NULL ({ }) One ({ 1 }) method ({ }) is ({ 2 }) segmentation ({ 3 }) by ({ 4 }) character ({ 5 }) category ({ 6 }) ( ({ 7 }) CAT ({ 8 }) ) ({ 9 }) , ({ 10 }) and ({ 11 }) the ({ 12 }) other ({ 13 }) is ({ 14 }) segmentation ({ 15 }) by ({ 16 }) characters ({ 17 }) ( ({ 18 }) CHAR ({ 19 }) ) ({ 20 }) . ({ 21 }) 
# Sentence pair (222) source length 10 target length 10 alignment score : 0.00373984
CAT puts a word boundary when character categories change . 
NULL ({ }) CAT ({ 1 }) places ({ 2 }) a ({ 3 }) word ({ 4 }) boundary ({ 5 }) when ({ 6 }) character ({ 7 }) categories ({ 8 }) change ({ 9 }) . ({ 10 }) 
# Sentence pair (223) source length 32 target length 32 alignment score : 6.32905e-06
Character categories in Japanese include : Kanji ( Chinese character ) , Hiragana , Katakana , Latin alphabet , numeral digit , multi-byte alphabet , multi-byte digit , and other tokens . 
NULL ({ }) Character ({ 1 }) categories ({ 2 }) in ({ 3 }) Japanese ({ 4 }) include ({ 5 }) : ({ 6 }) Kanji ({ 7 }) ( ({ 8 }) Chinese ({ 9 }) character ({ 10 }) ) ({ 11 }) , ({ 12 }) Hiragana ({ 13 }) , ({ 14 }) Katakana ({ 15 }) , ({ 16 }) Latin ({ 17 }) alphabet ({ 18 }) , ({ 19 }) numeral ({ 20 }) digit ({ 21 }) , ({ 22 }) multi-byte ({ 23 }) alphabet ({ 24 }) , ({ 25 }) multi-byte ({ 26 }) digit ({ 27 }) , ({ 28 }) and ({ 29 }) other ({ 30 }) tokens ({ 31 }) . ({ 32 }) 
# Sentence pair (224) source length 17 target length 16 alignment score : 0.000252888
The CHAR method considers every Unicode character as a word as proposed by Xu et al. 
NULL ({ }) The ({ 1 }) CHAR ({ 2 }) method ({ 3 }) considers ({ 4 }) every ({ 5 }) Unicode ({ 6 }) character ({ 7 }) as ({ 8 }) a ({ 9 }) word ({ 10 }) , ({ }) as ({ 11 }) proposed ({ 12 }) by ({ 13 }) Xu ({ 14 }) et ({ 15 }) al. ({ 16 }) 
# Sentence pair (225) source length 4 target length 4 alignment score : 0.340951
( 2004 ) . 
NULL ({ }) ( ({ 1 }) 2004 ({ 2 }) ) ({ 3 }) . ({ 4 }) 
# Sentence pair (226) source length 28 target length 28 alignment score : 9.34757e-05
We use two news corpora : Reuters corpora ( REUTERS ) and Japanese-English News Article Alignment Data ( JENAAD ) ( Utiyama and Isahara , 2003 ) . 
NULL ({ }) We ({ 1 }) use ({ 2 }) two ({ 3 }) news ({ 4 }) corpora ({ 5 }) : ({ 6 }) Reuters ({ 7 }) corpora ({ 8 }) ( ({ 9 }) REUTERS ({ 10 }) ) ({ 11 }) and ({ 12 }) Japanese-English ({ 13 }) News ({ 14 }) Article ({ 15 }) Alignment ({ 16 }) Data ({ 17 }) ( ({ 18 }) JENAAD ({ 19 }) ) ({ 20 }) ( ({ 21 }) Utiyama ({ 22 }) and ({ 23 }) Isahara ({ 24 }) , ({ 25 }) 2003 ({ 26 }) ) ({ 27 }) . ({ 28 }) 
# Sentence pair (227) source length 27 target length 26 alignment score : 1.68827e-07
Another corpus we use in the experiments is a Wikipedia corpus , Japanese-English Bilingual Corpus of Wikipedia 's Kyoto Articles 2 .01 ( WIKIPEDIA ) . 
NULL ({ 12 }) Another ({ 1 }) corpus ({ 2 }) we ({ 3 }) use ({ 4 }) in ({ 5 }) the ({ 6 }) experiments ({ 7 }) is ({ 8 }) a ({ 9 }) Wikipedia ({ 10 }) corpus ({ 11 }) : ({ }) the ({ }) Japanese-English ({ 13 }) Bilingual ({ 14 }) Corpus ({ 15 }) of ({ 16 }) Wikipedia ({ 17 }) 's ({ 18 }) Kyoto ({ 19 }) Articles ({ 20 }) 2 ({ 21 }) .01 ({ 22 }) ( ({ 23 }) WIKIPEDIA ({ 24 }) ) ({ 25 }) . ({ 26 }) 
# Sentence pair (228) source length 14 target length 13 alignment score : 0.000565349
From these corpora , we prepared three data sets as explained below . 
NULL ({ }) From ({ 1 }) these ({ 2 }) corpora ({ 3 }) , ({ 4 }) we ({ 5 }) prepared ({ 6 }) three ({ 7 }) data ({ 8 }) sets ({ 9 }) , ({ }) as ({ 10 }) explained ({ 11 }) below ({ 12 }) . ({ 13 }) 
# Sentence pair (229) source length 10 target length 14 alignment score : 2.00582e-16
In the case of REUTERS , we have used all 56 ,282 sentences . 
NULL ({ 2 3 4 8 }) For ({ 1 }) REUTERS ({ 5 }) , ({ 6 }) we ({ 7 }) used ({ 9 }) all ({ 10 }) 56 ({ 11 }) ,282 ({ 12 }) sentences ({ 13 }) . ({ 14 }) 
# Sentence pair (230) source length 35 target length 35 alignment score : 1.81617e-07
Then , we split the data into three parts : the first 1 ,000 as the test , the next 500 as the development , and the rest 55 ,282 as the training data . 
NULL ({ }) Then ({ 1 }) , ({ 2 }) we ({ 3 }) split ({ 4 }) the ({ 5 }) data ({ 6 }) into ({ 7 }) three ({ 8 }) parts ({ 9 }) : ({ 10 }) the ({ 11 }) first ({ 12 }) 1 ({ 13 }) ,000 ({ 14 }) as ({ 15 }) the ({ 16 }) test ({ 17 }) , ({ 18 }) the ({ 19 }) next ({ 20 }) 500 ({ 21 }) as ({ 22 }) the ({ 23 }) development ({ 24 }) , ({ 25 }) and ({ 26 }) the ({ 27 }) remaining ({ 28 }) 55 ({ 29 }) ,282 ({ 30 }) as ({ 31 }) the ({ 32 }) training ({ 33 }) data ({ 34 }) . ({ 35 }) 
# Sentence pair (231) source length 18 target length 18 alignment score : 2.01071e-07
In this data , we have combined JENAAD and REUTERS news corpora to get one news corpus . 
NULL ({ 6 }) For ({ 1 }) this ({ 2 }) data ({ 3 }) , ({ 4 }) we ({ 5 }) combined ({ 7 }) the ({ }) JENAAD ({ 8 }) and ({ 9 }) REUTERS ({ 10 }) news ({ 11 }) corpora ({ 12 }) to ({ 13 }) acquire ({ 14 }) one ({ 15 }) news ({ 16 }) corpus ({ 17 }) . ({ 18 }) 
# Sentence pair (232) source length 12 target length 12 alignment score : 1.67992e-07
We have used all 56 ,282 and 150 ,000 sentences respectively . 
NULL ({ 2 }) We ({ 1 }) used ({ 3 }) all ({ 4 }) 56 ({ 5 }) ,282 ({ 6 }) and ({ 7 }) 150 ({ 8 }) ,000 ({ 9 }) sentences ({ 10 }) , ({ }) respectively ({ 11 }) . ({ 12 }) 
# Sentence pair (233) source length 28 target length 28 alignment score : 1.91417e-24
For each corpus , we divide it into the first 1 ,000 , the next 500 , and the rest for test , development , and training . 
NULL ({ 23 25 26 }) For ({ 1 }) each ({ 2 }) corpus ({ 3 }) , ({ 4 }) we ({ 5 }) divided ({ 6 }) the ({ }) sentences ({ 7 }) into ({ 8 }) the ({ 9 }) first ({ 10 }) 1 ({ 11 }) ,000 ({ 12 }) for ({ }) testing ({ }) , ({ 13 }) the ({ 14 }) next ({ 15 }) 500 ({ 16 }) for ({ 21 }) development ({ 22 24 }) , ({ 17 }) and ({ 18 }) the ({ 19 }) remaining ({ 20 }) for ({ }) training ({ 27 }) . ({ 28 }) 
# Sentence pair (234) source length 23 target length 24 alignment score : 3.484e-17
We have gathered 2000 , 1000 , and 203 ,782 sentences for test , development , and training , respectively , in total . 
NULL ({ 2 21 22 }) In ({ 1 }) total ({ 23 }) , ({ }) we ({ }) gathered ({ 3 }) 2000 ({ 4 }) , ({ 5 }) 1000 ({ 6 }) , ({ 7 }) and ({ 8 }) 203 ({ 9 }) ,782 ({ 10 }) sentences ({ 11 }) for ({ 12 }) test ({ 13 }) , ({ 14 }) development ({ 15 }) , ({ 16 }) and ({ 17 }) training ({ 18 }) , ({ 19 }) respectively ({ 20 }) . ({ 24 }) 
# Sentence pair (235) source length 55 target length 57 alignment score : 6.19317e-25
Firstly , since the WIKIPEDIA corpus is a multi-category XML dataset , we have sorted them by the DOCID in the ascending order and by the document categories LTT , EPR , FML , BDS , CLT , BLD , GNM , SCL , ROD , SNT , PNM , HST , RLW , and SAT . 
NULL ({ 2 3 14 21 }) Since ({ 1 }) the ({ 4 }) WIKIPEDIA ({ 5 }) corpus ({ 6 }) is ({ 7 }) a ({ 8 }) multi-category ({ 9 }) XML ({ 10 }) dataset ({ 11 }) , ({ 12 }) we ({ 13 }) sorted ({ 15 }) them ({ 16 }) by ({ 17 }) the ({ 18 }) DOCID ({ 19 }) in ({ 20 }) ascending ({ 22 }) order ({ 23 }) , ({ }) and ({ 24 }) by ({ 25 }) the ({ 26 }) document ({ 27 }) categories ({ 28 }) : ({ }) LTT ({ 29 }) , ({ 30 }) EPR ({ 31 }) , ({ 32 }) FML ({ 33 }) , ({ 34 }) BDS ({ 35 }) , ({ 36 }) CLT ({ 37 }) , ({ 38 }) BLD ({ 39 }) , ({ 40 }) GNM ({ 41 }) , ({ 42 }) SCL ({ 43 }) , ({ 44 }) ROD ({ 45 }) , ({ 46 }) SNT ({ 47 }) , ({ 48 }) PNM ({ 49 }) , ({ 50 }) HST ({ 51 }) , ({ 52 }) RLW ({ 53 }) , ({ 54 }) and ({ 55 }) SAT ({ 56 }) . ({ 57 }) 
# Sentence pair (236) source length 26 target length 26 alignment score : 1.0864e-05
Secondly , we parsed it by xml .etree .ElementTree .parse of Python 2 .7 .2 , and obtained 477 ,036 sentence pairs without parsing errors . 
NULL ({ }) Next ({ 1 }) , ({ 2 }) we ({ 3 }) parsed ({ 4 }) it ({ 5 }) by ({ 6 }) xml ({ 7 }) .etree ({ 8 }) .ElementTree ({ 9 }) .parse ({ 10 }) of ({ 11 }) Python ({ 12 }) 2 ({ 13 }) .7 ({ 14 }) .2 ({ 15 }) , ({ 16 }) and ({ 17 }) obtained ({ 18 }) 477 ({ 19 }) ,036 ({ 20 }) sentence ({ 21 }) pairs ({ 22 }) without ({ 23 }) parsing ({ 24 }) errors ({ 25 }) . ({ 26 }) 
# Sentence pair (237) source length 24 target length 25 alignment score : 1.50888e-11
Thirdly , sentence pairs that include a character " | " in English or Japanese are removed because it caused a problem with Moses . 
NULL ({ }) Then ({ 1 }) , ({ 2 }) sentence ({ 3 }) pairs ({ 4 }) that ({ 5 }) include ({ 6 }) a ({ 7 }) character ({ 8 }) | ({ 9 10 11 }) in ({ 12 }) English ({ 13 }) or ({ 14 }) Japanese ({ 15 }) were ({ 16 }) removed ({ 17 }) , ({ }) because ({ 18 }) it ({ 19 }) caused ({ 20 }) a ({ 21 }) problem ({ 22 }) with ({ 23 }) Moses ({ 24 }) . ({ 25 }) 
# Sentence pair (238) source length 11 target length 11 alignment score : 0.0138655
Finally , we obtained 477 ,012 sentence pairs in total . 
NULL ({ }) Finally ({ 1 }) , ({ 2 }) we ({ 3 }) obtained ({ 4 }) 477 ({ 5 }) ,012 ({ 6 }) sentence ({ 7 }) pairs ({ 8 }) in ({ 9 }) total ({ 10 }) . ({ 11 }) 
# Sentence pair (239) source length 28 target length 28 alignment score : 4.68564e-10
In order to adjust the balance of the domains , we have sampled the data twice : First we extract the first line for every 477 lines . 
NULL ({ 12 }) In ({ 1 }) order ({ 2 }) to ({ 3 }) adjust ({ 4 }) the ({ 5 }) balance ({ 6 }) of ({ 7 }) the ({ 8 }) domains ({ 9 }) , ({ 10 }) we ({ 11 }) sampled ({ 13 }) the ({ 14 }) data ({ 15 }) twice ({ 16 }) : ({ 17 }) First ({ 18 }) , ({ }) we ({ 19 }) extracted ({ 20 }) the ({ 21 }) first ({ 22 }) line ({ 23 }) for ({ 24 }) every ({ 25 }) 477 ({ 26 }) lines ({ 27 }) . ({ 28 }) 
# Sentence pair (240) source length 25 target length 23 alignment score : 8.12958e-18
After this , we have merged the remaining 476 ,012 lines and from this extract the first line for every 952 lines . 
NULL ({ 2 5 }) Then ({ 1 }) , ({ 3 }) we ({ 4 }) merged ({ 6 }) the ({ 7 }) remaining ({ 8 }) 476 ({ 9 }) ,012 ({ 10 }) lines ({ 11 }) , ({ }) and ({ 12 }) from ({ 13 }) this ({ 14 }) extract ({ 15 }) , ({ }) we ({ }) extracted ({ }) the ({ 16 }) first ({ 17 }) line ({ 18 }) for ({ 19 }) every ({ 20 }) 952 ({ 21 }) lines ({ 22 }) . ({ 23 }) 
# Sentence pair (241) source length 17 target length 18 alignment score : 2.59317e-06
Finally , we have obtained 1 ,000 test , 500 development , and 475 ,512 training data . 
NULL ({ 4 }) Finally ({ 1 }) , ({ 2 }) we ({ 3 }) obtained ({ 5 }) 1 ({ 6 }) ,000 ({ 7 }) test ({ 8 }) , ({ 9 }) 500 ({ 10 }) development ({ 11 }) , ({ 12 }) and ({ 13 }) 475 ({ 14 }) ,512 ({ 15 }) training ({ 16 }) data ({ 17 }) . ({ 18 }) 
# Sentence pair (242) source length 56 target length 56 alignment score : 1.66898e-10
We have launched two word-based evaluation methods : BLEU ( Papineni et al. , 2002 ) with 4-gram setting and RIBES ( Isozaki et al. , 2010a ) , which has been reported to have a much higher correlation to human evaluation than BLEU within English-Japanese translation tasks ( Sudoh et al. , 2011 ) . 
NULL ({ }) We ({ 1 }) have ({ 2 }) launched ({ 3 }) two ({ 4 }) word-based ({ 5 }) evaluation ({ 6 }) methods ({ 7 }) : ({ 8 }) BLEU ({ 9 }) ( ({ 10 }) Papineni ({ 11 }) et ({ 12 }) al. ({ 13 }) , ({ 14 }) 2002 ({ 15 }) ) ({ 16 }) with ({ 17 }) 4-gram ({ 18 }) setting ({ 19 }) and ({ 20 }) RIBES ({ 21 }) ( ({ 22 }) Isozaki ({ 23 }) et ({ 24 }) al. ({ 25 }) , ({ 26 }) 2010a ({ 27 }) ) ({ 28 }) , ({ 29 }) which ({ 30 }) has ({ 31 }) been ({ 32 }) reported ({ 33 }) to ({ 34 }) have ({ 35 }) a ({ 36 }) much ({ 37 }) higher ({ 38 }) correlation ({ 39 }) to ({ 40 }) human ({ 41 }) evaluation ({ 42 }) than ({ 43 }) BLEU ({ 44 }) within ({ 45 }) English-Japanese ({ 46 }) translation ({ 47 }) tasks ({ 48 }) ( ({ 49 }) Sudoh ({ 50 }) et ({ 51 }) al. ({ 52 }) , ({ 53 }) 2011 ({ 54 }) ) ({ 55 }) . ({ 56 }) 
# Sentence pair (243) source length 22 target length 23 alignment score : 4.77384e-14
Currently , the most popular way to evaluate Statistical Machine Translation is to use word-based evaluation metrics such as BLEU and RIBES . 
NULL ({ }) Currently ({ 1 10 11 }) , ({ 2 }) the ({ 3 }) most ({ 4 }) popular ({ 5 }) way ({ 6 }) to ({ 7 }) evaluate ({ 8 }) SMT ({ 9 }) is ({ 12 }) to ({ 13 }) use ({ 14 }) word-based ({ 15 }) evaluation ({ 16 }) metrics ({ 17 }) , ({ }) such ({ 18 }) as ({ 19 }) BLEU ({ 20 }) and ({ 21 }) RIBES ({ 22 }) . ({ 23 }) 
# Sentence pair (244) source length 16 target length 16 alignment score : 0.0028885
However , these word-based evaluation metrics have a problem on independency of word segmentation evaluations . 
NULL ({ }) However ({ 1 }) , ({ 2 }) these ({ 3 }) word-based ({ 4 }) evaluation ({ 5 }) metrics ({ 6 }) have ({ 7 }) a ({ 8 }) problem ({ 9 }) on ({ 10 }) independency ({ 11 }) of ({ 12 }) word ({ 13 }) segmentation ({ 14 }) evaluations ({ 15 }) . ({ 16 }) 
# Sentence pair (245) source length 21 target length 20 alignment score : 0.000100889
If we do not have segmented reference and test data , we cannot evaluate outputs by word-based evaluation metrics . 
NULL ({ }) If ({ 1 }) we ({ 2 }) do ({ 3 }) not ({ 4 }) have ({ 5 }) segmented ({ 6 }) reference ({ 7 }) and ({ 8 }) test ({ 9 }) data ({ 10 }) , ({ 11 }) we ({ 12 }) cannot ({ 13 }) evaluate ({ 14 }) the ({ }) outputs ({ 15 }) by ({ 16 }) word-based ({ 17 }) evaluation ({ 18 }) metrics ({ 19 }) . ({ 20 }) 
# Sentence pair (246) source length 17 target length 20 alignment score : 6.77968e-12
For example , in the case of English-Japanese translations , we must tokenize reference data to evaluate SMT outputs . 
NULL ({ 4 5 6 }) For ({ 1 }) example ({ 2 }) , ({ 3 }) for ({ 7 }) English-Japanese ({ 8 }) translations ({ 9 }) , ({ 10 }) we ({ 11 }) must ({ 12 }) tokenize ({ 13 }) reference ({ 14 }) data ({ 15 }) to ({ 16 }) evaluate ({ 17 }) SMT ({ 18 }) outputs ({ 19 }) . ({ 20 }) 
# Sentence pair (247) source length 19 target length 22 alignment score : 2.92644e-12
On the other hand , in the case of Japanese-English translations , we must tokenize test data to evaluate the outputs . 
NULL ({ 6 7 8 }) On ({ 1 }) the ({ 2 }) other ({ 3 }) hand ({ 4 }) , ({ 5 }) for ({ 9 }) Japanese-English ({ 10 }) translations ({ 11 }) , ({ 12 }) we ({ 13 }) must ({ 14 }) tokenize ({ 15 }) test ({ 16 }) data ({ 17 }) to ({ 18 }) evaluate ({ 19 }) the ({ 20 }) outputs ({ 21 }) . ({ 22 }) 
# Sentence pair (248) source length 33 target length 32 alignment score : 1.97261e-08
As a result , we need to tokenize every sentence by word segmentation before evaluation , and it is hard to independently evaluate the effects of word segmentation on training data . 
NULL ({ }) As ({ 1 }) a ({ 2 }) result ({ 3 }) , ({ 4 }) we ({ 5 }) need ({ 6 }) to ({ 7 }) tokenize ({ 8 }) every ({ 9 }) sentence ({ 10 }) by ({ 11 }) word ({ 12 }) segmentation ({ 13 }) before ({ 14 }) evaluation ({ 15 }) , ({ 16 }) and ({ 17 }) it ({ 18 }) is ({ 19 }) therefore ({ }) difficult ({ 20 }) to ({ 21 }) independently ({ 22 }) evaluate ({ 23 }) the ({ 24 }) effects ({ 25 }) of ({ 26 }) word ({ 27 }) segmentation ({ 28 }) on ({ 29 }) training ({ 30 }) data ({ 31 }) . ({ 32 }) 
# Sentence pair (249) source length 20 target length 20 alignment score : 0.000507144
It is also possible to detokenize SMT outputs first , and then tokenize them by the shared word segmentation . 
NULL ({ }) It ({ 1 }) is ({ 2 }) also ({ 3 }) possible ({ 4 }) to ({ 5 }) detokenize ({ 6 }) SMT ({ 7 }) outputs ({ 8 }) first ({ 9 }) , ({ 10 }) and ({ 11 }) then ({ 12 }) tokenize ({ 13 }) them ({ 14 }) by ({ 15 }) the ({ 16 }) shared ({ 17 }) word ({ 18 }) segmentation ({ 19 }) . ({ 20 }) 
# Sentence pair (250) source length 24 target length 23 alignment score : 1.73368e-05
However , our preliminary experiments showed that the results obtained with this method were not independent from word segmentation of training data . 
NULL ({ }) However ({ 1 }) , ({ 2 }) our ({ 3 }) preliminary ({ 4 }) experiments ({ 5 }) indicated ({ 6 }) that ({ 7 }) the ({ 8 }) results ({ 9 }) obtained ({ 10 }) with ({ 11 }) this ({ 12 }) method ({ 13 }) were ({ 14 }) not ({ 15 }) independent ({ 16 }) from ({ 17 }) word ({ 18 }) segmentation ({ 19 }) of ({ 20 }) the ({ }) training ({ 21 }) data ({ 22 }) . ({ 23 }) 
# Sentence pair (251) source length 17 target length 18 alignment score : 1.65899e-09
And the best results were obtained when we use the same word segmentation as the training data . 
NULL ({ 2 }) The ({ 1 }) best ({ 3 }) results ({ 4 }) were ({ 5 }) obtained ({ 6 }) when ({ 7 }) we ({ 8 }) used ({ 9 }) the ({ 10 }) same ({ 11 }) word ({ 12 }) segmentation ({ 13 }) as ({ 14 }) the ({ 15 }) training ({ 16 }) data ({ 17 }) . ({ 18 }) 
# Sentence pair (252) source length 13 target length 12 alignment score : 2.54279e-06
Hence , this problem remains if we keep our word-based evaluations . 
NULL ({ }) Hence ({ 1 }) , ({ 2 }) if ({ 6 }) we ({ 7 }) keep ({ 8 }) our ({ 9 }) word-based ({ 10 }) evaluations ({ 11 }) , ({ }) this ({ 3 }) problem ({ 4 }) remains ({ 5 }) . ({ 12 }) 
# Sentence pair (253) source length 25 target length 26 alignment score : 3.9304e-12
In order to manage such a problem , we use one character-based metric BLEU in Characters ( De-noual and Lepage , 2005 ) with 4-gram . 
NULL ({ 6 }) In ({ 1 }) order ({ 2 }) to ({ 3 }) manage ({ 4 5 }) this ({ }) issue ({ 7 }) , ({ 8 }) we ({ 9 }) used ({ 10 }) one ({ 11 }) character-based ({ 12 }) metric ({ 13 }) BLEU ({ 14 }) in ({ 15 }) Characters ({ 16 }) ( ({ 17 }) De-noual ({ 18 }) and ({ 19 }) Lepage ({ 20 }) , ({ 21 }) 2005 ({ 22 }) ) ({ 23 }) with ({ 24 }) 4-gram ({ 25 }) . ({ 26 }) 
# Sentence pair (254) source length 25 target length 24 alignment score : 4.55448e-06
As this method evaluates the character-level information , outputs are not required to be segmented and it is free from word segmentation variations . 
NULL ({ }) As ({ 1 }) this ({ 2 }) method ({ 3 }) evaluates ({ 4 }) the ({ 5 }) character-level ({ 6 }) information ({ 7 }) , ({ 8 }) outputs ({ 9 }) are ({ 10 }) not ({ 11 }) required ({ 12 }) to ({ 13 }) be ({ 14 }) segmented ({ 15 }) , ({ }) and ({ 16 }) it ({ 17 }) is ({ 18 }) free ({ 19 }) from ({ 20 }) word ({ 21 }) segmentation ({ 22 }) variations ({ 23 }) . ({ 24 }) 
# Sentence pair (255) source length 17 target length 16 alignment score : 1.51751e-10
We have conducted English and Japanese machine translation in both directions by the following steps : 
NULL ({ 12 13 }) We ({ 1 }) have ({ 2 }) conducted ({ 3 }) English ({ 4 }) and ({ 5 }) Japanese ({ 6 }) machine ({ 7 }) translation ({ 8 }) in ({ 9 }) both ({ 10 }) directions ({ 11 }) , ({ }) following ({ 14 }) the ({ }) steps ({ 15 }) below ({ }) : ({ 16 }) 
# Sentence pair (256) source length 21 target length 20 alignment score : 3.064e-05
1Apply the Head-Finalization ( Isozaki et al. , 2010b ) to English text in the case of English-Japanese translation . 
NULL ({ }) 1 ({ }) .Apply ({ 1 }) the ({ 2 }) Head-Finalization ({ 3 }) ( ({ 4 }) Isozaki ({ 5 }) et ({ 6 }) al. ({ 7 }) , ({ 8 }) 2010b ({ 9 }) ) ({ 10 }) to ({ 11 }) English ({ 12 }) text ({ 13 }) in ({ 14 }) the ({ 15 }) case ({ 16 }) of ({ 17 }) English-Japanese ({ 18 }) translation ({ 19 }) . ({ 20 }) 
# Sentence pair (257) source length 20 target length 18 alignment score : 1.09256e-05
2Run Japanese word segmentation methods and a normalization script which was introduced by the NTCIR-9 PATMT task . 
NULL ({ }) 2 ({ }) .Run ({ 1 }) Japanese ({ 2 }) word ({ 3 }) segmentation ({ 4 }) methods ({ 5 }) and ({ 6 }) a ({ 7 }) normalization ({ 8 }) script ({ 9 }) , ({ }) which ({ 10 }) was ({ 11 }) introduced ({ 12 }) by ({ 13 }) the ({ 14 }) NTCIR-9 ({ 15 }) PATMT ({ 16 }) task ({ 17 }) . ({ 18 }) 
# Sentence pair (258) source length 13 target length 12 alignment score : 0.000588538
3Tokenize and lowercase English text by Moses' tokenizer and lowercase scripts . 
NULL ({ }) 3 ({ }) .Tokenize ({ 1 }) and ({ 2 }) lowercase ({ 3 }) English ({ 4 }) texts ({ 5 }) by ({ 6 }) Moses' ({ 7 }) tokenizer ({ 8 }) and ({ 9 }) lowercase ({ 10 }) scripts ({ 11 }) . ({ 12 }) 
# Sentence pair (259) source length 16 target length 15 alignment score : 0.00013357
4Create language models from target languages' training data , with SRILM 1 .5 .12 . 
NULL ({ }) 4 ({ }) .Create ({ 1 }) language ({ 2 }) models ({ 3 }) from ({ 4 }) target ({ 5 }) languages' ({ 6 }) training ({ 7 }) data ({ 8 }) , ({ 9 }) with ({ 10 }) SRILM ({ 11 }) 1 ({ 12 }) .5 ({ 13 }) .12 ({ 14 }) . ({ 15 }) 
# Sentence pair (260) source length 13 target length 12 alignment score : 0.00115419
5Create translation models with Giza++ 1 .0 .5 ( 2011-09-24 ) . 
NULL ({ }) 5 ({ }) .Create ({ 1 }) translation ({ 2 }) models ({ 3 }) with ({ 4 }) Giza++ ({ 5 }) 1 ({ 6 }) .0 ({ 7 }) .5 ({ 8 }) ( ({ 9 }) 2011-09-24 ({ 10 }) ) ({ 11 }) . ({ 12 }) 
# Sentence pair (261) source length 11 target length 10 alignment score : 0.00183719
6Decode source test data with Moses ( 2010-08-13 ) . 
NULL ({ }) 6 ({ }) .Decode ({ 1 }) source ({ 2 }) test ({ 3 }) data ({ 4 }) with ({ 5 }) Moses ({ 6 }) ( ({ 7 }) 2010-08-13 ({ 8 }) ) ({ 9 }) . ({ 10 }) 
# Sentence pair (262) source length 8 target length 7 alignment score : 0.0116808
7Compute evaluation scores of the outputs . 
NULL ({ }) 7 ({ }) .Compute ({ 1 }) evaluation ({ 2 }) scores ({ 3 }) of ({ 4 }) the ({ 5 }) outputs ({ 6 }) . ({ 7 }) 
# Sentence pair (263) source length 28 target length 28 alignment score : 4.63921e-05
We used Enju 2 .4 .2 ( Miyao and Tsujii , 2005 ) and Head Finalization ( Isozaki et al. , 2010b ) to preprocess English data . 
NULL ({ }) We ({ 1 }) used ({ 2 }) Enju ({ 3 }) 2 ({ 4 }) .4 ({ 5 }) .2 ({ 6 }) ( ({ 7 }) Miyao ({ 8 }) and ({ 9 }) Tsujii ({ 10 }) , ({ 11 }) 2005 ({ 12 }) ) ({ 13 }) and ({ 14 }) Head ({ 15 }) Finalization ({ 16 }) ( ({ 17 }) Isozaki ({ 18 }) et ({ 19 }) al. ({ 20 }) , ({ 21 }) 2010b ({ 22 }) ) ({ 23 }) to ({ 24 }) preprocess ({ 25 }) English ({ 26 }) data ({ 27 }) . ({ 28 }) 
# Sentence pair (264) source length 15 target length 14 alignment score : 0.000448331
This method enabled more accurate translations within English-Japanese translations than the conventional settings . 
NULL ({ }) This ({ 1 }) method ({ 2 }) enabled ({ 3 }) more ({ 4 }) accurate ({ 5 }) translations ({ 6 }) within ({ 7 }) English-Japanese ({ 8 }) translations ({ 9 }) than ({ 10 }) with ({ }) the ({ 11 }) conventional ({ 12 }) settings ({ 13 }) . ({ 14 }) 
# Sentence pair (265) source length 17 target length 17 alignment score : 0.00120482
We have applied the following Head Finalization rules from ( Su-doh et al. , 2011 ) : 
NULL ({ }) We ({ 1 }) have ({ 2 }) applied ({ 3 }) the ({ 4 }) following ({ 5 }) Head ({ 6 }) Finalization ({ 7 }) rules ({ 8 }) from ({ 9 }) ( ({ 10 }) Su-doh ({ 11 }) et ({ 12 }) al. ({ 13 }) , ({ 14 }) 2011 ({ 15 }) ) ({ 16 }) : ({ 17 }) 
# Sentence pair (266) source length 17 target length 17 alignment score : 0.000977203
- Reverse each phrase 's word orders when the phrase does not end with a head . 
NULL ({ }) - ({ 1 }) Reverse ({ 2 }) each ({ 3 }) phrase ({ 4 }) 's ({ 5 }) word ({ 6 }) orders ({ 7 }) when ({ 8 }) the ({ 9 }) phrase ({ 10 }) does ({ 11 }) not ({ 12 }) end ({ 13 }) with ({ 14 }) a ({ 15 }) head ({ 16 }) . ({ 17 }) 
# Sentence pair (267) source length 5 target length 5 alignment score : 0.251551
- Exclude coordination from reversing 
NULL ({ }) - ({ 1 }) Exclude ({ 2 }) coordination ({ 3 }) from ({ 4 }) reversing ({ 5 }) 
# Sentence pair (268) source length 7 target length 7 alignment score : 0.0968298
- Convert plural nouns to singular forms 
NULL ({ }) - ({ 1 }) Convert ({ 2 }) plural ({ 3 }) nouns ({ 4 }) to ({ 5 }) singular ({ 6 }) forms ({ 7 }) 
# Sentence pair (269) source length 9 target length 15 alignment score : 6.32855e-18
- Remove articles " a " , " an " , and " the " 
NULL ({ 5 14 }) - ({ 1 }) Remove ({ 2 }) articles ({ 3 }) a ({ 4 }) , ({ 11 }) an ({ 6 }) , ({ 7 }) and ({ 12 }) the ({ 8 9 10 13 15 }) 
# Sentence pair (270) source length 10 target length 10 alignment score : 0.039932
- Insert pseudo-particles _va0 , _va1 , and _va2 . 
NULL ({ }) - ({ 1 }) Insert ({ 2 }) pseudo-particles ({ 3 }) _va0 ({ 4 }) , ({ 5 }) _va1 ({ 6 }) , ({ 7 }) and ({ 8 }) _va2 ({ 9 }) . ({ 10 }) 
# Sentence pair (271) source length 26 target length 26 alignment score : 7.53417e-05
For the pseudo-particles , we use the following insertion rules ( arg1 and arg2 are swapped when the head verb 's voice is passive ) : 
NULL ({ }) For ({ 1 }) the ({ 2 }) pseudo-particles ({ 3 }) , ({ 4 }) we ({ 5 }) use ({ 6 }) the ({ 7 }) following ({ 8 }) insertion ({ 9 }) rules ({ 10 }) ( ({ 11 }) arg1 ({ 12 }) and ({ 13 }) arg2 ({ 14 }) are ({ 15 }) swapped ({ 16 }) when ({ 17 }) the ({ 18 }) head ({ 19 }) verb ({ 20 }) 's ({ 21 }) voice ({ 22 }) is ({ 23 }) passive ({ 24 }) ) ({ 25 }) : ({ 26 }) 
# Sentence pair (272) source length 12 target length 12 alignment score : 0.0143646
- Add _va0 after the arg1 entry of the sentence head verb 
NULL ({ }) - ({ 1 }) Add ({ 2 }) _va0 ({ 3 }) after ({ 4 }) the ({ 5 }) arg1 ({ 6 }) entry ({ 7 }) of ({ 8 }) the ({ 9 }) sentence ({ 10 }) head ({ 11 }) verb ({ 12 }) 
# Sentence pair (273) source length 9 target length 9 alignment score : 0.0655608
- Add _va1 after arg1 entries of other verbs 
NULL ({ }) - ({ 1 }) Add ({ 2 }) _va1 ({ 3 }) after ({ 4 }) arg1 ({ 5 }) entries ({ 6 }) of ({ 7 }) other ({ 8 }) verbs ({ 9 }) 
# Sentence pair (274) source length 9 target length 9 alignment score : 0.0663508
- Add _va2 after arg2 entries of all verbs 
NULL ({ }) - ({ 1 }) Add ({ 2 }) _va2 ({ 3 }) after ({ 4 }) arg2 ({ 5 }) entries ({ 6 }) of ({ 7 }) all ({ 8 }) verbs ({ 9 }) 
# Sentence pair (275) source length 13 target length 13 alignment score : 0.00797983
Table 2 and Table 3 show the English-Japanese and Japanese-English evaluation results . 
NULL ({ }) Table ({ 1 }) 2 ({ 2 }) and ({ 3 }) Table ({ 4 }) 3 ({ 5 }) show ({ 6 }) the ({ 7 }) English-Japanese ({ 8 }) and ({ 9 }) Japanese-English ({ 10 }) evaluation ({ 11 }) results ({ 12 }) . ({ 13 }) 
# Sentence pair (276) source length 14 target length 14 alignment score : 0.00481182
The best scores in each evaluation metrics are highlighted for each data set . 
NULL ({ }) The ({ 1 }) best ({ 2 }) scores ({ 3 }) in ({ 4 }) each ({ 5 }) evaluation ({ 6 }) metrics ({ 7 }) are ({ 8 }) highlighted ({ 9 }) for ({ 10 }) each ({ 11 }) data ({ 12 }) set ({ 13 }) . ({ 14 }) 
# Sentence pair (277) source length 28 target length 27 alignment score : 1.0087e-05
All evaluation metrics have been used in both directions between English and Japanese , to measure consistency and sufficiency of the metrics in the language pair . 
NULL ({ }) All ({ 1 }) evaluation ({ 2 }) metrics ({ 3 }) have ({ 4 }) been ({ 5 }) used ({ 6 }) in ({ 7 }) both ({ 8 }) directions ({ 9 }) between ({ 10 }) English ({ 11 }) and ({ 12 }) Japanese ({ 13 }) , ({ 14 }) to ({ 15 }) measure ({ 16 }) the ({ }) consistency ({ 17 }) and ({ 18 }) sufficiency ({ 19 }) of ({ 20 }) the ({ 21 }) metrics ({ 22 }) in ({ 23 }) the ({ 24 }) language ({ 25 }) pair ({ 26 }) . ({ 27 }) 
# Sentence pair (278) source length 33 target length 31 alignment score : 2.94184e-10
In this case , the evaluation scores created by BLEU and RIBES are not comparative due to the differences of Japanese word definitions between the outputs of word segmentation methods . 
NULL ({ }) In ({ 1 }) this ({ 2 }) case ({ 3 }) , ({ 4 }) the ({ 5 }) evaluation ({ 6 }) scores ({ 7 }) created ({ 8 }) by ({ 9 }) BLEU ({ 10 }) and ({ 11 }) RIBES ({ 12 }) are ({ 13 }) not ({ 14 }) comparative ({ 15 }) , ({ }) due ({ 16 }) to ({ 17 }) the ({ 18 }) differences ({ 19 }) in ({ 20 }) the ({ }) Japanese ({ 21 }) word ({ 22 }) definitions ({ 23 }) among ({ 24 }) the ({ 25 }) outputs ({ 26 }) of ({ 27 }) word ({ 28 }) segmentation ({ 29 }) methods ({ 30 }) . ({ 31 }) 
# Sentence pair (279) source length 43 target length 39 alignment score : 7.16053e-11
Furthermore , the CHAR scores in BLEU and BLEU in Characters should be regarded as almost same while small changes have been introduced due to statistical errors and the differences in the methods how to treat space characters . 
NULL ({ }) Furthermore ({ 1 }) , ({ 2 }) the ({ 3 }) CHAR ({ 4 }) scores ({ 5 }) in ({ 6 }) BLEU ({ 7 }) and ({ 8 }) BLEU ({ 9 }) in ({ 10 }) Characters ({ 11 }) should ({ 12 }) be ({ 13 }) regarded ({ 14 }) as ({ 15 }) almost ({ 16 }) the ({ }) same ({ 17 }) , ({ }) while ({ 18 }) small ({ 19 }) changes ({ 20 }) have ({ 21 }) been ({ 22 }) introduced ({ 23 }) , ({ }) due ({ 24 }) to ({ 25 }) statistical ({ 26 }) errors ({ 27 }) and ({ 28 }) the ({ 29 }) differences ({ 30 }) in ({ 31 }) the ({ 32 }) methods ({ 33 }) in ({ }) how ({ 34 }) to ({ 35 }) treat ({ 36 }) space ({ 37 }) characters ({ 38 }) . ({ 39 }) 
# Sentence pair (280) source length 27 target length 26 alignment score : 2.74665e-06
We found that the three supervised morphological analyzers KyTea , MeCab , and JUMAN were much higher than latticelm and CAT , and were competitive . 
NULL ({ }) We ({ 1 }) found ({ 2 }) that ({ 3 }) the ({ 4 }) three ({ 5 }) supervised ({ 6 }) morphological ({ 7 }) analyzers ({ 8 }) : ({ }) KyTea ({ 9 }) , ({ 10 }) MeCab ({ 11 }) , ({ 12 }) and ({ 13 }) JUMAN ({ 14 }) were ({ 15 }) much ({ 16 }) higher ({ 17 }) than ({ 18 }) latticelm ({ 19 }) and ({ 20 }) CAT ({ 21 }) , ({ 22 }) and ({ 23 }) were ({ 24 }) competitive ({ 25 }) . ({ 26 }) 
# Sentence pair (281) source length 38 target length 31 alignment score : 1.09372e-16
For instance , on REUTERS in Table 2 , BLEU scores were ranged from 27 .88 to 29 .53 , while latticelm was 15 .28 and CAT was 22 .10 . 
NULL ({ }) For ({ 1 }) instance ({ 2 }) , ({ 3 }) on ({ 4 }) REUTERS ({ 5 }) in ({ 6 }) Table ({ 7 }) 2 ({ 8 }) , ({ 9 }) BLEU ({ 10 }) scores ({ 11 }) ranged ({ 12 13 }) from ({ 14 }) 27 ({ 15 }) .88 ({ 16 }) to ({ 17 }) 29 ({ 18 }) .53 ({ 19 }) , ({ 20 }) while ({ 21 }) for ({ }) latticelm ({ 22 }) , ({ }) the ({ }) score ({ }) was ({ 23 }) 15 ({ 24 }) .28 ({ 25 }) and ({ 26 }) for ({ }) CAT ({ 27 }) , ({ }) the ({ }) score ({ }) was ({ 28 }) 22 ({ 29 }) .10 ({ 30 }) . ({ 31 }) 
# Sentence pair (282) source length 20 target length 17 alignment score : 1.19611e-09
The unsupervised morphological analyzer latticelm and one of heuristic methods CAT were worse than our expectations . 
NULL ({ }) The ({ 1 }) unsupervised ({ 2 }) morphological ({ 3 }) analyzer ({ 4 }) , ({ }) latticelm ({ 5 }) , ({ }) and ({ 6 }) one ({ 7 }) of ({ 8 }) heuristic ({ 9 }) methods ({ 10 }) , ({ }) CAT ({ 11 }) , ({ }) performed ({ 12 }) worse ({ 13 }) than ({ 14 }) expectations ({ 15 16 }) . ({ 17 }) 
# Sentence pair (283) source length 13 target length 14 alignment score : 7.55156e-18
These two were the worst or the second worst results in all settings . 
NULL ({ 7 }) These ({ 1 }) two ({ 2 }) results ({ 10 }) were ({ 3 }) the ({ 4 }) worst ({ 5 6 9 }) , ({ 8 }) in ({ 11 }) all ({ 12 }) of ({ }) the ({ }) settings ({ 13 }) . ({ 14 }) 
# Sentence pair (284) source length 13 target length 12 alignment score : 0.000229901
The results of CHAR were counterintuitive and yet to be discussed . 
NULL ({ }) The ({ 1 }) results ({ 2 }) of ({ 3 }) CHAR ({ 4 }) were ({ 5 }) counterintuitive ({ 6 }) and ({ 7 }) are ({ }) yet ({ 8 }) to ({ 9 }) be ({ 10 }) discussed ({ 11 }) . ({ 12 }) 
# Sentence pair (285) source length 15 target length 13 alignment score : 1.88497e-19
It was relatively much better than the supervised morphological analyzers in BLEU . 
NULL ({ 2 3 }) The ({ 1 }) results ({ 4 }) were ({ }) better ({ 5 }) than ({ 6 }) the ({ }) results ({ }) for ({ }) the ({ 7 }) supervised ({ 8 }) morphological ({ 9 }) analyzers ({ 10 }) in ({ 11 }) BLEU ({ 12 }) . ({ 13 }) 
# Sentence pair (286) source length 11 target length 13 alignment score : 3.13342e-10
Besides , it was almost competitive in RIBES and BLUE in Characters . 
NULL ({ 2 3 }) It ({ 1 }) was ({ 4 }) almost ({ 5 }) competitive ({ 6 }) in ({ 7 }) RIBES ({ 8 }) and ({ 9 }) BLUE ({ 10 }) in ({ 11 }) Characters ({ 12 }) . ({ 13 }) 
# Sentence pair (287) source length 24 target length 24 alignment score : 2.43807e-27
For example , CHAR achieved the best 38 .42 score in BLEU on REUTERS , but the second best KyTea was 29 .53 . 
NULL ({ 3 }) CHAR ({ 1 4 }) achieved ({ 5 }) the ({ 6 }) best ({ 7 }) score ({ 10 }) in ({ 11 }) BLEU ({ 12 }) on ({ 13 }) REUTERS ({ 14 }) ( ({ }) 38 ({ 8 }) .42 ({ 9 }) ) ({ }) , ({ 15 }) but ({ 16 }) the ({ 17 }) second-best ({ 18 19 }) was ({ 21 }) KyTea ({ 20 }) ( ({ }) 29 ({ 22 }) .53 ({ 2 23 }) ) ({ }) . ({ 24 }) 
# Sentence pair (288) source length 23 target length 26 alignment score : 5.38491e-13
In the case of BLEU in Characters on REUTERS , CHAR achieved 38 .61 , while the worst supervised result was KyTea 's 39 .82 . 
NULL ({ 2 3 4 }) For ({ 1 }) BLEU ({ 5 }) in ({ 6 }) Characters ({ 7 }) on ({ 8 }) REUTERS ({ 9 }) , ({ 10 }) CHAR ({ 11 }) achieved ({ 12 }) 38 ({ 13 }) .61 ({ 14 }) , ({ 15 }) while ({ 16 }) the ({ 17 }) worst ({ 18 }) supervised ({ 19 }) result ({ 20 }) was ({ 21 }) KyTea ({ 22 }) 's ({ 23 }) 39 ({ 24 }) .82 ({ 25 }) . ({ 26 }) 
# Sentence pair (289) source length 15 target length 15 alignment score : 1.69537e-15
In this case , the evaluation scores are lower than English-Japanese translations in general . 
NULL ({ 13 }) For ({ 1 }) Japanese-English ({ 2 }) translations ({ 3 }) , ({ 4 }) the ({ 5 }) evaluation ({ 6 }) scores ({ 7 }) were ({ 8 }) generally ({ }) lower ({ 9 }) than ({ 10 }) for ({ }) English-Japanese ({ 11 }) translations ({ 12 14 }) . ({ 15 }) 
# Sentence pair (290) source length 10 target length 10 alignment score : 0.000480361
It is because Japanese-English translations are conducted without Head-Finalization . 
NULL ({ }) This ({ 1 }) is ({ 2 }) because ({ 3 }) Japanese-English ({ 4 }) translations ({ 5 }) are ({ 6 }) conducted ({ 7 }) without ({ 8 }) Head-Finalization ({ 9 }) . ({ 10 }) 
# Sentence pair (291) source length 15 target length 15 alignment score : 0.00430788
Again , the supervised morphological analyzers KyTea , MeCab , and JUMAN were competitive . 
NULL ({ }) Again ({ 1 }) , ({ 2 }) the ({ 3 }) supervised ({ 4 }) morphological ({ 5 }) analyzers ({ 6 }) KyTea ({ 7 }) , ({ 8 }) MeCab ({ 9 }) , ({ 10 }) and ({ 11 }) JUMAN ({ 12 }) were ({ 13 }) competitive ({ 14 }) . ({ 15 }) 
# Sentence pair (292) source length 14 target length 14 alignment score : 0.00073437
All supervised analyzers were better than the unsupervised and the both heuristic methods . 
NULL ({ }) All ({ 1 }) supervised ({ 2 }) analyzers ({ 3 }) performed ({ 4 }) better ({ 5 }) than ({ 6 }) the ({ 7 }) unsupervised ({ 8 }) and ({ 9 }) the ({ 10 }) both ({ 11 }) heuristic ({ 12 }) methods ({ 13 }) . ({ 14 }) 
# Sentence pair (293) source length 22 target length 25 alignment score : 1.72649e-13
On the other hand , the unsupervised morphological analyzer latticelm and one of heuristic methods CAT were competitive to the supervised analyzers in RIBES . 
NULL ({ 2 }) Conversely ({ 1 3 4 }) , ({ 5 }) the ({ 6 }) unsupervised ({ 7 }) morphological ({ 8 }) analyzer ({ 9 }) latticelm ({ 10 }) and ({ 11 }) one ({ 12 }) of ({ 13 }) heuristic ({ 14 }) methods ({ 15 }) CAT ({ 16 }) performed ({ 17 }) competitively ({ 18 }) with ({ 19 }) the ({ 20 }) supervised ({ 21 }) analyzers ({ 22 }) in ({ 23 }) RIBES ({ 24 }) . ({ 25 }) 
# Sentence pair (294) source length 12 target length 15 alignment score : 1.17021e-13
For example , latticelm was 62 .51 and KyTea was 62 .90 on REUTERS . 
NULL ({ 3 }) latticelm ({ 1 }) was ({ 5 }) 62 ({ 6 }) .51 ({ 2 4 7 }) and ({ 8 }) KyTea ({ 9 }) was ({ 10 }) 62 ({ 11 }) .90 ({ 12 }) on ({ 13 }) REUTERS ({ 14 }) . ({ 15 }) 
# Sentence pair (295) source length 15 target length 15 alignment score : 0.00167823
In this case , CHAR was not competitive to the supervised analyzers in total . 
NULL ({ }) In ({ 1 }) this ({ 2 }) case ({ 3 }) , ({ 4 }) CHAR ({ 5 }) was ({ 6 }) not ({ 7 }) competitive ({ 8 }) to ({ 9 }) the ({ 10 }) supervised ({ 11 }) analyzers ({ 12 }) in ({ 13 }) total ({ 14 }) . ({ 15 }) 
# Sentence pair (296) source length 31 target length 34 alignment score : 3.54738e-29
The results were the worst scores in BLEU and RIBES on REUTERS and JENAAD+REUTERS . The only one exception was in the case of the best 56 .55 BLEU in Characters on REUTERS . 
NULL ({ 15 20 21 }) The ({ 1 }) results ({ 2 }) for ({ }) CHAR ({ }) were ({ 3 }) the ({ 4 }) lowest ({ 5 }) scores ({ 6 }) in ({ 7 }) BLEU ({ 8 }) and ({ 9 }) RIBES ({ 10 }) on ({ 11 }) REUTERS ({ 12 }) and ({ 13 }) JENAAD+REUTERS ({ 14 }) , ({ }) with ({ }) the ({ 22 }) exception ({ 23 }) of ({ 24 }) the ({ 25 }) best ({ 26 }) 56 ({ 16 18 27 }) .55 ({ 17 19 28 }) BLEU ({ 29 }) in ({ 30 }) Characters ({ 31 }) on ({ 32 }) REUTERS ({ 33 }) . ({ 34 }) 
# Sentence pair (297) source length 19 target length 18 alignment score : 5.90552e-05
We found the results of the supervised morphological analyzers are better in both English-Japanese and Japanese-English experiments . 
NULL ({ }) We ({ 1 }) found ({ 2 }) that ({ }) the ({ 3 }) results ({ 4 }) of ({ 5 }) the ({ 6 }) supervised ({ 7 }) morphological ({ 8 }) analyzers ({ 9 }) were ({ 10 }) better ({ 11 }) in ({ 12 }) both ({ 13 }) English-Japanese ({ 14 }) and ({ 15 }) Japanese-English ({ 16 }) experiments ({ 17 }) . ({ 18 }) 
# Sentence pair (298) source length 39 target length 37 alignment score : 2.01904e-13
And the differences in the word definition of KyTea , MeCab , and JUMAN were not remarkable , especially in English-Japanese translations , although the word definition of KyTea is much shorter than MeCab and JUMAN . 
NULL ({ }) Furthermore ({ 1 }) , ({ }) the ({ 2 }) differences ({ 3 }) in ({ 4 }) the ({ 5 }) word ({ 6 }) definition ({ 7 }) of ({ 8 }) KyTea ({ 9 }) , ({ 10 }) MeCab ({ 11 }) , ({ 12 }) and ({ 13 }) JUMAN ({ 14 }) were ({ 15 }) not ({ 16 }) substantial ({ 17 }) , ({ 18 }) especially ({ 19 }) for ({ 20 }) English-Japanese ({ 21 }) translations ({ 22 }) , ({ 23 }) although ({ 24 }) the ({ 25 }) word ({ 26 }) definition ({ 27 }) of ({ 28 }) KyTea ({ 29 }) is ({ 30 }) much ({ 31 }) shorter ({ 32 }) than ({ 33 }) for ({ }) MeCab ({ 34 }) and ({ 35 }) JUMAN ({ 36 }) . ({ 37 }) 
# Sentence pair (299) source length 25 target length 24 alignment score : 3.50447e-06
This result implies that phrase-based SMT can output sufficiently reasonable word / phrase alignments that can treat different word definitions in most cases . 
NULL ({ }) This ({ 1 }) result ({ 2 }) implies ({ 3 }) that ({ 4 }) phrase-based ({ 5 }) SMT ({ 6 }) can ({ 7 }) output ({ 8 }) sufficiently ({ 9 }) reasonable ({ 10 }) word ({ 11 }) / ({ 12 }) phrase ({ 13 }) alignments ({ 14 }) that ({ 15 }) can ({ 16 }) treat ({ 17 }) different ({ 18 }) word ({ 19 }) definitions ({ 20 }) , ({ }) in ({ 21 }) most ({ 22 }) cases ({ 23 }) . ({ 24 }) 
# Sentence pair (300) source length 26 target length 27 alignment score : 3.60349e-09
On the other hand , the unsupervised morphological analyzer latticelm and one of our heuristic methods CAT were very much worse than the supervised morphological analyzers . 
NULL ({ }) On ({ 1 }) the ({ 2 }) other ({ 3 }) hand ({ 4 }) , ({ 5 }) the ({ 6 }) unsupervised ({ 7 }) morphological ({ 8 }) analyzer ({ 9 }) latticelm ({ 10 }) and ({ 11 }) one ({ 12 }) of ({ 13 }) our ({ 14 }) heuristic ({ 15 }) methods ({ 16 }) CAT ({ 17 }) performed ({ 18 19 }) much ({ 20 }) poorer ({ 21 }) than ({ 22 }) the ({ 23 }) supervised ({ 24 }) morphological ({ 25 }) analyzers ({ 26 }) . ({ 27 }) 
# Sentence pair (301) source length 9 target length 9 alignment score : 0.0210308
The experiments demonstrated an unexpected result for CHAR . 
NULL ({ }) The ({ 1 }) experiments ({ 2 }) demonstrated ({ 3 }) an ({ 4 }) unexpected ({ 5 }) result ({ 6 }) for ({ 7 }) CHAR ({ 8 }) . ({ 9 }) 
# Sentence pair (302) source length 12 target length 11 alignment score : 5.78323e-12
It was good at English-Japanese but not at Japanese-English translations . 
NULL ({ }) It ({ 1 }) excelled ({ 2 3 }) with ({ 4 }) English-Japanese ({ 5 }) translations ({ }) , ({ }) but ({ 6 }) not ({ 7 }) with ({ 8 }) Japanese-English ({ 9 }) translations ({ 10 }) . ({ 11 }) 
# Sentence pair (303) source length 13 target length 9 alignment score : 8.7674e-07
We consider the possible reasons for this result : 
NULL ({ }) We ({ 1 }) consider ({ 2 }) the ({ 3 }) possible ({ 4 }) reasons ({ 5 }) for ({ 6 }) this ({ 7 }) result ({ 8 }) in ({ }) the ({ }) following ({ }) list ({ }) : ({ 9 }) 
# Sentence pair (304) source length 11 target length 11 alignment score : 0.0115007
- The Head Finalization of English-Japanese lead better phrase alignments . 
NULL ({ }) - ({ 1 }) The ({ 2 }) Head ({ 3 }) Finalization ({ 4 }) of ({ 5 }) English-Japanese ({ 6 }) lead ({ 7 }) better ({ 8 }) phrase ({ 9 }) alignments ({ 10 }) . ({ 11 }) 
# Sentence pair (305) source length 26 target length 26 alignment score : 4.56306e-05
- Since CHAR treat a character as a word , the best combination of its phrase alignments were the best suited for the SMT decoding . 
NULL ({ }) - ({ 1 }) Since ({ 2 }) CHAR ({ 3 }) treats ({ 4 }) a ({ 5 }) character ({ 6 }) as ({ 7 }) a ({ 8 }) word ({ 9 }) , ({ 10 }) the ({ 11 }) best ({ 12 }) combination ({ 13 }) of ({ 14 }) its ({ 15 }) phrase ({ 16 }) alignments ({ 17 }) were ({ 18 }) the ({ 19 }) best ({ 20 }) suited ({ 21 }) for ({ 22 }) the ({ 23 }) SMT ({ 24 }) decoding ({ 25 }) . ({ 26 }) 
# Sentence pair (306) source length 15 target length 15 alignment score : 0.00237043
On the other hand , we observed the following issues from our error analysis : 
NULL ({ }) On ({ 1 }) the ({ 2 }) other ({ 3 }) hand ({ 4 }) , ({ 5 }) we ({ 6 }) observed ({ 7 }) the ({ 8 }) following ({ 9 }) issues ({ 10 }) from ({ 11 }) our ({ 12 }) error ({ 13 }) analysis ({ 14 }) : ({ 15 }) 
# Sentence pair (307) source length 9 target length 9 alignment score : 0.0249073
- Uncommon named entities were almost wrongly translated . 
NULL ({ }) - ({ 1 }) Uncommon ({ 2 }) named ({ 3 }) entities ({ 4 }) were ({ 5 }) almost ({ 6 }) wrongly ({ 7 }) translated ({ 8 }) . ({ 9 }) 
# Sentence pair (308) source length 14 target length 14 alignment score : 0.000907743
( For example ,  Czech was produced instead of  Czechoslovakia . ) 
NULL ({ }) ( ({ 1 }) For ({ 2 }) example ({ 3 }) , ({ 4 })  ({ 5 }) Czech ({ 6 }) was ({ 7 }) produced ({ 8 }) instead ({ 9 }) of ({ 10 })  ({ 11 }) Czechoslovakia ({ 12 }) . ({ 13 }) ) ({ 14 }) 
# Sentence pair (309) source length 14 target length 13 alignment score : 1.03484e-14
- Long sentences were translated worse than the other word segmentation outputs . 
NULL ({ 8 }) - ({ 1 }) Long ({ 2 6 7 }) sentences ({ 3 }) were ({ 4 }) not ({ }) translated ({ 5 }) as ({ }) well ({ }) as ({ }) other ({ 9 }) word ({ 10 }) segmentation ({ 11 }) outputs ({ 12 }) . ({ 13 }) 
# Sentence pair (310) source length 14 target length 14 alignment score : 0.000110261
The reasons of the CHAR results are yet to be analyzed in details . 
NULL ({ }) The ({ 1 }) reasons ({ 2 }) for ({ 3 }) the ({ 4 }) CHAR ({ 5 }) results ({ 6 }) are ({ 7 }) yet ({ 8 }) to ({ 9 }) be ({ 10 }) analyzed ({ 11 }) in ({ 12 }) detail ({ 13 }) . ({ 14 }) 
# Sentence pair (311) source length 24 target length 24 alignment score : 9.16737e-05
However , this result indicates that there is a possibility of better word segmentation than popular supervised morphological analyzers and CHAR word segmentation . 
NULL ({ }) However ({ 1 }) , ({ 2 }) this ({ 3 }) result ({ 4 }) indicates ({ 5 }) that ({ 6 }) there ({ 7 }) is ({ 8 }) a ({ 9 }) possibility ({ 10 }) of ({ 11 }) better ({ 12 }) word ({ 13 }) segmentation ({ 14 }) than ({ 15 }) popular ({ 16 }) supervised ({ 17 }) morphological ({ 18 }) analyzers ({ 19 }) and ({ 20 }) CHAR ({ 21 }) word ({ 22 }) segmentation ({ 23 }) . ({ 24 }) 
# Sentence pair (312) source length 11 target length 10 alignment score : 0.00304601
We are planning to conduct further investigation in future . 
NULL ({ }) We ({ 1 }) are ({ 2 }) planning ({ 3 }) to ({ 4 }) conduct ({ 5 }) further ({ 6 }) investigations ({ 7 }) in ({ 8 }) the ({ }) future ({ 9 }) . ({ 10 }) 
# Sentence pair (313) source length 38 target length 37 alignment score : 1.06564e-35
The current evaluation metrics we pursued in this paper were not sufficient to discuss more accurately about the relative advantages and disadvantages of word segmentation , since they did not produce consistent scores as explained below : 
NULL ({ 18 }) The ({ 1 }) current ({ 2 }) evaluation ({ 3 }) metrics ({ 4 }) that ({ }) we ({ 5 }) pursued ({ 6 }) in ({ 7 }) this ({ 8 }) paper ({ 9 }) were ({ 10 }) insufficient ({ 11 12 28 29 30 }) to ({ 13 }) discuss ({ 14 }) the ({ }) relative ({ 15 19 }) advantages ({ 16 17 20 }) and ({ 21 }) disadvantages ({ 22 }) of ({ 23 }) word ({ 24 }) segmentation ({ 25 }) in ({ }) detail ({ }) , ({ 26 }) since ({ 27 }) the ({ }) scores ({ 33 }) that ({ }) were ({ }) produced ({ 31 }) were ({ }) inconsistent ({ 32 }) , ({ }) as ({ 34 }) explained ({ 35 }) below ({ 36 }) : ({ 37 }) 
# Sentence pair (314) source length 10 target length 10 alignment score : 0.0121976
- There were many contradictory figures among evaluation metrics . 
NULL ({ }) - ({ 1 }) There ({ 2 }) were ({ 3 }) many ({ 4 }) contradictory ({ 5 }) figures ({ 6 }) among ({ 7 }) evaluation ({ 8 }) metrics ({ 9 }) . ({ 10 }) 
# Sentence pair (315) source length 15 target length 15 alignment score : 0.000494125
There was a case that BLEU was high , while other metrics were low . 
NULL ({ }) There ({ 1 }) was ({ 2 }) a ({ 3 }) case ({ 4 }) that ({ 5 }) BLEU ({ 6 }) was ({ 7 }) high ({ 8 }) , ({ 9 }) while ({ 10 }) other ({ 11 }) metrics ({ 12 }) were ({ 13 }) low ({ 14 }) . ({ 15 }) 
# Sentence pair (316) source length 20 target length 19 alignment score : 1.63761e-06
Moreover , there is also a case that RIBES and BLEU in Characters were incompatible with each other . 
NULL ({ }) Moreover ({ 1 }) , ({ 2 }) there ({ 3 }) is ({ 4 }) also ({ 5 }) a ({ 6 }) case ({ 7 }) in ({ }) which ({ 8 }) RIBES ({ 9 }) and ({ 10 }) BLEU ({ 11 }) in ({ 12 }) Characters ({ 13 }) were ({ 14 }) incompatible ({ 15 }) with ({ 16 }) each ({ 17 }) other ({ 18 }) . ({ 19 }) 
# Sentence pair (317) source length 41 target length 41 alignment score : 7.81898e-15
For example , on WIKIPEDIA in Table 2 , while CHAR was relatively the highest and greatly better than the supervised morphological analyzers in RIBES , MeCab achieved the best score and notably better than CHAR in BLEU in Characters . 
NULL ({ 13 }) For ({ 1 }) example ({ 2 }) , ({ 3 }) on ({ 4 }) WIKIPEDIA ({ 5 }) in ({ 6 }) Table ({ 7 }) 2 ({ 8 }) , ({ 9 }) while ({ 10 }) CHAR ({ 11 }) was ({ 12 }) the ({ 14 }) highest ({ 15 }) , ({ }) and ({ 16 }) performed ({ 17 }) better ({ 18 }) than ({ 19 }) the ({ 20 }) supervised ({ 21 }) morphological ({ 22 }) analyzers ({ 23 }) in ({ 24 }) RIBES ({ 25 }) , ({ 26 }) MeCab ({ 27 }) achieved ({ 28 }) the ({ 29 }) best ({ 30 }) score ({ 31 }) and ({ 32 }) notably ({ 33 }) better ({ 34 }) than ({ 35 }) CHAR ({ 36 }) in ({ 37 }) BLEU ({ 38 }) in ({ 39 }) Characters ({ 40 }) . ({ 41 }) 
# Sentence pair (318) source length 28 target length 28 alignment score : 1.62788e-05
- If we compare every column in a row , there were tendencies that the best and the worst corpora were the same for every evaluation metrics . 
NULL ({ }) - ({ 1 }) If ({ 2 }) we ({ 3 }) compare ({ 4 }) every ({ 5 }) column ({ 6 }) in ({ 7 }) a ({ 8 }) row ({ 9 }) , ({ 10 }) there ({ 11 }) were ({ 12 }) tendencies ({ 13 }) that ({ 14 }) the ({ 15 }) best ({ 16 }) and ({ 17 }) the ({ 18 }) worst ({ 19 }) corpora ({ 20 }) were ({ 21 }) the ({ 22 }) same ({ 23 }) for ({ 24 }) every ({ 25 }) evaluation ({ 26 }) metrics ({ 27 }) . ({ 28 }) 
# Sentence pair (319) source length 34 target length 34 alignment score : 2.51383e-07
In Table 2 , REUTERS was the best and WIKIPEDIA was the worst in terms of BLEU , but also JENAAD+REUTERS was the best and WIKIPEDIA was the worst in terms of RIBES . 
NULL ({ }) In ({ 1 }) Table ({ 2 }) 2 ({ 3 }) , ({ 4 }) REUTERS ({ 5 }) was ({ 6 }) the ({ 7 }) best ({ 8 }) and ({ 9 }) WIKIPEDIA ({ 10 }) was ({ 11 }) the ({ 12 }) worst ({ 13 }) in ({ 14 }) terms ({ 15 }) of ({ 16 }) BLEU ({ 17 }) , ({ 18 }) but ({ 19 }) also ({ 20 }) JENAAD+REUTERS ({ 21 }) was ({ 22 }) the ({ 23 }) best ({ 24 }) and ({ 25 }) WIKIPEDIA ({ 26 }) was ({ 27 }) the ({ 28 }) worst ({ 29 }) in ({ 30 }) terms ({ 31 }) of ({ 32 }) RIBES ({ 33 }) . ({ 34 }) 
# Sentence pair (320) source length 16 target length 16 alignment score : 0.000921603
- Even when we compare every row in a column , there were no tendencies . 
NULL ({ }) - ({ 1 }) Even ({ 2 }) when ({ 3 }) we ({ 4 }) compare ({ 5 }) every ({ 6 }) row ({ 7 }) in ({ 8 }) a ({ 9 }) column ({ 10 }) , ({ 11 }) there ({ 12 }) were ({ 13 }) no ({ 14 }) tendencies ({ 15 }) . ({ 16 }) 
# Sentence pair (321) source length 24 target length 24 alignment score : 0.000121728
For instance , in terms of BLEU in Characters , CHAR , JUMAN , and MeCab achieved the best scores in Table 3 . 
NULL ({ }) For ({ 1 }) instance ({ 2 }) , ({ 3 }) in ({ 4 }) terms ({ 5 }) of ({ 6 }) BLEU ({ 7 }) in ({ 8 }) Characters ({ 9 }) , ({ 10 }) CHAR ({ 11 }) , ({ 12 }) JUMAN ({ 13 }) , ({ 14 }) and ({ 15 }) MeCab ({ 16 }) achieved ({ 17 }) the ({ 18 }) best ({ 19 }) scores ({ 20 }) in ({ 21 }) Table ({ 22 }) 3 ({ 23 }) . ({ 24 }) 
# Sentence pair (322) source length 33 target length 33 alignment score : 1.24761e-09
This work focused on how the difference of word segmentation affects SMT outputs , the quality of the unsupervised word segmentation on SMT , and the meta-evaluation of the current evaluation metrics . 
NULL ({ }) This ({ 1 }) work ({ 2 }) focused ({ 3 }) on ({ 4 }) how ({ 5 }) the ({ 6 }) differences ({ 7 }) in ({ 8 }) word ({ 9 }) segmentation ({ 10 }) affected ({ 11 }) SMT ({ 12 }) outputs ({ 13 }) , ({ 14 }) the ({ 15 }) quality ({ 16 }) of ({ 17 }) the ({ 18 }) unsupervised ({ 19 }) word ({ 20 }) segmentation ({ 21 }) on ({ 22 }) SMT ({ 23 }) , ({ 24 }) and ({ 25 }) the ({ 26 }) meta-evaluation ({ 27 }) of ({ 28 }) the ({ 29 }) current ({ 30 }) evaluation ({ 31 }) metrics ({ 32 }) . ({ 33 }) 
# Sentence pair (323) source length 27 target length 26 alignment score : 1.05813e-05
In summary , we found that the representative morphological analyzers were competitive and much better than both unsupervised analyzer and one of our heuristic methods . 
NULL ({ }) In ({ 1 }) summary ({ 2 }) , ({ 3 }) we ({ 4 }) found ({ 5 }) that ({ 6 }) the ({ 7 }) representative ({ 8 }) morphological ({ 9 }) analyzers ({ 10 }) were ({ 11 }) competitive ({ 12 }) and ({ 13 }) much ({ 14 }) better ({ 15 }) than ({ 16 }) both ({ 17 }) the ({ }) unsupervised ({ 18 }) analyzer ({ 19 }) and ({ 20 }) one ({ 21 }) of ({ 22 }) our ({ 23 }) heuristic ({ 24 }) methods ({ 25 }) . ({ 26 }) 
# Sentence pair (324) source length 26 target length 27 alignment score : 4.94019e-08
After all , a heuristic word segmentation method CHAR achieved relatively good word-based BLEU scores and competitive character-based BLEU results , compared to the supervised analyzers . 
NULL ({ }) Nevertheless ({ 1 2 }) , ({ 3 }) a ({ 4 }) heuristic ({ 5 }) word ({ 6 }) segmentation ({ 7 }) method ({ 8 }) CHAR ({ 9 }) achieved ({ 10 }) relatively ({ 11 }) good ({ 12 }) word-based ({ 13 }) BLEU ({ 14 }) scores ({ 15 }) and ({ 16 }) competitive ({ 17 }) character-based ({ 18 }) BLEU ({ 19 }) results ({ 20 }) , ({ 21 }) compared ({ 22 }) to ({ 23 }) the ({ 24 }) supervised ({ 25 }) analyzers ({ 26 }) . ({ 27 }) 
# Sentence pair (325) source length 34 target length 34 alignment score : 4.0431e-28
Additionally , as we could not always obtain consistent scores from the current evaluation metrics , they were not sufficient to discuss more accurately about the relative advantages and disadvantages of word segmentation . 
NULL ({ 26 }) Additionally ({ 1 }) , ({ 2 }) as ({ 3 }) we ({ 4 }) could ({ 5 }) not ({ 6 }) always ({ 7 }) obtain ({ 8 }) consistent ({ 9 }) scores ({ 10 }) from ({ 11 }) the ({ 12 }) current ({ 13 }) evaluation ({ 14 }) metrics ({ 15 }) , ({ 16 }) the ({ }) data ({ 17 }) was ({ 18 }) insufficient ({ 19 20 }) for ({ 21 }) discussing ({ 22 }) the ({ }) relative ({ 23 27 }) advantages ({ 24 25 28 }) and ({ 29 }) disadvantages ({ 30 }) of ({ 31 }) word ({ 32 }) segmentation ({ 33 }) , ({ }) with ({ }) accuracy ({ }) . ({ 34 }) 
# Sentence pair (326) source length 17 target length 15 alignment score : 5.84023e-05
We also suggested it is possible to implement more optimized word segmentation on SMT . 
NULL ({ }) We ({ 1 }) have ({ }) also ({ 2 }) suggested ({ 3 }) that ({ }) it ({ 4 }) is ({ 5 }) possible ({ 6 }) to ({ 7 }) implement ({ 8 }) more ({ 9 }) optimized ({ 10 }) word ({ 11 }) segmentation ({ 12 }) on ({ 13 }) SMT ({ 14 }) . ({ 15 }) 
# Sentence pair (327) source length 9 target length 9 alignment score : 0.0288065
On Contribution of Syntactic Dependencies to Word Sense Disambiguation 
NULL ({ }) On ({ 1 }) Contribution ({ 2 }) of ({ 3 }) Syntactic ({ 4 }) Dependencies ({ 5 }) to ({ 6 }) Word ({ 7 }) Sense ({ 8 }) Disambiguation ({ 9 }) 
# Sentence pair (328) source length 21 target length 21 alignment score : 0.000609478
Traditionally , many researchers have addressed word sense disambiguation ( WSD ) as an independent classification problem for each word . 
NULL ({ }) Traditionally ({ 1 }) , ({ 2 }) many ({ 3 }) researchers ({ 4 }) have ({ 5 }) addressed ({ 6 }) word ({ 7 }) sense ({ 8 }) disambiguation ({ 9 }) ( ({ 10 }) WSD ({ 11 }) ) ({ 12 }) as ({ 13 }) an ({ 14 }) independent ({ 15 }) classification ({ 16 }) problem ({ 17 }) for ({ 18 }) each ({ 19 }) word ({ 20 }) . ({ 21 }) 
# Sentence pair (329) source length 42 target length 31 alignment score : 3.79889e-31
However , problems with their approaches are the disregard of the interdependencies of word senses , and the limited applicability to those word senses for which training instances are served . 
NULL ({ 10 18 }) However ({ 1 }) , ({ 2 }) the ({ 8 }) problem ({ }) with ({ 4 }) these ({ 5 }) approaches ({ 6 }) , ({ }) is ({ }) that ({ }) they ({ }) disregard ({ 9 }) the ({ 11 }) interdependencies ({ 12 }) of ({ 13 }) word ({ 14 }) senses ({ 15 }) , ({ 16 }) and ({ 17 }) that ({ }) it ({ }) is ({ }) limited ({ 19 }) in ({ }) its ({ }) applicability ({ 20 }) to ({ 21 }) the ({ }) word ({ 23 }) senses ({ 24 }) for ({ 25 }) which ({ 26 }) training ({ 27 }) instances ({ 28 }) are ({ 29 }) served ({ 30 }) .**[<-This ({ 7 }) sentence ({ 31 }) is ({ }) a ({ }) bit ({ 3 }) confusing] ({ 22 }) 
# Sentence pair (330) source length 19 target length 19 alignment score : 0.00170634
In this paper , we propose a supervised WSD model based on the syntactic dependencies of word senses . 
NULL ({ }) In ({ 1 }) this ({ 2 }) paper ({ 3 }) , ({ 4 }) we ({ 5 }) propose ({ 6 }) a ({ 7 }) supervised ({ 8 }) WSD ({ 9 }) model ({ 10 }) based ({ 11 }) on ({ 12 }) the ({ 13 }) syntactic ({ 14 }) dependencies ({ 15 }) of ({ 16 }) word ({ 17 }) senses ({ 18 }) . ({ 19 }) 
# Sentence pair (331) source length 22 target length 22 alignment score : 2.11785e-11
Particularly , we assume that there exist strong dependencies between the sense of a syntactic head and those of its dependents . 
NULL ({ 6 }) In ({ }) particular ({ 1 }) , ({ 2 }) we ({ 3 }) assume ({ 4 }) that ({ 5 }) strong ({ 8 }) dependencies ({ 9 }) between ({ 10 }) the ({ 11 }) sense ({ 12 }) of ({ 13 }) a ({ 14 }) syntactic ({ 15 }) head ({ 16 }) and ({ 17 }) those ({ 18 }) of ({ 19 }) its ({ 20 }) dependents ({ 21 }) exist ({ 7 }) . ({ 22 }) 
# Sentence pair (332) source length 27 target length 27 alignment score : 4.83462e-05
We describe these dependencies on the tree-structured conditional random fields ( T-CRFs ) , and obtain the most appropriate assignment of senses optimized over the sentence . 
NULL ({ }) We ({ 1 }) describe ({ 2 }) these ({ 3 }) dependencies ({ 4 }) on ({ 5 }) the ({ 6 }) tree-structured ({ 7 }) conditional ({ 8 }) random ({ 9 }) fields ({ 10 }) ( ({ 11 }) T-CRFs ({ 12 }) ) ({ 13 }) , ({ 14 }) and ({ 15 }) obtain ({ 16 }) the ({ 17 }) most ({ 18 }) appropriate ({ 19 }) assignment ({ 20 }) of ({ 21 }) senses ({ 22 }) optimized ({ 23 }) over ({ 24 }) the ({ 25 }) sentence ({ 26 }) . ({ 27 }) 
# Sentence pair (333) source length 44 target length 45 alignment score : 7.41482e-14
Also , we define these sense dependencies in combination with various coarse-grained sense tag sets , so that our model can even work for words that do not appear in the training data , and these combined features help relieve the data sparseness problem . 
NULL ({ 34 }) Furthermore ({ 1 }) , ({ 2 }) we ({ 3 }) define ({ 4 }) these ({ 5 }) sense ({ 6 }) dependencies ({ 7 }) in ({ 8 }) combination ({ 9 }) with ({ 10 }) various ({ 11 }) coarse-grained ({ 12 }) sense ({ 13 }) tag ({ 14 }) sets ({ 15 }) , ({ 16 }) so ({ 17 }) that ({ 18 }) our ({ 19 }) model ({ 20 }) can ({ 21 }) also ({ 22 }) work ({ 23 }) for ({ 24 }) words ({ 25 }) that ({ 26 }) do ({ 27 }) not ({ 28 }) appear ({ 29 }) in ({ 30 }) the ({ 31 }) training ({ 32 }) data ({ 33 }) ; ({ 35 }) these ({ 36 }) combined ({ 37 }) features ({ 38 }) help ({ 39 }) relieve ({ 40 }) the ({ 41 }) data ({ 42 }) sparseness ({ 43 }) problem ({ 44 }) . ({ 45 }) 
# Sentence pair (334) source length 32 target length 28 alignment score : 1.10918e-09
In experiments , we show the appropriateness of considering the sense dependencies , as well as the advantage of the combination of fine- and coarse-grained tag sets . 
NULL ({ }) In ({ 1 }) experiments ({ 2 }) , ({ 3 }) we ({ 4 }) display ({ 5 }) the ({ 6 }) appropriateness ({ 7 }) of ({ 8 }) considering ({ 9 }) the ({ 10 }) sense ({ 11 }) dependencies ({ 12 }) , ({ 13 }) as ({ 14 }) well ({ 15 }) as ({ 16 }) the ({ 17 }) advantage ({ 18 }) of ({ 19 }) [having ({ 20 }) ? ({ }) Using ({ }) ?] ({ }) the ({ }) combination ({ 21 }) of ({ 22 }) fine- ({ 23 }) and ({ 24 }) coarse-grained ({ 25 }) tag ({ 26 }) sets ({ 27 }) . ({ 28 }) 
# Sentence pair (335) source length 17 target length 17 alignment score : 0.00142215
The performance of our model is shown to be comparable to those of state-of-the-art WSD systems . 
NULL ({ }) The ({ 1 }) performance ({ 2 }) of ({ 3 }) our ({ 4 }) model ({ 5 }) is ({ 6 }) shown ({ 7 }) to ({ 8 }) be ({ 9 }) comparable ({ 10 }) to ({ 11 }) those ({ 12 }) of ({ 13 }) state-of-the-art ({ 14 }) WSD ({ 15 }) systems ({ 16 }) . ({ 17 }) 
# Sentence pair (336) source length 19 target length 18 alignment score : 1.28484e-09
We also present an in-depth analysis on the effectiveness of the sense dependency features with intuitive examples . 
NULL ({ }) We ({ 1 }) also ({ 2 }) present ({ 3 }) an ({ 4 }) in-depth ({ 5 }) analysis ({ 6 }) of ({ 7 }) the ({ 8 }) effectiveness ({ 9 }) of ({ 10 }) the ({ 11 }) sense ({ 12 }) dependency ({ 13 }) features ({ 14 }) by ({ }) using ({ 15 }) intuitive ({ 16 }) examples ({ 17 }) . ({ 18 }) 
# Sentence pair (337) source length 17 target length 16 alignment score : 0.000227564
Word sense disambiguation ( WSD ) is one of the fundamental problems in computational linguistics . 
NULL ({ }) Word ({ 1 }) sense ({ 2 }) disambiguation ({ 3 }) ( ({ 4 }) WSD ({ 5 }) ) ({ 6 }) is ({ 7 }) one ({ 8 }) of ({ 9 }) the ({ 10 }) most ({ }) fundamental ({ 11 }) problems ({ 12 }) in ({ 13 }) computational ({ 14 }) linguistics ({ 15 }) . ({ 16 }) 
# Sentence pair (338) source length 28 target length 28 alignment score : 2.69982e-05
The task of WSD is to resolve the inherent polysemy of words by determining the appropriate sense( s ) for each polysemous word in a given text . 
NULL ({ }) The ({ 1 }) task ({ 2 }) of ({ 3 }) WSD ({ 4 }) is ({ 5 }) to ({ 6 }) resolve ({ 7 }) the ({ 8 }) inherent ({ 9 }) polysemy ({ 10 }) of ({ 11 }) words ({ 12 }) by ({ 13 }) determining ({ 14 }) the ({ 15 }) appropriate ({ 16 }) sense( ({ 17 }) s ({ 18 }) ) ({ 19 }) for ({ 20 }) each ({ 21 }) polysemous ({ 22 }) word ({ 23 }) in ({ 24 }) a ({ 25 }) given ({ 26 }) text ({ 27 }) . ({ 28 }) 
# Sentence pair (339) source length 51 target length 34 alignment score : 5.62646e-28
It is considered to be an intermediate , but necessary step toward many NLP applications including machine translation and information extraction , which require the knowledge of word senses to achieve better performance . 
NULL ({ }) It ({ 1 }) is ({ 2 }) considered ({ 3 }) to ({ 4 }) be ({ 5 }) an ({ 6 }) intermediate ({ 7 }) , ({ 8 }) but ({ 9 }) necessary ({ 10 }) step ({ 11 }) for ({ }) many ({ 13 }) NLP ({ 14 }) applications ({ 15 }) , ({ }) including ({ 16 }) machine ({ 17 }) translation ({ 18 }) and ({ 19 }) information ({ 20 }) extraction ({ 21 }) , ({ 22 }) which[what ({ 12 }) does ({ }) " ({ }) which ({ }) " ({ }) refer ({ }) to ({ }) ? ({ }) Machine ({ }) translation ({ }) ? ({ }) Information ({ 33 }) extraction ({ }) , ({ }) or ({ }) both ({ }) ? ({ }) Clarify] ({ 23 }) require ({ 24 }) the ({ 25 }) knowledge ({ 26 }) of ({ 27 }) word ({ 28 }) senses ({ 29 }) to ({ 30 }) perform ({ 31 }) better ({ 32 }) . ({ 34 }) 
# Sentence pair (340) source length 23 target length 22 alignment score : 8.44735e-10
One major obstacle to large-scale and precise WSD is the data sparseness problem caused by the fine-grainedness of the sense distinction . 
NULL ({ 19 }) One ({ 1 }) major ({ 2 }) obstacle ({ 3 }) for ({ 4 }) large-scale ({ 5 }) and ({ 6 }) precise ({ 7 }) WSD ({ 8 }) is ({ 9 }) solving ({ 10 }) the ({ }) data ({ 11 }) sparseness ({ 12 }) problem ({ 13 }) caused ({ 14 }) by ({ 15 }) the ({ 16 }) fine-grained ({ }) nature ({ 17 }) of ({ 18 }) sense ({ 20 }) distinction ({ 21 }) . ({ 22 }) 
# Sentence pair (341) source length 17 target length 17 alignment score : 1.34745e-08
In order to resolve this problem , several semi-supervised approaches have been explored in recent years . 
NULL ({ 14 }) In ({ 1 }) recent ({ 15 }) years ({ 16 }) in ({ }) order ({ 2 }) to ({ 3 }) resolve ({ 4 }) this ({ 5 }) problem ({ 6 }) , ({ 7 }) several ({ 8 }) semi-supervised ({ 9 }) approaches ({ 10 }) have ({ 11 }) been ({ 12 }) explored ({ 13 }) . ({ 17 }) 
# Sentence pair (342) source length 28 target length 28 alignment score : 1.45143e-09
Some researchers have addressed directly the scarcity of the training data , and explored the methods to obtain more tagged instances , by the co-training and self-training . 
NULL ({ 24 }) Some ({ 1 }) researchers ({ 2 }) have ({ 3 }) addressed ({ 4 }) the ({ 6 }) scarcity ({ 7 }) of ({ 8 }) the ({ 9 }) training ({ 10 }) data ({ 11 }) directly ({ 5 }) , ({ 12 }) and ({ 13 }) have ({ }) explored ({ 14 }) the ({ 15 }) methods ({ 16 }) to ({ 17 }) obtain ({ 18 }) more ({ 19 }) tagged ({ 20 }) instances ({ 21 }) , ({ 22 }) by ({ 23 }) co-training ({ 25 }) and ({ 26 }) self-training ({ 27 }) . ({ 28 }) 
# Sentence pair (343) source length 18 target length 18 alignment score : 0.00146701
Other researchers have employed useful global information , such as the domain information extracted from unannotated corpora . 
NULL ({ }) Other ({ 1 }) researchers ({ 2 }) have ({ 3 }) employed ({ 4 }) useful ({ 5 }) global ({ 6 }) information ({ 7 }) , ({ 8 }) such ({ 9 }) as ({ 10 }) the ({ 11 }) domain ({ 12 }) information ({ 13 }) extracted ({ 14 }) from ({ 15 }) unannotated ({ 16 }) corpora ({ 17 }) . ({ 18 }) 
# Sentence pair (344) source length 31 target length 32 alignment score : 8.44941e-11
Although the use of the global information has succeeded in dramatically increase the performance of WSD , there are much room left to examine the effectiveness of local or syntactic information . 
NULL ({ 5 }) Although ({ 1 }) the ({ 2 }) use ({ 3 }) of ({ 4 }) global ({ 6 }) information ({ 7 }) has ({ 8 }) succeeded ({ 9 }) in ({ 10 }) dramatically ({ 11 }) increasing ({ 12 }) the ({ 13 }) performance ({ 14 }) of ({ 15 }) WSD ({ 16 }) , ({ 17 }) there ({ 18 }) is ({ 19 }) much ({ 20 }) room ({ 21 }) left ({ 22 }) to ({ 23 }) examine ({ 24 }) the ({ 25 }) effectiveness ({ 26 }) of ({ 27 }) local ({ 28 }) or ({ 29 }) syntactic ({ 30 }) information ({ 31 }) . ({ 32 }) 
# Sentence pair (345) source length 15 target length 15 alignment score : 5.21229e-06
One of such information yet to be explored is the interdependencies of word senses . 
NULL ({ 2 }) One ({ 1 }) such ({ 3 }) information ({ 4 }) yet ({ 5 }) to ({ 6 }) be ({ 7 }) explored ({ 8 }) , ({ }) is ({ 9 }) the ({ 10 }) interdependency ({ 11 }) of ({ 12 }) word ({ 13 }) senses ({ 14 }) . ({ 15 }) 
# Sentence pair (346) source length 47 target length 49 alignment score : 4.68461e-16
Although the use of local and syntactic information has been common in WSD , traditional approaches to WSD are based on the individual classification framework for each word , in which each word 's sense is treated independently , regardless of any interdependencies nor cooccurrences of word senses . 
NULL ({ 29 30 }) Although ({ 1 }) the ({ 2 }) use ({ 3 }) of ({ 4 }) local ({ 5 }) and ({ 6 }) syntactic ({ 7 }) information ({ 8 }) has ({ 9 }) been ({ 10 }) common ({ 11 }) in ({ 12 }) WSD ({ 13 }) , ({ 14 }) traditional ({ 15 }) approaches ({ 16 }) to ({ 17 }) WSD ({ 18 }) are ({ 19 }) based ({ 20 }) on ({ 21 }) the ({ 22 }) individual ({ 23 }) classification ({ 24 }) framework ({ 25 }) for ({ 26 }) each ({ 27 }) word ({ 28 }) ; ({ 31 }) each ({ 32 }) word ({ 33 }) 's ({ 34 }) sense ({ 35 }) is ({ 36 }) treated ({ 37 }) independently ({ 38 }) , ({ 39 }) regardless ({ 40 }) of ({ 41 }) any ({ 42 }) interdependencies ({ 43 }) or ({ }) cooccurrences ({ 44 45 }) of ({ 46 }) word ({ 47 }) senses ({ 48 }) . ({ 49 }) 
# Sentence pair (347) source length 16 target length 16 alignment score : 1.32242e-08
As a result , the resulting sense assignment may not semantically consistent over the sentence . 
NULL ({ 2 }) In ({ 1 }) turn ({ 3 }) , ({ 4 }) the ({ 5 }) resulting ({ 6 }) sense ({ 7 }) assignment ({ 8 }) may ({ 9 }) not ({ 10 }) be ({ }) semantically ({ 11 }) consistent ({ 12 }) over ({ 13 }) the ({ 14 }) sentence ({ 15 }) . ({ 16 }) 
# Sentence pair (348) source length 16 target length 15 alignment score : 0.000280396
To solve this problem is of great interest from both practical and theoretical perspectives . 
NULL ({ }) To ({ 1 }) solve ({ 2 }) this ({ 3 }) problem ({ 4 }) is ({ 5 }) of ({ 6 }) great ({ 7 }) interest ({ 8 }) from ({ 9 }) both ({ 10 }) a ({ }) practical ({ 11 }) and ({ 12 }) theoretical ({ 13 }) viewpoint ({ 14 }) . ({ 15 }) 
# Sentence pair (349) source length 19 target length 19 alignment score : 0.000830585
In this thesis , we present a WSD model that naturally handles all content words in a sentence . 
NULL ({ }) In ({ 1 }) this ({ 2 }) thesis ({ 3 }) , ({ 4 }) we ({ 5 }) present ({ 6 }) a ({ 7 }) WSD ({ 8 }) model ({ 9 }) that ({ 10 }) naturally ({ 11 }) handles ({ 12 }) all ({ 13 }) content ({ 14 }) words ({ 15 }) in ({ 16 }) a ({ 17 }) sentence ({ 18 }) . ({ 19 }) 
# Sentence pair (350) source length 44 target length 38 alignment score : 9.96151e-22
We focus on the use of the interdependency of word senses , so that we can directly address the issue of semantic ambiguity of a whole sentence arose from the interaction of each word 's sense ambiguity . 
NULL ({ 7 }) We ({ 1 }) focus ({ 2 }) on ({ 3 }) using ({ }) the ({ 4 }) interdependency ({ 5 8 }) of ({ 9 }) word ({ 10 }) senses ({ 11 }) , ({ 12 }) so ({ 13 }) that ({ 14 }) we ({ 15 }) can ({ 16 }) directly ({ 17 }) address ({ 18 }) the ({ 19 }) issue ({ 20 }) of ({ 21 }) semantic ({ 22 }) ambiguity ({ 23 }) in ({ 24 }) a ({ 25 }) whole ({ 26 }) sentence ({ 27 }) that ({ }) arose ({ 28 }) from ({ 29 }) the ({ 30 }) interaction ({ 31 }) of ({ 32 }) each ({ 33 }) word ({ 34 }) 's ({ 35 }) sense ({ 36 }) ambiguity ({ 37 }) . ({ 38 }) **[ ({ }) <- ({ 6 }) this ({ }) part ({ }) is ({ }) confusing ({ }) .] ({ }) 
# Sentence pair (351) source length 31 target length 31 alignment score : 1.37908e-16
Specifically , we assume that there exist strong sense dependencies between a syntactic head and its dependents in the dependency tree , rather than between neighboring words in the sentence . 
NULL ({ 6 28 }) Specifically ({ 1 }) , ({ 2 }) we ({ 3 }) assume ({ 4 }) that ({ 5 }) are ({ 7 }) strong ({ 8 }) sense ({ 9 }) dependencies ({ 10 }) between ({ 11 }) a ({ 12 }) syntactic ({ 13 }) head ({ 14 }) , ({ }) and ({ 15 }) its ({ 16 }) dependents ({ 17 }) in ({ 18 }) the ({ 19 }) dependency ({ 20 }) tree ({ 21 }) , ({ 22 }) rather ({ 23 }) than ({ 24 }) between ({ 25 }) neighboring ({ 26 }) words ({ 27 }) of ({ }) a ({ 29 }) sentence ({ 30 }) . ({ 31 }) 
# Sentence pair (352) source length 21 target length 20 alignment score : 2.3066e-05
We confirm the appropriateness of this assumption by showing the superiority of the tree-structured models over the linear-chain models . 
NULL ({ }) We ({ 1 }) confirm ({ 2 }) the ({ 3 }) validity ({ 4 }) of ({ 5 }) this ({ 6 }) assumption ({ 7 }) , ({ }) by ({ 8 }) showing ({ 9 }) the ({ 10 }) superiority ({ 11 }) of ({ 12 }) the ({ 13 }) tree-structured ({ 14 }) models ({ 15 }) over ({ 16 }) the ({ 17 }) linear-chain ({ 18 }) models ({ 19 }) . ({ 20 }) 
# Sentence pair (353) source length 15 target length 15 alignment score : 0.00735914
Furthermore , we combine these sense dependency features with various coarse-grained sense tag sets . 
NULL ({ }) Furthermore ({ 1 }) , ({ 2 }) we ({ 3 }) combine ({ 4 }) these ({ 5 }) sense ({ 6 }) dependency ({ 7 }) features ({ 8 }) with ({ 9 }) various ({ 10 }) coarse-grained ({ 11 }) sense ({ 12 }) tag ({ 13 }) sets ({ 14 }) . ({ 15 }) 
# Sentence pair (354) source length 30 target length 30 alignment score : 6.38611e-07
This is to relieve the data sparseness problem caused by the explosion of the number of features , which is roughly squared by the combination of two word senses . 
NULL ({ }) This ({ 1 }) is ({ 2 }) to ({ 3 }) relieve ({ 4 }) the ({ 5 }) data ({ 6 }) sparseness ({ 7 }) problem ({ 8 }) caused ({ 9 }) by ({ 10 }) the ({ 11 }) explosion ({ 12 }) in ({ 13 }) the ({ 14 }) number ({ 15 }) of ({ 16 }) features ({ 17 }) , ({ 18 }) which ({ 19 }) is ({ 20 }) roughly ({ 21 }) squared ({ 22 }) by ({ 23 }) the ({ 24 }) combination ({ 25 }) of ({ 26 }) two ({ 27 }) word ({ 28 }) senses ({ 29 }) . ({ 30 }) 
# Sentence pair (355) source length 29 target length 30 alignment score : 7.64036e-12
The combined features also enable our model to work even for those words that do not appear in the training data , which the traditional individual classifiers cannot handle . 
NULL ({ 12 24 }) The ({ 1 }) combined ({ 2 }) features ({ 3 }) also ({ 4 }) enable ({ 5 }) our ({ 6 }) model ({ 7 }) to ({ 8 }) work ({ 9 }) , ({ }) even ({ 10 }) for ({ 11 }) words ({ 13 }) that ({ 14 }) do ({ 15 }) not ({ 16 }) appear ({ 17 }) in ({ 18 }) the ({ 19 }) training ({ 20 }) data ({ 21 }) , ({ 22 }) which ({ 23 }) traditional ({ 25 }) individual ({ 26 }) classifiers ({ 27 }) cannot ({ 28 }) handle ({ 29 }) . ({ 30 }) 
# Sentence pair (356) source length 17 target length 17 alignment score : 0.00420252
As a machine learning method , we adopt the tree-structured conditional random fields ( T-CRFs ) . 
NULL ({ }) As ({ 1 }) a ({ 2 }) machine ({ 3 }) learning ({ 4 }) method ({ 5 }) , ({ 6 }) we ({ 7 }) adopt ({ 8 }) the ({ 9 }) tree-structured ({ 10 }) conditional ({ 11 }) random ({ 12 }) fields ({ 13 }) ( ({ 14 }) T-CRFs ({ 15 }) ) ({ 16 }) . ({ 17 }) 
# Sentence pair (357) source length 33 target length 31 alignment score : 1.27572e-07
We solve WSD as a labeling problem to a sentence described as a dependency tree , where the vertices correspond to words and the edges correspond to the sense dependencies . 
NULL ({ }) We ({ 1 }) solve ({ 2 }) WSD ({ 3 }) as ({ 4 }) a ({ 5 }) labeling ({ 6 }) problem ({ 7 }) to ({ 8 }) a ({ 9 }) sentence ({ 10 }) described ({ 11 }) as ({ 12 }) a ({ 13 }) dependency ({ 14 }) tree ({ 15 }) , ({ 16 }) where ({ 17 }) the ({ 18 }) vertices ({ 19 }) correspond ({ 20 }) to ({ 21 }) the ({ }) words ({ 22 }) , ({ }) and ({ 23 }) the ({ 24 }) edges ({ 25 }) correspond ({ 26 }) to ({ 27 }) the ({ 28 }) sense ({ 29 }) dependencies ({ 30 }) . ({ 31 }) 
# Sentence pair (358) source length 19 target length 19 alignment score : 0.00125437
In this model , the intensities of the sense dependencies are described as the weights of edge features . 
NULL ({ }) In ({ 1 }) this ({ 2 }) model ({ 3 }) , ({ 4 }) the ({ 5 }) intensities ({ 6 }) of ({ 7 }) the ({ 8 }) sense ({ 9 }) dependencies ({ 10 }) are ({ 11 }) described ({ 12 }) as ({ 13 }) the ({ 14 }) weights ({ 15 }) of ({ 16 }) edge ({ 17 }) features ({ 18 }) . ({ 19 }) 
# Sentence pair (359) source length 17 target length 17 alignment score : 1.72853e-05
T-CRFs also enable us to incorporate various sense tag sets all together in a simple framework . 
NULL ({ }) T-CRFs ({ 1 }) also ({ 2 }) enable ({ 3 }) us ({ 4 }) to ({ 5 }) incorporate ({ 6 }) various ({ 7 }) sense ({ 8 }) tag ({ 9 }) sets ({ 10 }) all ({ 11 }) together ({ 12 }) into ({ 13 }) a ({ 14 }) simple ({ 15 }) framework ({ 16 }) . ({ 17 }) 
# Sentence pair (360) source length 42 target length 42 alignment score : 1.47698e-07
In our experiments , three interesting results are found : the interdependency of word senses contribute to the improvement of WSD models , the combined features with coarse-grained sense tags work effectively , and the tree-structured model outperforms the linear-chain model . 
NULL ({ }) In ({ 1 }) our ({ 2 }) experiments ({ 3 }) , ({ 4 }) three ({ 5 }) interesting ({ 6 }) results ({ 7 }) are ({ 8 }) found ({ 9 }) : ({ 10 }) the ({ 11 }) interdependency ({ 12 }) of ({ 13 }) word ({ 14 }) senses ({ 15 }) contribute ({ 16 }) to ({ 17 }) the ({ 18 }) improvement ({ 19 }) of ({ 20 }) WSD ({ 21 }) models ({ 22 }) , ({ 23 }) the ({ 24 }) combined ({ 25 }) features ({ 26 }) with ({ 27 }) coarse-grained ({ 28 }) sense ({ 29 }) tags ({ 30 }) work ({ 31 }) effectively ({ 32 }) , ({ 33 }) and ({ 34 }) the ({ 35 }) tree-structured ({ 36 }) model ({ 37 }) outperforms ({ 38 }) the ({ 39 }) linear-chain ({ 40 }) model ({ 41 }) . ({ 42 }) 
# Sentence pair (361) source length 36 target length 35 alignment score : 1.17048e-06
These results are confirmed on three data sets ( the SemCor corpus and the Senseval-2 and -3 English all-words task test sets ) and on two sense inventories ( WordNet synsets and supersenses ) . 
NULL ({ }) These ({ 1 }) results ({ 2 }) are ({ 3 }) confirmed ({ 4 }) on ({ 5 }) three ({ 6 }) data ({ 7 }) sets ({ 8 }) ( ({ 9 }) the ({ 10 }) SemCor ({ 11 }) corpus ({ 12 }) and ({ 13 }) the ({ 14 }) Senseval-2 ({ 15 }) and ({ 16 }) -3 ({ 17 }) English ({ 18 }) all-words ({ 19 }) task ({ 20 }) test ({ 21 }) sets ({ 22 }) ) ({ 23 }) , ({ }) and ({ 24 }) on ({ 25 }) two ({ 26 }) sense ({ 27 }) inventories ({ 28 }) ( ({ 29 }) WordNet ({ 30 }) synsets ({ 31 }) and ({ 32 }) supersenses ({ 33 }) ) ({ 34 }) . ({ 35 }) 
# Sentence pair (362) source length 13 target length 13 alignment score : 1.14027e-05
Our final model is shown to perform comparably with state-of-the-art WSD systems . 
NULL ({ }) Our ({ 1 }) final ({ 2 }) model ({ 3 }) is ({ 4 }) shown ({ 5 }) to ({ 6 }) perform ({ 7 }) comparably ({ 8 }) to ({ 9 }) state-of-the-art ({ 10 }) WSD ({ 11 }) systems ({ 12 }) . ({ 13 }) 
# Sentence pair (363) source length 22 target length 22 alignment score : 0.000436618
The rest of the paper is organized as follows : In Section 2 , we describe background topics related to WSD . 
NULL ({ }) The ({ 1 }) rest ({ 2 }) of ({ 3 }) the ({ 4 }) paper ({ 5 }) is ({ 6 }) organized ({ 7 }) as ({ 8 }) follows ({ 9 }) : ({ 10 }) In ({ 11 }) Section ({ 12 }) 2 ({ 13 }) , ({ 14 }) we ({ 15 }) describe ({ 16 }) background ({ 17 }) topics ({ 18 }) related ({ 19 }) to ({ 20 }) WSD ({ 21 }) . ({ 22 }) 
# Sentence pair (364) source length 15 target length 15 alignment score : 0.00337492
In Section 3 , we describe current problems of WSD , and related works . 
NULL ({ }) In ({ 1 }) Section ({ 2 }) 3 ({ 3 }) , ({ 4 }) we ({ 5 }) describe ({ 6 }) current ({ 7 }) problems ({ 8 }) of ({ 9 }) WSD ({ 10 }) , ({ 11 }) and ({ 12 }) related ({ 13 }) works ({ 14 }) . ({ 15 }) 
# Sentence pair (365) source length 23 target length 20 alignment score : 1.39632e-07
In Section 4 , we describe our model with intuitive examples , and the machine learning method we use . 
NULL ({ }) In ({ 1 }) Section ({ 2 }) 4 ({ 3 }) , ({ 4 }) we ({ 5 }) describe ({ 6 }) our ({ 7 }) model ({ 8 }) with ({ 9 }) intuitive ({ 10 }) examples ({ 11 }) , ({ 12 }) and ({ 13 }) we ({ }) describe ({ }) the ({ 14 }) machine ({ 15 }) learning ({ 16 }) method ({ 17 }) that ({ }) we ({ 18 }) use ({ 19 }) . ({ 20 }) 
# Sentence pair (366) source length 31 target length 30 alignment score : 1.28683e-09
In Section 5 , 6 , and 7 , we present our experimental setup and results , and an in-depth analysis on the contribution of the sense dependency features . 
NULL ({ 15 }) In ({ 1 }) Section ({ 2 }) 5 ({ 3 }) , ({ 4 }) 6 ({ 5 }) , ({ 6 }) and ({ 7 }) 7 ({ 8 }) , ({ 9 }) we ({ 10 }) present ({ 11 }) our ({ 12 }) experimental ({ 13 }) setup ({ 14 }) , ({ }) the ({ }) results ({ 16 }) , ({ 17 }) and ({ 18 }) an ({ 19 }) in-depth ({ 20 }) analysis ({ 21 }) on ({ 22 }) the ({ 23 }) contribution ({ 24 }) of ({ 25 }) the ({ 26 }) sense ({ 27 }) dependency ({ 28 }) features ({ 29 }) . ({ 30 }) 
# Sentence pair (367) source length 12 target length 11 alignment score : 0.00136343
Finally , in Section 8 , we present concluding remarks . 
NULL ({ }) Finally ({ 1 }) , ({ 2 }) in ({ 3 }) Section ({ 4 }) 8 ({ 5 }) , ({ 6 }) we ({ 7 }) present ({ 8 }) our ({ }) concluding ({ 9 }) remarks ({ 10 }) . ({ 11 }) 
# Sentence pair (368) source length 19 target length 20 alignment score : 1.52658e-07
The WordNet is a broad-coverage machine-readable dictionary ( MRD ) for English , which contains about 150 ,000 words . 
NULL ({ 14 }) The ({ 1 }) WordNet ({ 2 }) is ({ 3 }) a ({ 4 }) broad-coverage ({ 5 }) machine-readable ({ 6 }) dictionary ({ 7 }) ( ({ 8 }) MRD ({ 9 }) ) ({ 10 }) for ({ 11 }) English ({ 12 }) , ({ 13 }) containing ({ 15 }) about ({ 16 }) 150 ({ 17 }) ,000 ({ 18 }) words ({ 19 }) . ({ 20 }) 
# Sentence pair (369) source length 31 target length 31 alignment score : 6.94574e-15
It also serves as an ontology , in which various kinds of meta data , relations among words and senses , and well-organized hierarchical classification of word senses are defined . 
NULL ({ 7 8 9 }) WordNet ({ 1 }) also ({ 2 }) serves ({ 3 }) as ({ 4 }) an ({ 5 }) ontology ({ 6 }) of ({ }) various ({ 10 }) kinds ({ 11 }) of ({ 12 }) meta ({ 13 }) data ({ 14 }) , ({ 15 }) relations ({ 16 }) among ({ 17 }) words ({ 18 }) and ({ 19 }) senses ({ 20 }) , ({ 21 }) and ({ 22 }) a ({ }) well-organized ({ 23 }) hierarchical ({ 24 }) classification ({ 25 }) of ({ 26 }) word ({ 27 }) senses ({ 28 }) that ({ }) are ({ 29 }) defined ({ 30 }) . ({ 31 }) 
# Sentence pair (370) source length 17 target length 17 alignment score : 0.00143182
In this paper , we always refer to the WordNet version 2 .0 unless otherwise noted . 
NULL ({ }) In ({ 1 }) this ({ 2 }) paper ({ 3 }) , ({ 4 }) we ({ 5 }) always ({ 6 }) refer ({ 7 }) to ({ 8 }) the ({ 9 }) WordNet ({ 10 }) version ({ 11 }) 2 ({ 12 }) .0 ({ 13 }) unless ({ 14 }) otherwise ({ 15 }) noted ({ 16 }) . ({ 17 }) 
# Sentence pair (371) source length 16 target length 16 alignment score : 0.00435469
The statistical information of the WordNet 2 .0 is shown in Table 1 and 2 . 
NULL ({ }) The ({ 1 }) statistical ({ 2 }) information ({ 3 }) of ({ 4 }) the ({ 5 }) WordNet ({ 6 }) 2 ({ 7 }) .0 ({ 8 }) is ({ 9 }) shown ({ 10 }) in ({ 11 }) Table ({ 12 }) 1 ({ 13 }) and ({ 14 }) 2 ({ 15 }) . ({ 16 }) 
# Sentence pair (372) source length 27 target length 27 alignment score : 4.43256e-16
In the WordNet , nouns and verbs are organized in hierarchical structures with IS-A ( hypernym-hyponym ) relationships among words , as shown in Figure 1 . 
NULL ({ 2 22 }) As ({ 1 }) shown ({ 23 }) in ({ 24 }) Figure ({ 25 }) 1 ({ 26 }) , ({ }) in ({ }) WordNet ({ 3 }) , ({ 4 }) nouns ({ 5 }) and ({ 6 }) verbs ({ 7 }) are ({ 8 }) organized ({ 9 }) into ({ 10 }) hierarchical ({ 11 }) structures ({ 12 }) with ({ 13 }) IS-A ({ 14 }) ( ({ 15 }) hypernym-hyponym ({ 16 }) ) ({ 17 }) relationships ({ 18 }) among ({ 19 }) words ({ 20 }) , ({ 21 }) . ({ 27 }) 
# Sentence pair (373) source length 20 target length 17 alignment score : 6.77798e-07
Nouns have a far deeper structure than verbs , while that of verbs is transversely developed . 
NULL ({ }) Nouns ({ 1 }) have ({ 2 }) a ({ 3 }) far ({ 4 }) deeper ({ 5 }) structure ({ 6 }) than ({ 7 }) verbs ({ 8 }) do ({ }) , ({ 9 }) while ({ 10 }) that ({ 11 }) the ({ }) structure ({ }) of ({ 12 }) verbs ({ 13 }) is ({ 14 }) transversely ({ 15 }) developed ({ 16 }) . ({ 17 }) 
# Sentence pair (374) source length 27 target length 21 alignment score : 3.82379e-10
All nouns and verbs except some top-level concepts are classified into primitive groups called supersenses , which we describe later . 
NULL ({ }) All ({ 1 }) nouns ({ 2 }) and ({ 3 }) verbs ({ 4 }) , ({ }) with ({ }) the ({ }) exception ({ 5 }) of ({ }) some ({ 6 }) top-level ({ 7 }) concepts ({ 8 }) , ({ }) are ({ 9 }) classified ({ 10 }) into ({ 11 }) primitive ({ 12 }) groups ({ 13 }) called ({ 14 }) supersenses ({ 15 }) , ({ 16 }) which ({ 17 }) we ({ 18 }) will ({ }) describe ({ 19 }) later ({ 20 }) . ({ 21 }) 
# Sentence pair (375) source length 50 target length 50 alignment score : 1.47757e-13
Figure 1 shows the WordNet hierarchical structure for the first sense ( financial bank ) of a noun bank , where each line shows a synset with the list of words headed by its supersense label , and an arrow denotes that two synsets are in an IS-A relation . 
NULL ({ 37 }) Figure ({ 1 }) 1 ({ 2 }) shows ({ 3 }) the ({ 4 }) WordNet ({ 5 }) hierarchical ({ 6 }) structure ({ 7 }) for ({ 8 }) the ({ 9 }) first ({ 10 }) sense ({ 11 }) ( ({ 12 }) financial ({ 13 }) bank ({ 14 }) ) ({ 15 }) of ({ 16 }) a ({ 17 }) noun ({ 18 }) bank ({ 19 }) , ({ 20 }) where ({ 21 }) each ({ 22 }) line ({ 23 }) indicates ({ 24 }) a ({ 25 }) synset ({ 26 }) with ({ 27 }) the ({ 28 }) list ({ 29 }) of ({ 30 }) words ({ 31 }) headed ({ 32 }) by ({ 33 }) its ({ 34 }) supersense ({ 35 }) label ({ 36 }) ; ({ 38 }) an ({ 39 }) arrow ({ 40 }) denotes ({ 41 }) that ({ 42 }) the ({ }) two ({ 43 }) synsets ({ 44 }) are ({ 45 }) in ({ 46 }) an ({ 47 }) IS-A ({ 48 }) relation ({ 49 }) . ({ 50 }) 
# Sentence pair (376) source length 18 target length 17 alignment score : 3.72752e-05
The synset {group#1 , grouping#1} is a broad semantic category that governs the supersense noun group . 
NULL ({ }) The ({ 1 }) synset ({ 2 }) {group#1 ({ 3 }) , ({ 4 }) grouping#1} ({ 5 }) is ({ 6 }) a ({ 7 }) broad ({ 8 }) semantic ({ 9 }) category ({ 10 }) that ({ 11 }) governs ({ 12 }) the ({ 13 }) supersense ({ 14 }) group ({ }) noun ({ 15 }) .group ({ 16 }) . ({ 17 }) 
# Sentence pair (377) source length 36 target length 36 alignment score : 4.41165e-07
The lower synsets {social group#1} , {organization#1 , organisation#3} , and {institution#1 , establishment#2} are the more specific synsets , which in this paper we call the first , second , and third general synsets . 
NULL ({ }) The ({ 1 }) lower ({ 2 }) synsets ({ 3 }) {social ({ 4 }) group#1} ({ 5 }) , ({ 6 }) {organization#1 ({ 7 }) , ({ 8 }) organisation#3} ({ 9 }) , ({ 10 }) and ({ 11 }) {institution#1 ({ 12 }) , ({ 13 }) establishment#2} ({ 14 }) are ({ 15 }) the ({ 16 }) more ({ 17 }) specific ({ 18 }) synsets ({ 19 }) , ({ 20 }) which ({ 21 }) in ({ 22 }) this ({ 23 }) paper ({ 24 }) we ({ 25 }) call ({ 26 }) the ({ 27 }) first ({ 28 }) , ({ 29 }) second ({ 30 }) , ({ 31 }) and ({ 32 }) third ({ 33 }) general ({ 34 }) synsets ({ 35 }) . ({ 36 }) 
# Sentence pair (378) source length 30 target length 30 alignment score : 7.62045e-07
Note that since the organizations of adjectives and adverbs are far different from those of nouns and verbs , we use this hierarchical information for only nouns and verbs . 
NULL ({ }) Note ({ 1 }) that ({ 2 }) since ({ 3 }) the ({ 4 }) organizations ({ 5 }) of ({ 6 }) adjectives ({ 7 }) and ({ 8 }) adverbs ({ 9 }) are ({ 10 }) very ({ 11 }) different ({ 12 }) from ({ 13 }) those ({ 14 }) of ({ 15 }) nouns ({ 16 }) and ({ 17 }) verbs ({ 18 }) , ({ 19 }) we ({ 20 }) use ({ 21 }) this ({ 22 }) hierarchical ({ 23 }) information ({ 24 }) for ({ 25 }) only ({ 26 }) nouns ({ 27 }) and ({ 28 }) verbs ({ 29 }) . ({ 30 }) 
# Sentence pair (379) source length 20 target length 20 alignment score : 0.000503413
A supersense is a coarse-grained semantic category , with which each noun or verb synset in WordNet is associated . 
NULL ({ }) A ({ 1 }) supersense ({ 2 }) is ({ 3 }) a ({ 4 }) coarse-grained ({ 5 }) semantic ({ 6 }) category ({ 7 }) , ({ 8 }) with ({ 9 }) which ({ 10 }) each ({ 11 }) noun ({ 12 }) or ({ 13 }) verb ({ 14 }) synset ({ 15 }) in ({ 16 }) WordNet ({ 17 }) is ({ 18 }) associated ({ 19 }) . ({ 20 }) 
# Sentence pair (380) source length 14 target length 14 alignment score : 0.00341311
Noun and verb synsets are associated with 26 and 15 categories , respectively . 
NULL ({ }) Noun ({ 1 }) and ({ 2 }) verb ({ 3 }) synsets ({ 4 }) are ({ 5 }) associated ({ 6 }) with ({ 7 }) 26 ({ 8 }) and ({ 9 }) 15 ({ 10 }) categories ({ 11 }) , ({ 12 }) respectively ({ 13 }) . ({ 14 }) 
# Sentence pair (381) source length 25 target length 25 alignment score : 0.000120759
The coarse-grained sets of sense labels are easily recognizable , and enable us to build a high-performance and robust tagger with small training data . 
NULL ({ }) The ({ 1 }) coarse-grained ({ 2 }) sets ({ 3 }) of ({ 4 }) sense ({ 5 }) labels ({ 6 }) are ({ 7 }) easily ({ 8 }) recognizable ({ 9 }) , ({ 10 }) and ({ 11 }) enable ({ 12 }) us ({ 13 }) to ({ 14 }) build ({ 15 }) a ({ 16 }) high-performance ({ 17 }) and ({ 18 }) robust ({ 19 }) tagger ({ 20 }) with ({ 21 }) small ({ 22 }) training ({ 23 }) data ({ 24 }) . ({ 25 }) 
# Sentence pair (382) source length 35 target length 30 alignment score : 4.58919e-12
Hence , we can expect them to act as a good smoothing feature for WSD , which would make up for the sparseness of features associated with finer-grained senses . 
NULL ({ }) Hence ({ 1 }) , ({ 2 }) we ({ 3 }) can ({ 4 }) expect ({ 5 }) them ({ 6 }) to ({ 7 }) act ({ 8 }) as ({ 9 }) a ({ 10 }) good ({ 11 }) smoothing ({ 12 }) feature ({ 13 }) for ({ 14 }) WSD ({ 15 }) , ({ 16 }) which ({ 17 }) would ({ 18 }) make ({ 19 }) up ({ 20 }) for ({ 21 }) the ({ }) problem ({ }) of ({ }) the ({ 22 }) sparseness ({ 23 }) of ({ 24 }) features ({ 25 }) , ({ }) commonly ({ }) associated ({ 26 }) with ({ 27 }) finer-grained ({ 28 }) senses ({ 29 }) . ({ 30 }) 
# Sentence pair (383) source length 21 target length 21 alignment score : 9.58174e-05
The effectiveness of using supersenses for WSD has recently been shown by several researchers ( e.g. , , and ) . 
NULL ({ }) The ({ 1 }) effectiveness ({ 2 }) of ({ 3 }) using ({ 4 }) supersenses ({ 5 }) for ({ 6 }) WSD ({ 7 }) has ({ 8 }) recently ({ 9 }) been ({ 10 }) shown ({ 11 }) by ({ 12 }) several ({ 13 }) researchers ({ 14 }) ( ({ 15 }) e.g. ({ 16 }) , ({ 17 }) , ({ 18 }) and ({ 19 }) ) ({ 20 }) . ({ 21 }) 
# Sentence pair (384) source length 8 target length 8 alignment score : 0.0301673
The lists of supersenses are shown below . 
NULL ({ }) The ({ 1 }) lists ({ 2 }) of ({ 3 }) supersenses ({ 4 }) are ({ 5 }) shown ({ 6 }) below ({ 7 }) . ({ 8 }) 
# Sentence pair (385) source length 55 target length 55 alignment score : 4.65433e-11
- Noun supersense : act , animal , artifact , attribute , body , cognition , communication , event , feeling , food , group , location , motive , object , quantity , phenomenon , plant , possession , process , person , relation , shape , state , substance , time , Tops 
NULL ({ }) - ({ 1 }) Noun ({ 2 }) supersense ({ 3 }) : ({ 4 }) act ({ 5 }) , ({ 6 }) animal ({ 7 }) , ({ 8 }) artifact ({ 9 }) , ({ 10 }) attribute ({ 11 }) , ({ 12 }) body ({ 13 }) , ({ 14 }) cognition ({ 15 }) , ({ 16 }) communication ({ 17 }) , ({ 18 }) event ({ 19 }) , ({ 20 }) feeling ({ 21 }) , ({ 22 }) food ({ 23 }) , ({ 24 }) group ({ 25 }) , ({ 26 }) location ({ 27 }) , ({ 28 }) motive ({ 29 }) , ({ 30 }) object ({ 31 }) , ({ 32 }) quantity ({ 33 }) , ({ 34 }) phenomenon ({ 35 }) , ({ 36 }) plant ({ 37 }) , ({ 38 }) possession ({ 39 }) , ({ 40 }) process ({ 41 }) , ({ 42 }) person ({ 43 }) , ({ 44 }) relation ({ 45 }) , ({ 46 }) shape ({ 47 }) , ({ 48 }) state ({ 49 }) , ({ 50 }) substance ({ 51 }) , ({ 52 }) time ({ 53 }) , ({ 54 }) Tops ({ 55 }) 
# Sentence pair (386) source length 31 target length 31 alignment score : 1.6401e-05
- Verb supersense : body , change , cognition , communication , competition , consumption , contact , creation , emotion , perception , possession , social , stative , weather 
NULL ({ }) - ({ 1 }) Verb ({ 2 }) supersense ({ 3 }) : ({ 4 }) body ({ 5 }) , ({ 6 }) change ({ 7 }) , ({ 8 }) cognition ({ 9 }) , ({ 10 }) communication ({ 11 }) , ({ 12 }) competition ({ 13 }) , ({ 14 }) consumption ({ 15 }) , ({ 16 }) contact ({ 17 }) , ({ 18 }) creation ({ 19 }) , ({ 20 }) emotion ({ 21 }) , ({ 22 }) perception ({ 23 }) , ({ 24 }) possession ({ 25 }) , ({ 26 }) social ({ 27 }) , ({ 28 }) stative ({ 29 }) , ({ 30 }) weather ({ 31 }) 
# Sentence pair (387) source length 23 target length 23 alignment score : 5.31336e-10
Since the data sparsity has been a significant problem in WSD , the sense frequency information is necessary to achieve good performance . 
NULL ({ 2 }) Since ({ 1 }) data ({ 3 }) sparsity ({ 4 }) has ({ 5 }) been ({ 6 }) a ({ 7 }) significant ({ 8 }) issue ({ 9 }) in ({ 10 }) WSD ({ 11 }) , ({ 12 }) the ({ 13 }) sense ({ 14 }) frequency ({ 15 }) information ({ 16 }) is ({ 17 }) necessary ({ 18 }) in ({ 19 }) achieving ({ 20 }) a ({ }) good ({ 21 }) performance ({ 22 }) . ({ 23 }) 
# Sentence pair (388) source length 13 target length 14 alignment score : 0.00012188
In this section , we introduce two kinds of the sense frequency information . 
NULL ({ 10 }) In ({ 1 }) this ({ 2 }) section ({ 3 }) , ({ 4 }) we ({ 5 }) introduce ({ 6 }) two ({ 7 }) kinds ({ 8 }) of ({ 9 }) sense ({ 11 }) frequency ({ 12 }) information ({ 13 }) . ({ 14 }) 
# Sentence pair (389) source length 16 target length 16 alignment score : 0.00276548
A sense ranking is the ranking of a sense of a word in the WordNet . 
NULL ({ }) A ({ 1 }) sense ({ 2 }) ranking ({ 3 }) is ({ 4 }) the ({ 5 }) ranking ({ 6 }) of ({ 7 }) a ({ 8 }) sense ({ 9 }) of ({ 10 }) a ({ 11 }) word ({ 12 }) in ({ 13 }) the ({ 14 }) WordNet ({ 15 }) . ({ 16 }) 
# Sentence pair (390) source length 27 target length 26 alignment score : 8.26072e-06
Since senses of a word are ordered according to frequency , the sense ranking acts as a useful feature offering a preference for frequent senses . 
NULL ({ }) Since ({ 1 }) senses ({ 2 }) of ({ 3 }) a ({ 4 }) word ({ 5 }) are ({ 6 }) ordered ({ 7 }) according ({ 8 }) to ({ 9 }) frequency ({ 10 }) , ({ 11 }) the ({ 12 }) sense ({ 13 }) ranking ({ 14 }) acts ({ 15 }) as ({ 16 }) a ({ 17 }) useful ({ 18 }) feature ({ 19 }) that ({ }) offers ({ 20 }) a ({ 21 }) preference ({ 22 }) for ({ 23 }) frequent ({ 24 }) senses ({ 25 }) . ({ 26 }) 
# Sentence pair (391) source length 32 target length 32 alignment score : 2.29188e-06
It is also important as a back-off feature , which enables our model to output the first ( most frequent ) sense when no other features are active for that word . 
NULL ({ }) It ({ 1 }) is ({ 2 }) also ({ 3 }) important ({ 4 }) as ({ 5 }) a ({ 6 }) back-off ({ 7 }) feature ({ 8 }) , ({ 9 }) which ({ 10 }) enables ({ 11 }) our ({ 12 }) model ({ 13 }) to ({ 14 }) output ({ 15 }) the ({ 16 }) first ({ 17 }) ( ({ 18 }) most ({ 19 }) frequent ({ 20 }) ) ({ 21 }) sense ({ 22 }) when ({ 23 }) no ({ 24 }) other ({ 25 }) features ({ 26 }) are ({ 27 }) active ({ 28 }) for ({ 29 }) that ({ 30 }) word ({ 31 }) . ({ 32 }) 
# Sentence pair (392) source length 25 target length 26 alignment score : 3.42241e-13
The first sense classifier is known as a strong baseline in WSD , which can be even considered to be a good alternative to WSD . 
NULL ({ 19 }) The ({ 1 }) first ({ 2 }) sense ({ 3 }) classifier ({ 4 }) is ({ 5 }) known ({ 6 }) as ({ 7 }) a ({ 8 }) strong ({ 9 }) baseline ({ 10 }) in ({ 11 }) WSD ({ 12 }) , ({ 13 }) which ({ 14 }) can ({ 15 }) even ({ 17 }) be ({ 16 }) considered ({ 18 }) as ({ 20 }) a ({ 21 }) good ({ 22 }) alternative ({ 23 }) to ({ 24 }) WSD ({ 25 }) . ({ 26 }) 
# Sentence pair (393) source length 32 target length 32 alignment score : 7.03083e-06
In our experiment , our first sense classifier achieved the accuracies 65 .3% for the Senseval-2 English all-words task data , and 63 .4% for the Senseval-3 English all-words task data . 
NULL ({ }) In ({ 1 }) our ({ 2 }) experiment ({ 3 }) , ({ 4 }) our ({ 5 }) first ({ 6 }) sense ({ 7 }) classifier ({ 8 }) achieved ({ 9 }) the ({ 10 }) accuracies ({ 11 }) 65 ({ 12 }) .3% ({ 13 }) for ({ 14 }) the ({ 15 }) Senseval-2 ({ 16 }) English ({ 17 }) all-words ({ 18 }) task ({ 19 }) data ({ 20 }) , ({ 21 }) and ({ 22 }) 63 ({ 23 }) .4% ({ 24 }) for ({ 25 }) the ({ 26 }) Senseval-3 ({ 27 }) English ({ 28 }) all-words ({ 29 }) task ({ 30 }) data ({ 31 }) . ({ 32 }) 
# Sentence pair (394) source length 40 target length 40 alignment score : 2.79234e-07
Since the sense ranking in the WordNet is based on the word frequency in the SemCor , this baseline performs far better on the SemCor : 75 .9% for the brown1 section and 74 .3% for the brown2 section . 
NULL ({ }) Since ({ 1 }) the ({ 2 }) sense ({ 3 }) ranking ({ 4 }) in ({ 5 }) the ({ 6 }) WordNet ({ 7 }) is ({ 8 }) based ({ 9 }) on ({ 10 }) the ({ 11 }) word ({ 12 }) frequency ({ 13 }) in ({ 14 }) the ({ 15 }) SemCor ({ 16 }) , ({ 17 }) this ({ 18 }) baseline ({ 19 }) performs ({ 20 }) far ({ 21 }) better ({ 22 }) on ({ 23 }) the ({ 24 }) SemCor ({ 25 }) : ({ 26 }) 75 ({ 27 }) .9% ({ 28 }) for ({ 29 }) the ({ 30 }) brown1 ({ 31 }) section ({ 32 }) and ({ 33 }) 74 ({ 34 }) .3% ({ 35 }) for ({ 36 }) the ({ 37 }) brown2 ({ 38 }) section ({ 39 }) . ({ 40 }) 
# Sentence pair (395) source length 16 target length 16 alignment score : 0.00326355
Alternatively , we can consider incorporating the first sense of each word as a feature . 
NULL ({ }) Alternatively ({ 1 }) , ({ 2 }) we ({ 3 }) can ({ 4 }) consider ({ 5 }) incorporating ({ 6 }) the ({ 7 }) first ({ 8 }) sense ({ 9 }) of ({ 10 }) each ({ 11 }) word ({ 12 }) as ({ 13 }) a ({ 14 }) feature ({ 15 }) . ({ 16 }) 
# Sentence pair (396) source length 29 target length 29 alignment score : 1.20792e-05
Instead of uniformly predicting the distribution of sense frequencies according to their sense ranking , it can capture the conditional probability of each sense over the first sense . 
NULL ({ }) Instead ({ 1 }) of ({ 2 }) uniformly ({ 3 }) predicting ({ 4 }) the ({ 5 }) distribution ({ 6 }) of ({ 7 }) sense ({ 8 }) frequencies ({ 9 }) according ({ 10 }) to ({ 11 }) their ({ 12 }) sense ({ 13 }) ranking ({ 14 }) , ({ 15 }) it ({ 16 }) can ({ 17 }) capture ({ 18 }) the ({ 19 }) conditional ({ 20 }) probability ({ 21 }) of ({ 22 }) each ({ 23 }) sense ({ 24 }) over ({ 25 }) the ({ 26 }) first ({ 27 }) sense ({ 28 }) . ({ 29 }) 
# Sentence pair (397) source length 25 target length 24 alignment score : 5.4687e-13
It is considered to be a good feature that reflects the sense frequency information when sufficient training data is available for every sense . 
NULL ({ }) When ({ 1 }) sufficient ({ 16 }) training ({ 17 }) data ({ 18 }) is ({ 19 }) available ({ 20 }) for ({ 21 }) every ({ 22 }) sense ({ 23 }) this ({ }) method ({ 15 }) is ({ 2 }) considered ({ 3 }) to ({ 4 }) be ({ 5 }) a ({ 6 }) good ({ 7 }) feature ({ 8 }) that ({ 9 }) reflects ({ 10 }) the ({ 11 }) sense ({ 12 }) frequency ({ 13 }) information ({ 14 }) . ({ 24 }) 
# Sentence pair (398) source length 22 target length 21 alignment score : 4.81863e-07
For this reason , we use this first sense feature instead of the ranking feature , for the supersense-based evaluation . 
NULL ({ }) For ({ 1 }) such ({ 2 }) a ({ }) reason ({ 3 }) , ({ 4 }) we ({ 5 }) use ({ 6 }) this ({ 7 }) first ({ 8 }) sense ({ 9 }) feature ({ 10 }) instead ({ 11 }) of ({ 12 }) the ({ 13 }) ranking ({ 14 }) feature ({ 15 }) , ({ 16 }) for ({ 17 }) the ({ 18 }) supersense-based ({ 19 }) evaluation ({ 20 }) . ({ 21 }) 
# Sentence pair (399) source length 16 target length 16 alignment score : 0.00121036
For the unsupervised WSD , the use of sense dependencies has been a common method . 
NULL ({ }) For ({ 1 }) the ({ 2 }) unsupervised ({ 3 }) WSD ({ 4 }) , ({ 5 }) the ({ 6 }) use ({ 7 }) of ({ 8 }) sense ({ 9 }) dependencies ({ 10 }) has ({ 11 }) been ({ 12 }) a ({ 13 }) common ({ 14 }) method ({ 15 }) . ({ 16 }) 
# Sentence pair (400) source length 22 target length 22 alignment score : 1.0643e-09
introduces an unsupervised graph-based algorithm , and showed a significant superiority of the sequence labeling model over the individual label assignment . 
NULL ({ }) introduces ({ 1 }) an ({ 2 }) unsupervised ({ 3 }) graph-based ({ 4 }) algorithm ({ 5 }) , ({ 6 }) and ({ 7 }) shows ({ 8 }) a ({ 9 }) significant ({ 10 }) improvement ({ 11 }) over ({ 12 }) the ({ 13 }) sequence ({ 14 }) labeling ({ 15 }) model ({ 16 }) over ({ 17 }) the ({ 18 }) individual ({ 19 }) label ({ 20 }) assignment ({ 21 }) . ({ 22 }) 
# Sentence pair (401) source length 28 target length 26 alignment score : 6.6214e-07
built a model based on various word semantic similarity measures and graph centrality algorithms , which also used the graph structure incorporating the word-sense dependencies . 
NULL ({ }) built ({ 1 }) a ({ 2 }) model ({ 3 }) based ({ 4 }) on ({ 5 }) various ({ 6 }) word ({ 7 }) semantic ({ 8 }) similarity ({ 9 }) measures ({ 10 }) , ({ }) and ({ 11 }) graph ({ 12 }) centrality ({ 13 }) algorithms ({ 14 }) , ({ 15 }) which ({ 16 }) also ({ 17 }) used ({ 18 }) the ({ 19 }) graph ({ 20 }) structure ({ 21 }) that ({ }) incorporates ({ 22 }) the ({ 23 }) word-sense ({ 24 }) dependencies ({ 25 }) . ({ 26 }) 
# Sentence pair (402) source length 17 target length 18 alignment score : 1.12587e-05
Thus , the effectiveness of sense dependencies for the unsupervised WSD has been shown by several researches . 
NULL ({ 9 }) Thus ({ 1 }) , ({ 2 }) the ({ 3 }) effectiveness ({ 4 }) of ({ 5 }) sense ({ 6 }) dependencies ({ 7 }) for ({ 8 }) unsupervised ({ 10 }) WSD ({ 11 }) has ({ 12 }) been ({ 13 }) shown ({ 14 }) by ({ 15 }) several ({ 16 }) researches ({ 17 }) . ({ 18 }) 
# Sentence pair (403) source length 21 target length 23 alignment score : 1.2134e-08
On the other hand , the traditional approach to the supervised WSD is to solve an independent classification problem for each word . 
NULL ({ 10 }) On ({ 1 }) the ({ 2 }) contrary ({ 3 4 }) , ({ 5 }) the ({ 6 }) traditional ({ 7 }) approach ({ 8 }) to ({ 9 }) supervised ({ 11 }) WSD ({ 12 }) is ({ 13 }) to ({ 14 }) solve ({ 15 }) an ({ 16 }) independent ({ 17 }) classification ({ 18 }) problem ({ 19 }) for ({ 20 }) each ({ 21 }) word ({ 22 }) . ({ 23 }) 
# Sentence pair (404) source length 18 target length 19 alignment score : 7.12983e-06
This approach has been developed along with the researches based on the lexical sample task in the Sensevals . 
NULL ({ 8 }) This ({ 1 }) approach ({ 2 }) has ({ 3 }) been ({ 4 }) developed ({ 5 }) along ({ 6 }) with ({ 7 }) research ({ 9 }) based ({ 10 }) on ({ 11 }) the ({ 12 }) lexical ({ 13 }) sample ({ 14 }) task ({ 15 }) in ({ 16 }) the ({ 17 }) Sensevals ({ 18 }) . ({ 19 }) 
# Sentence pair (405) source length 28 target length 30 alignment score : 2.53305e-15
However , as we described in Section 1 , this approach cannot deal with the interdependencies among word senses , and may output a semantically inconsistent assignment of senses . 
NULL ({ 4 }) However ({ 1 }) , ({ 2 }) as ({ 3 }) described ({ 5 }) in ({ 6 }) Section ({ 7 }) 1 ({ 8 }) , ({ 9 }) this ({ 10 }) approach ({ 11 }) cannot ({ 12 }) handle ({ 13 14 }) the ({ 15 }) interdependencies ({ 16 }) among ({ 17 }) word ({ 18 }) senses ({ 19 }) , ({ 20 }) and ({ 21 }) may ({ 22 }) output ({ 23 }) a ({ 24 }) semantically ({ 25 }) inconsistent ({ 26 }) assignment ({ 27 }) of ({ 28 }) senses ({ 29 }) . ({ 30 }) 
# Sentence pair (406) source length 22 target length 22 alignment score : 6.52962e-06
Recently , with the growing interest on the all-words task , a few supervised WSD systems have incorporated the sense dependencies . 
NULL ({ }) Recently ({ 1 }) , ({ 2 }) with ({ 3 }) the ({ 4 }) growing ({ 5 }) interest ({ 6 }) in ({ 7 }) the ({ 8 }) all-words ({ 9 }) task ({ 10 }) , ({ 11 }) a ({ 12 }) few ({ 13 }) supervised ({ 14 }) WSD ({ 15 }) systems ({ 16 }) have ({ 17 }) incorporated ({ 18 }) the ({ 19 }) sense ({ 20 }) dependencies ({ 21 }) . ({ 22 }) 
# Sentence pair (407) source length 13 target length 13 alignment score : 0.00824582
SenseLearner and SuperSenseLearner incorporate sequencial sense dependencies into the supervised WSD frameworks . 
NULL ({ }) SenseLearner ({ 1 }) and ({ 2 }) SuperSenseLearner ({ 3 }) incorporate ({ 4 }) sequential ({ 5 }) sense ({ 6 }) dependencies ({ 7 }) into ({ 8 }) the ({ 9 }) supervised ({ 10 }) WSD ({ 11 }) frameworks ({ 12 }) . ({ 13 }) 
# Sentence pair (408) source length 17 target length 17 alignment score : 0.000470764
They no longer treat each word sense individually , assuming the sense dependencies between adjacent words . 
NULL ({ }) They ({ 1 }) no ({ 2 }) longer ({ 3 }) treat ({ 4 }) each ({ 5 }) word ({ 6 }) sense ({ 7 }) individually ({ 8 }) , ({ 9 }) assuming ({ 10 }) the ({ 11 }) sense ({ 12 }) dependencies ({ 13 }) between ({ 14 }) adjacent ({ 15 }) words ({ 16 }) . ({ 17 }) 
# Sentence pair (409) source length 19 target length 13 alignment score : 2.38648e-10
also took a sequencial tagging approach for the disambiguation of WordNet supersenses . 
NULL ({ }) also ({ 1 }) took ({ 2 }) a ({ 3 }) sequential ({ 4 }) tagging ({ 5 }) approach ({ 6 }) for ({ 7 }) the ({ 8 }) disambiguation ({ 9 }) of ({ 10 }) WordNet ({ 11 }) supersenses ({ 12 }) . ({ 13 }) [<-This ({ }) sentence ({ }) is ({ }) a ({ }) bit ({ }) confusing] ({ }) 
# Sentence pair (410) source length 25 target length 23 alignment score : 4.67289e-10
However , the dependencies they considered are rather simple ones between the adjacent words , and between either WordNet synsets or supersenses . 
NULL ({ 3 }) The ({ }) dependencies ({ 4 }) that ({ }) they ({ 5 }) considered ({ 6 }) , ({ }) however ({ 1 }) , ({ 2 }) are ({ 7 }) rather ({ 8 }) simple ({ 9 }) ones ({ 10 }) between ({ 11 }) the ({ 12 }) adjacent ({ 13 }) words ({ 14 }) , ({ 15 }) and ({ 16 }) between ({ 17 }) either ({ 18 }) WordNet ({ 19 }) synsets ({ 20 }) or ({ 21 }) supersenses ({ 22 }) . ({ 23 }) 
# Sentence pair (411) source length 20 target length 20 alignment score : 8.62171e-25
Note additionally that they do not mention how and how much they contribute to the improvement of supervised WSD . 
NULL ({ 14 15 }) Note ({ 1 }) additionally ({ 2 10 11 }) , ({ }) that ({ 3 }) they ({ 4 }) do ({ 5 }) not ({ 6 }) mention ({ 7 }) the ({ }) means ({ 8 }) or ({ 9 }) the ({ }) quality ({ 13 }) of ({ 17 }) contribution ({ 12 }) in ({ }) improving ({ 16 }) supervised ({ 18 }) WSD ({ 19 }) . ({ 20 }) 
# Sentence pair (412) source length 22 target length 28 alignment score : 1.55776e-25
One interesting model related is the exponential family model proposed by , which captures the occurrences and co-occurrences of words and senses in a joint probability distribution . 
NULL ({ 5 6 13 }) The ({ 1 }) exponential ({ 7 }) family ({ 2 }) model ({ 3 }) proposed ({ 10 }) by ({ 11 }) , ({ 12 }) captures ({ 4 8 9 14 }) the ({ 15 }) occurrences ({ 16 }) and ({ 17 }) co-occurrences ({ 18 }) of ({ 19 }) words ({ 20 }) and ({ 21 }) senses ({ 22 }) in ({ 23 }) a ({ 24 }) joint ({ 25 }) probability ({ 26 }) distribution ({ 27 }) . ({ 28 }) 
# Sentence pair (413) source length 30 target length 29 alignment score : 5.57076e-09
Although they focused on the use of the co-occurrences of word senses rather than the dependencies , they clarified the contribution of sense co-occurrences to the supervised WSD . 
NULL ({ 15 }) Although ({ 1 }) they ({ 2 }) focused ({ 3 }) on ({ 4 }) the ({ 5 }) use ({ 6 }) of ({ 7 }) the ({ 8 }) co-occurrences ({ 9 }) of ({ 10 }) word ({ 11 }) senses ({ 12 }) rather ({ 13 }) than ({ 14 }) that ({ }) of ({ }) dependencies ({ 16 }) , ({ 17 }) they ({ 18 }) clarified ({ 19 }) the ({ 20 }) contribution ({ 21 }) of ({ 22 }) sense ({ 23 }) co-occurrences ({ 24 }) to ({ 25 }) the ({ 26 }) supervised ({ 27 }) WSD ({ 28 }) . ({ 29 }) 
# Sentence pair (414) source length 32 target length 30 alignment score : 1.55491e-12
In this context , it is of an interest if the sense dependencies on a syntactic structure , rather than on a linear chain , works effectively or not . 
NULL ({ }) In ({ 1 }) this ({ 2 }) context ({ 3 }) , ({ 4 }) it ({ 5 }) is ({ 6 }) of ({ 7 }) interest ({ 8 9 }) to ({ }) note ({ 10 }) whether ({ }) the ({ 11 }) sense ({ 12 }) dependencies ({ 13 }) on ({ 14 }) a ({ 15 }) syntactic ({ 16 }) structure ({ 17 }) , ({ 18 }) rather ({ 19 }) than ({ 20 }) on ({ 21 }) a ({ 22 }) linear ({ 23 }) chain ({ 24 }) , ({ 25 }) works ({ 26 }) effectively ({ 27 }) or ({ 28 }) not ({ }) .**[why ({ 29 }) ?] ({ 30 }) 
# Sentence pair (415) source length 23 target length 23 alignment score : 9.48975e-05
To the extent of our knowledge , there exists no model that considers the interdependencies of word senses on a syntactic tree . 
NULL ({ }) To ({ 1 }) the ({ 2 }) extent ({ 3 }) of ({ 4 }) our ({ 5 }) knowledge ({ 6 }) , ({ 7 }) there ({ 8 }) exists ({ 9 }) no ({ 10 }) model ({ 11 }) that ({ 12 }) considers ({ 13 }) the ({ 14 }) interdependencies ({ 15 }) of ({ 16 }) word ({ 17 }) senses ({ 18 }) on ({ 19 }) a ({ 20 }) syntactic ({ 21 }) tree ({ 22 }) . ({ 23 }) 
# Sentence pair (416) source length 25 target length 24 alignment score : 1.40498e-07
Also , despite the approaches described above , the contribution of sense dependencies for the supervised WSD has not explicitly examined thus far . 
NULL ({ }) Furthermore ({ 1 }) , ({ 2 }) despite ({ 3 }) the ({ 4 }) approaches ({ 5 }) described ({ 6 }) above ({ 7 }) , ({ 8 }) the ({ 9 }) contribution ({ 10 }) of ({ 11 }) sense ({ 12 }) dependencies ({ 13 }) for ({ 14 }) the ({ 15 }) supervised ({ 16 }) WSD ({ 17 }) has ({ 18 }) not ({ 19 }) been ({ }) explicitly ({ 20 }) examined ({ 21 }) thus ({ 22 }) far ({ 23 }) . ({ 24 }) 
# Sentence pair (417) source length 8 target length 8 alignment score : 0.068509
These questions are clarified by our research . 
NULL ({ }) These ({ 1 }) questions ({ 2 }) are ({ 3 }) clarified ({ 4 }) by ({ 5 }) our ({ 6 }) research ({ 7 }) . ({ 8 }) 
# Sentence pair (418) source length 20 target length 19 alignment score : 3.40388e-06
In Section 1 , we presented one of the most significant problems in WSD - the data sparsity . 
NULL ({ }) In ({ 1 }) Section ({ 2 }) 1 ({ 3 }) , ({ 4 }) we ({ 5 }) presented ({ 6 }) one ({ 7 }) of ({ 8 }) the ({ 9 }) most ({ 10 }) significant ({ 11 }) issues ({ 12 }) in ({ 13 }) WSD ({ 14 }) - ({ 15 }) the ({ 16 }) data ({ 17 }) sparsity ({ 18 }) problem ({ }) . ({ 19 }) 
# Sentence pair (419) source length 33 target length 31 alignment score : 4.54584e-09
This problem may even be magnified when we consider the interdependencies of word senses , since the number of features is roughly squared by the combination of two word senses . 
NULL ({ }) This ({ 1 }) problem ({ 2 }) may ({ 3 }) even ({ 4 }) be ({ 5 }) magnified ({ 6 }) , ({ }) when ({ 7 }) taking ({ 8 }) into ({ }) consideration ({ 9 }) the ({ 10 }) interdependencies ({ 11 }) of ({ 12 }) word ({ 13 }) senses ({ 14 }) , ({ 15 }) since ({ 16 }) the ({ 17 }) number ({ 18 }) of ({ 19 }) features ({ 20 }) is ({ 21 }) roughly ({ 22 }) squared ({ 23 }) by ({ 24 }) the ({ 25 }) combination ({ 26 }) of ({ 27 }) two ({ 28 }) word ({ 29 }) senses ({ 30 }) . ({ 31 }) 
# Sentence pair (420) source length 33 target length 34 alignment score : 3.38585e-12
In order to relieve this problem , we use the hierarchical information in the WordNet , including the superordinate words and supersenses , which we describe in Section 2 .1 and 2 .2 . 
NULL ({ 25 }) In ({ 1 }) order ({ 2 }) to ({ 3 }) relieve ({ 4 }) this ({ 5 }) problem ({ 6 }) , ({ 7 }) we ({ 8 }) use ({ 9 }) the ({ 10 }) hierarchical ({ 11 }) information ({ 12 }) in ({ 13 }) the ({ 14 }) WordNet ({ 15 }) , ({ 16 }) including ({ 17 }) the ({ 18 }) superordinate ({ 19 }) words ({ 20 }) and ({ 21 }) supersenses ({ 22 }) , ({ 23 }) as ({ 24 }) described ({ 26 }) in ({ 27 }) Section ({ 28 }) 2 ({ 29 }) .1 ({ 30 }) and ({ 31 }) 2 ({ 32 }) .2 ({ 33 }) . ({ 34 }) 
# Sentence pair (421) source length 13 target length 13 alignment score : 5.83893e-07
The use of the hierarchical information has been motivated by several researches . 
NULL ({ 4 }) The ({ 1 }) use ({ 2 }) of ({ 3 }) hierarchical ({ 5 }) information ({ 6 }) has ({ 7 }) been ({ 8 }) motivated ({ 9 }) by ({ 10 }) several ({ 11 }) different ({ }) researches ({ 12 }) . ({ 13 }) 
# Sentence pair (422) source length 56 target length 58 alignment score : 7.10602e-20
For example , a WSD system by , which was ranked second in the Senseval-3 , consists of two models : the first model applied to words seen in the training data , and the second model that performs a generalized disambiguation process for words unseen in the data by using the hierarchical information in the WordNet . 
NULL ({ 9 10 38 }) For ({ 1 }) example ({ 2 }) , ({ 3 }) a ({ 4 }) WSD ({ 5 }) system ({ 6 }) by ({ 7 }) , ({ 8 }) ranked ({ 11 }) second ({ 12 }) in ({ 13 }) the ({ 14 }) Senseval-3 ({ 15 }) , ({ 16 }) consists ({ 17 }) of ({ 18 }) two ({ 19 }) models ({ 20 }) : ({ 21 }) the ({ 22 }) first ({ 23 }) model ({ 24 }) applied ({ 25 }) to ({ 26 }) words ({ 27 }) seen ({ 28 }) in ({ 29 }) the ({ 30 }) training ({ 31 }) data ({ 32 }) , ({ 33 }) and ({ 34 }) the ({ 35 }) second ({ 36 }) model ({ 37 }) performs ({ 39 }) a ({ 40 }) generalized ({ 41 }) disambiguation ({ 42 }) process ({ 43 }) for ({ 44 }) words ({ 45 }) unseen ({ 46 }) in ({ 47 }) the ({ 48 }) data ({ 49 }) , ({ }) by ({ 50 }) using ({ 51 }) the ({ 52 }) hierarchical ({ 53 }) information ({ 54 }) in ({ 55 }) the ({ 56 }) WordNet ({ 57 }) . ({ 58 }) 
# Sentence pair (423) source length 31 target length 29 alignment score : 1.19093e-08
The fine granularity of the WordNet synsets is not just a major obstacle to high-performance WSD , but is sometimes too fine-grained even for a human to disambiguate . 
NULL ({ }) The ({ 1 }) fine ({ 2 }) granularity ({ 3 }) of ({ 4 }) the ({ 5 }) WordNet ({ 6 }) synsets ({ 7 }) is ({ 8 }) not ({ 9 }) just ({ 10 }) a ({ 11 }) major ({ 12 }) obstacle ({ 13 }) in ({ }) achieving ({ 14 }) a ({ }) high-performance ({ 15 }) WSD ({ 16 }) , ({ 17 }) but ({ 18 }) is ({ 19 }) sometimes ({ 20 }) too ({ 21 }) fine-grained ({ 22 }) even ({ 23 }) for ({ 24 }) a ({ 25 }) human ({ 26 }) to ({ 27 }) disambiguate ({ 28 }) . ({ 29 }) 
# Sentence pair (424) source length 33 target length 31 alignment score : 2.11042e-11
This is reflected in the low inter-annotator agreement of sense tagging ( typically around 70% ) , which implies that WSD models are unlikely to perform better than this accuracy . 
NULL ({ }) This ({ 1 }) is ({ 2 }) reflected ({ 3 }) in ({ 4 }) the ({ 5 }) low ({ 6 }) inter-annotator ({ 7 }) agreement ({ 8 }) of ({ 9 }) sense ({ 10 }) tagging ({ 11 }) ( ({ 12 }) typically ({ 13 }) around ({ 14 }) 70% ({ 15 }) ) ({ 16 }) , ({ 17 }) which ({ 18 }) implies ({ 19 }) that ({ 20 }) WSD ({ 21 }) models ({ 22 }) would ({ 23 }) be ({ }) unlikely ({ 24 }) to ({ 25 }) perform ({ 26 }) better ({ 27 }) than ({ 28 }) the ({ }) accuracy ({ 30 }) achieved ({ 29 }) . ({ 31 }) 
# Sentence pair (425) source length 15 target length 15 alignment score : 1.20918e-06
Also , this fine-grainedness is reported to be not appropriate for many NLP applications . 
NULL ({ }) Also ({ 1 }) , ({ 2 }) this ({ 3 }) fine-grained ({ }) nature ({ 4 }) is ({ 5 }) reported ({ 6 }) to ({ 7 }) be ({ 8 }) inappropriate ({ 9 10 }) for ({ 11 }) many ({ 12 }) NLP ({ 13 }) applications ({ 14 }) . ({ 15 }) 
# Sentence pair (426) source length 15 target length 15 alignment score : 0.00301177
For example , reported that coarse-grained sense distinctions are sufficient for several NLP applications . 
NULL ({ }) For ({ 1 }) example ({ 2 }) , ({ 3 }) reported ({ 4 }) that ({ 5 }) coarse-grained ({ 6 }) sense ({ 7 }) distinctions ({ 8 }) are ({ 9 }) sufficient ({ 10 }) for ({ 11 }) several ({ 12 }) NLP ({ 13 }) applications ({ 14 }) . ({ 15 }) 
# Sentence pair (427) source length 24 target length 22 alignment score : 1.13424e-08
Especially , the use of the supersenses has recently been investigated by , and receiving much attention in the WSD field . 
NULL ({ }) In ({ }) particular ({ 1 }) , ({ 2 }) the ({ 3 }) use ({ 4 }) of ({ 5 }) the ({ 6 }) supersenses ({ 7 }) has ({ 8 }) recently ({ 9 }) been ({ 10 }) investigated ({ 11 }) by ({ 12 }) , ({ 13 }) and ({ 14 }) has ({ }) received ({ 15 }) much ({ 16 }) attention ({ 17 }) in ({ 18 }) the ({ 19 }) WSD ({ 20 }) field ({ 21 }) . ({ 22 }) 
# Sentence pair (428) source length 11 target length 15 alignment score : 3.22902e-13
In this case , the inter-annotator agreements are turned out to reach around 90% . 
NULL ({ 11 }) In ({ 1 }) this ({ 2 }) case ({ 3 }) , ({ 4 }) the ({ 5 }) inter-annotator ({ 6 }) agreements ({ 7 }) have ({ 8 }) reached ({ 9 }) nearly90% ({ 10 12 13 14 }) . ({ 15 }) 
# Sentence pair (429) source length 20 target length 19 alignment score : 1.36464e-09
For this reason , we use as our sense inventory the WordNet supersenses as well as the synsets . 
NULL ({ 11 }) For ({ 1 }) this ({ 2 }) reason ({ 3 }) , ({ 4 }) we ({ 5 }) use ({ 6 }) the ({ }) WordNet ({ 12 }) supersenses ({ 13 }) , ({ }) as ({ 14 }) well ({ 15 }) as ({ 16 }) the ({ 17 }) synsets ({ 18 }) as ({ 7 }) our ({ 8 }) sense ({ 9 }) inventory ({ 10 }) . ({ 19 }) 
# Sentence pair (430) source length 13 target length 13 alignment score : 0.00995932
In Section 3 , we described two problems in the WSD field . 
NULL ({ }) In ({ 1 }) Section ({ 2 }) 3 ({ 3 }) , ({ 4 }) we ({ 5 }) described ({ 6 }) two ({ 7 }) problems ({ 8 }) in ({ 9 }) the ({ 10 }) WSD ({ 11 }) field ({ 12 }) . ({ 13 }) 
# Sentence pair (431) source length 20 target length 18 alignment score : 1.65712e-05
One is the independent classification of each word 's sense regardless of the sense dependencies among words . 
NULL ({ }) One ({ 1 }) problem ({ }) is ({ 2 }) the ({ 3 }) independent ({ 4 }) classification ({ 5 }) of ({ 6 }) each ({ 7 }) word ({ 8 }) 's ({ 9 }) sense ({ 10 }) , ({ }) regardless ({ 11 }) of ({ 12 }) the ({ 13 }) sense ({ 14 }) dependencies ({ 15 }) among ({ 16 }) words ({ 17 }) . ({ 18 }) 
# Sentence pair (432) source length 21 target length 19 alignment score : 8.50747e-06
The other is the scarcity of the training data arose from the fine granularity of the sense distinction . 
NULL ({ }) The ({ 1 }) other ({ 2 }) problem ({ }) is ({ 3 }) the ({ 4 }) scarcity ({ 5 }) of ({ 6 }) the ({ 7 }) training ({ 8 }) data ({ 9 }) that ({ }) arose ({ 10 }) from ({ 11 }) the ({ 12 }) fine ({ 13 }) granularity ({ 14 }) of ({ 15 }) the ({ 16 }) sense ({ 17 }) distinction ({ 18 }) . ({ 19 }) 
# Sentence pair (433) source length 9 target length 11 alignment score : 9.82297e-08
We address these problems by the combination of two methods . 
NULL ({ 6 8 }) We ({ 1 }) address ({ 2 }) these ({ 3 }) problems ({ 4 }) by ({ 5 }) combining ({ 7 }) two ({ 9 }) methods ({ 10 }) . ({ 11 }) 
# Sentence pair (434) source length 19 target length 17 alignment score : 3.41945e-05
The first is the use of the syntactic dependencies of word senses on a dependency tree . 
NULL ({ }) The ({ 1 }) first ({ 2 }) [method ({ 3 }) ?] ({ }) is ({ }) the ({ 4 }) use ({ 5 }) of ({ 6 }) the ({ 7 }) syntactic ({ 8 }) dependencies ({ 9 }) of ({ 10 }) word ({ 11 }) senses ({ 12 }) on ({ 13 }) a ({ 14 }) dependency ({ 15 }) tree ({ 16 }) . ({ 17 }) 
# Sentence pair (435) source length 33 target length 32 alignment score : 2.2391e-10
Particularly , we assume that there exist strong dependencies of word senses between a head and its dependents in the dependency tree , rather than between neighboring words in the sentence . 
NULL ({ }) In ({ }) particular ({ 1 }) , ({ 2 }) we ({ 3 }) assume ({ 4 }) that ({ 5 }) there ({ 6 }) are ({ 7 }) strong ({ 8 }) dependencies ({ 9 }) of ({ 10 }) word ({ 11 }) senses ({ 12 }) between ({ 13 }) a ({ 14 }) head ({ 15 }) and ({ 16 }) its ({ 17 }) dependents ({ 18 }) in ({ 19 }) the ({ 20 }) dependency ({ 21 }) tree ({ 22 }) , ({ 23 }) rather ({ 24 }) than ({ 25 }) between ({ 26 }) neighboring ({ 27 }) words ({ 28 }) in ({ 29 }) the ({ 30 }) sentence ({ 31 }) . ({ 32 }) 
# Sentence pair (436) source length 26 target length 26 alignment score : 2.24915e-05
Even though some models so far have considered the dependencies between adjacent words , no one has focused on the syntactic dependencies of word senses . 
NULL ({ }) Even ({ 1 }) though ({ 2 }) some ({ 3 }) models ({ 4 }) so ({ 5 }) far ({ 6 }) have ({ 7 }) considered ({ 8 }) the ({ 9 }) dependencies ({ 10 }) between ({ 11 }) adjacent ({ 12 }) words ({ 13 }) , ({ 14 }) no ({ 15 }) one ({ 16 }) has ({ 17 }) focused ({ 18 }) on ({ 19 }) the ({ 20 }) syntactic ({ 21 }) dependencies ({ 22 }) of ({ 23 }) word ({ 24 }) senses ({ 25 }) . ({ 26 }) 
# Sentence pair (437) source length 27 target length 27 alignment score : 7.2891e-06
Thus , to the extent of our knowledge , our model is the first WSD model that incorporates the sense dependencies based on a syntactic tree . 
NULL ({ }) Thus ({ 1 }) , ({ 2 }) to ({ 3 }) the ({ 4 }) extent ({ 5 }) of ({ 6 }) our ({ 7 }) knowledge ({ 8 }) , ({ 9 }) our ({ 10 }) model ({ 11 }) is ({ 12 }) the ({ 13 }) first ({ 14 }) WSD ({ 15 }) model ({ 16 }) that ({ 17 }) incorporates ({ 18 }) the ({ 19 }) sense ({ 20 }) dependencies ({ 21 }) based ({ 22 }) on ({ 23 }) a ({ 24 }) syntactic ({ 25 }) tree ({ 26 }) . ({ 27 }) 
# Sentence pair (438) source length 15 target length 16 alignment score : 2.2798e-06
The second is the combination of various coarse-grained sense tag sets with the WordNet synsets . 
NULL ({ 6 }) The ({ 1 }) second ({ 2 }) [method ({ 3 }) ?] ({ 4 }) combines ({ 5 }) various ({ 7 }) coarse-grained ({ 8 }) sense ({ 9 }) tag ({ 10 }) sets ({ 11 }) with ({ 12 }) the ({ 13 }) WordNet ({ 14 }) synsets ({ 15 }) . ({ 16 }) 
# Sentence pair (439) source length 24 target length 24 alignment score : 0.000179343
This enables our model to work for unseen words in the training data , and is expected to relieve the data sparseness problem . 
NULL ({ }) This ({ 1 }) enables ({ 2 }) our ({ 3 }) model ({ 4 }) to ({ 5 }) work ({ 6 }) for ({ 7 }) unseen ({ 8 }) words ({ 9 }) in ({ 10 }) the ({ 11 }) training ({ 12 }) data ({ 13 }) , ({ 14 }) and ({ 15 }) is ({ 16 }) expected ({ 17 }) to ({ 18 }) relieve ({ 19 }) the ({ 20 }) data ({ 21 }) sparseness ({ 22 }) problem ({ 23 }) . ({ 24 }) 
# Sentence pair (440) source length 13 target length 13 alignment score : 0.00843435
In our experiment , these tag sets are used in two ways . 
NULL ({ }) In ({ 1 }) our ({ 2 }) experiment ({ 3 }) , ({ 4 }) these ({ 5 }) tag ({ 6 }) sets ({ 7 }) are ({ 8 }) used ({ 9 }) in ({ 10 }) two ({ 11 }) ways ({ 12 }) . ({ 13 }) 
# Sentence pair (441) source length 18 target length 18 alignment score : 2.7497e-13
One way is to use them directly as the sense inventory instead of a finer sense inventory . 
NULL ({ 3 4 }) One ({ 1 }) way ({ 2 }) directly ({ 7 }) uses ({ 5 }) them ({ 6 }) as ({ 8 }) the ({ 9 }) sense ({ 10 }) inventory ({ 11 }) , ({ }) instead ({ 12 }) of ({ 13 }) as ({ }) a ({ 14 }) finer ({ 15 }) sense ({ 16 }) inventory ({ 17 }) . ({ 18 }) 
# Sentence pair (442) source length 29 target length 29 alignment score : 2.2448e-05
In our supersense-based model , we use the supersenses as the sense inventory , and each word sense is disambiguated at the granularity level of this tag set . 
NULL ({ }) In ({ 1 }) our ({ 2 }) supersense-based ({ 3 }) model ({ 4 }) , ({ 5 }) we ({ 6 }) use ({ 7 }) the ({ 8 }) supersenses ({ 9 }) as ({ 10 }) the ({ 11 }) sense ({ 12 }) inventory ({ 13 }) , ({ 14 }) and ({ 15 }) each ({ 16 }) word ({ 17 }) sense ({ 18 }) is ({ 19 }) disambiguated ({ 20 }) at ({ 21 }) the ({ 22 }) granularity ({ 23 }) level ({ 24 }) of ({ 25 }) this ({ 26 }) tag ({ 27 }) set ({ 28 }) . ({ 29 }) 
# Sentence pair (443) source length 22 target length 22 alignment score : 1.68399e-05
This method serves us much more training instances for each coarser sense , while we can no longer distinguish finer senses . 
NULL ({ }) This ({ 1 }) method ({ 2 }) serves ({ 3 }) us ({ 4 }) many ({ 5 }) more ({ 6 }) training ({ 7 }) instances ({ 8 }) for ({ 9 }) each ({ 10 }) coarser ({ 11 }) sense ({ 12 }) , ({ 13 }) while ({ 14 }) we ({ 15 }) can ({ 16 }) no ({ 17 }) longer ({ 18 }) distinguish ({ 19 }) finer ({ 20 }) senses ({ 21 }) . ({ 22 }) 
# Sentence pair (444) source length 17 target length 14 alignment score : 4.97419e-10
The other is to use them in combination with finer sense tag sets . 
NULL ({ 4 }) The ({ 1 }) other ({ 2 }) way ({ 3 }) uses ({ 5 }) them**[<-define ({ 6 }) " ({ }) them ({ }) " ({ }) ] ({ }) in ({ 7 }) combination ({ 8 }) with ({ 9 }) finer ({ 10 }) sense ({ 11 }) tag ({ 12 }) sets ({ 13 }) . ({ 14 }) 
# Sentence pair (445) source length 19 target length 19 alignment score : 0.00126748
In our synset-based model , three coarse-grained label sets are incorporated in combination with the fine-grained WordNet synsets . 
NULL ({ }) In ({ 1 }) our ({ 2 }) synset-based ({ 3 }) model ({ 4 }) , ({ 5 }) three ({ 6 }) coarse-grained ({ 7 }) label ({ 8 }) sets ({ 9 }) are ({ 10 }) incorporated ({ 11 }) in ({ 12 }) combination ({ 13 }) with ({ 14 }) the ({ 15 }) fine-grained ({ 16 }) WordNet ({ 17 }) synsets ({ 18 }) . ({ 19 }) 
# Sentence pair (446) source length 33 target length 33 alignment score : 7.24114e-08
Although the sense disambiguation is still based on the finer senses , the coarser sense tags will help the discrimination of the finer senses , serving generalized information for each fine-grained sense . 
NULL ({ 2 }) Although ({ 1 }) sense ({ 3 }) disambiguation ({ 4 }) is ({ 5 }) still ({ 6 }) based ({ 7 }) on ({ 8 }) the ({ 9 }) finer ({ 10 }) senses ({ 11 }) , ({ 12 }) the ({ 13 }) coarser ({ 14 }) sense ({ 15 }) tags ({ 16 }) will ({ 17 }) help ({ 18 }) the ({ 19 }) discrimination ({ 20 }) of ({ 21 }) the ({ 22 }) finer ({ 23 }) senses ({ 24 }) , ({ }) thereby ({ 25 }) serving ({ 26 }) generalized ({ 27 }) information ({ 28 }) for ({ 29 }) each ({ 30 }) fine-grained ({ 31 }) sense ({ 32 }) . ({ 33 }) 
# Sentence pair (447) source length 28 target length 22 alignment score : 2.40024e-16
This approach has been taken in several hierarchical WSD methods , but never combined with the sense dependencies as we use . 
NULL ({ 20 }) This ({ 1 }) approach ({ 2 }) has ({ 3 }) been ({ 4 }) taken ({ 5 }) in ({ 6 }) several ({ 7 }) hierarchical ({ 8 }) WSD ({ 9 }) methods ({ 10 }) , ({ 11 }) but ({ 12 }) has ({ }) never ({ 13 }) been ({ }) combined ({ 14 }) with ({ 15 }) the ({ 16 }) sense ({ 17 }) dependencies ({ 18 }) in ({ }) a ({ }) way ({ 19 }) that ({ }) have ({ }) used ({ 21 }) them ({ }) . ({ 22 }) 
# Sentence pair (448) source length 8 target length 9 alignment score : 5.06801e-05
The process of WSD is summarized as below . 
NULL ({ }) The ({ 1 }) process ({ 2 }) of ({ 3 }) WSD ({ 4 }) is ({ 5 }) summarized ({ 6 }) below ({ 7 8 }) . ({ 9 }) 
# Sentence pair (449) source length 34 target length 34 alignment score : 5.52315e-06
At the beginning , we parse target sentences with a dependency parser , and compact the outputted trees in order to capture informative dependencies among words , as described in Section 4 .3 . 
NULL ({ }) At ({ 1 }) the ({ 2 }) beginning ({ 3 }) , ({ 4 }) we ({ 5 }) parse ({ 6 }) target ({ 7 }) sentences ({ 8 }) with ({ 9 }) a ({ 10 }) dependency ({ 11 }) parser ({ 12 }) , ({ 13 }) and ({ 14 }) compact ({ 15 }) the ({ 16 }) outputted ({ 17 }) trees ({ 18 }) in ({ 19 }) order ({ 20 }) to ({ 21 }) capture ({ 22 }) informative ({ 23 }) dependencies ({ 24 }) among ({ 25 }) words ({ 26 }) , ({ 27 }) as ({ 28 }) described ({ 29 }) in ({ 30 }) Section ({ 31 }) 4 ({ 32 }) .3 ({ 33 }) . ({ 34 }) 
# Sentence pair (450) source length 16 target length 16 alignment score : 0.00268001
Then , the WSD task is regarded as a labeling task on the tree structures . 
NULL ({ }) Then ({ 1 }) , ({ 2 }) the ({ 3 }) WSD ({ 4 }) task ({ 5 }) is ({ 6 }) regarded ({ 7 }) as ({ 8 }) a ({ 9 }) labeling ({ 10 }) task ({ 11 }) on ({ 12 }) the ({ 13 }) tree ({ 14 }) structures ({ 15 }) . ({ 16 }) 
# Sentence pair (451) source length 27 target length 26 alignment score : 1.40008e-05
By using T-CRFs , we can model this as the maximization of the probability of word sense trees , given scores for vertices and edges . 
NULL ({ }) By ({ 1 }) using ({ 2 }) T-CRFs ({ 3 }) , ({ 4 }) we ({ 5 }) can ({ 6 }) model ({ 7 }) this ({ 8 }) as ({ 9 }) the ({ 10 }) maximization ({ 11 }) of ({ 12 }) the ({ 13 }) probability ({ 14 }) of ({ 15 }) word ({ 16 }) sense ({ 17 }) trees ({ 18 }) , ({ 19 }) given ({ 20 }) the ({ }) scores ({ 21 }) for ({ 22 }) vertices ({ 23 }) and ({ 24 }) edges ({ 25 }) . ({ 26 }) 
# Sentence pair (452) source length 29 target length 31 alignment score : 2.88165e-11
In the training phase , all vertex features and edge features are extracted using the gold-standard senses , and the weight vectors for them are optimized over the training data . 
NULL ({ 23 24 }) In ({ 1 }) the ({ 2 }) training ({ 3 }) phase ({ 4 }) , ({ 5 }) all ({ 6 }) vertex ({ 7 }) features ({ 8 }) and ({ 9 }) edge ({ 10 }) features ({ 11 }) are ({ 12 }) extracted ({ 13 }) using ({ 14 }) the ({ 15 }) gold-standard ({ 16 }) senses ({ 17 }) , ({ 18 }) and ({ 19 }) the ({ 20 }) weight ({ 21 }) vectors ({ 22 }) are ({ 25 }) optimized ({ 26 }) over ({ 27 }) the ({ 28 }) training ({ 29 }) data ({ 30 }) . ({ 31 }) 
# Sentence pair (453) source length 32 target length 32 alignment score : 6.48068e-06
Finally , in the testing phase , all possible combinations of senses are evaluated for each sentence , and the most probable sense assignment is selected by evaluating the equation 3 . 
NULL ({ }) Finally ({ 1 }) , ({ 2 }) in ({ 3 }) the ({ 4 }) testing ({ 5 }) phase ({ 6 }) , ({ 7 }) all ({ 8 }) possible ({ 9 }) combinations ({ 10 }) of ({ 11 }) senses ({ 12 }) are ({ 13 }) evaluated ({ 14 }) for ({ 15 }) each ({ 16 }) sentence ({ 17 }) , ({ 18 }) and ({ 19 }) the ({ 20 }) most ({ 21 }) probable ({ 22 }) sense ({ 23 }) assignment ({ 24 }) is ({ 25 }) selected ({ 26 }) by ({ 27 }) evaluating ({ 28 }) the ({ 29 }) equation ({ 30 }) 3 ({ 31 }) . ({ 32 }) 
# Sentence pair (454) source length 14 target length 14 alignment score : 0.00461132
Conditional Random Fields ( CRFs ) are graph-based probabilistic discriminative models proposed by . 
NULL ({ }) Conditional ({ 1 }) Random ({ 2 }) Fields ({ 3 }) ( ({ 4 }) CRFs ({ 5 }) ) ({ 6 }) are ({ 7 }) graph-based ({ 8 }) probabilistic ({ 9 }) discriminative ({ 10 }) models ({ 11 }) proposed ({ 12 }) by ({ 13 }) . ({ 14 }) 
# Sentence pair (455) source length 13 target length 14 alignment score : 0.000112423
CRFs are the state-of-the-art methods for sequence labeling problems in many NLP tasks . 
NULL ({ 3 }) CRFs ({ 1 }) are ({ 2 }) state-of-the-art ({ 4 }) methods ({ 5 }) for ({ 6 }) sequence ({ 7 }) labeling ({ 8 }) problems ({ 9 }) in ({ 10 }) many ({ 11 }) NLP ({ 12 }) tasks ({ 13 }) . ({ 14 }) 
# Sentence pair (456) source length 17 target length 17 alignment score : 0.00130398
CRFs construct a conditional model / MATH from a set of paired observations and label sequences . 
NULL ({ }) CRFs ({ 1 }) construct ({ 2 }) a ({ 3 }) conditional ({ 4 }) model ({ 5 }) / ({ 6 }) MATH ({ 7 }) from ({ 8 }) a ({ 9 }) set ({ 10 }) of ({ 11 }) paired ({ 12 }) observations ({ 13 }) and ({ 14 }) label ({ 15 }) sequences ({ 16 }) . ({ 17 }) 
# Sentence pair (457) source length 93 target length 95 alignment score : 5.14351e-23
The conditional probability of a label sequence / MATH conditioned on a data sequence / MATH is given by / MATH , where / MATH and / MATH are the feature vectors for an edge and a vertex , / MATH and / MATH are the weight vectors for them , / MATH and / MATH are the set of components of / MATH associated with an edge / MATH and a vertex / MATH , and / MATH is the partition function which constrains the sum of all the probabilities to be 1 . 
NULL ({ 49 50 51 }) The ({ 1 }) conditional ({ 2 }) probability ({ 3 }) of ({ 4 }) a ({ 5 }) label ({ 6 }) sequence ({ 7 }) / ({ 8 }) MATH ({ 9 }) conditioned ({ 10 }) on ({ 11 }) a ({ 12 }) data ({ 13 }) sequence ({ 14 }) / ({ 15 }) MATH ({ 16 }) is ({ 17 }) given ({ 18 }) by ({ 19 }) / ({ 20 }) MATH ({ 21 }) , ({ 22 }) where ({ 23 }) / ({ 24 }) MATH ({ 25 }) and ({ 26 }) / ({ 27 }) MATH ({ 28 }) are ({ 29 }) the ({ 30 }) feature ({ 31 }) vectors ({ 32 }) for ({ 33 }) an ({ 34 }) edge ({ 35 }) and ({ 36 }) a ({ 37 }) vertex ({ 38 }) , ({ 39 }) / ({ 40 }) MATH ({ 41 }) and ({ 42 }) / ({ 43 }) MATH ({ 44 }) are ({ 45 }) the ({ 46 }) weight ({ 47 }) vectors ({ 48 }) , ({ }) / ({ 52 }) MATH ({ 53 }) and ({ 54 }) / ({ 55 }) MATH ({ 56 }) are ({ 57 }) the ({ 58 }) set ({ 59 }) of ({ 60 }) components ({ 61 }) of ({ 62 }) / ({ 63 }) MATH ({ 64 }) associated ({ 65 }) with ({ 66 }) an ({ 67 }) edge ({ 68 }) / ({ 69 }) MATH ({ 70 }) and ({ 71 }) a ({ 72 }) vertex ({ 73 }) / ({ 74 }) MATH ({ 75 }) , ({ 76 }) and ({ 77 }) / ({ 78 }) MATH ({ 79 }) is ({ 80 }) the ({ 81 }) partition ({ 82 }) function ({ 83 }) that ({ 84 }) constrains ({ 85 }) the ({ 86 }) sum ({ 87 }) of ({ 88 }) all ({ 89 }) the ({ 90 }) probabilities ({ 91 }) to ({ 92 }) be ({ 93 }) 1 ({ 94 }) . ({ 95 }) 
# Sentence pair (458) source length 29 target length 28 alignment score : 7.06575e-06
Tree-structured CRFs ( T-CRFs ) are different from widely used linear-chain CRFs in that the random variables are organized in a tree structure ( acyclic graph ) . 
NULL ({ }) Tree-structured ({ 1 }) CRFs ({ 2 }) ( ({ 3 }) T-CRFs ({ 4 }) ) ({ 5 }) are ({ 6 }) different ({ 7 }) from ({ 8 }) widely ({ 9 }) used ({ 10 }) linear-chain ({ 11 }) CRFs ({ 12 }) , ({ }) in ({ 13 }) that ({ 14 }) the ({ 15 }) random ({ 16 }) variables ({ 17 }) are ({ 18 }) organized ({ 19 }) in ({ 20 }) a ({ 21 }) tree ({ 22 }) structure ({ 23 }) ( ({ 24 }) acyclic ({ 25 }) graph ({ 26 }) ) ({ 27 }) . ({ 28 }) 
# Sentence pair (459) source length 24 target length 24 alignment score : 8.16422e-09
Hence , we can consider them appropriate for modeling the syntactic dependencies of word senses , which cannot be represented by linear structures . 
NULL ({ }) Hence ({ 1 }) , ({ 2 }) we ({ 3 }) can ({ 4 }) consider ({ 5 }) them ({ 6 }) relevant ({ 7 }) in ({ 8 }) modeling ({ 9 }) the ({ 10 }) syntactic ({ 11 }) dependencies ({ 12 }) of ({ 13 }) word ({ 14 }) senses ({ 15 }) , ({ 16 }) which ({ 17 }) cannot ({ 18 }) be ({ 19 }) represented ({ 20 }) by ({ 21 }) linear ({ 22 }) structures ({ 23 }) . ({ 24 }) 
# Sentence pair (460) source length 49 target length 48 alignment score : 1.48568e-09
In this model , the optimal label assignment / MATH for an observation sequence / MATH is then calculated by / MATH , where / MATH denotes a vertex corresponding to a word while / MATH denotes the vertex corresponding to its parent in the dependency tree . 
NULL ({ }) In ({ 1 }) this ({ 2 }) model ({ 3 }) , ({ 4 }) the ({ 5 }) optimal ({ 6 }) label ({ 7 }) assignment ({ 8 }) / ({ 9 }) MATH ({ 10 }) for ({ 11 }) an ({ 12 }) observation ({ 13 }) sequence ({ 14 }) / ({ 15 }) MATH ({ 16 }) is ({ 17 }) then ({ 18 }) calculated ({ 19 }) by ({ 20 }) / ({ 21 }) MATH ({ 22 }) , ({ 23 }) where ({ 24 }) / ({ 25 }) MATH ({ 26 }) denotes ({ 27 }) a ({ 28 }) vertex ({ 29 }) corresponding ({ 30 }) to ({ 31 }) a ({ 32 }) word ({ 33 }) , ({ }) while ({ 34 }) / ({ 35 }) MATH ({ 36 }) denotes ({ 37 }) the ({ 38 }) vertex ({ 39 }) corresponding ({ 40 }) to ({ 41 }) its ({ 42 }) parent ({ 43 }) in ({ 44 }) the ({ 45 }) dependency ({ 46 }) tree ({ 47 }) . ({ 48 }) 
# Sentence pair (461) source length 24 target length 24 alignment score : 9.73397e-06
If we interpret / MATH as the vertex associated with the preceding word in a sentence , it reduces to a linear-chain CRF . 
NULL ({ }) If ({ 1 }) we ({ 2 }) interpret ({ 3 }) / ({ 4 }) MATH ({ 5 }) as ({ 6 }) the ({ 7 }) vertex ({ 8 }) associated ({ 9 }) with ({ 10 }) the ({ 11 }) preceding ({ 12 }) word ({ 13 }) in ({ 14 }) a ({ 15 }) sentence ({ 16 }) , ({ 17 }) it ({ 18 }) delineates ({ 19 }) into ({ 20 }) a ({ 21 }) linear-chain ({ 22 }) CRF ({ 23 }) . ({ 24 }) 
# Sentence pair (462) source length 39 target length 39 alignment score : 3.19504e-07
Although T-CRFs are relatively new models , they have already been applied to several NLP tasks , such as semantic role labeling and semantic annotation , proving to be useful in modeling the semantic structure of a text . 
NULL ({ }) Although ({ 1 }) T-CRFs ({ 2 }) are ({ 3 }) relatively ({ 4 }) new ({ 5 }) models ({ 6 }) , ({ 7 }) they ({ 8 }) have ({ 9 }) already ({ 10 }) been ({ 11 }) applied ({ 12 }) to ({ 13 }) several ({ 14 }) NLP ({ 15 }) tasks ({ 16 }) , ({ 17 }) such ({ 18 }) as ({ 19 }) semantic ({ 20 }) role ({ 21 }) labeling ({ 22 }) and ({ 23 }) semantic ({ 24 }) annotation ({ 25 }) , ({ 26 }) proving ({ 27 }) to ({ 28 }) be ({ 29 }) useful ({ 30 }) in ({ 31 }) modeling ({ 32 }) the ({ 33 }) semantic ({ 34 }) structure ({ 35 }) of ({ 36 }) a ({ 37 }) text ({ 38 }) . ({ 39 }) 
# Sentence pair (463) source length 11 target length 11 alignment score : 0.0226269
Our model is the first application of T-CRFs to WSD . 
NULL ({ }) Our ({ 1 }) model ({ 2 }) is ({ 3 }) the ({ 4 }) first ({ 5 }) application ({ 6 }) of ({ 7 }) T-CRFs ({ 8 }) to ({ 9 }) WSD ({ 10 }) . ({ 11 }) 
# Sentence pair (464) source length 18 target length 18 alignment score : 1.33814e-09
In this section , we introduce a method to build graph structures on which CRFs are constructed . 
NULL ({ 7 }) In ({ 1 }) this ({ 2 }) section ({ 3 }) , ({ 4 }) we ({ 5 }) introduce ({ 6 }) the ({ }) method ({ 8 }) of ({ 9 }) building ({ 10 }) graph ({ 11 }) structures ({ 12 }) on ({ 13 }) which ({ 14 }) CRFs ({ 15 }) are ({ 16 }) constructed ({ 17 }) . ({ 18 }) 
# Sentence pair (465) source length 15 target length 15 alignment score : 0.00358539
First , we describe how to construct a tree used in the tree-structured model . 
NULL ({ }) First ({ 1 }) , ({ 2 }) we ({ 3 }) describe ({ 4 }) how ({ 5 }) to ({ 6 }) construct ({ 7 }) a ({ 8 }) tree ({ 9 }) used ({ 10 }) in ({ 11 }) the ({ 12 }) tree-structured ({ 13 }) model ({ 14 }) . ({ 15 }) 
# Sentence pair (466) source length 11 target length 11 alignment score : 0.0164974
Let us consider the synset-level disambiguation of the following sentence . 
NULL ({ }) Let ({ 1 }) us ({ 2 }) consider ({ 3 }) the ({ 4 }) synset-level ({ 5 }) disambiguation ({ 6 }) of ({ 7 }) the ({ 8 }) following ({ 9 }) sentence ({ 10 }) . ({ 11 }) 
# Sentence pair (467) source length 11 target length 11 alignment score : 0.0241059
( i ) - The man destroys confidence in banks . 
NULL ({ }) ( ({ 1 }) i ({ 2 }) ) ({ 3 }) - ({ 4 }) The ({ 5 }) man ({ 6 }) destroys ({ 7 }) confidence ({ 8 }) in ({ 9 }) banks ({ 10 }) . ({ 11 }) 
# Sentence pair (468) source length 26 target length 27 alignment score : 3.15135e-08
At the beginning , we parse this sentence with the Sagae and Tsujii 's dependency parser , which outputs parsed trees in the CoNLL-X dependency format . 
NULL ({ 10 }) In ({ 1 }) the ({ 2 }) beginning ({ 3 }) , ({ 4 }) we ({ 5 }) parse ({ 6 }) this ({ 7 }) sentence ({ 8 }) with ({ 9 }) Sagae ({ 11 }) and ({ 12 }) Tsujii ({ 13 }) 's ({ 14 }) dependency ({ 15 }) parser ({ 16 }) , ({ 17 }) which ({ 18 }) outputs ({ 19 }) parsed ({ 20 }) trees ({ 21 }) in ({ 22 }) the ({ 23 }) CoNLL-X ({ 24 }) dependency ({ 25 }) format ({ 26 }) . ({ 27 }) 
# Sentence pair (469) source length 38 target length 38 alignment score : 1.00708e-06
The left-hand side of Figure 2 shows the parsed tree for Sentence ( i ) , where each child-parent edge denotes a directed dependency of words , and the labels on the edges denote the dependency types . 
NULL ({ }) The ({ 1 }) left-hand ({ 2 }) side ({ 3 }) of ({ 4 }) Figure ({ 5 }) 2 ({ 6 }) shows ({ 7 }) the ({ 8 }) parsed ({ 9 }) tree ({ 10 }) for ({ 11 }) Sentence ({ 12 }) ( ({ 13 }) i ({ 14 }) ) ({ 15 }) , ({ 16 }) where ({ 17 }) each ({ 18 }) child-parent ({ 19 }) edge ({ 20 }) denotes ({ 21 }) a ({ 22 }) directed ({ 23 }) dependency ({ 24 }) of ({ 25 }) words ({ 26 }) , ({ 27 }) and ({ 28 }) the ({ 29 }) labels ({ 30 }) on ({ 31 }) the ({ 32 }) edges ({ 33 }) denote ({ 34 }) the ({ 35 }) dependency ({ 36 }) types ({ 37 }) . ({ 38 }) 
# Sentence pair (470) source length 19 target length 19 alignment score : 0.000894556
This dependency tree describes dependencies among all words in a sentence , including content words and function words . 
NULL ({ }) This ({ 1 }) dependency ({ 2 }) tree ({ 3 }) describes ({ 4 }) dependencies ({ 5 }) among ({ 6 }) all ({ 7 }) words ({ 8 }) in ({ 9 }) a ({ 10 }) sentence ({ 11 }) , ({ 12 }) including ({ 13 }) content ({ 14 }) words ({ 15 }) and ({ 16 }) function ({ 17 }) words ({ 18 }) . ({ 19 }) 
# Sentence pair (471) source length 26 target length 26 alignment score : 6.48472e-05
However , some of these dependencies are not informative for our WSD task , because our task does not focus on the disambiguation function words . 
NULL ({ }) However ({ 1 }) , ({ 2 }) some ({ 3 }) of ({ 4 }) these ({ 5 }) dependencies ({ 6 }) are ({ 7 }) not ({ 8 }) informative ({ 9 }) for ({ 10 }) our ({ 11 }) WSD ({ 12 }) task ({ 13 }) , ({ 14 }) because ({ 15 }) our ({ 16 }) task ({ 17 }) does ({ 18 }) not ({ 19 }) focus ({ 20 }) on ({ 21 }) the ({ 22 }) disambiguation ({ 23 }) function ({ 24 }) words ({ 25 }) . ({ 26 }) 
# Sentence pair (472) source length 38 target length 38 alignment score : 5.26599e-08
For example , on the right-hand side of Figure 2 , the dependencies among confidence-in-bank are splitted into the two dependencies confidence-in and in-bank ; Hence our model cannot capture the direct dependency between confidence and bank . 
NULL ({ }) For ({ 1 }) example ({ 2 }) , ({ 3 }) on ({ 4 }) the ({ 5 }) right-hand ({ 6 }) side ({ 7 }) of ({ 8 }) Figure ({ 9 }) 2 ({ 10 }) , ({ 11 }) the ({ 12 }) dependencies ({ 13 }) among ({ 14 }) confidence-in-bank ({ 15 }) are ({ 16 }) split ({ 17 }) into ({ 18 }) the ({ 19 }) two ({ 20 }) dependencies ({ 21 }) confidence-in ({ 22 }) and ({ 23 }) in-bank ({ 24 }) ; ({ 25 }) hence ({ 26 }) our ({ 27 }) model ({ 28 }) cannot ({ 29 }) capture ({ 30 }) the ({ 31 }) direct ({ 32 }) dependency ({ 33 }) between ({ 34 }) confidence ({ 35 }) and ({ 36 }) bank ({ 37 }) . ({ 38 }) 
# Sentence pair (473) source length 24 target length 24 alignment score : 8.76026e-05
One way to resolve this problem is to use higher-order ( semi-Markov ) dependencies , but this may drastically increase the computational cost . 
NULL ({ }) One ({ 1 }) way ({ 2 }) to ({ 3 }) resolve ({ 4 }) this ({ 5 }) problem ({ 6 }) is ({ 7 }) to ({ 8 }) use ({ 9 }) higher-order ({ 10 }) ( ({ 11 }) semi-Markov ({ 12 }) ) ({ 13 }) dependencies ({ 14 }) , ({ 15 }) but ({ 16 }) this ({ 17 }) may ({ 18 }) drastically ({ 19 }) increase ({ 20 }) the ({ 21 }) computational ({ 22 }) cost ({ 23 }) . ({ 24 }) 
# Sentence pair (474) source length 30 target length 32 alignment score : 3.08764e-15
For this reason , for the synset-based model , we convert the outputted dependency tree into a tree of content words , as exemplified on the right-hand side of Figure 2 . 
NULL ({ 2 3 }) Thus ({ 1 }) , ({ 4 }) for ({ 5 }) the ({ 6 }) synset-based ({ 7 }) model ({ 8 }) , ({ 9 }) we ({ 10 }) convert ({ 11 }) the ({ 12 }) outputted ({ 13 }) dependency ({ 14 }) tree ({ 15 }) into ({ 16 }) a ({ 17 }) tree ({ 18 }) of ({ 19 }) content ({ 20 }) words ({ 21 }) , ({ 22 }) as ({ 23 }) exemplified ({ 24 }) on ({ 25 }) the ({ 26 }) right-hand ({ 27 }) side ({ 28 }) of ({ 29 }) Figure ({ 30 }) 2 ({ 31 }) . ({ 32 }) 
# Sentence pair (475) source length 35 target length 35 alignment score : 3.32908e-06
In this process , the function words are removed from the tree , and their parent and child vertices are directly connected with the dependency labels of the uppermost edge in the original tree . 
NULL ({ }) In ({ 1 }) this ({ 2 }) process ({ 3 }) , ({ 4 }) the ({ 5 }) function ({ 6 }) words ({ 7 }) are ({ 8 }) removed ({ 9 }) from ({ 10 }) the ({ 11 }) tree ({ 12 }) , ({ 13 }) and ({ 14 }) their ({ 15 }) parent ({ 16 }) and ({ 17 }) child ({ 18 }) vertices ({ 19 }) are ({ 20 }) directly ({ 21 }) connected ({ 22 }) with ({ 23 }) the ({ 24 }) dependency ({ 25 }) labels ({ 26 }) of ({ 27 }) the ({ 28 }) uppermost ({ 29 }) edge ({ 30 }) in ({ 31 }) the ({ 32 }) original ({ 33 }) tree ({ 34 }) . ({ 35 }) 
# Sentence pair (476) source length 24 target length 28 alignment score : 4.53371e-19
Then , on the right-hand side of Figure 2 , we can see that the dependency between confidence and bank is now described as a direct edge . 
NULL ({ 11 12 14 }) Then ({ 1 }) , ({ 2 }) on ({ 3 }) the ({ 4 }) right-hand ({ 5 13 }) side ({ 6 }) of ({ 7 }) Figure ({ 8 }) 2 ({ 9 }) , ({ 10 }) the ({ 15 }) dependency ({ 16 }) between ({ 17 }) confidence ({ 18 }) and ({ 19 }) bank ({ 20 }) is ({ 21 }) now ({ 22 }) described ({ 23 }) as ({ 24 }) a ({ 25 }) direct ({ 26 }) edge ({ 27 }) . ({ 28 }) 
# Sentence pair (477) source length 20 target length 20 alignment score : 4.68437e-13
Thus , by the compaction of the trees , our model can capture more useful dependencies among word senses . 
NULL ({ 2 3 }) By ({ 1 }) the ({ 4 }) compaction ({ 5 }) of ({ 6 }) the ({ 7 }) trees ({ 8 }) , ({ }) therefore ({ }) , ({ 9 }) our ({ 10 }) model ({ 11 }) can ({ 12 }) capture ({ 13 }) more ({ 14 }) useful ({ 15 }) dependencies ({ 16 }) among ({ 17 }) word ({ 18 }) senses ({ 19 }) . ({ 20 }) 
# Sentence pair (478) source length 30 target length 32 alignment score : 2.73565e-13
Note that for the supersense-based model , we further convert the tree into a tree of nouns and verbs , because supersenses are defined for only these two parts of speech . 
NULL ({ 2 3 }) For ({ 1 }) the ({ 4 }) supersense-based ({ 5 }) model ({ 6 }) , ({ 7 }) we ({ 8 }) further ({ 9 }) convert ({ 10 }) the ({ 11 }) tree ({ 12 }) into ({ 13 }) a ({ 14 }) tree ({ 15 }) of ({ 16 }) nouns ({ 17 }) and ({ 18 }) verbs ({ 19 }) , ({ 20 }) because ({ 21 }) supersenses ({ 22 }) are ({ 23 }) defined ({ 24 }) for ({ 25 }) only ({ 26 }) these ({ 27 }) two ({ 28 }) parts ({ 29 }) of ({ 30 }) speech ({ 31 }) . ({ 32 }) 
# Sentence pair (479) source length 48 target length 48 alignment score : 3.4135e-13
The inclusion of removed words and dependency relation labels are performed in the same manner as in the synset-based model , and the tree on the right hand side of Figure 2 in this case remains unchanged because the sentence does not contain any adjectives nor adverbs . 
NULL ({ 21 }) The ({ 1 }) inclusion ({ 2 }) of ({ 3 }) removed ({ 4 }) words ({ 5 }) and ({ 6 }) dependency ({ 7 }) relation ({ 8 }) labels ({ 9 }) are ({ 10 }) performed ({ 11 }) in ({ 12 }) the ({ 13 }) same ({ 14 }) manner ({ 15 }) as ({ 16 }) in ({ 17 }) the ({ 18 }) synset-based ({ 19 }) model ({ 20 }) ; ({ 22 }) the ({ 23 }) tree ({ 24 }) on ({ 25 }) the ({ 26 }) right ({ 27 }) hand ({ 28 }) side ({ 29 }) of ({ 30 }) Figure ({ 31 }) 2 ({ 32 }) in ({ 33 }) this ({ 34 }) case ({ 35 }) remains ({ 36 }) unchanged ({ 37 }) , ({ }) because ({ 38 }) the ({ 39 }) sentence ({ 40 }) does ({ 41 }) not ({ 42 }) contain ({ 43 }) any ({ 44 }) adjectives ({ 45 }) nor ({ 46 }) adverbs ({ 47 }) . ({ 48 }) 
# Sentence pair (480) source length 11 target length 14 alignment score : 3.8975e-15
For the linear-chain models , we do not need to parse a sentence . 
NULL ({ 10 }) For ({ 1 }) the ({ 2 }) linear-chain ({ 3 }) models ({ 4 }) , ({ 5 }) parsing ({ 6 }) a ({ 12 }) sentence ({ 13 }) is ({ }) unnecessary ({ 7 8 9 11 }) . ({ 14 }) 
# Sentence pair (481) source length 18 target length 18 alignment score : 0.00104597
At first , we connect every adjacent words with an edge , and build a linear chain . 
NULL ({ }) At ({ 1 }) first ({ 2 }) , ({ 3 }) we ({ 4 }) connect ({ 5 }) every ({ 6 }) adjacent ({ 7 }) words ({ 8 }) with ({ 9 }) an ({ 10 }) edge ({ 11 }) , ({ 12 }) and ({ 13 }) build ({ 14 }) a ({ 15 }) linear ({ 16 }) chain ({ 17 }) . ({ 18 }) 
# Sentence pair (482) source length 48 target length 47 alignment score : 6.25192e-14
Next , as the same reason for the tree-structured case , we remove from the graph those words that we do not need to disambiguate , in order to capture the direct dependencies between content words ( or nouns and verbs in the supersense-based model ) . 
NULL ({ }) Next ({ 1 }) , ({ 2 }) as ({ 3 }) the ({ 4 }) same ({ 5 }) reason ({ 6 }) as ({ }) for ({ 7 }) the ({ 8 }) tree-structured ({ 9 }) case ({ 10 }) , ({ 11 }) we ({ 12 }) remove ({ 13 }) those ({ 17 }) words ({ 18 }) that ({ 19 }) we ({ 20 }) do ({ 21 }) not ({ 22 }) need ({ 23 }) to ({ 24 }) disambiguate ({ 25 }) from ({ 14 }) the ({ 15 }) graph ({ 16 }) , ({ 26 }) in ({ 27 }) order ({ 28 }) to ({ 29 }) capture ({ 30 }) the ({ 31 }) direct ({ 32 }) dependencies ({ 33 }) between ({ 34 }) content ({ 35 }) words ({ 36 }) ( ({ 37 }) or ({ 38 }) nouns ({ 39 }) and ({ 40 }) verbs ({ 41 }) in ({ 42 }) the ({ 43 }) supersense-based ({ 44 }) model ({ 45 }) ) ({ 46 }) . ({ 47 }) 
# Sentence pair (483) source length 23 target length 21 alignment score : 6.6871e-06
Thus , the process of the tree compaction is performed in the same manner , as described in Figure 3 . 
NULL ({ }) Thus ({ 1 }) , ({ 2 }) the ({ 3 }) process ({ 4 }) of ({ 5 }) the ({ 6 }) tree ({ 7 }) compaction[ ({ 8 }) ? ({ }) ?] ({ }) is ({ 9 }) performed ({ 10 }) in ({ 11 }) the ({ 12 }) same ({ 13 }) manner ({ 14 }) , ({ 15 }) as ({ 16 }) described ({ 17 }) in ({ 18 }) Figure ({ 19 }) 3 ({ 20 }) . ({ 21 }) 
# Sentence pair (484) source length 16 target length 16 alignment score : 0.00294588
In this section , let us present an intuitive illustration of how our model works . 
NULL ({ }) In ({ 1 }) this ({ 2 }) section ({ 3 }) , ({ 4 }) let ({ 5 }) us ({ 6 }) present ({ 7 }) an ({ 8 }) intuitive ({ 9 }) illustration ({ 10 }) of ({ 11 }) how ({ 12 }) our ({ 13 }) model ({ 14 }) works ({ 15 }) . ({ 16 }) 
# Sentence pair (485) source length 50 target length 51 alignment score : 3.72983e-27
Here , we focus on three words destroy , confidence , and bank in Sentence ( i ) , and for simplicity consider only two major senses for each word as described in Table 3 , so that the number of possible sense assignments is in this case / MATH . 
NULL ({ 19 20 46 48 }) Here ({ 1 }) , ({ 2 }) we ({ 3 }) focus ({ 4 }) on ({ 5 }) three ({ 6 }) words ({ 7 }) : ({ }) destroy ({ 8 }) , ({ 9 }) confidence ({ 10 }) , ({ 11 }) and ({ 12 }) bank ({ 13 }) in ({ 14 }) Sentence ({ 15 }) ( ({ 16 }) I ({ 17 }) ) ({ 18 }) . ({ 47 }) For ({ 21 }) simplicity ({ 22 }) , ({ }) we ({ }) consider ({ 23 }) only ({ 24 }) two ({ 25 }) major ({ 26 }) senses ({ 27 }) for ({ 28 }) each ({ 29 }) word ({ 30 }) as ({ 31 }) described ({ 32 }) in ({ 33 }) Table ({ 34 }) 3 ({ 35 }) , ({ 36 }) so ({ 37 }) that ({ 38 }) the ({ 39 }) number ({ 40 }) of ({ 41 }) possible ({ 42 }) sense ({ 43 }) assignments ({ 44 }) is ({ 45 }) / ({ 49 }) MATH ({ 50 }) . ({ 51 }) 
# Sentence pair (486) source length 24 target length 24 alignment score : 0.000180692
After an appropriate compaction of the dependency tree , relationships among destroy , confidence , and bank , are represented as direct connections . 
NULL ({ }) After ({ 1 }) an ({ 2 }) appropriate ({ 3 }) compaction ({ 4 }) of ({ 5 }) the ({ 6 }) dependency ({ 7 }) tree ({ 8 }) , ({ 9 }) relationships ({ 10 }) among ({ 11 }) destroy ({ 12 }) , ({ 13 }) confidence ({ 14 }) , ({ 15 }) and ({ 16 }) bank ({ 17 }) , ({ 18 }) are ({ 19 }) represented ({ 20 }) as ({ 21 }) direct ({ 22 }) connections ({ 23 }) . ({ 24 }) 
# Sentence pair (487) source length 24 target length 24 alignment score : 0.000123514
Now , our objective is to determine the correct assignment of senses to these words , given the trained weight vector for features . 
NULL ({ }) Now ({ 1 }) , ({ 2 }) our ({ 3 }) objective ({ 4 }) is ({ 5 }) to ({ 6 }) determine ({ 7 }) the ({ 8 }) correct ({ 9 }) assignment ({ 10 }) of ({ 11 }) senses ({ 12 }) to ({ 13 }) these ({ 14 }) words ({ 15 }) , ({ 16 }) given ({ 17 }) the ({ 18 }) trained ({ 19 }) weight ({ 20 }) vector ({ 21 }) for ({ 22 }) features ({ 23 }) . ({ 24 }) 
# Sentence pair (488) source length 14 target length 14 alignment score : 0.0043487
We conduct this by evaluating the scores for all possible assignment of senses . 
NULL ({ }) We ({ 1 }) conduct ({ 2 }) this ({ 3 }) by ({ 4 }) evaluating ({ 5 }) the ({ 6 }) scores ({ 7 }) for ({ 8 }) all ({ 9 }) possible ({ 10 }) assignment ({ 11 }) of ({ 12 }) senses ({ 13 }) . ({ 14 }) 
# Sentence pair (489) source length 11 target length 11 alignment score : 0.0257216
Let us start from the dependency between confidence and bank . 
NULL ({ }) Let ({ 1 }) us ({ 2 }) start ({ 3 }) from ({ 4 }) the ({ 5 }) dependency ({ 6 }) between ({ 7 }) confidence ({ 8 }) and ({ 9 }) bank ({ 10 }) . ({ 11 }) 
# Sentence pair (490) source length 49 target length 47 alignment score : 5.56509e-14
The first intuition would be that confidence( n )#2 is strongly related to a group or an institution ( financial bank ) but not related to natural landscape ( river bank ) , while confidence( n )#1 depends mostly on persons and not on other entities . 
NULL ({ }) The ({ 1 }) first ({ 2 }) intuition ({ 3 }) would ({ 4 }) be ({ 5 }) that ({ 6 }) confidence( ({ 7 }) n ({ 8 }) )#2 ({ 9 }) is ({ 10 }) strongly ({ 11 }) related ({ 12 }) to ({ 13 }) a ({ 14 }) group ({ 15 }) or ({ 16 }) an ({ 17 }) institution ({ 18 }) ( ({ 19 }) financial ({ 20 }) bank ({ 21 }) ) ({ 22 }) , ({ }) but ({ 23 }) is ({ }) unrelated ({ 24 25 }) to ({ 26 }) a ({ }) natural ({ 27 }) landscape ({ 28 }) ( ({ 29 }) river ({ 30 }) bank ({ 31 }) ) ({ 32 }) , ({ 33 }) while ({ 34 }) confidence( ({ 35 }) n ({ 36 }) )#1 ({ 37 }) depends ({ 38 }) mostly ({ 39 }) on ({ 40 }) persons ({ 41 }) and ({ 42 }) not ({ 43 }) on ({ 44 }) other ({ 45 }) entities ({ 46 }) . ({ 47 }) 
# Sentence pair (491) source length 31 target length 30 alignment score : 3.465e-07
Because bank does not have a " person " meaning , the weight of confidence( n )#2-bank( n )#1 is expected to be higher than other possible sense bigrams . 
NULL ({ }) Because ({ 1 }) bank ({ 2 }) does ({ 3 }) not ({ 4 }) have ({ 5 }) a ({ 6 }) " ({ 7 }) person ({ 8 }) " ({ 9 }) meaning ({ 10 }) , ({ 11 }) the ({ 12 }) weight ({ 13 }) of ({ 14 }) confidence( ({ 15 }) n ({ 16 }) )#2-bank( ({ 17 }) n ({ 18 }) )#1 ({ 19 }) is ({ 20 }) expected ({ 21 }) to ({ 22 }) be ({ 23 }) higher ({ 24 }) than ({ 25 }) for ({ }) other ({ 26 }) possible ({ 27 }) sense ({ 28 }) bigrams ({ 29 }) . ({ 30 }) 
# Sentence pair (492) source length 14 target length 14 alignment score : 0.00445815
A similar argument can be made for the dependency between destroy and confidence . 
NULL ({ }) A ({ 1 }) similar ({ 2 }) argument ({ 3 }) can ({ 4 }) be ({ 5 }) made ({ 6 }) for ({ 7 }) the ({ 8 }) dependency ({ 9 }) between ({ 10 }) destroy ({ 11 }) and ({ 12 }) confidence ({ 13 }) . ({ 14 }) 
# Sentence pair (493) source length 33 target length 33 alignment score : 1.11436e-06
We can assume that destroy( v )#1 is usually associated with real objects , whereas destroy( v )#2 can take either a real entity or an abstract thing as its direct object . 
NULL ({ }) We ({ 1 }) can ({ 2 }) assume ({ 3 }) that ({ 4 }) destroy( ({ 5 }) v ({ 6 }) )#1 ({ 7 }) is ({ 8 }) usually ({ 9 }) associated ({ 10 }) with ({ 11 }) real ({ 12 }) objects ({ 13 }) , ({ 14 }) whereas ({ 15 }) destroy( ({ 16 }) v ({ 17 }) )#2 ({ 18 }) can ({ 19 }) take ({ 20 }) either ({ 21 }) a ({ 22 }) real ({ 23 }) entity ({ 24 }) or ({ 25 }) an ({ 26 }) abstract ({ 27 }) thing ({ 28 }) as ({ 29 }) its ({ 30 }) direct ({ 31 }) object ({ 32 }) . ({ 33 }) 
# Sentence pair (494) source length 35 target length 32 alignment score : 3.70668e-09
Given confidence does not have an " object " meaning , the weights of destroy( v )#2-confidence( n )#1 and destroy( v )#2-confidence( n )#2 would be the largest among others . 
NULL ({ }) Given ({ 1 }) confidence ({ 2 }) does ({ 3 }) not ({ 4 }) have ({ 5 }) an ({ 6 }) " ({ 7 }) object ({ 8 }) " ({ 9 }) meaning ({ 10 }) , ({ 11 }) the ({ 12 }) weights ({ 13 }) of ({ 14 }) destroy( ({ 15 }) v ({ 16 }) )#2-confidence( ({ 17 }) n ({ 18 }) )#1 ({ 19 }) and ({ 20 }) destroy( ({ 21 }) v ({ 22 }) )#2-confidence( ({ 23 }) n ({ 24 }) )#2 ({ 25 }) would ({ 26 }) be ({ 27 }) the ({ 28 }) largest ({ 29 }) [largest ({ }) what ({ }) ?] ({ }) among ({ 30 }) others ({ 31 }) . ({ 32 }) 
# Sentence pair (495) source length 44 target length 44 alignment score : 3.85026e-08
Finally , given all scores for these sense dependencies , we can evaluate the overall score for the sentence , and see / MATHdestroy( v )#2 , confidence( n )#2 , bank( n )#1 / MATH is the most probable assignment of senses . 
NULL ({ }) Finally ({ 1 }) , ({ 2 }) given ({ 3 }) all ({ 4 }) scores ({ 5 }) for ({ 6 }) these ({ 7 }) sense ({ 8 }) dependencies ({ 9 }) , ({ 10 }) we ({ 11 }) can ({ 12 }) evaluate ({ 13 }) the ({ 14 }) overall ({ 15 }) score ({ 16 }) for ({ 17 }) the ({ 18 }) sentence ({ 19 }) , ({ 20 }) and ({ 21 }) see ({ 22 }) / ({ 23 }) MATHdestroy( ({ 24 }) v ({ 25 }) )#2 ({ 26 }) , ({ 27 }) confidence( ({ 28 }) n ({ 29 }) )#2 ({ 30 }) , ({ 31 }) bank( ({ 32 }) n ({ 33 }) )#1 ({ 34 }) / ({ 35 }) MATH ({ 36 }) is ({ 37 }) the ({ 38 }) most ({ 39 }) probable ({ 40 }) assignment ({ 41 }) of ({ 42 }) senses ({ 43 }) . ({ 44 }) 
# Sentence pair (496) source length 27 target length 27 alignment score : 7.72621e-05
Practically , specific bigrams of synsets such as confidence( n )#2-bank( n )#1 and destroy( v )#2-confidence( n )#2 may not appear in the training data . 
NULL ({ }) Practically ({ 1 }) , ({ 2 }) specific ({ 3 }) bigrams ({ 4 }) of ({ 5 }) synsets ({ 6 }) such ({ 7 }) as ({ 8 }) confidence( ({ 9 }) n ({ 10 }) )#2-bank( ({ 11 }) n ({ 12 }) )#1 ({ 13 }) and ({ 14 }) destroy( ({ 15 }) v ({ 16 }) )#2-confidence( ({ 17 }) n ({ 18 }) )#2 ({ 19 }) may ({ 20 }) not ({ 21 }) appear ({ 22 }) in ({ 23 }) the ({ 24 }) training ({ 25 }) data ({ 26 }) . ({ 27 }) 
# Sentence pair (497) source length 14 target length 14 alignment score : 0.00944253
In this case , sense bigrams combined with coarser sense labels work effectively . 
NULL ({ }) In ({ 1 }) this ({ 2 }) case ({ 3 }) , ({ 4 }) sense ({ 5 }) bigrams ({ 6 }) combined ({ 7 }) with ({ 8 }) coarser ({ 9 }) sense ({ 10 }) labels ({ 11 }) work ({ 12 }) effectively ({ 13 }) . ({ 14 }) 
# Sentence pair (498) source length 40 target length 40 alignment score : 3.54693e-09
For example , if there exist synset bigrams such as destroy( v )#2-affection( n )#1 in the training data , the model can still perform the disambiguation process properly by considering a generalized synset-supersense bigram destroy( v )#2-noun .feeling . 
NULL ({ }) For ({ 1 }) example ({ 2 }) , ({ 3 }) if ({ 4 }) there ({ 5 }) are ({ 6 }) synset ({ 7 }) bigrams ({ 8 }) such ({ 9 }) as ({ 10 }) destroy( ({ 11 }) v ({ 12 }) )#2-affection( ({ 13 }) n ({ 14 }) )#1 ({ 15 }) in ({ 16 }) the ({ 17 }) training ({ 18 }) data ({ 19 }) , ({ 20 }) the ({ 21 }) model ({ 22 }) can ({ 23 }) still ({ 24 }) perform ({ 25 }) the ({ 26 }) disambiguation ({ 27 }) process ({ 28 }) properly ({ 29 }) by ({ 30 }) considering ({ 31 }) a ({ 32 }) generalized ({ 33 }) synset-supersense ({ 34 }) bigram ({ 35 }) destroy( ({ 36 }) v ({ 37 }) )#2-noun ({ 38 }) .feeling ({ 39 }) . ({ 40 }) 
# Sentence pair (499) source length 13 target length 13 alignment score : 0.00283406
The detailed description of sense bigrams are given in Section 4 .7 . 
NULL ({ }) The ({ 1 }) detailed ({ 2 }) description ({ 3 }) of ({ 4 }) sense ({ 5 }) bigrams ({ 6 }) are ({ 7 }) provided ({ 8 }) in ({ 9 }) Section ({ 10 }) 4 ({ 11 }) .7 ({ 12 }) . ({ 13 }) 
# Sentence pair (500) source length 45 target length 45 alignment score : 3.10918e-08
Using the information in the WordNet , we make use of four sense labels for each word : a synset / MATH , two general synsets / MATH and / MATH , and a supersense / MATH , which we introduced in Section 2 . 
NULL ({ }) Using ({ 1 }) the ({ 2 }) information ({ 3 }) in ({ 4 }) the ({ 5 }) WordNet ({ 6 }) , ({ 7 }) we ({ 8 }) make ({ 9 }) use ({ 10 }) of ({ 11 }) four ({ 12 }) sense ({ 13 }) labels ({ 14 }) for ({ 15 }) each ({ 16 }) word ({ 17 }) : ({ 18 }) a ({ 19 }) synset ({ 20 }) / ({ 21 }) MATH ({ 22 }) , ({ 23 }) two ({ 24 }) general ({ 25 }) synsets ({ 26 }) / ({ 27 }) MATH ({ 28 }) and ({ 29 }) / ({ 30 }) MATH ({ 31 }) , ({ 32 }) and ({ 33 }) a ({ 34 }) supersense ({ 35 }) / ({ 36 }) MATH ({ 37 }) , ({ 38 }) which ({ 39 }) we ({ 40 }) introduced ({ 41 }) in ({ 42 }) Section ({ 43 }) 2 ({ 44 }) . ({ 45 }) 
# Sentence pair (501) source length 21 target length 20 alignment score : 3.12065e-05
These labels represent word senses at various levels , and to be combined with the vertex and edge features . 
NULL ({ }) These ({ 1 }) labels ({ 2 }) represent ({ 3 }) word ({ 4 }) senses ({ 5 }) at ({ 6 }) various ({ 7 }) levels ({ 8 }) , ({ 9 }) and ({ 10 }) are ({ }) to ({ 11 }) be ({ 12 }) combined ({ 13 }) with ({ 14 }) the ({ 15 }) vertex ({ 16 }) and ({ 17 }) edge ({ 18 }) features ({ 19 }) . ({ 20 }) 
# Sentence pair (502) source length 30 target length 30 alignment score : 6.8075e-06
We hereinafter distinguish each sense label by putting one of the prefixes WS , G1 , G2 , and SS , as in WS :bank#1 and SS :noun .group . 
NULL ({ }) We ({ 1 }) hereafter ({ 2 }) distinguish ({ 3 }) each ({ 4 }) sense ({ 5 }) label ({ 6 }) by ({ 7 }) putting ({ 8 }) one ({ 9 }) of ({ 10 }) the ({ 11 }) prefixes ({ 12 }) WS ({ 13 }) , ({ 14 }) G1 ({ 15 }) , ({ 16 }) G2 ({ 17 }) , ({ 18 }) and ({ 19 }) SS ({ 20 }) , ({ 21 }) as ({ 22 }) in ({ 23 }) WS ({ 24 }) :bank#1 ({ 25 }) and ({ 26 }) SS ({ 27 }) :noun ({ 28 }) .group ({ 29 }) . ({ 30 }) 
# Sentence pair (503) source length 12 target length 12 alignment score : 0.0179316
The examples of these sense labels are shown in Table 4 . 
NULL ({ }) The ({ 1 }) examples ({ 2 }) of ({ 3 }) these ({ 4 }) sense ({ 5 }) labels ({ 6 }) are ({ 7 }) shown ({ 8 }) in ({ 9 }) Table ({ 10 }) 4 ({ 11 }) . ({ 12 }) 
# Sentence pair (504) source length 26 target length 26 alignment score : 9.9438e-05
In our model , we combine the synset and supersense labels with the vertex features , and all four sense labels with the edge features . 
NULL ({ }) In ({ 1 }) our ({ 2 }) model ({ 3 }) , ({ 4 }) we ({ 5 }) combine ({ 6 }) the ({ 7 }) synset ({ 8 }) and ({ 9 }) supersense ({ 10 }) labels ({ 11 }) with ({ 12 }) the ({ 13 }) vertex ({ 14 }) features ({ 15 }) , ({ 16 }) and ({ 17 }) all ({ 18 }) four ({ 19 }) sense ({ 20 }) labels ({ 21 }) with ({ 22 }) the ({ 23 }) edge ({ 24 }) features ({ 25 }) . ({ 26 }) 
# Sentence pair (505) source length 24 target length 24 alignment score : 9.05455e-05
We denote the set of sense labels for vertex features by / MATH , and the one for edge features by / MATH . 
NULL ({ }) We ({ 1 }) denote ({ 2 }) the ({ 3 }) set ({ 4 }) of ({ 5 }) sense ({ 6 }) labels ({ 7 }) for ({ 8 }) vertex ({ 9 }) features ({ 10 }) by ({ 11 }) / ({ 12 }) MATH ({ 13 }) , ({ 14 }) and ({ 15 }) the ({ 16 }) one ({ 17 }) for ({ 18 }) edge ({ 19 }) features ({ 20 }) by ({ 21 }) / ({ 22 }) MATH ({ 23 }) . ({ 24 }) 
# Sentence pair (506) source length 29 target length 29 alignment score : 2.10004e-05
Each of these sense labels is combined with the contextual information in the vertex features , whereas all possible combinations of two sense labels comprise the edge features . 
NULL ({ }) Each ({ 1 }) of ({ 2 }) these ({ 3 }) sense ({ 4 }) labels ({ 5 }) is ({ 6 }) combined ({ 7 }) with ({ 8 }) the ({ 9 }) contextual ({ 10 }) information ({ 11 }) in ({ 12 }) the ({ 13 }) vertex ({ 14 }) features ({ 15 }) , ({ 16 }) whereas ({ 17 }) all ({ 18 }) possible ({ 19 }) combinations ({ 20 }) of ({ 21 }) two ({ 22 }) sense ({ 23 }) labels ({ 24 }) comprise ({ 25 }) the ({ 26 }) edge ({ 27 }) features ({ 28 }) . ({ 29 }) 
# Sentence pair (507) source length 19 target length 21 alignment score : 1.26768e-10
We implement as vertex features a set of typical contextual features widely used in a lot of supervised WSD models . 
NULL ({ 15 17 }) We ({ 1 }) implement ({ 2 }) as ({ 3 }) vertex ({ 4 }) features ({ 5 }) a ({ 6 }) set ({ 7 }) of ({ 8 }) typical ({ 9 }) contextual ({ 10 }) features ({ 11 }) widely ({ 12 }) used ({ 13 }) in ({ 14 }) many ({ 16 }) supervised ({ 18 }) WSD ({ 19 }) models ({ 20 }) . ({ 21 }) 
# Sentence pair (508) source length 16 target length 16 alignment score : 0.000762393
Most of these features are those used by with the exception of the syntactic features . 
NULL ({ }) Most ({ 1 }) of ({ 2 }) these ({ 3 }) features ({ 4 }) are ({ 5 }) those ({ 6 }) used ({ 7 }) by ({ 8 }) with ({ 9 }) the ({ 10 }) exception ({ 11 }) of ({ 12 }) the ({ 13 }) syntactic ({ 14 }) features ({ 15 }) . ({ 16 }) 
# Sentence pair (509) source length 39 target length 43 alignment score : 3.44698e-26
In order to see whether the sense dependency features are certainly effective or not , we include as vertex features the word forms , lemmas , and parts of speech of both the parent and the child words in the dependency tree . 
NULL ({ 6 10 }) In ({ 1 }) order ({ 2 }) to ({ 3 }) see ({ 4 }) the ({ }) efficiency ({ 5 }) of ({ }) sense ({ 7 }) dependency ({ 8 }) features ({ 9 }) , ({ 15 }) we ({ 16 }) include ({ 17 }) as ({ 18 }) vertex ({ 19 }) features ({ 20 }) the ({ 21 }) word ({ 22 }) forms ({ 23 }) , ({ 24 }) lemmas ({ 11 12 13 14 25 }) , ({ 26 }) and ({ 27 }) parts ({ 28 }) of ({ 29 }) speech ({ 30 }) of ({ 31 }) both ({ 32 }) the ({ 33 }) parent ({ 34 }) and ({ 35 }) the ({ 36 }) child ({ 37 }) words ({ 38 }) in ({ 39 }) the ({ 40 }) dependency ({ 41 }) tree ({ 42 }) . ({ 43 }) 
# Sentence pair (510) source length 19 target length 19 alignment score : 0.000191732
These features provide the syntactic information of the parent and child words , but are not semantically disambiguated . 
NULL ({ }) These ({ 1 }) features ({ 2 }) provide ({ 3 }) the ({ 4 }) syntactic ({ 5 }) information ({ 6 }) of ({ 7 }) the ({ 8 }) parent ({ 9 }) and ({ 10 }) child ({ 11 }) words ({ 12 }) , ({ 13 }) but ({ 14 }) are ({ 15 }) not ({ 16 }) semantically ({ 17 }) disambiguated ({ 18 }) . ({ 19 }) 
# Sentence pair (511) source length 32 target length 32 alignment score : 7.61523e-07
Therefore , if the sense bigram features work effectively over these features , it clearly shows that there exist instances that cannot be disambiguated without considering the interdependency of word senses . 
NULL ({ }) Therefore ({ 1 }) , ({ 2 }) if ({ 3 }) the ({ 4 }) sense ({ 5 }) bigram ({ 6 }) features ({ 7 }) work ({ 8 }) effectively ({ 9 }) over ({ 10 }) these ({ 11 }) features ({ 12 }) , ({ 13 }) it ({ 14 }) clearly ({ 15 }) shows ({ 16 }) that ({ 17 }) there ({ 18 }) exist ({ 19 }) instances ({ 20 }) that ({ 21 }) cannot ({ 22 }) be ({ 23 }) disambiguated ({ 24 }) without ({ 25 }) considering ({ 26 }) the ({ 27 }) interdependency ({ 28 }) of ({ 29 }) word ({ 30 }) senses ({ 31 }) . ({ 32 }) 
# Sentence pair (512) source length 37 target length 37 alignment score : 1.02196e-06
The list of vertex features also includes the information of both the preceding and following words , which in the linear-chain model plays the same role as the parent and child information in the tree-structured model . 
NULL ({ }) The ({ 1 }) list ({ 2 }) of ({ 3 }) vertex ({ 4 }) features ({ 5 }) also ({ 6 }) includes ({ 7 }) the ({ 8 }) information ({ 9 }) of ({ 10 }) both ({ 11 }) the ({ 12 }) preceding ({ 13 }) and ({ 14 }) following ({ 15 }) words ({ 16 }) , ({ 17 }) which ({ 18 }) in ({ 19 }) the ({ 20 }) linear-chain ({ 21 }) model ({ 22 }) plays ({ 23 }) the ({ 24 }) same ({ 25 }) role ({ 26 }) as ({ 27 }) the ({ 28 }) parent ({ 29 }) and ({ 30 }) child ({ 31 }) information ({ 32 }) in ({ 33 }) the ({ 34 }) tree-structured ({ 35 }) model ({ 36 }) . ({ 37 }) 
# Sentence pair (513) source length 17 target length 17 alignment score : 0.00214103
Below is the list of contextual information used for the vertex features in the synset-based model . 
NULL ({ }) Below ({ 1 }) is ({ 2 }) the ({ 3 }) list ({ 4 }) of ({ 5 }) contextual ({ 6 }) information ({ 7 }) used ({ 8 }) for ({ 9 }) the ({ 10 }) vertex ({ 11 }) features ({ 12 }) in ({ 13 }) the ({ 14 }) synset-based ({ 15 }) model ({ 16 }) . ({ 17 }) 
# Sentence pair (514) source length 9 target length 9 alignment score : 0.031682
We refer to these features as / MATH . 
NULL ({ }) We ({ 1 }) refer ({ 2 }) to ({ 3 }) these ({ 4 }) features ({ 5 }) as ({ 6 }) / ({ 7 }) MATH ({ 8 }) . ({ 9 }) 
# Sentence pair (515) source length 16 target length 16 alignment score : 0.00407808
- Word form ( WF ) : word form as it appears in a text . 
NULL ({ }) - ({ 1 }) Word ({ 2 }) form ({ 3 }) ( ({ 4 }) WF ({ 5 }) ) ({ 6 }) : ({ 7 }) word ({ 8 }) form ({ 9 }) as ({ 10 }) it ({ 11 }) appears ({ 12 }) in ({ 13 }) a ({ 14 }) text ({ 15 }) . ({ 16 }) 
# Sentence pair (516) source length 13 target length 13 alignment score : 0.0166297
- Global context ( GC ) : bag-of-words within a 60-word window . 
NULL ({ }) - ({ 1 }) Global ({ 2 }) context ({ 3 }) ( ({ 4 }) GC ({ 5 }) ) ({ 6 }) : ({ 7 }) bag-of-words ({ 8 }) within ({ 9 }) a ({ 10 }) 60-word ({ 11 }) window ({ 12 }) . ({ 13 }) 
# Sentence pair (517) source length 44 target length 44 alignment score : 9.07902e-09
- Local PoS ( LP ) : / MATH , / MATH , / MATH , / MATH , / MATH , / MATH , and / MATH , where / MATH in / MATH denotes the relative position to the target word . 
NULL ({ }) - ({ 1 }) Local ({ 2 }) PoS ({ 3 }) ( ({ 4 }) LP ({ 5 }) ) ({ 6 }) : ({ 7 }) / ({ 8 }) MATH ({ 9 }) , ({ 10 }) / ({ 11 }) MATH ({ 12 }) , ({ 13 }) / ({ 14 }) MATH ({ 15 }) , ({ 16 }) / ({ 17 }) MATH ({ 18 }) , ({ 19 }) / ({ 20 }) MATH ({ 21 }) , ({ 22 }) / ({ 23 }) MATH ({ 24 }) , ({ 25 }) and ({ 26 }) / ({ 27 }) MATH ({ 28 }) , ({ 29 }) where ({ 30 }) / ({ 31 }) MATH ({ 32 }) in ({ 33 }) / ({ 34 }) MATH ({ 35 }) denotes ({ 36 }) the ({ 37 }) relative ({ 38 }) position ({ 39 }) to ({ 40 }) the ({ 41 }) target ({ 42 }) word ({ 43 }) . ({ 44 }) 
# Sentence pair (518) source length 72 target length 72 alignment score : 5.10399e-14
- Local context ( LC ) : / MATH , / MATH , / MATH , / MATH , / MATH , / MATH , / MATH , / MATH , / MATH , / MATH , / MATH , and / MATH , where / MATH denotes the word at the relative position / MATH , and / MATH the n-gram from the relative position / MATH to / MATH . 
NULL ({ }) - ({ 1 }) Local ({ 2 }) context ({ 3 }) ( ({ 4 }) LC ({ 5 }) ) ({ 6 }) : ({ 7 }) / ({ 8 }) MATH ({ 9 }) , ({ 10 }) / ({ 11 }) MATH ({ 12 }) , ({ 13 }) / ({ 14 }) MATH ({ 15 }) , ({ 16 }) / ({ 17 }) MATH ({ 18 }) , ({ 19 }) / ({ 20 }) MATH ({ 21 }) , ({ 22 }) / ({ 23 }) MATH ({ 24 }) , ({ 25 }) / ({ 26 }) MATH ({ 27 }) , ({ 28 }) / ({ 29 }) MATH ({ 30 }) , ({ 31 }) / ({ 32 }) MATH ({ 33 }) , ({ 34 }) / ({ 35 }) MATH ({ 36 }) , ({ 37 }) / ({ 38 }) MATH ({ 39 }) , ({ 40 }) and ({ 41 }) / ({ 42 }) MATH ({ 43 }) , ({ 44 }) where ({ 45 }) / ({ 46 }) MATH ({ 47 }) denotes ({ 48 }) the ({ 49 }) word ({ 50 }) at ({ 51 }) the ({ 52 }) relative ({ 53 }) position ({ 54 }) / ({ 55 }) MATH ({ 56 }) , ({ 57 }) and ({ 58 }) / ({ 59 }) MATH ({ 60 }) the ({ 61 }) n-gram ({ 62 }) from ({ 63 }) the ({ 64 }) relative ({ 65 }) position ({ 66 }) / ({ 67 }) MATH ({ 68 }) to ({ 69 }) / ({ 70 }) MATH ({ 71 }) . ({ 72 }) 
# Sentence pair (519) source length 23 target length 23 alignment score : 0.000111335
- Syntactic context ( SC ) : word forms , lemmas , and parts of speech of the parent and child words . 
NULL ({ }) - ({ 1 }) Syntactic ({ 2 }) context ({ 3 }) ( ({ 4 }) SC ({ 5 }) ) ({ 6 }) : ({ 7 }) word ({ 8 }) forms ({ 9 }) , ({ 10 }) lemmas ({ 11 }) , ({ 12 }) and ({ 13 }) parts ({ 14 }) of ({ 15 }) speech ({ 16 }) of ({ 17 }) the ({ 18 }) parent ({ 19 }) and ({ 20 }) child ({ 21 }) words ({ 22 }) . ({ 23 }) 
# Sentence pair (520) source length 29 target length 28 alignment score : 5.26805e-06
Using this contextual information and the set of vertex labels / MATH , we construct a set of features on a vertex / MATH by / MATH . 
NULL ({ }) Using ({ 1 }) this ({ 2 }) contextual ({ 3 }) information ({ 4 }) , ({ }) and ({ 5 }) the ({ 6 }) set ({ 7 }) of ({ 8 }) vertex ({ 9 }) labels ({ 10 }) / ({ 11 }) MATH ({ 12 }) , ({ 13 }) we ({ 14 }) construct ({ 15 }) a ({ 16 }) set ({ 17 }) of ({ 18 }) features ({ 19 }) on ({ 20 }) a ({ 21 }) vertex ({ 22 }) / ({ 23 }) MATH ({ 24 }) by ({ 25 }) / ({ 26 }) MATH ({ 27 }) . ({ 28 }) 
# Sentence pair (521) source length 17 target length 17 alignment score : 0.000789118
Additionally , we include the sense ranking feature ( see Section 2 .3 for detail ) . 
NULL ({ }) Additionally ({ 1 }) , ({ 2 }) we ({ 3 }) include ({ 4 }) the ({ 5 }) sense ({ 6 }) ranking ({ 7 }) feature ({ 8 }) ( ({ 9 }) see ({ 10 }) Section ({ 11 }) 2 ({ 12 }) .3 ({ 13 }) for ({ 14 }) detail ({ 15 }) ) ({ 16 }) . ({ 17 }) 
# Sentence pair (522) source length 17 target length 15 alignment score : 1.10523e-06
Note that this feature is not combined with any sense labels nor contextual information . 
NULL ({ }) Note ({ 1 }) that ({ 2 }) this ({ 3 }) feature ({ 4 }) is ({ 5 }) not ({ 6 }) combined ({ 7 }) with ({ 8 }) any ({ 9 }) sense ({ 10 }) label ({ 11 }) nor ({ 12 }) with ({ }) any ({ }) contextual ({ 13 }) information ({ 14 }) . ({ 15 }) 
# Sentence pair (523) source length 38 target length 37 alignment score : 3.23575e-13
For the supersense-based model , we use vertex features based on , which includes some features from the named entity recognition literature such as the word shape features along with the standard feature set for WSD . 
NULL ({ 24 }) For ({ 1 }) the ({ 2 }) supersense-based ({ 3 }) model ({ 4 }) , ({ 5 }) we ({ 6 }) use ({ 7 }) vertex ({ 8 }) features ({ 9 }) based ({ 10 }) on ({ 11 }) , ({ 12 }) which ({ 13 }) include ({ 14 }) some ({ 15 }) features ({ 16 }) from ({ 17 }) the ({ 18 }) named ({ 19 }) entity ({ 20 }) recognition ({ 21 }) literature ({ 22 }) , ({ }) including ({ 23 }) the ({ 25 }) word ({ 26 }) shape ({ 27 }) features ({ 28 }) , ({ }) along ({ 29 }) with ({ 30 }) the ({ 31 }) standard ({ 32 }) feature ({ 33 }) set ({ 34 }) for ({ 35 }) WSD ({ 36 }) . ({ 37 }) 
# Sentence pair (524) source length 13 target length 13 alignment score : 0.0127536
As the sense frequency information , we use the first sense feature . 
NULL ({ }) As ({ 1 }) the ({ 2 }) sense ({ 3 }) frequency ({ 4 }) information ({ 5 }) , ({ 6 }) we ({ 7 }) use ({ 8 }) the ({ 9 }) first ({ 10 }) sense ({ 11 }) feature ({ 12 }) . ({ 13 }) 
# Sentence pair (525) source length 31 target length 31 alignment score : 1.03212e-10
Unlike in the synset-based model , we do not incorporate the syntactic information of the parent and child words , since it has been reported not to improve the performance . 
NULL ({ }) Unlike ({ 1 }) in ({ 2 }) the ({ 3 }) synset-based ({ 4 }) model ({ 5 }) , ({ 6 }) we ({ 7 }) do ({ 8 }) not ({ 9 }) incorporate ({ 10 }) the ({ 11 }) syntactic ({ 12 }) information ({ 13 }) of ({ 14 }) the ({ 15 }) parent ({ 16 }) and ({ 17 }) child ({ 18 }) words ({ 19 }) , ({ 20 }) since ({ 21 }) it ({ 22 }) has ({ 23 }) not ({ 26 }) been ({ 24 }) reported ({ 25 }) to ({ 27 }) improve ({ 28 }) the ({ 29 }) performance ({ 30 }) . ({ 31 }) 
# Sentence pair (526) source length 14 target length 14 alignment score : 0.00804978
We design a set of edge features that represents the inter-word sense dependencies . 
NULL ({ }) We ({ 1 }) design ({ 2 }) a ({ 3 }) set ({ 4 }) of ({ 5 }) edge ({ 6 }) features ({ 7 }) that ({ 8 }) represents ({ 9 }) the ({ 10 }) inter-word ({ 11 }) sense ({ 12 }) dependencies ({ 13 }) . ({ 14 }) 
# Sentence pair (527) source length 13 target length 13 alignment score : 0.00883234
For each edge , we define the sense bigram features / MATH . 
NULL ({ }) For ({ 1 }) each ({ 2 }) edge ({ 3 }) , ({ 4 }) we ({ 5 }) define ({ 6 }) the ({ 7 }) sense ({ 8 }) bigram ({ 9 }) features ({ 10 }) / ({ 11 }) MATH ({ 12 }) . ({ 13 }) 
# Sentence pair (528) source length 49 target length 49 alignment score : 1.48366e-08
Moreover , in addition to these simple bigrams , we define two kinds of combined bigrams : the sense bigrams with dependency relation labels ( e.g. WS :confidence#2-( NMOD )-WS :bank#1 ) , and the sense bigrams with removed words in between ( e.g. WS :confidence#2-in-WS :bank#1 ) . 
NULL ({ }) Moreover ({ 1 }) , ({ 2 }) in ({ 3 }) addition ({ 4 }) to ({ 5 }) these ({ 6 }) simple ({ 7 }) bigrams ({ 8 }) , ({ 9 }) we ({ 10 }) define ({ 11 }) two ({ 12 }) kinds ({ 13 }) of ({ 14 }) combined ({ 15 }) bigrams ({ 16 }) : ({ 17 }) the ({ 18 }) sense ({ 19 }) bigrams ({ 20 }) with ({ 21 }) dependency ({ 22 }) relation ({ 23 }) labels ({ 24 }) ( ({ 25 }) e.g. ({ 26 }) WS ({ 27 }) :confidence#2-( ({ 28 }) NMOD ({ 29 }) )-WS ({ 30 }) :bank#1 ({ 31 }) ) ({ 32 }) , ({ 33 }) and ({ 34 }) the ({ 35 }) sense ({ 36 }) bigrams ({ 37 }) with ({ 38 }) removed ({ 39 }) words ({ 40 }) in ({ 41 }) between ({ 42 }) ( ({ 43 }) e.g. ({ 44 }) WS ({ 45 }) :confidence#2-in-WS ({ 46 }) :bank#1 ({ 47 }) ) ({ 48 }) . ({ 49 }) 
# Sentence pair (529) source length 13 target length 13 alignment score : 0.00303914
Consequently , the number of features for each edge is / MATH . 
NULL ({ }) Consequently ({ 1 }) , ({ 2 }) the ({ 3 }) number ({ 4 }) of ({ 5 }) features ({ 6 }) for ({ 7 }) each ({ 8 }) edge ({ 9 }) is ({ 10 }) / ({ 11 }) MATH ({ 12 }) . ({ 13 }) 
# Sentence pair (530) source length 15 target length 13 alignment score : 1.39636e-05
In this section , we introduce corpora we use for the evaluation . 
NULL ({ }) In ({ 1 }) this ({ 2 }) section ({ 3 }) , ({ 4 }) we ({ 5 }) introduce ({ 6 }) corpora ({ 7 }) that ({ }) we ({ 8 }) have ({ }) used ({ 9 }) for ({ 10 }) the ({ 11 }) evaluation ({ 12 }) . ({ 13 }) 
# Sentence pair (531) source length 27 target length 28 alignment score : 1.56816e-07
SemCor is a corpus , in which all content words are annotated with the WordNet synsets , and consists of balanced 352 files from the Brown Corpus . 
NULL ({ 5 }) SemCor ({ 1 }) is ({ 2 }) a ({ 3 }) corpus ({ 4 }) in ({ 6 }) which ({ 7 }) all ({ 8 }) content ({ 9 }) words ({ 10 }) are ({ 11 }) annotated ({ 12 }) with ({ 13 }) the ({ 14 }) WordNet ({ 15 }) synsets ({ 16 }) , ({ 17 }) and ({ 18 }) consists ({ 19 }) of ({ 20 }) balanced ({ 21 }) 352 ({ 22 }) files ({ 23 }) from ({ 24 }) the ({ 25 }) Brown ({ 26 }) Corpus ({ 27 }) . ({ 28 }) 
# Sentence pair (532) source length 15 target length 15 alignment score : 0.00276696
It is divided into three parts : brown1 , brown2 , and brownv sections . 
NULL ({ }) It ({ 1 }) is ({ 2 }) divided ({ 3 }) into ({ 4 }) three ({ 5 }) parts ({ 6 }) : ({ 7 }) brown1 ({ 8 }) , ({ 9 }) brown2 ({ 10 }) , ({ 11 }) and ({ 12 }) brownv ({ 13 }) sections ({ 14 }) . ({ 15 }) 
# Sentence pair (533) source length 30 target length 30 alignment score : 3.08718e-06
In brown1 and brown2 , all content words ( nouns , verbs , adjectives , and adverbs ) are semantically annotated , while in brownv only verbs are annotated . 
NULL ({ }) In ({ 1 }) brown1 ({ 2 }) and ({ 3 }) brown2 ({ 4 }) , ({ 5 }) all ({ 6 }) content ({ 7 }) words ({ 8 }) ( ({ 9 }) nouns ({ 10 }) , ({ 11 }) verbs ({ 12 }) , ({ 13 }) adjectives ({ 14 }) , ({ 15 }) and ({ 16 }) adverbs ({ 17 }) ) ({ 18 }) are ({ 19 }) semantically ({ 20 }) annotated ({ 21 }) , ({ 22 }) while ({ 23 }) in ({ 24 }) brownv ({ 25 }) only ({ 26 }) verbs ({ 27 }) are ({ 28 }) annotated ({ 29 }) . ({ 30 }) 
# Sentence pair (534) source length 71 target length 71 alignment score : 3.66618e-12
Also , we use two data sets from the Senseval ( International Workshop on Evaluating Word Sense Disambiguation Systems ) exercises : the Senseval-2 English all-words task test set , consisting of three articles from the Wall Street Journal , and the Senseval-3 English all-words task test set , consisting of two articles from the Wall Street Journal and a fiction excerpt from the unannotated portion of the Brown corpus . 
NULL ({ }) Also ({ 1 }) , ({ 2 }) we ({ 3 }) use ({ 4 }) two ({ 5 }) data ({ 6 }) sets ({ 7 }) from ({ 8 }) the ({ 9 }) Senseval ({ 10 }) ( ({ 11 }) International ({ 12 }) Workshop ({ 13 }) on ({ 14 }) Evaluating ({ 15 }) Word ({ 16 }) Sense ({ 17 }) Disambiguation ({ 18 }) Systems ({ 19 }) ) ({ 20 }) exercises ({ 21 }) : ({ 22 }) the ({ 23 }) Senseval-2 ({ 24 }) English ({ 25 }) all-words ({ 26 }) task ({ 27 }) test ({ 28 }) set ({ 29 }) , ({ 30 }) consisting ({ 31 }) of ({ 32 }) three ({ 33 }) articles ({ 34 }) from ({ 35 }) the ({ 36 }) Wall ({ 37 }) Street ({ 38 }) Journal ({ 39 }) , ({ 40 }) and ({ 41 }) the ({ 42 }) Senseval-3 ({ 43 }) English ({ 44 }) all-words ({ 45 }) task ({ 46 }) test ({ 47 }) set ({ 48 }) , ({ 49 }) consisting ({ 50 }) of ({ 51 }) two ({ 52 }) articles ({ 53 }) from ({ 54 }) the ({ 55 }) Wall ({ 56 }) Street ({ 57 }) Journal ({ 58 }) and ({ 59 }) a ({ 60 }) fiction ({ 61 }) excerpt ({ 62 }) from ({ 63 }) the ({ 64 }) unannotated ({ 65 }) portion ({ 66 }) of ({ 67 }) the ({ 68 }) Brown ({ 69 }) corpus ({ 70 }) . ({ 71 }) 
# Sentence pair (535) source length 41 target length 41 alignment score : 3.93675e-07
As the data sets for evaluation , we use the brown1 and brown2 sections ( denoted as SEM ) of SemCor , and the Senseval-2 and -3 all-words task test sets ( denoted as SE2 and SE3 , respectively ) . 
NULL ({ }) As ({ 1 }) the ({ 2 }) data ({ 3 }) sets ({ 4 }) for ({ 5 }) evaluation ({ 6 }) , ({ 7 }) we ({ 8 }) use ({ 9 }) the ({ 10 }) brown1 ({ 11 }) and ({ 12 }) brown2 ({ 13 }) sections ({ 14 }) ( ({ 15 }) denoted ({ 16 }) as ({ 17 }) SEM ({ 18 }) ) ({ 19 }) of ({ 20 }) SemCor ({ 21 }) , ({ 22 }) and ({ 23 }) the ({ 24 }) Senseval-2 ({ 25 }) and ({ 26 }) -3 ({ 27 }) all-words ({ 28 }) task ({ 29 }) test ({ 30 }) sets ({ 31 }) ( ({ 32 }) denoted ({ 33 }) as ({ 34 }) SE2 ({ 35 }) and ({ 36 }) SE3 ({ 37 }) , ({ 38 }) respectively ({ 39 }) ) ({ 40 }) . ({ 41 }) 
# Sentence pair (536) source length 12 target length 12 alignment score : 0.0117079
We use the converted versions annotated with WordNet 2 .0 synsets . 
NULL ({ }) We ({ 1 }) use ({ 2 }) the ({ 3 }) converted ({ 4 }) versions ({ 5 }) annotated ({ 6 }) with ({ 7 }) WordNet ({ 8 }) 2 ({ 9 }) .0 ({ 10 }) synsets ({ 11 }) . ({ 12 }) 
# Sentence pair (537) source length 15 target length 18 alignment score : 8.82243e-15
Note that these data sets are different from the originals in that multi-word expressions are already segmented . 
NULL ({ 2 11 12 }) These ({ 1 }) data ({ 4 }) sets ({ 5 }) are ({ 6 }) different ({ 7 }) from ({ 8 }) the ({ 9 }) originals ({ 10 }) because ({ 3 }) multi-word ({ 13 }) expressions ({ 14 }) are ({ 15 }) already ({ 16 }) segmented ({ 17 }) . ({ 18 }) 
# Sentence pair (538) source length 32 target length 37 alignment score : 9.1668e-19
However , on the other hand , our model cannot output any answers to multi-word expressions that have no directly corresponding WordNet synsets , because we treat expression as one unit in the process of WSD . 
NULL ({ 4 7 }) However ({ 1 }) , ({ 2 }) our ({ 8 }) model ({ 9 }) cannot ({ 10 }) output ({ 11 }) any ({ 12 }) answers ({ 3 5 6 13 }) to ({ 14 }) multi-word ({ 15 }) expressions ({ 16 }) that ({ 17 }) have ({ 18 }) no ({ 19 }) directly ({ 20 }) corresponding ({ 21 }) WordNet ({ 22 }) synsets ({ 23 }) , ({ 24 }) because ({ 25 }) we ({ 26 }) treat ({ 27 }) expression ({ 28 }) as ({ 29 }) one ({ 30 }) unit ({ 31 }) in ({ 32 }) the ({ 33 }) process ({ 34 }) of ({ 35 }) WSD ({ 36 }) . ({ 37 }) 
# Sentence pair (539) source length 46 target length 41 alignment score : 1.31876e-14
For example , the multi-word expression tear-filled is treated as one instance but not tagged with any WordNet synsets in the converted corpus , while in the original corpus it is tagged with two WordNet synsets for tear and filled . 
NULL ({ }) For ({ 1 }) example ({ 2 }) , ({ 3 }) the ({ 4 }) multi-word ({ 5 }) expression ({ 6 }) tear-filled ({ 7 }) is ({ 8 }) treated ({ 9 }) as ({ 10 }) one ({ 11 }) instance ({ 12 }) , ({ }) but ({ 13 }) are ({ }) untagged ({ 14 15 }) with ({ 16 }) any ({ 17 }) WordNet ({ 18 }) synsets ({ 19 }) in ({ 20 }) the ({ 21 }) converted ({ 22 }) corpus ({ 23 }) , ({ 24 }) while ({ 25 }) in ({ 26 }) the ({ 27 }) original ({ 28 }) corpus ({ 29 }) it[define ({ 30 }) " ({ }) it ({ }) " ({ }) ] ({ }) is ({ 31 }) tagged ({ 32 }) with ({ 33 }) two ({ 34 }) WordNet ({ 35 }) synsets ({ 36 }) for ({ 37 }) tear ({ 38 }) and ({ 39 }) filled ({ 40 }) . ({ 41 }) 
# Sentence pair (540) source length 25 target length 25 alignment score : 7.71262e-05
For this reason , we exclude such instances beforehand , and evaluate our models focused on expressions that have corresponding synsets in the WordNet . 
NULL ({ }) For ({ 1 }) this ({ 2 }) reason ({ 3 }) , ({ 4 }) we ({ 5 }) exclude ({ 6 }) such ({ 7 }) instances ({ 8 }) beforehand ({ 9 }) , ({ 10 }) and ({ 11 }) evaluate ({ 12 }) our ({ 13 }) models ({ 14 }) focused ({ 15 }) on ({ 16 }) expressions ({ 17 }) that ({ 18 }) have ({ 19 }) corresponding ({ 20 }) synsets ({ 21 }) in ({ 22 }) the ({ 23 }) WordNet ({ 24 }) . ({ 25 }) 
# Sentence pair (541) source length 13 target length 13 alignment score : 0.00460446
The resulting statistics of the data sets are shown in Table 5 . 
NULL ({ }) The ({ 1 }) resulting ({ 2 }) statistics ({ 3 }) of ({ 4 }) the ({ 5 }) data ({ 6 }) sets ({ 7 }) are ({ 8 }) shown ({ 9 }) in ({ 10 }) Table ({ 11 }) 5 ({ 12 }) . ({ 13 }) 
# Sentence pair (542) source length 20 target length 20 alignment score : 0.000458195
The evaluation of our model is performed by splitting these corpora into training , development , and test sets . 
NULL ({ }) The ({ 1 }) evaluation ({ 2 }) of ({ 3 }) our ({ 4 }) model ({ 5 }) is ({ 6 }) performed ({ 7 }) by ({ 8 }) splitting ({ 9 }) these ({ 10 }) corpora ({ 11 }) into ({ 12 }) training ({ 13 }) , ({ 14 }) development ({ 15 }) , ({ 16 }) and ({ 17 }) test ({ 18 }) sets ({ 19 }) . ({ 20 }) 
# Sentence pair (543) source length 49 target length 49 alignment score : 3.07243e-09
At first , all files in SEM are sorted according to their file names and distributed into five data sets in order ( denoted as SEM-A , SEM-B , SEM-C , SEM-D , and SEM-E ) , so that each set has almost the same distribution of domains . 
NULL ({ }) At ({ 1 }) first ({ 2 }) , ({ 3 }) all ({ 4 }) files ({ 5 }) in ({ 6 }) SEM ({ 7 }) are ({ 8 }) sorted ({ 9 }) according ({ 10 }) to ({ 11 }) their ({ 12 }) file ({ 13 }) names ({ 14 }) and ({ 15 }) distributed ({ 16 }) into ({ 17 }) five ({ 18 }) data ({ 19 }) sets ({ 20 }) in ({ 21 }) order ({ 22 }) ( ({ 23 }) denoted ({ 24 }) as ({ 25 }) SEM-A ({ 26 }) , ({ 27 }) SEM-B ({ 28 }) , ({ 29 }) SEM-C ({ 30 }) , ({ 31 }) SEM-D ({ 32 }) , ({ 33 }) and ({ 34 }) SEM-E ({ 35 }) ) ({ 36 }) , ({ 37 }) so ({ 38 }) that ({ 39 }) each ({ 40 }) set ({ 41 }) has ({ 42 }) almost ({ 43 }) the ({ 44 }) same ({ 45 }) distribution ({ 46 }) of ({ 47 }) domains ({ 48 }) . ({ 49 }) 
# Sentence pair (544) source length 36 target length 36 alignment score : 3.94507e-07
Furthermore , each of these five data sets is again split into two sets : SEM-A1 , SEM-A2 , / MATH , SEM-E1 , and SEM-E2 , also according to the order of file names . 
NULL ({ }) Furthermore ({ 1 }) , ({ 2 }) each ({ 3 }) of ({ 4 }) these ({ 5 }) five ({ 6 }) data ({ 7 }) sets ({ 8 }) is ({ 9 }) again ({ 10 }) split ({ 11 }) into ({ 12 }) two ({ 13 }) sets ({ 14 }) : ({ 15 }) SEM-A1 ({ 16 }) , ({ 17 }) SEM-A2 ({ 18 }) , ({ 19 }) / ({ 20 }) MATH ({ 21 }) , ({ 22 }) SEM-E1 ({ 23 }) , ({ 24 }) and ({ 25 }) SEM-E2 ({ 26 }) , ({ 27 }) also ({ 28 }) according ({ 29 }) to ({ 30 }) the ({ 31 }) order ({ 32 }) of ({ 33 }) file ({ 34 }) names ({ 35 }) . ({ 36 }) 
# Sentence pair (545) source length 11 target length 11 alignment score : 0.0304698
Our evaluation is based on a 5-fold cross validation scheme . 
NULL ({ }) Our ({ 1 }) evaluation ({ 2 }) is ({ 3 }) based ({ 4 }) on ({ 5 }) a ({ 6 }) 5-fold ({ 7 }) cross ({ 8 }) validation ({ 9 }) scheme ({ 10 }) . ({ 11 }) 
# Sentence pair (546) source length 25 target length 25 alignment score : 8.62396e-05
In the training phase , four sets ( e.g. SEM-A , SEM-B , SEM-C , SEM-D ) in the SEM are used for training . 
NULL ({ }) In ({ 1 }) the ({ 2 }) training ({ 3 }) phase ({ 4 }) , ({ 5 }) four ({ 6 }) sets ({ 7 }) ( ({ 8 }) e.g. ({ 9 }) SEM-A ({ 10 }) , ({ 11 }) SEM-B ({ 12 }) , ({ 13 }) SEM-C ({ 14 }) , ({ 15 }) SEM-D ({ 16 }) ) ({ 17 }) in ({ 18 }) the ({ 19 }) SEM ({ 20 }) are ({ 21 }) used ({ 22 }) for ({ 23 }) training ({ 24 }) . ({ 25 }) 
# Sentence pair (547) source length 34 target length 34 alignment score : 1.33429e-06
Next , for the evaluation on SemCor , one half of the rest ( e.g. SEM-E1 ) is used for development and the other half ( e.g. SEM-E2 ) is used for evaluation . 
NULL ({ }) Next ({ 1 }) , ({ 2 }) for ({ 3 }) the ({ 4 }) evaluation ({ 5 }) on ({ 6 }) SemCor ({ 7 }) , ({ 8 }) one ({ 9 }) half ({ 10 }) of ({ 11 }) the ({ 12 }) rest ({ 13 }) ( ({ 14 }) e.g. ({ 15 }) SEM-E1 ({ 16 }) ) ({ 17 }) is ({ 18 }) used ({ 19 }) for ({ 20 }) development ({ 21 }) and ({ 22 }) the ({ 23 }) other ({ 24 }) half ({ 25 }) ( ({ 26 }) e.g. ({ 27 }) SEM-E2 ({ 28 }) ) ({ 29 }) is ({ 30 }) used ({ 31 }) for ({ 32 }) evaluation ({ 33 }) . ({ 34 }) 
# Sentence pair (548) source length 40 target length 39 alignment score : 4.67189e-09
For the evaluation on the Senseval data sets , all instances of the rest ( e.g. SEM-E ) is used for development and one of the Senseval data sets ( SE2 or SE3 ) is used for evaluation . 
NULL ({ }) For ({ 1 }) the ({ 2 }) evaluation ({ 3 }) on ({ 4 }) the ({ 5 }) Senseval ({ 6 }) data ({ 7 }) sets ({ 8 }) , ({ 9 }) all ({ 10 }) instances ({ 11 }) of ({ 12 }) the ({ 13 }) rest ({ 14 }) ( ({ 15 }) e.g. ({ 16 }) SEM-E ({ 17 }) ) ({ 18 }) are ({ 19 }) used ({ 20 }) for ({ 21 }) development ({ 22 }) , ({ }) and ({ 23 }) one ({ 24 }) of ({ 25 }) the ({ 26 }) Senseval ({ 27 }) data ({ 28 }) sets ({ 29 }) ( ({ 30 }) SE2 ({ 31 }) or ({ 32 }) SE3 ({ 33 }) ) ({ 34 }) is ({ 35 }) used ({ 36 }) for ({ 37 }) evaluation ({ 38 }) . ({ 39 }) 
# Sentence pair (549) source length 32 target length 32 alignment score : 4.82464e-06
Lastly , for the comparison with state-of-the-art models , our model is trained on the whole set of SEM , and SE2 and SE3 are used for development and evaluation respectively . 
NULL ({ }) Lastly ({ 1 }) , ({ 2 }) for ({ 3 }) the ({ 4 }) comparison ({ 5 }) with ({ 6 }) state-of-the-art ({ 7 }) models ({ 8 }) , ({ 9 }) our ({ 10 }) model ({ 11 }) is ({ 12 }) trained ({ 13 }) on ({ 14 }) the ({ 15 }) whole ({ 16 }) set ({ 17 }) of ({ 18 }) SEM ({ 19 }) , ({ 20 }) and ({ 21 }) SE2 ({ 22 }) and ({ 23 }) SE3 ({ 24 }) are ({ 25 }) used ({ 26 }) for ({ 27 }) development ({ 28 }) and ({ 29 }) evaluation ({ 30 }) respectively ({ 31 }) . ({ 32 }) 
# Sentence pair (550) source length 23 target length 23 alignment score : 0.00024548
All sentences are parsed by the Sagae and Tsujii 's dependency parser , and the T-CRF model is trained by using Amis . 
NULL ({ }) All ({ 1 }) sentences ({ 2 }) are ({ 3 }) parsed ({ 4 }) by ({ 5 }) the ({ 6 }) Sagae ({ 7 }) and ({ 8 }) Tsujii ({ 9 }) 's ({ 10 }) dependency ({ 11 }) parser ({ 12 }) , ({ 13 }) and ({ 14 }) the ({ 15 }) T-CRF ({ 16 }) model ({ 17 }) is ({ 18 }) trained ({ 19 }) by ({ 20 }) using ({ 21 }) Amis ({ 22 }) . ({ 23 }) 
# Sentence pair (551) source length 19 target length 19 alignment score : 0.000453143
During the development phase , we tune the Gaussian parameter / MATH for the / MATH regularization term . 
NULL ({ }) During ({ 1 }) the ({ 2 }) development ({ 3 }) phase ({ 4 }) , ({ 5 }) we ({ 6 }) tune ({ 7 }) the ({ 8 }) Gaussian ({ 9 }) parameter ({ 10 }) / ({ 11 }) MATH ({ 12 }) for ({ 13 }) the ({ 14 }) / ({ 15 }) MATH ({ 16 }) regularization ({ 17 }) term ({ 18 }) . ({ 19 }) 
# Sentence pair (552) source length 32 target length 26 alignment score : 6.27591e-12
As the evaluation measure , we use the standard recall measure , which is equivalent to the precision as we output answers to all instances . 
NULL ({ }) As ({ 1 }) the ({ 2 }) evaluation ({ 3 }) measure ({ 4 }) , ({ 5 }) we ({ 6 }) use ({ 7 }) the ({ 8 }) standard ({ 9 }) recall ({ 10 }) measure ({ 11 }) , ({ 12 }) which ({ 13 }) is ({ 14 }) equivalent ({ 15 }) to ({ 16 }) the ({ 17 }) precision ({ 18 }) as ({ 19 }) we ({ 20 }) output ({ 21 }) answers ({ 22 }) to ({ 23 }) all ({ 24 }) instances ({ 25 }) . ({ }) **[This ({ }) section ({ }) is ({ }) a ({ }) bit ({ }) monotonous] ({ 26 }) 
# Sentence pair (553) source length 11 target length 11 alignment score : 0.0107301
The synset-based evaluation is performed based on the WordNet synsets . 
NULL ({ }) The ({ 1 }) synset-based ({ 2 }) evaluation ({ 3 }) is ({ 4 }) performed ({ 5 }) based ({ 6 }) on ({ 7 }) the ({ 8 }) WordNet ({ 9 }) synsets ({ 10 }) . ({ 11 }) 
# Sentence pair (554) source length 19 target length 19 alignment score : 0.000550339
We evaluate the outputs of our system for all instances that are semantically tagged in the data sets . 
NULL ({ }) We ({ 1 }) evaluate ({ 2 }) the ({ 3 }) outputs ({ 4 }) of ({ 5 }) our ({ 6 }) system ({ 7 }) for ({ 8 }) all ({ 9 }) instances ({ 10 }) that ({ 11 }) are ({ 12 }) semantically ({ 13 }) tagged ({ 14 }) in ({ 15 }) the ({ 16 }) data ({ 17 }) sets ({ 18 }) . ({ 19 }) 
# Sentence pair (555) source length 15 target length 15 alignment score : 0.00324508
Each target word is either a noun , verb , adjective , or adverb . 
NULL ({ }) Each ({ 1 }) target ({ 2 }) word ({ 3 }) is ({ 4 }) either ({ 5 }) a ({ 6 }) noun ({ 7 }) , ({ 8 }) verb ({ 9 }) , ({ 10 }) adjective ({ 11 }) , ({ 12 }) or ({ 13 }) adverb ({ 14 }) . ({ 15 }) 
# Sentence pair (556) source length 14 target length 14 alignment score : 0.00401455
For the supersense-based evaluation , we follow most of the experimental setup in . 
NULL ({ }) For ({ 1 }) the ({ 2 }) supersense-based ({ 3 }) evaluation ({ 4 }) , ({ 5 }) we ({ 6 }) follow ({ 7 }) most ({ 8 }) of ({ 9 }) the ({ 10 }) experimental ({ 11 }) setup ({ 12 }) in ({ 13 }) . ({ 14 }) 
# Sentence pair (557) source length 35 target length 35 alignment score : 1.04459e-25
As they noted , in the WordNet , there is semantically inconsistent labeling of supersenses such that top level synsets are tagged as the supersense noun .Tops rather than the specific supersense they govern . 
NULL ({ 10 16 17 }) As ({ 1 }) noted ({ 2 3 }) , ({ 4 }) in ({ 5 }) the ({ 6 }) WordNet ({ 7 }) , ({ 8 }) the ({ }) labeling ({ 13 }) of ({ 14 }) supersensesis ({ 9 15 }) semantically ({ 11 }) inconsistent ({ 12 }) , ({ }) and ({ }) top ({ 18 }) level ({ 19 }) synsets ({ 20 }) are ({ 21 }) tagged ({ 22 }) as ({ 23 }) the ({ 24 }) supersense ({ 25 }) noun ({ 26 }) .Tops[ ({ 27 }) ? ({ }) ?] ({ }) rather ({ 28 }) than ({ 29 }) the ({ 30 }) specific ({ 31 }) supersense ({ 32 }) they ({ 33 }) govern ({ 34 }) . ({ 35 }) 
# Sentence pair (558) source length 24 target length 24 alignment score : 0.000326335
For example , nouns such as peach and plum are tagged as noun .plant but their hypernym plant itself belongs to noun .Tops . 
NULL ({ }) For ({ 1 }) example ({ 2 }) , ({ 3 }) nouns ({ 4 }) such ({ 5 }) as ({ 6 }) peach ({ 7 }) and ({ 8 }) plum ({ 9 }) are ({ 10 }) tagged ({ 11 }) as ({ 12 }) noun ({ 13 }) .plant ({ 14 }) but ({ 15 }) their ({ 16 }) hypernym ({ 17 }) plant ({ 18 }) itself ({ 19 }) belongs ({ 20 }) to ({ 21 }) noun ({ 22 }) .Tops ({ 23 }) . ({ 24 }) 
# Sentence pair (559) source length 73 target length 72 alignment score : 1.54585e-13
For this reason , we adopted the modification of noun supersenses in the same way as , substituting noun .Tops labels with more specific supersense labels when possible , and left some general nouns with noun .TopsoteNouns which are left with noun .Tops are : entity , thing , anything , something , nothing , object , living thing , organism , benthos , heterotroph , life , and biont . . 
NULL ({ }) For ({ 1 }) this ({ 2 }) reason ({ 3 }) , ({ 4 }) we ({ 5 }) adopted ({ 6 }) the ({ 7 }) modification ({ 8 }) of ({ 9 }) noun ({ 10 }) supersenses ({ 11 }) in ({ 12 }) the ({ 13 }) same ({ 14 }) way ({ 15 }) as ({ 16 }) , ({ 17 }) substituting ({ 18 }) noun ({ 19 }) .Tops ({ 20 }) labels ({ 21 }) with ({ 22 }) more ({ 23 }) specific ({ 24 }) supersense ({ 25 }) labels ({ 26 }) when ({ 27 }) possible ({ 28 }) , ({ 29 }) and ({ 30 }) left ({ 31 }) some ({ 32 }) general ({ 33 }) nouns ({ 34 }) with ({ 35 }) noun ({ 36 }) .TopsoteNouns ({ 37 }) , ({ }) which ({ 38 }) are ({ 39 }) left ({ 40 }) with ({ 41 }) noun ({ 42 }) .Tops ({ 43 }) are ({ 44 }) : ({ 45 }) entity ({ 46 }) , ({ 47 }) thing ({ 48 }) , ({ 49 }) anything ({ 50 }) , ({ 51 }) something ({ 52 }) , ({ 53 }) nothing ({ 54 }) , ({ 55 }) object ({ 56 }) , ({ 57 }) living ({ 58 }) thing ({ 59 }) , ({ 60 }) organism ({ 61 }) , ({ 62 }) benthos ({ 63 }) , ({ 64 }) heterotroph ({ 65 }) , ({ 66 }) life ({ 67 }) , ({ 68 }) and ({ 69 }) biont ({ 70 }) . ({ 71 }) . ({ 72 }) 
# Sentence pair (560) source length 9 target length 9 alignment score : 0.0606729
The evaluation is based on these modified labels . 
NULL ({ }) The ({ 1 }) evaluation ({ 2 }) is ({ 3 }) based ({ 4 }) on ({ 5 }) these ({ 6 }) modified ({ 7 }) labels ({ 8 }) . ({ 9 }) 
# Sentence pair (561) source length 25 target length 11 alignment score : 4.08494e-19
We ignore the adjective and adverb instances in the evaluation . 
NULL ({ }) We ({ 1 }) ignore ({ 2 }) the ({ 3 }) adjective ({ 4 }) and ({ 5 }) adverb ({ 6 }) instances ({ 7 }) in ({ 8 }) the ({ 9 }) evaluation ({ 10 }) .**[This ({ }) section ({ }) is ({ }) a ({ }) bit ({ }) confusing ({ }) . ({ 11 }) Maybe ({ }) break ({ }) up ({ }) the ({ }) longer ({ }) sentences ({ }) to ({ }) clarify] ({ }) 
# Sentence pair (562) source length 42 target length 41 alignment score : 2.27112e-08
Table 6 is the list of models we use for the evaluation , where FS and SR correspond to the first sense and sense ranking features respectively , and non-dependency denotes models that do not incorporate sense dependency features ( i.e. 
NULL ({ }) Table ({ 1 }) 6 ({ 2 }) is ({ 3 }) the ({ 4 }) list ({ 5 }) of ({ 6 }) models ({ 7 }) that ({ }) we ({ 8 }) use ({ 9 }) for ({ 10 }) the ({ 11 }) evaluation ({ 12 }) , ({ 13 }) where ({ 14 }) FS ({ 15 }) and ({ 16 }) SR ({ 17 }) correspond ({ 18 }) to ({ 19 }) the ({ 20 }) first ({ 21 }) sense ({ 22 }) and ({ 23 }) sense ({ 24 }) ranking ({ 25 }) features ({ 26 }) respectively ({ 27 }) , ({ 28 }) and ({ 29 }) non-dependency ({ 30 }) denotes ({ 31 }) models ({ 32 }) that ({ 33 }) do ({ 34 }) not ({ 35 }) incorporate ({ 36 }) sense ({ 37 }) dependency ({ 38 }) features ({ 39 }) ( ({ 40 }) i.e. ({ 41 }) 
# Sentence pair (563) source length 6 target length 6 alignment score : 0.155371
only the vertex features ) . 
NULL ({ }) only ({ 1 }) the ({ 2 }) vertex ({ 3 }) features ({ 4 }) ) ({ 5 }) . ({ 6 }) 
# Sentence pair (564) source length 14 target length 14 alignment score : 0.00618596
In this section , we focus on the contribution of the sense dependencies . 
NULL ({ }) In ({ 1 }) this ({ 2 }) section ({ 3 }) , ({ 4 }) we ({ 5 }) focus ({ 6 }) on ({ 7 }) the ({ 8 }) contribution ({ 9 }) of ({ 10 }) the ({ 11 }) sense ({ 12 }) dependencies ({ 13 }) . ({ 14 }) 
# Sentence pair (565) source length 27 target length 27 alignment score : 0.000138049
Table 7 shows the comparisons between the tree-structured models with sense dependencies ( dependency models ) and the models without sense dependencies ( non-dependency models ) . 
NULL ({ }) Table ({ 1 }) 7 ({ 2 }) shows ({ 3 }) the ({ 4 }) comparisons ({ 5 }) between ({ 6 }) the ({ 7 }) tree-structured ({ 8 }) models ({ 9 }) with ({ 10 }) sense ({ 11 }) dependencies ({ 12 }) ( ({ 13 }) dependency ({ 14 }) models ({ 15 }) ) ({ 16 }) and ({ 17 }) the ({ 18 }) models ({ 19 }) without ({ 20 }) sense ({ 21 }) dependencies ({ 22 }) ( ({ 23 }) non-dependency ({ 24 }) models ({ 25 }) ) ({ 26 }) . ({ 27 }) 
# Sentence pair (566) source length 58 target length 62 alignment score : 3.88463e-23
In this section , each figure shows the mean recall ( equivalent to the precisions ) averaged over the five trials of the cross validation , the " Diff . " rows show the differences between the dependency models and the non-dependency models , and / MATH and / MATH denote the statistical significance of / MATH and / MATH respectively . 
NULL ({ 4 }) Each ({ 1 }) figure ({ 2 6 }) displays ({ 3 5 7 }) the ({ 8 }) mean ({ 9 }) recall ({ 10 }) ( ({ 11 }) equivalent ({ 12 }) to ({ 13 }) the ({ 14 }) precisions ({ 15 }) ) ({ 16 }) averaged ({ 17 }) over ({ 18 }) the ({ 19 }) five ({ 20 }) trials ({ 21 }) of ({ 22 }) the ({ 23 }) cross ({ 24 }) validation ({ 25 }) , ({ 26 }) the ({ 27 }) " ({ 28 }) Diff ({ 29 }) . ({ 30 }) " ({ 31 }) rows ({ 32 }) show ({ 33 }) the ({ 34 }) differences ({ 35 }) between ({ 36 }) the ({ 37 }) dependency ({ 38 }) models ({ 39 }) and ({ 40 }) the ({ 41 }) non-dependency ({ 42 }) models ({ 43 }) , ({ 44 }) and ({ 45 }) / ({ 46 }) MATH ({ 47 }) and ({ 48 }) / ({ 49 }) MATH ({ 50 }) denote ({ 51 }) the ({ 52 }) statistical ({ 53 }) significance ({ 54 }) of ({ 55 }) / ({ 56 }) MATH ({ 57 }) and ({ 58 }) / ({ 59 }) MATH ({ 60 }) respectively ({ 61 }) . ({ 62 }) 
# Sentence pair (567) source length 32 target length 30 alignment score : 5.96068e-15
We can see from Table 7 that with the sense frequency information , the tree-structured models ( statistically ) significantly outperformed the non-dependency models on all the data sets . 
NULL ({ 4 }) From ({ 1 }) Table ({ 5 }) 7 ({ 6 }) , ({ }) it ({ }) can ({ 2 }) be ({ }) seen ({ 3 }) that ({ 7 }) with ({ 8 }) the ({ 9 }) sense ({ 10 }) frequency ({ 11 }) information ({ 12 }) , ({ 13 }) the ({ 14 }) tree-structured ({ 15 }) models ({ 16 }) ( ({ 17 }) statistically ({ 18 }) ) ({ 19 }) significantly ({ 20 }) outperformed ({ 21 }) the ({ 22 }) non-dependency ({ 23 }) models ({ 24 }) on ({ 25 }) all ({ 26 }) the ({ 27 }) data ({ 28 }) sets ({ 29 }) . ({ 30 }) 
# Sentence pair (568) source length 54 target length 53 alignment score : 6.83658e-24
These improvements seem small in terms of figures ; However , considering for instance the No-Dep-SS-FS model outperforms the Baseline-SS-FS model only by 0 .37% on SEM , the further improvement of 0 .21% is considerable because this means our dependency model could handle 57% more instances over the first sense baseline . 
NULL ({ 7 }) These ({ 1 }) improvements ({ 2 }) seem ({ 3 }) insignificant ({ 4 }) in ({ 5 }) figures ({ 6 8 }) ; ({ 9 }) however ({ 10 }) , ({ 11 }) considering ({ 12 }) that ({ }) for ({ 13 }) instance ({ 14 }) the ({ 15 }) No-Dep-SS-FS ({ 16 }) model ({ 17 }) outperforms ({ 18 }) the ({ 19 }) Baseline-SS-FS ({ 20 }) model ({ 21 }) by ({ 23 }) only ({ 22 }) 0 ({ 24 }) .37% ({ 25 }) on ({ 26 }) SEM ({ 27 }) , ({ 28 }) the ({ 29 }) further ({ 30 }) improvement ({ 31 }) of ({ 32 }) 0 ({ 33 }) .21% ({ 34 }) is ({ 35 }) substantial ({ 36 }) , ({ }) because ({ 37 }) it ({ 38 }) indicates ({ 39 }) that ({ }) our ({ 40 }) dependency ({ 41 }) model ({ 42 }) could ({ 43 }) handle ({ 44 }) 57% ({ 45 }) more ({ 46 }) instances ({ 47 }) over ({ 48 }) the ({ 49 }) first ({ 50 }) sense ({ 51 }) baseline ({ 52 }) . ({ 53 }) 
# Sentence pair (569) source length 53 target length 51 alignment score : 1.03188e-11
Note that , without the sense frequency information , the synset-based tree-structured model ( Tree-WS ) performed poorer than the non-dependency model ( NoDep-WS ) on all the data sets , whereas the supersense-based model ( Tree-SS ) exhibited the robustness regardless of the existence of the sense frequency information . 
NULL ({ }) Note ({ 1 }) that ({ 2 }) , ({ 3 }) without ({ 4 }) the ({ 5 }) sense ({ 6 }) frequency ({ 7 }) information ({ 8 }) , ({ 9 }) the ({ 10 }) synset-based ({ 11 }) tree-structured ({ 12 }) model ({ 13 }) ( ({ 14 }) Tree-WS ({ 15 }) ) ({ 16 }) performed ({ 17 }) worse ({ 18 }) than ({ 19 }) the ({ 20 }) non-dependency ({ 21 }) model ({ 22 }) ( ({ 23 }) NoDep-WS ({ 24 }) ) ({ 25 }) on ({ 26 }) all ({ 27 }) the ({ 28 }) data ({ 29 }) sets ({ 30 }) , ({ 31 }) whereas ({ 32 }) the ({ 33 }) supersense-based ({ 34 }) model ({ 35 }) ( ({ 36 }) Tree-SS ({ 37 }) ) ({ 38 }) exhibited ({ 39 }) the ({ 40 }) robustness ({ 41 }) [of ({ }) ...] ({ }) regardless ({ 42 }) of ({ 43 }) the ({ 44 }) existence ({ 45 }) of ({ 46 }) the ({ 47 }) sense ({ 48 }) frequency ({ 49 }) information ({ 50 }) . ({ 51 }) 
# Sentence pair (570) source length 39 target length 39 alignment score : 2.9286e-07
These results suggest that for the synset-based model , in which most synsets do not have enough instances in the training data , the combination with sense-frequency information is necessary in order to avoid the data sparseness problem . 
NULL ({ }) These ({ 1 }) results ({ 2 }) suggest ({ 3 }) that ({ 4 }) for ({ 5 }) the ({ 6 }) synset-based ({ 7 }) model ({ 8 }) , ({ 9 }) in ({ 10 }) which ({ 11 }) most ({ 12 }) synsets ({ 13 }) do ({ 14 }) not ({ 15 }) have ({ 16 }) enough ({ 17 }) instances ({ 18 }) in ({ 19 }) the ({ 20 }) training ({ 21 }) data ({ 22 }) , ({ 23 }) the ({ 24 }) combination ({ 25 }) with ({ 26 }) sense-frequency ({ 27 }) information ({ 28 }) is ({ 29 }) necessary ({ 30 }) in ({ 31 }) order ({ 32 }) to ({ 33 }) avoid ({ 34 }) the ({ 35 }) data ({ 36 }) sparseness ({ 37 }) problem ({ 38 }) . ({ 39 }) 
# Sentence pair (571) source length 17 target length 17 alignment score : 0.00323382
Similarly , Table 8 shows the comparisons between the linear-chain dependency models and the non-dependency models . 
NULL ({ }) Similarly ({ 1 }) , ({ 2 }) Table ({ 3 }) 8 ({ 4 }) shows ({ 5 }) the ({ 6 }) comparisons ({ 7 }) between ({ 8 }) the ({ 9 }) linear-chain ({ 10 }) dependency ({ 11 }) models ({ 12 }) and ({ 13 }) the ({ 14 }) non-dependency ({ 15 }) models ({ 16 }) . ({ 17 }) 
# Sentence pair (572) source length 51 target length 51 alignment score : 1.6774e-09
In the supersense-based evaluation , although the differences are slightly smaller than in the tree-structured models , we confirmed that the sense dependencies with the first sense features work effectively , with the overall improvements of 0 .29% , 0 .20% , and 0 .30% for the three data sets . 
NULL ({ }) In ({ 1 }) the ({ 2 }) supersense-based ({ 3 }) evaluation ({ 4 }) , ({ 5 }) although ({ 6 }) the ({ 7 }) differences ({ 8 }) are ({ 9 }) slightly ({ 10 }) smaller ({ 11 }) than ({ 12 }) in ({ 13 }) the ({ 14 }) tree-structured ({ 15 }) models ({ 16 }) , ({ 17 }) we ({ 18 }) confirmed ({ 19 }) that ({ 20 }) the ({ 21 }) sense ({ 22 }) dependencies ({ 23 }) with ({ 24 }) the ({ 25 }) first ({ 26 }) sense ({ 27 }) features ({ 28 }) work ({ 29 }) effectively ({ 30 }) , ({ 31 }) with ({ 32 }) the ({ 33 }) overall ({ 34 }) improvements ({ 35 }) of ({ 36 }) 0 ({ 37 }) .29% ({ 38 }) , ({ 39 }) 0 ({ 40 }) .20% ({ 41 }) , ({ 42 }) and ({ 43 }) 0 ({ 44 }) .30% ({ 45 }) for ({ 46 }) the ({ 47 }) three ({ 48 }) data ({ 49 }) sets ({ 50 }) . ({ 51 }) 
# Sentence pair (573) source length 17 target length 17 alignment score : 0.00231268
However , without the first sense features , no statistically significant improvement nor deterioration is observed . 
NULL ({ }) However ({ 1 }) , ({ 2 }) without ({ 3 }) the ({ 4 }) first ({ 5 }) sense ({ 6 }) features ({ 7 }) , ({ 8 }) no ({ 9 }) statistically ({ 10 }) significant ({ 11 }) improvement ({ 12 }) nor ({ 13 }) deterioration ({ 14 }) is ({ 15 }) observed ({ 16 }) . ({ 17 }) 
# Sentence pair (574) source length 17 target length 17 alignment score : 0.00170108
In the synset-based evaluation , the overall trend is almost same as in the tree-structured case . 
NULL ({ }) In ({ 1 }) the ({ 2 }) synset-based ({ 3 }) evaluation ({ 4 }) , ({ 5 }) the ({ 6 }) overall ({ 7 }) trend ({ 8 }) is ({ 9 }) almost ({ 10 }) same ({ 11 }) as ({ 12 }) in ({ 13 }) the ({ 14 }) tree-structured ({ 15 }) case ({ 16 }) . ({ 17 }) 
# Sentence pair (575) source length 39 target length 35 alignment score : 4.26859e-15
However , by the incorporation of the sense dependencies , the improvements with the sense ranking features are even smaller , and the deteriorations without them are even larger than in the tree-structured case . 
NULL ({ }) Nonetheless ({ 1 }) , ({ 2 }) by ({ 3 }) the ({ 4 }) incorporation ({ 5 }) of ({ 6 }) the ({ 7 }) sense ({ 8 }) dependencies ({ 9 }) , ({ 10 }) the ({ 11 }) improvements ({ 12 }) with ({ 13 }) the ({ 14 }) sense ({ 15 }) ranking ({ 16 }) features ({ 17 }) was ({ 18 }) even ({ 19 }) less ({ 20 }) , ({ 21 }) and ({ 22 }) the ({ 23 }) deteriorations ({ 24 }) without ({ 25 }) them[define ({ 26 }) " ({ }) them ({ }) " ({ }) ] ({ }) were ({ 27 }) even ({ 28 }) more ({ 29 }) than ({ 30 }) in ({ 31 }) the ({ 32 }) tree-structured ({ 33 }) case ({ 34 }) . ({ 35 }) 
# Sentence pair (576) source length 23 target length 23 alignment score : 7.51411e-05
These results seem to suggest that the sense dependencies on the tree structures are more robust than those on the linear chains . 
NULL ({ }) These ({ 1 }) results ({ 2 }) seem ({ 3 }) to ({ 4 }) suggest ({ 5 }) that ({ 6 }) the ({ 7 }) sense ({ 8 }) dependencies ({ 9 }) on ({ 10 }) the ({ 11 }) tree ({ 12 }) structures ({ 13 }) are ({ 14 }) more ({ 15 }) robust ({ 16 }) than ({ 17 }) those ({ 18 }) on ({ 19 }) the ({ 20 }) linear ({ 21 }) chains ({ 22 }) . ({ 23 }) 
# Sentence pair (577) source length 19 target length 19 alignment score : 0.000820142
In this section , let us focus on the difference between the tree-structured models and the linear-chain models . 
NULL ({ }) In ({ 1 }) this ({ 2 }) section ({ 3 }) , ({ 4 }) let ({ 5 }) us ({ 6 }) focus ({ 7 }) on ({ 8 }) the ({ 9 }) difference ({ 10 }) between ({ 11 }) the ({ 12 }) tree-structured ({ 13 }) models ({ 14 }) and ({ 15 }) the ({ 16 }) linear-chain ({ 17 }) models ({ 18 }) . ({ 19 }) 
# Sentence pair (578) source length 39 target length 35 alignment score : 2.08301e-11
In the results shown in Table 9 , although some of the differences are marginal , we can see that the tree-structured models outperformed the linear-chain models , focusing on the statistically significant differences . 
NULL ({ }) In ({ 1 }) the ({ 2 }) results ({ 3 }) shown ({ 4 }) in ({ 5 }) Table ({ 6 }) 9 ({ 7 }) , ({ 8 }) although ({ 9 }) some ({ 10 }) of ({ 11 }) the ({ 12 }) differences ({ 13 }) are ({ 14 }) marginal ({ 15 }) , ({ 16 }) we ({ 17 }) can ({ 18 }) see ({ 19 }) that ({ 20 }) the ({ 21 }) tree-structured ({ 22 }) models ({ 23 }) outperformed ({ 24 }) the ({ 25 }) linear-chain ({ 26 }) models ({ 27 }) , ({ 28 }) focusing ({ 29 }) on ({ 30 }) the ({ 31 }) statistically ({ 32 }) significant ({ 33 }) differences ({ 34 }) .**[<-This ({ }) is ({ }) a ({ }) confusing ({ }) sentence] ({ 35 }) 
# Sentence pair (579) source length 29 target length 31 alignment score : 4.91585e-18
These results suggest that although both the dependency trees and the linear chains capture useful dependencies of word senses , the dependencies on the tree structures capture more important information . 
NULL ({ 4 }) Thus ({ 1 }) , ({ }) although ({ 3 5 }) both ({ 6 }) the ({ 7 }) dependency ({ 8 }) trees ({ 9 }) and ({ 10 }) the ({ 11 }) linear ({ 12 }) chains ({ 2 13 }) capture ({ 14 }) useful ({ 15 }) dependencies ({ 16 }) of ({ 17 }) word ({ 18 }) senses ({ 19 }) , ({ 20 }) the ({ 21 }) dependencies ({ 22 }) on ({ 23 }) the ({ 24 }) tree ({ 25 }) structures ({ 26 }) capture ({ 27 }) more ({ 28 }) important ({ 29 }) information ({ 30 }) . ({ 31 }) 
# Sentence pair (580) source length 10 target length 10 alignment score : 0.0288679
Table 10 shows the contributions of the coarse-grained labels . 
NULL ({ }) Table ({ 1 }) 10 ({ 2 }) shows ({ 3 }) the ({ 4 }) contributions ({ 5 }) of ({ 6 }) the ({ 7 }) coarse-grained ({ 8 }) labels ({ 9 }) . ({ 10 }) 
# Sentence pair (581) source length 44 target length 44 alignment score : 1.97869e-17
Whereas Tree-WS-SR and Tree-WS use all four sense labels for the edge features ( / MATH ) , Tree-WS-SR' and Tree-WS' only use the synset labels ( / MATH ) , so that we can see the contribution of the coarse-grained sense labels . 
NULL ({ 32 33 }) Whereas ({ 1 }) Tree-WS-SR ({ 2 }) and ({ 3 }) Tree-WS ({ 4 }) use ({ 5 }) all ({ 6 }) four ({ 7 }) sense ({ 8 }) labels ({ 9 }) for ({ 10 }) the ({ 11 }) edge ({ 12 }) features ({ 13 }) ( ({ 14 }) / ({ 15 }) MATH ({ 16 }) ) ({ 17 }) , ({ 18 }) Tree-WS-SR' ({ 19 }) and ({ 20 }) Tree-WS' ({ 21 }) only ({ 22 }) use ({ 23 }) the ({ 24 }) synset ({ 25 }) labels ({ 26 }) ( ({ 27 }) / ({ 28 }) MATH ({ 29 }) ) ({ 30 }) . ({ }) Thus ({ }) , ({ 31 }) we ({ 34 }) can ({ 35 }) see ({ 36 }) the ({ 37 }) contribution ({ 38 }) of ({ 39 }) the ({ 40 }) coarse-grained ({ 41 }) sense ({ 42 }) labels ({ 43 }) . ({ 44 }) 
# Sentence pair (582) source length 31 target length 31 alignment score : 4.33437e-07
Although the improvements are marginal , we can see that the coarse-grained sense labels did consistently improve the performance on all the data sets , relieving the data sparseness problem . 
NULL ({ }) Although ({ 1 }) the ({ 2 }) improvements ({ 3 }) are ({ 4 }) marginal ({ 5 }) , ({ 6 }) we ({ 7 }) can ({ 8 }) see ({ 9 }) that ({ 10 }) the ({ 11 }) coarse-grained ({ 12 }) sense ({ 13 }) labels ({ 14 }) consistently ({ 15 }) did ({ 16 }) improve ({ 17 }) the ({ 18 }) performance ({ 19 }) on ({ 20 }) all ({ 21 }) the ({ 22 }) data ({ 23 }) sets ({ 24 }) , ({ 25 }) relieving ({ 26 }) the ({ 27 }) data ({ 28 }) sparseness ({ 29 }) problem ({ 30 }) . ({ 31 }) 
# Sentence pair (583) source length 32 target length 32 alignment score : 2.65752e-06
Since synset-based models can directly be used as supersense taggers by a simple conversion of senses , we compared the performance of the synset-based model with that of the supersense-based model . 
NULL ({ }) Since ({ 1 }) synset-based ({ 2 }) models ({ 3 }) can ({ 4 }) directly ({ 5 }) be ({ 6 }) used ({ 7 }) as ({ 8 }) supersense ({ 9 }) taggers ({ 10 }) by ({ 11 }) a ({ 12 }) simple ({ 13 }) conversion ({ 14 }) of ({ 15 }) senses ({ 16 }) , ({ 17 }) we ({ 18 }) compared ({ 19 }) the ({ 20 }) performance ({ 21 }) of ({ 22 }) the ({ 23 }) synset-based ({ 24 }) model ({ 25 }) with ({ 26 }) that ({ 27 }) of ({ 28 }) the ({ 29 }) supersense-based ({ 30 }) model ({ 31 }) . ({ 32 }) 
# Sentence pair (584) source length 42 target length 42 alignment score : 5.61975e-10
Interestingly , when evaluated at the supersense level , the synset-based models considerably outperformed the supersense-based models , with the overall improvements of 0 .69% with the sense frequency information and 1 .41% without it , as shown in Table fcomp-ws-ss-tree . 
NULL ({ }) Interestingly ({ 1 }) , ({ 2 }) when ({ 3 }) evaluated ({ 4 }) at ({ 5 }) the ({ 6 }) supersense ({ 7 }) level ({ 8 }) , ({ 9 }) the ({ 10 }) synset-based ({ 11 }) models ({ 12 }) considerably ({ 13 }) outperformed ({ 14 }) the ({ 15 }) supersense-based ({ 16 }) models ({ 17 }) , ({ 18 }) with ({ 19 }) an ({ 20 }) overall ({ 21 }) improvements ({ 22 }) of ({ 23 }) 0 ({ 24 }) .69% ({ 25 }) with ({ 26 }) the ({ 27 }) sense ({ 28 }) frequency ({ 29 }) information ({ 30 }) and ({ 31 }) 1 ({ 32 }) .41% ({ 33 }) without ({ 34 }) it ({ 35 }) , ({ 36 }) as ({ 37 }) shown ({ 38 }) in ({ 39 }) Table ({ 40 }) fcomp-ws-ss-tree ({ 41 }) . ({ 42 }) 
# Sentence pair (585) source length 45 target length 48 alignment score : 5.31883e-28
These results suggest that even though the granularity of the supersenses is sufficient for many NLP tasks , they are too coarse-grained to capture enough information for WSD models ; Therefore , even for the supersense-based disambiguation , we can improve the performance by considering finer-grained senses . 
NULL ({ 4 33 }) Thus ({ 1 }) , ({ }) even ({ 5 }) though ({ 6 }) the ({ 7 }) granularity ({ 8 }) of ({ 9 }) the ({ 10 }) supersenses ({ 11 }) is ({ 12 }) sufficient ({ 13 }) for ({ 14 }) many ({ 15 }) NLP ({ 16 }) tasks ({ 17 }) , ({ 18 }) they ({ 19 }) are ({ 20 }) too ({ 21 }) coarse-grained ({ 22 }) to ({ 23 }) capture ({ 24 }) enough ({ 25 }) information ({ 26 }) for ({ 27 }) WSD ({ 28 }) models ({ 29 }) ; ({ 30 }) therefore ({ 31 }) , ({ 32 }) for ({ 34 }) the ({ 35 }) supersense-based ({ 36 }) disambiguation ({ 37 }) , ({ 38 }) we ({ 39 }) can ({ 40 }) improve ({ 41 }) the ({ 42 }) performance ({ 43 }) by ({ 44 }) considering ({ 2 45 }) finer-grained ({ 3 46 }) senses ({ 47 }) . ({ 48 }) 
# Sentence pair (586) source length 14 target length 14 alignment score : 0.00323592
Table 12 shows the comparison of our model with the state-of-the-art WSD systems . 
NULL ({ }) Table ({ 1 }) 12 ({ 2 }) shows ({ 3 }) the ({ 4 }) comparison ({ 5 }) of ({ 6 }) our ({ 7 }) model ({ 8 }) with ({ 9 }) the ({ 10 }) state-of-the-art ({ 11 }) WSD ({ 12 }) systems ({ 13 }) . ({ 14 }) 
# Sentence pair (587) source length 11 target length 11 alignment score : 0.00970587
The evaluation here is performed with the Senseval official scorer . 
NULL ({ }) The ({ 1 }) evaluation ({ 2 }) here ({ 3 }) is ({ 4 }) performed ({ 5 }) with ({ 6 }) the ({ 7 }) Senseval ({ 8 }) official ({ 9 }) scorer ({ 10 }) . ({ 11 }) 
# Sentence pair (588) source length 25 target length 25 alignment score : 4.83558e-05
Our model Tree-WS-SR outperformed the two best systems in the Senseval-3 ( Gambl and SenseLearner ) , but lagged behind PNNL by 1 .6% . 
NULL ({ }) Our ({ 1 }) model ({ 2 }) Tree-WS-SR ({ 3 }) outperformed ({ 4 }) the ({ 5 }) two ({ 6 }) best ({ 7 }) systems ({ 8 }) in ({ 9 }) the ({ 10 }) Senseval-3 ({ 11 }) ( ({ 12 }) Gambl ({ 13 }) and ({ 14 }) SenseLearner ({ 15 }) ) ({ 16 }) , ({ 17 }) but ({ 18 }) lagged ({ 19 }) behind ({ 20 }) PNNL ({ 21 }) by ({ 22 }) 1 ({ 23 }) .6% ({ 24 }) . ({ 25 }) 
# Sentence pair (589) source length 84 target length 74 alignment score : 3.7383e-26
However , considering that all systems in Table 12 except for Simil-Prime utilize other sense-annotated corpora in addition to SemCor , such as the Senseval data sets or example sentences in the WordNet , and our model cannot handle multi-word expressions that do not exist in the WordNet as noted in Section 5 .1 , we can conclude that the performance of our T-CRF model is comparable to that of state-of-the-art WSD systems . 
NULL ({ 2 }) However ({ 1 }) , ({ }) taking ({ }) into ({ }) consideration ({ }) that ({ 4 }) all ({ 5 }) systems ({ 6 }) in ({ 7 }) Table ({ 8 }) 12 ({ 9 }) except ({ 10 }) for ({ 11 }) Simil-Prime ({ 12 }) utilize ({ 13 }) other ({ 14 }) sense-annotated ({ 15 }) corpora ({ 16 }) in ({ 17 }) addition ({ 18 }) to ({ 19 }) SemCor ({ 20 }) , ({ 21 }) such ({ 22 }) as ({ 23 }) the ({ 24 }) Senseval ({ 25 }) data ({ 26 }) sets ({ 27 }) or ({ 28 }) example ({ 29 }) sentences ({ 30 }) in ({ 31 }) the ({ 32 }) WordNet ({ 33 }) , ({ 34 }) and ({ 35 }) that ({ }) our ({ 36 }) model ({ 37 }) cannot ({ 38 }) handle ({ 39 }) multi-word ({ 40 }) expressions ({ 41 }) that ({ 42 }) do ({ 43 }) not ({ 44 }) exist ({ 45 }) in ({ 46 }) the ({ 47 }) WordNet ({ 48 }) as ({ 49 }) noted ({ 50 }) in ({ 51 }) Section ({ 52 }) 5 ({ 53 }) .1 ({ 54 }) , ({ 55 }) we ({ 56 }) can ({ 57 }) conclude ({ 58 }) that ({ 59 }) the ({ 60 }) performance ({ 61 }) of ({ 62 }) our ({ 63 }) T-CRF ({ 64 }) model ({ 65 }) is ({ 66 }) comparable ({ 67 }) to ({ 68 }) that ({ 69 }) of ({ 70 }) state-of-the-art ({ 71 }) WSD ({ 72 }) systems ({ 73 }) . ({ 74 }) **[This ({ }) is ({ }) a ({ }) long ({ }) sentence- ({ 3 }) shorten ({ }) .] ({ }) 
# Sentence pair (590) source length 22 target length 22 alignment score : 0.000440858
Table 13 shows the list of the 15 largest-weighted sense dependency features in the tree-structured , synset-based model ( Tree-WS ) . 
NULL ({ }) Table ({ 1 }) 13 ({ 2 }) shows ({ 3 }) the ({ 4 }) list ({ 5 }) of ({ 6 }) the ({ 7 }) 15 ({ 8 }) largest-weighted ({ 9 }) sense ({ 10 }) dependency ({ 11 }) features ({ 12 }) in ({ 13 }) the ({ 14 }) tree-structured ({ 15 }) , ({ 16 }) synset-based ({ 17 }) model ({ 18 }) ( ({ 19 }) Tree-WS ({ 20 }) ) ({ 21 }) . ({ 22 }) 
# Sentence pair (591) source length 38 target length 38 alignment score : 2.36094e-07
The list includes features associated with verb-noun relations ( e.g. SS :verb .consumption-SS :noun .food ) and noun-noun relations ( e.g. SS :noun .communication-SS :noun .communication ) , which we will describe in detail with several examples . 
NULL ({ }) The ({ 1 }) list ({ 2 }) includes ({ 3 }) features ({ 4 }) associated ({ 5 }) with ({ 6 }) verb-noun ({ 7 }) relations ({ 8 }) ( ({ 9 }) e.g. ({ 10 }) SS ({ 11 }) :verb ({ 12 }) .consumption-SS ({ 13 }) :noun ({ 14 }) .food ({ 15 }) ) ({ 16 }) and ({ 17 }) noun-noun ({ 18 }) relations ({ 19 }) ( ({ 20 }) e.g. ({ 21 }) SS ({ 22 }) :noun ({ 23 }) .communication-SS ({ 24 }) :noun ({ 25 }) .communication ({ 26 }) ) ({ 27 }) , ({ 28 }) which ({ 29 }) we ({ 30 }) will ({ 31 }) describe ({ 32 }) in ({ 33 }) detail ({ 34 }) with ({ 35 }) several ({ 36 }) examples ({ 37 }) . ({ 38 }) 
# Sentence pair (592) source length 21 target length 21 alignment score : 0.000133766
Hereinafter , / MATH denotes / MATH in Equation 3 , and / MATH denotes the exponential of / MATH . 
NULL ({ }) Hereinafter ({ 1 }) , ({ 2 }) / ({ 3 }) MATH ({ 4 }) denotes ({ 5 }) / ({ 6 }) MATH ({ 7 }) in ({ 8 }) Equation ({ 9 }) 3 ({ 10 }) , ({ 11 }) and ({ 12 }) / ({ 13 }) MATH ({ 14 }) denotes ({ 15 }) the ({ 16 }) exponential ({ 17 }) of ({ 18 }) / ({ 19 }) MATH ({ 20 }) . ({ 21 }) 
# Sentence pair (593) source length 41 target length 39 alignment score : 7.67409e-14
We call a feature either with a positive lambda or with an alpha larger than 1 as an excitatory feature , while that either with a negative lambda or an alpha smaller than 1 as an inhibitory feature . 
NULL ({ }) We ({ 1 }) call ({ 2 }) a ({ 3 }) feature ({ 4 }) either ({ 5 }) with ({ 6 }) a ({ 7 }) positive ({ 8 }) lambda ({ 9 }) or ({ 10 }) with ({ 11 }) an ({ 12 }) alpha ({ 13 }) larger ({ 14 }) than ({ 15 }) 1 ({ 16 }) as ({ 17 }) an ({ 18 }) excitatory ({ 19 }) feature ({ 20 }) , ({ 21 }) and ({ 22 }) those ({ 23 }) features ({ }) with ({ }) either ({ 24 }) with ({ 25 }) a ({ 26 }) negative ({ 27 }) lambda ({ 28 }) or ({ 29 }) an ({ 30 }) alpha ({ 31 }) smaller ({ 32 }) than ({ 33 }) 1 ({ 34 }) as ({ 35 }) an ({ 36 }) inhibitory ({ 37 }) feature ({ 38 }) . ({ 39 }) 
# Sentence pair (594) source length 18 target length 18 alignment score : 0.00182653
Also , Table 14 shows the 15 largest-weighted sense dependency features in the linear-chain , synset-based model . 
NULL ({ }) Also ({ 1 }) , ({ 2 }) Table ({ 3 }) 14 ({ 4 }) shows ({ 5 }) the ({ 6 }) 15 ({ 7 }) largest-weighted ({ 8 }) sense ({ 9 }) dependency ({ 10 }) features ({ 11 }) in ({ 12 }) the ({ 13 }) linear-chain ({ 14 }) , ({ 15 }) synset-based ({ 16 }) model ({ 17 }) . ({ 18 }) 
# Sentence pair (595) source length 34 target length 34 alignment score : 4.78596e-07
When compared to the outputs of the tree-structured model , we can see that the linear-chain model captures more successive noun-noun dependencies , while the tree-structured model captures more adjective-noun and verb-object dependencies . 
NULL ({ }) When ({ 1 }) compared ({ 2 }) to ({ 3 }) the ({ 4 }) outputs ({ 5 }) of ({ 6 }) the ({ 7 }) tree-structured ({ 8 }) model ({ 9 }) , ({ 10 }) we ({ 11 }) can ({ 12 }) see ({ 13 }) that ({ 14 }) the ({ 15 }) linear-chain ({ 16 }) model ({ 17 }) captures ({ 18 }) more ({ 19 }) successive ({ 20 }) noun-noun ({ 21 }) dependencies ({ 22 }) , ({ 23 }) while ({ 24 }) the ({ 25 }) tree-structured ({ 26 }) model ({ 27 }) captures ({ 28 }) more ({ 29 }) adjective-noun ({ 30 }) and ({ 31 }) verb-object ({ 32 }) dependencies ({ 33 }) . ({ 34 }) 
# Sentence pair (596) source length 37 target length 36 alignment score : 5.159e-08
Thus , although the difference of the recalls is small , we can assume that the sense dependency features in the tree-structured model and those in the linear-chain model have different contributions to the results . 
NULL ({ }) Thus ({ 1 }) , ({ 2 }) although ({ 3 }) the ({ 4 }) difference ({ 5 }) of ({ 6 }) the ({ 7 }) recalls ({ 8 }) is ({ 9 }) small ({ 10 }) , ({ 11 }) we ({ 12 }) can ({ 13 }) assume ({ 14 }) that ({ 15 }) the ({ 16 }) sense ({ 17 }) dependency ({ 18 }) features ({ 19 }) in ({ 20 }) the ({ 21 }) tree-structured ({ 22 }) model ({ 23 }) , ({ }) and ({ 24 }) those ({ 25 }) in ({ 26 }) the ({ 27 }) linear-chain ({ 28 }) model ({ 29 }) have ({ 30 }) different ({ 31 }) contributions ({ 32 }) to ({ 33 }) the ({ 34 }) results ({ 35 }) . ({ 36 }) 
# Sentence pair (597) source length 33 target length 33 alignment score : 2.06009e-07
The simultaneous use of both is of an interest from practical and semantical perspectives ; However , since it makes our model no longer a tree , the implementation is not straightforward . 
NULL ({ }) The ({ 1 }) simultaneous ({ 2 }) use ({ 3 }) of ({ 4 }) both ({ 5 }) is ({ 6 }) of ({ 7 }) an ({ 8 }) interest ({ 9 }) from ({ 10 }) practical ({ 11 }) and ({ 12 }) semantical ({ 13 }) perspectives ({ 14 }) ; ({ 15 }) however ({ 16 }) , ({ 17 }) since ({ 18 }) it ({ 19 }) makes ({ 20 }) our ({ 21 }) model ({ 22 }) no ({ 23 }) longer ({ 24 }) a ({ 25 }) tree ({ 26 }) , ({ 27 }) the ({ 28 }) implementation ({ 29 }) is ({ 30 }) not ({ 31 }) straightforward ({ 32 }) . ({ 33 }) 
# Sentence pair (598) source length 12 target length 12 alignment score : 0.0141902
Hence , this is left as one of our future works . 
NULL ({ }) Hence ({ 1 }) , ({ 2 }) this ({ 3 }) is ({ 4 }) left ({ 5 }) as ({ 6 }) one ({ 7 }) of ({ 8 }) our ({ 9 }) future ({ 10 }) works ({ 11 }) . ({ 12 }) 
# Sentence pair (599) source length 39 target length 38 alignment score : 3.3683e-08
In this section , we present instance-based analyses based on the first 100 instances for which the answer of the dependency model Tree-WS-SR differs from that of the non-dependency model NoDep-WS-SR in the first trial on SemCor . 
NULL ({ }) In ({ 1 }) this ({ 2 }) section ({ 3 }) , ({ 4 }) we ({ 5 }) present ({ 6 }) an ({ }) instance-based ({ 7 }) analyses ({ 8 }) based ({ 9 }) on ({ 10 }) the ({ 11 }) first ({ 12 }) 100 ({ 13 }) instances ({ 14 }) for ({ 15 }) which ({ 16 }) the ({ 17 }) answer ({ 18 }) of ({ 19 }) the ({ 20 }) dependency ({ 21 }) model ({ 22 }) Tree-WS-SR ({ 23 }) differs ({ 24 }) from ({ 25 }) that ({ 26 }) of ({ 27 }) the ({ 28 }) non-dependency ({ 29 }) model ({ 30 }) NoDep-WS-SR ({ 31 }) in ({ 32 }) the ({ 33 }) first ({ 34 }) trial ({ 35 }) on ({ 36 }) SemCor ({ 37 }) . ({ 38 }) 
# Sentence pair (600) source length 23 target length 23 alignment score : 7.94578e-05
We extracted only the largest-weighted edge feature for each instance , assuming that this feature had the largest contribution to the result . 
NULL ({ }) We ({ 1 }) extracted ({ 2 }) only ({ 3 }) the ({ 4 }) largest-weighted ({ 5 }) edge ({ 6 }) feature ({ 7 }) for ({ 8 }) each ({ 9 }) instance ({ 10 }) , ({ 11 }) assuming ({ 12 }) that ({ 13 }) this ({ 14 }) feature ({ 15 }) had ({ 16 }) the ({ 17 }) largest ({ 18 }) contribution ({ 19 }) to ({ 20 }) the ({ 21 }) result ({ 22 }) . ({ 23 }) 
# Sentence pair (601) source length 38 target length 38 alignment score : 6.19306e-08
These instances consist of 54 positive instances , for which Tree-WS-SR output the correct answer while NoDep-WS-SR did not , and 46 negative instances , for which Tree-WS-SR did not output the correct answer while NoDep-WS-SR did . 
NULL ({ }) These ({ 1 }) instances ({ 2 }) consist ({ 3 }) of ({ 4 }) 54 ({ 5 }) positive ({ 6 }) instances ({ 7 }) , ({ 8 }) for ({ 9 }) which ({ 10 }) Tree-WS-SR ({ 11 }) output ({ 12 }) the ({ 13 }) correct ({ 14 }) answer ({ 15 }) while ({ 16 }) NoDep-WS-SR ({ 17 }) did ({ 18 }) not ({ 19 }) , ({ 20 }) and ({ 21 }) 46 ({ 22 }) negative ({ 23 }) instances ({ 24 }) , ({ 25 }) for ({ 26 }) which ({ 27 }) Tree-WS-SR ({ 28 }) did ({ 29 }) not ({ 30 }) output ({ 31 }) the ({ 32 }) correct ({ 33 }) answer ({ 34 }) while ({ 35 }) NoDep-WS-SR ({ 36 }) did ({ 37 }) . ({ 38 }) 
# Sentence pair (602) source length 15 target length 15 alignment score : 0.000210454
Table 15 and 16 shows the count of each edge type for these instances . 
NULL ({ }) Table ({ 1 }) 15 ({ 2 }) and ({ 3 }) 16 ({ 4 }) show ({ 5 }) the ({ 6 }) count ({ 7 }) of ({ 8 }) each ({ 9 }) edge ({ 10 }) type ({ 11 }) for ({ 12 }) these ({ 13 }) instances ({ 14 }) . ({ 15 }) 
# Sentence pair (603) source length 23 target length 23 alignment score : 0.000240463
For both positive and negative instances , the verb-noun dependencies are the dominant dependencies , corresponding to 48% of all the instances . 
NULL ({ }) For ({ 1 }) both ({ 2 }) positive ({ 3 }) and ({ 4 }) negative ({ 5 }) instances ({ 6 }) , ({ 7 }) the ({ 8 }) verb-noun ({ 9 }) dependencies ({ 10 }) are ({ 11 }) the ({ 12 }) dominant ({ 13 }) dependencies ({ 14 }) , ({ 15 }) corresponding ({ 16 }) to ({ 17 }) 48% ({ 18 }) of ({ 19 }) all ({ 20 }) the ({ 21 }) instances ({ 22 }) . ({ 23 }) 
# Sentence pair (604) source length 40 target length 41 alignment score : 5.39857e-11
One noteworthy point is that more number of noun-noun dependencies are found in the positive instances than in the negative instances , which might suggest that noun-noun dependencies are particularly likely to capture useful dependencies and contribute to positive instances . 
NULL ({ }) One ({ 1 }) noteworthy ({ 2 }) point ({ 3 }) is ({ 4 }) that ({ 5 }) more ({ 6 }) number ({ 7 }) of ({ 8 }) noun-noun ({ 9 }) dependencies ({ 10 }) are ({ 11 }) found ({ 12 }) in ({ 13 }) the ({ 14 }) positive ({ 15 }) instances ({ 16 }) than ({ 17 }) in ({ 18 }) the ({ 19 }) negative ({ 20 }) instances ({ 21 }) , ({ 22 }) further ({ 23 }) suggesting ({ 24 25 }) that ({ 26 }) noun-noun ({ 27 }) dependencies ({ 28 }) are ({ 29 }) particularly ({ 30 }) likely ({ 31 }) to ({ 32 }) capture ({ 33 }) useful ({ 34 }) dependencies ({ 35 }) and ({ 36 }) contribute ({ 37 }) to ({ 38 }) positive ({ 39 }) instances ({ 40 }) . ({ 41 }) 
# Sentence pair (605) source length 17 target length 17 alignment score : 0.000560861
First of all , let us present two instances in which the verb-noun dependencies worked effectively . 
NULL ({ }) First ({ 1 }) of ({ 2 }) all ({ 3 }) , ({ 4 }) let ({ 5 }) us ({ 6 }) present ({ 7 }) two ({ 8 }) instances ({ 9 }) in ({ 10 }) which ({ 11 }) the ({ 12 }) verb-noun ({ 13 }) dependencies ({ 14 }) worked ({ 15 }) effectively ({ 16 }) . ({ 17 }) 
# Sentence pair (606) source length 5 target length 4 alignment score : 0.0214186
The first sentence is 
NULL ({ }) The ({ 1 }) first ({ 2 }) sentence ({ 3 }) is ({ 4 }) : ({ }) 
# Sentence pair (607) source length 24 target length 24 alignment score : 7.74319e-05
From this earth , then , while it was still virgin God took dust and fashioned the man , the beginning of humanity . 
NULL ({ }) From ({ 1 }) this ({ 2 }) earth ({ 3 }) , ({ 4 }) then ({ 5 }) , ({ 6 }) while ({ 7 }) it ({ 8 }) was ({ 9 }) still ({ 10 }) virgin ({ 11 }) God ({ 12 }) took ({ 13 }) dust ({ 14 }) and ({ 15 }) fashioned ({ 16 }) the ({ 17 }) man ({ 18 }) , ({ 19 }) the ({ 20 }) beginning ({ 21 }) of ({ 22 }) humanity ({ 23 }) . ({ 24 }) 
# Sentence pair (608) source length 15 target length 14 alignment score : 4.90595e-08
The verb take has surprisingly as many as 42 senses in the WordNet . 
NULL ({ }) Surprisingly ({ 1 5 }) , ({ }) the ({ }) verb ({ 2 }) take ({ 3 }) has ({ 4 }) as ({ 6 }) many ({ 7 }) as ({ 8 }) 42 ({ 9 }) senses ({ 10 }) in ({ 11 }) the ({ 12 }) WordNet ({ 13 }) . ({ 14 }) 
# Sentence pair (609) source length 55 target length 56 alignment score : 1.58662e-10
But , fortunatelly , the first six senses belong to different supersenses , and our dependency model succeeded in outputting the correct sense take#4 ( SS :verb .contact , take physically ) by making use of the strong dependency SS :verb .contact-SS :noun .substance ( / MATH ) , given dust#1 belongs to noun .substance . 
NULL ({ 2 }) But ({ 1 }) fortunately ({ 3 }) , ({ 4 }) the ({ 5 }) first ({ 6 }) six ({ 7 }) senses ({ 8 }) belong ({ 9 }) to ({ 10 }) different ({ 11 }) supersenses ({ 12 }) , ({ 13 }) and ({ 14 }) our ({ 15 }) dependency ({ 16 }) model ({ 17 }) succeeded ({ 18 }) in ({ 19 }) outputting ({ 20 }) the ({ 21 }) correct ({ 22 }) sense ({ 23 }) take#4 ({ 24 }) ( ({ 25 }) SS ({ 26 }) :verb ({ 27 }) .contact ({ 28 }) , ({ 29 }) take ({ 30 }) physically ({ 31 }) ) ({ 32 }) by ({ 33 }) making ({ 34 }) use ({ 35 }) of ({ 36 }) the ({ 37 }) strong ({ 38 }) dependency ({ 39 }) SS ({ 40 }) :verb ({ 41 }) .contact-SS ({ 42 }) :noun ({ 43 }) .substance ({ 44 }) ( ({ 45 }) / ({ 46 }) MATH ({ 47 }) ) ({ 48 }) , ({ 49 }) given ({ 50 }) dust#1 ({ 51 }) belongs ({ 52 }) to ({ 53 }) noun ({ 54 }) .substance ({ 55 }) . ({ 56 }) 
# Sentence pair (610) source length 14 target length 14 alignment score : 0.00643094
The second instance is also a positive instance from the SEM-A data set . 
NULL ({ }) The ({ 1 }) second ({ 2 }) instance ({ 3 }) is ({ 4 }) also ({ 5 }) a ({ 6 }) positive ({ 7 }) instance ({ 8 }) from ({ 9 }) the ({ 10 }) SEM-A ({ 11 }) data ({ 12 }) set ({ 13 }) . ({ 14 }) 
# Sentence pair (611) source length 36 target length 36 alignment score : 1.00308e-06
For a serious young man who plays golf with a serious intensity , Palmer has such an inherent sense of humor that it relieves the strain and keeps his nerves from jangling like banjo strings . 
NULL ({ }) For ({ 1 }) a ({ 2 }) serious ({ 3 }) young ({ 4 }) man ({ 5 }) who ({ 6 }) plays ({ 7 }) golf ({ 8 }) with ({ 9 }) a ({ 10 }) serious ({ 11 }) intensity ({ 12 }) , ({ 13 }) Palmer ({ 14 }) has ({ 15 }) such ({ 16 }) an ({ 17 }) inherent ({ 18 }) sense ({ 19 }) of ({ 20 }) humor ({ 21 }) that ({ 22 }) it ({ 23 }) relieves ({ 24 }) the ({ 25 }) strain ({ 26 }) and ({ 27 }) keeps ({ 28 }) his ({ 29 }) nerves ({ 30 }) from ({ 31 }) jangling ({ 32 }) like ({ 33 }) banjo ({ 34 }) strings ({ 35 }) . ({ 36 }) 
# Sentence pair (612) source length 15 target length 15 alignment score : 0.00156793
Here , has is an ambiguous verb that has 19 senses in the WordNet . 
NULL ({ }) Here ({ 1 }) , ({ 2 }) has ({ 3 }) is ({ 4 }) an ({ 5 }) ambiguous ({ 6 }) verb ({ 7 }) that ({ 8 }) has ({ 9 }) 19 ({ 10 }) senses ({ 11 }) in ({ 12 }) the ({ 13 }) WordNet ({ 14 }) . ({ 15 }) 
# Sentence pair (613) source length 19 target length 19 alignment score : 0.000892891
The correct sense here is have( v )#2 ( SS :verb .stative , have as a feature ) . 
NULL ({ }) The ({ 1 }) correct ({ 2 }) sense ({ 3 }) here ({ 4 }) is ({ 5 }) have( ({ 6 }) v ({ 7 }) )#2 ({ 8 }) ( ({ 9 }) SS ({ 10 }) :verb ({ 11 }) .stative ({ 12 }) , ({ 13 }) have ({ 14 }) as ({ 15 }) a ({ 16 }) feature ({ 17 }) ) ({ 18 }) . ({ 19 }) 
# Sentence pair (614) source length 34 target length 34 alignment score : 3.55325e-06
Given sense of humor#1 belongs to the supersense noun .attribute , the correct sense was output by the strong verb-object dependency G1 :have( v )#2-( OBJ )-SS :noun .attribute ( / MATH ) . 
NULL ({ }) Given ({ 1 }) sense ({ 2 }) of ({ 3 }) humor#1 ({ 4 }) belongs ({ 5 }) to ({ 6 }) the ({ 7 }) supersense ({ 8 }) noun ({ 9 }) .attribute ({ 10 }) , ({ 11 }) the ({ 12 }) correct ({ 13 }) sense ({ 14 }) was ({ 15 }) output ({ 16 }) by ({ 17 }) the ({ 18 }) strong ({ 19 }) verb-object ({ 20 }) dependency ({ 21 }) G1 ({ 22 }) :have( ({ 23 }) v ({ 24 }) )#2-( ({ 25 }) OBJ ({ 26 }) )-SS ({ 27 }) :noun ({ 28 }) .attribute ({ 29 }) ( ({ 30 }) / ({ 31 }) MATH ({ 32 }) ) ({ 33 }) . ({ 34 }) 
# Sentence pair (615) source length 45 target length 44 alignment score : 1.70311e-09
While this verb-object dependency had a large excitatory weight , the corresponding verb-subject dependency had an inhibitory weight ( G1 :have( v )#2-( SBJ )-SS :noun .attribute ( / MATH ) ) , which means the dependency relationlabel also contributed to the result . 
NULL ({ }) While ({ 1 }) this ({ 2 }) verb-object ({ 3 }) dependency ({ 4 }) had ({ 5 }) a ({ 6 }) large ({ 7 }) excitatory ({ 8 }) weight ({ 9 }) , ({ 10 }) the ({ 11 }) corresponding ({ 12 }) verb-subject ({ 13 }) dependency ({ 14 }) had ({ 15 }) an ({ 16 }) inhibitory ({ 17 }) weight ({ 18 }) ( ({ 19 }) G1 ({ 20 }) :have( ({ 21 }) v ({ 22 }) )#2-( ({ 23 }) SBJ ({ 24 }) )-SS ({ 25 }) :noun ({ 26 }) .attribute ({ 27 }) ( ({ 28 }) / ({ 29 }) MATH ({ 30 }) ) ({ 31 }) ) ({ 32 }) , ({ 33 }) which ({ 34 }) indicates ({ 35 }) that ({ }) the ({ 36 }) dependency ({ 37 }) relationlabel ({ 38 }) also ({ 39 }) contributed ({ 40 }) to ({ 41 }) the ({ 42 }) result ({ 43 }) . ({ 44 }) 
# Sentence pair (616) source length 13 target length 13 alignment score : 0.00278269
Note also that this long dependency cannot be described by linear-chain models . 
NULL ({ }) Note ({ 1 }) also ({ 2 }) that ({ 3 }) this ({ 4 }) long ({ 5 }) dependency ({ 6 }) cannot ({ 7 }) be ({ 8 }) described ({ 9 }) by ({ 10 }) linear-chain ({ 11 }) models ({ 12 }) . ({ 13 }) 
# Sentence pair (617) source length 17 target length 17 alignment score : 0.00051734
Next , let us show a typical negative example , where a verb-subject dependency worked inappropriately . 
NULL ({ }) Next ({ 1 }) , ({ 2 }) let ({ 3 }) us ({ 4 }) show ({ 5 }) a ({ 6 }) typical ({ 7 }) negative ({ 8 }) example ({ 9 }) , ({ 10 }) where ({ 11 }) a ({ 12 }) verb-subject ({ 13 }) dependency ({ 14 }) worked ({ 15 }) inappropriately ({ 16 }) . ({ 17 }) 
# Sentence pair (618) source length 27 target length 27 alignment score : 1.74711e-05
The repeated efforts in Christian history to describe death as altogether the consequence of human sin show that these two aspects of death cannot be separated . 
NULL ({ }) The ({ 1 }) repeated ({ 2 }) efforts ({ 3 }) in ({ 4 }) Christian ({ 5 }) history ({ 6 }) to ({ 7 }) describe ({ 8 }) death ({ 9 }) as ({ 10 }) altogether ({ 11 }) the ({ 12 }) consequence ({ 13 }) of ({ 14 }) human ({ 15 }) sin ({ 16 }) show ({ 17 }) that ({ 18 }) these ({ 19 }) two ({ 20 }) aspects ({ 21 }) of ({ 22 }) death ({ 23 }) cannot ({ 24 }) be ({ 25 }) separated ({ 26 }) . ({ 27 }) 
# Sentence pair (619) source length 52 target length 52 alignment score : 1.488e-09
The correct sense for show here is show#2 ( verb .cognition , establish the validity ) , but the model output show#3 ( verb .communication , prove evidence for ) affected by the long dependency WS :testify( v )#2-( SBJ )-SS :noun .act ( / MATH ) between efforts and show . 
NULL ({ }) The ({ 1 }) correct ({ 2 }) sense ({ 3 }) for ({ 4 }) show ({ 5 }) here ({ 6 }) is ({ 7 }) show#2 ({ 8 }) ( ({ 9 }) verb ({ 10 }) .cognition ({ 11 }) , ({ 12 }) establish ({ 13 }) the ({ 14 }) validity ({ 15 }) ) ({ 16 }) , ({ 17 }) but ({ 18 }) the ({ 19 }) model ({ 20 }) output ({ 21 }) show#3 ({ 22 }) ( ({ 23 }) verb ({ 24 }) .communication ({ 25 }) , ({ 26 }) prove ({ 27 }) evidence ({ 28 }) for ({ 29 }) ) ({ 30 }) affected ({ 31 }) by ({ 32 }) the ({ 33 }) long ({ 34 }) dependency ({ 35 }) WS ({ 36 }) :testify( ({ 37 }) v ({ 38 }) )#2-( ({ 39 }) SBJ ({ 40 }) )-SS ({ 41 }) :noun ({ 42 }) .act ({ 43 }) ( ({ 44 }) / ({ 45 }) MATH ({ 46 }) ) ({ 47 }) between ({ 48 }) efforts ({ 49 }) and ({ 50 }) show ({ 51 }) . ({ 52 }) 
# Sentence pair (620) source length 13 target length 14 alignment score : 1.83174e-05
This subject information seems to be not adequate for the disambiguation of show . 
NULL ({ }) This ({ 1 }) subject ({ 2 }) information ({ 3 }) seems ({ 4 }) to ({ 5 }) be ({ 6 }) inadequate ({ 7 8 }) for ({ 9 }) the ({ 10 }) disambiguation ({ 11 }) of ({ 12 }) show ({ 13 }) . ({ 14 }) 
# Sentence pair (621) source length 8 target length 8 alignment score : 0.0548447
Next we focus on the noun-noun dependencies . 
NULL ({ }) Next ({ 1 }) we ({ 2 }) focus ({ 3 }) on ({ 4 }) the ({ 5 }) noun-noun ({ 6 }) dependencies ({ 7 }) . ({ 8 }) 
# Sentence pair (622) source length 8 target length 8 alignment score : 0.0667017
The first example is a negative instance . 
NULL ({ }) The ({ 1 }) first ({ 2 }) example ({ 3 }) is ({ 4 }) a ({ 5 }) negative ({ 6 }) instance ({ 7 }) . ({ 8 }) 
# Sentence pair (623) source length 24 target length 24 alignment score : 3.53967e-05
Philadelphia permitted him to seek a better connection after he had refused to reconsider his decision to end his career as a player . 
NULL ({ }) Philadelphia ({ 1 }) permitted ({ 2 }) him ({ 3 }) to ({ 4 }) seek ({ 5 }) a ({ 6 }) better ({ 7 }) connection ({ 8 }) after ({ 9 }) he ({ 10 }) had ({ 11 }) refused ({ 12 }) to ({ 13 }) reconsider ({ 14 }) his ({ 15 }) decision ({ 16 }) to ({ 17 }) end ({ 18 }) his ({ 19 }) career ({ 20 }) as ({ 21 }) a ({ 22 }) player ({ 23 }) . ({ 24 }) 
# Sentence pair (624) source length 32 target length 32 alignment score : 2.48459e-06
The noun career has two meanings : the particular occupation for which you are trained ( career#1 ) and the general progression of your working or professional life ( career#2 ) . 
NULL ({ }) The ({ 1 }) noun ({ 2 }) career ({ 3 }) has ({ 4 }) two ({ 5 }) meanings ({ 6 }) : ({ 7 }) the ({ 8 }) particular ({ 9 }) occupation ({ 10 }) for ({ 11 }) which ({ 12 }) you ({ 13 }) are ({ 14 }) trained ({ 15 }) ( ({ 16 }) career#1 ({ 17 }) ) ({ 18 }) and ({ 19 }) the ({ 20 }) general ({ 21 }) progression ({ 22 }) of ({ 23 }) your ({ 24 }) working ({ 25 }) or ({ 26 }) professional ({ 27 }) life ({ 28 }) ( ({ 29 }) career#2 ({ 30 }) ) ({ 31 }) . ({ 32 }) 
# Sentence pair (625) source length 56 target length 54 alignment score : 1.45725e-13
From the phrase career as a player , we can assume that the correct sense of career can be either of two senses , and possibly there is a preference for career#2 , as captured by the largest-weighted dependency WS :career%1%2-( NMOD )-SS :noun .person ( / MATH ) between career and player . 
NULL ({ }) From ({ 1 }) the ({ 2 }) phrase ({ 3 }) career ({ 4 }) as ({ 5 }) a ({ 6 }) player ({ 7 }) , ({ 8 }) we ({ 9 }) can ({ 10 }) assume ({ 11 }) that ({ 12 }) the ({ 13 }) correct ({ 14 }) sense ({ 15 }) of ({ 16 }) career ({ 17 }) can ({ 18 }) be ({ 19 }) either ({ 20 }) of ({ 21 }) two ({ 22 }) senses ({ 23 }) , ({ 24 }) with ({ 25 }) the ({ }) possibility ({ 26 }) that ({ }) there ({ 27 }) is ({ 28 }) a ({ 29 }) preference ({ 30 }) for ({ 31 }) career#2 ({ 32 }) , ({ 33 }) as ({ 34 }) captured ({ 35 }) by ({ 36 }) the ({ 37 }) largest-weighted ({ 38 }) dependency ({ 39 }) WS ({ 40 }) :career%1%2-( ({ 41 }) NMOD ({ 42 }) )-SS ({ 43 }) :noun ({ 44 }) .person ({ 45 }) ( ({ 46 }) / ({ 47 }) MATH ({ 48 }) ) ({ 49 }) between ({ 50 }) career ({ 51 }) and ({ 52 }) player ({ 53 }) . ({ 54 }) 
# Sentence pair (626) source length 28 target length 28 alignment score : 2.20131e-05
Although there was originally the preference for the correct sense career#1 by the sense frequency features , the noun-noun dependency thus contributed to the wrong answer career#2 . 
NULL ({ }) Although ({ 1 }) there ({ 2 }) was ({ 3 }) originally ({ 4 }) the ({ 5 }) preference ({ 6 }) for ({ 7 }) the ({ 8 }) correct ({ 9 }) sense ({ 10 }) career#1 ({ 11 }) by ({ 12 }) the ({ 13 }) sense ({ 14 }) frequency ({ 15 }) features ({ 16 }) , ({ 17 }) the ({ 18 }) noun-noun ({ 19 }) dependency ({ 20 }) thus ({ 21 }) contributed ({ 22 }) to ({ 23 }) the ({ 24 }) wrong ({ 25 }) answer ({ 26 }) career#2 ({ 27 }) . ({ 28 }) 
# Sentence pair (627) source length 22 target length 22 alignment score : 0.000117404
The determining clue for this instance seems to be the verb-object dependency end-career , which was not captured by our model . 
NULL ({ }) The ({ 1 }) determining ({ 2 }) clue ({ 3 }) for ({ 4 }) this ({ 5 }) instance ({ 6 }) seems ({ 7 }) to ({ 8 }) be ({ 9 }) the ({ 10 }) verb-object ({ 11 }) dependency ({ 12 }) end-career ({ 13 }) , ({ 14 }) which ({ 15 }) was ({ 16 }) not ({ 17 }) captured ({ 18 }) by ({ 19 }) our ({ 20 }) model ({ 21 }) . ({ 22 }) 
# Sentence pair (628) source length 19 target length 19 alignment score : 0.000470191
Among the ten positive instances of the noun-noun dependencies , four instances were contributed by the noun-of-noun dependencies . 
NULL ({ }) Among ({ 1 }) the ({ 2 }) ten ({ 3 }) positive ({ 4 }) instances ({ 5 }) of ({ 6 }) the ({ 7 }) noun-noun ({ 8 }) dependencies ({ 9 }) , ({ 10 }) four ({ 11 }) instances ({ 12 }) were ({ 13 }) contributed ({ 14 }) by ({ 15 }) the ({ 16 }) noun-of-noun ({ 17 }) dependencies ({ 18 }) . ({ 19 }) 
# Sentence pair (629) source length 23 target length 25 alignment score : 1.72042e-14
Since dependencies of this type were not observed in the negative instances at all , they seem to particularly contribute to the positive instances . 
NULL ({ 13 14 }) Since ({ 1 }) dependencies ({ 2 }) of ({ 3 }) this ({ 4 }) type ({ 5 }) were ({ 6 }) not ({ 7 }) observed ({ 8 }) in ({ 9 }) the ({ 10 }) negative ({ 11 }) instances ({ 12 }) , ({ 15 }) they ({ 16 }) seem ({ 17 }) to ({ 18 }) particularly ({ 19 }) contribute ({ 20 }) to ({ 21 }) the ({ 22 }) positive ({ 23 }) instances ({ 24 }) . ({ 25 }) 
# Sentence pair (630) source length 7 target length 7 alignment score : 0.0684111
Let us consider the following example . 
NULL ({ }) Let ({ 1 }) us ({ 2 }) consider ({ 3 }) the ({ 4 }) following ({ 5 }) example ({ 6 }) . ({ 7 }) 
# Sentence pair (631) source length 44 target length 44 alignment score : 1.56605e-08
The embarrassment of these theories over the naturalness of death is an illustration of the thesis that death cannot be only a punishment , for some termination seems necessary in a life that is lived within the natural order of time and change . 
NULL ({ }) The ({ 1 }) embarrassment ({ 2 }) of ({ 3 }) these ({ 4 }) theories ({ 5 }) over ({ 6 }) the ({ 7 }) naturalness ({ 8 }) of ({ 9 }) death ({ 10 }) is ({ 11 }) an ({ 12 }) illustration ({ 13 }) of ({ 14 }) the ({ 15 }) thesis ({ 16 }) that ({ 17 }) death ({ 18 }) cannot ({ 19 }) be ({ 20 }) only ({ 21 }) a ({ 22 }) punishment ({ 23 }) , ({ 24 }) for ({ 25 }) some ({ 26 }) termination ({ 27 }) seems ({ 28 }) necessary ({ 29 }) in ({ 30 }) a ({ 31 }) life ({ 32 }) that ({ 33 }) is ({ 34 }) lived ({ 35 }) within ({ 36 }) the ({ 37 }) natural ({ 38 }) order ({ 39 }) of ({ 40 }) time ({ 41 }) and ({ 42 }) change ({ 43 }) . ({ 44 }) 
# Sentence pair (632) source length 63 target length 63 alignment score : 3.12426e-11
Although the correct sense time#5 ( noun .Tops , the continuum of experience in which events pass from the future through the present to the past ) is not a frequent sense , our model correctly output the correct sense by using the dependency SS :noun .object-of-WS :time%1%5 ( / MATH ) , given natural order#1 belongs to the supersense noun .object . 
NULL ({ }) Although ({ 1 }) the ({ 2 }) correct ({ 3 }) sense ({ 4 }) time#5 ({ 5 }) ( ({ 6 }) noun ({ 7 }) .Tops ({ 8 }) , ({ 9 }) the ({ 10 }) continuum ({ 11 }) of ({ 12 }) experience ({ 13 }) in ({ 14 }) which ({ 15 }) events ({ 16 }) pass ({ 17 }) from ({ 18 }) the ({ 19 }) future ({ 20 }) through ({ 21 }) the ({ 22 }) present ({ 23 }) to ({ 24 }) the ({ 25 }) past ({ 26 }) ) ({ 27 }) is ({ 28 }) not ({ 29 }) a ({ 30 }) frequent ({ 31 }) sense ({ 32 }) , ({ 33 }) our ({ 34 }) model ({ 35 }) correctly ({ 36 }) output ({ 37 }) the ({ 38 }) correct ({ 39 }) sense ({ 40 }) by ({ 41 }) using ({ 42 }) the ({ 43 }) dependency ({ 44 }) SS ({ 45 }) :noun ({ 46 }) .object-of-WS ({ 47 }) :time%1%5 ({ 48 }) ( ({ 49 }) / ({ 50 }) MATH ({ 51 }) ) ({ 52 }) , ({ 53 }) given ({ 54 }) natural ({ 55 }) order#1 ({ 56 }) belongs ({ 57 }) to ({ 58 }) the ({ 59 }) supersense ({ 60 }) noun ({ 61 }) .object ({ 62 }) . ({ 63 }) 
# Sentence pair (633) source length 17 target length 16 alignment score : 2.00889e-12
Another interesting result observed is that the noun-noun dependencies in coordination relations work remarkably strongly . 
NULL ({ 5 }) Through ({ 1 }) our ({ 2 }) result ({ 3 }) , ({ }) we ({ }) observed ({ 4 }) that ({ 6 }) the ({ 7 }) noun-noun ({ 8 }) dependencies ({ 9 }) in ({ 10 }) coordination ({ 11 }) relations ({ 12 }) work ({ 13 }) remarkably ({ 14 }) well ({ 15 }) . ({ 16 }) 
# Sentence pair (634) source length 20 target length 20 alignment score : 0.000643232
In the following sentence , three words nails , levels , and T squares are in a coordination relation . 
NULL ({ }) In ({ 1 }) the ({ 2 }) following ({ 3 }) sentence ({ 4 }) , ({ 5 }) three ({ 6 }) words ({ 7 }) nails ({ 8 }) , ({ 9 }) levels ({ 10 }) , ({ 11 }) and ({ 12 }) T ({ 13 }) squares ({ 14 }) are ({ 15 }) in ({ 16 }) a ({ 17 }) coordination ({ 18 }) relation ({ 19 }) . ({ 20 }) 
# Sentence pair (635) source length 50 target length 50 alignment score : 3.79991e-09
He also bought a huge square of pegboard for hanging up his tools , and lumber for his workbench , sandpaper and glue and assorted nails , levels and T squares and plumb lines and several gadgets that he had no idea how touse or what they were for . 
NULL ({ }) He ({ 1 }) also ({ 2 }) bought ({ 3 }) a ({ 4 }) huge ({ 5 }) square ({ 6 }) of ({ 7 }) pegboard ({ 8 }) for ({ 9 }) hanging ({ 10 }) up ({ 11 }) his ({ 12 }) tools ({ 13 }) , ({ 14 }) and ({ 15 }) lumber ({ 16 }) for ({ 17 }) his ({ 18 }) workbench ({ 19 }) , ({ 20 }) sandpaper ({ 21 }) and ({ 22 }) glue ({ 23 }) and ({ 24 }) assorted ({ 25 }) nails ({ 26 }) , ({ 27 }) levels ({ 28 }) and ({ 29 }) T ({ 30 }) squares ({ 31 }) and ({ 32 }) plumb ({ 33 }) lines ({ 34 }) and ({ 35 }) several ({ 36 }) gadgets ({ 37 }) that ({ 38 }) he ({ 39 }) had ({ 40 }) no ({ 41 }) idea ({ 42 }) how ({ 43 }) touse ({ 44 }) or ({ 45 }) what ({ 46 }) they ({ 47 }) were ({ 48 }) for ({ 49 }) . ({ 50 }) 
# Sentence pair (636) source length 37 target length 36 alignment score : 5.02807e-07
Here , the correct sense for nail is nail#2 ( noun .artifact , a thin pointed piece of metal ) and that for level is level#5 ( noun .artifact , indicator of the horizontal ) . 
NULL ({ }) Here ({ 1 }) , ({ 2 }) the ({ 3 }) correct ({ 4 }) sense ({ 5 }) for ({ 6 }) nail ({ 7 }) is ({ 8 }) nail#2 ({ 9 }) ( ({ 10 }) noun ({ 11 }) .artifact ({ 12 }) , ({ 13 }) a ({ 14 }) thin ({ 15 }) pointed ({ 16 }) piece ({ 17 }) of ({ 18 }) metal ({ 19 }) ) ({ 20 }) , ({ }) and ({ 21 }) that ({ 22 }) for ({ 23 }) level ({ 24 }) is ({ 25 }) level#5 ({ 26 }) ( ({ 27 }) noun ({ 28 }) .artifact ({ 29 }) , ({ 30 }) indicator ({ 31 }) of ({ 32 }) the ({ 33 }) horizontal ({ 34 }) ) ({ 35 }) . ({ 36 }) 
# Sentence pair (637) source length 20 target length 20 alignment score : 0.00067314
The relatively low frequency of these senses prevent our model from outputting the correct senses in an ordinal way . 
NULL ({ }) The ({ 1 }) relatively ({ 2 }) low ({ 3 }) frequency ({ 4 }) of ({ 5 }) these ({ 6 }) senses ({ 7 }) prevent ({ 8 }) our ({ 9 }) model ({ 10 }) from ({ 11 }) outputting ({ 12 }) the ({ 13 }) correct ({ 14 }) senses ({ 15 }) in ({ 16 }) an ({ 17 }) ordinal ({ 18 }) way ({ 19 }) . ({ 20 }) 
# Sentence pair (638) source length 52 target length 52 alignment score : 3.93545e-09
However , the dependency model could capture the fact that two words in a coordination relation are quite likely to belong to the same semantic group ( SS :noun .artifact-( COORD )-SS :noun .artifact ( / MATH ) ) , and hence succeeded in the correct disambiguation of these three words . 
NULL ({ }) However ({ 1 }) , ({ 2 }) the ({ 3 }) dependency ({ 4 }) model ({ 5 }) could ({ 6 }) capture ({ 7 }) the ({ 8 }) fact ({ 9 }) that ({ 10 }) two ({ 11 }) words ({ 12 }) in ({ 13 }) a ({ 14 }) coordination ({ 15 }) relation ({ 16 }) are ({ 17 }) quite ({ 18 }) likely ({ 19 }) to ({ 20 }) belong ({ 21 }) to ({ 22 }) the ({ 23 }) same ({ 24 }) semantic ({ 25 }) group ({ 26 }) ( ({ 27 }) SS ({ 28 }) :noun ({ 29 }) .artifact-( ({ 30 }) COORD ({ 31 }) )-SS ({ 32 }) :noun ({ 33 }) .artifact ({ 34 }) ( ({ 35 }) / ({ 36 }) MATH ({ 37 }) ) ({ 38 }) ) ({ 39 }) , ({ 40 }) and ({ 41 }) hence ({ 42 }) succeeded ({ 43 }) in ({ 44 }) the ({ 45 }) correct ({ 46 }) disambiguation ({ 47 }) of ({ 48 }) these ({ 49 }) three ({ 50 }) words ({ 51 }) . ({ 52 }) 
# Sentence pair (639) source length 23 target length 23 alignment score : 0.000167233
More generally , we have observed that the coordination features for an edge that connects the same supersense all have positive weights . 
NULL ({ }) More ({ 1 }) generally ({ 2 }) , ({ 3 }) we ({ 4 }) have ({ 5 }) observed ({ 6 }) that ({ 7 }) the ({ 8 }) coordination ({ 9 }) features ({ 10 }) for ({ 11 }) an ({ 12 }) edge ({ 13 }) that ({ 14 }) connects ({ 15 }) the ({ 16 }) same ({ 17 }) supersense ({ 18 }) all ({ 19 }) have ({ 20 }) positive ({ 21 }) weights ({ 22 }) . ({ 23 }) 
# Sentence pair (640) source length 35 target length 35 alignment score : 9.70992e-08
In this paper , we proposed a novel approach to the all-words WSD , focusing on the use of syntactic dependencies of word senses , and investigated the contribution of these dependencies to WSD . 
NULL ({ }) In ({ 1 }) this ({ 2 }) paper ({ 3 }) , ({ 4 }) we ({ 5 }) proposed ({ 6 }) a ({ 7 }) novel ({ 8 }) approach ({ 9 }) for ({ 10 }) the ({ 11 }) all-words ({ 12 }) WSD ({ 13 }) , ({ 14 }) focusing ({ 15 }) on ({ 16 }) the ({ 17 }) use ({ 18 }) of ({ 19 }) syntactic ({ 20 }) dependencies ({ 21 }) of ({ 22 }) word ({ 23 }) senses ({ 24 }) , ({ 25 }) and ({ 26 }) investigated ({ 27 }) the ({ 28 }) contribution ({ 29 }) of ({ 30 }) these ({ 31 }) dependencies ({ 32 }) to ({ 33 }) WSD ({ 34 }) . ({ 35 }) 
# Sentence pair (641) source length 29 target length 29 alignment score : 1.32327e-05
Our proposals were twofold : to apply tree-structured CRFs to the dependency trees , and to use the combined bigrams of fine- and coarse-grained senses as edge features . 
NULL ({ }) Our ({ 1 }) proposals ({ 2 }) were ({ 3 }) twofold ({ 4 }) : ({ 5 }) to ({ 6 }) apply ({ 7 }) tree-structured ({ 8 }) CRFs ({ 9 }) to ({ 10 }) the ({ 11 }) dependency ({ 12 }) trees ({ 13 }) , ({ 14 }) and ({ 15 }) to ({ 16 }) use ({ 17 }) the ({ 18 }) combined ({ 19 }) bigrams ({ 20 }) of ({ 21 }) fine- ({ 22 }) and ({ 23 }) coarse-grained ({ 24 }) senses ({ 25 }) as ({ 26 }) edge ({ 27 }) features ({ 28 }) . ({ 29 }) 
# Sentence pair (642) source length 42 target length 40 alignment score : 8.91959e-10
In our experiments , the sense dependency features were shown to work effectively for WSD , with 0 .29% , 0 .64% , and 0 .30% improvements of recalls for SemCor , Senseval-2 , and Senseval-3 data sets respectively . 
NULL ({ }) In ({ 1 }) our ({ 2 }) experiments ({ 3 }) , ({ 4 }) the ({ 5 }) sense ({ 6 }) dependency ({ 7 }) features ({ 8 }) were ({ 9 }) shown ({ 10 }) to ({ 11 }) work ({ 12 }) effectively ({ 13 }) for ({ 14 }) WSD ({ 15 }) , ({ 16 }) with ({ 17 }) a ({ }) 0 ({ 18 }) .29% ({ 19 }) , ({ 20 }) 0 ({ 21 }) .64% ({ 22 }) , ({ 23 }) and ({ 24 }) 0 ({ 25 }) .30% ({ 26 }) improvement ({ 27 }) of ({ 28 }) recalls ({ 29 }) for ({ 30 }) SemCor ({ 31 }) , ({ 32 }) Senseval-2 ({ 33 }) , ({ 34 }) and ({ 35 }) Senseval-3 ({ 36 }) data ({ 37 }) sets ({ 38 }) , ({ }) respectively ({ 39 }) . ({ 40 }) 
# Sentence pair (643) source length 21 target length 23 alignment score : 1.92392e-12
Despite the small improvements in terms of overall figures , these improvements indeed correspond to 25%-57% improvements over the first sense baseline . 
NULL ({ 7 }) Despite ({ 1 }) the ({ 2 }) small ({ 3 }) improvements ({ 4 }) in ({ 5 }) overall ({ 8 }) figures ({ 6 9 }) , ({ 10 }) these ({ 11 }) improvements ({ 12 }) indeed ({ 13 }) correspond ({ 14 }) to ({ 15 }) 25%-57% ({ 16 }) improvements ({ 17 }) over ({ 18 }) the ({ 19 }) first ({ 20 }) sense ({ 21 }) baseline ({ 22 }) . ({ 23 }) 
# Sentence pair (644) source length 32 target length 29 alignment score : 1.30519e-17
The dependency tree structures was shown to be appropriate for modeling the dependencies of word senses , by the results that the tree-structured models outperformed the linear-chain models . 
NULL ({ 21 }) The ({ 1 }) dependency ({ 2 }) tree ({ 3 }) structures ({ 4 }) were ({ 5 }) shown ({ 6 }) to ({ 7 }) be ({ 8 }) appropriate ({ 9 }) in ({ 10 }) modeling ({ 11 }) the ({ 12 }) dependencies ({ 13 }) of ({ 14 }) word ({ 15 }) senses ({ 16 }) , ({ 17 }) because ({ 18 }) the ({ 19 }) results ({ 20 }) of ({ }) the ({ 22 }) tree-structured ({ 23 }) models ({ 24 }) outperformed ({ 25 }) the ({ 26 }) [results ({ }) of ({ }) ?] ({ }) linear-chain ({ 27 }) models ({ 28 }) . ({ 29 }) 
# Sentence pair (645) source length 28 target length 28 alignment score : 6.99308e-07
In the analysis section , we presented an in-depth analysis of the observed instances , and saw that the noun-noun dependencies particularly contribute to the positive instances . 
NULL ({ }) In ({ 1 }) the ({ 2 }) analysis ({ 3 }) section ({ 4 }) , ({ 5 }) we ({ 6 }) presented ({ 7 }) an ({ 8 }) in-depth ({ 9 }) analysis ({ 10 }) of ({ 11 }) the ({ 12 }) observed ({ 13 }) instances ({ 14 }) , ({ 15 }) and ({ 16 }) observed ({ 17 }) that ({ 18 }) the ({ 19 }) noun-noun ({ 20 }) dependencies ({ 21 }) particularly ({ 22 }) contribute ({ 23 }) to ({ 24 }) the ({ 25 }) positive ({ 26 }) instances ({ 27 }) . ({ 28 }) 
# Sentence pair (646) source length 20 target length 19 alignment score : 1.12747e-06
Also , the combination of coarse-grained tag sets with the sense dependency features were proved to be effective . 
NULL ({ }) In ({ }) addition ({ 1 }) , ({ 2 }) the ({ 3 }) combination ({ 4 }) of ({ 5 }) coarse-grained ({ 6 }) tag ({ 7 }) sets ({ 8 }) with ({ 9 }) the ({ 10 }) sense ({ 11 }) dependency ({ 12 }) features ({ 13 }) were ({ 14 }) proved ({ 15 }) to ({ 16 }) be ({ 17 }) effective ({ 18 }) . ({ 19 }) 
# Sentence pair (647) source length 42 target length 43 alignment score : 3.84688e-25
However , our experiments on the other hand showed that even when combined with the coarse-grained tag sets , the sense dependency features do not improve the performance unless combined with proper sense frequency information , due to the data sparseness problem . 
NULL ({ 5 6 36 }) However ({ 1 }) , ({ 2 }) our ({ 3 }) experiments ({ 4 }) showed ({ 8 9 }) that ({ 10 }) even ({ 11 }) when ({ 12 }) combined ({ 13 }) with ({ 14 }) the ({ 15 }) coarse-grained ({ 16 }) tag ({ 17 }) sets ({ 18 }) , ({ 19 }) the ({ 20 }) sense ({ 21 }) dependency ({ 22 }) features ({ 23 }) do ({ 24 }) not ({ 25 }) improve ({ 26 }) the ({ 27 }) performance ({ 28 }) , ({ }) unless ({ 7 29 }) combined ({ 30 }) with ({ 31 }) proper ({ 32 }) sense ({ 33 }) frequency ({ 34 }) information ({ 35 }) . ({ }) This ({ }) is ({ }) due ({ 37 }) to ({ 38 }) the ({ 39 }) data ({ 40 }) sparseness ({ 41 }) problem ({ 42 }) . ({ 43 }) 
# Sentence pair (648) source length 35 target length 33 alignment score : 4.35996e-08
The supersense-based WSD models , on the contrary , exhibited the robustness regardless of the existence of the sense frequency information , while they are defeated by the synset-based models in recalls . 
NULL ({ }) The ({ 1 }) supersense-based ({ 2 }) WSD ({ 3 }) models ({ 4 }) , ({ 5 }) on ({ 6 }) the ({ 7 }) contrary ({ 8 }) , ({ 9 }) exhibited ({ 10 }) the ({ 11 }) robustness ({ 12 }) [of ({ }) ...] ({ }) regardless ({ 13 }) of ({ 14 }) the ({ 15 }) existence ({ 16 }) of ({ 17 }) the ({ 18 }) sense ({ 19 }) frequency ({ 20 }) information ({ 21 }) , ({ 22 }) while ({ 23 }) they ({ 24 }) are ({ 25 }) defeated ({ 26 }) by ({ 27 }) the ({ 28 }) synset-based ({ 29 }) models ({ 30 }) in ({ 31 }) recalls ({ 32 }) . ({ 33 }) 
# Sentence pair (649) source length 31 target length 29 alignment score : 1.00763e-07
These results show the importance of fine-grained and coarse-grained sense information , and that the combination of both enables us to build a precise and robust WSD system . 
NULL ({ }) These ({ 1 }) results ({ 2 }) show ({ 3 }) the ({ 4 }) importance ({ 5 }) of ({ 6 }) fine-grained ({ 7 }) and ({ 8 }) coarse-grained ({ 9 }) sense ({ 10 }) information ({ 11 }) , ({ 12 }) and ({ 13 }) show ({ }) that ({ 14 }) the ({ 15 }) combination ({ 16 }) of ({ 17 }) both ({ 18 }) enables ({ 19 }) us ({ 20 }) to ({ 21 }) build ({ 22 }) a ({ 23 }) more ({ }) precise ({ 24 }) and ({ 25 }) robust ({ 26 }) WSD ({ 27 }) system ({ 28 }) . ({ 29 }) 
# Sentence pair (650) source length 16 target length 16 alignment score : 0.000992929
The performance of our tree-structured model was comparable to that of the state-of-the-art WSD systems . 
NULL ({ }) The ({ 1 }) performance ({ 2 }) of ({ 3 }) our ({ 4 }) tree-structured ({ 5 }) model ({ 6 }) was ({ 7 }) comparable ({ 8 }) to ({ 9 }) that ({ 10 }) of ({ 11 }) the ({ 12 }) state-of-the-art ({ 13 }) WSD ({ 14 }) systems ({ 15 }) . ({ 16 }) 
# Sentence pair (651) source length 40 target length 36 alignment score : 4.18388e-13
Although our model was based on a simple framework and trained only on the SemCor corpus , the results we gained were promising , suggesting that our model still has a great potential for improvement . 
NULL ({ }) Although ({ 1 }) our ({ 2 }) model ({ 3 }) was ({ 4 }) based ({ 5 }) on ({ 6 }) a ({ 7 }) simple ({ 8 }) framework ({ 9 }) , ({ }) and ({ 10 }) was ({ }) trained ({ 11 }) only ({ 12 }) on ({ 13 }) the ({ 14 }) SemCor ({ 15 }) corpus ({ 16 }) , ({ 17 }) the ({ 18 }) results ({ 19 }) that ({ }) we ({ 20 }) gained ({ 21 }) were ({ 22 }) promising ({ 23 }) . ({ }) They ({ 24 }) suggested ({ 25 }) that ({ 26 }) our ({ 27 }) model ({ 28 }) still ({ 29 }) has ({ 30 }) a ({ 31 }) great ({ 32 }) potential ({ 33 }) for ({ 34 }) improvement ({ 35 }) . ({ 36 }) 
# Sentence pair (652) source length 14 target length 14 alignment score : 0.00492146
Our next interest is to combine our framework with the recently-developed semi-supervised frameworks . 
NULL ({ }) Our ({ 1 }) next ({ 2 }) interest ({ 3 }) is ({ 4 }) to ({ 5 }) combine ({ 6 }) our ({ 7 }) framework ({ 8 }) with ({ 9 }) the ({ 10 }) recently-developed ({ 11 }) semi-supervised ({ 12 }) frameworks ({ 13 }) . ({ 14 }) 
# Sentence pair (653) source length 20 target length 20 alignment score : 0.000616281
The combination of the local and syntactic dependencies with the global information is expected to further the WSD research . 
NULL ({ }) The ({ 1 }) combination ({ 2 }) of ({ 3 }) the ({ 4 }) local ({ 5 }) and ({ 6 }) syntactic ({ 7 }) dependencies ({ 8 }) with ({ 9 }) the ({ 10 }) global ({ 11 }) information ({ 12 }) is ({ 13 }) expected ({ 14 }) to ({ 15 }) further ({ 16 }) the ({ 17 }) WSD ({ 18 }) research ({ 19 }) . ({ 20 }) 
# Sentence pair (654) source length 31 target length 29 alignment score : 1.00276e-14
Generating short summary videos for rushes is a challenging task due to difficulty in redundancy elimination and determination of important objects and events being placed in the summary . 
NULL ({ 19 }) Generating ({ 1 }) short ({ 2 }) summary ({ 3 }) videos ({ 4 }) for ({ 5 }) rushes ({ 6 }) is ({ 7 }) a ({ 8 }) challenging ({ 9 }) task ({ 10 }) due ({ 11 }) to ({ 12 }) the ({ }) difficulty ({ 13 }) in ({ 14 }) eliminating ({ 15 }) redundancy ({ 16 }) and ({ 17 }) determining ({ 18 }) the ({ }) important ({ 20 }) objects ({ 21 }) and ({ 22 }) events ({ 23 }) to ({ }) be ({ }) placed ({ 24 25 }) in ({ 26 }) the ({ 27 }) summary ({ 28 }) . ({ 29 }) 
# Sentence pair (655) source length 24 target length 24 alignment score : 4.62672e-05
Redundancy elimination is difficult since repetitive segments , which are takes of the same scene , usually have different lengths and motion patterns . 
NULL ({ }) Redundancy ({ 1 }) elimination ({ 2 }) is ({ 3 }) difficult ({ 4 }) since ({ 5 }) repetitive ({ 6 }) segments ({ 7 }) , ({ 8 }) which ({ 9 }) are ({ 10 }) takes ({ 11 }) of ({ 12 }) the ({ 13 }) same ({ 14 }) scene ({ 15 }) , ({ 16 }) usually ({ 17 }) have ({ 18 }) different ({ 19 }) lengths ({ 20 }) and ({ 21 }) motion ({ 22 }) patterns ({ 23 }) . ({ 24 }) 
# Sentence pair (656) source length 18 target length 14 alignment score : 1.13504e-09
This makes approaches using one keyframe for shot representation failed in doing clustering . 
NULL ({ }) This ({ 1 }) makes ({ 2 }) approaches ({ 3 }) using ({ 4 }) one ({ 5 }) keyframe ({ 6 }) for ({ 7 }) a ({ }) shot ({ 8 }) representation ({ 9 }) fail ({ 10 }) when ({ 11 }) trying ({ 12 }) to ({ }) form ({ }) a ({ }) cluster ({ 13 }) . ({ 14 }) 
# Sentence pair (657) source length 29 target length 28 alignment score : 8.53726e-14
In addition , even repetitive segments can be determined precisely , the summary generated by concatenating together selected segments still has longer duration than the upper limit . 
NULL ({ }) In ({ 1 }) addition ({ 2 }) , ({ 3 }) even ({ 4 }) repetitive ({ 5 }) segments ({ 6 }) can ({ 7 }) be ({ 8 }) precisely ({ 10 }) determined ({ 9 }) , ({ 11 }) but ({ }) the ({ 12 }) summary ({ 13 }) generated ({ 14 }) by ({ 15 }) concatenating ({ 16 }) together ({ 17 }) the ({ }) selected ({ 18 }) segments ({ 19 }) still ({ 20 }) takes ({ 21 }) longer ({ 22 23 }) than ({ 24 }) the ({ 25 }) upper ({ 26 }) limit ({ 27 }) . ({ 28 }) 
# Sentence pair (658) source length 20 target length 20 alignment score : 0.000321322
It is questionable to select a sub-segment so that it conveys information of the scene as much as possible . 
NULL ({ }) It ({ 1 }) is ({ 2 }) questionable ({ 3 }) to ({ 4 }) select ({ 5 }) a ({ 6 }) sub-segment ({ 7 }) so ({ 8 }) that ({ 9 }) it ({ 10 }) conveys ({ 11 }) information ({ 12 }) of ({ 13 }) the ({ 14 }) scene ({ 15 }) as ({ 16 }) much ({ 17 }) as ({ 18 }) possible ({ 19 }) . ({ 20 }) 
# Sentence pair (659) source length 9 target length 12 alignment score : 1.96721e-11
In this paper , we introduce two approaches to these problems . 
NULL ({ 4 }) ,We ({ 1 2 3 5 }) introduce ({ 6 }) two ({ 7 }) approaches ({ 8 }) to ({ 9 }) solve ({ }) these ({ 10 }) problems ({ 11 }) . ({ 12 }) 
# Sentence pair (660) source length 30 target length 27 alignment score : 7.71e-12
In the first approach , one keyframe is used for shot representation in doing clustering; and sub-segments are selected using motion information for generating the summary . 
NULL ({ }) In ({ 1 }) the ({ 2 }) first ({ 3 }) approach ({ 4 }) , ({ 5 }) one ({ 6 }) keyframe ({ 7 }) is ({ 8 }) used ({ 9 }) for ({ 10 }) representing ({ 12 }) a ({ }) shot ({ 11 }) when ({ 13 }) forming ({ 14 }) a ({ }) cluster; ({ 15 }) and ({ 16 }) sub-segments ({ 17 }) are ({ 18 }) selected ({ 19 }) using ({ 20 }) the ({ }) motion ({ 21 }) information ({ 22 }) for ({ 23 }) generating ({ 24 }) the ({ 25 }) summary ({ 26 }) . ({ 27 }) 
# Sentence pair (661) source length 30 target length 27 alignment score : 1.65992e-07
Meanwhile , in the second approach , all frames of a shot are used for clustering; and a simple skimming method is used to select sub-segments . 
NULL ({ }) Meanwhile ({ 1 }) , ({ 2 }) in ({ 3 }) the ({ 4 }) second ({ 5 }) approach ({ 6 }) , ({ 7 }) all ({ 8 }) the ({ }) frames ({ 9 }) of ({ 10 }) a ({ 11 }) given ({ }) shot ({ 12 }) are ({ 13 }) used ({ 14 }) for ({ 15 }) clustering; ({ 16 }) and ({ 17 }) a ({ 18 }) simple ({ 19 }) skimming ({ 20 }) method ({ 21 }) is ({ 22 }) used ({ 23 }) to ({ 24 }) select ({ 25 }) the ({ }) sub-segments ({ 26 }) . ({ 27 }) 
# Sentence pair (662) source length 19 target length 16 alignment score : 1.80417e-07
Experimental results on the TRECVID 2008 dataset and comparison between the two approaches are reported . 
NULL ({ }) The ({ }) experimental ({ 1 }) results ({ 2 }) on ({ 3 }) the ({ 4 }) TRECVID ({ 5 }) 2008 ({ 6 }) dataset ({ 7 }) and ({ 8 }) a ({ }) comparison ({ 9 }) between ({ 10 }) the ({ 11 }) two ({ 12 }) approaches ({ 13 }) are ({ 14 }) also ({ }) reported ({ 15 }) . ({ 16 }) 
# Sentence pair (663) source length 23 target length 23 alignment score : 0.000113639
With the availability of multimedia databases growing at an exponential rate , users are increasingly requiring assistance in accessing digital video contents . 
NULL ({ }) With ({ 1 }) the ({ 2 }) availability ({ 3 }) of ({ 4 }) multimedia ({ 5 }) databases ({ 6 }) growing ({ 7 }) at ({ 8 }) an ({ 9 }) exponential ({ 10 }) rate ({ 11 }) , ({ 12 }) users ({ 13 }) are ({ 14 }) increasingly ({ 15 }) requiring ({ 16 }) assistance ({ 17 }) in ({ 18 }) accessing ({ 19 }) digital ({ 20 }) video ({ 21 }) contents ({ 22 }) . ({ 23 }) 
# Sentence pair (664) source length 27 target length 30 alignment score : 4.46835e-28
Video summarization is a significant research that helps to meet these needs by developing a condensed version of a full length digital video with the most important contents \CITE . 
NULL ({ 3 7 15 }) Video ({ 1 }) summarization ({ 2 6 }) significantly ({ }) helps ({ 8 }) to ({ 9 }) meet ({ 10 }) this ({ 11 }) need ({ 12 }) by ({ 13 }) developing ({ 14 }) a ({ 4 }) condensed ({ 5 16 }) version ({ 17 }) of ({ 18 }) a ({ 19 }) full ({ 20 }) length ({ 21 }) digital ({ 22 }) video ({ 23 }) using ({ 24 }) only ({ }) the ({ 25 }) most ({ 26 }) important ({ 27 }) contents ({ 28 }) \CITE ({ 29 }) . ({ 30 }) 
# Sentence pair (665) source length 17 target length 16 alignment score : 3.72709e-10
Summary videos can help users to browse and navigate large video archives efficiently and effectively . 
NULL ({ 6 }) Summary ({ 1 }) videos ({ 2 }) can ({ 3 }) help ({ 4 }) users ({ 5 }) more ({ }) efficiently ({ 13 }) and ({ 14 }) effectively ({ 15 }) browse ({ 7 }) and ({ 8 }) navigate ({ 9 }) through ({ }) large ({ 10 }) video ({ 11 }) archives ({ 12 }) . ({ 16 }) 
# Sentence pair (666) source length 33 target length 30 alignment score : 6.998e-16
Generating summary videos for BBC rushes \CITE is a challenging task due to difficulty in redundancy elimination and determination of important objects and events being placed in the summary . 
NULL ({ 15 }) Generating ({ 1 }) summary ({ 2 }) videos ({ 3 }) for ({ 4 }) BBC ({ 5 }) rushes ({ 6 }) \CITE ({ 7 }) is ({ 8 }) a ({ 9 }) challenging ({ 10 }) task ({ 11 }) due ({ 12 }) to ({ 13 }) the ({ }) difficulty ({ 14 }) with ({ }) redundancy ({ 16 }) elimination ({ 17 }) and ({ 18 }) determining ({ 19 }) the ({ }) most ({ 20 }) important ({ 21 }) objects ({ 22 }) and ({ 23 }) events ({ 24 }) to ({ }) be ({ }) placed ({ 25 26 }) in ({ 27 }) the ({ 28 }) summary ({ 29 }) . ({ 30 }) 
# Sentence pair (667) source length 40 target length 38 alignment score : 1.66589e-09
Since the length of the summary is limited to 2\% duration of the original video , there is a trade-off between recall and usability ( e.g user friendly through smooth presentation , being easy to understand ) . 
NULL ({ }) Since ({ 1 }) the ({ 2 }) length ({ 3 }) of ({ 4 }) the ({ 5 }) summary ({ 6 }) is ({ 7 }) limited ({ 8 }) to ({ 9 }) 2\% ({ 10 }) duration ({ 11 }) of ({ 12 }) the ({ 13 }) original ({ 14 }) video ({ 15 }) , ({ 16 }) there ({ 17 }) is ({ 18 }) a ({ 19 }) trade-off ({ 20 }) between ({ 21 }) the ({ }) recall ({ 22 }) and ({ 23 }) usability ({ 24 }) ( ({ 25 }) e.g. ({ 26 }) user ({ 27 }) friendly ({ 28 }) through ({ 29 }) smooth ({ 30 }) presentation ({ 31 }) , ({ 32 }) / ({ }) being ({ 33 }) easy ({ 34 }) to ({ 35 }) understand ({ 36 }) ) ({ 37 }) . ({ 38 }) 
# Sentence pair (668) source length 27 target length 28 alignment score : 9.73267e-09
High recall , i.e many objects and events ( called scenes ) are included in the summary , usually reduce the number of frames for each scene . 
NULL ({ 13 }) High ({ 1 }) recall ({ 2 }) , ({ 3 }) i.e. ({ 4 }) many ({ 5 }) objects ({ 6 }) and ({ 7 }) events ({ 8 }) ( ({ 9 }) called ({ 10 }) scenes ({ 11 }) ) ({ 12 }) included ({ 14 }) in ({ 15 }) the ({ 16 }) summary ({ 17 }) , ({ 18 }) usually ({ 19 }) reduces ({ 20 }) the ({ 21 }) number ({ 22 }) of ({ 23 }) frames ({ 24 }) for ({ 25 }) each ({ 26 }) scene ({ 27 }) . ({ 28 }) 
# Sentence pair (669) source length 21 target length 22 alignment score : 3.25027e-08
For example , the maximum duration for the summary of a 30 minute length video is 36 seconds ( \MATH ) . 
NULL ({ }) For ({ 1 }) example ({ 2 }) , ({ 3 }) the ({ 4 }) maximum ({ 5 }) duration ({ 6 }) for ({ 7 }) a ({ 8 }) summary ({ 9 }) of ({ 10 }) a ({ 11 }) 30 ({ 12 }) minute ({ 13 14 }) video ({ 15 }) is ({ 16 }) 36 ({ 17 }) seconds ({ 18 }) ( ({ 19 }) \MATH ({ 20 }) ) ({ 21 }) . ({ 22 }) 
# Sentence pair (670) source length 18 target length 18 alignment score : 0.00194627
If the summary consists of 20 scenes , the average duration for each scene is 1.8 seconds . 
NULL ({ }) If ({ 1 }) the ({ 2 }) summary ({ 3 }) consists ({ 4 }) of ({ 5 }) 20 ({ 6 }) scenes ({ 7 }) , ({ 8 }) the ({ 9 }) average ({ 10 }) duration ({ 11 }) for ({ 12 }) each ({ 13 }) scene ({ 14 }) is ({ 15 }) 1.8 ({ 16 }) seconds ({ 17 }) . ({ 18 }) 
# Sentence pair (671) source length 20 target length 20 alignment score : 1.13624e-05
For the event such as " `Woman attacks man on bench on left and runs off with large bag . 
NULL ({ }) For ({ 1 }) an ({ 2 }) event ({ 3 }) such ({ 4 }) as ({ 5 }) " ({ 6 }) `Woman ({ 7 }) attacks ({ 8 }) man ({ 9 }) on ({ 10 }) bench ({ 11 }) on ({ 12 }) left ({ 13 }) and ({ 14 }) runs ({ 15 }) off ({ 16 }) with ({ 17 }) large ({ 18 }) bag ({ 19 }) . ({ 20 }) 
# Sentence pair (672) source length 21 target length 20 alignment score : 9.95496e-06
" ', with this length constraint , it is difficult to present it in a pleasant tempo and rhythm . 
NULL ({ }) " ({ 1 }) ', ({ 2 }) with ({ 3 }) this ({ 4 }) length ({ 5 }) constraint ({ 6 }) , ({ 7 }) it ({ 8 }) would ({ 9 }) be ({ }) difficult ({ 10 }) to ({ 11 }) present ({ 12 }) it ({ 13 }) in ({ 14 }) a ({ 15 }) pleasant ({ 16 }) tempo ({ 17 }) and ({ 18 }) rhythm ({ 19 }) . ({ 20 }) 
# Sentence pair (673) source length 25 target length 20 alignment score : 2.27504e-14
On the contrary , smooth presentation of events consumes a lot number of frames , that decrease the recall . 
NULL ({ }) On ({ 1 }) the ({ 2 }) other ({ 3 }) hand ({ }) , ({ 4 }) a ({ }) smooth ({ 5 }) presentation ({ 6 }) of ({ 7 }) these ({ }) events ({ 8 }) would ({ }) consume ({ 9 }) a ({ 10 }) large ({ 11 }) number ({ 12 }) of ({ 13 }) frames ({ 14 }) , ({ 15 }) which ({ 16 }) would ({ }) decrease ({ 17 }) the ({ 18 }) recall ({ 19 }) . ({ 20 }) 
# Sentence pair (674) source length 12 target length 12 alignment score : 0.0101627
In general , generating summary videos consists of the following steps : 
NULL ({ }) In ({ 1 }) general ({ 2 }) , ({ 3 }) generating ({ 4 }) summary ({ 5 }) videos ({ 6 }) consists ({ 7 }) of ({ 8 }) the ({ 9 }) following ({ 10 }) steps ({ 11 }) : ({ 12 }) 
# Sentence pair (675) source length 19 target length 17 alignment score : 1.05965e-05
Video segmentation : This step decomposes the original video into segments , such shots or sub-shots . 
NULL ({ }) Video ({ 1 }) segmentation ({ 2 }) : ({ 3 }) This ({ 4 }) step ({ 5 }) breaks ({ 6 }) down ({ }) the ({ 7 }) original ({ 8 }) video ({ 9 }) into ({ 10 }) segments ({ 11 }) , ({ 12 }) such ({ 13 }) as ({ }) shots ({ 14 }) or ({ 15 }) sub-shots ({ 16 }) . ({ 17 }) 
# Sentence pair (676) source length 15 target length 15 alignment score : 9.93442e-05
Each segment should be aligned such that it is a part of a scene . 
NULL ({ }) Each ({ 1 }) segment ({ 2 }) should ({ 3 }) be ({ 4 }) aligned ({ 5 }) so ({ 6 }) that ({ 7 }) it ({ 8 }) is ({ 9 }) a ({ 10 }) part ({ 11 }) of ({ 12 }) a ({ 13 }) scene ({ 14 }) . ({ 15 }) 
# Sentence pair (677) source length 17 target length 16 alignment score : 0.000556994
Redundancy elimination : This step groups segments that belong to the same take into clusters . 
NULL ({ }) Redundancy ({ 1 }) elimination ({ 2 }) : ({ 3 }) This ({ 4 }) step ({ 5 }) groups ({ 6 }) the ({ }) segments ({ 7 }) that ({ 8 }) belong ({ 9 }) to ({ 10 }) the ({ 11 }) same ({ 12 }) take ({ 13 }) into ({ 14 }) clusters ({ 15 }) . ({ 16 }) 
# Sentence pair (678) source length 12 target length 12 alignment score : 0.0117662
Only one representative segment is used for the final summary video . 
NULL ({ }) Only ({ 1 }) one ({ 2 }) representative ({ 3 }) segment ({ 4 }) is ({ 5 }) used ({ 6 }) for ({ 7 }) the ({ 8 }) final ({ 9 }) summary ({ 10 }) video ({ 11 }) . ({ 12 }) 
# Sentence pair (679) source length 5 target length 5 alignment score : 0.141135
The others are discarded . 
NULL ({ }) The ({ 1 }) others ({ 2 }) are ({ 3 }) discarded ({ 4 }) . ({ 5 }) 
# Sentence pair (680) source length 29 target length 26 alignment score : 3.61907e-10
Junk elimination : This step removes color bars , clapboards , all black or all white frames that are unnecessary for the final summary video . 
NULL ({ }) Junk ({ 1 }) elimination ({ 2 }) : ({ 3 }) This ({ 4 }) step ({ 5 }) removes ({ 6 }) the ({ }) color ({ 7 }) bars ({ 8 }) , ({ 9 }) clapboards ({ 10 }) , ({ 11 }) and ({ }) the ({ }) all ({ 12 }) black ({ 13 }) or ({ 14 }) all ({ 15 }) white ({ 16 }) frames ({ 17 }) that ({ 18 }) are ({ 19 }) unnecessary ({ 20 }) in ({ 21 }) the ({ 22 }) final ({ 23 }) summary ({ 24 }) video ({ 25 }) . ({ 26 }) 
# Sentence pair (681) source length 24 target length 21 alignment score : 3.79086e-06
Summary generation : This step selects frames from representative segments of clusters and concatenate to form the final summary video . 
NULL ({ }) Summary ({ 1 }) generation ({ 2 }) : ({ 3 }) This ({ 4 }) step ({ 5 }) selects ({ 6 }) the ({ }) frames ({ 7 }) from ({ 8 }) the ({ }) representative ({ 9 }) segments ({ 10 }) of ({ 11 }) clusters ({ 12 }) and ({ 13 }) concatenates ({ 14 }) them ({ }) to ({ 15 }) form ({ 16 }) the ({ 17 }) final ({ 18 }) summary ({ 19 }) video ({ 20 }) . ({ 21 }) 
# Sentence pair (682) source length 25 target length 25 alignment score : 1.57861e-07
While the steps of video segmentation and junk elimination are easy to handle , the steps of redundancy elimination and summary generation are difficult . 
NULL ({ }) While ({ 1 }) the ({ 2 }) steps ({ 3 }) for ({ 4 }) video ({ 5 }) segmentation ({ 6 }) and ({ 7 }) junk ({ 8 }) elimination ({ 9 }) are ({ 10 }) easy ({ 11 }) to ({ 12 }) handle ({ 13 }) , ({ 14 }) the ({ 15 }) steps ({ 16 }) for ({ 17 }) redundancy ({ 18 }) elimination ({ 19 }) and ({ 20 }) summary ({ 21 }) generation ({ 22 }) are ({ 23 }) difficult ({ 24 }) . ({ 25 }) 
# Sentence pair (683) source length 36 target length 36 alignment score : 9.36006e-12
For example , as for redundancy elimination , the question is how to represent a segment into a feature vector and how to compute the similarity between two segments having different length and motion pattern . 
NULL ({ }) For ({ 1 }) example ({ 2 }) , ({ 3 }) as ({ 4 }) for ({ 5 }) redundancy ({ 6 }) elimination ({ 7 }) , ({ 8 }) the ({ 9 }) question ({ 10 }) is ({ 11 }) how ({ 12 }) to ({ 13 }) represent ({ 14 }) a ({ 15 }) segment ({ 16 }) in ({ 17 }) a ({ 18 }) feature ({ 19 }) vector ({ 20 }) and ({ 21 }) how ({ 22 }) to ({ 23 }) compute ({ 24 }) the ({ 25 }) similarity ({ 26 }) between ({ 27 }) two ({ 28 }) segments ({ 29 }) having ({ 30 }) different ({ 31 }) lengths ({ 32 }) and ({ 33 }) motion ({ 34 }) patterns ({ 35 }) . ({ 36 }) 
# Sentence pair (684) source length 30 target length 29 alignment score : 8.25128e-09
In the other case , assume that we have selected appropriate segments , the total length of these segments are usually larger than that of the final summary . 
NULL ({ }) In ({ 1 }) the ({ 2 }) other ({ 3 }) case ({ 4 }) , ({ 5 }) assuming ({ 6 }) that ({ 7 }) we ({ 8 }) have ({ 9 }) selected ({ 10 }) the ({ }) appropriate ({ 11 }) segments ({ 12 }) , ({ 13 }) the ({ 14 }) total ({ 15 }) length ({ 16 }) of ({ 17 }) these ({ 18 }) segments ({ 19 }) is ({ 20 }) usually ({ 21 }) larger ({ 22 }) than ({ 23 }) that ({ 24 }) of ({ 25 }) the ({ 26 }) final ({ 27 }) summary ({ 28 }) . ({ 29 }) 
# Sentence pair (685) source length 29 target length 26 alignment score : 1.70176e-15
The question is how to determine the important part of the selected segment such that it conveys information of the scene as much as possible . 
NULL ({ }) The ({ 1 }) question ({ 2 }) is ({ 3 }) how ({ 4 }) to ({ 5 }) determine ({ 6 }) the ({ 7 }) most ({ }) important ({ 8 }) parts ({ 9 }) of ({ 10 }) the ({ 11 }) selected ({ 12 }) segments ({ 13 }) so ({ 14 }) that ({ 15 }) they ({ 16 }) convey ({ 17 }) as ({ 22 }) much ({ 23 }) of ({ }) the ({ }) information ({ 18 }) of ({ 19 }) the ({ 20 }) scene ({ 21 }) as ({ 24 }) possible ({ 25 }) . ({ 26 }) 
# Sentence pair (686) source length 14 target length 14 alignment score : 0.00416337
In this paper , we present two approaches for handling these difficult steps . 
NULL ({ }) In ({ 1 }) this ({ 2 }) paper ({ 3 }) , ({ 4 }) we ({ 5 }) present ({ 6 }) two ({ 7 }) approaches ({ 8 }) for ({ 9 }) handling ({ 10 }) these ({ 11 }) difficult ({ 12 }) steps ({ 13 }) . ({ 14 }) 
# Sentence pair (687) source length 21 target length 20 alignment score : 4.52804e-09
The first approach represents each segment by one key-frame and groups similar segments by doing clustering on these key-frames . 
NULL ({ }) The ({ 1 }) first ({ 2 }) approach ({ 3 }) represents ({ 4 }) each ({ 5 }) segment ({ 6 }) by ({ 7 }) using ({ }) one ({ 8 }) key-frame ({ 9 }) and ({ 10 }) groups ({ 11 }) similar ({ 12 }) segments ({ 13 }) by ({ 14 }) clustering ({ 16 }) them ({ 15 }) on ({ 17 }) these ({ 18 }) key-frames ({ 19 }) . ({ 20 }) 
# Sentence pair (688) source length 18 target length 19 alignment score : 2.02918e-14
Then the portion of each segment that has high motion is used to include into the final summary . 
NULL ({ 13 }) Then ({ 1 }) the ({ 2 }) portion ({ 3 }) of ({ 4 }) each ({ 5 }) segment ({ 6 }) that ({ 7 }) has ({ 8 }) the ({ }) highest ({ 9 }) motion ({ 10 }) is ({ 11 }) included ({ 12 14 }) in ({ 15 }) the ({ 16 }) final ({ 17 }) summary ({ 18 }) . ({ 19 }) 
# Sentence pair (689) source length 12 target length 12 alignment score : 0.0095057
Meanwhile , the second approach uses another strategy for redundancy elimination . 
NULL ({ }) Meanwhile ({ 1 }) , ({ 2 }) the ({ 3 }) second ({ 4 }) approach ({ 5 }) uses ({ 6 }) another ({ 7 }) strategy ({ 8 }) for ({ 9 }) redundancy ({ 10 }) elimination ({ 11 }) . ({ 12 }) 
# Sentence pair (690) source length 25 target length 25 alignment score : 4.55495e-06
Specifically , for each segment , a set of frames are extracted by sampling at a certain time interval ( e.g 5 frames ) . 
NULL ({ }) Specifically ({ 1 }) , ({ 2 }) for ({ 3 }) each ({ 4 }) segment ({ 5 }) , ({ 6 }) a ({ 7 }) set ({ 8 }) of ({ 9 }) frames ({ 10 }) are ({ 11 }) extracted ({ 12 }) by ({ 13 }) sampling ({ 14 }) at ({ 15 }) a ({ 16 }) certain ({ 17 }) time ({ 18 }) interval ({ 19 }) ( ({ 20 }) e.g. ({ 21 }) 5 ({ 22 }) frames ({ 23 }) ) ({ 24 }) . ({ 25 }) 
# Sentence pair (691) source length 13 target length 12 alignment score : 0.00129549
The clustering process is performed on the frames of all segments . 
NULL ({ }) The ({ 1 }) clustering ({ 2 }) process ({ 3 }) is ({ 4 }) performed ({ 5 }) on ({ 6 }) the ({ 7 }) frames ({ 8 }) of ({ 9 }) all ({ 10 }) the ({ }) segments ({ 11 }) . ({ 12 }) 
# Sentence pair (692) source length 22 target length 23 alignment score : 3.28808e-06
Then , the segments that share a large enough number of frames with respect to their size are merged into one cluster . 
NULL ({ 3 }) Then ({ 1 }) , ({ 2 }) segments ({ 4 }) that ({ 5 }) share ({ 6 }) a ({ 7 }) large ({ 8 }) enough ({ 9 }) number ({ 10 }) of ({ 11 }) frames ({ 12 }) with ({ 13 }) respect ({ 14 }) to ({ 15 }) their ({ 16 }) size ({ 17 }) are ({ 18 }) merged ({ 19 }) into ({ 20 }) one ({ 21 }) cluster ({ 22 }) . ({ 23 }) 
# Sentence pair (693) source length 26 target length 26 alignment score : 1.46382e-06
In order to generate the final summary , with each representative segment , the middle part is selected with the skim rate of 2 frames . 
NULL ({ }) In ({ 1 }) order ({ 2 }) to ({ 3 }) generate ({ 4 }) the ({ 5 }) final ({ 6 }) summary ({ 7 }) , ({ 8 }) with ({ 9 }) each ({ 10 }) representative ({ 11 }) segment ({ 12 }) , ({ 13 }) the ({ 14 }) middle ({ 15 }) part ({ 16 }) is ({ 17 }) selected ({ 18 }) with ({ 19 }) a ({ 20 }) skim ({ 21 }) rate ({ 22 }) of ({ 23 }) 2 ({ 24 }) frames ({ 25 }) . ({ 26 }) 
# Sentence pair (694) source length 28 target length 26 alignment score : 3.21092e-06
This paper is organized as follows : section \REF introduces details of the first approach; , while section \REF presents details of the second approach . 
NULL ({ }) This ({ 1 }) paper ({ 2 }) is ({ 3 }) organized ({ 4 }) as ({ 5 }) follows ({ 6 }) : ({ 7 }) section ({ 8 }) \REF ({ 9 }) introduces ({ 10 }) the ({ }) details ({ 11 }) of ({ 12 }) the ({ 13 }) first ({ 14 }) approach; ({ 15 }) , ({ 16 }) while ({ 17 }) section ({ 18 }) \REF ({ 19 }) presents ({ 20 }) the ({ }) details ({ 21 }) of ({ 22 }) the ({ 23 }) second ({ 24 }) approach ({ 25 }) . ({ 26 }) 
# Sentence pair (695) source length 12 target length 11 alignment score : 0.00160279
Section \REF describes experimental results on the TRECVID 2008 dataset . 
NULL ({ }) Section ({ 1 }) \REF ({ 2 }) describes ({ 3 }) our ({ }) experimental ({ 4 }) results ({ 5 }) on ({ 6 }) the ({ 7 }) TRECVID ({ 8 }) 2008 ({ 9 }) dataset ({ 10 }) . ({ 11 }) 
# Sentence pair (696) source length 11 target length 11 alignment score : 0.0243852
Finally , section \REF and section \REF conclude the paper . 
NULL ({ }) Finally ({ 1 }) , ({ 2 }) section ({ 3 }) \REF ({ 4 }) and ({ 5 }) section ({ 6 }) \REF ({ 7 }) conclude ({ 8 }) the ({ 9 }) paper ({ 10 }) . ({ 11 }) 
# Sentence pair (697) source length 16 target length 17 alignment score : 4.83297e-08
From the definition , all rushes are unedited; therefore it must consist of hard cut only . 
NULL ({ 2 }) By ({ 1 }) definition ({ 3 }) , ({ 4 }) all ({ 5 }) rushes ({ 6 }) are ({ 7 }) unedited; ({ 8 }) therefore ({ 9 }) they ({ 10 }) must ({ 11 }) consist ({ 12 }) of ({ 13 }) hard ({ 14 }) cuts ({ 15 }) only ({ 16 }) . ({ 17 }) 
# Sentence pair (698) source length 23 target length 21 alignment score : 9.69149e-06
The shot boundary detection algorithm in \CITE is used to determine shot boundary and partition the input video into shots . 
NULL ({ }) The ({ 1 }) shot ({ 2 }) boundary ({ 3 }) detection ({ 4 }) algorithm ({ 5 }) in ({ 6 }) \CITE ({ 7 }) is ({ 8 }) used ({ 9 }) to ({ 10 }) determine ({ 11 }) the ({ }) shot ({ 12 }) boundary ({ 13 }) and ({ 14 }) to ({ }) partition ({ 15 }) the ({ 16 }) input ({ 17 }) video ({ 18 }) into ({ 19 }) shots ({ 20 }) . ({ 21 }) 
# Sentence pair (699) source length 15 target length 15 alignment score : 0.00479623
A local color histogram is extracted by dividing a video frame into \MATH blocks . 
NULL ({ }) A ({ 1 }) local ({ 2 }) color ({ 3 }) histogram ({ 4 }) is ({ 5 }) extracted ({ 6 }) by ({ 7 }) dividing ({ 8 }) a ({ 9 }) video ({ 10 }) frame ({ 11 }) into ({ 12 }) \MATH ({ 13 }) blocks ({ 14 }) . ({ 15 }) 
# Sentence pair (700) source length 18 target length 18 alignment score : 0.000497339
The \MATH distance is used to compute the distance between each blocks of frames \MATH and \MATH . 
NULL ({ }) The ({ 1 }) \MATH ({ 2 }) distance ({ 3 }) is ({ 4 }) used ({ 5 }) to ({ 6 }) compute ({ 7 }) the ({ 8 }) distance ({ 9 }) between ({ 10 }) each ({ 11 }) block ({ 12 }) of ({ 13 }) frames ({ 14 }) \MATH ({ 15 }) and ({ 16 }) \MATH ({ 17 }) . ({ 18 }) 
# Sentence pair (701) source length 10 target length 11 alignment score : 0.000188162
Next , these values are sorted into an ascending order . 
NULL ({ }) Next ({ 1 }) , ({ 2 }) these ({ 3 }) values ({ 4 }) are ({ 5 }) sorted ({ 6 }) into ({ 7 }) ascending ({ 8 9 }) order ({ 10 }) . ({ 11 }) 
# Sentence pair (702) source length 29 target length 29 alignment score : 2.06783e-12
The sum of the middle eight of these 16 values are used to define a cut between frames \MATH and \MATH if these values exceed a threshold \MATH . 
NULL ({ 15 }) The ({ 1 }) sum ({ 2 }) of ({ 3 }) the ({ 4 }) middle ({ 5 }) eight ({ 6 }) of ({ 7 }) these ({ 8 }) 16 ({ 9 }) values ({ 10 }) is ({ 11 }) used ({ 12 }) to ({ 13 }) define ({ 14 }) the ({ }) cut ({ 16 }) between ({ 17 }) frames ({ 18 }) \MATH ({ 19 }) and ({ 20 }) \MATH ({ 21 }) if ({ 22 }) these ({ 23 }) values ({ 24 }) exceed ({ 25 }) the ({ 26 }) threshold ({ 27 }) \MATH ({ 28 }) . ({ 29 }) 
# Sentence pair (703) source length 16 target length 15 alignment score : 3.04544e-08
However , this algorithm cannot distinguish between hard cut and the large objects motion . 
NULL ({ }) However ({ 1 }) , ({ 2 }) this ({ 3 }) algorithm ({ 4 }) cannot ({ 5 }) distinguish ({ 6 }) between ({ 7 }) hard ({ 8 }) cuts ({ 9 }) and ({ 10 }) the ({ 11 }) motion ({ 14 }) of ({ }) large ({ 12 }) objects ({ 13 }) . ({ 15 }) 
# Sentence pair (704) source length 29 target length 29 alignment score : 9.57848e-06
To overcome this problem , motion-based features are computed for each video frame using the Lucas-Kanade point-based tracking functions provided in the OpenCV toolkit\footnote{http : //opencvlibrary.sourceforge.net / } . 
NULL ({ }) To ({ 1 }) overcome ({ 2 }) this ({ 3 }) problem ({ 4 }) , ({ 5 }) motion-based ({ 6 }) features ({ 7 }) are ({ 8 }) computed ({ 9 }) for ({ 10 }) each ({ 11 }) video ({ 12 }) frame ({ 13 }) using ({ 14 }) the ({ 15 }) Lucas-Kanade ({ 16 }) point-based ({ 17 }) tracking ({ 18 }) functions ({ 19 }) provided ({ 20 }) in ({ 21 }) the ({ 22 }) OpenCV ({ 23 }) toolkit\footnote{http ({ 24 }) : ({ 25 }) //opencvlibrary.sourceforge.net ({ 26 }) / ({ 27 }) } ({ 28 }) . ({ 29 }) 
# Sentence pair (705) source length 12 target length 12 alignment score : 0.0169609
The magnitude is computed from the motion vector for each frame . 
NULL ({ }) The ({ 1 }) magnitude ({ 2 }) is ({ 3 }) computed ({ 4 }) from ({ 5 }) the ({ 6 }) motion ({ 7 }) vector ({ 8 }) for ({ 9 }) each ({ 10 }) frame ({ 11 }) . ({ 12 }) 
# Sentence pair (706) source length 36 target length 35 alignment score : 2.59509e-13
Therefore , if the algorithm detected a cut between frames \MATH and \MATH , whose magnitude is larger than a threshold \MATH , these cuts are rejected since they are motions from large objects . 
NULL ({ 20 }) Therefore ({ 1 }) , ({ 2 }) if ({ 3 }) the ({ 4 }) algorithm ({ 5 }) detected ({ 6 }) a ({ 7 }) cut ({ 8 }) between ({ 9 }) frames ({ 10 }) \MATH ({ 11 }) and ({ 12 }) \MATH ({ 13 }) , ({ 14 }) whose ({ 15 }) magnitude ({ 16 }) is ({ 17 }) larger ({ 18 }) than ({ 19 }) the ({ }) threshold ({ 21 }) \MATH ({ 22 }) , ({ 23 }) these ({ 24 }) cuts ({ 25 }) are ({ 26 }) rejected ({ 27 }) since ({ 28 }) they ({ 29 }) are ({ 30 }) the ({ }) motions ({ 31 }) of ({ 32 }) large ({ 33 }) objects ({ 34 }) . ({ 35 }) 
# Sentence pair (707) source length 16 target length 17 alignment score : 1.43856e-07
Finally , the short shots with less than 25 frames ( 1 second ) are removed . 
NULL ({ 3 }) Finally ({ 1 }) , ({ 2 }) short ({ 4 }) shots ({ 5 }) of ({ 6 }) less ({ 7 }) than ({ 8 }) 25 ({ 9 }) frames ({ 10 }) ( ({ 11 }) 1 ({ 12 }) second ({ 13 }) ) ({ 14 }) are ({ 15 }) removed ({ 16 }) . ({ 17 }) 
# Sentence pair (708) source length 15 target length 15 alignment score : 0.00239355
The sub-shot segmentation algorithm in \CITE is used to divide shots into smaller units . 
NULL ({ }) The ({ 1 }) sub-shot ({ 2 }) segmentation ({ 3 }) algorithm ({ 4 }) in ({ 5 }) \CITE ({ 6 }) is ({ 7 }) used ({ 8 }) to ({ 9 }) divide ({ 10 }) shots ({ 11 }) into ({ 12 }) smaller ({ 13 }) units ({ 14 }) . ({ 15 }) 
# Sentence pair (709) source length 22 target length 20 alignment score : 2.30017e-07
A first frame of the shot is chosen as the base frame \MATH and next frame \MATH for comparison . 
NULL ({ }) The ({ 1 }) first ({ 2 }) frame ({ 3 }) of ({ 4 }) the ({ 5 }) shot ({ 6 }) is ({ 7 }) chosen ({ 8 }) as ({ 9 }) the ({ 10 }) base ({ 11 }) frame ({ 12 }) \MATH ({ 13 }) and ({ 14 }) the ({ }) next ({ 15 }) frame ({ 16 }) \MATH ({ 17 }) for ({ 18 }) a ({ }) comparison ({ 19 }) . ({ 20 }) 
# Sentence pair (710) source length 33 target length 28 alignment score : 1.32717e-09
The \MATH distance used to compute the distance of frame sequence until the sum of the sorted value of lower eight is larger than a threshold \MATH . 
NULL ({ }) The ({ 1 }) \MATH ({ 2 }) distance ({ 3 }) used ({ 4 }) to ({ 5 }) compute ({ 6 }) the ({ 7 }) distance ({ 8 }) of ({ 9 }) the ({ }) frame ({ 10 }) sequence ({ 11 }) until ({ 12 }) the ({ 13 }) sum ({ 14 }) of ({ 15 }) the ({ 16 }) sorted ({ 17 }) value ({ 18 }) of ({ 19 }) the ({ }) lower ({ 20 }) eight ({ 21 }) is ({ 22 }) larger ({ 23 }) than ({ 24 }) the ({ }) threshold ({ 26 }) \MATH ({ 27 }) . ({ 28 }) //[distance ({ 25 }) / ({ }) length?] ({ }) 
# Sentence pair (711) source length 23 target length 23 alignment score : 0.000255438
The frames from \MATH to \MATH , then , form a sub-shot and frame \MATH is used as the next base frame . 
NULL ({ }) The ({ 1 }) frames ({ 2 }) from ({ 3 }) \MATH ({ 4 }) to ({ 5 }) \MATH ({ 6 }) , ({ 7 }) then ({ 8 }) , ({ 9 }) form ({ 10 }) a ({ 11 }) sub-shot ({ 12 }) and ({ 13 }) frame ({ 14 }) \MATH ({ 15 }) is ({ 16 }) used ({ 17 }) as ({ 18 }) the ({ 19 }) next ({ 20 }) base ({ 21 }) frame ({ 22 }) . ({ 23 }) 
# Sentence pair (712) source length 13 target length 13 alignment score : 3.82634e-05
Finally , the short sub-shots with less than 25 frames are removed . 
NULL ({ }) Finally ({ 1 }) , ({ 2 }) the ({ 3 }) short ({ 4 }) sub-shots ({ 5 }) of ({ 6 }) less ({ 7 }) than ({ 8 }) 25 ({ 9 }) frames ({ 10 }) are ({ 11 }) removed ({ 12 }) . ({ 13 }) 
# Sentence pair (713) source length 18 target length 18 alignment score : 3.93799e-07
We employ a keyframe extraction algorithm proposed in \CITE to extract the representative keyframes from each sub-shot . 
NULL ({ 3 }) We ({ 1 }) use ({ 2 }) the ({ }) keyframe ({ 4 }) extraction ({ 5 }) algorithm ({ 6 }) proposed ({ 7 }) in ({ 8 }) \CITE ({ 9 }) to ({ 10 }) extract ({ 11 }) the ({ 12 }) representative ({ 13 }) keyframes ({ 14 }) from ({ 15 }) each ({ 16 }) sub-shot ({ 17 }) . ({ 18 }) 
# Sentence pair (714) source length 20 target length 19 alignment score : 0.000122954
In this approach , cosine distance is used to measure the difference between neighboring frames in each sub-shot . 
NULL ({ }) In ({ 1 }) this ({ 2 }) approach ({ 3 }) , ({ 4 }) the ({ }) cosine ({ 5 }) distance ({ 6 }) is ({ 7 }) used ({ 8 }) to ({ 9 }) measure ({ 10 }) the ({ 11 }) difference ({ 12 }) between ({ 13 }) neighboring ({ 14 }) frames ({ 15 }) in ({ 16 }) each ({ 17 }) sub-shot ({ 18 }) . ({ 19 }) 
# Sentence pair (715) source length 28 target length 28 alignment score : 4.31406e-05
Keyframes are selected at the midpoints between two consecutive high curvature points where the high curvature points are detected from the curve of the cumulative frame difference . 
NULL ({ }) Keyframes ({ 1 }) are ({ 2 }) selected ({ 3 }) at ({ 4 }) the ({ 5 }) midpoints ({ 6 }) between ({ 7 }) two ({ 8 }) consecutive ({ 9 }) high ({ 10 }) curvature ({ 11 }) points ({ 12 }) where ({ 13 }) the ({ 14 }) high ({ 15 }) curvature ({ 16 }) points ({ 17 }) are ({ 18 }) detected ({ 19 }) from ({ 20 }) the ({ 21 }) curve ({ 22 }) of ({ 23 }) the ({ 24 }) cumulative ({ 25 }) frame ({ 26 }) difference ({ 27 }) . ({ 28 }) 
# Sentence pair (716) source length 24 target length 24 alignment score : 0.000113642
The characteristics of color bars are vertically averaged , and the color histograms for each block in the same column should be similar . 
NULL ({ }) The ({ 1 }) characteristics ({ 2 }) of ({ 3 }) color ({ 4 }) bars ({ 5 }) are ({ 6 }) vertically ({ 7 }) averaged ({ 8 }) , ({ 9 }) and ({ 10 }) the ({ 11 }) color ({ 12 }) histograms ({ 13 }) for ({ 14 }) each ({ 15 }) block ({ 16 }) in ({ 17 }) the ({ 18 }) same ({ 19 }) column ({ 20 }) should ({ 21 }) be ({ 22 }) similar ({ 23 }) . ({ 24 }) 
# Sentence pair (717) source length 26 target length 24 alignment score : 1.5416e-08
We employ the algorithm proposed in \CITE by using \MATH distance to compute histogram differences between any two neighboring blocks in each column . 
NULL ({ }) We ({ 1 }) used ({ 2 }) the ({ 3 }) algorithm ({ 4 }) proposed ({ 5 }) in ({ 6 }) \CITE ({ 7 }) by ({ 8 }) using ({ 9 }) the ({ }) \MATH ({ 10 }) distance ({ 11 }) to ({ 12 }) compute ({ 13 }) the ({ }) histogram ({ 14 }) differences ({ 15 }) between ({ 16 }) any ({ 17 }) two ({ 18 }) neighboring ({ 19 }) blocks ({ 20 }) in ({ 21 }) each ({ 22 }) column ({ 23 }) . ({ 24 }) 
# Sentence pair (718) source length 10 target length 11 alignment score : 6.42727e-05
Next , we sort these values into an ascending order . 
NULL ({ }) Next ({ 1 }) , ({ 2 }) we ({ 3 }) sort ({ 4 }) these ({ 5 }) values ({ 6 }) into ({ 7 }) ascending ({ 8 9 }) order ({ 10 }) . ({ 11 }) 
# Sentence pair (719) source length 24 target length 23 alignment score : 9.14513e-08
If the value of the \MATH is smaller than threshold \MATH , then these sub-shot is defined as a color bar sub-shot . 
NULL ({ }) If ({ 1 }) the ({ 2 }) value ({ 3 }) of ({ 4 }) the ({ 5 }) \MATH ({ 6 }) is ({ 7 }) smaller ({ 8 }) than ({ 9 }) the ({ }) threshold ({ 10 }) \MATH ({ 11 }) , ({ 12 }) then ({ 13 }) these ({ 14 }) sub-shots ({ 15 }) are ({ 16 }) defined ({ 17 }) as ({ 18 }) a ({ 19 }) color ({ 20 }) bar ({ 21 }) sub-shot ({ 22 }) . ({ 23 }) 
# Sentence pair (720) source length 19 target length 18 alignment score : 6.89177e-07
From the properties of single color image , a dominant color in its global histogram is large . 
NULL ({ }) From ({ 1 }) the ({ 2 }) properties ({ 3 }) of ({ 4 }) a ({ }) single ({ 5 }) color ({ 6 }) image ({ 7 }) , ({ 8 }) the ({ 9 }) dominant ({ 10 }) color ({ 11 }) in ({ 12 }) its ({ 13 }) global ({ 14 }) histogram ({ 15 }) is ({ 16 }) large ({ 17 }) . ({ 18 }) 
# Sentence pair (721) source length 29 target length 27 alignment score : 1.04431e-06
If the value of the \MATH of global color histogram is larger than threshold \MATH , then these sub-shots are defined as a single color sub-shot . 
NULL ({ }) If ({ 1 }) the ({ 2 }) value ({ 3 }) of ({ 4 }) the ({ 5 }) \MATH ({ 6 }) of ({ 7 }) the ({ }) global ({ 8 }) color ({ 9 }) histogram ({ 10 }) is ({ 11 }) larger ({ 12 }) than ({ 13 }) the ({ }) threshold ({ 14 }) \MATH ({ 15 }) , ({ 16 }) then ({ 17 }) these ({ 18 }) sub-shots ({ 19 }) are ({ 20 }) defined ({ 21 }) as ({ 22 }) a ({ 23 }) single ({ 24 }) color ({ 25 }) sub-shot ({ 26 }) . ({ 27 }) 
# Sentence pair (722) source length 27 target length 28 alignment score : 8.41234e-12
In rushes videos , there are many types of clapper boards , appearance but the same type of clapper boards is often used in the same movie . 
NULL ({ 12 }) In ({ 1 }) rushes ({ 2 }) videos ({ 3 }) , ({ 4 }) there ({ 5 }) are ({ 6 }) many ({ 7 }) types ({ 8 }) of ({ 9 }) clapper ({ 10 }) boards ({ 11 13 }) , ({ }) but ({ 14 }) the ({ 15 }) same ({ 16 }) type ({ 17 }) of ({ 18 }) clapper ({ 19 }) board ({ 20 }) is ({ 21 }) often ({ 22 }) used ({ 23 }) in ({ 24 }) the ({ 25 }) same ({ 26 }) movie ({ 27 }) . ({ 28 }) 
# Sentence pair (723) source length 18 target length 17 alignment score : 1.406e-11
The clapper boards have many types , such as scale , rotation , and illumination changes . 
NULL ({ 4 }) There ({ 1 }) are ({ }) many ({ 5 }) types ({ 6 }) of ({ }) clapper ({ 2 }) boards ({ 3 }) , ({ 7 }) such ({ 8 }) as ({ 9 }) scale ({ 10 }) , ({ 11 }) rotation ({ 12 }) , ({ 13 }) and ({ 14 }) illumination ({ 15 }) changes ({ 16 }) . ({ 17 }) 
# Sentence pair (724) source length 27 target length 27 alignment score : 4.03261e-05
The NDK algorithm , proposed in \CITE , is invariant to image scaling , translation , rotation , illumination changes , and affine or 3D projection . 
NULL ({ }) The ({ 1 }) NDK ({ 2 }) algorithm ({ 3 }) , ({ 4 }) proposed ({ 5 }) in ({ 6 }) \CITE ({ 7 }) , ({ 8 }) is ({ 9 }) invariant ({ 10 }) to ({ 11 }) image ({ 12 }) scaling ({ 13 }) , ({ 14 }) translation ({ 15 }) , ({ 16 }) rotation ({ 17 }) , ({ 18 }) illumination ({ 19 }) changes ({ 20 }) , ({ 21 }) and ({ 22 }) affine ({ 23 }) or ({ 24 }) 3D ({ 25 }) projection ({ 26 }) . ({ 27 }) 
# Sentence pair (725) source length 24 target length 23 alignment score : 9.3724e-06
A set of 80 example keyframes of clapper boards are extracted from the development set and used as a set of queries . 
NULL ({ }) A ({ 1 }) set ({ 2 }) of ({ 3 }) 80 ({ 4 }) example ({ 5 }) keyframes ({ 6 }) of ({ 7 }) clapper ({ 8 }) boards ({ 9 }) were ({ 10 }) extracted ({ 11 }) from ({ 12 }) the ({ 13 }) development ({ 14 }) set ({ 15 }) and ({ 16 }) is ({ }) used ({ 17 }) as ({ 18 }) a ({ 19 }) set ({ 20 }) of ({ 21 }) queries ({ 22 }) . ({ 23 }) 
# Sentence pair (726) source length 20 target length 20 alignment score : 0.000503345
Next , we extract the keypoints of the keyframes given from section \REF and match them with the query . 
NULL ({ }) Next ({ 1 }) , ({ 2 }) we ({ 3 }) extract ({ 4 }) the ({ 5 }) keypoints ({ 6 }) of ({ 7 }) the ({ 8 }) keyframes ({ 9 }) given ({ 10 }) from ({ 11 }) section ({ 12 }) \REF ({ 13 }) and ({ 14 }) match ({ 15 }) them ({ 16 }) with ({ 17 }) the ({ 18 }) query ({ 19 }) . ({ 20 }) 
# Sentence pair (727) source length 27 target length 27 alignment score : 1.9747e-17
If a result of the NDK algorithm returns a match between a keyframe with a query then we define the sub-shot is a clapper board sub-shot . 
NULL ({ 18 }) If ({ 1 }) the ({ 2 }) result ({ 3 }) of ({ 4 }) the ({ 5 }) NDK ({ 6 }) algorithm ({ 7 }) returns ({ 8 }) a ({ 9 }) match ({ 10 }) from ({ 11 }) a ({ 12 }) keyframe ({ 13 }) with ({ 14 }) a ({ 15 }) query ({ 16 }) then ({ 17 }) the ({ 20 }) sub-shot ({ 21 }) is ({ 22 }) defined ({ 19 }) as ({ }) a ({ 23 }) clapper ({ 24 }) board ({ 25 }) sub-shot ({ 26 }) . ({ 27 }) 
# Sentence pair (728) source length 14 target length 14 alignment score : 1.59318e-07
The unused keyframes containing of story units for generate video summary are removed . 
NULL ({ 5 }) The ({ 1 }) unused ({ 2 }) keyframes ({ 3 }) containing ({ 4 }) story ({ 6 }) units ({ 7 }) for ({ 8 }) the ({ }) generated ({ 9 }) video ({ 10 }) summary ({ 11 }) are ({ 12 }) removed ({ 13 }) . ({ 14 }) 
# Sentence pair (729) source length 19 target length 17 alignment score : 5.23743e-09
However , rushes videos containing of repetitive story , such as retake scenes , are unedited . 
NULL ({ 6 }) However ({ 1 }) , ({ 2 }) rushes ({ 3 }) videos ({ 4 }) containing ({ 5 }) a ({ }) repetitive ({ 7 }) story ({ 8 }) , ({ 9 }) such ({ 10 }) as ({ 11 }) a ({ }) retake ({ 12 }) of ({ }) scenes ({ 13 }) , ({ 14 }) are ({ 15 }) unedited ({ 16 }) . ({ 17 }) 
# Sentence pair (730) source length 13 target length 15 alignment score : 5.76922e-09
To create the efficiently of rushes videos , the repetitive contents must be eliminated . 
NULL ({ 3 5 }) To ({ 1 }) efficiently ({ 4 }) create ({ 2 }) rushes ({ 6 }) videos ({ 7 }) , ({ 8 }) the ({ 9 }) repetitive ({ 10 }) contents ({ 11 }) must ({ 12 }) be ({ 13 }) eliminated ({ 14 }) . ({ 15 }) 
# Sentence pair (731) source length 12 target length 12 alignment score : 0.0159258
Generally , a group of continuous contents often share some properties . 
NULL ({ }) Generally ({ 1 }) , ({ 2 }) a ({ 3 }) group ({ 4 }) of ({ 5 }) continuous ({ 6 }) contents ({ 7 }) often ({ 8 }) share ({ 9 }) some ({ 10 }) properties ({ 11 }) . ({ 12 }) 
# Sentence pair (732) source length 22 target length 19 alignment score : 1.6333e-08
From this characteristic , clustering technique can be used to separate the data into groups of similar contents . 
NULL ({ }) With ({ 1 }) this ({ 2 }) characteristic ({ 3 }) in ({ }) mind ({ }) , ({ 4 }) a ({ }) clustering ({ 5 }) technique ({ 6 }) can ({ 7 }) be ({ 8 }) used ({ 9 }) to ({ 10 }) separate ({ 11 }) the ({ 12 }) data ({ 13 }) into ({ 14 }) groups ({ 15 }) of ({ 16 }) similar ({ 17 }) contents ({ 18 }) . ({ 19 }) 
# Sentence pair (733) source length 24 target length 22 alignment score : 4.86798e-06
Each group , called cluster , consists of contents that are similar between themselves and dissimilar to contents of other groups . 
NULL ({ }) Each ({ 1 }) group ({ 2 }) , ({ 3 }) called ({ 4 }) a ({ }) cluster ({ 5 }) , ({ 6 }) consists ({ 7 }) of ({ 8 }) contents ({ 9 }) that ({ 10 }) are ({ 11 }) similar ({ 12 }) between ({ 13 }) themselves ({ 14 }) and ({ 15 }) dissimilar ({ 16 }) to ({ 17 }) the ({ }) contents ({ 18 }) of ({ 19 }) other ({ 20 }) groups ({ 21 }) . ({ 22 }) 
# Sentence pair (734) source length 23 target length 23 alignment score : 4.84916e-06
GreedyRSC , proposed in \CITE , is used to find clusters with high precision and the number of clusters is automatically determined . 
NULL ({ }) GreedyRSC ({ 1 }) , ({ 2 }) proposed ({ 3 }) in ({ 4 }) \CITE ({ 5 }) , ({ 6 }) is ({ 7 }) used ({ 8 }) to ({ 9 }) find ({ 10 }) clusters ({ 11 }) at ({ 12 }) high ({ 13 }) precision ({ 14 }) and ({ 15 }) the ({ 16 }) number ({ 17 }) of ({ 18 }) clusters ({ 19 }) is ({ 20 }) automatically ({ 21 }) determined ({ 22 }) . ({ 23 }) 
# Sentence pair (735) source length 27 target length 26 alignment score : 6.07808e-08
To do the clustering on keyframes , three different features , including mean , variance , and skewness , are extracted from local color histogram . 
NULL ({ 3 }) To ({ 1 }) do ({ 2 }) clustering ({ 4 }) on ({ 5 }) keyframes ({ 6 }) , ({ 7 }) three ({ 8 }) different ({ 9 }) features ({ 10 }) , ({ 11 }) including ({ 12 }) the ({ }) mean ({ 13 }) , ({ 14 }) variance ({ 15 }) , ({ 16 }) and ({ 17 }) skew ({ 18 }) , ({ 19 }) are ({ 20 }) extracted ({ 21 }) from ({ 22 }) the ({ }) local ({ 23 }) color ({ 24 }) histogram ({ 25 }) . ({ 26 }) 
# Sentence pair (736) source length 15 target length 14 alignment score : 0.00016202
These values are used to represent the keyframes content and defined as follows : 
NULL ({ }) These ({ 1 }) values ({ 2 }) are ({ 3 }) used ({ 4 }) to ({ 5 }) represent ({ 6 }) the ({ 7 }) keyframes ({ 8 }) content ({ 9 }) and ({ 10 }) are ({ }) defined ({ 11 }) as ({ 12 }) follows ({ 13 }) : ({ 14 }) 
# Sentence pair (737) source length 10 target length 9 alignment score : 0.00986082
Figure \REF shows an example of clustering result . 
NULL ({ }) Figure ({ 1 }) \REF ({ 2 }) shows ({ 3 }) an ({ 4 }) example ({ 5 }) of ({ 6 }) a ({ }) clustering ({ 7 }) result ({ 8 }) . ({ 9 }) 
# Sentence pair (738) source length 22 target length 20 alignment score : 3.45581e-09
So far , we completely remove the unused contents from rushes video and reduce repetition of the story contents . 
NULL ({ }) So ({ 1 }) far ({ 2 }) , ({ 3 }) we ({ 4 }) have ({ }) completely ({ 5 }) removed ({ 6 }) the ({ 7 }) unused ({ 8 }) contents ({ 9 }) from ({ 10 }) rushes ({ 11 }) videos ({ 12 }) and ({ 13 }) reduced ({ 14 }) any ({ }) repetition ({ 15 }) of ({ 16 }) the ({ 17 }) story ({ 18 }) contents ({ 19 }) . ({ 20 }) 
# Sentence pair (739) source length 46 target length 45 alignment score : 7.24959e-11
The objective of rushes summarization at TRECVID 2008 is to generate short summaries ( the upper limit of the duration of summary is 2\% of the original video ) , less repetitive of content , and must have many objects and events as possible . 
NULL ({ 33 }) The ({ 1 }) objective ({ 2 }) of ({ 3 }) rushes ({ 4 }) summarization ({ 5 }) at ({ 6 }) TRECVID ({ 7 }) 2008 ({ 8 }) is ({ 9 }) to ({ 10 }) generate ({ 11 }) short ({ 12 }) summaries ({ 13 }) ( ({ 14 }) the ({ 15 }) upper ({ 16 }) limit ({ 17 }) of ({ 18 }) the ({ 19 }) duration ({ 20 }) of ({ 21 }) a ({ }) summary ({ 22 }) is ({ 23 }) 2\% ({ 24 }) of ({ 25 }) the ({ 26 }) original ({ 27 }) video ({ 28 }) ) ({ 29 }) , ({ 30 }) less ({ 31 }) repetitive ({ 32 }) content ({ 34 }) , ({ 35 }) and ({ 36 }) must ({ 37 }) have ({ 38 }) as ({ }) many ({ 39 }) objects ({ 40 }) and ({ 41 }) events ({ 42 }) as ({ 43 }) possible ({ 44 }) . ({ 45 }) 
# Sentence pair (740) source length 19 target length 16 alignment score : 1.91361e-06
To reach this objective , the important keyframes should be selected to generate summary video . 
NULL ({ }) To ({ 1 }) reach ({ 2 }) this ({ 3 }) objective ({ 4 }) , ({ 5 }) only ({ }) the ({ 6 }) most ({ }) important ({ 7 }) keyframes ({ 8 }) should ({ 9 }) be ({ 10 }) selected ({ 11 }) to ({ 12 }) generate ({ 13 }) a ({ }) summary ({ 14 }) video ({ 15 }) . ({ 16 }) 
# Sentence pair (741) source length 15 target length 14 alignment score : 0.00123405
To generate summary , we first compute its maximum duration in seconds \MATH , 
NULL ({ }) To ({ 1 }) generate ({ 2 }) a ({ }) summary ({ 3 }) , ({ 4 }) we ({ 5 }) first ({ 6 }) compute ({ 7 }) its ({ 8 }) maximum ({ 9 }) duration ({ 10 }) in ({ 11 }) seconds ({ 12 }) \MATH ({ 13 }) , ({ 14 }) 
# Sentence pair (742) source length 10 target length 10 alignment score : 0.0345642
where \MATH is the maximum duration for the summary . 
NULL ({ }) where ({ 1 }) \MATH ({ 2 }) is ({ 3 }) the ({ 4 }) maximum ({ 5 }) duration ({ 6 }) for ({ 7 }) the ({ 8 }) summary ({ 9 }) . ({ 10 }) 
# Sentence pair (743) source length 17 target length 16 alignment score : 0.000623751
Second , we compute quota length for each cluster based on the cluster size \MATH . 
NULL ({ }) Second ({ 1 }) , ({ 2 }) we ({ 3 }) compute ({ 4 }) the ({ }) quota ({ 5 }) length ({ 6 }) for ({ 7 }) each ({ 8 }) cluster ({ 9 }) based ({ 10 }) on ({ 11 }) the ({ 12 }) cluster ({ 13 }) size ({ 14 }) \MATH ({ 15 }) . ({ 16 }) 
# Sentence pair (744) source length 39 target length 36 alignment score : 1.93856e-08
Third , merge consecutive sub-shots in each cluster into shots and compute the priority of each shot based on priority of shot weighted duration and shot weighted average motion magnitude using the following equation : \MATH</p> 
NULL ({ }) Third ({ 1 }) , ({ 2 }) merge ({ 3 }) the ({ }) consecutive ({ 4 }) sub-shots ({ 5 }) in ({ 6 }) each ({ 7 }) cluster ({ 8 }) into ({ 9 }) shots ({ 10 }) and ({ 11 }) compute ({ 12 }) the ({ 13 }) priority ({ 14 }) of ({ 15 }) each ({ 16 }) shot ({ 17 }) based ({ 18 }) on ({ 19 }) the ({ }) priority ({ 20 }) of ({ 21 }) the ({ }) shot ({ 22 }) weighted ({ 23 }) duration ({ 24 }) and ({ 25 }) shot ({ 26 }) weighted ({ 27 }) average ({ 28 }) motion ({ 29 }) magnitude ({ 30 }) using ({ 31 }) the ({ 32 }) following ({ 33 }) equation ({ 34 }) : ({ 35 }) \MATH</p> ({ 36 }) 
# Sentence pair (745) source length 17 target length 17 alignment score : 0.00276411
Next , these \MATH values are sorted into descending order and the first shot is selected . 
NULL ({ }) Next ({ 1 }) , ({ 2 }) these ({ 3 }) \MATH ({ 4 }) values ({ 5 }) are ({ 6 }) sorted ({ 7 }) into ({ 8 }) descending ({ 9 }) order ({ 10 }) and ({ 11 }) the ({ 12 }) first ({ 13 }) shot ({ 14 }) is ({ 15 }) selected ({ 16 }) . ({ 17 }) 
# Sentence pair (746) source length 19 target length 18 alignment score : 5.3734e-09
Forth , sort sub-shots in the selected shot in descending order based on the average motion magnitude . 
NULL ({ }) Fourth ({ 1 }) , ({ 2 }) sub-shots ({ 3 4 }) in ({ 5 }) the ({ 6 }) selected ({ 7 }) shot ({ 8 }) in ({ 9 }) descending ({ 10 }) order ({ 11 }) are ({ }) sorted ({ }) based ({ 12 }) on ({ 13 }) the ({ 14 }) average ({ 15 }) motion ({ 16 }) magnitude ({ 17 }) . ({ 18 }) 
# Sentence pair (747) source length 18 target length 16 alignment score : 5.25976e-09
Select sub-shots from top to bottom until the quota length for that shot is reached . 
NULL ({ }) The ({ 1 }) sub-shots ({ 2 }) are ({ }) selected ({ }) from ({ 3 }) top ({ 4 }) to ({ 5 }) bottom ({ 6 }) until ({ 7 }) the ({ 8 }) quota ({ 9 }) length ({ 10 }) for ({ 11 }) that ({ 12 }) shot ({ 13 }) is ({ 14 }) reached ({ 15 }) . ({ 16 }) 
# Sentence pair (748) source length 24 target length 23 alignment score : 1.81061e-09
Fifth , for each selected sub-shot , extract 25 frames ( 1 second ) around the middle to generate the final summary . 
NULL ({ }) Fifth ({ 1 }) , ({ 2 }) for ({ 3 }) each ({ 4 }) selected ({ 5 }) sub-shot ({ 6 }) , ({ 7 }) 25 ({ 9 }) frames ({ 10 }) ( ({ 11 }) 1 ({ 12 }) second ({ 13 }) ) ({ 14 }) around ({ 15 }) the ({ 16 }) middle ({ 17 }) are ({ }) extracted ({ 8 }) to ({ 18 }) generate ({ 19 }) the ({ 20 }) final ({ 21 }) summary ({ 22 }) . ({ 23 }) 
# Sentence pair (749) source length 17 target length 19 alignment score : 5.37109e-12
This system is adopted with some modifications from the system developed for the same task last year \CITE . 
NULL ({ }) This ({ 1 }) system ({ 2 }) has ({ 3 }) some ({ 6 }) modifications ({ 4 5 7 }) from ({ 8 }) the ({ 9 }) system ({ 10 }) developed ({ 11 }) for ({ 12 }) the ({ 13 }) same ({ 14 }) task ({ 15 }) last ({ 16 }) year ({ 17 }) \CITE ({ 18 }) . ({ 19 }) 
# Sentence pair (750) source length 20 target length 18 alignment score : 1.36121e-05
Specifically , the original video is decomposed into segments , which are shots with hard cut transition . 
NULL ({ }) Specifically ({ 1 }) , ({ 2 }) the ({ 3 }) original ({ 4 }) video ({ 5 }) is ({ 6 }) broken ({ 7 }) down ({ }) into ({ 8 }) segments ({ 9 }) , ({ 10 }) which ({ 11 }) are ({ 12 }) shots ({ 13 }) with ({ 14 }) a ({ }) hard ({ 15 }) cut ({ 16 }) transition ({ 17 }) . ({ 18 }) 
# Sentence pair (751) source length 19 target length 18 alignment score : 2.80169e-05
These segments are further decomposed into fragments so that each fragment represents a portion of a scene . 
NULL ({ }) These ({ 1 }) segments ({ 2 }) are ({ 3 }) further ({ 4 }) broken ({ 5 }) down ({ }) into ({ 6 }) fragments ({ 7 }) so ({ 8 }) that ({ 9 }) each ({ 10 }) fragment ({ 11 }) represents ({ 12 }) a ({ 13 }) portion ({ 14 }) of ({ 15 }) a ({ 16 }) scene ({ 17 }) . ({ 18 }) 
# Sentence pair (752) source length 43 target length 41 alignment score : 1.36365e-11
In order to reduce the computation time , we only extract a subset of frames from the original video by sampling at a five frame interval ( i.e extract frames 0th , 5th , 10th , and so on ) . 
NULL ({ }) In ({ 1 }) order ({ 2 }) to ({ 3 }) reduce ({ 4 }) the ({ 5 }) computation ({ 6 }) time ({ 7 }) , ({ 8 }) we ({ 9 }) only ({ 10 }) extract ({ 11 }) a ({ 12 }) subset ({ 13 }) of ({ 14 }) the ({ }) frames ({ 15 }) from ({ 16 }) the ({ 17 }) original ({ 18 }) video ({ 19 }) by ({ 20 }) sampling ({ 21 }) it ({ }) at ({ 22 }) a ({ 23 }) five ({ 24 }) frame ({ 25 }) interval ({ 26 }) ( ({ 27 }) i.e. ({ 28 }) extract ({ 29 }) frames ({ 30 }) 0 ({ 31 }) , ({ 32 }) 5th ({ 33 }) , ({ 34 }) 10th ({ 35 }) , ({ 36 }) and ({ 37 }) so ({ 38 }) on ({ 39 }) ) ({ 40 }) . ({ 41 }) 
# Sentence pair (753) source length 20 target length 20 alignment score : 0.00103862
For each frame , we use grid color moments with the same configuration as in \CITE for feature representation . 
NULL ({ }) For ({ 1 }) each ({ 2 }) frame ({ 3 }) , ({ 4 }) we ({ 5 }) use ({ 6 }) grid ({ 7 }) color ({ 8 }) moments ({ 9 }) with ({ 10 }) the ({ 11 }) same ({ 12 }) configuration ({ 13 }) as ({ 14 }) in ({ 15 }) \CITE ({ 16 }) for ({ 17 }) feature ({ 18 }) representation ({ 19 }) . ({ 20 }) 
# Sentence pair (754) source length 29 target length 28 alignment score : 9.97787e-06
The segment boundary , which is located at hard cut transition , is determined by using a loose threshold on the Euclidean distance between two consecutive frames . 
NULL ({ }) The ({ 1 }) segment ({ 2 }) boundary ({ 3 }) , ({ 4 }) which ({ 5 }) is ({ 6 }) located ({ 7 }) at ({ 8 }) the ({ }) hard ({ 9 }) cut ({ 10 }) transition ({ 11 }) , ({ 12 }) is ({ 13 }) determined ({ 14 }) by ({ 15 }) using ({ 16 }) a ({ 17 }) loose ({ 18 }) threshold ({ 19 }) on ({ 20 }) the ({ 21 }) Euclidean ({ 22 }) distance ({ 23 }) between ({ 24 }) two ({ 25 }) consecutive ({ 26 }) frames ({ 27 }) . ({ 28 }) 
# Sentence pair (755) source length 18 target length 17 alignment score : 0.000215253
Meanwhile , the fragment boundary is determined by using a strict threshold to detect dramatic motion . 
NULL ({ }) Meanwhile ({ 1 }) , ({ 2 }) the ({ 3 }) fragment ({ 4 }) boundary ({ 5 }) is ({ 6 }) determined ({ 7 }) by ({ 8 }) using ({ 9 }) a ({ 10 }) strict ({ 11 }) threshold ({ 12 }) to ({ 13 }) detect ({ 14 }) any ({ }) dramatic ({ 15 }) motion ({ 16 }) . ({ 17 }) 
# Sentence pair (756) source length 28 target length 26 alignment score : 2.97192e-06
Instead of selecting one keyframe to represent one fragment as many other systems do , we use all frames of each fragment for redundancy elimination . 
NULL ({ }) Instead ({ 1 }) of ({ 2 }) selecting ({ 3 }) one ({ 4 }) keyframe ({ 5 }) to ({ 6 }) represent ({ 7 }) one ({ 8 }) fragment ({ 9 }) as ({ 10 }) many ({ 11 }) other ({ 12 }) systems ({ 13 }) do ({ 14 }) , ({ 15 }) we ({ 16 }) use ({ 17 }) all ({ 18 }) the ({ }) frames ({ 19 }) of ({ 20 }) each ({ 21 }) fragment ({ 22 }) for ({ 23 }) the ({ }) redundancy ({ 24 }) elimination ({ 25 }) . ({ 26 }) 
# Sentence pair (757) source length 22 target length 20 alignment score : 2.50723e-05
We use GreedyRSC \CITE to do clustering on the set of all sampled frames extracted from the original video . 
NULL ({ }) We ({ 1 }) use ({ 2 }) GreedyRSC ({ 3 }) \CITE ({ 4 }) to ({ 5 }) do ({ 6 }) the ({ }) clustering ({ 7 }) on ({ 8 }) the ({ 9 }) set ({ 10 }) of ({ 11 }) all ({ 12 }) the ({ }) sampled ({ 13 }) frames ({ 14 }) extracted ({ 15 }) from ({ 16 }) the ({ 17 }) original ({ 18 }) video ({ 19 }) . ({ 20 }) 
# Sentence pair (758) source length 11 target length 11 alignment score : 0.000876949
The number of clusters is determined automatically by this method . 
NULL ({ }) The ({ 1 }) number ({ 2 }) of ({ 3 }) clusters ({ 4 }) is ({ 5 }) determined ({ 6 }) automatically ({ 7 }) using ({ 8 }) this ({ 9 }) method ({ 10 }) . ({ 11 }) 
# Sentence pair (759) source length 13 target length 13 alignment score : 0.00674228
Frames that belong to the same cluster are assigned the same label . 
NULL ({ }) Frames ({ 1 }) that ({ 2 }) belong ({ 3 }) to ({ 4 }) the ({ 5 }) same ({ 6 }) cluster ({ 7 }) are ({ 8 }) assigned ({ 9 }) the ({ 10 }) same ({ 11 }) label ({ 12 }) . ({ 13 }) 
# Sentence pair (760) source length 22 target length 21 alignment score : 0.000104292
By this discretization process , we can cast one fragment as one string whose characters are labels of its frames . 
NULL ({ }) By ({ 1 }) this ({ 2 }) discretization ({ 3 }) process ({ 4 }) , ({ 5 }) we ({ 6 }) can ({ 7 }) cast ({ 8 }) one ({ 9 }) fragment ({ 10 }) as ({ 11 }) one ({ 12 }) string ({ 13 }) whose ({ 14 }) characters ({ 15 }) are ({ 16 }) the ({ }) labels ({ 17 }) of ({ 18 }) its ({ 19 }) frames ({ 20 }) . ({ 21 }) 
# Sentence pair (761) source length 27 target length 28 alignment score : 1.52477e-11
We compute the similarity value between two fragments by counting the number of shared characters between two strings and being normalized to the size of each string . 
NULL ({ }) We ({ 1 }) compute ({ 2 }) the ({ 3 }) similarity ({ 4 5 }) between ({ 6 }) two ({ 7 }) fragments ({ 8 }) by ({ 9 }) counting ({ 10 }) the ({ 11 }) number ({ 12 }) of ({ 13 }) shared ({ 14 }) characters ({ 15 }) between ({ 16 }) two ({ 17 }) strings ({ 18 }) and ({ 19 }) being ({ 20 }) normalized ({ 21 }) to ({ 22 }) the ({ 23 }) size ({ 24 }) of ({ 25 }) each ({ 26 }) string ({ 27 }) . ({ 28 }) 
# Sentence pair (762) source length 18 target length 18 alignment score : 4.70687e-06
If this value is larger than a threshold , these two segments are merged into one cluster . 
NULL ({ }) If ({ 1 }) this ({ 2 }) value ({ 3 }) is ({ 4 }) larger ({ 5 }) than ({ 6 }) the ({ 7 }) threshold ({ 8 }) , ({ 9 }) these ({ 10 }) two ({ 11 }) segments ({ 12 }) are ({ 13 }) merged ({ 14 }) into ({ 15 }) one ({ 16 }) cluster ({ 17 }) . ({ 18 }) 
# Sentence pair (763) source length 36 target length 36 alignment score : 7.49839e-14
We found that this approach is more effective than the approach using one keyframe for one fragment since the more number of keyframes is used , the more information is available to make right decision . 
NULL ({ 22 }) We ({ 1 }) found ({ 2 }) that ({ 3 }) this ({ 4 }) approach ({ 5 }) is ({ 6 }) more ({ 7 }) effective ({ 8 }) than ({ 9 }) the ({ 10 }) approach ({ 11 }) using ({ 12 }) one ({ 13 }) keyframe ({ 14 }) for ({ 15 }) one ({ 16 }) fragment ({ 17 }) since ({ 18 }) the ({ 19 }) more ({ 20 }) keyframes ({ 21 }) that ({ 23 }) are ({ 24 }) used ({ 25 }) , ({ 26 }) the ({ 27 }) more ({ 28 }) information ({ 29 }) is ({ 30 }) available ({ 31 }) to ({ 32 }) make ({ 33 }) the ({ }) right ({ 34 }) decision ({ 35 }) . ({ 36 }) 
# Sentence pair (764) source length 27 target length 26 alignment score : 7.60795e-06
We select junk frames such as color bar frames , single color ( black or white ) frames to form the reference junk frame set . 
NULL ({ }) We ({ 1 }) select ({ 2 }) junk ({ 3 }) frames ({ 4 }) such ({ 5 }) as ({ 6 }) color ({ 7 }) bar ({ 8 }) frames ({ 9 }) , ({ 10 }) and ({ }) single ({ 11 }) color ({ 12 }) ( ({ 13 }) black ({ 14 }) or ({ 15 }) white ({ 16 }) ) ({ 17 }) frames ({ 18 }) to ({ 19 }) form ({ 20 }) the ({ 21 }) reference ({ 22 }) junk ({ 23 }) frame ({ 24 }) set ({ 25 }) . ({ 26 }) 
# Sentence pair (765) source length 25 target length 26 alignment score : 1.60583e-07
To check whether a fragment is a junk , we compare the frames of this fragment to the frames of the reference junk frame set . 
NULL ({ 7 }) To ({ 1 }) check ({ 2 }) whether ({ 3 }) a ({ 4 }) fragment ({ 5 }) is ({ 6 }) junk ({ 8 }) , ({ 9 }) we ({ 10 }) compare ({ 11 }) the ({ 12 }) frames ({ 13 }) of ({ 14 }) this ({ 15 }) fragment ({ 16 }) to ({ 17 }) the ({ 18 }) frames ({ 19 }) of ({ 20 }) the ({ 21 }) reference ({ 22 }) junk ({ 23 }) frame ({ 24 }) set ({ 25 }) . ({ 26 }) 
# Sentence pair (766) source length 17 target length 17 alignment score : 0.00304187
The similarity between two frames is the Euclidean distance between two grid color moment feature vectors . 
NULL ({ }) The ({ 1 }) similarity ({ 2 }) between ({ 3 }) two ({ 4 }) frames ({ 5 }) is ({ 6 }) the ({ 7 }) Euclidean ({ 8 }) distance ({ 9 }) between ({ 10 }) two ({ 11 }) grid ({ 12 }) color ({ 13 }) moment ({ 14 }) feature ({ 15 }) vectors ({ 16 }) . ({ 17 }) 
# Sentence pair (767) source length 11 target length 10 alignment score : 0.0071681
We empirically select thresholds for each type of junk . 
NULL ({ }) We ({ 1 }) empirically ({ 2 }) select ({ 3 }) the ({ }) thresholds ({ 4 }) for ({ 5 }) each ({ 6 }) type ({ 7 }) of ({ 8 }) junk ({ 9 }) . ({ 10 }) 
# Sentence pair (768) source length 45 target length 44 alignment score : 5.76735e-11
If the similarity between one frame in the input fragment and one frame in the reference junk frame set is lower than the predefined thresholds, the input fragment is considered as junk and all fragments of the cluster containing junk fragment are eliminated . 
NULL ({ 31 }) If ({ 1 }) the ({ 2 }) similarity ({ 3 }) between ({ 4 }) one ({ 5 }) frame ({ 6 }) in ({ 7 }) the ({ 8 }) input ({ 9 }) fragment ({ 10 }) and ({ 11 }) one ({ 12 }) frame ({ 13 }) in ({ 14 }) the ({ 15 }) reference ({ 16 }) junk ({ 17 }) frame ({ 18 }) set ({ 19 }) is ({ 20 }) lower ({ 21 }) than ({ 22 }) the ({ 23 }) predefined ({ 24 }) thresholds, ({ 25 }) the ({ 26 }) input ({ 27 }) fragment ({ 28 }) is ({ 29 }) considered ({ 30 }) junk ({ 32 }) and ({ 33 }) all ({ 34 }) the ({ }) fragments ({ 35 }) of ({ 36 }) the ({ 37 }) cluster ({ 38 }) containing ({ 39 }) the ({ }) junk ({ 40 }) fragment ({ 41 }) are ({ 42 }) eliminated ({ 43 }) . ({ 44 }) 
# Sentence pair (769) source length 25 target length 22 alignment score : 3.28451e-06
In our system, we only check fragments that are located at two ends of the original video for reducing computation time . 
NULL ({ }) In ({ 1 }) our ({ 2 }) system, ({ 3 }) we ({ 4 }) only ({ 5 }) check ({ 6 }) the ({ }) fragments ({ 7 }) that ({ 8 }) are ({ 9 }) located ({ 10 }) at ({ 11 }) the ({ }) two ({ 12 }) ends ({ 13 }) of ({ 14 }) the ({ 15 }) original ({ 16 }) video ({ 17 }) for ({ 18 }) reducing ({ 19 }) the ({ }) computation ({ 20 }) time ({ 21 }) . ({ 22 }) 
# Sentence pair (770) source length 22 target length 22 alignment score : 0.0002651
However, by using the clustering result, junk fragments that are not checked against the reference junk frame set are also removed . 
NULL ({ }) However, ({ 1 }) by ({ 2 }) using ({ 3 }) the ({ 4 }) clustering ({ 5 }) result, ({ 6 }) junk ({ 7 }) fragments ({ 8 }) that ({ 9 }) are ({ 10 }) not ({ 11 }) checked ({ 12 }) against ({ 13 }) the ({ 14 }) reference ({ 15 }) junk ({ 16 }) frame ({ 17 }) set ({ 18 }) are ({ 19 }) also ({ 20 }) removed ({ 21 }) . ({ 22 }) 
# Sentence pair (771) source length 27 target length 27 alignment score : 4.64363e-05
For each cluster, we merge adjacent fragments into longer fragments and select the longest fragment as the representative fragment to be included in the final summary . 
NULL ({ }) For ({ 1 }) each ({ 2 }) cluster, ({ 3 }) we ({ 4 }) merge ({ 5 }) adjacent ({ 6 }) fragments ({ 7 }) into ({ 8 }) longer ({ 9 }) fragments ({ 10 }) and ({ 11 }) select ({ 12 }) the ({ 13 }) longest ({ 14 }) fragment ({ 15 }) as ({ 16 }) the ({ 17 }) representative ({ 18 }) fragment ({ 19 }) to ({ 20 }) be ({ 21 }) included ({ 22 }) in ({ 23 }) the ({ 24 }) final ({ 25 }) summary ({ 26 }) . ({ 27 }) 
# Sentence pair (772) source length 28 target length 29 alignment score : 1.4481e-15
Since the length of these fragments is still larger than the maximum length of the final summary, we employ a simple strategy to shrink these fragments as follows . 
NULL ({ 27 28 }) Since ({ 1 }) the ({ 2 }) length ({ 3 }) of ({ 4 }) these ({ 5 }) fragments ({ 6 }) is ({ 7 }) still ({ 8 }) larger ({ 9 }) than ({ 10 }) the ({ 11 }) maximum ({ 12 }) length ({ 13 }) of ({ 14 }) the ({ 15 }) final ({ 16 }) summary, ({ 17 }) we ({ 18 }) use ({ 19 }) the ({ }) following ({ 20 }) simple ({ 21 }) strategy ({ 22 }) to ({ 23 }) shrink ({ 24 }) these ({ 25 }) fragments ({ 26 }) . ({ 29 }) 
# Sentence pair (773) source length 27 target length 27 alignment score : 4.25732e-05
First, we assign a quota, which is the maximum duration, for each fragment by dividing the maximum duration for the summary to the number of clusters . 
NULL ({ }) First, ({ 1 }) we ({ 2 }) assign ({ 3 }) a ({ 4 }) quota, ({ 5 }) which ({ 6 }) is ({ 7 }) the ({ 8 }) maximum ({ 9 }) duration, ({ 10 }) for ({ 11 }) each ({ 12 }) fragment ({ 13 }) by ({ 14 }) dividing ({ 15 }) the ({ 16 }) maximum ({ 17 }) duration ({ 18 }) for ({ 19 }) the ({ 20 }) summary ({ 21 }) to ({ 22 }) the ({ 23 }) number ({ 24 }) of ({ 25 }) clusters ({ 26 }) . ({ 27 }) 
# Sentence pair (774) source length 19 target length 18 alignment score : 9.11751e-06
Second, for each fragment, we extract the portion which is expanded from the central of the fragment . 
NULL ({ }) Second, ({ 1 }) for ({ 2 }) each ({ 3 }) fragment, ({ 4 }) we ({ 5 }) extract ({ 6 }) the ({ 7 }) portion ({ 8 }) that ({ 9 }) is ({ 10 }) expanded ({ 11 }) from ({ 12 }) the ({ 13 }) central ({ 14 }) part ({ }) of ({ 15 }) the ({ 16 }) fragment ({ 17 }) . ({ 18 }) 
# Sentence pair (775) source length 24 target length 22 alignment score : 1.05605e-16
This portion covers a duration twice as much as the fragment quota by selecting frames with sampling rate of 2 frames . 
NULL ({ 7 9 }) This ({ 1 }) portion ({ 2 }) covers ({ 3 }) a ({ 4 }) duration ({ 5 }) twice ({ 6 }) the ({ }) size ({ 8 }) of ({ }) the ({ 10 }) fragment ({ 11 }) quota ({ 12 }) by ({ 13 }) selecting ({ 14 }) the ({ }) frames ({ 15 }) with ({ 16 }) a ({ }) sampling ({ 17 }) rate ({ 18 }) of ({ 19 }) two ({ 20 }) frames ({ 21 }) . ({ 22 }) 
# Sentence pair (776) source length 42 target length 41 alignment score : 1.02895e-09
Specifically, we select frames \MATH, \MATH, ..., \MATH, \MATH, ..., \MATH, \MATH, where \MATH is the middle frame of the fragment, and \MATH is half of number of frames computed from the quota\MATH and frame rate ( 25fps ) \MATH : 
NULL ({ 26 }) Specifically, ({ 1 }) we ({ 2 }) select ({ 3 }) frames ({ 4 }) \MATH, ({ 5 }) \MATH, ({ 6 }) ..., ({ 7 }) \MATH, ({ 8 }) \MATH, ({ 9 }) ..., ({ 10 }) \MATH, ({ 11 }) \MATH, ({ 12 }) where ({ 13 }) \MATH ({ 14 }) is ({ 15 }) the ({ 16 }) middle ({ 17 }) frame ({ 18 }) of ({ 19 }) the ({ 20 }) fragment, ({ 21 }) and ({ 22 }) \MATH ({ 23 }) is ({ 24 }) half ({ 25 }) the ({ }) number ({ 27 }) of ({ 28 }) frames ({ 29 }) computed ({ 30 }) from ({ 31 }) the ({ 32 }) quota\MATH ({ 33 }) and ({ 34 }) the ({ }) frame ({ 35 }) rate ({ 36 }) ( ({ 37 }) 25fps ({ 38 }) ) ({ 39 }) \MATH ({ 40 }) : ({ 41 }) 
# Sentence pair (777) source length 15 target length 14 alignment score : 2.34102e-07
We have tested our approaches with 40 videos of TRECVID 2008 test set . 
NULL ({ }) We ({ 1 }) have ({ 2 }) tested ({ 3 }) our ({ 4 }) approaches ({ 5 }) on ({ 6 }) 40 ({ 7 }) videos ({ 8 }) from ({ 9 }) the ({ }) TRECVID ({ 10 }) 2008 ({ 11 }) test ({ 12 }) set ({ 13 }) . ({ 14 }) 
# Sentence pair (778) source length 19 target length 19 alignment score : 5.93623e-05
Table \REF shows a comparison between these approaches for the measures used in evaluation of this task \CITE . 
NULL ({ }) Table ({ 1 }) \REF ({ 2 }) presents ({ 3 }) a ({ 4 }) comparison ({ 5 }) between ({ 6 }) these ({ 7 }) approaches ({ 8 }) for ({ 9 }) the ({ 10 }) measures ({ 11 }) used ({ 12 }) in ({ 13 }) evaluation ({ 14 }) of ({ 15 }) this ({ 16 }) task ({ 17 }) \CITE ({ 18 }) . ({ 19 }) 
# Sentence pair (779) source length 34 target length 33 alignment score : 8.81801e-14
The system NII-2 achieves higher recall ( IN ) than the system NII-1 since NII-1 only uses one keyframe for each sub-shot and has shorter duration ( DU ) for summary videos . 
NULL ({ }) The ({ 1 }) NII-2system ({ 2 3 }) achieves ({ 4 }) a ({ }) higher ({ 5 }) recall ({ 6 }) ( ({ 7 }) IN ({ 8 }) ) ({ 9 }) than ({ 10 }) the ({ 11 }) NII-1 ({ 13 }) system ({ 12 }) because ({ 14 }) NII-1 ({ 15 }) only ({ 16 }) uses ({ 17 }) one ({ 18 }) keyframe ({ 19 }) for ({ 20 }) each ({ 21 }) sub-shot ({ 22 }) and ({ 23 }) has ({ 24 }) a ({ }) shorter ({ 25 }) duration ({ 26 }) ( ({ 27 }) DU ({ 28 }) ) ({ 29 }) for ({ 30 }) summary ({ 31 }) videos ({ 32 }) . ({ 33 }) 
# Sentence pair (780) source length 6 target length 9 alignment score : 1.88765e-12
However, NII-1 has a better score in quality . 
NULL ({ 4 7 }) However, ({ 1 6 }) NII-1 ({ 2 }) has ({ 3 }) better ({ 5 }) quality ({ 8 }) . ({ 9 }) 
# Sentence pair (781) source length 32 target length 32 alignment score : 1.16952e-07
The summary videos generated by NII-1 have fewer duplications ( RE ), are presented in a smoother way ( TE ) and are easy to judge for inclusions ( TT ) . 
NULL ({ }) The ({ 1 }) summary ({ 2 }) videos ({ 3 }) generated ({ 4 }) by ({ 5 }) NII-1 ({ 6 }) have ({ 7 }) less ({ 8 }) duplication ({ 9 }) ( ({ 10 }) RE ({ 11 }) ), ({ 12 }) are ({ 13 }) presented ({ 14 }) in ({ 15 }) a ({ 16 }) smoother ({ 17 }) way ({ 18 }) ( ({ 19 }) TE ({ 20 }) ), ({ 21 }) and ({ 22 }) are ({ 23 }) easy ({ 24 }) to ({ 25 }) judge ({ 26 }) for ({ 27 }) inclusions ({ 28 }) ( ({ 29 }) TT ({ 30 }) ) ({ 31 }) . ({ 32 }) 
# Sentence pair (782) source length 9 target length 9 alignment score : 0.0482799
In terms of efficiency, NII-2 is much better . 
NULL ({ }) In ({ 1 }) terms ({ 2 }) of ({ 3 }) efficiency, ({ 4 }) NII-2 ({ 5 }) is ({ 6 }) much ({ 7 }) better ({ 8 }) . ({ 9 }) 
# Sentence pair (783) source length 38 target length 34 alignment score : 1.10069e-11
The clapper board detection process using NDK consumes around half of processing time of NII-1 but performance is low due to large variations of clapper boards in videos ( see Figure \REF ) . 
NULL ({ }) The ({ 1 }) clapper ({ 2 }) board ({ 3 }) detection ({ 4 }) process ({ 5 }) using ({ 6 }) NDK ({ 7 }) consumes ({ 8 }) around ({ 9 }) half ({ 10 }) of ({ 11 }) the ({ }) processing ({ 12 }) time ({ 13 }) of ({ 14 }) NII-1, ({ 15 }) but ({ 16 }) its ({ }) performance ({ 17 }) is ({ 18 }) low ({ 19 }) due ({ 20 }) to ({ 21 }) the ({ }) large ({ 22 }) variations ({ 23 }) in ({ 24 }) clapper ({ 25 }) boards ({ 26 }) in ({ 27 }) the ({ }) videos ({ 28 }) ( ({ 29 }) see ({ 30 }) Figure ({ 31 }) \REF ({ 32 }) ) ({ 33 }) . ({ 34 }) 
# Sentence pair (784) source length 18 target length 17 alignment score : 0.000194839
The comparable performance in junk elimination of both systems suggests that simple methods are more favorable . 
NULL ({ }) The ({ 1 }) comparable ({ 2 }) performance ({ 3 }) in ({ 4 }) the ({ }) junk ({ 5 }) elimination ({ 6 }) of ({ 7 }) both ({ 8 }) systems ({ 9 }) suggests ({ 10 }) that ({ 11 }) simpler ({ 12 }) methods ({ 13 }) are ({ 14 }) more ({ 15 }) favorable ({ 16 }) . ({ 17 }) 
# Sentence pair (785) source length 42 target length 41 alignment score : 5.146e-18
In addition, by using simple features and sampling frames in the original video, NII-2 significantly speeds up the processing time ( computed from the time taking the input video to the time picking the summary video ) to quasi real-time . 
NULL ({ }) In ({ 1 }) addition, ({ 2 }) by ({ 3 }) using ({ 4 }) simple ({ 5 }) features ({ 6 }) and ({ 7 }) sampling ({ 8 }) frames ({ 9 }) in ({ 10 }) the ({ 11 }) original ({ 12 }) video, ({ 13 }) NII-2 ({ 14 }) significantly ({ 15 }) increases ({ 16 17 }) the ({ 18 }) processing ({ 19 }) time ({ 20 }) ( ({ 21 }) computed ({ 22 }) from ({ 23 }) the ({ 24 }) time ({ 25 }) the ({ 27 }) input ({ 28 }) video ({ 29 }) is ({ }) taken ({ 26 }) to ({ 30 }) the ({ 31 }) time ({ 32 }) the ({ 34 }) summary ({ 35 }) video ({ 36 }) is ({ }) picked ({ 33 }) ) ({ 37 }) to ({ 38 }) quasi ({ 39 }) real-time ({ 40 }) . ({ 41 }) 
# Sentence pair (786) source length 16 target length 14 alignment score : 0.000160566
Practical summarization systems usually have good balance between fraction of inclusions and user-friendliness . 
NULL ({ }) Practical ({ 1 }) summarization ({ 2 }) systems ({ 3 }) usually ({ 4 }) have ({ 5 }) a ({ }) good ({ 6 }) balance ({ 7 }) between ({ 8 }) the ({ }) fraction ({ 9 }) of ({ 10 }) inclusions ({ 11 }) and ({ 12 }) user-friendliness ({ 13 }) . ({ 14 }) 
# Sentence pair (787) source length 11 target length 10 alignment score : 0.000149802
In Table \REF, we show performance of such systems . 
NULL ({ }) In ({ 1 }) Table ({ 2 }) \REF, ({ 3 }) we ({ 4 }) present ({ 5 }) the ({ }) performance ({ 6 }) of ({ 7 }) such ({ 8 }) systems ({ 9 }) . ({ 10 }) 
# Sentence pair (788) source length 39 target length 35 alignment score : 2.2245e-17
The 14 systems listed in this table have IN score larger than the median ( 0.45 ); and other scores such as RE and TE larger than half of maximum score ( 2.5 ) . 
NULL ({ }) The ({ 1 }) 14 ({ 2 }) systems ({ 3 }) listed ({ 4 }) in ({ 5 }) this ({ 6 }) table ({ 7 }) have ({ 8 }) an ({ }) IN ({ 9 }) score ({ 10 }) that ({ }) is ({ }) above ({ 12 }) the ({ 13 }) median ({ 14 }) ( ({ 15 }) 0.45 ({ 16 }) ); ({ 17 }) and ({ 18 }) other ({ 19 }) scores, ({ 20 }) such ({ 21 }) as ({ 22 }) RE ({ 23 }) and ({ 24 }) TE, ({ 25 }) are ({ }) larger ({ 11 26 }) than ({ 27 }) half ({ 28 }) of ({ 29 }) the ({ }) maximum ({ 30 }) score ({ 31 }) ( ({ 32 }) 2.5 ({ 33 }) ) ({ 34 }) . ({ 35 }) 
# Sentence pair (789) source length 17 target length 18 alignment score : 9.83046e-09
Compared to other systems listed in this list, our system NII-2 is one of the fastest systems . 
NULL ({ }) Compared ({ 1 }) to ({ 2 }) the ({ }) other ({ 3 }) systems ({ 4 }) listed ({ 5 }) in ({ 6 }) this ({ 7 }) table, ({ 8 }) our ({ 9 }) NII-2system ({ 10 11 }) is ({ 12 }) one ({ 13 }) of ({ 14 }) the ({ 15 }) fastest ({ 16 17 }) . ({ 18 }) 
# Sentence pair (790) source length 43 target length 44 alignment score : 1.99982e-20
Compared to the other systems participating in this task of TRECVID 2008, NII-1 has good performance in measures such as DU and TT ( see Figure \REF and Figure \REF; while NII-2 achieves good performance in measure IN ( see Figure \REF ) . 
NULL ({ 15 }) Compared ({ 1 }) to ({ 2 }) the ({ 3 }) other ({ 4 }) systems ({ 5 }) participating ({ 6 }) in ({ 7 }) this ({ 8 }) task ({ 9 }) of ({ 10 }) TRECVID ({ 11 }) 2008, ({ 12 }) NII-1 ({ 13 }) performed ({ 14 }) better ({ 16 }) in ({ 17 }) such ({ 19 }) measures ({ 18 }) as ({ 20 }) DU ({ 21 }) and ({ 22 }) TT ({ 23 }) ( ({ 24 }) see ({ 25 }) Figure ({ 26 }) \REF ({ 27 }) and ({ 28 }) Figure ({ 29 }) \REF; ({ 30 }) while ({ 31 }) NII-2 ({ 32 }) performs ({ 33 34 }) well ({ 35 }) in ({ 36 }) the ({ }) IN ({ 38 }) measure ({ 37 }) ( ({ 39 }) see ({ 40 }) Figure ({ 41 }) \REF ({ 42 }) ) ({ 43 }) . ({ 44 }) 
# Sentence pair (791) source length 10 target length 9 alignment score : 0.00728981
One of most difficult steps is redundancy elimination . 
NULL ({ }) One ({ 1 }) of ({ 2 }) the ({ }) most ({ 3 }) difficult ({ 4 }) steps ({ 5 }) is ({ 6 }) redundancy ({ 7 }) elimination ({ 8 }) . ({ 9 }) 
# Sentence pair (792) source length 18 target length 16 alignment score : 1.63947e-05
Lack of discriminative representation of segments and robust clustering methods is the main reason \CITE . 
NULL ({ }) The ({ }) lack ({ 1 }) of ({ 2 }) discriminative ({ 3 }) representation ({ 4 }) of ({ 5 }) the ({ }) segments ({ 6 }) and ({ 7 }) robust ({ 8 }) clustering ({ 9 }) methods ({ 10 }) is ({ 11 }) the ({ 12 }) main ({ 13 }) reason ({ 14 }) \CITE ({ 15 }) . ({ 16 }) 
# Sentence pair (793) source length 14 target length 14 alignment score : 0.000226676
Two typical cases that usually happen in clustering result are fragmentation and outliers . 
NULL ({ }) Two ({ 1 }) typical ({ 2 }) cases ({ 3 }) that ({ 4 }) usually ({ 5 }) happen ({ 6 }) in ({ 7 }) clustering ({ 8 }) results ({ 9 }) are ({ 10 }) fragmentation ({ 11 }) and ({ 12 }) outliers ({ 13 }) . ({ 14 }) 
# Sentence pair (794) source length 14 target length 16 alignment score : 1.14603e-08
Fragmentation is the case that samples of one cluster are put into several different clusters . 
NULL ({ 3 5 }) Fragmentation ({ 1 }) is ({ 2 }) where ({ 4 }) samples ({ 6 }) of ({ 7 }) one ({ 8 }) cluster ({ 9 }) are ({ 10 }) put ({ 11 }) into ({ 12 }) several ({ 13 }) different ({ 14 }) clusters ({ 15 }) . ({ 16 }) 
# Sentence pair (795) source length 19 target length 17 alignment score : 0.000101653
Outliers are irrelevant and noisy samples in one cluster due to poor determination of cluster boundary . 
NULL ({ }) Outliers ({ 1 }) are ({ 2 }) irrelevant ({ 3 }) and ({ 4 }) noisy ({ 5 }) samples ({ 6 }) in ({ 7 }) one ({ 8 }) cluster ({ 9 }) due ({ 10 }) to ({ 11 }) the ({ }) poor ({ 12 }) determination ({ 13 }) of ({ 14 }) the ({ }) cluster ({ 15 }) boundary ({ 16 }) . ({ 17 }) 
# Sentence pair (796) source length 13 target length 14 alignment score : 1.96515e-06
Therefore, it is necessary to develop robust methods for detection of repetitive segments . 
NULL ({ 11 }) Therefore, ({ 1 }) it ({ 2 }) is ({ 3 }) necessary ({ 4 }) to ({ 5 }) develop ({ 6 }) robust ({ 7 }) methods ({ 8 }) for ({ 9 }) detecting ({ 10 }) repetitive ({ 12 }) segments ({ 13 }) . ({ 14 }) 
# Sentence pair (797) source length 28 target length 24 alignment score : 1.23248e-09
Using all frames of one segment instead of using one keyframe as proposed in NII-2 is one of the efforts toward this direction . 
NULL ({ }) Using ({ 1 }) all ({ 2 }) the ({ }) frames ({ 3 }) of ({ 4 }) one ({ 5 }) segment ({ 6 }) instead ({ 7 }) of ({ 8 }) using ({ 9 }) one ({ 10 }) keyframe ({ 11 }) as ({ 12 }) proposed ({ 13 }) in ({ 14 }) NII-2 ({ 15 }) is ({ 16 }) one ({ 17 }) of ({ 18 }) the ({ 19 }) current ({ }) efforts ({ 20 }) being ({ }) made ({ }) towards ({ 21 }) this ({ 22 }) end ({ 23 }) . ({ 24 }) 
# Sentence pair (798) source length 18 target length 18 alignment score : 3.29304e-09
Although the result is not very high as expected, we still believe that this approach is promising . 
NULL ({ }) Although ({ 1 }) the ({ 2 }) results ({ 3 }) are ({ 4 }) not ({ 5 }) as ({ 6 }) high ({ 7 }) as ({ 8 }) expected, ({ 9 }) we ({ 10 }) still ({ 11 }) believe ({ 12 }) that ({ 13 }) this ({ 14 }) approach ({ 15 }) is ({ 16 }) promising ({ 17 }) . ({ 18 }) 
# Sentence pair (799) source length 15 target length 14 alignment score : 8.76454e-05
We have presented two different approaches for generating short summary for rushes video . 
NULL ({ }) We ({ 1 }) have ({ 2 }) presented ({ 3 }) two ({ 4 }) different ({ 5 }) approaches ({ 6 }) for ({ 7 }) generating ({ 8 }) a ({ }) short ({ 9 }) summary ({ 10 }) for ({ 11 }) rushes ({ 12 }) videos ({ 13 }) . ({ 14 }) 
# Sentence pair (800) source length 19 target length 21 alignment score : 1.86985e-26
In the first approach, NII-1, redundancy elimination is done by doing clustering on the set of keyframes extracted from sub-shots . 
NULL ({ 8 }) In ({ 1 }) the ({ 2 }) first ({ 3 }) approach, ({ 4 7 10 }) NII-1, ({ 5 9 11 }) clustering ({ 12 }) the ({ 14 }) set ({ 15 }) of ({ 16 }) keyframes ({ 17 }) extracted ({ 18 }) from ({ 19 }) the ({ }) sub-shots ({ 20 }) helps ({ 13 }) to ({ }) eliminate ({ }) redundancy ({ 6 }) . ({ 21 }) 
# Sentence pair (801) source length 22 target length 22 alignment score : 5.15902e-12
With each representative segment of each cluster, the portion that has high degree of motion is selected to form the summary . 
NULL ({ 10 11 }) With ({ 1 }) each ({ 2 }) representative ({ 3 }) segment ({ 4 }) of ({ 5 }) each ({ 6 }) cluster, ({ 7 }) the ({ 8 }) portion ({ 9 }) with ({ }) the ({ }) highest ({ 12 }) degree ({ 13 }) of ({ 14 }) motion ({ 15 }) is ({ 16 }) selected ({ 17 }) to ({ 18 }) form ({ 19 }) the ({ 20 }) summary ({ 21 }) . ({ 22 }) 
# Sentence pair (802) source length 15 target length 14 alignment score : 3.62164e-17
This approach achieves good performance in usability score but low performance in recall . 
NULL ({ 6 }) This ({ 1 }) approach ({ 2 }) has ({ 3 }) a ({ }) good ({ 4 5 }) usability ({ 7 }) score ({ 8 }) but ({ 9 }) is ({ }) not ({ }) very ({ 10 }) good ({ 11 }) at ({ 12 }) recall ({ 13 }) . ({ 14 }) 
# Sentence pair (803) source length 25 target length 22 alignment score : 1.19688e-06
In the second approach, NII-2, all frames of each sub-shot are used to compute the similarity among sub-shots in clustering process . 
NULL ({ }) In ({ 1 }) the ({ 2 }) second ({ 3 }) approach, ({ 4 }) NII-2, ({ 5 }) all ({ 6 }) the ({ }) frames ({ 7 }) of ({ 8 }) each ({ 9 }) sub-shot ({ 10 }) are ({ 11 }) used ({ 12 }) to ({ 13 }) compute ({ 14 }) the ({ 15 }) similarity ({ 16 }) among ({ 17 }) the ({ }) sub-shots ({ 18 }) in ({ 19 }) the ({ }) clustering ({ 20 }) process ({ 21 }) . ({ 22 }) 
# Sentence pair (804) source length 24 target length 23 alignment score : 5.53926e-07
With each representative segment of each cluster, the middle part is selected to form the summary with skipping rate of 2 frames . 
NULL ({ }) With ({ 1 }) each ({ 2 }) representative ({ 3 }) segment ({ 4 }) of ({ 5 }) each ({ 6 }) cluster, ({ 7 }) the ({ 8 }) middle ({ 9 }) part ({ 10 }) is ({ 11 }) selected ({ 12 }) to ({ 13 }) form ({ 14 }) the ({ 15 }) summary ({ 16 }) with ({ 17 }) a ({ }) skipping ({ 18 }) rate ({ 19 }) of ({ 20 }) two ({ 21 }) frames ({ 22 }) . ({ 23 }) 
# Sentence pair (805) source length 14 target length 14 alignment score : 2.25646e-17
This approach achieves good performance in recall and reasonable performance in usability score . 
NULL ({ 6 11 }) This ({ 1 }) approach ({ 2 }) is ({ 3 }) good ({ 4 }) for ({ 5 }) recall ({ 7 }) and ({ 8 }) has ({ }) a ({ }) reasonably ({ 9 }) good ({ 10 }) usability ({ 12 }) score ({ 13 }) . ({ 14 }) 
# Sentence pair (806) source length 26 target length 24 alignment score : 8.68339e-13
Compared to other systems participating in TRECVID 2008 summarization task, NII-2 is among best systems that have good balance between recall and usability . 
NULL ({ 16 17 }) Compared ({ 1 }) to ({ 2 }) other ({ 3 }) systems ({ 4 }) participating ({ 5 }) in ({ 6 }) the ({ }) TRECVID ({ 7 }) 2008 ({ 8 }) summarization ({ 9 }) task, ({ 10 }) NII-2 ({ 11 }) is ({ 12 }) among ({ 13 }) the ({ }) best ({ 14 }) systems ({ 15 }) with ({ }) a ({ }) good ({ 18 }) balance ({ 19 }) between ({ 20 }) recall ({ 21 }) and ({ 22 }) usability ({ 23 }) . ({ 24 }) 
# Sentence pair (807) source length 9 target length 7 alignment score : 0.00153104
Face Retrieval Improvement by Learning Visual Consistency 
NULL ({ }) Face ({ 1 }) Retrieval ({ 2 }) Improvement ({ 3 }) by ({ 4 }) the ({ }) Learning ({ 5 }) of ({ }) Visual ({ 6 }) Consistency ({ 7 }) 
# Sentence pair (808) source length 21 target length 18 alignment score : 1.15993e-07
Searching persons is one of the essential tasks required by users for image and video search engines . 
NULL ({ }) Searching ({ 1 }) for ({ }) images ({ }) of ({ }) people ({ 2 }) is ({ 3 }) one ({ 4 }) of ({ 5 }) the ({ 6 }) essential ({ 7 }) tasks ({ 8 }) required ({ 9 }) by ({ 10 }) users ({ 11 }) for ({ 12 }) image ({ 13 }) and ({ 14 }) video ({ 15 }) search ({ 16 }) engines ({ 17 }) . ({ 18 }) 
# Sentence pair (809) source length 33 target length 32 alignment score : 6.70035e-07
However , the current search engines have limited capabilities for this task since they usually rely on texts associated with image and video which are likely to return many irrelevant results . 
NULL ({ }) However ({ 1 }) , ({ 2 }) the ({ 3 }) current ({ 4 }) search ({ 5 }) engines ({ 6 }) have ({ 7 }) limited ({ 8 }) capabilities ({ 9 }) for ({ 10 }) this ({ 11 }) task ({ 12 }) since ({ 13 }) they ({ 14 }) usually ({ 15 }) rely ({ 16 }) on ({ 17 }) texts ({ 18 }) associated ({ 19 }) with ({ 20 }) image ({ 21 }) and ({ 22 }) video ({ 23 }) , ({ }) which ({ 24 }) are ({ 25 }) likely ({ 26 }) to ({ 27 }) return ({ 28 }) many ({ 29 }) irrelevant ({ 30 }) results ({ 31 }) . ({ 32 }) 
# Sentence pair (810) source length 26 target length 30 alignment score : 1.64654e-18
In this paper , we propose a method to effectively retrieve relevant faces for one person by learning visual consistency from results retrieved from text correlation based search engines . 
NULL ({ 2 4 5 }) We ({ 1 }) propose ({ 6 }) a ({ 7 }) method ({ 8 }) to ({ 9 }) effectively ({ 10 }) retrieve ({ 3 11 }) relevant ({ 12 }) faces ({ 13 }) for ({ 14 }) one ({ 15 }) person ({ 16 }) by ({ 17 }) learning ({ 18 }) visual ({ 19 }) consistency ({ 20 }) from ({ 21 }) results ({ 22 }) retrieved ({ 23 }) from ({ 24 }) text ({ 25 }) correlation ({ 26 }) based ({ 27 }) search ({ 28 }) engines ({ 29 }) . ({ 30 }) 
# Sentence pair (811) source length 22 target length 23 alignment score : 1.02861e-15
This problem is challenging because ( i ) no any label is provided leading to be difficult to use supervised-based ranking methods . 
NULL ({ 12 15 }) This ({ 1 }) problem ({ 2 }) is ({ 3 }) challenging ({ 4 }) because ({ 5 }) ( ({ 6 }) i ({ 7 }) ) ({ 8 }) there ({ 9 }) is ({ }) no ({ 10 }) label ({ 11 }) provided ({ 13 }) making ({ 14 }) it ({ 16 }) difficult ({ 17 }) to ({ 18 }) use ({ 19 }) supervised-based ({ 20 }) ranking ({ 21 }) methods ({ 22 }) . ({ 23 }) 
# Sentence pair (812) source length 19 target length 19 alignment score : 0.000528501
( ii ) current face recognition techniques are still unmatured with wild-face databases even with supervised learning methods . 
NULL ({ }) ( ({ 1 }) ii ({ 2 }) ) ({ 3 }) current ({ 4 }) face ({ 5 }) recognition ({ 6 }) techniques ({ 7 }) are ({ 8 }) still ({ 9 }) immature ({ 10 }) with ({ 11 }) wild-face ({ 12 }) databases ({ 13 }) even ({ 14 }) with ({ 15 }) supervised ({ 16 }) learning ({ 17 }) methods ({ 18 }) . ({ 19 }) 
# Sentence pair (813) source length 47 target length 47 alignment score : 1.64463e-15
In the proposed method , we treat the problem as a classification problem which input faces are classified as 'personX' ( the queried person ) or 'non-personX' and the faces are ranked based on their relevant score that is inferred from the classifier 's probability output . 
NULL ({ 38 39 }) In ({ 1 }) the ({ 2 }) proposed ({ 3 }) method ({ 4 }) , ({ 5 }) we ({ 6 }) treat ({ 7 }) this ({ 8 }) problem ({ 9 }) as ({ 10 }) a ({ 11 }) classification ({ 12 }) problem ({ 13 }) in ({ }) which ({ 14 }) input ({ 15 }) faces ({ 16 }) are ({ 17 }) classified ({ 18 }) as ({ 19 }) 'person-X' ({ 20 }) ( ({ 21 }) the ({ 22 }) queried ({ 23 }) person ({ 24 }) ) ({ 25 }) or ({ 26 }) 'non-person-X' ({ 27 }) , ({ }) and ({ 28 }) the ({ 29 }) faces ({ 30 }) are ({ 31 }) ranked ({ 32 }) based ({ 33 }) on ({ 34 }) their ({ 35 }) relevant ({ 36 }) score ({ 37 }) inferred ({ 40 }) from ({ 41 }) the ({ 42 }) classifier ({ 43 }) 's ({ 44 }) probability ({ 45 }) output ({ 46 }) . ({ 47 }) 
# Sentence pair (814) source length 25 target length 26 alignment score : 8.46674e-13
In order to train this classifier , we use a bagging-based framework to combine results from multiple weak classifiers which are trained using different subsets . 
NULL ({ 2 3 }) To ({ 1 }) train ({ 4 }) this ({ 5 }) classifier ({ 6 }) , ({ 7 }) we ({ 8 }) use ({ 9 }) a ({ 10 }) bagging-based ({ 11 }) framework ({ 12 }) to ({ 13 }) combine ({ 14 }) results ({ 15 }) from ({ 16 }) multiple ({ 17 }) weak ({ 18 }) classifiers ({ 19 }) , ({ }) which ({ 20 }) are ({ 21 }) trained ({ 22 }) using ({ 23 }) different ({ 24 }) subsets ({ 25 }) . ({ 26 }) 
# Sentence pair (815) source length 22 target length 22 alignment score : 0.000320341
These training subsets are extracted and labeled automatically from the rank list produced from the classifier trained from the previous step . 
NULL ({ }) These ({ 1 }) training ({ 2 }) subsets ({ 3 }) are ({ 4 }) extracted ({ 5 }) and ({ 6 }) labeled ({ 7 }) automatically ({ 8 }) from ({ 9 }) the ({ 10 }) rank ({ 11 }) list ({ 12 }) produced ({ 13 }) from ({ 14 }) the ({ 15 }) classifier ({ 16 }) trained ({ 17 }) from ({ 18 }) the ({ 19 }) previous ({ 20 }) step ({ 21 }) . ({ 22 }) 
# Sentence pair (816) source length 16 target length 16 alignment score : 0.00273141
In addition , outliers detection methods are used to produce the rank list for initialization . 
NULL ({ }) In ({ 1 }) addition ({ 2 }) , ({ 3 }) outlier ({ 4 }) detection ({ 5 }) methods ({ 6 }) are ({ 7 }) used ({ 8 }) to ({ 9 }) produce ({ 10 }) the ({ 11 }) rank ({ 12 }) list ({ 13 }) for ({ 14 }) initialization ({ 15 }) . ({ 16 }) 
# Sentence pair (817) source length 31 target length 32 alignment score : 2.20896e-12
Experimental results on various face sets retrieved from the caption of news photos show that the retrieval performance is improved after each iteration leading the final performance outperforms the baseline algorithms . 
NULL ({ 19 }) Experimental ({ 1 }) results ({ 2 }) on ({ 3 }) various ({ 4 }) face ({ 5 }) sets ({ 6 }) retrieved ({ 7 }) from ({ 8 }) the ({ 9 }) captions ({ 10 }) of ({ 11 }) news ({ 12 }) photos ({ 13 }) show ({ 14 }) that ({ 15 }) the ({ 16 }) retrieval ({ 17 }) performance ({ 18 }) improved ({ 20 }) after ({ 21 }) each ({ 22 }) iteration ({ 23 }) with ({ 24 }) the ({ 25 }) final ({ 26 }) performance ({ 27 }) outperforming ({ 28 }) the ({ 29 }) baseline ({ 30 }) algorithms ({ 31 }) . ({ 32 }) 
# Sentence pair (818) source length 21 target length 21 alignment score : 3.40096e-09
With the rapid growing of digital technology , large image and video databases are available easier than ever to users . 
NULL ({ }) With ({ 1 }) the ({ 2 }) rapid ({ 3 }) growth ({ 4 }) of ({ 5 }) digital ({ 6 }) technology ({ 7 }) , ({ 8 }) large ({ 9 }) image ({ 10 }) and ({ 11 }) video ({ 12 }) databases ({ 13 }) are ({ 14 }) more ({ }) available ({ 15 16 }) than ({ 17 }) ever ({ 18 }) to ({ 19 }) users ({ 20 }) . ({ 21 }) 
# Sentence pair (819) source length 17 target length 18 alignment score : 1.92391e-06
Therefore , effective and efficient tools are strongly needed for indexing and retrieving based on visual contents . 
NULL ({ }) Therefore ({ 1 }) , ({ 2 }) effective ({ 3 }) and ({ 4 }) efficient ({ 5 }) tools ({ 6 }) are ({ 7 }) needed ({ 8 9 }) for ({ 10 }) indexing ({ 11 }) and ({ 12 }) retrieving ({ 13 }) based ({ 14 }) on ({ 15 }) visual ({ 16 }) contents ({ 17 }) . ({ 18 }) 
# Sentence pair (820) source length 19 target length 21 alignment score : 2.33278e-16
One of the typical examples for this application is to search a specific person by providing his or her name . 
NULL ({ 2 3 10 }) A ({ 1 }) typical ({ 4 }) example ({ 5 }) for ({ 6 }) this ({ 7 }) application ({ 8 }) is ({ 9 }) searching ({ 11 }) for ({ }) a ({ 12 }) specific ({ 13 }) person ({ 14 }) by ({ 15 }) providing ({ 16 }) his ({ 17 }) or ({ 18 }) her ({ 19 }) name ({ 20 }) . ({ 21 }) 
# Sentence pair (821) source length 21 target length 23 alignment score : 1.89632e-15
Usually , most of current search engines use text associated with images or videos as a significant clue to return the results . 
NULL ({ 4 16 21 }) Usually ({ 1 }) , ({ 2 }) most ({ 3 }) current ({ 5 }) search ({ 6 }) engines ({ 7 }) use ({ 8 }) the ({ }) texts ({ 9 }) associated ({ 10 }) with ({ 11 }) images ({ 12 }) or ({ 13 }) videos ({ 14 }) as ({ 15 }) significant ({ 17 }) clues ({ 18 }) for ({ 19 }) returning ({ 20 }) results ({ 22 }) . ({ 23 }) 
# Sentence pair (822) source length 26 target length 43 alignment score : 1.15313e-50
However , since it is not necessary faces and names appear simultaneously and are aligned ( as shown in Figure \REF ) , the main drawback of this approach is existence of many irrelevant results that makes the retrieval performance very low . 
NULL ({ 5 24 27 28 30 32 38 }) However ({ 1 }) , ({ 2 }) other ({ 3 }) un-queried ({ 4 6 7 }) faces ({ 8 }) and ({ 9 }) names ({ 10 }) appear ({ 11 }) simultaneously ({ 12 }) and ({ 13 }) are ({ 14 }) aligned ({ 15 }) ( ({ 16 }) as ({ 17 }) shown ({ 18 }) in ({ 19 }) Figure ({ 20 }) \REF ({ 21 }) ) ({ 22 }) , ({ 23 }) which ({ 36 }) significantly ({ 41 }) lowers ({ 25 26 29 31 33 34 35 37 42 }) retrieval ({ 39 }) performance ({ 40 }) . ({ 43 }) 
# Sentence pair (823) source length 22 target length 20 alignment score : 1.36551e-05
Therefore it is necessary to improve the retrieval performance by taking into account visual information from the retrieved faces . 
NULL ({ }) Therefore ({ 1 }) , ({ }) it ({ 2 }) is ({ 3 }) necessary ({ 4 }) to ({ 5 }) improve ({ 6 }) the ({ 7 }) retrieval ({ 8 }) performance ({ 9 }) by ({ 10 }) taking ({ 11 }) into ({ 12 }) account ({ 13 }) the ({ }) visual ({ 14 }) information ({ 15 }) from ({ 16 }) the ({ 17 }) retrieved ({ 18 }) faces ({ 19 }) . ({ 20 }) 
# Sentence pair (824) source length 10 target length 10 alignment score : 0.0246315
This problem is challenging due to the following reasons : 
NULL ({ }) This ({ 1 }) problem ({ 2 }) is ({ 3 }) challenging ({ 4 }) due ({ 5 }) to ({ 6 }) the ({ 7 }) following ({ 8 }) reasons ({ 9 }) : ({ 10 }) 
# Sentence pair (825) source length 31 target length 30 alignment score : 7.63252e-07
-Large variations in face appearance due to pose changes , illumination conditions , occlusions and facial expressions make face recognition difficult even with state of the art techniques \CITE . 
NULL ({ }) -Large ({ 1 }) variations ({ 2 }) in ({ 3 }) face ({ 4 }) appearance ({ 5 }) due ({ 6 }) to ({ 7 }) pose ({ 8 }) changes ({ 9 }) , ({ 10 }) illumination ({ 11 }) conditions ({ 12 }) , ({ 13 }) occlusions ({ 14 }) , ({ }) and ({ 15 }) facial ({ 16 }) expressions ({ 17 }) make ({ 18 }) face ({ 19 }) recognition ({ 20 }) difficult ({ 21 }) even ({ 22 }) with ({ 23 }) state ({ 24 }) of ({ 25 }) the ({ 26 }) art ({ 27 }) techniques ({ 28 }) \CITE ({ 29 }) . ({ 30 }) 
# Sentence pair (826) source length 33 target length 34 alignment score : 2.1516e-19
-The fact the retrieved face set consists of faces of several persons while no any label is given makes supervised learning methods as well as unsupervised learning methods such as \MATH -means inapplicable . 
NULL ({ 17 }) -The ({ 1 }) fact ({ 2 }) the ({ 3 }) retrieved ({ 4 }) face ({ 5 }) set ({ 6 }) consists ({ 7 }) of ({ 8 }) faces ({ 9 }) of ({ 10 }) several ({ 11 }) people ({ 12 }) with ({ 13 }) no ({ 14 }) label ({ 15 16 }) makes ({ 18 19 }) supervised ({ 20 }) learning ({ 21 }) methods ({ 22 }) as ({ 23 }) well ({ 24 }) as ({ 25 }) unsupervised ({ 26 }) learning ({ 27 }) methods ({ 28 }) such ({ 29 }) as ({ 30 }) , ({ }) \MATH ({ 31 }) -means ({ 32 }) , ({ }) inapplicable ({ 33 }) . ({ 34 }) 
# Sentence pair (827) source length 10 target length 14 alignment score : 3.67781e-18
In this paper , we propose a method to solve the mentioned problem . 
NULL ({ 2 3 4 5 }) We ({ 1 }) propose ({ 6 }) a ({ 7 }) method ({ 8 }) to ({ 9 }) solve ({ 10 }) the ({ 11 }) above-mentioned ({ 12 }) problem ({ 13 }) . ({ 14 }) 
# Sentence pair (828) source length 21 target length 21 alignment score : 7.86195e-16
The main idea is to learn visual consistency assumed to exist among the results returned from current text-based search engines . 
NULL ({ 10 }) The ({ 1 }) main ({ 2 }) idea ({ 3 }) is ({ 4 }) to ({ 5 }) assume ({ 6 11 }) that ({ }) there ({ 9 }) is ({ }) visual ({ 7 }) consistency ({ 8 }) among ({ 12 }) the ({ 13 }) results ({ 14 }) returned ({ 15 }) from ({ 16 }) current ({ 17 }) text-based ({ 18 }) search ({ 19 }) engines ({ 20 }) . ({ 21 }) 
# Sentence pair (829) source length 7 target length 7 alignment score : 0.00273267
The method consists of two stages . 
NULL ({ }) This ({ 1 }) method ({ 2 }) consists ({ 3 }) of ({ 4 }) two ({ 5 }) stages ({ 6 }) . ({ 7 }) 
# Sentence pair (830) source length 19 target length 19 alignment score : 0.000842503
In the first stage , we explore local density of faces to identify potential candidates for relevant faces . 
NULL ({ }) In ({ 1 }) the ({ 2 }) first ({ 3 }) stage ({ 4 }) , ({ 5 }) we ({ 6 }) explore ({ 7 }) local ({ 8 }) density ({ 9 }) of ({ 10 }) faces ({ 11 }) to ({ 12 }) identify ({ 13 }) potential ({ 14 }) candidates ({ 15 }) for ({ 16 }) relevant ({ 17 }) faces ({ 18 }) . ({ 19 }) 
# Sentence pair (831) source length 33 target length 33 alignment score : 1.04821e-20
This stage is stemmed from the observation that faces relevant to the queried person tend to form dense clusters while irrelevant faces are very sparse since they look different from each other . 
NULL ({ 11 }) This ({ 1 }) stage ({ 2 }) is ({ 3 }) based ({ 4 }) on ({ 5 }) the ({ 6 }) observation ({ 7 }) that ({ 8 }) facial ({ 9 }) images ({ 10 }) of ({ }) the ({ 12 }) queried ({ 13 }) person ({ 14 }) tend ({ 15 }) to ({ 16 }) form ({ 17 }) dense ({ 18 }) clusters ({ 19 }) while ({ 20 }) irrelevant ({ 21 }) facial ({ 22 }) images ({ }) are ({ 23 }) sparse ({ 24 25 }) since ({ 26 }) they ({ 27 }) look ({ 28 }) different ({ 29 }) from ({ 30 }) each ({ 31 }) other ({ 32 }) . ({ 33 }) 
# Sentence pair (832) source length 10 target length 10 alignment score : 0.0241919
We use an outliers detection method for this purpose . 
NULL ({ }) We ({ 1 }) use ({ 2 }) an ({ 3 }) outlier ({ 4 }) detection ({ 5 }) method ({ 6 }) for ({ 7 }) this ({ 8 }) purpose ({ 9 }) . ({ 10 }) 
# Sentence pair (833) source length 48 target length 30 alignment score : 3.87926e-34
The output is a rank list in which faces having larger number of neighbors within a distance are predicted as relevant ones and therefore are put on the top . 
NULL ({ }) The ({ 1 }) output ({ 2 }) is ({ 3 }) a ({ 4 }) rank ({ 5 }) list ({ 6 }) in ({ 7 }) which ({ 8 }) faces ({ 9 }) with ({ 10 }) larger ({ 11 }) number ({ 12 }) of ({ 13 }) neighbors ({ 14 }) within ({ 15 }) a ({ 16 }) certain ({ }) distance ({ 17 }) are ({ 18 }) considered ({ 19 }) as ({ 20 }) relevant ({ 21 }) and ({ 23 }) are ({ 25 }) therefore ({ 24 }) put ({ 26 }) at ({ 27 }) the ({ 28 }) top ({ 29 }) of ({ }) the ({ }) list ({ }) . ({ 30 }) //[What ({ }) do ({ }) you ({ }) mean ({ }) by ({ }) gneighborsh ({ 22 }) ? ({ }) Do ({ }) you ({ }) mean ({ }) the ({ }) un-queried ({ }) faces ({ }) ? ({ }) ] ({ }) 
# Sentence pair (834) source length 21 target length 21 alignment score : 0.000291073
Since the above ranking method is based on the number of neighbors , it is sensitive to the chosen distance . 
NULL ({ }) Since ({ 1 }) the ({ 2 }) above ({ 3 }) ranking ({ 4 }) method ({ 5 }) is ({ 6 }) based ({ 7 }) on ({ 8 }) the ({ 9 }) number ({ 10 }) of ({ 11 }) neighbors ({ 12 }) , ({ 13 }) it ({ 14 }) is ({ 15 }) sensitive ({ 16 }) to ({ 17 }) the ({ 18 }) specified ({ 19 }) distance ({ 20 }) . ({ 21 }) 
# Sentence pair (835) source length 11 target length 14 alignment score : 1.58357e-17
It is necessary to use the second stage to improve the rank list . 
NULL ({ 4 6 }) A ({ 1 }) second ({ 7 }) stage ({ 8 }) is ({ 2 }) necessary ({ 3 5 }) to ({ 9 }) improve ({ 10 }) this ({ 11 }) rank ({ 12 }) list ({ 13 }) . ({ 14 }) 
# Sentence pair (836) source length 29 target length 28 alignment score : 7.18633e-06
We model this problem as a classification problem which input faces are classified as personX ( the queried person ) or non-personX ( the irrelevant person ) . 
NULL ({ }) We ({ 1 }) model ({ 2 }) this ({ 3 }) problem ({ 4 }) as ({ 5 }) a ({ 6 }) classification ({ 7 }) problem ({ 8 }) in ({ }) which ({ 9 }) input ({ 10 }) faces ({ 11 }) are ({ 12 }) classified ({ 13 }) as ({ 14 }) person-X ({ 15 }) ( ({ 16 }) the ({ 17 }) queried ({ 18 }) person ({ 19 }) ) ({ 20 }) or ({ 21 }) non-person-X ({ 22 }) ( ({ 23 }) the ({ 24 }) irrelevant ({ 25 }) person ({ 26 }) ) ({ 27 }) . ({ 28 }) 
# Sentence pair (837) source length 19 target length 19 alignment score : 0.000435049
The faces are ranked based on their relevant score that is inferred from the classifier 's probability output . 
NULL ({ }) The ({ 1 }) faces ({ 2 }) are ({ 3 }) ranked ({ 4 }) based ({ 5 }) on ({ 6 }) their ({ 7 }) relevancy ({ 8 }) score ({ 9 }) that ({ 10 }) is ({ 11 }) inferred ({ 12 }) from ({ 13 }) the ({ 14 }) classifier ({ 15 }) 's ({ 16 }) probability ({ 17 }) output ({ 18 }) . ({ 19 }) 
# Sentence pair (838) source length 25 target length 25 alignment score : 0.000105075
Since annotation data is not available , the rank list from the previous step is used to assign labels for a subset of faces . 
NULL ({ }) Since ({ 1 }) annotation ({ 2 }) data ({ 3 }) is ({ 4 }) not ({ 5 }) available ({ 6 }) , ({ 7 }) the ({ 8 }) rank ({ 9 }) list ({ 10 }) from ({ 11 }) the ({ 12 }) previous ({ 13 }) step ({ 14 }) is ({ 15 }) used ({ 16 }) to ({ 17 }) assign ({ 18 }) labels ({ 19 }) for ({ 20 }) a ({ 21 }) subset ({ 22 }) of ({ 23 }) faces ({ 24 }) . ({ 25 }) 
# Sentence pair (839) source length 21 target length 22 alignment score : 7.59757e-09
This subset then is used to train a classifier using a supervised method such as support vector machines ( SVM ) . 
NULL ({ 11 }) This ({ 1 }) subset ({ 2 }) then ({ 3 }) is ({ 4 }) used ({ 5 }) to ({ 6 }) train ({ 7 }) a ({ 8 }) classifier ({ 9 }) using ({ 10 }) supervised ({ 12 }) methods ({ 13 }) such ({ 14 }) as ({ 15 }) support ({ 16 }) vector ({ 17 }) machines ({ 18 }) ( ({ 19 }) SVM ({ 20 }) ) ({ 21 }) . ({ 22 }) 
# Sentence pair (840) source length 14 target length 15 alignment score : 3.42256e-08
The trained classifier is used to re-rank faces in the original input set again . 
NULL ({ 14 }) The ({ 1 }) trained ({ 2 }) classifier ({ 3 }) is ({ 4 }) used ({ 5 }) to ({ 6 }) re-rank ({ 7 }) faces ({ 8 }) in ({ 9 }) the ({ 10 }) original ({ 11 }) input ({ 12 }) set ({ 13 }) . ({ 15 }) 
# Sentence pair (841) source length 15 target length 15 alignment score : 0.00370706
This step is repeated a number of times to get the final rank list . 
NULL ({ }) This ({ 1 }) step ({ 2 }) is ({ 3 }) repeated ({ 4 }) a ({ 5 }) number ({ 6 }) of ({ 7 }) times ({ 8 }) to ({ 9 }) get ({ 10 }) the ({ 11 }) final ({ 12 }) rank ({ 13 }) list ({ 14 }) . ({ 15 }) 
# Sentence pair (842) source length 18 target length 18 alignment score : 0.00134842
Since automatically assigning labels from the rank list is not reliable , the trained classifiers are weak . 
NULL ({ }) Since ({ 1 }) automatically ({ 2 }) assigning ({ 3 }) labels ({ 4 }) from ({ 5 }) the ({ 6 }) rank ({ 7 }) list ({ 8 }) is ({ 9 }) not ({ 10 }) reliable ({ 11 }) , ({ 12 }) the ({ 13 }) trained ({ 14 }) classifiers ({ 15 }) are ({ 16 }) weak ({ 17 }) . ({ 18 }) 
# Sentence pair (843) source length 38 target length 37 alignment score : 2.50716e-08
In order to get the final strong classifier , we employ the idea of ensemble learning \CITE in which weak classifiers trained on different subsets are combined to improve stability and classification accuracy of single classifiers . 
NULL ({ }) In ({ 1 }) order ({ 2 }) to ({ 3 }) get ({ 4 }) the ({ 5 }) final ({ 6 }) strong ({ 7 }) classifier ({ 8 }) , ({ 9 }) we ({ 10 }) use ({ 11 }) the ({ 12 }) idea ({ 13 }) of ({ 14 }) ensemble ({ 15 }) learning ({ 16 }) \CITE ({ 17 }) in ({ 18 }) which ({ 19 }) weak ({ 20 }) classifiers ({ 21 }) trained ({ 22 }) on ({ 23 }) different ({ 24 }) subsets ({ 25 }) are ({ 26 }) combined ({ 27 }) to ({ 28 }) improve ({ 29 }) the ({ }) stability ({ 30 }) and ({ 31 }) classification ({ 32 }) accuracy ({ 33 }) of ({ 34 }) single ({ 35 }) classifiers ({ 36 }) . ({ 37 }) 
# Sentence pair (844) source length 14 target length 15 alignment score : 8.92495e-10
This stage is effective for improving the rank list due to the following reasons : 
NULL ({ 11 }) This ({ 1 }) stage ({ 2 }) is ({ 3 }) effective ({ 4 }) for ({ 5 }) improving ({ 6 }) the ({ 7 }) rank ({ 8 }) list ({ 9 }) for ({ 10 }) the ({ 12 }) following ({ 13 }) reasons ({ 14 }) : ({ 15 }) 
# Sentence pair (845) source length 25 target length 22 alignment score : 7.3665e-10
-Supervised learning methods such as SVM have strong theoretical background in finding optimal decision boundary even with existence of noisy data . 
NULL ({ 7 }) -Supervised ({ 1 }) learning ({ 2 }) methods ({ 3 }) such ({ 4 }) , ({ }) as ({ 5 }) SVMs ({ 6 }) , ({ }) provide ({ }) a ({ }) strong ({ 8 }) theoretical ({ 9 }) background ({ 10 }) in ({ 11 }) finding ({ 12 }) optimal ({ 13 }) decision ({ 14 }) boundary ({ 15 }) even ({ 16 }) with ({ 17 }) existence ({ 18 }) of ({ 19 }) noisy ({ 20 }) data ({ 21 }) . ({ 22 }) 
# Sentence pair (846) source length 18 target length 18 alignment score : 6.69952e-12
Furthermore , with recent studies \CITE SVM classifiers can provide probability outputs that are suitable for ranking . 
NULL ({ 9 }) Furthermore ({ 1 }) , ({ 2 }) recent ({ 3 4 }) studies ({ 5 }) suggest ({ }) that ({ }) \CITE ({ 6 }) SVM ({ 7 }) classifiers ({ 8 }) provide ({ 10 }) probability ({ 11 }) outputs ({ 12 }) that ({ 13 }) are ({ 14 }) suitable ({ 15 }) for ({ 16 }) ranking ({ 17 }) . ({ 18 }) 
# Sentence pair (847) source length 12 target length 12 alignment score : 0.0133566
-Bagging framework helps to leverage noises in the unsupervised labeling process . 
NULL ({ }) -Bagging ({ 1 }) framework ({ 2 }) helps ({ 3 }) to ({ 4 }) leverage ({ 5 }) noises ({ 6 }) in ({ 7 }) the ({ 8 }) unsupervised ({ 9 }) labeling ({ 10 }) process ({ 11 }) . ({ 12 }) 
# Sentence pair (848) source length 5 target length 5 alignment score : 0.176974
Our contribution is two-fold : 
NULL ({ }) Our ({ 1 }) contribution ({ 2 }) is ({ 3 }) two-fold ({ 4 }) : ({ 5 }) 
# Sentence pair (849) source length 26 target length 26 alignment score : 3.21021e-10
-We propose a general framework to boost the face retrieval performance from the results retrieved from text correlation based search engines by learning visual consistency . 
NULL ({ 13 }) -We ({ 1 }) propose ({ 2 }) a ({ 3 }) general ({ 4 }) framework ({ 5 }) to ({ 6 }) boost ({ 7 }) the ({ 8 }) face ({ 9 }) retrieval ({ 10 }) performance ({ 11 }) from ({ 12 }) results ({ 14 }) retrieved ({ 15 }) from ({ 16 }) text ({ 17 }) correlation-based ({ 18 19 }) search ({ 20 }) engines ({ 21 }) by ({ 22 }) the ({ }) learning ({ 23 }) of ({ }) visual ({ 24 }) consistency ({ 25 }) . ({ 26 }) 
# Sentence pair (850) source length 41 target length 26 alignment score : 1.79886e-22
It integrates seamlessly current existing data mining methods such as outliers detection , supervised learning and unsupervised learning based on bagging for a practical problem . 
NULL ({ }) It ({ 1 }) seamlessly ({ 2 }) integrates ({ 3 }) current ({ 4 }) data ({ 6 }) mining ({ 7 }) methods ({ 8 }) such ({ 9 }) as ({ 10 }) outlier ({ 11 }) detection ({ 12 }) , ({ 13 }) supervised ({ 14 }) learning ({ 15 }) , ({ }) and ({ 16 }) unsupervised ({ 17 }) learning ({ 18 }) based ({ 19 }) on ({ 20 }) bagging ({ 21 }) for ({ 22 }) a ({ 23 }) practical ({ 24 }) problem ({ 25 }) . ({ 26 }) //[What ({ }) or ({ }) who ({ }) is ({ }) glearningh ({ 5 }) visual ({ }) consistency ({ }) ? ({ }) Are ({ }) the ({ }) search ({ }) engines ({ }) learning ({ }) ? ({ }) ] ({ }) 
# Sentence pair (851) source length 9 target length 9 alignment score : 0.0382155
Our framework requires few parameters and works stably . 
NULL ({ }) Our ({ 1 }) framework ({ 2 }) requires ({ 3 }) few ({ 4 }) parameters ({ 5 }) and ({ 6 }) works ({ 7 }) stably ({ 8 }) . ({ 9 }) 
# Sentence pair (852) source length 26 target length 25 alignment score : 2.18951e-05
-We demonstrate feasibility of using tolerance of supervised learning methods when working with noisy datasets combined with ensemble learning to improve the final performance . 
NULL ({ }) -We ({ 1 }) demonstrate ({ 2 }) the ({ }) feasibility ({ 3 }) of ({ 4 }) using ({ 5 }) tolerance ({ 6 }) of ({ 7 }) supervised ({ 8 }) learning ({ 9 }) methods ({ 10 }) when ({ 11 }) working ({ 12 }) with ({ 13 }) noisy ({ 14 }) datasets ({ 15 }) combined ({ 16 }) with ({ 17 }) ensemble ({ 18 }) learning ({ 19 }) to ({ 20 }) improve ({ 21 }) the ({ 22 }) final ({ 23 }) performance ({ 24 }) . ({ 25 }) 
# Sentence pair (853) source length 17 target length 15 alignment score : 5.76033e-11
There are several approaches proposed for general object classification rather than for face retrieval . 
NULL ({ }) There ({ 1 }) are ({ 2 }) several ({ 3 }) more ({ }) proposed ({ 5 }) approaches ({ 4 }) for ({ 6 }) general ({ 7 }) object ({ 8 }) classification ({ 9 }) than ({ 11 }) for ({ }) those ({ 10 }) for ({ 12 }) face ({ 13 }) retrieval ({ 14 }) . ({ 15 }) 
# Sentence pair (854) source length 31 target length 29 alignment score : 2.91868e-07
For example , as described in \CITE , objects are retrieved by an image search engine and then are re-ranked by learning visual consistencies from the retrieved objects . 
NULL ({ }) For ({ 1 }) example ({ 2 }) , ({ 3 }) as ({ 4 }) described ({ 5 }) in ({ 6 }) \CITE ({ 7 }) , ({ 8 }) objects ({ 9 }) are ({ 10 }) retrieved ({ 11 }) by ({ 12 }) an ({ 13 }) image ({ 14 }) search ({ 15 }) engine ({ 16 }) and ({ 17 }) then ({ 18 }) are ({ 19 }) re-ranked ({ 20 }) by ({ 21 }) the ({ }) learning ({ 22 }) of ({ }) visual ({ 23 }) consistencies ({ 24 }) from ({ 25 }) the ({ 26 }) retrieved ({ 27 }) objects ({ 28 }) . ({ 29 }) 
# Sentence pair (855) source length 53 target length 53 alignment score : 1.70826e-19
Compared to the problem of face retrieval based recognition , the problem of object classification is easier since classification of different object types such as airplane and non-airplane only needs to handle inter-variations between different categories while discriminating personA and personB requires to handle both intra-variations and inter-variations of the same category . 
NULL ({ 43 }) Compared ({ 1 }) to ({ 2 }) the ({ 3 }) problem ({ 4 }) of ({ 5 }) face-based ({ 6 7 8 }) recognition ({ 9 }) , ({ 10 }) the ({ 11 }) problem ({ 12 }) of ({ 13 }) object ({ 14 }) classification ({ 15 }) is ({ 16 }) easier ({ 17 }) since ({ 18 }) classification ({ 19 }) of ({ 20 }) different ({ 21 }) object ({ 22 }) types ({ 23 }) such ({ 24 }) as ({ 25 }) airplane ({ 26 }) and ({ 27 }) non-airplane ({ 28 }) only ({ 29 }) needs ({ 30 }) to ({ 31 }) handle ({ 32 }) inter-variations ({ 33 }) between ({ 34 }) different ({ 35 }) categories ({ 36 }) , ({ }) while ({ 37 }) discriminating ({ 38 }) between ({ }) person-A ({ 39 }) and ({ 40 }) person-B ({ 41 }) requires ({ 42 }) handling ({ 44 }) of ({ }) both ({ 45 }) intra-variations ({ 46 }) and ({ 47 }) inter-variations ({ 48 }) of ({ 49 }) the ({ 50 }) same ({ 51 }) category ({ 52 }) . ({ 53 }) 
# Sentence pair (856) source length 31 target length 30 alignment score : 6.05668e-10
Furthermore , in order to work in unsupervised mode , these approaches need a method to collect negative samples ( e.g. non-airplane ) which are inapplicable in our problem . 
NULL ({ }) Furthermore ({ 1 }) , ({ 2 }) in ({ 3 }) order ({ 4 }) to ({ 5 }) work ({ 6 }) in ({ 7 }) unsupervised ({ 8 }) mode ({ 9 }) , ({ 10 }) these ({ 11 }) approaches ({ 12 }) need ({ 13 }) a ({ 14 }) method ({ 15 }) to ({ 16 }) collect ({ 17 }) negative ({ 18 }) samples ({ 19 }) ( ({ 20 }) e.g. ({ 21 }) non-airplane ({ 22 }) ) ({ 23 }) , ({ }) which ({ 24 }) are ({ 25 }) inapplicable ({ 26 }) to ({ 27 }) our ({ 28 }) problem ({ 29 }) . ({ 30 }) 
# Sentence pair (857) source length 40 target length 38 alignment score : 6.11912e-36
Working closely to our problem , in \cite{Ozkan06CVPR} , a graph based approach was proposed \CITEin which a graph is formed by faces as nodes and weights of edges linked between nodes are the similarity of faces . 
NULL ({ 17 18 }) A ({ 1 }) graph-based ({ 12 }) approach ({ 13 }) was ({ 14 }) proposed ({ 15 }) by ({ }) \CITE ({ }) , ({ 6 }) in ({ 7 }) which ({ 8 }) a ({ 10 }) graph ({ 11 19 }) is ({ 20 }) formed ({ 21 }) by ({ 22 }) faces ({ 23 }) as ({ 24 }) nodes ({ 25 }) , ({ }) and ({ 26 }) the ({ }) weights ({ 27 }) of ({ 28 }) edges ({ 29 }) linked ({ 30 }) between ({ 31 }) nodes ({ 32 }) are ({ 33 }) the ({ 34 }) similarity ({ 35 }) of ({ 36 }) faces ({ 37 }) , ({ 9 }) is ({ }) closely ({ 16 }) related ({ 2 }) to ({ 3 }) our ({ 4 }) problem ({ 5 }) . ({ 38 }) 
# Sentence pair (858) source length 66 target length 58 alignment score : 3.39173e-32
By assuming that the number of faces of the queried person are larger than that of other persons , and these faces tend to form the most similar subset among the set of retrieved faces , this problem is considered equal to the problem of finding the densest subgraph of a full graph whose solution is available . 
NULL ({ 56 }) Assuming ({ 1 2 }) that ({ 3 }) the ({ 4 }) number ({ 5 }) of ({ 6 }) faces ({ 7 }) of ({ 8 }) the ({ 9 }) queried ({ 10 }) person ({ 11 }) is ({ 12 }) larger ({ 13 }) than ({ 14 }) that ({ 15 }) of ({ 16 }) others ({ }) and ({ 20 }) that ({ }) these ({ 21 }) faces ({ 22 }) tend ({ 23 }) to ({ 24 }) form ({ 25 }) the ({ 26 }) most ({ 27 }) similar ({ 28 }) subset ({ 29 }) among ({ 30 }) the ({ 31 }) set ({ 32 }) of ({ 33 }) retrieved ({ 34 }) faces ({ 35 }) , ({ 36 }) this ({ 37 }) problem ({ 38 }) is ({ 39 }) considered ({ 40 }) equal ({ 41 }) to ({ 42 }) the ({ 43 }) problem ({ 44 }) of ({ 45 }) finding ({ 46 }) the ({ 47 }) densest ({ 48 }) subgraph ({ 49 }) of ({ 50 }) a ({ 51 }) full ({ 52 }) graph ({ 53 }) with ({ }) an ({ }) available ({ 57 }) solution ({ 55 }) . ({ 58 }) //[Do ({ 17 }) graphs ({ 18 }) have ({ }) solutions ({ }) ? ({ }) They ({ 19 }) just ({ 54 }) provide ({ }) information ({ }) .] ({ }) 
# Sentence pair (859) source length 30 target length 29 alignment score : 1.63642e-06
Although , experimental results showed effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person . 
NULL ({ }) Although ({ 1 }) , ({ 2 }) experimental ({ 3 }) results ({ 4 }) showed ({ 5 }) the ({ }) effectiveness ({ 6 }) of ({ 7 }) this ({ 8 }) method ({ 9 }) , ({ 10 }) it ({ 11 }) is ({ 12 }) still ({ 13 }) questionable ({ 14 }) whether ({ 15 }) the ({ 16 }) densest ({ 17 }) subgraph ({ 18 }) intuitively ({ 19 }) describes ({ 20 }) most ({ 21 }) of ({ 22 }) relevant ({ 23 }) faces ({ 24 }) of ({ 25 }) the ({ 26 }) queried ({ 27 }) person ({ 28 }) . ({ 29 }) 
# Sentence pair (860) source length 25 target length 28 alignment score : 6.53425e-11
Furthermore , choosing an optimal threshold to convert the initial graph into a binary graph is difficult and rather ad hoc due to the curse of dimensionality . 
NULL ({ 24 26 }) Furthermore ({ 1 }) , ({ 2 }) choosing ({ 3 }) an ({ 4 }) optimal ({ 5 }) threshold ({ 6 }) to ({ 7 }) convert ({ 8 }) the ({ 9 }) initial ({ 10 }) graph ({ 11 }) into ({ 12 }) a ({ 13 }) binary ({ 14 }) graph ({ 15 }) is ({ 16 }) difficult ({ 17 }) and ({ 18 }) rather ({ 19 }) ad ({ 20 }) hoc ({ 21 }) due ({ 22 }) to ({ 23 }) dimensionality ({ 25 27 }) . ({ 28 }) 
# Sentence pair (861) source length 19 target length 19 alignment score : 4.81884e-06
In another work \CITE , a clustering-based approach was proposed to associate names and faces in news photos . 
NULL ({ }) In ({ 1 }) another ({ 2 }) work ({ 3 }) \CITE ({ 4 }) , ({ 5 }) a ({ 6 }) clustering-based ({ 7 }) approach ({ 8 }) was ({ 9 }) proposed ({ 10 }) for ({ 11 }) associating ({ 12 }) names ({ 13 }) and ({ 14 }) faces ({ 15 }) in ({ 16 }) news ({ 17 }) photos ({ 18 }) . ({ 19 }) 
# Sentence pair (862) source length 44 target length 44 alignment score : 4.98073e-08
To solve the problem of ambiguity between several names and one face , a modified \MATH -means clustering process was used in which faces are assigned to the closest cluster ( each cluster corresponding to one name ) after a number of iterations . 
NULL ({ }) To ({ 1 }) solve ({ 2 }) the ({ 3 }) problem ({ 4 }) of ({ 5 }) ambiguity ({ 6 }) between ({ 7 }) several ({ 8 }) names ({ 9 }) and ({ 10 }) one ({ 11 }) face ({ 12 }) , ({ 13 }) a ({ 14 }) modified ({ 15 }) \MATH ({ 16 }) -means ({ 17 }) clustering ({ 18 }) process ({ 19 }) was ({ 20 }) used ({ 21 }) in ({ 22 }) which ({ 23 }) faces ({ 24 }) are ({ 25 }) assigned ({ 26 }) to ({ 27 }) the ({ 28 }) closest ({ 29 }) cluster ({ 30 }) ( ({ 31 }) each ({ 32 }) cluster ({ 33 }) corresponding ({ 34 }) to ({ 35 }) one ({ 36 }) name ({ 37 }) ) ({ 38 }) after ({ 39 }) a ({ 40 }) number ({ 41 }) of ({ 42 }) iterations ({ 43 }) . ({ 44 }) 
# Sentence pair (863) source length 35 target length 34 alignment score : 6.51861e-09
Although the result was impressive , it is not easy to apply for our problem since a large number of irrelevant faces ( more than 12% ) are eliminated manually before doing clustering . 
NULL ({ }) Although ({ 1 }) the ({ 2 }) result ({ 3 }) was ({ 4 }) impressive ({ 5 }) , ({ 6 }) it ({ 7 }) is ({ 8 }) not ({ 9 }) easy ({ 10 }) to ({ 11 }) apply ({ 12 }) it ({ }) to ({ 13 }) our ({ 14 }) problem ({ 15 }) since ({ 16 }) a ({ 17 }) large ({ 18 }) number ({ 19 }) of ({ 20 }) irrelevant ({ 21 }) faces ({ 22 }) ( ({ 23 }) more ({ 24 }) than ({ 25 }) 12% ({ 26 }) ) ({ 27 }) are ({ 28 }) eliminated ({ 29 }) manually ({ 30 }) before ({ 31 }) performing ({ 32 }) clustering ({ 33 }) . ({ 34 }) 
# Sentence pair (864) source length 14 target length 14 alignment score : 0.00891296
This paper is organized as follows : Section \REF introduces our proposed framework . 
NULL ({ }) This ({ 1 }) paper ({ 2 }) is ({ 3 }) organized ({ 4 }) as ({ 5 }) follows ({ 6 }) : ({ 7 }) Section ({ 8 }) \REF ({ 9 }) introduces ({ 10 }) our ({ 11 }) proposed ({ 12 }) framework ({ 13 }) . ({ 14 }) 
# Sentence pair (865) source length 9 target length 9 alignment score : 0.00155082
Section \REF introduce briefly typical outliers detection methods . 
NULL ({ }) Section ({ 1 }) \REF ({ 2 }) briefly ({ 3 }) introduces ({ 4 }) typical ({ 5 }) outlier ({ 6 }) detection ({ 7 }) methods ({ 8 }) . ({ 9 }) 
# Sentence pair (866) source length 9 target length 9 alignment score : 0.0255151
Experiments and results are described in section \REF . 
NULL ({ }) Experiments ({ 1 }) and ({ 2 }) results ({ 3 }) are ({ 4 }) described ({ 5 }) in ({ 6 }) section ({ 7 }) \REF ({ 8 }) . ({ 9 }) 
# Sentence pair (867) source length 8 target length 8 alignment score : 0.0641704
Finally , section \REF concludes the paper . 
NULL ({ }) Finally ({ 1 }) , ({ 2 }) section ({ 3 }) \REF ({ 4 }) concludes ({ 5 }) the ({ 6 }) paper ({ 7 }) . ({ 8 }) 
# Sentence pair (868) source length 26 target length 23 alignment score : 1.37814e-08
Given a set of faces returned by any text-based correlation search engine , our method performs a ranking process summarized as follows : 
NULL ({ }) Given ({ 1 }) a ({ 2 }) set ({ 3 }) of ({ 4 }) faces ({ 5 }) returned ({ 6 }) by ({ 7 }) any ({ 8 }) text-based ({ 9 }) correlation ({ 10 }) search ({ 11 }) engine ({ 12 }) , ({ 13 }) our ({ 14 }) method ({ 15 }) is ({ }) used ({ }) to ({ }) perform ({ 16 }) a ({ 17 }) ranking ({ 18 }) process ({ 19 }) summarized ({ 20 }) as ({ 21 }) follows ({ 22 }) : ({ 23 }) 
# Sentence pair (869) source length 13 target length 13 alignment score : 0.00726288
-Step 1 : Detect eye positions , and then perform face normalizations . 
NULL ({ }) -Step ({ 1 }) 1 ({ 2 }) : ({ 3 }) Detect ({ 4 }) eye ({ 5 }) positions ({ 6 }) , ({ 7 }) and ({ 8 }) then ({ 9 }) perform ({ 10 }) face ({ 11 }) normalizations ({ 12 }) . ({ 13 }) 
# Sentence pair (870) source length 16 target length 16 alignment score : 0.00423336
-Step 2 : Compute an eigenface space and project the input faces into this subspace . 
NULL ({ }) -Step ({ 1 }) 2 ({ 2 }) : ({ 3 }) Compute ({ 4 }) an ({ 5 }) eigenface ({ 6 }) space ({ 7 }) and ({ 8 }) project ({ 9 }) the ({ 10 }) input ({ 11 }) faces ({ 12 }) into ({ 13 }) this ({ 14 }) subspace ({ 15 }) . ({ 16 }) 
# Sentence pair (871) source length 16 target length 16 alignment score : 0.00262323
-Step 3 : Estimate ranks of faces using an outliers detection method mentioned in \REF . 
NULL ({ }) -Step ({ 1 }) 3 ({ 2 }) : ({ 3 }) Estimate ({ 4 }) ranks ({ 5 }) of ({ 6 }) faces ({ 7 }) using ({ 8 }) an ({ 9 }) outlier ({ 10 }) detection ({ 11 }) method ({ 12 }) mentioned ({ 13 }) in ({ 14 }) \REF ({ 15 }) . ({ 16 }) 
# Sentence pair (872) source length 15 target length 15 alignment score : 0.000111404
-Step 4 : Train a ensemble classifier \MATH using this rank list by Bag-Rank-SVM . 
NULL ({ }) -Step ({ 1 }) 4 ({ 2 }) : ({ 3 }) Train ({ 4 }) an ({ 5 }) ensemble ({ 6 }) classifier ({ 7 }) \MATH ({ 8 }) using ({ 9 }) this ({ 10 }) rank ({ 11 }) list ({ 12 }) by ({ 13 }) Bag-Rank-SVM ({ 14 }) . ({ 15 }) 
# Sentence pair (873) source length 18 target length 18 alignment score : 0.00206565
-Step 5 : Use the classifier \MATH to estimate the probability of faces in the original set . 
NULL ({ }) -Step ({ 1 }) 5 ({ 2 }) : ({ 3 }) Use ({ 4 }) the ({ 5 }) classifier ({ 6 }) \MATH ({ 7 }) to ({ 8 }) estimate ({ 9 }) the ({ 10 }) probability ({ 11 }) of ({ 12 }) faces ({ 13 }) in ({ 14 }) the ({ 15 }) original ({ 16 }) set ({ 17 }) . ({ 18 }) 
# Sentence pair (874) source length 8 target length 8 alignment score : 0.0019764
Rank these faces using their probability score . 
NULL ({ }) Rank ({ 1 }) these ({ 2 }) faces ({ 3 }) using ({ 4 }) their ({ 5 }) probability ({ 6 }) scores ({ 7 }) . ({ 8 }) 
# Sentence pair (875) source length 23 target length 24 alignment score : 7.47893e-08
-Step 6 : Repeat steps from 4 and 5 $T$ times and return ranked faces produced by the last classifier \MATH to users . 
NULL ({ 6 }) -Step ({ 1 }) 6 ({ 2 }) : ({ 3 }) Repeat ({ 4 }) steps ({ 5 }) 4 ({ 7 }) and ({ 8 }) 5 ({ 9 }) $T$ ({ 10 }) times ({ 11 }) and ({ 12 }) return ({ 13 }) ranked ({ 14 }) faces ({ 15 }) produced ({ 16 }) by ({ 17 }) the ({ 18 }) last ({ 19 }) classifier ({ 20 }) \MATH ({ 21 }) to ({ 22 }) users ({ 23 }) . ({ 24 }) 
# Sentence pair (876) source length 18 target length 19 alignment score : 6.58794e-07
Steps from 1 and 2 are typical for any face processing system and described in details in \REF . 
NULL ({ }) Steps ({ 1 2 }) 1 ({ 3 }) and ({ 4 }) 2 ({ 5 }) are ({ 6 }) typical ({ 7 }) for ({ 8 }) any ({ 9 }) face ({ 10 }) processing ({ 11 }) system ({ 12 }) and ({ 13 }) described ({ 14 }) in ({ 15 }) detail ({ 16 }) in ({ 17 }) \REF ({ 18 }) . ({ 19 }) 
# Sentence pair (877) source length 13 target length 14 alignment score : 3.75473e-06
Step 3 used to find initial ranks for faces is described in \REF . 
NULL ({ 10 }) Step ({ 1 }) 3 ({ 2 }) used ({ 3 }) to ({ 4 }) find ({ 5 }) initial ({ 6 }) ranks ({ 7 }) for ({ 8 }) faces ({ 9 }) described ({ 11 }) in ({ 12 }) \REF ({ 13 }) . ({ 14 }) 
# Sentence pair (878) source length 11 target length 11 alignment score : 0.00109121
We use a simple outliers detection method for this step . 
NULL ({ }) We ({ 1 }) used ({ 2 }) a ({ 3 }) simple ({ 4 }) outlier ({ 5 }) detection ({ 6 }) method ({ 7 }) for ({ 8 }) this ({ 9 }) step ({ 10 }) . ({ 11 }) 
# Sentence pair (879) source length 8 target length 8 alignment score : 0.064622
The Bag-Rank-SVM algorithm is described as follows : 
NULL ({ }) The ({ 1 }) Bag-Rank-SVM ({ 2 }) algorithm ({ 3 }) is ({ 4 }) described ({ 5 }) as ({ 6 }) follows ({ 7 }) : ({ 8 }) 
# Sentence pair (880) source length 22 target length 22 alignment score : 0.000693965
-Step 1 : Select a set \MATH including \MATH top ranked faces and then randomly select a subset \MATH from \MATH . 
NULL ({ }) -Step ({ 1 }) 1 ({ 2 }) : ({ 3 }) Select ({ 4 }) a ({ 5 }) set ({ 6 }) \MATH ({ 7 }) including ({ 8 }) \MATH ({ 9 }) top ({ 10 }) ranked ({ 11 }) faces ({ 12 }) and ({ 13 }) then ({ 14 }) randomly ({ 15 }) select ({ 16 }) a ({ 17 }) subset ({ 18 }) \MATH ({ 19 }) from ({ 20 }) \MATH ({ 21 }) . ({ 22 }) 
# Sentence pair (881) source length 8 target length 8 alignment score : 0.0924833
Label faces in \MATH as positive samples . 
NULL ({ }) Label ({ 1 }) faces ({ 2 }) in ({ 3 }) \MATH ({ 4 }) as ({ 5 }) positive ({ 6 }) samples ({ 7 }) . ({ 8 }) 
# Sentence pair (882) source length 22 target length 22 alignment score : 0.000719026
-Step 2 : Select a set \MATH including \MATH bottom ranked faces and then randomly select a subset \MATH from \MATH . 
NULL ({ }) -Step ({ 1 }) 2 ({ 2 }) : ({ 3 }) Select ({ 4 }) a ({ 5 }) set ({ 6 }) \MATH ({ 7 }) including ({ 8 }) \MATH ({ 9 }) bottom ({ 10 }) ranked ({ 11 }) faces ({ 12 }) and ({ 13 }) then ({ 14 }) randomly ({ 15 }) select ({ 16 }) a ({ 17 }) subset ({ 18 }) \MATH ({ 19 }) from ({ 20 }) \MATH ({ 21 }) . ({ 22 }) 
# Sentence pair (883) source length 8 target length 8 alignment score : 0.0923406
Label faces in \MATH as negative samples . 
NULL ({ }) Label ({ 1 }) faces ({ 2 }) in ({ 3 }) \MATH ({ 4 }) as ({ 5 }) negative ({ 6 }) samples ({ 7 }) . ({ 8 }) 
# Sentence pair (884) source length 20 target length 20 alignment score : 0.000949501
-Step 3 : Use \MATH and \MATH to train a weak classifier \MATH using LibSVM \CITE with probability outputs . 
NULL ({ }) -Step ({ 1 }) 3 ({ 2 }) : ({ 3 }) Use ({ 4 }) \MATH ({ 5 }) and ({ 6 }) \MATH ({ 7 }) to ({ 8 }) train ({ 9 }) a ({ 10 }) weak ({ 11 }) classifier ({ 12 }) \MATH ({ 13 }) using ({ 14 }) LibSVM ({ 15 }) \CITE ({ 16 }) with ({ 17 }) probability ({ 18 }) outputs ({ 19 }) . ({ 20 }) 
# Sentence pair (885) source length 13 target length 14 alignment score : 2.67714e-05
-Step 4 : Repeat steps from Step 1 to Step 3 \MATH times . 
NULL ({ 6 }) -Step ({ 1 }) 4 ({ 2 }) : ({ 3 }) Repeat ({ 4 }) steps ({ 5 }) Step ({ 7 }) 1 ({ 8 }) to ({ 9 }) Step ({ 10 }) 3 ({ 11 }) \MATH ({ 12 }) times ({ 13 }) . ({ 14 }) 
# Sentence pair (886) source length 6 target length 6 alignment score : 0.187881
-Step 5 : Return \MATH . 
NULL ({ }) -Step ({ 1 }) 5 ({ 2 }) : ({ 3 }) Return ({ 4 }) \MATH ({ 5 }) . ({ 6 }) 
# Sentence pair (887) source length 62 target length 61 alignment score : 3.30086e-27
Since it is not guaranteed top \MATH and bottom \MATH of faces in the rank list are correctly correspondent to faces of the queried person \MATH and faces of non person \MATH as shown in Figure \REF , selecting randomly subsets to train weak classifiers and then combining these classifiers might help to reduce risk of using noisy training sets . 
NULL ({ 17 53 }) Since ({ 1 }) it ({ 2 }) is ({ 3 }) not ({ 4 }) guaranteed ({ 5 }) that ({ }) the ({ }) top ({ 6 }) \MATH ({ 7 }) and ({ 8 }) bottom ({ 9 }) \MATH ({ 10 }) of ({ 11 }) faces ({ 12 }) in ({ 13 }) the ({ 14 }) rank ({ 15 }) list ({ 16 }) correctly ({ 18 }) correspond ({ 19 }) to ({ 20 }) the ({ }) faces ({ 21 }) of ({ 22 }) the ({ 23 }) queried ({ 24 }) person-\MATH ({ 25 26 }) and ({ 27 }) faces ({ 28 }) of ({ 29 }) non ({ 30 }) person-\MATH ({ 31 32 }) as ({ 33 }) shown ({ 34 }) in ({ 35 }) Figure ({ 36 }) \REF ({ 37 }) , ({ 38 }) randomly ({ 40 }) selecting ({ 39 }) subsets ({ 41 }) to ({ 42 }) train ({ 43 }) weak ({ 44 }) classifiers ({ 45 }) , ({ }) and ({ 46 }) then ({ 47 }) combining ({ 48 }) these ({ 49 }) classifiers ({ 50 }) might ({ 51 }) help ({ 52 }) reduce ({ 54 }) the ({ }) risk ({ 55 }) of ({ 56 }) using ({ 57 }) noisy ({ 58 }) training ({ 59 }) sets ({ 60 }) . ({ 61 }) 
# Sentence pair (888) source length 29 target length 29 alignment score : 2.65864e-05
In our framework , outliers detection methods are used to initialize the rank list that is then used to label a subset of samples for training SVM classifiers . 
NULL ({ }) In ({ 1 }) our ({ 2 }) framework ({ 3 }) , ({ 4 }) outlier ({ 5 }) detection ({ 6 }) methods ({ 7 }) are ({ 8 }) used ({ 9 }) to ({ 10 }) initialize ({ 11 }) the ({ 12 }) rank ({ 13 }) list ({ 14 }) that ({ 15 }) is ({ 16 }) then ({ 17 }) used ({ 18 }) to ({ 19 }) label ({ 20 }) a ({ 21 }) subset ({ 22 }) of ({ 23 }) samples ({ 24 }) for ({ 25 }) training ({ 26 }) SVM ({ 27 }) classifiers ({ 28 }) . ({ 29 }) 
# Sentence pair (889) source length 25 target length 26 alignment score : 2.12995e-16
We introduce here two common outliers detection methods including distance-based outliers detection( DBO ) \CITE and local outliers factor based method ( LOF ) \CITE . 
NULL ({ }) We ({ 1 }) introduce ({ 2 3 }) two ({ 4 }) common ({ 5 }) outlier ({ 6 }) detection ({ 7 }) methods ({ 8 }) , ({ }) distance-based ({ 9 10 }) outlier ({ 11 }) detection ({ 12 }) ( ({ }) DBO ({ 13 }) ) ({ 14 }) \CITE ({ 15 }) and ({ 16 }) local ({ 17 }) outlier ({ 18 }) factor-based ({ 19 20 }) method ({ 21 }) ( ({ 22 }) LOF ({ 23 }) ) ({ 24 }) \CITE ({ 25 }) . ({ 26 }) 
# Sentence pair (890) source length 38 target length 36 alignment score : 1.44026e-09
Adapting the definition \CITE , given a set of objects \MATH , an object \MATH is considered as an outliers if there are fewer than \MATH neighboring objects in \MATH lying within a distance \MATH . 
NULL ({ }) Adapting ({ 1 }) the ({ 2 }) definition ({ 3 }) from ({ }) Knorr ({ }) \CITE ({ 4 }) , ({ 5 }) given ({ 6 }) a ({ 7 }) set ({ 8 }) of ({ 9 }) objects ({ 10 }) \MATH ({ 11 }) , ({ 12 }) an ({ 13 }) object ({ 14 }) \MATH ({ 15 }) is ({ 16 }) considered ({ 17 }) as ({ 18 }) an ({ 19 }) outlier ({ 20 }) if ({ 21 }) there ({ 22 }) are ({ 23 }) fewer ({ 24 }) than ({ 25 }) \MATH ({ 26 }) neighboring ({ 27 }) objects ({ 28 }) in ({ 29 }) \MATH ({ 30 }) lying ({ 31 }) within ({ 32 }) a ({ 33 }) distance ({ 34 }) \MATH ({ 35 }) . ({ 36 }) 
# Sentence pair (891) source length 9 target length 9 alignment score : 0.00110806
The outliers detection process is summarized as follows : 
NULL ({ }) This ({ 1 }) outlier ({ 2 }) detection ({ 3 }) process ({ 4 }) is ({ 5 }) summarized ({ 6 }) as ({ 7 }) follows ({ 8 }) : ({ 9 }) 
# Sentence pair (892) source length 13 target length 13 alignment score : 0.0140564
-Step 1 : Compute the distance between every pair of data objects . 
NULL ({ }) -Step ({ 1 }) 1 ({ 2 }) : ({ 3 }) Compute ({ 4 }) the ({ 5 }) distance ({ 6 }) between ({ 7 }) every ({ 8 }) pair ({ 9 }) of ({ 10 }) data ({ 11 }) objects ({ 12 }) . ({ 13 }) 
# Sentence pair (893) source length 23 target length 22 alignment score : 5.68793e-05
-Step 2 : For each object , compute \MATH which is the number of neighboring objects lying within a distance \MATH . 
NULL ({ }) -Step ({ 1 }) 2 ({ 2 }) : ({ 3 }) For ({ 4 }) each ({ 5 }) object ({ 6 }) , ({ 7 }) compute ({ 8 }) \MATH ({ 9 }) , ({ }) which ({ 10 }) is ({ 11 }) the ({ 12 }) number ({ 13 }) of ({ 14 }) neighboring ({ 15 }) objects ({ 16 }) lying ({ 17 }) within ({ 18 }) a ({ 19 }) distance ({ 20 }) \MATH ({ 21 }) . ({ 22 }) 
# Sentence pair (894) source length 11 target length 11 alignment score : 0.0325344
-Step 3 : Rank objects based on their scores \MATH . 
NULL ({ }) -Step ({ 1 }) 3 ({ 2 }) : ({ 3 }) Rank ({ 4 }) objects ({ 5 }) based ({ 6 }) on ({ 7 }) their ({ 8 }) scores ({ 9 }) \MATH ({ 10 }) . ({ 11 }) 
# Sentence pair (895) source length 29 target length 28 alignment score : 1.22816e-05
In our experiments , the distance between two objects is Euclidean distance between two faces and is computed in the eigen-subspace ( described in section \REF ) . 
NULL ({ }) In ({ 1 }) our ({ 2 }) experiments ({ 3 }) , ({ 4 }) the ({ 5 }) distance ({ 6 }) between ({ 7 }) two ({ 8 }) objects ({ 9 }) is ({ 10 }) the ({ }) Euclidean ({ 11 }) distance ({ 12 }) between ({ 13 }) two ({ 14 }) faces ({ 15 }) and ({ 16 }) is ({ 17 }) computed ({ 18 }) in ({ 19 }) the ({ 20 }) eigen-subspace ({ 21 }) ( ({ 22 }) described ({ 23 }) in ({ 24 }) section ({ 25 }) \REF ({ 26 }) ) ({ 27 }) . ({ 28 }) 
# Sentence pair (896) source length 18 target length 18 alignment score : 0.000105344
Figure \REF shows two examples of good and bad performance using this method for ranking relevant faces . 
NULL ({ }) Figure ({ 1 }) \REF ({ 2 }) shows ({ 3 }) two ({ 4 }) examples ({ 5 }) of ({ 6 }) good ({ 7 }) and ({ 8 }) bad ({ 9 }) performances ({ 10 }) using ({ 11 }) this ({ 12 }) method ({ 13 }) for ({ 14 }) ranking ({ 15 }) relevant ({ 16 }) faces ({ 17 }) . ({ 18 }) 
# Sentence pair (897) source length 29 target length 29 alignment score : 1.84924e-05
According to the method described in \CITE , the local outliers factor of an object \MATH is computed by the following steps and then used to rank faces : 
NULL ({ }) According ({ 1 }) to ({ 2 }) the ({ 3 }) method ({ 4 }) described ({ 5 }) in ({ 6 }) \CITE ({ 7 }) , ({ 8 }) the ({ 9 }) local ({ 10 }) outlier ({ 11 }) factor ({ 12 }) of ({ 13 }) an ({ 14 }) object ({ 15 }) \MATH ({ 16 }) is ({ 17 }) computed ({ 18 }) by ({ 19 }) the ({ 20 }) following ({ 21 }) steps ({ 22 }) and ({ 23 }) then ({ 24 }) used ({ 25 }) to ({ 26 }) rank ({ 27 }) faces ({ 28 }) : ({ 29 }) 
# Sentence pair (898) source length 31 target length 30 alignment score : 9.71862e-06
-Step 1 : For each data object \MATH compute \MATH ( the distance to the \MATH nearest neighbor ) and \MATH ( all points in a \MATH sphere ) . 
NULL ({ }) -Step ({ 1 }) 1 ({ 2 }) : ({ 3 }) For ({ 4 }) each ({ 5 }) data ({ 6 }) object ({ 7 }) \MATH ({ 8 }) compute ({ 9 }) the ({ }) \MATH ({ 10 }) ( ({ 11 }) the ({ 12 }) distance ({ 13 }) to ({ 14 }) the ({ 15 }) \MATH ({ 16 }) nearest ({ 17 }) neighbor ({ 18 }) ) ({ 19 }) and ({ 20 }) \MATH ({ 21 }) ( ({ 22 }) all ({ 23 }) points ({ 24 }) in ({ 25 }) a ({ 26 }) \MATH ({ 27 }) sphere ({ 28 }) ) ({ 29 }) . ({ 30 }) 
# Sentence pair (899) source length 37 target length 35 alignment score : 2.16514e-07
- Step 2 : Compute reachability distance for each data object \MATH with respect to data object \MATH as : \MATH , where \MATH is distance from data object \MATH to data object \MATH . 
NULL ({ }) - ({ 1 }) Step ({ 2 }) 2 ({ 3 }) : ({ 4 }) Compute ({ 5 }) the ({ }) reachability ({ 6 }) distance ({ 7 }) for ({ 8 }) each ({ 9 }) data ({ 10 }) object ({ 11 }) \MATH ({ 12 }) with ({ 13 }) respect ({ 14 }) to ({ 15 }) data ({ 16 }) object ({ 17 }) \MATH ({ 18 }) as ({ 19 }) : ({ 20 }) \MATH ({ 21 }) , ({ 22 }) where ({ 23 }) \MATH ({ 24 }) is ({ 25 }) the ({ }) distance ({ 26 }) from ({ 27 }) data ({ 28 }) object ({ 29 }) \MATH ({ 30 }) to ({ 31 }) data ({ 32 }) object ({ 33 }) \MATH ({ 34 }) . ({ 35 }) 
# Sentence pair (900) source length 38 target length 36 alignment score : 1.14546e-09
-Step 3 : Compute local reachability density of data object \MATH as inverse of the average reachability distance based on the \MATH ( minimum number of data objects ) nearest neighbors of data object \MATH . 
NULL ({ 32 }) -Step ({ 1 }) 3 ({ 2 }) : ({ 3 }) Compute ({ 4 }) local ({ 5 }) reachability ({ 6 }) density ({ 7 }) of ({ 8 }) data ({ 9 }) object ({ 10 }) \MATH ({ 11 }) as ({ 12 }) inverse ({ 13 }) of ({ 14 }) the ({ 15 }) average ({ 16 }) reachability ({ 17 }) distance ({ 18 }) based ({ 19 }) on ({ 20 }) the ({ 21 }) \MATH ({ 22 }) ( ({ 23 }) minimum ({ 24 }) number ({ 25 }) of ({ 26 }) data ({ 27 }) objects ({ 28 }) ) ({ 29 }) of ({ }) the ({ }) nearest ({ 30 }) neighbors ({ 31 }) to ({ }) data ({ 33 }) object ({ 34 }) \MATH ({ 35 }) . ({ 36 }) 
# Sentence pair (901) source length 34 target length 32 alignment score : 3.3159e-07
-Step 4 : Compute LOF of data object \MATH as average of the ratios of the local reachability density of data object \MATH and local reachability density of \MATH nearest neighbors . 
NULL ({ }) -Step ({ 1 }) 4 ({ 2 }) : ({ 3 }) Compute ({ 4 }) LOF ({ 5 }) of ({ 6 }) data ({ 7 }) object ({ 8 }) \MATH ({ 9 }) as ({ 10 }) the ({ }) average ({ 11 }) of ({ 12 }) the ({ 13 }) ratios ({ 14 }) of ({ 15 }) the ({ 16 }) local ({ 17 }) reachability ({ 18 }) density ({ 19 }) of ({ 20 }) data ({ 21 }) object ({ 22 }) \MATH ({ 23 }) and ({ 24 }) local ({ 25 }) reachability ({ 26 }) density ({ 27 }) of ({ 28 }) \MATH ({ 29 }) of ({ }) nearest ({ 30 }) neighbors ({ 31 }) . ({ 32 }) 
# Sentence pair (902) source length 11 target length 11 alignment score : 0.014144
We used the dataset described in \CITE for our experiments . 
NULL ({ }) We ({ 1 }) used ({ 2 }) the ({ 3 }) dataset ({ 4 }) described ({ 5 }) in ({ 6 }) \CITE ({ 7 }) for ({ 8 }) our ({ 9 }) experiments ({ 10 }) . ({ 11 }) 
# Sentence pair (903) source length 23 target length 23 alignment score : 2.46293e-05
This dataset consists of approximately half a million news pictures and captions from Yahoo News over a period of roughly two years . 
NULL ({ }) This ({ 1 }) dataset ({ 2 }) consisted ({ 3 }) of ({ 4 }) approximately ({ 5 }) half ({ 6 }) a ({ 7 }) million ({ 8 }) news ({ 9 }) pictures ({ 10 }) and ({ 11 }) captions ({ 12 }) from ({ 13 }) Yahoo ({ 14 }) News ({ 15 }) over ({ 16 }) a ({ 17 }) period ({ 18 }) of ({ 19 }) roughly ({ 20 }) two ({ 21 }) years ({ 22 }) . ({ 23 }) 
# Sentence pair (904) source length 21 target length 21 alignment score : 0.000209414
Using a robust face detector , 44 , 773 faces were detected and normalized to the size of 86\MATH86 pixels . 
NULL ({ }) Using ({ 1 }) a ({ 2 }) robust ({ 3 }) face ({ 4 }) detector ({ 5 }) , ({ 6 }) 44 ({ 7 }) , ({ 8 }) 773 ({ 9 }) faces ({ 10 }) were ({ 11 }) detected ({ 12 }) and ({ 13 }) normalized ({ 14 }) to ({ 15 }) the ({ 16 }) size ({ 17 }) of ({ 18 }) 86\MATH86 ({ 19 }) pixels ({ 20 }) . ({ 21 }) 
# Sentence pair (905) source length 34 target length 33 alignment score : 5.16111e-08
After eliminating faces whose facial features are poorly detected by a rectification process and faces whose associated names are not extracted properly from corresponding captions , 30 , 281 faces were kept . 
NULL ({ }) After ({ 1 }) eliminating ({ 2 }) faces ({ 3 }) whose ({ 4 }) facial ({ 5 }) features ({ 6 }) were ({ 7 }) poorly ({ 8 }) detected ({ 9 }) by ({ 10 }) a ({ 11 }) rectification ({ 12 }) process ({ 13 }) and ({ 14 }) faces ({ 15 }) whose ({ 16 }) associated ({ 17 }) names ({ 18 }) were ({ 19 }) not ({ 20 }) extracted ({ 21 }) properly ({ 22 }) from ({ 23 }) the ({ }) corresponding ({ 24 }) captions ({ 25 }) , ({ 26 }) 30 ({ 27 }) , ({ 28 }) 281 ({ 29 }) faces ({ 30 }) were ({ 31 }) kept ({ 32 }) . ({ 33 }) 
# Sentence pair (906) source length 13 target length 13 alignment score : 0.0125137
Figure \REF shows an example of a news photo and its caption . 
NULL ({ }) Figure ({ 1 }) \REF ({ 2 }) shows ({ 3 }) an ({ 4 }) example ({ 5 }) of ({ 6 }) a ({ 7 }) news ({ 8 }) photo ({ 9 }) and ({ 10 }) its ({ 11 }) caption ({ 12 }) . ({ 13 }) 
# Sentence pair (907) source length 83 target length 93 alignment score : 3.31944e-49
We selected sixteen celebrities who are government leaders such as George W . Bush ( US ) , Vladimir Putin ( Russia ) , Ziang Jemin ( China ) , Tony Blair ( UK ) , Junichiro Koizumi ( Japan ) , Roh Moo-hyun ( Korea ) , Abdullah Gul ( Turkey ) , and other key persons such as John Paul II ( the Former Pope ) , Kofi Annan and Hans Blix ( UN ) . These persons are selected since their appearances are highly frequent in the dataset \CITE . 
NULL ({ 10 69 78 82 86 }) We ({ 1 }) selected ({ 2 }) sixteen ({ 3 6 79 }) government ({ 4 7 80 }) leaders ({ 5 8 81 }) including ({ 9 }) George ({ 11 }) W ({ 12 }) . ({ 13 }) Bush ({ 14 }) ( ({ 15 }) US ({ 16 }) ) ({ 17 }) , ({ 18 }) Vladimir ({ 19 }) Putin ({ 20 }) ( ({ 21 }) Russia ({ 22 }) ) ({ 23 }) , ({ 24 }) Ziang ({ 25 }) Jemin ({ 26 }) ( ({ 27 }) China ({ 28 }) ) ({ 29 }) , ({ 30 }) Tony ({ 31 }) Blair ({ 32 }) ( ({ 33 }) UK ({ 34 }) ) ({ 35 }) , ({ 36 }) Junichiro ({ 37 }) Koizumi ({ 38 }) ( ({ 39 }) Japan ({ 40 }) ) ({ 41 }) , ({ 42 }) Roh ({ 43 }) Moo-hyun ({ 44 }) ( ({ 45 }) Korea ({ 46 }) ) ({ 47 }) , ({ 48 }) Abdullah ({ 49 }) Gul ({ 50 }) ( ({ 51 }) Turkey ({ 52 }) ) ({ 53 }) , ({ 54 }) and ({ 55 }) other ({ 56 }) key ({ 57 }) individuals ({ 58 }) such ({ 59 }) as ({ 60 }) John ({ 61 }) Paul ({ 62 }) II ({ 63 }) ( ({ 64 }) the ({ 65 }) Former ({ 66 }) Pope ({ 67 }) ) ({ 68 }) and ({ }) Kofi ({ 70 }) Annan ({ 71 }) and ({ 72 }) Hans ({ 73 }) Blix ({ 74 }) ( ({ 75 }) UN ({ 76 }) ) ({ 77 }) since ({ 83 }) their ({ 84 }) images ({ 85 }) appeared ({ 87 }) frequently ({ 88 }) in ({ 89 }) the ({ 90 }) dataset ({ 91 }) \CITE ({ 92 }) . ({ 93 }) 
# Sentence pair (908) source length 39 target length 39 alignment score : 4.65061e-07
For each person , variations of his name are collected . For example , George W . Bush , President Bush , U . S . President , etc are variations of U . S . President Bush . 
NULL ({ }) For ({ 1 }) each ({ 2 }) person ({ 3 }) , ({ 4 }) variations ({ 5 }) of ({ 6 }) his ({ 7 }) name ({ 8 }) were ({ 9 }) collected ({ 10 }) . ({ 11 }) For ({ 12 }) example ({ 13 }) , ({ 14 }) George ({ 15 }) W ({ 16 }) . ({ 17 }) Bush ({ 18 }) , ({ 19 }) President ({ 20 }) Bush ({ 21 }) , ({ 22 }) U ({ 23 }) . ({ 24 }) S ({ 25 }) . ({ 26 }) President ({ 27 }) , ({ 28 }) etc ({ 29 }) are ({ 30 }) variations ({ 31 }) of ({ 32 }) U ({ 33 }) . ({ 34 }) S ({ 35 }) . ({ 36 }) President ({ 37 }) Bush ({ 38 }) . ({ 39 }) 
# Sentence pair (909) source length 23 target length 23 alignment score : 0.000100427
We indexed image captions and then used this index to retrieve faces associated with the captions containing names of the queried person . 
NULL ({ }) We ({ 1 }) indexed ({ 2 }) image ({ 3 }) captions ({ 4 }) and ({ 5 }) then ({ 6 }) used ({ 7 }) this ({ 8 }) index ({ 9 }) to ({ 10 }) retrieve ({ 11 }) faces ({ 12 }) associated ({ 13 }) with ({ 14 }) the ({ 15 }) captions ({ 16 }) containing ({ 17 }) names ({ 18 }) of ({ 19 }) the ({ 20 }) queried ({ 21 }) person ({ 22 }) . ({ 23 }) 
# Sentence pair (910) source length 20 target length 20 alignment score : 0.000420518
The faces retrieved from different names of each person are merged into a set used for our ranking process . 
NULL ({ }) The ({ 1 }) faces ({ 2 }) retrieved ({ 3 }) from ({ 4 }) different ({ 5 }) names ({ 6 }) of ({ 7 }) each ({ 8 }) person ({ 9 }) were ({ 10 }) merged ({ 11 }) into ({ 12 }) a ({ 13 }) set ({ 14 }) used ({ 15 }) for ({ 16 }) our ({ 17 }) ranking ({ 18 }) process ({ 19 }) . ({ 20 }) 
# Sentence pair (911) source length 12 target length 12 alignment score : 0.0245203
Figure \REF shows faces retrieved when searching Mr . Kofi Annan . 
NULL ({ }) Figure ({ 1 }) \REF ({ 2 }) shows ({ 3 }) faces ({ 4 }) retrieved ({ 5 }) when ({ 6 }) searching ({ 7 }) Mr ({ 8 }) . ({ 9 }) Kofi ({ 10 }) Annan ({ 11 }) . ({ 12 }) 
# Sentence pair (912) source length 23 target length 23 alignment score : 5.44465e-05
Figure \REF shows the distribution of retrieved faces from this method and the corresponding number of relevant faces for these ten persons . 
NULL ({ }) Figure ({ 1 }) \REF ({ 2 }) shows ({ 3 }) the ({ 4 }) distribution ({ 5 }) of ({ 6 }) retrieved ({ 7 }) faces ({ 8 }) from ({ 9 }) this ({ 10 }) method ({ 11 }) and ({ 12 }) the ({ 13 }) corresponding ({ 14 }) number ({ 15 }) of ({ 16 }) relevant ({ 17 }) faces ({ 18 }) for ({ 19 }) these ({ 20 }) ten ({ 21 }) individuals ({ 22 }) . ({ 23 }) 
# Sentence pair (913) source length 18 target length 18 alignment score : 0.000210205
In total , 3 , 907 faces are retrieved in which 2 , 094 faces are relevant . 
NULL ({ }) In ({ 1 }) total ({ 2 }) , ({ 3 }) 3 ({ 4 }) , ({ 5 }) 907 ({ 6 }) faces ({ 7 }) were ({ 8 }) retrieved ({ 9 }) in ({ 10 }) which ({ 11 }) 2 ({ 12 }) , ({ 13 }) 094 ({ 14 }) faces ({ 15 }) were ({ 16 }) relevant ({ 17 }) . ({ 18 }) 
# Sentence pair (914) source length 13 target length 8 alignment score : 4.04859e-07
On average , the precision is 52.49% . 
NULL ({ }) On ({ 1 }) average ({ 2 }) , ({ 3 }) the ({ 4 }) precision ({ 5 }) was ({ 6 }) 52.49% ({ 7 }) . ({ 8 }) //[precision ({ }) / ({ }) accuracy ({ }) ? ({ }) ] ({ }) 
# Sentence pair (915) source length 13 target length 13 alignment score : 0.00854115
We used an eye detector to detect eye positions of detected faces . 
NULL ({ }) We ({ 1 }) used ({ 2 }) an ({ 3 }) eye ({ 4 }) detector ({ 5 }) to ({ 6 }) detect ({ 7 }) eye ({ 8 }) positions ({ 9 }) of ({ 10 }) detected ({ 11 }) faces ({ 12 }) . ({ 13 }) 
# Sentence pair (916) source length 14 target length 14 alignment score : 0.00382157
These eye positions were used to align faces to a predefined canonical pose . 
NULL ({ }) These ({ 1 }) eye ({ 2 }) positions ({ 3 }) were ({ 4 }) used ({ 5 }) to ({ 6 }) align ({ 7 }) faces ({ 8 }) to ({ 9 }) a ({ 10 }) predefined ({ 11 }) canonical ({ 12 }) pose ({ 13 }) . ({ 14 }) 
# Sentence pair (917) source length 20 target length 20 alignment score : 0.000229248
To compensate for illumination effects , the subtraction of the bestfit brightness plane followed by histogram equalization was applied . 
NULL ({ }) To ({ 1 }) compensate ({ 2 }) for ({ 3 }) illumination ({ 4 }) effects ({ 5 }) , ({ 6 }) the ({ 7 }) subtraction ({ 8 }) of ({ 9 }) the ({ 10 }) best-fit ({ 11 }) brightness ({ 12 }) plane ({ 13 }) followed ({ 14 }) by ({ 15 }) histogram ({ 16 }) equalization ({ 17 }) was ({ 18 }) applied ({ 19 }) . ({ 20 }) 
# Sentence pair (918) source length 9 target length 9 alignment score : 0.0500067
This normalization process is shown in Figure \REF . 
NULL ({ }) This ({ 1 }) normalization ({ 2 }) process ({ 3 }) is ({ 4 }) shown ({ 5 }) in ({ 6 }) Figure ({ 7 }) \REF ({ 8 }) . ({ 9 }) 
# Sentence pair (919) source length 21 target length 19 alignment score : 1.03682e-07
We then used PCA \CITE to reduce the number of dimensions of the feature vector for face representation . 
NULL ({ }) We ({ 1 }) then ({ 2 }) used ({ 3 }) principle ({ 4 }) component ({ }) analysis ({ }) \CITE ({ 5 }) to ({ 6 }) reduce ({ 7 }) the ({ 8 }) number ({ 9 }) of ({ 10 }) dimensions ({ 11 }) of ({ 12 }) the ({ 13 }) feature ({ 14 }) vector ({ 15 }) for ({ 16 }) face ({ 17 }) representation ({ 18 }) . ({ 19 }) 
# Sentence pair (920) source length 15 target length 16 alignment score : 6.1696e-07
Eigenfaces were computed from the original face set returned by the text based query method . 
NULL ({ }) Eigenfaces ({ 1 }) were ({ 2 }) computed ({ 3 }) from ({ 4 }) the ({ 5 }) original ({ 6 }) face ({ 7 }) set ({ 8 }) returned ({ 9 }) by ({ 10 }) the ({ 11 }) text-based ({ 12 13 }) query ({ 14 }) method ({ 15 }) . ({ 16 }) 
# Sentence pair (921) source length 23 target length 17 alignment score : 1.33306e-12
The number of eigenfaces was selected so that 97% of the total energy are retained \CITE . 
NULL ({ }) A ({ 1 }) number ({ 2 }) of ({ 3 }) eigenfaces ({ 4 }) was ({ 5 }) selected ({ 6 }) so ({ 7 }) that ({ 8 }) 97% ({ 9 }) of ({ 10 }) the ({ 11 }) total ({ 12 }) energy ({ 13 }) was ({ 14 }) retained ({ 15 }) \CITE ({ 16 }) . ({ 17 }) //[What ({ }) is ({ }) that ({ }) number ({ }) ? ({ }) ] ({ }) 
# Sentence pair (922) source length 24 target length 23 alignment score : 7.20501e-06
We evaluated the retrieval performance with measures that are popularly used in information retrieval such as precision , recall and average precision . 
NULL ({ }) We ({ 1 }) evaluated ({ 2 }) the ({ 3 }) retrieval ({ 4 }) performance ({ 5 }) with ({ 6 }) measures ({ 7 }) that ({ 8 }) are ({ 9 }) commonly ({ 10 }) used ({ 11 }) in ({ 12 }) information ({ 13 }) retrieval ({ 14 }) such ({ 15 }) as ({ 16 }) precision ({ 17 }) , ({ 18 }) recall ({ 19 }) , ({ }) and ({ 20 }) average ({ 21 }) precision ({ 22 }) . ({ 23 }) 
# Sentence pair (923) source length 54 target length 40 alignment score : 5.09314e-23
Given a queried person , assuming that \MATH is the total number of faces returned , \MATH is the number of relevant faces , \MATH is the number of relevant faces , we calculate recall and precision as follows : 
NULL ({ }) Given ({ 1 }) a ({ 2 }) queried ({ 3 }) person ({ 4 }) , ({ 5 }) assuming ({ 6 }) that ({ 7 }) \MATH ({ 8 }) is ({ 9 }) the ({ 10 }) total ({ 11 }) number ({ 12 }) of ({ 13 }) faces ({ 14 }) returned ({ 15 }) , ({ 16 }) \MATH ({ 17 }) is ({ 18 }) the ({ 19 }) number ({ 20 }) of ({ 21 }) relevant ({ 22 }) faces ({ 23 }) , ({ 24 }) \MATH ({ 25 }) is ({ 26 }) the ({ 27 }) number ({ 28 }) of ({ 29 }) relevant ({ 30 }) faces ({ 31 }) , ({ 32 }) we ({ 33 }) calculated ({ 34 }) recall ({ 35 }) and ({ 36 }) precision ({ 37 }) as ({ 38 }) follows ({ 39 }) : ({ }) //[Nrel ({ 40 }) and ({ }) Nhit ({ }) are ({ }) exactly ({ }) the ({ }) same ({ }) here ({ }) . ({ }) They ({ }) should ({ }) be ({ }) different ({ }) .] ({ }) 
# Sentence pair (924) source length 15 target length 15 alignment score : 0.00647113
Precision and recall only evaluate the quality of an unordered set of retrieved faces . 
NULL ({ }) Precision ({ 1 }) and ({ 2 }) recall ({ 3 }) only ({ 4 }) evaluate ({ 5 }) the ({ 6 }) quality ({ 7 }) of ({ 8 }) an ({ 9 }) unordered ({ 10 }) set ({ 11 }) of ({ 12 }) retrieved ({ 13 }) faces ({ 14 }) . ({ 15 }) 
# Sentence pair (925) source length 10 target length 11 alignment score : 0.000199035
To evaluate ranked lists , the average precision is used . 
NULL ({ 6 }) To ({ 1 }) evaluate ({ 2 }) ranked ({ 3 }) lists ({ 4 }) , ({ 5 }) average ({ 7 }) precision ({ 8 }) is ({ 9 }) used ({ 10 }) . ({ 11 }) 
# Sentence pair (926) source length 30 target length 29 alignment score : 4.29645e-06
The average precision is computed by taking average of the interpolated precision measured at the 11 recall levels of 0.0 , 0.1 , 0.2 , ... , 1.0 . 
NULL ({ }) The ({ 1 }) average ({ 2 }) precision ({ 3 }) is ({ 4 }) computed ({ 5 }) by ({ 6 }) taking ({ 7 }) the ({ }) average ({ 8 }) of ({ 9 }) the ({ 10 }) interpolated ({ 11 }) precision ({ 12 }) measured ({ 13 }) at ({ 14 }) the ({ 15 }) 11 ({ 16 }) recall ({ 17 }) levels ({ 18 }) of ({ 19 }) 0.0 ({ 20 }) , ({ 21 }) 0.1 ({ 22 }) , ({ 23 }) 0.2 ({ 24 }) , ({ 25 }) ... ({ 26 }) , ({ 27 }) 1.0 ({ 28 }) . ({ 29 }) 
# Sentence pair (927) source length 23 target length 23 alignment score : 0.000377846
The interpolated precision \MATH at a certain recall level \MATH is defined as the highest precision found for any recall level \MATH : 
NULL ({ }) The ({ 1 }) interpolated ({ 2 }) precision ({ 3 }) \MATH ({ 4 }) at ({ 5 }) a ({ 6 }) certain ({ 7 }) recall ({ 8 }) level ({ 9 }) \MATH ({ 10 }) is ({ 11 }) defined ({ 12 }) as ({ 13 }) the ({ 14 }) highest ({ 15 }) precision ({ 16 }) found ({ 17 }) for ({ 18 }) any ({ 19 }) recall ({ 20 }) level ({ 21 }) \MATH ({ 22 }) : ({ 23 }) 
# Sentence pair (928) source length 28 target length 26 alignment score : 1.16215e-07
In addition , to evaluate performance of multiple queries , we used mean average precision that is the mean of average precisions computed from queries . 
NULL ({ }) In ({ 1 }) addition ({ 2 }) , ({ 3 }) to ({ 4 }) evaluate ({ 5 }) the ({ }) performance ({ 6 }) of ({ 7 }) multiple ({ 8 }) queries ({ 9 }) , ({ 10 }) we ({ 11 }) used ({ 12 }) mean ({ 13 }) average ({ 14 }) precision ({ 15 }) , ({ }) which ({ 16 }) is ({ 17 }) the ({ 18 }) mean ({ 19 }) of ({ 20 }) average ({ 21 }) precisions ({ 22 }) computed ({ 23 }) from ({ 24 }) queries ({ 25 }) . ({ 26 }) 
# Sentence pair (929) source length 21 target length 20 alignment score : 0.000138502
We show in Figure \REF the retrieval performance of outliers detection methods and the baseline method using text correlation . 
NULL ({ }) We ({ 1 }) show ({ 2 }) in ({ 3 }) Figure ({ 4 }) \REF ({ 5 }) the ({ 6 }) retrieval ({ 7 }) performance ({ 8 }) of ({ 9 }) the ({ }) outlier ({ 10 }) detection ({ 11 }) methods ({ 12 }) and ({ 13 }) the ({ 14 }) baseline ({ 15 }) method ({ 16 }) using ({ 17 }) text ({ 18 }) correlation ({ 19 }) . ({ 20 }) 
# Sentence pair (930) source length 18 target length 19 alignment score : 1.82248e-06
In the baseline method , faces are sorted by the time that the associated news article is published . 
NULL ({ 12 }) In ({ 1 }) the ({ 2 }) baseline ({ 3 }) method ({ 4 }) , ({ 5 }) faces ({ 6 }) were ({ 7 }) sorted ({ 8 }) by ({ 9 }) the ({ 10 }) time ({ 11 }) the ({ 13 }) associated ({ 14 }) news ({ 15 }) article ({ 16 }) was ({ 17 }) published ({ 18 }) . ({ 19 }) 
# Sentence pair (931) source length 10 target length 9 alignment score : 0.000489217
It indicates that DBO-based method outperforms the others . 
NULL ({ }) It ({ 1 }) indicated ({ 2 }) that ({ 3 }) the ({ }) DBO-based ({ 4 }) method ({ 5 }) outperformed ({ 6 }) the ({ 7 }) others ({ 8 }) . ({ 9 }) 
# Sentence pair (932) source length 7 target length 7 alignment score : 0.00478156
The baseline method performs the worst . 
NULL ({ }) The ({ 1 }) baseline ({ 2 }) method ({ 3 }) performed ({ 4 }) the ({ 5 }) worst ({ 6 }) . ({ 7 }) 
# Sentence pair (933) source length 14 target length 13 alignment score : 0.000611032
LOF-based method tends to be less sensitive when the threshold is changed . 
NULL ({ }) The ({ }) LOF-based ({ 1 }) method ({ 2 }) tends ({ 3 }) to ({ 4 }) be ({ 5 }) less ({ 6 }) sensitive ({ 7 }) when ({ 8 }) the ({ 9 }) threshold ({ 10 }) is ({ 11 }) changed ({ 12 }) . ({ 13 }) 
# Sentence pair (934) source length 11 target length 11 alignment score : 0.0059567
This suggests that the input face sets are quite dense . 
NULL ({ }) This ({ 1 }) suggests ({ 2 }) that ({ 3 }) the ({ 4 }) input ({ 5 }) face ({ 6 }) sets ({ 7 }) were ({ 8 }) quite ({ 9 }) dense ({ 10 }) . ({ 11 }) 
# Sentence pair (935) source length 17 target length 14 alignment score : 5.8905e-06
We studied effect of choosing number of times \MATH in the Bag-Rank-SVM algorithm . 
NULL ({ }) We ({ 1 }) studied ({ 2 }) the ({ }) effect ({ 3 }) of ({ 4 }) choosing ({ 5 }) the ({ }) number ({ 6 }) of ({ 7 }) times ({ 8 }) \MATH ({ 9 }) appeared ({ }) in ({ 10 }) the ({ 11 }) Bag-Rank-SVM ({ 12 }) algorithm ({ 13 }) . ({ 14 }) 
# Sentence pair (936) source length 32 target length 32 alignment score : 8.4847e-07
We used DBO as the method for making the initial rank list from which 30 training subsets were generated and used for training SVM classifiers using linear kernel with probability output . 
NULL ({ }) We ({ 1 }) used ({ 2 }) DBO ({ 3 }) as ({ 4 }) the ({ 5 }) method ({ 6 }) for ({ 7 }) making ({ 8 }) the ({ 9 }) initial ({ 10 }) rank ({ 11 }) list ({ 12 }) from ({ 13 }) which ({ 14 }) 30 ({ 15 }) training ({ 16 }) subsets ({ 17 }) were ({ 18 }) generated ({ 19 }) and ({ 20 }) used ({ 21 }) for ({ 22 }) training ({ 23 }) SVM ({ 24 }) classifiers ({ 25 }) using ({ 26 }) linear ({ 27 }) kernels ({ 28 }) with ({ 29 }) probability ({ 30 }) output ({ 31 }) . ({ 32 }) 
# Sentence pair (937) source length 34 target length 32 alignment score : 8.67586e-08
To select one subset , we set \MATH and \MATH which means 20% of highest ranked faces are used for \MATH and 30% of lowest ranked faces are used for \MATH . 
NULL ({ }) To ({ 1 }) select ({ 2 }) one ({ 3 }) subset ({ 4 }) , ({ 5 }) we ({ 6 }) set ({ 7 }) \MATH ({ 8 }) and ({ 9 }) \MATH ({ 10 }) which ({ 11 }) means ({ 12 }) 20% ({ 13 }) of ({ 14 }) the ({ }) highest ({ 15 }) ranked ({ 16 }) faces ({ 17 }) were ({ 18 }) used ({ 19 }) for ({ 20 }) \MATH ({ 21 }) and ({ 22 }) 30% ({ 23 }) of ({ 24 }) the ({ }) lowest ({ 25 }) ranked ({ 26 }) faces ({ 27 }) were ({ 28 }) used ({ 29 }) for ({ 30 }) \MATH ({ 31 }) . ({ 32 }) 
# Sentence pair (938) source length 36 target length 19 alignment score : 5.57842e-21
The subsets \MATH and \MATH are generated by randomly selecting with replacement 70% samples of \MATH amd \MATH . 
NULL ({ }) The ({ 1 }) subsets ({ 2 }) \MATH ({ 3 }) and ({ 4 }) \MATH ({ 5 }) were ({ 6 }) generated ({ 7 }) by ({ 8 }) randomly ({ 9 }) selecting ({ 10 }) with ({ 11 }) replacement ({ 12 }) 70% ({ 13 }) samples ({ 14 }) of ({ 15 }) \MATH ({ 16 }) and ({ }) \MATH ({ }) .[gWith ({ 17 }) replacementh ({ 18 }) does ({ }) not ({ }) make ({ }) sense ({ }) here ({ }) . ({ 19 }) I ({ }) am ({ }) not ({ }) sure ({ }) what ({ }) you ({ }) want ({ }) to ({ }) say ({ }) .] ({ }) 
# Sentence pair (939) source length 11 target length 11 alignment score : 2.28827e-06
Figure \REF shows performance of single classifiers and ensemble classifiers . 
NULL ({ }) Figure ({ 1 }) \REF ({ 2 }) shows ({ 3 }) the ({ }) performance ({ 4 }) of ({ 5 }) single ({ 6 7 }) and ({ 8 }) ensemble ({ 9 }) classifiers ({ 10 }) . ({ 11 }) 
# Sentence pair (940) source length 13 target length 13 alignment score : 0.00136352
It suggests that the performance does not change significantly after 5 iterations . 
NULL ({ }) It ({ 1 }) suggests ({ 2 }) that ({ 3 }) the ({ 4 }) performance ({ 5 }) does ({ 6 }) not ({ 7 }) change ({ 8 }) significantly ({ 9 }) after ({ 10 }) five ({ 11 }) iterations ({ 12 }) . ({ 13 }) 
# Sentence pair (941) source length 17 target length 17 alignment score : 1.74039e-13
In addition , the performance of the ranking process is improved when using the ensemble classifier . 
NULL ({ 14 }) In ({ 1 }) addition ({ 2 }) , ({ 3 }) the ({ 4 }) performance ({ 5 }) of ({ 6 }) the ({ 7 }) ranking ({ 8 }) process ({ 9 }) improved ({ 11 }) when ({ 12 }) the ({ }) ensemble ({ 13 15 }) classifier ({ 16 }) was ({ 10 }) used ({ }) . ({ 17 }) 
# Sentence pair (942) source length 32 target length 32 alignment score : 5.23907e-09
We set the number of iterations for the Bag-Rank-SVM algorithm being 5 and set the number of iterations of the outer loop $T=30$ to see how much the final performance changes . 
NULL ({ }) We ({ 1 }) set ({ 2 }) the ({ 3 }) number ({ 4 }) of ({ 5 }) iterations ({ 6 }) for ({ 7 }) the ({ 8 }) Bag-Rank-SVM ({ 9 }) algorithm ({ 10 }) at ({ 11 }) five ({ 12 }) and ({ 13 }) set ({ 14 }) the ({ 15 }) number ({ 16 }) of ({ 17 }) iterations ({ 18 }) of ({ 19 }) the ({ 20 }) outer ({ 21 }) loop ({ 22 }) $T=30$ ({ 23 }) to ({ 24 }) see ({ 25 }) how ({ 26 }) much ({ 27 }) the ({ 28 }) final ({ 29 }) performance ({ 30 }) changes ({ 31 }) . ({ 32 }) 
# Sentence pair (943) source length 16 target length 17 alignment score : 5.82582e-08
As shown in Figure \REF , the performance does not change so much after 5 iterations . 
NULL ({ 12 }) As ({ 1 }) shown ({ 2 }) in ({ 3 }) Figure ({ 4 }) \REF ({ 5 }) , ({ 6 }) the ({ 7 }) performance ({ 8 }) did ({ 9 }) not ({ 10 }) change ({ 11 }) much ({ 13 }) after ({ 14 }) five ({ 15 }) iterations ({ 16 }) . ({ 17 }) 
# Sentence pair (944) source length 15 target length 15 alignment score : 0.00411456
From these experiments , \MATH and \MATH are suitable values for the proposed method . 
NULL ({ }) From ({ 1 }) these ({ 2 }) experiments ({ 3 }) , ({ 4 }) \MATH ({ 5 }) and ({ 6 }) \MATH ({ 7 }) are ({ 8 }) suitable ({ 9 }) values ({ 10 }) for ({ 11 }) the ({ 12 }) proposed ({ 13 }) method ({ 14 }) . ({ 15 }) 
# Sentence pair (945) source length 32 target length 33 alignment score : 5.26585e-14
The performance of different methods shown in Figure \REF indicates that our proposed method outperforms the distance-based outliers detection method and has comparable performance with the supervised method using 5% annotation data . 
NULL ({ 24 }) The ({ 1 }) performance ({ 2 }) of ({ 3 }) different ({ 4 }) methods ({ 5 }) shown ({ 6 }) in ({ 7 }) Figure ({ 8 }) \REF ({ 9 }) indicates ({ 10 }) that ({ 11 }) our ({ 12 }) proposed ({ 13 }) method ({ 14 }) outperformed ({ 15 }) the ({ 16 }) distance-based ({ 17 }) outlier ({ 18 }) detection ({ 19 }) method ({ 20 }) and ({ 21 }) performed ({ 22 }) comparable ({ 23 }) to ({ 25 }) the ({ 26 }) supervised ({ 27 }) method ({ 28 }) using ({ 29 }) 5% ({ 30 }) annotation ({ 31 }) data ({ 32 }) . ({ 33 }) 
# Sentence pair (946) source length 35 target length 35 alignment score : 3.49275e-09
As shown in Figure \REF , \REF , \REF , our proposed method produces better results in terms of average precision in which relevant faces are put on the top of the returned list . 
NULL ({ }) As ({ 1 }) shown ({ 2 }) in ({ 3 }) Figures ({ 4 }) \REF ({ 5 }) , ({ 6 }) \REF ({ 7 }) , ({ 8 }) \REF ({ 9 }) , ({ 10 }) our ({ 11 }) proposed ({ 12 }) method ({ 13 }) produced ({ 14 }) better ({ 15 }) results ({ 16 }) in ({ 17 }) terms ({ 18 }) of ({ 19 }) average ({ 20 }) precision ({ 21 }) in ({ 22 }) which ({ 23 }) relevant ({ 24 }) faces ({ 25 }) were ({ 26 }) put ({ 27 }) at ({ 28 }) the ({ 29 }) top ({ 30 }) of ({ 31 }) the ({ 32 }) returned ({ 33 }) list ({ 34 }) . ({ 35 }) 
# Sentence pair (947) source length 20 target length 19 alignment score : 9.40294e-11
We present a method to effectively rank faces retrieved by text-based correlation methods when searching a specific person . 
NULL ({ }) We ({ 1 }) presented ({ 2 }) a ({ 3 }) method ({ 4 }) for ({ 5 }) effectively ({ 6 }) ranking ({ 7 }) faces ({ 8 }) retrieved ({ 9 }) using ({ 10 }) text-based ({ 11 }) correlation ({ 12 }) methods ({ 13 }) when ({ 14 }) searching ({ 15 }) for ({ }) a ({ 16 }) specific ({ 17 }) person ({ 18 }) . ({ 19 }) 
# Sentence pair (948) source length 51 target length 30 alignment score : 7.1958e-30
Using the rank list estimated from the previous steps , we automatically select a subset of positive and negative samples to train a classifier using SVM with probability outputs . 
NULL ({ }) Using ({ 1 }) the ({ 2 }) rank ({ 3 }) list ({ 4 }) estimated ({ 5 }) from ({ 6 }) the ({ 7 }) previous ({ 8 }) steps ({ 9 }) , ({ 10 }) we ({ 11 }) automatically ({ 12 }) selected ({ }) a ({ 14 }) subset ({ 15 }) of ({ 16 }) positive ({ 17 }) and ({ 18 }) negative ({ 19 }) samples ({ 20 }) to ({ 21 }) train ({ 22 }) a ({ 23 }) classifier ({ 24 }) using ({ 25 }) SVM ({ 26 }) with ({ 27 }) probability ({ 28 }) outputs ({ 29 }) . ({ 30 }) //[Since ({ }) this ({ }) is ({ }) the ({ }) conclusion ({ }) , ({ }) you ({ }) might ({ }) want ({ }) to ({ }) be ({ }) more ({ }) specific ({ }) on ({ }) what ({ }) gthe ({ }) previous ({ }) stepsh ({ 13 }) are ({ }) . ({ }) ] ({ }) 
# Sentence pair (949) source length 13 target length 13 alignment score : 0.00513336
This classifier is used to rank input faces for the next step . 
NULL ({ }) This ({ 1 }) classifier ({ 2 }) was ({ 3 }) used ({ 4 }) to ({ 5 }) rank ({ 6 }) input ({ 7 }) faces ({ 8 }) for ({ 9 }) the ({ 10 }) next ({ 11 }) step ({ 12 }) . ({ 13 }) 
# Sentence pair (950) source length 19 target length 18 alignment score : 2.38085e-09
Since labels of training sets are still noisy , the classified trained by these datasets are weak . 
NULL ({ }) Since ({ 1 }) the ({ }) labels ({ 2 }) of ({ 3 }) training ({ 4 }) sets ({ 5 }) were ({ 6 }) still ({ 7 }) noisy ({ 8 }) , ({ 9 }) the ({ 10 }) classifiers ({ 11 }) trained ({ 12 }) from ({ 13 }) these ({ 14 }) datasets ({ 15 }) were ({ 16 }) weak ({ 17 }) . ({ 18 }) 
# Sentence pair (951) source length 22 target length 21 alignment score : 3.55163e-14
By combining multiple weak classifiers in a bagging framework , the final strong classifier is constructed and produce good results . 
NULL ({ 15 }) By ({ 1 }) combining ({ 2 }) multiple ({ 3 }) weak ({ 4 }) classifiers ({ 5 }) in ({ 6 }) a ({ 7 }) bagging ({ 8 }) framework ({ 9 }) , ({ 10 }) we ({ }) constructed ({ 16 }) the ({ 11 }) final ({ 12 }) strong ({ 13 }) classifier ({ 14 }) , ({ }) which ({ 17 }) produced ({ 18 }) good ({ 19 }) results ({ 20 }) . ({ 21 }) 
# Sentence pair (952) source length 19 target length 18 alignment score : 5.59863e-11
To get initial rank for the first step , we propose to use common outliers detection method . 
NULL ({ 12 }) To ({ 1 }) obtain ({ 2 }) the ({ }) initial ({ 3 }) rank ({ 4 }) for ({ 5 }) the ({ 6 }) first ({ 7 }) step ({ 8 }) , ({ 9 }) we ({ 10 }) proposed ({ 11 }) using ({ 13 }) a ({ }) common ({ 14 }) outlier ({ 15 }) detection ({ 16 }) method ({ 17 }) . ({ 18 }) 
# Sentence pair (953) source length 20 target length 19 alignment score : 3.05115e-05
Experiments on a large number of persons with thousands of retrieved images show effectiveness of the proposed method . 
NULL ({ }) Experiments ({ 1 }) on ({ 2 }) a ({ 3 }) large ({ 4 }) number ({ 5 }) of ({ 6 }) persons ({ 7 }) with ({ 8 }) thousands ({ 9 }) of ({ 10 }) retrieved ({ 11 }) images ({ 12 }) showed ({ 13 }) the ({ }) effectiveness ({ 14 }) of ({ 15 }) the ({ 16 }) proposed ({ 17 }) method ({ 18 }) . ({ 19 }) 
# Sentence pair (954) source length 10 target length 10 alignment score : 0.0379163
Face detection , tracking , and recognition for broadcast video 
NULL ({ }) Face ({ 1 }) detection ({ 2 }) , ({ 3 }) tracking ({ 4 }) , ({ 5 }) and ({ 6 }) recognition ({ 7 }) for ({ 8 }) broadcast ({ 9 }) video ({ 10 }) 
# Sentence pair (955) source length 52 target length 43 alignment score : 5.43749e-26
Human face processing techniques for broadcast video including face detection , tracking and recognition have long been a topic that attracts much research interest due to its crucial value in various applications including video structuring , indexing , retrieval , summarization , etc. 
NULL ({ 42 }) Human ({ 1 }) face ({ 2 }) processing ({ 3 }) techniques ({ 4 }) for ({ 5 }) broadcast ({ 6 }) video ({ 7 }) , ({ }) including ({ 8 }) face ({ 9 }) detection ({ 10 }) , ({ 11 }) tracking ({ 12 }) , ({ }) and ({ 13 }) recognition ({ 14 }) , ({ }) have ({ 15 }) long ({ 16 }) been ({ 17 }) a ({ 18 }) topic ({ 19 }) that ({ 20 }) has ({ }) attracted ({ 21 }) a ({ }) lot ({ 22 }) of ({ }) research ({ 23 }) interest ({ 24 }) due ({ 25 }) to ({ 26 }) its ({ 27 }) crucial ({ 28 }) value ({ 29 }) in ({ 30 }) various ({ 31 }) applications ({ 32 }) , ({ }) such ({ }) as ({ 33 }) in ({ }) video ({ 34 }) structuring ({ 35 }) , ({ 36 }) indexing ({ 37 }) , ({ 38 }) retrieval ({ 39 }) , ({ 40 }) and ({ }) summarization ({ 41 }) . ({ 43 }) 
# Sentence pair (956) source length 50 target length 44 alignment score : 7.50279e-15
The main reason is human face provides rich information for people 's appearance such as a government leader in a news video , a pitcher in a sport video or a hero in a movie , and is the basis for interpreting facts . 
NULL ({ }) The ({ 1 }) main ({ 2 }) reason ({ 3 }) for ({ }) this ({ }) is ({ 4 }) that ({ }) the ({ }) human ({ 5 }) face ({ 6 }) provides ({ 7 }) rich ({ 8 }) information ({ 9 }) for ({ 10 }) people ({ 11 }) 's ({ 12 }) appearances ({ 13 }) , ({ }) such ({ 14 }) as ({ 15 }) for ({ }) a ({ 16 }) government ({ 17 }) leader ({ 18 }) in ({ 19 }) a ({ 20 }) news ({ 21 }) video ({ 22 }) , ({ 23 }) a ({ 24 }) pitcher ({ 25 }) in ({ 26 }) a ({ 27 }) sports ({ 28 }) video ({ 29 }) or ({ 30 }) a ({ 31 }) hero ({ 32 }) in ({ 33 }) a ({ 34 }) movie ({ 35 }) , ({ 36 }) and ({ 37 }) is ({ 38 }) the ({ 39 }) basis ({ 40 }) for ({ 41 }) interpreting ({ 42 }) facts ({ 43 }) . ({ 44 }) 
# Sentence pair (957) source length 21 target length 19 alignment score : 2.49085e-07
This article describes state-of-the art techniques for face detection , tracking and recognition with application to broadcast video . 
NULL ({ }) This ({ 1 }) article ({ 2 }) describes ({ 3 }) some ({ }) state-of-the ({ 4 }) art ({ 5 }) techniques ({ 6 }) for ({ 7 }) face ({ 8 }) detection ({ 9 }) , ({ 10 }) tracking ({ 11 }) , ({ }) and ({ 12 }) recognition ({ 13 }) with ({ 14 }) applications ({ 15 }) to ({ 16 }) broadcast ({ 17 }) video ({ 18 }) . ({ 19 }) 
# Sentence pair (958) source length 25 target length 21 alignment score : 1.01141e-08
Face detection which is the task of localizing faces in an input image is fundamental for any face processing system . 
NULL ({ }) Face ({ 1 }) detection ({ 2 }) , ({ }) which ({ 3 }) is ({ 4 }) the ({ 5 }) task ({ 6 }) of ({ 7 }) localizing ({ 8 }) faces ({ 9 }) in ({ 10 }) an ({ 11 }) input ({ 12 }) image ({ 13 }) , ({ }) is ({ 14 }) a ({ }) fundamental ({ 15 }) part ({ 16 }) of ({ }) any ({ 17 }) face ({ 18 }) processing ({ 19 }) system ({ 20 }) . ({ 21 }) 
# Sentence pair (959) source length 16 target length 17 alignment score : 1.36463e-06
The extracted faces can then be used for initializing of face tracking or automatic face recognition . 
NULL ({ 10 }) The ({ 1 }) extracted ({ 2 }) faces ({ 3 }) can ({ 4 }) then ({ 5 }) be ({ 6 }) used ({ 7 }) for ({ 8 }) initializing ({ 9 }) face ({ 11 }) tracking ({ 12 }) or ({ 13 }) automatic ({ 14 }) face ({ 15 }) recognition ({ 16 }) . ({ 17 }) 
# Sentence pair (960) source length 10 target length 10 alignment score : 0.0202931
An ideal face detector should possess the following characteristics : 
NULL ({ }) An ({ 1 }) ideal ({ 2 }) face ({ 3 }) detector ({ 4 }) should ({ 5 }) possess ({ 6 }) the ({ 7 }) following ({ 8 }) characteristics ({ 9 }) : ({ 10 }) 
# Sentence pair (961) source length 33 target length 31 alignment score : 1.64594e-17
- Robustness : it should be capable of handling appearance variations of pose changes , size , illuminations , occlusions , complex background , facial expressions , low resolutions , etc. 
NULL ({ 12 30 }) - ({ 1 }) Robustness ({ 2 }) : ({ 3 }) it ({ 4 }) should ({ 5 }) be ({ 6 }) capable ({ 7 }) of ({ 8 }) handling ({ 9 }) appearance ({ 10 }) variations ({ 11 }) , ({ }) such ({ }) as ({ }) pose ({ 13 }) changes ({ 14 }) , ({ 15 }) size ({ 16 }) , ({ 17 }) illuminations ({ 18 }) , ({ 19 }) occlusions ({ 20 }) , ({ 21 }) complex ({ 22 }) backgrounds ({ 23 }) , ({ 24 }) facial ({ 25 }) expressions ({ 26 }) , ({ 27 }) and ({ }) low ({ 28 }) resolutions ({ 29 }) . ({ 31 }) 
# Sentence pair (962) source length 25 target length 21 alignment score : 1.06245e-09
- Fastness : it should be fast for real-time processing which is an important factor in processing large video archives . 
NULL ({ }) - ({ 1 }) Quickness ({ 2 }) : ({ 3 }) it ({ 4 }) should ({ 5 }) be ({ 6 }) fast ({ 7 }) in ({ }) order ({ }) to ({ }) perform ({ 8 }) real-time ({ 9 }) processing ({ 10 }) , ({ }) which ({ 11 }) is ({ 12 }) an ({ 13 }) important ({ 14 }) factor ({ 15 }) in ({ 16 }) processing ({ 17 }) large ({ 18 }) video ({ 19 }) archives ({ 20 }) . ({ 21 }) 
# Sentence pair (963) source length 10 target length 10 alignment score : 2.14191e-06
- Simplicity : The training process should be simple . 
NULL ({ }) - ({ 1 }) Simplicity ({ 2 }) : ({ 3 }) the ({ 4 }) training ({ 5 }) process ({ 6 }) should ({ 7 }) be ({ 8 }) simple ({ 9 }) . ({ 10 }) 
# Sentence pair (964) source length 23 target length 23 alignment score : 3.25679e-07
For example , the training time is short , the number of parameters is small and training samples are collected without costly . 
NULL ({ }) For ({ 1 }) example ({ 2 }) , ({ 3 }) the ({ 4 }) training ({ 5 }) time ({ 6 }) is ({ 7 }) short ({ 8 }) , ({ 9 }) the ({ 10 }) number ({ 11 }) of ({ 12 }) parameters ({ 13 }) is ({ 14 }) small ({ 15 }) , ({ }) and ({ 16 }) training ({ 17 }) samples ({ 18 }) are ({ 19 }) collected ({ 20 }) cheaply ({ 21 22 }) . ({ 23 }) 
# Sentence pair (965) source length 15 target length 14 alignment score : 2.39e-05
Many approaches have been proposed for building fast and robust face detectors \CITE . 
NULL ({ }) Many ({ 1 }) approaches ({ 2 }) have ({ 3 }) been ({ 4 }) proposed ({ 5 }) for ({ 6 }) building ({ 7 }) faster ({ 8 }) and ({ 9 }) more ({ }) robust ({ 10 }) face ({ 11 }) detectors ({ 12 }) \CITE ({ 13 }) . ({ 14 }) 
# Sentence pair (966) source length 24 target length 22 alignment score : 3.89394e-06
Among them , those using advanced learning methods such as neural network , support vector machines and boosting are the best . 
NULL ({ }) Among ({ 1 }) them ({ 2 }) , ({ 3 }) those ({ 4 }) using ({ 5 }) advanced ({ 6 }) learning ({ 7 }) methods ({ 8 }) , ({ }) such ({ 9 }) as ({ 10 }) neural ({ 11 }) network ({ 12 }) , ({ 13 }) support ({ 14 }) vector ({ 15 }) machines ({ 16 }) and ({ 17 }) boosting ({ 18 }) , ({ }) are ({ 19 }) the ({ 20 }) best ({ 21 }) . ({ 22 }) 
# Sentence pair (967) source length 13 target length 12 alignment score : 0.000215087
Typically , detecting faces in an image includes the following steps : 
NULL ({ }) Typically ({ 1 }) , ({ 2 }) detecting ({ 3 }) the ({ }) faces ({ 4 }) in ({ 5 }) an ({ 6 }) image ({ 7 }) takes ({ 8 }) the ({ 9 }) following ({ 10 }) steps ({ 11 }) : ({ 12 }) 
# Sentence pair (968) source length 38 target length 36 alignment score : 5.7272e-09
- Window scanning : in order to detect faces at multiple locations and sizes , a fixed window size ( e.g. 24x24 pixels ) is used to extract image patterns at every location and scale . 
NULL ({ }) - ({ 1 }) Window ({ 2 }) scanning ({ 3 }) : ({ 4 }) in ({ 5 }) order ({ 6 }) to ({ 7 }) detect ({ 8 }) faces ({ 9 }) at ({ 10 }) multiple ({ 11 }) locations ({ 12 }) and ({ 13 }) sizes ({ 14 }) , ({ 15 }) a ({ 16 }) fixed ({ 17 }) window ({ 18 }) size ({ 19 }) ( ({ 20 }) e.g. ({ 21 }) 24 ({ }) x ({ }) 24 ({ 22 }) pixels ({ 23 }) ) ({ 24 }) is ({ 25 }) used ({ 26 }) to ({ 27 }) extract ({ 28 }) image ({ 29 }) patterns ({ 30 }) at ({ 31 }) every ({ 32 }) location ({ 33 }) and ({ 34 }) scale ({ 35 }) . ({ 36 }) 
# Sentence pair (969) source length 31 target length 27 alignment score : 8.74369e-10
The number of patterns extracted from one 320x240 frame image is large , approximately 160 ,000 in which only a small number of patterns containing face . 
NULL ({ }) The ({ 1 }) number ({ 2 }) of ({ 3 }) patterns ({ 4 }) extracted ({ 5 }) from ({ 6 }) a ({ }) 320 ({ 7 }) x ({ }) 240 ({ 8 }) frame ({ 9 }) image ({ 10 }) is ({ 11 }) large ({ 12 }) , ({ 13 }) approximately ({ 14 }) 160 ({ 15 }) ,000 ({ 16 }) , ({ }) in ({ 17 }) which ({ 18 }) only ({ 19 }) a ({ 20 }) small ({ 21 }) number ({ 22 }) of ({ 23 }) patterns ({ 24 }) contain ({ 25 }) a ({ }) face ({ 26 }) . ({ 27 }) 
# Sentence pair (970) source length 14 target length 13 alignment score : 0.00248108
- Feature extraction : given an image pattern , features are extracted . 
NULL ({ }) - ({ 1 }) Feature ({ 2 }) extraction ({ 3 }) : ({ 4 }) given ({ 5 }) an ({ 6 }) image ({ 7 }) pattern ({ 8 }) , ({ 9 }) the ({ }) features ({ 10 }) are ({ 11 }) extracted ({ 12 }) . ({ 13 }) 
# Sentence pair (971) source length 22 target length 21 alignment score : 1.20357e-05
The most popular feature type is Haar wavelet since it is very fast to compute using the integral image \CITE . 
NULL ({ }) The ({ 1 }) most ({ 2 }) popular ({ 3 }) feature ({ 4 }) type ({ 5 }) is ({ 6 }) the ({ }) Haar ({ 7 }) wavelet ({ 8 }) because ({ 9 }) it ({ 10 }) is ({ 11 }) very ({ 12 }) fast ({ 13 }) to ({ 14 }) compute ({ 15 }) using ({ 16 }) the ({ 17 }) integral ({ 18 }) image ({ 19 }) \CITE ({ 20 }) . ({ 21 }) 
# Sentence pair (972) source length 23 target length 21 alignment score : 3.37546e-05
Other feature types can be listed including pixel intensity \CITE , local binary patterns \CITE and edge orientation histogram \CITE . 
NULL ({ }) Other ({ 1 }) feature ({ 2 }) types ({ 3 }) can ({ 4 }) be ({ 5 }) listed ({ 6 }) including ({ 7 }) the ({ }) pixel ({ 8 }) intensity ({ 9 }) \CITE ({ 10 }) , ({ 11 }) local ({ 12 }) binary ({ 13 }) patterns ({ 14 }) \CITE ({ 15 }) , ({ }) and ({ 16 }) edge ({ 17 }) orientation ({ 18 }) histogram ({ 19 }) \CITE ({ 20 }) . ({ 21 }) 
# Sentence pair (973) source length 36 target length 31 alignment score : 2.46064e-15
- Classification : the extracted features is passed through a classifier which is trained beforehand to classify the input pattern associated with these features as a face or a non-face . 
NULL ({ }) - ({ 1 }) Classification ({ 2 }) : ({ 3 }) the ({ 4 }) extracted ({ 5 }) features ({ 6 }) are ({ 7 }) passed ({ 8 }) through ({ 9 }) a ({ 10 }) classifier ({ 11 }) that ({ 12 }) has ({ 13 }) been ({ }) previously ({ }) trained ({ 14 }) to ({ 16 }) classify ({ 17 }) the ({ 18 }) input ({ 19 }) pattern ({ 20 }) associated ({ 21 }) with ({ 22 }) these ({ 23 }) features ({ 24 }) as ({ 25 }) a ({ 26 }) face ({ 27 }) or ({ 28 }) a ({ 29 }) non-face ({ 30 }) . ({ 31 }) //[trained ({ }) / ({ }) programmed ({ 15 }) ?] ({ }) 
# Sentence pair (974) source length 27 target length 27 alignment score : 6.87712e-05
- Merging overlapping detections : since the classifier is insensitive to small changes in translation and scale , there might be multiple detections around each face . 
NULL ({ }) - ({ 1 }) Merging ({ 2 }) overlapping ({ 3 }) detections ({ 4 }) : ({ 5 }) since ({ 6 }) the ({ 7 }) classifier ({ 8 }) is ({ 9 }) insensitive ({ 10 }) to ({ 11 }) small ({ 12 }) changes ({ 13 }) in ({ 14 }) translation ({ 15 }) and ({ 16 }) scale ({ 17 }) , ({ 18 }) there ({ 19 }) might ({ 20 }) be ({ 21 }) multiple ({ 22 }) detections ({ 23 }) around ({ 24 }) each ({ 25 }) face ({ 26 }) . ({ 27 }) 
# Sentence pair (975) source length 24 target length 22 alignment score : 4.58992e-07
In order to return one final detection per face , it is necessary to combine overlapping detections into a single detection . 
NULL ({ }) In ({ 1 }) order ({ 2 }) to ({ 3 }) return ({ 4 }) a ({ }) single ({ 5 }) final ({ 6 }) detection ({ 7 }) per ({ 8 }) face ({ 9 }) , ({ 10 }) it ({ 11 }) is ({ 12 }) necessary ({ 13 }) to ({ 14 }) combine ({ 15 }) the ({ }) overlapping ({ 16 }) detections ({ 17 }) into ({ 18 }) a ({ 19 }) single ({ 20 }) detection ({ 21 }) . ({ 22 }) 
# Sentence pair (976) source length 33 target length 36 alignment score : 3.38658e-31
Since the number of processed patterns is large while the vast majority of them are non-face , a single classifier based systems such as neural network \CITE and support vector machines \CITE are usually slow . 
NULL ({ 7 10 13 14 }) Since ({ 1 }) the ({ 2 }) vast ({ 3 8 11 }) majority ({ 9 12 }) of ({ 4 }) processed ({ 5 }) patterns ({ 6 }) are ({ 15 }) non-face ({ 16 }) , ({ 17 }) the ({ 18 }) single ({ 19 }) classifier ({ 20 }) based ({ 21 }) systems ({ 22 }) , ({ }) such ({ 23 }) as ({ 24 }) the ({ }) neural ({ 25 }) network ({ 26 }) \CITE ({ 27 }) and ({ 28 }) the ({ }) support ({ 29 }) vector ({ 30 }) machines ({ 31 }) \CITE ({ 32 }) , ({ }) are ({ 33 }) usually ({ 34 }) slow ({ 35 }) . ({ 36 }) 
# Sentence pair (977) source length 26 target length 26 alignment score : 4.1923e-05
To overcome this problem , a combination of simple-to-complex classifiers has been proposed \CITE leading to the first real-time robust face detector in the world . 
NULL ({ }) To ({ 1 }) overcome ({ 2 }) this ({ 3 }) problem ({ 4 }) , ({ 5 }) a ({ 6 }) combination ({ 7 }) of ({ 8 }) simple-to-complex ({ 9 }) classifiers ({ 10 }) has ({ 11 }) been ({ 12 }) proposed ({ 13 }) \CITE ({ 14 }) leading ({ 15 }) to ({ 16 }) the ({ 17 }) first ({ 18 }) real-time ({ 19 }) robust ({ 20 }) face ({ 21 }) detector ({ 22 }) in ({ 23 }) the ({ 24 }) world ({ 25 }) . ({ 26 }) 
# Sentence pair (978) source length 41 target length 39 alignment score : 1.31504e-17
In this structure , fast and simple classifiers are used as filters at the earliest stages to quickly reject a large number of non-face patterns and slower yet more accurate classifiers are then used for classifying face-like patterns . 
NULL ({ }) In ({ 1 }) this ({ 2 }) structure ({ 3 }) , ({ 4 }) fast ({ 5 }) and ({ 6 }) simple ({ 7 }) classifiers ({ 8 }) are ({ 9 }) used ({ 10 }) as ({ 11 }) filters ({ 12 }) in ({ 13 }) the ({ 14 }) earliest ({ 15 }) stages ({ 16 }) to ({ 17 }) quickly ({ 18 }) reject ({ 19 }) a ({ 20 }) large ({ 21 }) number ({ 22 }) of ({ 23 }) the ({ }) non-face ({ 24 }) patterns ({ 25 }) and ({ 26 }) then ({ 33 }) slower ({ 27 }) but ({ 28 }) more ({ 29 }) accurate ({ 30 }) classifiers ({ 31 }) are ({ 32 }) used ({ 34 }) for ({ 35 }) classifying ({ 36 }) the ({ }) face-like ({ 37 }) patterns ({ 38 }) . ({ 39 }) 
# Sentence pair (979) source length 22 target length 21 alignment score : 4.01904e-09
In this way , the complexity of classifiers can be adapted corresponding to the increasing difficulty in the input patterns . 
NULL ({ 17 }) In ({ 1 }) this ({ 2 }) way ({ 3 }) , ({ 4 }) the ({ 5 }) complexity ({ 6 }) of ({ 7 }) classifiers ({ 8 }) can ({ 9 }) be ({ 10 }) adapted ({ 11 }) to ({ }) correspond ({ 12 }) to ({ 13 }) the ({ 14 }) increasing ({ 15 }) difficulty ({ 16 }) with ({ }) the ({ 18 }) input ({ 19 }) patterns ({ 20 }) . ({ 21 }) 
# Sentence pair (980) source length 9 target length 8 alignment score : 4.44684e-05
Training classifiers usually consists of several steps : 
NULL ({ }) Training ({ 1 }) classifiers ({ 2 }) usually ({ 3 }) consist ({ 4 }) of ({ 5 }) the ({ }) following ({ 6 }) steps ({ 7 }) : ({ 8 }) 
# Sentence pair (981) source length 20 target length 20 alignment score : 0.000856115
- Training set preparation : Supervised learning methods require a large number of training samples to obtain accurate classifiers . 
NULL ({ }) - ({ 1 }) Training ({ 2 }) set ({ 3 }) preparation ({ 4 }) : ({ 5 }) Supervised ({ 6 }) learning ({ 7 }) methods ({ 8 }) require ({ 9 }) a ({ 10 }) large ({ 11 }) number ({ 12 }) of ({ 13 }) training ({ 14 }) samples ({ 15 }) to ({ 16 }) obtain ({ 17 }) accurate ({ 18 }) classifiers ({ 19 }) . ({ 20 }) 
# Sentence pair (982) source length 24 target length 24 alignment score : 2.88341e-07
The training samples are patterns that must be labeled as face ( positive sample ) or non-face ( negative sample ) in advance . 
NULL ({ }) The ({ 1 }) training ({ 2 }) samples ({ 3 }) are ({ 4 }) patterns ({ 5 }) that ({ 6 }) must ({ 7 }) be ({ 8 }) labeled ({ 9 }) as ({ 10 }) face ({ 11 }) ( ({ 12 }) positive ({ 13 }) samples ({ 14 }) ) ({ 15 }) or ({ 16 }) non-face ({ 17 }) ( ({ 18 }) negative ({ 19 }) samples ({ 20 }) ) ({ 21 }) in ({ 22 }) advance ({ 23 }) . ({ 24 }) 
# Sentence pair (983) source length 35 target length 32 alignment score : 2.2809e-10
Face patterns are manually collected in images containing faces and then are scaled to the same size and normalized to a canonical pose which eyes , mouth and nose are aligned . 
NULL ({ }) Face ({ 1 }) patterns ({ 2 }) are ({ 3 }) manually ({ 4 }) collected ({ 5 }) from ({ 6 }) images ({ 7 }) containing ({ 8 }) faces ({ 9 }) and ({ 10 }) then ({ 11 }) are ({ 12 }) scaled ({ 13 }) to ({ 14 }) the ({ 15 }) same ({ 16 }) size ({ 17 }) and ({ 18 }) normalized ({ 19 }) to ({ 20 }) a ({ 21 }) canonical ({ 22 }) pose ({ 23 }) in ({ }) which ({ 24 }) the ({ }) eyes ({ 25 }) , ({ 26 }) mouth ({ 27 }) , ({ }) and ({ 28 }) nose ({ 29 }) are ({ 30 }) aligned ({ 31 }) . ({ 32 }) 
# Sentence pair (984) source length 56 target length 52 alignment score : 5.86463e-14
Then these face patterns can be used to generate other artificial faces by randomly rotating the images ( about their center points ) up to 10 degree , scaling between 90% and 110% , translating up to half a pixel , and mirroring to enlarge the number of positive samples \CITE . 
NULL ({ }) Then ({ 1 }) these ({ 2 }) face ({ 3 }) patterns ({ 4 }) can ({ 5 }) be ({ 6 }) used ({ 7 }) to ({ 8 }) generate ({ 9 }) other ({ 10 }) artificial ({ 11 }) faces ({ 12 }) by ({ 13 }) randomly ({ 14 }) rotating ({ 15 }) the ({ 16 }) images ({ 17 }) ( ({ 18 }) about ({ 19 }) their ({ 20 }) center ({ 21 }) points ({ 22 }) ) ({ 23 }) by ({ }) up ({ 24 }) to ({ 25 }) 10 ({ 26 }) degrees ({ 27 }) , ({ 28 }) scaling ({ 29 }) them ({ }) between ({ 30 }) 90 ({ 31 }) and ({ 32 }) 110% ({ 33 }) , ({ 34 }) translating ({ 35 }) them ({ }) up ({ 36 }) to ({ 37 }) half ({ 38 }) a ({ 39 }) pixel ({ 40 }) , ({ 41 }) and ({ 42 }) mirroring ({ 43 }) them ({ }) to ({ 44 }) enlarge ({ 45 }) the ({ 46 }) number ({ 47 }) of ({ 48 }) positive ({ 49 }) samples ({ 50 }) \CITE ({ 51 }) . ({ 52 }) 
# Sentence pair (985) source length 18 target length 16 alignment score : 3.28634e-08
Collecting non-face patterns are usually done automatically by scanning through images which contain no faces . 
NULL ({ }) The ({ }) collection ({ 1 }) of ({ }) non-face ({ 2 }) patterns ({ 3 }) is ({ 4 }) usually ({ 5 }) done ({ 6 }) automatically ({ 7 }) by ({ 8 }) scanning ({ 9 }) through ({ 10 }) images ({ 11 }) which ({ 12 }) contain ({ 13 }) no ({ 14 }) faces ({ 15 }) . ({ 16 }) 
# Sentence pair (986) source length 27 target length 26 alignment score : 1.89923e-06
The accurate classifier described in \CITE requires about five thousand original face patterns and hundreds of million non-face patterns extracted from 9 ,500 non-face images . 
NULL ({ }) The ({ 1 }) accurate ({ 2 }) classifier ({ 3 }) described ({ 4 }) in ({ 5 }) \CITE ({ 6 }) requires ({ 7 }) about ({ 8 }) five ({ 9 }) thousand ({ 10 }) original ({ 11 }) face ({ 12 }) patterns ({ 13 }) and ({ 14 }) hundreds ({ 15 }) of ({ 16 }) millions ({ 17 }) of ({ }) non-face ({ 18 }) patterns ({ 19 }) extracted ({ 20 }) from ({ 21 }) 9 ({ 22 }) ,500 ({ 23 }) non-face ({ 24 }) images ({ 25 }) . ({ 26 }) 
# Sentence pair (987) source length 24 target length 24 alignment score : 1.08196e-08
In \CITE a smaller number of training samples can be used to build a robust face detector by using edge orientation histogram feature . 
NULL ({ }) In ({ 1 }) \CITE ({ 2 }) a ({ 3 }) smaller ({ 4 }) number ({ 5 }) of ({ 6 }) training ({ 7 }) samples ({ 8 }) can ({ 9 }) be ({ 10 }) used ({ 11 }) to ({ 12 }) build ({ 13 }) a ({ 14 }) robust ({ 15 }) face ({ 16 }) detector ({ 17 }) by ({ 18 }) using ({ 19 }) an ({ }) edge ({ 20 }) orientation ({ 21 }) histogram ({ 22 23 }) . ({ 24 }) 
# Sentence pair (988) source length 38 target length 32 alignment score : 9.88947e-17
- Learning method selection : Basically , in the ideal case with proper settings , advanced learning methods such as neural network , support vector machines and AdaBoost produce similar performance . 
NULL ({ }) - ({ 1 }) Learning ({ 2 }) method ({ 3 }) selection ({ 4 }) : ({ 5 }) Basically ({ 6 }) , ({ 7 }) in ({ 8 }) an ({ 9 }) ideal ({ 10 }) situation ({ 11 }) with ({ 12 }) the ({ }) proper ({ 13 }) settings ({ 14 }) , ({ 15 }) the ({ }) advanced ({ 16 }) learning ({ 17 }) methods ({ 18 }) , ({ }) such ({ 19 }) as ({ 20 }) the ({ }) neural ({ 21 }) network ({ 22 }) , ({ 23 }) support ({ 24 }) vector ({ 25 }) machines ({ 26 }) , ({ }) and ({ 27 }) AdaBoost ({ 28 }) , ({ }) can ({ 29 }) perform ({ 30 }) similarly ({ 31 }) . ({ 32 }) 
# Sentence pair (989) source length 14 target length 14 alignment score : 0.00503545
However , in practice , it is difficult to find these proper settings . 
NULL ({ }) However ({ 1 }) , ({ 2 }) in ({ 3 }) practice ({ 4 }) , ({ 5 }) it ({ 6 }) is ({ 7 }) difficult ({ 8 }) to ({ 9 }) find ({ 10 }) these ({ 11 }) proper ({ 12 }) settings ({ 13 }) . ({ 14 }) 
# Sentence pair (990) source length 18 target length 15 alignment score : 1.34086e-07
Using neural network requires the design of layers , nodes , etc.hich is complicated . 
NULL ({ }) Using ({ 1 }) a ({ }) neural ({ 2 }) network ({ 3 }) requires ({ 4 }) the ({ 5 }) design ({ 6 }) of ({ 7 }) layers ({ 8 }) , ({ 9 }) nodes ({ 10 }) , ({ 11 }) etc. ({ 12 }) , ({ }) which ({ }) is ({ 13 }) complicated ({ 14 }) . ({ 15 }) 
# Sentence pair (991) source length 28 target length 28 alignment score : 2.02011e-21
Therefore , it is preferable to use support vector machines since the number of parameters is only two if using RBF kernel and many tools are available . 
NULL ({ 12 14 }) Therefore ({ 1 }) , ({ 2 }) it ({ 3 }) is ({ 4 }) preferable ({ 5 }) to ({ 6 }) use ({ 7 }) support ({ 8 }) vector ({ 9 }) machines ({ 10 }) because ({ 11 }) only ({ 17 }) two ({ 18 }) parameters ({ 15 }) are ({ }) necessary ({ 13 }) if ({ 19 }) a ({ }) RBF ({ 21 }) kernel ({ 22 }) is ({ 16 }) used ({ 20 }) and ({ 23 }) many ({ 24 }) tools ({ 25 }) are ({ 26 }) available ({ 27 }) . ({ 28 }) 
# Sentence pair (992) source length 19 target length 19 alignment score : 2.14009e-09
Another learning method which has been used widely in many object detection systems is AdaBoost and its variants . 
NULL ({ }) Another ({ 1 }) learning ({ 2 }) method ({ 3 }) that ({ 4 }) has ({ 5 }) been ({ 6 }) widely ({ 8 }) used ({ 7 }) in ({ 9 }) many ({ 10 }) object ({ 11 }) detection ({ 12 }) systems ({ 13 }) is ({ 14 }) AdaBoost ({ 15 }) and ({ 16 }) its ({ 17 }) variants ({ 18 }) . ({ 19 }) 
# Sentence pair (993) source length 18 target length 18 alignment score : 0.000671128
The advantage of AdaBoost is it can be used for both selecting features and learning the classifier . 
NULL ({ }) The ({ 1 }) advantage ({ 2 }) of ({ 3 }) AdaBoost ({ 4 }) is ({ 5 }) it ({ 6 }) can ({ 7 }) be ({ 8 }) used ({ 9 }) for ({ 10 }) both ({ 11 }) selecting ({ 12 }) features ({ 13 }) and ({ 14 }) learning ({ 15 }) the ({ 16 }) classifier ({ 17 }) . ({ 18 }) 
# Sentence pair (994) source length 29 target length 25 alignment score : 2.70474e-11
Face tracking is the process of locating a moving face or several ones in time using a camera , as illustrated in Figure 1 . 
NULL ({ }) Face ({ 1 }) tracking ({ 2 }) is ({ 3 }) the ({ 4 }) process ({ 5 }) of ({ 6 }) locating ({ 7 }) a ({ 8 }) moving ({ 9 }) face ({ 10 }) or ({ 11 }) several ({ 12 }) of ({ }) them ({ }) over ({ 14 }) a ({ }) period ({ 13 }) of ({ }) time ({ 15 }) using ({ 16 }) a ({ 17 }) camera ({ 18 }) , ({ 19 }) as ({ 20 }) illustrated ({ 21 }) in ({ 22 }) Fig. ({ 23 }) 1 ({ 24 }) . ({ 25 }) 
# Sentence pair (995) source length 13 target length 11 alignment score : 1.89336e-06
Face is first initialized manually or by a face detector . 
NULL ({ }) A ({ 1 }) given ({ }) face ({ }) is ({ 2 }) first ({ 3 }) initialized ({ 4 }) manually ({ 5 }) or ({ 6 }) by ({ 7 }) a ({ 8 }) face ({ 9 }) detector ({ 10 }) . ({ 11 }) 
# Sentence pair (996) source length 30 target length 28 alignment score : 2.79785e-09
Face tracker then analyses subsequent video frames and outputs the location of the initialized face within these frames by estimating the motion parameters of the moving face . 
NULL ({ }) The ({ 1 }) face ({ }) tracker ({ 2 }) then ({ 3 }) analyzes ({ 4 }) the ({ }) subsequent ({ 5 }) video ({ 6 }) frames ({ 7 }) and ({ 8 }) outputs ({ 9 }) the ({ 10 }) location ({ 11 }) of ({ 12 }) the ({ 13 }) initialized ({ 14 }) face ({ 15 }) within ({ 16 }) these ({ 17 }) frames ({ 18 }) by ({ 19 }) estimating ({ 20 }) the ({ 21 }) motion ({ 22 }) parameters ({ 23 }) of ({ 24 }) the ({ 25 }) moving ({ 26 }) face ({ 27 }) . ({ 28 }) 
# Sentence pair (997) source length 40 target length 38 alignment score : 5.92858e-12
Different from face detection , the outcome of which is the position and scale of one single face in one single frame , face tracking enables the information acquisition of multiple consecutive faces within consecutive video frames . 
NULL ({ }) This ({ 1 }) is ({ }) different ({ }) from ({ 2 }) face ({ 3 }) detection ({ 4 }) , ({ 5 }) the ({ 6 }) outcome ({ 7 }) of ({ 8 }) which ({ 9 }) is ({ 10 }) the ({ 11 }) position ({ 12 }) and ({ 13 }) scale ({ 14 }) of ({ 15 }) one ({ 16 }) single ({ 17 }) face ({ 18 }) in ({ 19 }) one ({ 20 }) single ({ 21 }) frame ({ 22 }) ; ({ 23 }) face ({ 24 }) tracking ({ 25 }) enables ({ 26 }) the ({ 27 }) information ({ 28 }) acquisition ({ 29 }) of ({ 30 }) multiple ({ 31 }) consecutive ({ 32 }) faces ({ 33 }) within ({ 34 }) consecutive ({ 35 }) video ({ 36 }) frames ({ 37 }) . ({ 38 }) 
# Sentence pair (998) source length 10 target length 10 alignment score : 0.0267053
More important , these faces have the same identity . 
NULL ({ }) More ({ 1 }) important ({ 2 }) , ({ 3 }) these ({ 4 }) faces ({ 5 }) have ({ 6 }) the ({ 7 }) same ({ 8 }) identity ({ 9 }) . ({ 10 }) 
# Sentence pair (999) source length 25 target length 24 alignment score : 1.53903e-09
Although frame-based face detection techniques have demonstrated success on real images , the current ability on detecting faces from video is still primitive . 
NULL ({ }) Although ({ 1 }) frame-based ({ 2 }) face ({ 3 }) detection ({ 4 }) techniques ({ 5 }) have ({ 6 }) been ({ }) successfully ({ 7 }) demonstrated ({ 8 }) on ({ 9 }) real ({ 10 }) images ({ 11 }) , ({ 12 }) the ({ 13 }) current ({ 14 }) ability ({ 15 }) for ({ 16 }) detecting ({ 17 }) faces ({ 18 }) from ({ 19 }) video ({ 20 }) is ({ 21 }) still ({ 22 }) primitive ({ 23 }) . ({ 24 }) 
# Sentence pair (1000) source length 22 target length 18 alignment score : 1.05759e-07
The detector responses can decrease due to different reasons including occlusions , lighting conditions and face pose . 
NULL ({ }) The ({ 1 }) quality ({ }) of ({ }) the ({ }) detector ({ 2 }) responses ({ 3 }) can ({ 4 }) decrease ({ 5 }) due ({ 6 }) to ({ 7 }) different ({ 8 }) reasons ({ 9 }) including ({ 10 }) occlusions ({ 11 }) , ({ 12 }) lighting ({ 13 }) conditions ({ 14 }) , ({ }) and ({ 15 }) face ({ 16 }) poses ({ 17 }) . ({ 18 }) 
# Sentence pair (1001) source length 22 target length 21 alignment score : 2.83287e-05
Without any additional information , these responses can easily be rejected even if they indicate the presence of a face . 
NULL ({ }) Without ({ 1 }) any ({ 2 }) additional ({ 3 }) information ({ 4 }) , ({ 5 }) these ({ 6 }) responses ({ 7 }) can ({ 8 }) easily ({ 9 }) be ({ 10 }) rejected ({ 11 }) , ({ }) even ({ 12 }) if ({ 13 }) they ({ 14 }) indicate ({ 15 }) the ({ 16 }) presence ({ 17 }) of ({ 18 }) a ({ 19 }) face ({ 20 }) . ({ 21 }) 
# Sentence pair (1002) source length 37 target length 33 alignment score : 9.11665e-11
It is therefore important to incorporate the temporal information in a video sequence to provide more complete video segments displaying the person of interest , which is always named as face tracking . 
NULL ({ }) It ({ 1 }) is ({ 2 }) therefore ({ 3 }) important ({ 4 }) to ({ 5 }) incorporate ({ 6 }) the ({ 7 }) temporal ({ 8 }) information ({ 9 }) in ({ 10 }) a ({ 11 }) video ({ 12 }) sequence ({ 13 }) to ({ 14 }) provide ({ 15 }) more ({ 16 }) complete ({ 17 }) video ({ 18 }) segments ({ 19 }) displaying ({ 20 }) the ({ 21 }) person ({ 22 }) of ({ 23 }) interest ({ 24 }) , ({ 25 }) which ({ 26 }) is ({ 27 }) always ({ 28 }) named ({ 29 }) as ({ 30 }) / ({ }) already ({ }) called ({ }) ? ({ }) face ({ 31 }) tracking ({ 32 }) . ({ 33 }) 
# Sentence pair (1003) source length 68 target length 67 alignment score : 5.2795e-21
One of the main applications of face tracking is person retrieval from broadcast video , for example : intelligent fast-forwards " , where the video jumps to the next scene containing a certain person / actor ; or retrieval of different TV interventions , e.g. interviews , shows , etc. , of a given person in a video or a large collection of TV broadcast videos . 
NULL ({ 22 }) One ({ 1 }) of ({ 2 }) the ({ 3 }) main ({ 4 }) applications ({ 5 }) for ({ 6 }) face ({ 7 }) tracking ({ 8 }) is ({ 9 }) in ({ }) the ({ }) person ({ 10 }) retrieval ({ 11 }) from ({ 12 }) broadcast ({ 13 }) video ({ 14 }) , ({ 15 }) for ({ 16 }) example ({ 17 }) : ({ 18 }) " ({ }) Intelligent ({ 19 20 }) fast-forwardsE, ({ 21 }) where ({ 23 }) the ({ 24 }) video ({ 25 }) jumps ({ 26 }) to ({ 27 }) the ({ 28 }) next ({ 29 }) scene ({ 30 }) containing ({ 31 }) a ({ 32 }) certain ({ 33 }) person ({ 34 }) / ({ 35 }) actor ({ 36 }) ; ({ 37 }) or ({ 38 }) retrieval ({ 39 }) of ({ 40 }) different ({ 41 }) TV ({ 42 }) interventions ({ 43 }) , ({ 44 }) e.g. ({ 45 }) interviews ({ 46 }) , ({ 47 }) shows ({ 48 }) , ({ 49 }) etc. ({ 50 }) , ({ 51 }) of ({ 52 }) a ({ 53 }) given ({ 54 }) person ({ 55 }) in ({ 56 }) a ({ 57 }) video ({ 58 }) or ({ 59 }) a ({ 60 }) large ({ 61 }) collection ({ 62 }) of ({ 63 }) TV ({ 64 }) broadcast ({ 65 }) videos ({ 66 }) . ({ 67 }) 
# Sentence pair (1004) source length 19 target length 18 alignment score : 2.66946e-07
In [5] , a person retrieval system for feature-length movie video is proposed using straightforward face tracking . 
NULL ({ }) In ({ 1 }) [5] ({ 2 }) , ({ 3 }) the ({ 4 }) person ({ 5 }) retrieval ({ 6 }) system ({ 7 }) for ({ 8 }) a ({ }) feature-length ({ 9 }) movie ({ 10 }) video ({ 11 }) is ({ 12 }) proposed ({ 13 }) using ({ 14 }) straightforward ({ 15 }) face ({ 16 }) tracking ({ 17 }) . ({ 18 }) 
# Sentence pair (1005) source length 39 target length 40 alignment score : 1.10315e-21
At run time a user outlines a face in a frame of the video , and the face tracks within the movie are then ranked according to the similarity to the outlined query face in the manner of Google . 
NULL ({ 12 13 38 }) At ({ 1 }) run ({ 2 }) time ({ 3 }) a ({ 4 }) user ({ 5 }) outlines ({ 6 }) a ({ 7 }) face ({ 8 }) in ({ 9 }) a ({ 10 }) video ({ 14 }) frame ({ 11 }) , ({ 15 }) and ({ 16 }) the ({ 17 }) face ({ 18 }) tracks ({ 19 }) within ({ 20 }) the ({ 21 }) movie ({ 22 }) are ({ 23 }) then ({ 24 }) ranked ({ 25 }) according ({ 26 }) to ({ 27 }) their ({ 28 }) similarity ({ 29 }) to ({ 30 }) the ({ 31 }) outlined ({ 32 }) query ({ 33 }) face ({ 34 }) in ({ 35 }) the ({ 36 }) same ({ }) way ({ 37 }) as ({ }) Google ({ 39 }) . ({ 40 }) 
# Sentence pair (1006) source length 28 target length 28 alignment score : 3.6038e-06
Since one face track corresponds to one identity , the workload of intra-shot face matching is greatly reduced , which is not available in frame-based face detection . 
NULL ({ }) Since ({ 1 }) one ({ 2 }) face ({ 3 }) track ({ 4 }) corresponds ({ 5 }) to ({ 6 }) one ({ 7 }) identity ({ 8 }) , ({ 9 }) the ({ 10 }) workload ({ 11 }) of ({ 12 }) intra-shot ({ 13 }) face ({ 14 }) matching ({ 15 }) is ({ 16 }) greatly ({ 17 }) reduced ({ 18 }) , ({ 19 }) which ({ 20 }) is ({ 21 }) not ({ 22 }) available ({ 23 }) in ({ 24 }) frame-based ({ 25 }) face ({ 26 }) detection ({ 27 }) . ({ 28 }) 
# Sentence pair (1007) source length 21 target length 21 alignment score : 0.000307121
In addition , face tracking provides multiple examples of the same character 's appearance to help with inter-shot face matching . 
NULL ({ }) In ({ 1 }) addition ({ 2 }) , ({ 3 }) face ({ 4 }) tracking ({ 5 }) provides ({ 6 }) multiple ({ 7 }) examples ({ 8 }) of ({ 9 }) the ({ 10 }) same ({ 11 }) character ({ 12 }) 's ({ 13 }) appearance ({ 14 }) to ({ 15 }) help ({ 16 }) with ({ 17 }) inter-shot ({ 18 }) face ({ 19 }) matching ({ 20 }) . ({ 21 }) 
# Sentence pair (1008) source length 37 target length 37 alignment score : 1.39718e-13
Face tracking also finds applications in the area of face-name association , the objective of which is to label television or movie footage with the identity of the person present in each frame of the video . 
NULL ({ 4 }) Face ({ 1 }) tracking ({ 2 }) is ({ }) also ({ 3 }) used ({ 5 }) in ({ 6 }) the ({ 7 }) area ({ 8 }) of ({ 9 }) face-name ({ 10 }) association ({ 11 }) , ({ 12 }) the ({ 13 }) objective ({ 14 }) of ({ 15 }) which ({ 16 }) is ({ 17 }) to ({ 18 }) label ({ 19 }) television ({ 20 }) or ({ 21 }) movie ({ 22 }) footage ({ 23 }) with ({ 24 }) the ({ 25 }) identity ({ 26 }) of ({ 27 }) the ({ 28 }) person ({ 29 }) present ({ 30 }) in ({ 31 }) each ({ 32 }) frame ({ 33 }) of ({ 34 }) the ({ 35 }) video ({ 36 }) . ({ 37 }) 
# Sentence pair (1009) source length 11 target length 11 alignment score : 0.00265711
Everingham et al [8] proposed an automatic face-name association system . 
NULL ({ }) Everingham ({ 1 }) et ({ 2 }) al. ({ 3 }) [8] ({ 4 }) proposed ({ 5 }) an ({ 6 }) automatic ({ 7 }) face-name ({ 8 }) association ({ 9 }) system ({ 10 }) . ({ 11 }) 
# Sentence pair (1010) source length 28 target length 25 alignment score : 5.74582e-19
This system uses a face tracker similar with [5] to extract a few hundred tracks of a particular character each in a single shot . 
NULL ({ 17 }) This ({ 1 }) system ({ 2 }) uses ({ 3 }) a ({ 4 }) face ({ 5 }) tracker ({ 6 }) similar ({ 7 }) to ({ 8 }) the ({ }) one ({ }) in ({ }) [5] ({ 9 }) that ({ }) can ({ 10 }) extract ({ 11 }) a ({ 12 }) few ({ 13 }) hundred ({ 14 }) tracks ({ 15 }) of ({ 16 }) each ({ 20 }) particular ({ 18 }) character ({ 19 }) in ({ 21 }) a ({ 22 }) single ({ 23 }) shot ({ 24 }) . ({ 25 }) 
# Sentence pair (1011) source length 38 target length 35 alignment score : 3.50291e-09
Based on the temporal information obtained from the face tracker , textual information for TV and movie footage including subtitles and transcripts is employed to assign the character 's name to each face track . 
NULL ({ }) Based ({ 1 }) on ({ 2 }) the ({ 3 }) temporal ({ 4 }) information ({ 5 }) obtained ({ 6 }) from ({ 7 }) the ({ 8 }) face ({ 9 }) tracker ({ 10 }) , ({ 11 }) the ({ }) textual ({ 12 }) information ({ 13 }) for ({ 14 }) TV ({ 15 }) and ({ 16 }) the ({ }) movie ({ 17 }) footage ({ 18 }) including ({ 19 }) the ({ }) subtitles ({ 20 }) and ({ 21 }) transcripts ({ 22 }) is ({ 23 }) employed ({ 24 }) to ({ 25 }) assign ({ 26 }) the ({ 27 }) character ({ 28 }) 's ({ 29 }) name ({ 30 }) to ({ 31 }) each ({ 32 }) face ({ 33 }) track ({ 34 }) . ({ 35 }) 
# Sentence pair (1012) source length 37 target length 34 alignment score : 3.84452e-10
For instance , shots containing a particular person can be retrieved by a keyword like " Bush " or " Julia Roberts " instead of an outlined query face as used in [5] . 
NULL ({ }) For ({ 1 }) instance ({ 2 }) , ({ 3 }) shots ({ 4 }) containing ({ 5 }) a ({ 6 }) particular ({ 7 }) person ({ 8 }) can ({ 9 }) be ({ 10 }) retrieved ({ 11 }) by ({ 12 }) a ({ 13 }) keyword ({ 14 }) like ({ 15 }) " ({ 16 }) Bush ({ 17 }) " ({ 18 }) or ({ 19 }) " ({ 20 }) Julia ({ 21 }) Roberts ({ 22 }) " ({ 23 }) instead ({ 24 }) of ({ }) the ({ }) use ({ }) of ({ 25 }) an ({ 26 }) outlined ({ 27 }) query ({ 28 }) face ({ 29 }) as ({ 30 }) used ({ 31 }) in ({ 32 }) [5] ({ 33 }) . ({ 34 }) 
# Sentence pair (1013) source length 38 target length 36 alignment score : 4.85733e-13
Besides broadcast video , face tracker also has important applications in the video used in humanoid robotics , visual surveillance , human-computer interaction ( HCI ) , video conferencing , face-based biometric person authentication , etc. 
NULL ({ }) Besides ({ 1 }) broadcast ({ 2 }) video ({ 3 }) , ({ 4 }) face ({ 5 }) tracker ({ 6 }) also ({ 7 }) has ({ 8 }) important ({ 9 }) applications ({ 10 }) in ({ 11 }) the ({ 12 }) videos ({ 13 }) used ({ 14 }) in ({ 15 }) humanoid ({ 16 }) robotics ({ 17 }) , ({ 18 }) visual ({ 19 }) surveillance ({ 20 }) , ({ 21 }) human-computer ({ 22 }) interaction ({ 23 }) ( ({ 24 }) HCI ({ 25 }) ) ({ 26 }) , ({ 27 }) video ({ 28 }) conferencing ({ 29 }) , ({ 30 }) and ({ }) face-based ({ 31 }) biometric ({ 32 }) person ({ 33 }) authentication ({ 34 }) among ({ 36 }) others ({ 35 }) . ({ }) 
# Sentence pair (1014) source length 19 target length 18 alignment score : 1.21802e-09
Choosing a face tracker can be a difficult task due to the variety of face trackers available . 
NULL ({ }) Choosing ({ 1 }) a ({ 2 }) face ({ 3 }) tracker ({ 4 }) can ({ 5 }) be ({ 6 }) a ({ 7 }) difficult ({ 8 }) task ({ 9 }) because ({ 10 }) of ({ 11 }) the ({ 12 }) variety ({ 13 }) of ({ 14 }) face ({ 15 }) trackers ({ 16 }) currently ({ }) available ({ 17 }) . ({ 18 }) 
# Sentence pair (1015) source length 39 target length 39 alignment score : 1.7672e-07
The application provider will have to decide which face tracker is best suited to his / her individual needs and , of course , the type of video that he / she wants to use as the target . 
NULL ({ }) The ({ 1 }) application ({ 2 }) provider ({ 3 }) will ({ 4 }) have ({ 5 }) to ({ 6 }) decide ({ 7 }) which ({ 8 }) face ({ 9 }) tracker ({ 10 }) is ({ 11 }) best ({ 12 }) suited ({ 13 }) to ({ 14 }) his ({ 15 }) / ({ 16 }) her ({ 17 }) individual ({ 18 }) needs ({ 19 }) and ({ 20 }) , ({ 21 }) of ({ 22 }) course ({ 23 }) , ({ 24 }) the ({ 25 }) type ({ 26 }) of ({ 27 }) video ({ 28 }) that ({ 29 }) he ({ 30 }) / ({ 31 }) she ({ 32 }) wants ({ 33 }) to ({ 34 }) use ({ 35 }) as ({ 36 }) the ({ 37 }) target ({ 38 }) . ({ 39 }) 
# Sentence pair (1016) source length 18 target length 17 alignment score : 0.000118574
Generally speaking , the important issues that should be addressed include speed , robustness and accuracy . 
NULL ({ }) Generally ({ 1 }) speaking ({ 2 }) , ({ 3 }) the ({ 4 }) important ({ 5 }) issues ({ 6 }) that ({ 7 }) should ({ 8 }) be ({ 9 }) addressed ({ 10 }) include ({ 11 }) speed ({ 12 }) , ({ 13 }) robustness ({ 14 }) , ({ }) and ({ 15 }) accuracy ({ 16 }) . ({ 17 }) 
# Sentence pair (1017) source length 38 target length 39 alignment score : 6.38939e-13
Can the system run in real time ? Similar with many other processing tools for broadcast video , speed is not the most critical issue because offline processing is permitted in most cases of video structuring and indexing . 
NULL ({ 34 }) Can ({ 1 }) the ({ 2 }) system ({ 3 }) run ({ 4 }) in ({ 5 }) real ({ 6 }) time ({ 7 }) ? ({ 8 }) Similar ({ 9 }) to ({ 10 }) many ({ 11 }) other ({ 12 }) processing ({ 13 }) tools ({ 14 }) for ({ 15 }) broadcast ({ 16 }) video ({ 17 }) , ({ 18 }) speed ({ 19 }) is ({ 20 }) not ({ 21 }) the ({ 22 }) most ({ 23 }) critical ({ 24 }) issue ({ 25 }) because ({ 26 }) offline ({ 27 }) processing ({ 28 }) is ({ 29 }) permitted ({ 30 }) in ({ 31 }) most ({ 32 }) video ({ 35 }) structuring ({ 36 }) and ({ 37 }) indexing ({ 38 }) cases ({ 33 }) . ({ 39 }) 
# Sentence pair (1018) source length 33 target length 32 alignment score : 3.35817e-09
However , a real-time face tracker will become necessary if the target archive is established from too large quantities of videos , e.g. 24-hour continuous video recording that needs daily structuring . 
NULL ({ }) However ({ 1 }) , ({ 2 }) a ({ 3 }) real-time ({ 4 }) face ({ 5 }) tracker ({ 6 }) will ({ 7 }) become ({ 8 }) necessary ({ 9 }) if ({ 10 }) a ({ 11 }) target ({ 12 }) archive ({ 13 }) is ({ 14 }) established ({ 15 }) from ({ 16 }) too ({ 17 }) large ({ 18 }) a ({ }) quantity ({ 19 }) of ({ 20 }) videos ({ 21 }) , ({ 22 }) e.g. ({ 23 }) 24-hour ({ 24 }) continuous ({ 25 }) video ({ 26 }) recording ({ 27 }) that ({ 28 }) needs ({ 29 }) daily ({ 30 }) structuring ({ 31 }) . ({ 32 }) 
# Sentence pair (1019) source length 25 target length 24 alignment score : 1.88207e-10
On the other hand , the speed of the tracker is critical in most cases of applications for non-broadcast video , e.g. HCI . 
NULL ({ }) On ({ 1 }) the ({ 2 }) other ({ 3 }) hand ({ 4 }) , ({ 5 }) the ({ 6 }) speed ({ 7 }) of ({ 8 }) the ({ 9 }) tracker ({ 10 }) is ({ 11 }) critical ({ 12 }) in ({ 13 }) most ({ 14 }) of ({ 16 }) the ({ }) application ({ 17 }) cases ({ 15 }) for ({ 18 }) non-broadcast ({ 19 }) video ({ 20 }) , ({ 21 }) e.g. ({ 22 }) HCI ({ 23 }) . ({ 24 }) 
# Sentence pair (1020) source length 21 target length 20 alignment score : 3.29558e-05
It should be noted that there is always a tradeoff between speed and performance-related issues including robustness and accuracy . 
NULL ({ }) It ({ 1 }) should ({ 2 }) be ({ 3 }) noted ({ 4 }) that ({ 5 }) there ({ 6 }) is ({ 7 }) always ({ 8 }) a ({ 9 }) tradeoff ({ 10 }) between ({ 11 }) speed ({ 12 }) and ({ 13 }) performance-related ({ 14 }) issues ({ 15 }) including ({ 16 }) the ({ }) robustness ({ 17 }) and ({ 18 }) accuracy ({ 19 }) . ({ 20 }) 
# Sentence pair (1021) source length 73 target length 70 alignment score : 1.50508e-20
Can the system cope with varying illumination , facial expression , scale , pose , camerawork , occlusion and large head motion ? A number of illumination factors , e.g. light sources , background colors , luminance levels , and media , impact greatly on the change in appearance of a moving face , for instance , when tracking a person who are moving from indoor to outdoor environment . 
NULL ({ }) Can ({ 1 }) the ({ 2 }) system ({ 3 }) cope ({ 4 }) with ({ 5 }) varying ({ 6 }) illuminations ({ 7 }) , ({ 8 }) facial ({ 9 }) expressions ({ 10 }) , ({ 11 }) scales ({ 12 }) , ({ 13 }) poses ({ 14 }) , ({ 15 }) camerawork ({ 16 }) , ({ 17 }) occlusion ({ 18 }) , ({ }) and ({ 19 }) large ({ 20 }) head ({ 21 }) motions ({ 22 }) ? ({ 23 }) A ({ 24 }) number ({ 25 }) of ({ 26 }) illumination ({ 27 }) factors ({ 28 }) , ({ 29 }) e.g. ({ 30 }) light ({ 31 }) sources ({ 32 }) , ({ 33 }) background ({ 34 }) colors ({ 35 }) , ({ 36 }) luminance ({ 37 }) levels ({ 38 }) , ({ 39 }) and ({ 40 }) media ({ 41 }) , ({ 42 }) impact ({ 43 }) greatly ({ 44 }) on ({ 45 }) the ({ 46 }) change ({ 47 }) in ({ 48 }) appearance ({ 49 }) of ({ 50 }) a ({ 51 }) moving ({ 52 }) face ({ 53 }) , ({ 54 }) for ({ 55 }) instance ({ 56 }) , ({ 57 }) when ({ 58 }) tracking ({ 59 }) a ({ 60 }) person ({ 61 }) who ({ 62 }) is ({ 63 }) moving ({ 64 }) from ({ 65 }) an ({ }) indoor ({ 66 }) to ({ 67 }) an ({ }) outdoor ({ 68 }) environment ({ 69 }) . ({ 70 }) 
# Sentence pair (1022) source length 26 target length 24 alignment score : 2.90441e-06
Face tracking also tends to fail under large facial deformations of eyes , nose , mouth , etc. due to facial expression variation . 
NULL ({ }) Face ({ 1 }) tracking ({ 2 }) also ({ 3 }) tends ({ 4 }) to ({ 5 }) fail ({ 6 }) under ({ 7 }) large ({ 8 }) facial ({ 9 }) deformations ({ 10 }) of ({ 11 }) the ({ }) eyes ({ 12 }) , ({ 13 }) nose ({ 14 }) , ({ 15 }) mouth ({ 16 }) , ({ 17 }) etc. ({ 18 }) due ({ 19 }) to ({ 20 }) the ({ }) facial ({ 21 }) expression ({ 22 }) variation ({ 23 }) . ({ 24 }) 
# Sentence pair (1023) source length 29 target length 29 alignment score : 3.27252e-06
Different from non-broadcast video , e.g. video used for HCI , faces appearing in broadcast video varies from large close-up faces to small faces taken by a long-shot . 
NULL ({ }) Different ({ 1 }) from ({ 2 }) non-broadcast ({ 3 }) video ({ 4 }) , ({ 5 }) e.g. ({ 6 }) video ({ 7 }) used ({ 8 }) for ({ 9 }) HCI ({ 10 }) , ({ 11 }) faces ({ 12 }) appearing ({ 13 }) in ({ 14 }) broadcast ({ 15 }) video ({ 16 }) vary ({ 17 }) from ({ 18 }) large ({ 19 }) close-up ({ 20 }) faces ({ 21 }) to ({ 22 }) small ({ 23 }) faces ({ 24 }) taken ({ 25 }) by ({ 26 }) a ({ 27 }) long-shot ({ 28 }) . ({ 29 }) 
# Sentence pair (1024) source length 22 target length 20 alignment score : 1.09352e-07
Small face scale always leads to low resolution and will reject most face trackers designed by computer vision researchers . 
NULL ({ }) A ({ }) smaller ({ 1 }) face ({ 2 }) scale ({ 3 }) always ({ 4 }) leads ({ 5 }) to ({ 6 }) a ({ }) lower ({ 7 }) resolution ({ 8 }) and ({ 9 }) will ({ 10 }) reject ({ 11 }) most ({ 12 }) face ({ 13 }) trackers ({ 14 }) designed ({ 15 }) by ({ 16 }) computer ({ 17 }) vision ({ 18 }) researchers ({ 19 }) . ({ 20 }) 
# Sentence pair (1025) source length 29 target length 28 alignment score : 6.27187e-13
Pose variation , i.e. head rotations including pitch , roll and yaw , is another influencing factor , which can cause disappearance of part of the face . 
NULL ({ 26 }) Pose ({ 1 }) variations ({ 2 }) , ({ 3 }) i.e. ({ 4 }) head ({ 5 }) rotations ({ 6 }) including ({ 7 }) the ({ }) pitch ({ 8 }) , ({ 9 }) roll ({ 10 }) , ({ }) and ({ 11 }) yaw ({ 12 }) , ({ 13 }) is ({ 14 }) another ({ 15 }) influencing ({ 16 }) factor ({ 17 }) , ({ 18 }) which ({ 19 }) can ({ 20 }) cause ({ 21 }) disappearances ({ 22 }) of ({ 23 }) parts ({ 24 }) of ({ 25 }) faces ({ 27 }) . ({ 28 }) 
# Sentence pair (1026) source length 16 target length 17 alignment score : 6.65511e-10
In some cases , the variation of scale and pose might be caused by camerawork change . 
NULL ({ 7 }) In ({ 1 }) some ({ 2 }) cases ({ 3 }) , ({ 4 }) the ({ 5 }) scale ({ 8 }) and ({ 9 }) pose ({ 10 }) variations ({ 6 }) might ({ 11 }) be ({ 12 }) caused ({ 13 }) by ({ 14 }) camerawork ({ 15 }) changes ({ 16 }) . ({ 17 }) 
# Sentence pair (1027) source length 29 target length 30 alignment score : 3.35663e-17
Disappearance of part of the face is also apt to happen due to occlusion by other objects , and motion information may be distracted by alternate motion of them . 
NULL ({ 28 29 }) The ({ 1 }) partial ({ 2 }) disappearance ({ 3 }) of ({ 4 }) a ({ 5 }) face ({ 6 }) is ({ 7 }) also ({ 8 }) apt ({ 9 }) to ({ 10 }) happen ({ 11 }) due ({ 12 }) to ({ 13 }) occlusion ({ 14 }) by ({ 15 }) other ({ 16 }) objects ({ 17 }) , ({ 18 }) and ({ 19 }) motion ({ 20 }) information ({ 21 }) may ({ 22 }) be ({ 23 }) distracted ({ 24 }) by ({ 25 }) an ({ }) alternate ({ 26 }) motion ({ 27 }) . ({ 30 }) 
# Sentence pair (1028) source length 32 target length 33 alignment score : 5.06063e-13
Moreover , the task of face tracking becomes even more difficult when the head are moving fast relative to the frame rate so that the tracker fails to arrive in time " . 
NULL ({ }) Moreover ({ 1 }) , ({ 2 }) the ({ 3 }) task ({ 4 }) of ({ 5 }) face ({ 6 }) tracking ({ 7 }) becomes ({ 8 }) even ({ 9 }) more ({ 10 }) difficult ({ 11 }) when ({ 12 }) the ({ 13 }) head ({ 14 }) is ({ 15 }) moving ({ 16 }) fast ({ 17 }) relative ({ 18 }) to ({ 19 }) the ({ 20 }) frame ({ 21 }) rate ({ 22 }) , ({ }) so ({ 23 }) that ({ 24 }) the ({ 25 }) tracker ({ 26 }) fails ({ 27 }) to ({ 28 }) arrive ({ 29 }) in ({ 30 }) timeE. ({ 31 32 33 }) 
# Sentence pair (1029) source length 29 target length 29 alignment score : 6.90858e-06
How accurate is the tracking ? The first factor that affects the accuracy might be the false face detections generated when initializing the tracker by a face detector . 
NULL ({ }) How ({ 1 }) accurate ({ 2 }) is ({ 3 }) the ({ 4 }) tracking ({ 5 }) ? ({ 6 }) The ({ 7 }) first ({ 8 }) factor ({ 9 }) that ({ 10 }) affects ({ 11 }) the ({ 12 }) accuracy ({ 13 }) might ({ 14 }) be ({ 15 }) the ({ 16 }) false ({ 17 }) face ({ 18 }) detections ({ 19 }) generated ({ 20 }) when ({ 21 }) initializing ({ 22 }) the ({ 23 }) tracker ({ 24 }) by ({ 25 }) a ({ 26 }) face ({ 27 }) detector ({ 28 }) . ({ 29 }) 
# Sentence pair (1030) source length 13 target length 12 alignment score : 1.98776e-07
This problem is difficult to solve due to a fixed threshold . 
NULL ({ }) This ({ 1 }) problem ({ 2 }) is ({ 3 }) difficult ({ 4 }) to ({ 5 }) solve ({ 6 }) because ({ 7 }) it ({ 8 }) has ({ }) a ({ 9 }) fixed ({ 10 }) threshold ({ 11 }) . ({ 12 }) 
# Sentence pair (1031) source length 26 target length 22 alignment score : 1.46928e-08
Lowering the threshold of the face detector reduces false rejections but increases the number of false detections , and vice versa . 
NULL ({ }) Lowering ({ 1 }) the ({ 2 }) threshold ({ 3 }) of ({ 4 }) the ({ 5 }) face ({ 6 }) detector ({ 7 }) reduces ({ 8 }) the ({ }) number ({ }) of ({ }) false ({ 9 }) rejections ({ 10 }) , ({ }) but ({ 11 }) increases ({ 12 }) the ({ 13 }) number ({ 14 }) of ({ 15 }) false ({ 16 }) detections ({ 17 }) , ({ 18 }) and ({ 19 }) vice ({ 20 }) versa ({ 21 }) . ({ 22 }) 
# Sentence pair (1032) source length 17 target length 17 alignment score : 0.0012468
The drifting or the long sequence motion problem is another factor that might affect the accuracy . 
NULL ({ }) The ({ 1 }) drifting ({ 2 }) or ({ 3 }) the ({ 4 }) long ({ 5 }) sequence ({ 6 }) motion ({ 7 }) problem ({ 8 }) is ({ 9 }) another ({ 10 }) factor ({ 11 }) that ({ 12 }) might ({ 13 }) affect ({ 14 }) the ({ 15 }) accuracy ({ 16 }) . ({ 17 }) 
# Sentence pair (1033) source length 12 target length 12 alignment score : 0.0149185
This problem always happens due to the imperfect motion estimation technique . 
NULL ({ }) This ({ 1 }) problem ({ 2 }) always ({ 3 }) happens ({ 4 }) due ({ 5 }) to ({ 6 }) the ({ 7 }) imperfect ({ 8 }) motion ({ 9 }) estimation ({ 10 }) technique ({ 11 }) . ({ 12 }) 
# Sentence pair (1034) source length 31 target length 31 alignment score : 1.19675e-08
A tracker might accumulate motion errors and eventually lose track of the face , for instance , when tracking faces that change from a frontal view to a profile position . 
NULL ({ }) A ({ 1 }) tracker ({ 2 }) might ({ 3 }) accumulate ({ 4 }) motion ({ 5 }) errors ({ 6 }) and ({ 7 }) eventually ({ 8 }) lose ({ 9 }) track ({ 10 }) of ({ 11 }) a ({ 12 }) face ({ 13 }) , ({ 14 }) for ({ 15 }) instance ({ 16 }) , ({ 17 }) when ({ 18 }) tracking ({ 19 }) faces ({ 20 }) that ({ 21 }) change ({ 22 }) from ({ 23 }) a ({ 24 }) frontal ({ 25 }) view ({ 26 }) to ({ 27 }) a ({ 28 }) profile ({ 29 }) position ({ 30 }) . ({ 31 }) 
# Sentence pair (1035) source length 24 target length 25 alignment score : 1.39197e-07
Face tracking can be considered as an algorithm that analyses the video frames and outputs the location of moving faces within the video frame . 
NULL ({ 6 }) Face ({ 1 }) tracking ({ 2 }) can ({ 3 }) be ({ 4 }) considered ({ 5 }) an ({ 7 }) algorithm ({ 8 }) that ({ 9 }) analyzes ({ 10 }) the ({ 11 }) video ({ 12 }) frames ({ 13 }) and ({ 14 }) outputs ({ 15 }) the ({ 16 }) location ({ 17 }) of ({ 18 }) moving ({ 19 }) faces ({ 20 }) within ({ 21 }) the ({ 22 }) video ({ 23 }) frame ({ 24 }) . ({ 25 }) 
# Sentence pair (1036) source length 27 target length 25 alignment score : 7.64033e-11
For each tracked face , three steps are involved that are initialization , tracking and a stopping procedure , as illustrated in Figure 2 . 
NULL ({ 16 }) For ({ 1 }) each ({ 2 }) tracked ({ 3 }) face ({ 4 }) , ({ 5 }) three ({ 6 }) steps ({ 7 }) are ({ 8 }) involved ({ 9 }) , ({ }) which ({ 10 }) are ({ 11 }) the ({ }) initialization ({ 12 }) , ({ 13 }) tracking ({ 14 }) , ({ }) and ({ 15 }) stopping ({ 17 }) procedures ({ 18 }) , ({ 19 }) as ({ 20 }) illustrated ({ 21 }) in ({ 22 }) Fig. ({ 23 }) 2 ({ 24 }) . ({ 25 }) 
# Sentence pair (1037) source length 17 target length 17 alignment score : 4.17726e-07
Most of the developed methods use a face detector as the initialization of their tracking process . 
NULL ({ 10 }) Most ({ 1 }) of ({ 2 }) the ({ 3 }) developed ({ 4 }) methods ({ 5 }) use ({ 6 }) a ({ 7 }) face ({ 8 }) detector ({ 9 }) for ({ }) the ({ 11 }) initialization ({ 12 }) of ({ 13 }) their ({ 14 }) tracking ({ 15 }) processes ({ 16 }) . ({ 17 }) 
# Sentence pair (1038) source length 21 target length 20 alignment score : 2.11382e-07
An always ignored but existing difficulty of this step lies in the control of false face detections described above . 
NULL ({ }) An ({ 1 }) always ({ 2 }) ignored ({ 3 }) but ({ 4 }) existing ({ 5 }) difficulty ({ 6 }) with ({ 7 }) this ({ 8 }) step ({ 9 }) lies ({ 10 }) in ({ 11 }) the ({ 12 }) control ({ 13 }) of ({ 14 }) the ({ }) false ({ 15 }) face ({ 16 }) detections ({ 17 }) described ({ 18 }) above ({ 19 }) . ({ 20 }) 
# Sentence pair (1039) source length 14 target length 14 alignment score : 0.00348185
Another problem is the difficulty in handling the appearance of new non-frontal faces . 
NULL ({ }) Another ({ 1 }) problem ({ 2 }) is ({ 3 }) the ({ 4 }) difficulty ({ 5 }) in ({ 6 }) handling ({ 7 }) the ({ 8 }) appearance ({ 9 }) of ({ 10 }) new ({ 11 }) non-frontal ({ 12 }) faces ({ 13 }) . ({ 14 }) 
# Sentence pair (1040) source length 30 target length 29 alignment score : 2.16221e-09
Although there have been literatures in profile or intermediate pose face detector , this kind of work suffers from the false-detection problem far more than frontal face detector . 
NULL ({ }) Although ({ 1 }) there ({ 2 }) have ({ 3 }) been ({ 4 }) literatures ({ 5 }) on ({ 6 }) profile ({ 7 }) or ({ 8 }) intermediate ({ 9 }) pose ({ 10 }) face ({ 11 }) detectors ({ 12 }) , ({ 13 }) this ({ 14 }) kind ({ 15 }) of ({ 16 }) work ({ 17 }) suffers ({ 18 }) from ({ 19 }) the ({ 20 }) false-detection ({ 21 }) problem ({ 22 }) far ({ 23 }) more ({ 24 }) than ({ 25 }) a ({ }) frontal ({ 26 }) face ({ 27 }) detector ({ 28 }) . ({ 29 }) 
# Sentence pair (1041) source length 35 target length 34 alignment score : 9.70805e-08
To alleviate these two problems , Chaudhury et al [1] used two face probability maps instead of a fixed threshold to initialize face tracker , one for frontal views and one for profiles . 
NULL ({ }) To ({ 1 }) alleviate ({ 2 }) these ({ 3 }) two ({ 4 }) problems ({ 5 }) , ({ 6 }) Chaudhury ({ 7 }) et ({ 8 }) al. ({ 9 }) [1] ({ 10 }) used ({ 11 }) two ({ 12 }) face ({ 13 }) probability ({ 14 }) maps ({ 15 }) instead ({ 16 }) of ({ 17 }) a ({ 18 }) fixed ({ 19 }) threshold ({ 20 }) to ({ 21 }) initialize ({ 22 }) the ({ }) face ({ 23 }) tracker ({ 24 }) , ({ 25 }) one ({ 26 }) for ({ 27 }) frontal ({ 28 }) views ({ 29 }) and ({ 30 }) one ({ 31 }) for ({ 32 }) profiles ({ 33 }) . ({ 34 }) 
# Sentence pair (1042) source length 25 target length 25 alignment score : 6.04214e-05
All local maxima in these maps are chosen as the face candidates , the face probabilities of which are propagated throughout the temporal sequence . 
NULL ({ }) All ({ 1 }) local ({ 2 }) maxima ({ 3 }) in ({ 4 }) these ({ 5 }) maps ({ 6 }) are ({ 7 }) chosen ({ 8 }) as ({ 9 }) the ({ 10 }) face ({ 11 }) candidates ({ 12 }) , ({ 13 }) the ({ 14 }) face ({ 15 }) probabilities ({ 16 }) of ({ 17 }) which ({ 18 }) are ({ 19 }) propagated ({ 20 }) throughout ({ 21 }) the ({ 22 }) temporal ({ 23 }) sequence ({ 24 }) . ({ 25 }) 
# Sentence pair (1043) source length 19 target length 19 alignment score : 0.000730957
Candidates whose probabilities either go to zero or remain low over time are determined as non-face and eliminated . 
NULL ({ }) Candidates ({ 1 }) whose ({ 2 }) probabilities ({ 3 }) either ({ 4 }) go ({ 5 }) to ({ 6 }) zero ({ 7 }) or ({ 8 }) remain ({ 9 }) low ({ 10 }) over ({ 11 }) time ({ 12 }) are ({ 13 }) determined ({ 14 }) as ({ 15 }) non-face ({ 16 }) and ({ 17 }) eliminated ({ 18 }) . ({ 19 }) 
# Sentence pair (1044) source length 17 target length 15 alignment score : 0.000115077
The information from two face probability maps is combined to represent intermediate head pose . 
NULL ({ }) The ({ 1 }) information ({ 2 }) from ({ 3 }) the ({ }) two ({ 4 }) face ({ 5 }) probability ({ 6 }) maps ({ 7 }) is ({ 8 }) combined ({ 9 }) to ({ 10 }) represent ({ 11 }) an ({ }) intermediate ({ 12 }) head ({ 13 }) pose ({ 14 }) . ({ 15 }) 
# Sentence pair (1045) source length 37 target length 35 alignment score : 6.05035e-11
Their experiments showed that the proposed probabilistic detector improved the accuracy over traditional face detector and is able to handle the head movement covering a range of 90 degrees out-of-plane rotation ( yaw ) . 
NULL ({ }) Their ({ 1 }) experiments ({ 2 }) showed ({ 3 }) that ({ 4 }) the ({ 5 }) proposed ({ 6 }) probabilistic ({ 7 }) detector ({ 8 }) improved ({ 9 }) the ({ 10 }) accuracy ({ 11 }) more ({ 12 }) than ({ }) a ({ }) traditional ({ 13 }) face ({ 14 }) detector ({ 15 }) and ({ 16 }) is ({ 17 }) able ({ 18 }) to ({ 19 }) handle ({ 20 }) the ({ 21 }) head ({ 22 }) movement ({ 23 }) covering ({ 24 }) a ({ 25 }) range ({ 26 }) of ({ 27 }) 90 ({ 28 }) degrees ({ 29 }) out-of-plane ({ 30 }) rotation ({ 31 }) ( ({ 32 }) yaw ({ 33 }) ) ({ 34 }) . ({ 35 }) 
# Sentence pair (1046) source length 15 target length 15 alignment score : 1.68141e-05
After initialization , one should choose what features to track before tracking the face . 
NULL ({ 13 }) After ({ 1 }) initialization ({ 2 }) , ({ 3 }) one ({ 4 }) should ({ 5 }) choose ({ 6 }) what ({ 7 }) features ({ 8 }) to ({ 9 }) track ({ 10 }) before ({ 11 }) tracking ({ 12 }) a ({ }) face ({ 14 }) . ({ 15 }) 
# Sentence pair (1047) source length 29 target length 27 alignment score : 9.46849e-09
The exploitation of color is one of the common choices in order to be invariant to facial expression , scale and pose change [4 , 9] . 
NULL ({ }) The ({ 1 }) exploitation ({ 2 }) of ({ 3 }) color ({ 4 }) is ({ 5 }) one ({ 6 }) of ({ 7 }) the ({ 8 }) more ({ }) common ({ 9 }) choices ({ 10 }) in ({ 11 }) order ({ 12 }) to ({ 13 }) be ({ 14 }) invariant ({ 15 }) to ({ 16 }) facial ({ 17 }) expressions ({ 18 }) , ({ 19 }) scale ({ 20 }) , ({ }) and ({ 21 }) pose ({ 22 }) changes ({ 23 }) [4 ({ 24 }) , ({ 25 }) 9] ({ 26 }) . ({ 27 }) 
# Sentence pair (1048) source length 37 target length 37 alignment score : 8.24006e-07
However , color-based face trackers often depend on a learning set dedicated to the type of processed videos and are not guaranteed to be easily expendable to unknown videos with varying illumination conditions or different races . 
NULL ({ }) However ({ 1 }) , ({ 2 }) color-based ({ 3 }) face ({ 4 }) trackers ({ 5 }) often ({ 6 }) depend ({ 7 }) on ({ 8 }) a ({ 9 }) learning ({ 10 }) set ({ 11 }) dedicated ({ 12 }) to ({ 13 }) the ({ 14 }) type ({ 15 }) of ({ 16 }) processed ({ 17 }) videos ({ 18 }) and ({ 19 }) are ({ 20 }) not ({ 21 }) guaranteed ({ 22 }) to ({ 23 }) be ({ 24 }) easily ({ 25 }) expendable ({ 26 }) to ({ 27 }) unknown ({ 28 }) videos ({ 29 }) with ({ 30 }) varying ({ 31 }) illumination ({ 32 }) conditions ({ 33 }) or ({ 34 }) different ({ 35 }) races ({ 36 }) . ({ 37 }) 
# Sentence pair (1049) source length 12 target length 12 alignment score : 0.013561
Also , color is susceptible to occlusion by other head-like objects . 
NULL ({ }) Also ({ 1 }) , ({ 2 }) color ({ 3 }) is ({ 4 }) susceptible ({ 5 }) to ({ 6 }) occlusion ({ 7 }) by ({ 8 }) other ({ 9 }) head-like ({ 10 }) objects ({ 11 }) . ({ 12 }) 
# Sentence pair (1050) source length 39 target length 38 alignment score : 6.7677e-12
Another two choices are key-point [5 , 8] and facial features [3 , 6 , 10] , e.g. eyes , nose , mouth , etc. , both of which are more robust to varying illumination and occlusion . 
NULL ({ }) Two ({ 1 }) other ({ 2 }) choices ({ 3 }) are ({ 4 }) the ({ }) key-point ({ 5 }) [5 ({ 6 }) , ({ 7 }) 8] ({ 8 }) and ({ 9 }) facial ({ 10 }) features ({ 11 }) [3 ({ 12 }) , ({ 13 }) 6 ({ 14 }) , ({ 15 }) 10] ({ 16 }) , ({ 17 }) e.g. ({ 18 }) eyes ({ 19 }) , ({ 20 }) nose ({ 21 }) , ({ 22 }) mouth ({ 23 }) , ({ 24 }) etc. ({ 25 }) , ({ 26 }) both ({ 27 }) of ({ 28 }) which ({ 29 }) are ({ 30 }) more ({ 31 }) robust ({ 32 }) to ({ 33 }) varying ({ 34 }) illuminations ({ 35 }) and ({ 36 }) occlusions ({ 37 }) . ({ 38 }) 
# Sentence pair (1051) source length 38 target length 37 alignment score : 3.96867e-07
Although the generality of key-point allows for tracking different kinds of objects , without any face-specific knowledge its discriminant power between target and clutter might be in peril under tough conditions , e.g. strong background noise . 
NULL ({ }) Although ({ 1 }) the ({ 2 }) generality ({ 3 }) of ({ 4 }) key-points ({ 5 }) allows ({ 6 }) for ({ 7 }) tracking ({ 8 }) different ({ 9 }) kinds ({ 10 }) of ({ 11 }) objects ({ 12 }) , ({ 13 }) without ({ 14 }) any ({ 15 }) face-specific ({ 16 }) knowledge ({ 17 }) its ({ 18 }) discriminant ({ 19 }) power ({ 20 }) between ({ 21 }) the ({ }) target ({ 22 }) and ({ 23 }) clutter ({ 24 }) might ({ 25 }) be ({ 26 }) in ({ 27 }) peril ({ 28 }) under ({ 29 }) tough ({ 30 }) conditions ({ 31 }) , ({ 32 }) e.g. ({ 33 }) strong ({ 34 }) background ({ 35 }) noise ({ 36 }) . ({ 37 }) 
# Sentence pair (1052) source length 21 target length 19 alignment score : 3.77313e-11
Facial features enable to track higher-level information from a human face but are weak in low video quality . 
NULL ({ 4 }) Facial ({ 1 }) features ({ 2 }) enable ({ 3 }) the ({ }) tracking ({ 5 }) of ({ }) higher-level ({ 6 }) information ({ 7 }) from ({ 8 }) a ({ 9 }) human ({ 10 }) face ({ 11 }) , ({ }) but ({ 12 }) are ({ 13 }) weak ({ 14 }) in ({ 15 }) lower ({ 16 }) video ({ 17 }) quality ({ 18 }) . ({ 19 }) 
# Sentence pair (1053) source length 29 target length 29 alignment score : 8.5665e-13
Most facial-feature-based face trackers [6 , 10] are only tested by using non-broadcast video , e.g. webcam video , and their application potentiality to broadcast video is questionable . 
NULL ({ 11 }) Most ({ 1 }) facial-feature-based ({ 2 }) face ({ 3 }) trackers ({ 4 }) [6 ({ 5 }) , ({ 6 }) 10] ({ 7 }) have ({ 8 }) been ({ }) tested ({ 10 }) using ({ 12 }) only ({ 9 }) non-broadcast ({ 13 }) video ({ 14 }) , ({ 15 }) e.g. ({ 16 }) webcam ({ 17 }) video ({ 18 }) , ({ 19 }) and ({ 20 }) their ({ 21 }) application ({ 22 }) potentiality ({ 23 }) to ({ 24 }) broadcast ({ 25 }) video ({ 26 }) is ({ 27 }) questionable ({ 28 }) . ({ 29 }) 
# Sentence pair (1054) source length 11 target length 11 alignment score : 0.0182183
Note that these different cues described above may be combined . 
NULL ({ }) Note ({ 1 }) that ({ 2 }) these ({ 3 }) different ({ 4 }) cues ({ 5 }) described ({ 6 }) above ({ 7 }) may ({ 8 }) be ({ 9 }) combined ({ 10 }) . ({ 11 }) 
# Sentence pair (1055) source length 29 target length 28 alignment score : 3.08304e-07
An appearance-based or featureless tracker matches an observation model of the entire facial appearance with the input image , instead of choosing a few features to track . 
NULL ({ }) An ({ 1 }) appearance-based ({ 2 }) or ({ 3 }) featureless ({ 4 }) tracker ({ 5 }) matches ({ 6 }) an ({ 7 }) observation ({ 8 }) model ({ 9 }) of ({ 10 }) the ({ 11 }) entire ({ 12 }) facial ({ 13 }) appearance ({ 14 }) with ({ 15 }) the ({ 16 }) input ({ 17 }) image ({ 18 }) , ({ 19 }) instead ({ 20 }) of ({ 21 }) choosing ({ 22 }) only ({ }) a ({ 23 }) few ({ 24 }) features ({ 25 }) to ({ 26 }) track ({ 27 }) . ({ 28 }) 
# Sentence pair (1056) source length 15 target length 14 alignment score : 1.14381e-12
One example of appearance-based face tracker is [1] that has been introduced above . 
NULL ({ }) One ({ 1 }) example ({ 2 }) of ({ 3 }) an ({ }) appearance-based ({ 4 10 11 }) face ({ 5 }) tracker ({ 6 }) is ({ 7 }) [1] ({ 8 }) , ({ }) which ({ 9 }) was ({ }) introduced ({ 12 }) above ({ 13 }) . ({ 14 }) 
# Sentence pair (1057) source length 25 target length 25 alignment score : 1.68855e-08
Another example is proposed by Li et al [9] , which uses a multi-view face detector to detect and track faces of different poses . 
NULL ({ }) Another ({ 1 }) example ({ 2 }) was ({ 3 }) proposed ({ 4 }) by ({ 5 }) Li ({ 6 }) et ({ 7 }) al. ({ 8 }) [9] ({ 9 }) , ({ 10 }) which ({ 11 }) uses ({ 12 }) a ({ 13 }) multi-view ({ 14 }) face ({ 15 }) detector ({ 16 }) to ({ 17 }) detect ({ 18 }) and ({ 19 }) track ({ 20 }) faces ({ 21 }) from ({ 22 }) different ({ 23 }) poses ({ 24 }) . ({ 25 }) 
# Sentence pair (1058) source length 20 target length 20 alignment score : 0.000193475
Besides the face-based observation model , a head model is also included to represent the information of head rear . 
NULL ({ }) Besides ({ 1 }) the ({ 2 }) face-based ({ 3 }) observation ({ 4 }) model ({ 5 }) , ({ 6 }) a ({ 7 }) head ({ 8 }) model ({ 9 }) is ({ 10 }) also ({ 11 }) included ({ 12 }) to ({ 13 }) represent ({ 14 }) the ({ 15 }) information ({ 16 }) of ({ 17 }) head ({ 18 }) rear ({ 19 }) . ({ 20 }) 
# Sentence pair (1059) source length 33 target length 30 alignment score : 3.28002e-13
It is based on the idea that head can be considered as the object of interest instead of face because face is not always present in the tracking process . 
NULL ({ 12 13 }) It ({ 1 }) is ({ 2 }) based ({ 3 }) on ({ 4 }) the ({ 5 }) idea ({ 6 }) that ({ 7 }) a ({ }) head ({ 8 }) can ({ 9 }) be ({ 10 }) considered ({ 11 }) an ({ }) object ({ 14 }) of ({ 15 }) interest ({ 16 }) instead ({ 17 }) of ({ 18 }) a ({ }) face ({ 19 }) , ({ }) because ({ 20 }) the ({ }) face ({ 21 }) is ({ 22 }) not ({ 23 }) always ({ 24 }) present ({ 25 }) in ({ 26 }) the ({ 27 }) tracking ({ 28 }) process ({ 29 }) . ({ 30 }) 
# Sentence pair (1060) source length 34 target length 33 alignment score : 7.41988e-08
An extended particle filter is proposed to fuse these two interrelated information so as to handle the occlusion due to out-of-plane head rotation ( yaw ) that is more than 90 degrees . 
NULL ({ }) An ({ 1 }) extended ({ 2 }) particle ({ 3 }) filter ({ 4 }) is ({ 5 }) proposed ({ 6 }) to ({ 7 }) fuse ({ 8 }) these ({ 9 }) two ({ 10 }) interrelated ({ 11 }) information ({ 12 }) together ({ }) so ({ 13 }) as ({ 14 }) to ({ 15 }) handle ({ 16 }) the ({ 17 }) occlusion ({ 18 }) due ({ 19 }) to ({ 20 }) out-of-plane ({ 21 }) head ({ 22 }) rotation ({ 23 }) ( ({ 24 }) yaw ({ 25 }) ) ({ 26 }) that ({ 27 }) is ({ 28 }) more ({ 29 }) than ({ 30 }) 90 ({ 31 }) degrees ({ 32 }) . ({ 33 }) 
# Sentence pair (1061) source length 33 target length 33 alignment score : 4.83432e-08
During the tracking procedure , face tracking systems usually employ a motion model that describes how the image of the target might change for different possible motions of the face to track . 
NULL ({ }) During ({ 1 }) the ({ 2 }) tracking ({ 3 }) procedure ({ 4 }) , ({ 5 }) face ({ 6 }) tracking ({ 7 }) systems ({ 8 }) usually ({ 9 }) use ({ 10 }) a ({ 11 }) motion ({ 12 }) model ({ 13 }) that ({ 14 }) describes ({ 15 }) how ({ 16 }) the ({ 17 }) image ({ 18 }) of ({ 19 }) the ({ 20 }) target ({ 21 }) might ({ 22 }) change ({ 23 }) for ({ 24 }) different ({ 25 }) possible ({ 26 }) motions ({ 27 }) of ({ 28 }) the ({ 29 }) face ({ 30 }) to ({ 31 }) track ({ 32 }) . ({ 33 }) 
# Sentence pair (1062) source length 10 target length 9 alignment score : 8.57495e-05
Examples of simple motion models are as follows . 
NULL ({ }) Some ({ 1 }) examples ({ }) of ({ 2 }) simple ({ 3 }) motion ({ 4 }) models ({ 5 }) are ({ 6 }) as ({ 7 }) follows ({ 8 }) . ({ 9 }) 
# Sentence pair (1063) source length 45 target length 45 alignment score : 4.8371e-12
Based on the assumption that face can be considered as a planar object , the corresponding motion model can be a 2D transformation , e.g. affine transformation or homography , of an image of the face , e.g. the initial frame [3 , 6] . 
NULL ({ 10 }) Based ({ 1 }) on ({ 2 }) the ({ 3 }) assumption ({ 4 }) that ({ 5 }) a ({ }) face ({ 6 }) can ({ 7 }) be ({ 8 }) considered ({ 9 }) a ({ 11 }) planar ({ 12 }) object ({ 13 }) , ({ 14 }) the ({ 15 }) corresponding ({ 16 }) motion ({ 17 }) model ({ 18 }) can ({ 19 }) be ({ 20 }) a ({ 21 }) 2D ({ 22 }) transformation ({ 23 }) , ({ 24 }) e.g. ({ 25 }) affine ({ 26 }) transformation ({ 27 }) or ({ 28 }) homography ({ 29 }) , ({ 30 }) of ({ 31 }) an ({ 32 }) image ({ 33 }) of ({ 34 }) the ({ 35 }) face ({ 36 }) , ({ 37 }) e.g. ({ 38 }) the ({ 39 }) initial ({ 40 }) frame ({ 41 }) [3 ({ 42 }) , ({ 43 }) 6] ({ 44 }) . ({ 45 }) 
# Sentence pair (1064) source length 27 target length 27 alignment score : 6.34893e-08
Some researchers assume the face as a rigid 3D object , thus the motion model defines its aspect depending on its 3D position and orientation [10] . 
NULL ({ 4 }) Some ({ 1 }) researchers ({ 2 }) view ({ 3 }) a ({ }) face ({ 5 }) as ({ 6 }) a ({ 7 }) rigid ({ 8 }) 3D ({ 9 }) object ({ 10 }) , ({ 11 }) thus ({ 12 }) the ({ 13 }) motion ({ 14 }) model ({ 15 }) defines ({ 16 }) its ({ 17 }) aspect ({ 18 }) depending ({ 19 }) on ({ 20 }) its ({ 21 }) 3D ({ 22 }) position ({ 23 }) and ({ 24 }) orientation ({ 25 }) [10] ({ 26 }) . ({ 27 }) 
# Sentence pair (1065) source length 11 target length 10 alignment score : 0.00565559
However , face is actually both 3D and deformable . 
NULL ({ }) However ({ 1 }) , ({ 2 }) a ({ }) face ({ 3 }) is ({ 4 }) actually ({ 5 }) both ({ 6 }) 3D ({ 7 }) and ({ 8 }) deformable ({ 9 }) . ({ 10 }) 
# Sentence pair (1066) source length 35 target length 35 alignment score : 1.19457e-11
Some system try to model face in this sense , and the image of deformable faces can be covered with a mesh , i.e. a sophisticated geometry and texture face model [2 , 7] . 
NULL ({ }) Some ({ 1 }) systems ({ 2 }) try ({ 3 }) to ({ 4 }) model ({ 5 }) faces ({ 6 }) in ({ 7 }) this ({ 8 }) sense ({ 9 }) , ({ 10 }) and ({ 11 }) the ({ 12 }) image ({ 13 }) of ({ 14 }) deformed ({ 15 }) face ({ 16 }) can ({ 17 }) be ({ 18 }) covered ({ 19 }) with ({ 20 }) a ({ 21 }) mesh ({ 22 }) , ({ 23 }) i.e. ({ 24 }) a ({ 25 }) sophisticated ({ 26 }) geometry ({ 27 }) and ({ 28 }) texture ({ 29 }) face ({ 30 }) model ({ 31 }) [2 ({ 32 }) , ({ 33 }) 7] ({ 34 }) . ({ 35 }) 
# Sentence pair (1067) source length 17 target length 17 alignment score : 0.00182621
The motion of the face is defined by the position of the nodes of the mesh . 
NULL ({ }) The ({ 1 }) motion ({ 2 }) of ({ 3 }) the ({ 4 }) face ({ 5 }) is ({ 6 }) defined ({ 7 }) by ({ 8 }) the ({ 9 }) position ({ 10 }) of ({ 11 }) the ({ 12 }) nodes ({ 13 }) of ({ 14 }) the ({ 15 }) mesh ({ 16 }) . ({ 17 }) 
# Sentence pair (1068) source length 29 target length 25 alignment score : 2.5846e-14
Generally if the quality of the video is high , more sophisticated motion model is used , more accurate result the face tracker generates . 
NULL ({ }) Generally ({ 1 }) if ({ 2 }) the ({ 3 }) quality ({ 4 }) of ({ 5 }) the ({ 6 }) video ({ 7 }) is ({ 8 }) high ({ 9 }) , ({ 10 }) a ({ }) more ({ 11 }) sophisticated ({ 12 }) motion ({ 13 }) model ({ 14 }) is ({ 15 }) used ({ 16 }) , ({ 17 }) and ({ }) then ({ }) the ({ 21 }) face ({ 22 }) tracker ({ 23 }) generates ({ 24 }) a ({ }) more ({ 18 }) accurate ({ 19 }) result ({ 20 }) . ({ 25 }) 
# Sentence pair (1069) source length 34 target length 25 alignment score : 1.715e-13
For instance , a sophisticated geometry and texture model might suffer from false face detections and drifting less than a simple 2D transformation model . 
NULL ({ }) For ({ 1 }) instance ({ 2 }) , ({ 3 }) a ({ 4 }) sophisticated ({ 5 }) geometry ({ 6 }) and ({ 7 }) texture ({ 8 }) model ({ 9 }) might ({ 10 }) suffer ({ 11 }) from ({ 12 }) false ({ 13 }) face ({ 14 }) detections ({ 15 }) and ({ 16 }) a ({ }) level ({ }) of ({ }) drifting ({ 17 }) [less ({ 18 }) than ({ 19 }) / ({ }) that ({ }) is ({ }) worse ({ }) than ({ }) ?] ({ }) a ({ 20 }) simple ({ 21 }) 2D ({ 22 }) transformation ({ 23 }) model ({ 24 }) . ({ 25 }) 
# Sentence pair (1070) source length 48 target length 42 alignment score : 1.48731e-15
But note that most 3D-based and mesh-based face trackers require relatively clear appearance , high resolution , and limited pose variation of the face , e.g. out-of-plane head rotations ( roll and yaw ) that are far less than 90 degrees . 
NULL ({ }) However ({ 1 }) , ({ }) it ({ }) must ({ }) be ({ }) noted ({ 2 }) that ({ 3 }) most ({ 4 }) 3D-based ({ 5 }) and ({ 6 }) mesh-based ({ 7 }) face ({ 8 }) trackers ({ 9 }) require ({ 10 }) a ({ }) relatively ({ 11 }) clear ({ 12 }) appearance ({ 13 }) , ({ 14 }) high ({ 15 }) resolution ({ 16 }) , ({ 17 }) and ({ 18 }) a ({ }) limited ({ 19 }) pose ({ 20 }) variation ({ 21 }) of ({ 22 }) the ({ 23 }) face ({ 24 }) , ({ 25 }) e.g. ({ 26 }) out-of-plane ({ 27 }) head ({ 28 }) rotations ({ 29 }) ( ({ 30 }) roll ({ 31 }) and ({ 32 }) yaw ({ 33 }) ) ({ 34 }) that ({ 35 }) are ({ 36 }) far ({ 37 }) less ({ 38 }) than ({ 39 }) 90 ({ 40 }) degrees ({ 41 }) . ({ 42 }) 
# Sentence pair (1071) source length 14 target length 14 alignment score : 0.0085881
Both of these requirements are always unavailable in the case of broadcast video . 
NULL ({ }) Both ({ 1 }) of ({ 2 }) these ({ 3 }) requirements ({ 4 }) are ({ 5 }) always ({ 6 }) unavailable ({ 7 }) in ({ 8 }) the ({ 9 }) case ({ 10 }) of ({ 11 }) broadcast ({ 12 }) video ({ 13 }) . ({ 14 }) 
# Sentence pair (1072) source length 25 target length 25 alignment score : 3.0047e-05
Therefore , most 3D-based and mesh-based face trackers are only tested by using non-broadcast video , e.g. webcam video [2 , 7 , 10] . 
NULL ({ }) Therefore ({ 1 }) , ({ 2 }) most ({ 3 }) 3D-based ({ 4 }) and ({ 5 }) mesh-based ({ 6 }) face ({ 7 }) trackers ({ 8 }) are ({ 9 }) only ({ 10 }) tested ({ 11 }) by ({ 12 }) using ({ 13 }) non-broadcast ({ 14 }) video ({ 15 }) , ({ 16 }) e.g. ({ 17 }) webcam ({ 18 }) video ({ 19 }) [2 ({ 20 }) , ({ 21 }) 7 ({ 22 }) , ({ 23 }) 10] ({ 24 }) . ({ 25 }) 
# Sentence pair (1073) source length 9 target length 9 alignment score : 0.0229591
Finally , the stopping procedure is rarely discussed . 
NULL ({ }) Finally ({ 1 }) , ({ 2 }) the ({ 3 }) stopping ({ 4 }) procedure ({ 5 }) is ({ 6 }) rarely ({ 7 }) discussed ({ 8 }) . ({ 9 }) 
# Sentence pair (1074) source length 29 target length 28 alignment score : 1.06759e-09
This constitutes a major deficiency of face tracking algorithms that are generally not able to stop a face track in case of tracking error , i.e. drifting . 
NULL ({ }) This ({ 1 }) constitutes ({ 2 }) a ({ 3 }) major ({ 4 }) deficiency ({ 5 }) for ({ 6 }) the ({ }) face ({ 7 }) tracking ({ 8 }) algorithms ({ 9 }) that ({ 10 }) are ({ 11 }) generally ({ 12 }) not ({ 13 }) able ({ 14 }) to ({ 15 }) stop ({ 16 }) a ({ 17 }) face ({ 18 }) track ({ 19 }) in ({ 20 }) case ({ 21 }) of ({ 22 }) tracking ({ 23 }) errors ({ 24 }) , ({ 25 }) i.e. ({ 26 }) drifting ({ 27 }) . ({ 28 }) 
# Sentence pair (1075) source length 32 target length 32 alignment score : 1.44604e-06
Arnaud et al [3] proposed an approach that uses a general object tracker for face tracking and a stopping criterion based on the addition of an eye tracker to alleviate drifting . 
NULL ({ }) Arnaud ({ 1 }) et ({ 2 }) al. ({ 3 }) [3] ({ 4 }) proposed ({ 5 }) an ({ 6 }) approach ({ 7 }) that ({ 8 }) uses ({ 9 }) a ({ 10 }) general ({ 11 }) object ({ 12 }) tracker ({ 13 }) for ({ 14 }) face ({ 15 }) tracking ({ 16 }) and ({ 17 }) a ({ 18 }) stopping ({ 19 }) criterion ({ 20 }) based ({ 21 }) on ({ 22 }) the ({ 23 }) addition ({ 24 }) of ({ 25 }) an ({ 26 }) eye ({ 27 }) tracker ({ 28 }) to ({ 29 }) alleviate ({ 30 }) drifting ({ 31 }) . ({ 32 }) 
# Sentence pair (1076) source length 15 target length 12 alignment score : 9.86879e-08
Two positions of tracked eyes are compared with tracked face position . 
NULL ({ }) The ({ }) two ({ 1 }) positions ({ 2 }) of ({ 3 }) the ({ }) tracked ({ 4 }) eyes ({ 5 }) are ({ 6 }) compared ({ 7 }) with ({ 8 }) the ({ }) tracked ({ 9 }) face ({ 10 }) position ({ 11 }) . ({ 12 }) 
# Sentence pair (1077) source length 25 target length 26 alignment score : 1.54505e-10
If none of the two eyes are in the face region , it will be determined as drifting and the tracking process will be stopped . 
NULL ({ }) If ({ 1 }) neither ({ 2 }) of ({ 3 }) the ({ 4 }) eyes ({ 5 6 }) is ({ 7 }) in ({ 8 }) the ({ 9 }) face ({ 10 }) region ({ 11 }) , ({ 12 }) it ({ 13 }) will ({ 14 }) be ({ 15 }) determined ({ 16 }) as ({ 17 }) drifting ({ 18 }) and ({ 19 }) the ({ 20 }) tracking ({ 21 }) process ({ 22 }) will ({ 23 }) be ({ 24 }) stopped ({ 25 }) . ({ 26 }) 
# Sentence pair (1078) source length 17 target length 17 alignment score : 1.84604e-10
Besides , most mesh-based trackers and top-down trackers are considered to be able to avoid drifting . 
NULL ({ }) In ({ }) addition ({ 1 }) , ({ 2 }) most ({ 3 }) mesh-based ({ 4 5 }) and ({ 6 }) top-down ({ 7 }) trackers ({ 8 }) are ({ 9 }) assumed ({ 10 }) to ({ 11 }) be ({ 12 }) able ({ 13 }) to ({ 14 }) avoid ({ 15 }) drifting ({ 16 }) . ({ 17 }) 
# Sentence pair (1079) source length 25 target length 25 alignment score : 9.25754e-07
Face tracking has attracted much attention from researchers in communities including multimedia content analysis , computer vision , etc. because of its wide application . 
NULL ({ }) Face ({ 1 }) tracking ({ 2 }) has ({ 3 }) attracted ({ 4 }) much ({ 5 }) attention ({ 6 }) from ({ 7 }) researchers ({ 8 }) in ({ 9 }) communities ({ 10 }) including ({ 11 }) multimedia ({ 12 }) content ({ 13 }) analysis ({ 14 }) , ({ 15 }) computer ({ 16 }) vision ({ 17 }) , ({ 18 }) etc. ({ 19 }) because ({ 20 }) of ({ 21 }) its ({ 22 }) wide ({ 23 }) applications ({ 24 }) . ({ 25 }) 
# Sentence pair (1080) source length 34 target length 34 alignment score : 1.74438e-17
However , while most attempts have been made on face tracking for videos with high quality by computer vision researchers , only a limited number of face trackers are designed for broadcast video . 
NULL ({ }) However ({ 1 }) , ({ 2 }) while ({ 3 }) most ({ 4 }) of ({ }) the ({ }) attempts ({ 5 }) have ({ 6 }) been ({ 7 }) on ({ 9 }) the ({ }) face ({ 10 }) tracking ({ 11 }) for ({ 12 }) high-quality ({ 8 13 14 15 }) videos ({ 16 }) by ({ 17 }) computer ({ 18 }) vision ({ 19 }) researchers ({ 20 }) , ({ 21 }) only ({ 22 }) a ({ 23 }) limited ({ 24 }) number ({ 25 }) of ({ 26 }) face ({ 27 }) trackers ({ 28 }) are ({ 29 }) designed ({ 30 }) for ({ 31 }) broadcast ({ 32 }) video ({ 33 }) . ({ 34 }) 
# Sentence pair (1081) source length 35 target length 34 alignment score : 2.73434e-07
This is because the current ability of face tracking still depends on relatively clear appearance , high resolution , and limited pose variation of the face , which are unavailable in broadcast video . 
NULL ({ }) This ({ 1 }) is ({ 2 }) because ({ 3 }) the ({ 4 }) current ({ 5 }) ability ({ 6 }) of ({ 7 }) face ({ 8 }) tracking ({ 9 }) still ({ 10 }) depends ({ 11 }) on ({ 12 }) a ({ }) relatively ({ 13 }) clear ({ 14 }) appearance ({ 15 }) , ({ 16 }) high ({ 17 }) resolution ({ 18 }) , ({ 19 }) and ({ 20 }) limited ({ 21 }) pose ({ 22 }) variation ({ 23 }) of ({ 24 }) the ({ 25 }) face ({ 26 }) , ({ 27 }) which ({ 28 }) are ({ 29 }) unavailable ({ 30 }) in ({ 31 }) broadcast ({ 32 }) video ({ 33 }) . ({ 34 }) 
# Sentence pair (1082) source length 22 target length 22 alignment score : 0.000334159
On the other hand , currently proposed face trackers are still evaluated by using different types of videos and different criteria . 
NULL ({ }) On ({ 1 }) the ({ 2 }) other ({ 3 }) hand ({ 4 }) , ({ 5 }) currently ({ 6 }) proposed ({ 7 }) face ({ 8 }) trackers ({ 9 }) are ({ 10 }) still ({ 11 }) evaluated ({ 12 }) by ({ 13 }) using ({ 14 }) different ({ 15 }) types ({ 16 }) of ({ 17 }) videos ({ 18 }) and ({ 19 }) different ({ 20 }) criteria ({ 21 }) . ({ 22 }) 
# Sentence pair (1083) source length 29 target length 26 alignment score : 8.16e-10
A general evaluation criterion , in terms of speed , robustness and accuracy , is needed for performance comparison between face trackers of different purposes . 
NULL ({ }) A ({ 1 }) general ({ 2 }) evaluation ({ 3 }) criterion ({ 4 }) , ({ 5 }) in ({ 6 }) terms ({ 7 }) of ({ 8 }) speed ({ 9 }) , ({ 10 }) robustness ({ 11 }) , ({ }) and ({ 12 }) accuracy ({ 13 }) , ({ 14 }) is ({ 15 }) needed ({ 16 }) for ({ 17 }) a ({ }) performance ({ 18 }) comparison ({ 19 }) between ({ 20 }) the ({ }) face ({ 21 }) trackers ({ 22 }) with ({ 23 }) different ({ 24 }) purposes ({ 25 }) . ({ 26 }) 
# Sentence pair (1084) source length 7 target length 7 alignment score : 0.0630579
Unsupervised Face Annotation by Mining the Web 
NULL ({ }) Unsupervised ({ 1 }) Face ({ 2 }) Annotation ({ 3 }) by ({ 4 }) Mining ({ 5 }) the ({ 6 }) Web ({ 7 }) 
# Sentence pair (1085) source length 16 target length 16 alignment score : 0.00214471
Searching for images of people is an essential task for image and video search engines . 
NULL ({ }) Searching ({ 1 }) for ({ 2 }) images ({ 3 }) of ({ 4 }) people ({ 5 }) is ({ 6 }) an ({ 7 }) essential ({ 8 }) task ({ 9 }) for ({ 10 }) image ({ 11 }) and ({ 12 }) video ({ 13 }) search ({ 14 }) engines ({ 15 }) . ({ 16 }) 
# Sentence pair (1086) source length 33 target length 33 alignment score : 5.42716e-06
However , current search engines have limited capabilities for this task since they rely on text associated with images and video , and such text is likely to return many irrelevant results . 
NULL ({ }) However ({ 1 }) , ({ 2 }) current ({ 3 }) search ({ 4 }) engines ({ 5 }) have ({ 6 }) limited ({ 7 }) capabilities ({ 8 }) for ({ 9 }) this ({ 10 }) task ({ 11 }) since ({ 12 }) they ({ 13 }) rely ({ 14 }) on ({ 15 }) text ({ 16 }) associated ({ 17 }) with ({ 18 }) images ({ 19 }) and ({ 20 }) video ({ 21 }) , ({ 22 }) and ({ 23 }) such ({ 24 }) text ({ 25 }) is ({ 26 }) likely ({ 27 }) to ({ 28 }) return ({ 29 }) many ({ 30 }) irrelevant ({ 31 }) results ({ 32 }) . ({ 33 }) 
# Sentence pair (1087) source length 24 target length 24 alignment score : 5.74276e-09
We propose a method to retrieve relevant faces for one person by learning the visual consistency among results retrieved from text-correlation-based search engines . 
NULL ({ }) We ({ 1 }) propose ({ 2 }) a ({ 3 }) method ({ 4 }) for ({ 5 }) retrieving ({ 6 }) relevant ({ 7 }) faces ({ 8 }) of ({ 9 }) one ({ 10 }) person ({ 11 }) by ({ 12 }) learning ({ 13 }) the ({ 14 }) visual ({ 15 }) consistency ({ 16 }) among ({ 17 }) results ({ 18 }) retrieved ({ 19 }) from ({ 20 }) text-correlation-based ({ 21 }) search ({ 22 }) engines ({ 23 }) . ({ 24 }) 
# Sentence pair (1088) source length 7 target length 7 alignment score : 0.0888372
The method consists of two steps . 
NULL ({ }) The ({ 1 }) method ({ 2 }) consists ({ 3 }) of ({ 4 }) two ({ 5 }) steps ({ 6 }) . ({ 7 }) 
# Sentence pair (1089) source length 30 target length 30 alignment score : 1.84187e-07
In the first step , each candidate face obtained from a text-based search engine is ranked by a score that measures the distribution of visual similarities among the faces . 
NULL ({ }) In ({ 1 }) the ({ 2 }) first ({ 3 }) step ({ 4 }) , ({ 5 }) each ({ 6 }) candidate ({ 7 }) face ({ 8 }) obtained ({ 9 }) from ({ 10 }) a ({ 11 }) text-based ({ 12 }) search ({ 13 }) engine ({ 14 }) is ({ 15 }) ranked ({ 16 }) with ({ 17 }) a ({ 18 }) score ({ 19 }) that ({ 20 }) measures ({ 21 }) the ({ 22 }) distribution ({ 23 }) of ({ 24 }) visual ({ 25 }) similarities ({ 26 }) among ({ 27 }) the ({ 28 }) faces ({ 29 }) . ({ 30 }) 
# Sentence pair (1090) source length 21 target length 19 alignment score : 1.15851e-05
Faces that are possibly very relevant or irrelevant are ranked at the top or bottom of the list . 
NULL ({ }) Faces ({ 1 }) that ({ 2 }) are ({ 3 }) possibly ({ 4 }) very ({ 5 }) relevant ({ 6 }) or ({ 7 }) irrelevant ({ 8 }) are ({ 9 }) ranked ({ 10 }) at ({ 11 }) the ({ 12 }) top ({ 13 }) or ({ 14 }) bottom ({ 15 }) of ({ 16 }) the ({ 17 }) list ({ 18 }) , ({ }) respectively ({ }) . ({ 19 }) 
# Sentence pair (1091) source length 43 target length 43 alignment score : 3.73918e-08
The second step improves this ranking by treating this problem as a classification problem in which input faces are classified as 'person-$X$' or 'non-person-$X$' ; and the faces are re-ranked according to their relevant score inferred from the classifier 's probability output . 
NULL ({ }) The ({ 1 }) second ({ 2 }) step ({ 3 }) improves ({ 4 }) this ({ 5 }) ranking ({ 6 }) by ({ 7 }) treating ({ 8 }) this ({ 9 }) problem ({ 10 }) as ({ 11 }) a ({ 12 }) classification ({ 13 }) problem ({ 14 }) in ({ 15 }) which ({ 16 }) input ({ 17 }) faces ({ 18 }) are ({ 19 }) classified ({ 20 }) as ({ 21 }) 'person-$X$' ({ 22 }) or ({ 23 }) 'non-person-$X$' ({ 24 }) ; ({ 25 }) and ({ 26 }) the ({ 27 }) faces ({ 28 }) are ({ 29 }) re-ranked ({ 30 }) according ({ 31 }) to ({ 32 }) their ({ 33 }) relevant ({ 34 }) score ({ 35 }) inferred ({ 36 }) from ({ 37 }) the ({ 38 }) classifier ({ 39 }) 's ({ 40 }) probability ({ 41 }) output ({ 42 }) . ({ 43 }) 
# Sentence pair (1092) source length 22 target length 22 alignment score : 0.000347895
To train this classifier , we use a bagging-based framework to combine results from multiple weak classifiers trained using different subsets . 
NULL ({ }) To ({ 1 }) train ({ 2 }) this ({ 3 }) classifier ({ 4 }) , ({ 5 }) we ({ 6 }) use ({ 7 }) a ({ 8 }) bagging-based ({ 9 }) framework ({ 10 }) to ({ 11 }) combine ({ 12 }) results ({ 13 }) from ({ 14 }) multiple ({ 15 }) weak ({ 16 }) classifiers ({ 17 }) trained ({ 18 }) using ({ 19 }) different ({ 20 }) subsets ({ 21 }) . ({ 22 }) 
# Sentence pair (1093) source length 22 target length 22 alignment score : 0.000320341
These training subsets are extracted and labeled automatically from the rank list produced from the classifier trained from the previous step . 
NULL ({ }) These ({ 1 }) training ({ 2 }) subsets ({ 3 }) are ({ 4 }) extracted ({ 5 }) and ({ 6 }) labeled ({ 7 }) automatically ({ 8 }) from ({ 9 }) the ({ 10 }) rank ({ 11 }) list ({ 12 }) produced ({ 13 }) from ({ 14 }) the ({ 15 }) classifier ({ 16 }) trained ({ 17 }) from ({ 18 }) the ({ 19 }) previous ({ 20 }) step ({ 21 }) . ({ 22 }) 
# Sentence pair (1094) source length 17 target length 17 alignment score : 0.0012917
In this way , the accuracy of the ranked list increases after a number of iterations . 
NULL ({ }) In ({ 1 }) this ({ 2 }) way ({ 3 }) , ({ 4 }) the ({ 5 }) accuracy ({ 6 }) of ({ 7 }) the ({ 8 }) ranked ({ 9 }) list ({ 10 }) increases ({ 11 }) after ({ 12 }) a ({ 13 }) number ({ 14 }) of ({ 15 }) iterations ({ 16 }) . ({ 17 }) 
# Sentence pair (1095) source length 35 target length 35 alignment score : 1.27395e-06
Experimental results on various face sets retrieved from captions of news photos show that the retrieval performance improved after each iteration , with the final performance being higher than those of the existing algorithms . 
NULL ({ }) Experimental ({ 1 }) results ({ 2 }) on ({ 3 }) various ({ 4 }) face ({ 5 }) sets ({ 6 }) retrieved ({ 7 }) from ({ 8 }) captions ({ 9 }) of ({ 10 }) news ({ 11 }) photos ({ 12 }) show ({ 13 }) that ({ 14 }) the ({ 15 }) retrieval ({ 16 }) performance ({ 17 }) improved ({ 18 }) after ({ 19 }) each ({ 20 }) iteration ({ 21 }) , ({ 22 }) with ({ 23 }) the ({ 24 }) final ({ 25 }) performance ({ 26 }) being ({ 27 }) higher ({ 28 }) than ({ 29 }) those ({ 30 }) of ({ 31 }) the ({ 32 }) existing ({ 33 }) algorithms ({ 34 }) . ({ 35 }) 
# Sentence pair (1096) source length 22 target length 22 alignment score : 7.51084e-05
With the rapid growth of digital technology , large image and video databases have become more available than ever to users . 
NULL ({ }) With ({ 1 }) the ({ 2 }) rapid ({ 3 }) growth ({ 4 }) of ({ 5 }) digital ({ 6 }) technology ({ 7 }) , ({ 8 }) large ({ 9 }) image ({ 10 }) and ({ 11 }) video ({ 12 }) databases ({ 13 }) have ({ 14 }) become ({ 15 }) more ({ 16 }) available ({ 17 }) than ({ 18 }) ever ({ 19 }) to ({ 20 }) users ({ 21 }) . ({ 22 }) 
# Sentence pair (1097) source length 18 target length 20 alignment score : 4.55636e-10
This trend has shown the need for effective and efficient tools for indexing and retrieving based on visual content . 
NULL ({ 17 }) This ({ 1 }) trend ({ 2 }) has ({ 3 }) shown ({ 4 }) the ({ 5 }) need ({ 6 }) for ({ 7 }) effective ({ 8 }) and ({ 9 }) efficient ({ 10 }) tools ({ 11 }) for ({ 12 }) indexing ({ 13 }) and ({ 14 }) retrieving ({ 15 16 }) visual ({ 18 }) content ({ 19 }) . ({ 20 }) 
# Sentence pair (1098) source length 16 target length 16 alignment score : 0.00221398
A typical application is searching for a specific person by providing his or her name . 
NULL ({ }) A ({ 1 }) typical ({ 2 }) application ({ 3 }) is ({ 4 }) searching ({ 5 }) for ({ 6 }) a ({ 7 }) specific ({ 8 }) person ({ 9 }) by ({ 10 }) providing ({ 11 }) his ({ 12 }) or ({ 13 }) her ({ 14 }) name ({ 15 }) . ({ 16 }) 
# Sentence pair (1099) source length 19 target length 19 alignment score : 0.000486114
Most current search engines use the text associated with images and video as significant clues for returning results . 
NULL ({ }) Most ({ 1 }) current ({ 2 }) search ({ 3 }) engines ({ 4 }) use ({ 5 }) the ({ 6 }) text ({ 7 }) associated ({ 8 }) with ({ 9 }) images ({ 10 }) and ({ 11 }) video ({ 12 }) as ({ 13 }) significant ({ 14 }) clues ({ 15 }) for ({ 16 }) returning ({ 17 }) results ({ 18 }) . ({ 19 }) 
# Sentence pair (1100) source length 26 target length 28 alignment score : 1.97817e-16
However , other un-queried faces and names may appear with the queried ones ( as shown in Figure xx ) , and this significantly lowers retrieval performance . 
NULL ({ 15 16 17 }) However ({ 1 }) , ({ 2 }) other ({ 3 }) un-queried ({ 4 }) faces ({ 5 }) and ({ 6 }) names ({ 7 }) may ({ 8 }) appear ({ 9 }) with ({ 10 }) the ({ 11 }) queried ({ 12 }) ones ({ 13 }) ( ({ 14 }) Figure ({ 18 }) xx ({ 19 }) ) ({ 20 }) , ({ 21 }) and ({ 22 }) this ({ 23 }) significantly ({ 24 }) lowers ({ 25 }) the ({ }) retrieval ({ 26 }) performance ({ 27 }) . ({ 28 }) 
# Sentence pair (1101) source length 20 target length 20 alignment score : 0.000510932
One way to improve the retrieval performance is to take into account visual information present in the retrieved faces . 
NULL ({ }) One ({ 1 }) way ({ 2 }) to ({ 3 }) improve ({ 4 }) the ({ 5 }) retrieval ({ 6 }) performance ({ 7 }) is ({ 8 }) to ({ 9 }) take ({ 10 }) into ({ 11 }) account ({ 12 }) visual ({ 13 }) information ({ 14 }) present ({ 15 }) in ({ 16 }) the ({ 17 }) retrieved ({ 18 }) faces ({ 19 }) . ({ 20 }) 
# Sentence pair (1102) source length 9 target length 9 alignment score : 0.0336381
This task is challenging for the following reasons : 
NULL ({ }) This ({ 1 }) task ({ 2 }) is ({ 3 }) challenging ({ 4 }) for ({ 5 }) the ({ 6 }) following ({ 7 }) reasons ({ 8 }) : ({ 9 }) 
# Sentence pair (1103) source length 34 target length 34 alignment score : 4.40041e-10
-Large variations in facial appearance due to pose changes , illumination conditions , occlusions and facial expressions make face recognition difficult even with state-of-the-art techniques\CITE ( see an example in Figure xx ) . 
NULL ({ 28 }) -Large ({ 1 }) variations ({ 2 }) in ({ 3 }) facial ({ 4 }) appearance ({ 5 }) due ({ 6 }) to ({ 7 }) pose ({ 8 }) changes ({ 9 }) , ({ 10 }) illumination ({ 11 }) conditions ({ 12 }) , ({ 13 }) occlusions ({ 14 }) , ({ }) and ({ 15 }) facial ({ 16 }) expressions ({ 17 }) make ({ 18 }) face ({ 19 }) recognition ({ 20 }) difficult ({ 21 }) even ({ 22 }) with ({ 23 }) state-of-the-art ({ 24 }) techniques\CITE ({ 25 }) ( ({ 26 }) see ({ 27 }) example ({ 29 }) in ({ 30 }) Figure ({ 31 }) xx ({ 32 }) ) ({ 33 }) . ({ 34 }) 
# Sentence pair (1104) source length 24 target length 24 alignment score : 1.4882e-05
-The fact that the retrieved face set consists of faces of several people with no labels makes supervised and unsupervised learning methods inapplicable . 
NULL ({ }) -The ({ 1 }) fact ({ 2 }) that ({ 3 }) the ({ 4 }) retrieved ({ 5 }) face ({ 6 }) set ({ 7 }) consists ({ 8 }) of ({ 9 }) faces ({ 10 }) of ({ 11 }) several ({ 12 }) people ({ 13 }) with ({ 14 }) no ({ 15 }) labels ({ 16 }) makes ({ 17 }) supervised ({ 18 }) and ({ 19 }) unsupervised ({ 20 }) learning ({ 21 }) methods ({ 22 }) inapplicable ({ 23 }) . ({ 24 }) 
# Sentence pair (1105) source length 10 target length 10 alignment score : 0.000160378
We propose a method to solve the above problem . 
NULL ({ }) We ({ 1 }) propose ({ 2 }) a ({ 3 }) method ({ 4 }) for ({ 5 }) solving ({ 6 }) the ({ 7 }) above ({ 8 }) problem ({ 9 }) . ({ 10 }) 
# Sentence pair (1106) source length 31 target length 31 alignment score : 4.59395e-20
The main idea is to assume that there is visual consistency among the results returned from text-based search engines ; and then learn this visual consistency through an interactive process . 
NULL ({ 5 20 }) The ({ 1 }) main ({ 2 }) idea ({ 3 }) is ({ 4 }) the ({ }) assumption ({ 6 }) that ({ 7 }) there ({ 8 }) is ({ 9 }) visual ({ 10 }) consistency ({ 11 }) among ({ 12 }) the ({ 13 }) results ({ 14 }) returned ({ 15 }) from ({ 16 }) text-based ({ 17 }) search ({ 18 }) engines ({ 19 }) and ({ 21 }) this ({ 24 }) visual ({ 25 }) consistency ({ 26 }) is ({ }) then ({ 22 }) learned ({ 23 }) through ({ 27 }) an ({ 28 }) interactive ({ 29 }) process ({ 30 }) . ({ 31 }) 
# Sentence pair (1107) source length 7 target length 7 alignment score : 0.105207
This method consists of two stages . 
NULL ({ }) This ({ 1 }) method ({ 2 }) consists ({ 3 }) of ({ 4 }) two ({ 5 }) stages ({ 6 }) . ({ 7 }) 
# Sentence pair (1108) source length 23 target length 23 alignment score : 0.000223292
In the first stage , we explore the local density of faces to identify potential candidates for relevant faces and irrelevant faces . 
NULL ({ }) In ({ 1 }) the ({ 2 }) first ({ 3 }) stage ({ 4 }) , ({ 5 }) we ({ 6 }) explore ({ 7 }) the ({ 8 }) local ({ 9 }) density ({ 10 }) of ({ 11 }) faces ({ 12 }) to ({ 13 }) identify ({ 14 }) potential ({ 15 }) candidates ({ 16 }) for ({ 17 }) relevant ({ 18 }) faces ({ 19 }) and ({ 20 }) irrelevant ({ 21 }) faces ({ 22 }) . ({ 23 }) 
# Sentence pair (1109) source length 33 target length 33 alignment score : 2.07924e-06
This stage reflects the fact that the facial images of the queried person tend to form dense clusters , whereas irrelevant facial images are sparse since they look different from each other . 
NULL ({ }) This ({ 1 }) stage ({ 2 }) reflects ({ 3 }) the ({ 4 }) fact ({ 5 }) that ({ 6 }) the ({ 7 }) facial ({ 8 }) images ({ 9 }) of ({ 10 }) the ({ 11 }) queried ({ 12 }) person ({ 13 }) tend ({ 14 }) to ({ 15 }) form ({ 16 }) dense ({ 17 }) clusters ({ 18 }) , ({ 19 }) whereas ({ 20 }) irrelevant ({ 21 }) facial ({ 22 }) images ({ 23 }) are ({ 24 }) sparse ({ 25 }) since ({ 26 }) they ({ 27 }) look ({ 28 }) different ({ 29 }) from ({ 30 }) each ({ 31 }) other ({ 32 }) . ({ 33 }) 
# Sentence pair (1110) source length 17 target length 17 alignment score : 0.00219405
For each face , we define a score to measure the density of its neighbor set . 
NULL ({ }) For ({ 1 }) each ({ 2 }) face ({ 3 }) , ({ 4 }) we ({ 5 }) define ({ 6 }) a ({ 7 }) score ({ 8 }) to ({ 9 }) measure ({ 10 }) the ({ 11 }) density ({ 12 }) of ({ 13 }) its ({ 14 }) neighbor ({ 15 }) set ({ 16 }) . ({ 17 }) 
# Sentence pair (1111) source length 26 target length 30 alignment score : 1.07353e-17
This score is used to form a ranked list , in which faces having high density scores are considered relevant and are put at the top of the list . 
NULL ({ 27 28 }) This ({ 1 }) score ({ 2 }) is ({ 3 }) used ({ 4 }) to ({ 5 }) form ({ 6 }) a ({ 7 }) ranked ({ 8 }) list ({ 9 29 }) , ({ 10 }) in ({ 11 }) which ({ 12 }) faces ({ 13 }) with ({ 14 }) high-density ({ 15 16 }) scores ({ 17 }) are ({ 18 }) considered ({ 19 }) relevant ({ 20 }) and ({ 21 }) are ({ 22 }) put ({ 23 }) at ({ 24 }) the ({ 25 }) top ({ 26 }) . ({ 30 }) 
# Sentence pair (1112) source length 17 target length 17 alignment score : 0.00135237
The above ranking method is weak since dense clusters have no guarantee of containing relevant faces . 
NULL ({ }) The ({ 1 }) above ({ 2 }) ranking ({ 3 }) method ({ 4 }) is ({ 5 }) weak ({ 6 }) since ({ 7 }) dense ({ 8 }) clusters ({ 9 }) have ({ 10 }) no ({ 11 }) guarantee ({ 12 }) of ({ 13 }) containing ({ 14 }) relevant ({ 15 }) faces ({ 16 }) . ({ 17 }) 
# Sentence pair (1113) source length 13 target length 13 alignment score : 0.0094606
Therefore , a second stage is necessary to improve this ranked list . 
NULL ({ }) Therefore ({ 1 }) , ({ 2 }) a ({ 3 }) second ({ 4 }) stage ({ 5 }) is ({ 6 }) necessary ({ 7 }) to ({ 8 }) improve ({ 9 }) this ({ 10 }) ranked ({ 11 }) list ({ 12 }) . ({ 13 }) 
# Sentence pair (1114) source length 29 target length 29 alignment score : 1.57799e-05
We model this problem as a classification problem in which input faces are classified as person-\MATH ( the queried person ) or non-person-\MATH ( the un-queried person ) . 
NULL ({ }) We ({ 1 }) model ({ 2 }) this ({ 3 }) problem ({ 4 }) as ({ 5 }) a ({ 6 }) classification ({ 7 }) problem ({ 8 }) in ({ 9 }) which ({ 10 }) input ({ 11 }) faces ({ 12 }) are ({ 13 }) classified ({ 14 }) as ({ 15 }) person-\MATH ({ 16 }) ( ({ 17 }) the ({ 18 }) queried ({ 19 }) person ({ 20 }) ) ({ 21 }) or ({ 22 }) non-person-\MATH ({ 23 }) ( ({ 24 }) the ({ 25 }) un-queried ({ 26 }) person ({ 27 }) ) ({ 28 }) . ({ 29 }) 
# Sentence pair (1115) source length 19 target length 19 alignment score : 0.000538064
The faces are ranked according to a relevancy score that is inferred from the classifier 's probability output . 
NULL ({ }) The ({ 1 }) faces ({ 2 }) are ({ 3 }) ranked ({ 4 }) according ({ 5 }) to ({ 6 }) a ({ 7 }) relevancy ({ 8 }) score ({ 9 }) that ({ 10 }) is ({ 11 }) inferred ({ 12 }) from ({ 13 }) the ({ 14 }) classifier ({ 15 }) 's ({ 16 }) probability ({ 17 }) output ({ 18 }) . ({ 19 }) 
# Sentence pair (1116) source length 25 target length 25 alignment score : 0.000105075
Since annotation data is not available , the rank list from the previous step is used to assign labels for a subset of faces . 
NULL ({ }) Since ({ 1 }) annotation ({ 2 }) data ({ 3 }) is ({ 4 }) not ({ 5 }) available ({ 6 }) , ({ 7 }) the ({ 8 }) rank ({ 9 }) list ({ 10 }) from ({ 11 }) the ({ 12 }) previous ({ 13 }) step ({ 14 }) is ({ 15 }) used ({ 16 }) to ({ 17 }) assign ({ 18 }) labels ({ 19 }) for ({ 20 }) a ({ 21 }) subset ({ 22 }) of ({ 23 }) faces ({ 24 }) . ({ 25 }) 
# Sentence pair (1117) source length 22 target length 21 alignment score : 8.26416e-05
This subset is then used to train a classifier using supervised methods such as support vector machine ( SVM ) . 
NULL ({ }) This ({ 1 }) subset ({ 2 }) is ({ 3 }) then ({ 4 }) used ({ 5 }) to ({ 6 }) train ({ 7 }) a ({ 8 }) classifier ({ 9 }) using ({ 10 }) supervised ({ 11 }) methods ({ 12 }) such ({ 13 }) as ({ 14 }) a ({ }) support ({ 15 }) vector ({ 16 }) machine ({ 17 }) ( ({ 18 }) SVM ({ 19 }) ) ({ 20 }) . ({ 21 }) 
# Sentence pair (1118) source length 14 target length 14 alignment score : 0.00657663
The trained classifier is used to re-rank faces in the original input set . 
NULL ({ }) The ({ 1 }) trained ({ 2 }) classifier ({ 3 }) is ({ 4 }) used ({ 5 }) to ({ 6 }) re-rank ({ 7 }) faces ({ 8 }) in ({ 9 }) the ({ 10 }) original ({ 11 }) input ({ 12 }) set ({ 13 }) . ({ 14 }) 
# Sentence pair (1119) source length 15 target length 15 alignment score : 0.00379768
This step is repeated a number of times to get the final ranked list . 
NULL ({ }) This ({ 1 }) step ({ 2 }) is ({ 3 }) repeated ({ 4 }) a ({ 5 }) number ({ 6 }) of ({ 7 }) times ({ 8 }) to ({ 9 }) get ({ 10 }) the ({ 11 }) final ({ 12 }) ranked ({ 13 }) list ({ 14 }) . ({ 15 }) 
# Sentence pair (1120) source length 18 target length 18 alignment score : 0.00138139
Since automatically assigning labels from the ranked list is not reliable , the trained classifiers are weak . 
NULL ({ }) Since ({ 1 }) automatically ({ 2 }) assigning ({ 3 }) labels ({ 4 }) from ({ 5 }) the ({ 6 }) ranked ({ 7 }) list ({ 8 }) is ({ 9 }) not ({ 10 }) reliable ({ 11 }) , ({ 12 }) the ({ 13 }) trained ({ 14 }) classifiers ({ 15 }) are ({ 16 }) weak ({ 17 }) . ({ 18 }) 
# Sentence pair (1121) source length 38 target length 36 alignment score : 8.61319e-09
To get the final strong classifier , we use the idea of ensemble learning \CITE in which weak classifiers trained on different subsets are combined to improve the stability and classification accuracy of single classifiers . 
NULL ({ }) To ({ 1 }) obtain ({ 2 }) the ({ 3 }) final ({ 4 }) strong ({ 5 }) classifier ({ 6 }) , ({ 7 }) we ({ 8 }) use ({ 9 }) the ({ 10 }) [idea ({ }) / ({ }) concept?] ({ 11 }) of ({ 12 }) ensemble ({ 13 }) learning ({ 14 }) \CITE ({ 15 }) in ({ 16 }) which ({ 17 }) weak ({ 18 }) classifiers ({ 19 }) trained ({ 20 }) on ({ 21 }) different ({ 22 }) subsets ({ 23 }) are ({ 24 }) combined ({ 25 }) to ({ 26 }) improve ({ 27 }) the ({ 28 }) stability ({ 29 }) and ({ 30 }) classification ({ 31 }) accuracy ({ 32 }) of ({ 33 }) single ({ 34 }) classifiers ({ 35 }) . ({ 36 }) 
# Sentence pair (1122) source length 17 target length 17 alignment score : 0.00104371
The learned classifier can be further used for recognizing new facial images of the queried person . 
NULL ({ }) The ({ 1 }) learned ({ 2 }) classifier ({ 3 }) can ({ 4 }) be ({ 5 }) further ({ 6 }) used ({ 7 }) for ({ 8 }) recognizing ({ 9 }) new ({ 10 }) facial ({ 11 }) images ({ 12 }) of ({ 13 }) the ({ 14 }) queried ({ 15 }) person ({ 16 }) . ({ 17 }) 
# Sentence pair (1123) source length 15 target length 15 alignment score : 0.00334708
The second stage improves the ranked list and recognition performance for the following reasons : 
NULL ({ }) The ({ 1 }) second ({ 2 }) stage ({ 3 }) improves ({ 4 }) the ({ 5 }) ranked ({ 6 }) list ({ 7 }) and ({ 8 }) recognition ({ 9 }) performance ({ 10 }) for ({ 11 }) the ({ 12 }) following ({ 13 }) reasons ({ 14 }) : ({ 15 }) 
# Sentence pair (1124) source length 25 target length 24 alignment score : 2.19018e-05
-Supervised learning methods , such as SVM , provide a strong theoretical background for finding the optimal decision boundary even with noisy data . 
NULL ({ }) -Supervised ({ 1 }) learning ({ 2 }) methods ({ 3 }) , ({ 4 }) such ({ 5 }) as ({ 6 }) an ({ }) SVM ({ 7 }) , ({ 8 }) provide ({ 9 }) a ({ 10 }) strong ({ 11 }) theoretical ({ 12 }) background ({ 13 }) for ({ 14 }) finding ({ 15 }) the ({ 16 }) optimal ({ 17 }) decision ({ 18 }) boundary ({ 19 }) even ({ 20 }) with ({ 21 }) noisy ({ 22 }) data ({ 23 }) . ({ 24 }) 
# Sentence pair (1125) source length 18 target length 18 alignment score : 0.000224822
Furthermore , recent studies \CITE suggest that SVM classifiers provide probability outputs that are suitable for ranking . 
NULL ({ }) Furthermore ({ 1 }) , ({ 2 }) recent ({ 3 }) studies ({ 4 }) \CITE ({ 5 }) suggest ({ 6 }) that ({ 7 }) SVM ({ 8 }) classifiers ({ 9 }) provide ({ 10 }) probability ({ 11 }) outputs ({ 12 }) that ({ 13 }) are ({ 14 }) suitable ({ 15 }) for ({ 16 }) ranking ({ 17 }) . ({ 18 }) 
# Sentence pair (1126) source length 13 target length 13 alignment score : 0.00589447
-The bagging framework helps to leverage noises in the unsupervised labeling process . 
NULL ({ }) -The ({ 1 }) bagging ({ 2 }) framework ({ 3 }) helps ({ 4 }) to ({ 5 }) leverage ({ 6 }) noises ({ 7 }) in ({ 8 }) the ({ 9 }) unsupervised ({ 10 }) labeling ({ 11 }) process ({ 12 }) . ({ 13 }) 
# Sentence pair (1127) source length 5 target length 5 alignment score : 0.176974
Our contribution is two-fold : 
NULL ({ }) Our ({ 1 }) contribution ({ 2 }) is ({ 3 }) two-fold ({ 4 }) : ({ 5 }) 
# Sentence pair (1128) source length 20 target length 20 alignment score : 0.000561833
-We propose a general framework to boost the face retrieval performance of text-based search engines by visual consistency learning . 
NULL ({ }) -We ({ 1 }) propose ({ 2 }) a ({ 3 }) general ({ 4 }) framework ({ 5 }) to ({ 6 }) boost ({ 7 }) the ({ 8 }) face ({ 9 }) retrieval ({ 10 }) performance ({ 11 }) of ({ 12 }) text-based ({ 13 }) search ({ 14 }) engines ({ 15 }) by ({ 16 }) visual ({ 17 }) consistency ({ 18 }) learning ({ 19 }) . ({ 20 }) 
# Sentence pair (1129) source length 18 target length 19 alignment score : 2.68284e-06
The framework seamlessly integrates data mining techniques such as supervised learning , and unsupervised learning based on bagging . 
NULL ({ 12 }) The ({ 1 }) framework ({ 2 }) seamlessly ({ 3 }) integrates ({ 4 }) data ({ 5 }) mining ({ 6 }) techniques ({ 7 }) such ({ 8 }) as ({ 9 }) supervised ({ 10 }) learning ({ 11 }) and ({ 13 }) unsupervised ({ 14 }) learning ({ 15 }) based ({ 16 }) on ({ 17 }) bagging ({ 18 }) . ({ 19 }) 
# Sentence pair (1130) source length 11 target length 11 alignment score : 0.0135082
-Our framework requires only a few parameters and works stably . 
NULL ({ }) -Our ({ 1 }) framework ({ 2 }) requires ({ 3 }) only ({ 4 }) a ({ 5 }) few ({ 6 }) parameters ({ 7 }) and ({ 8 }) works ({ 9 }) stably ({ 10 }) . ({ 11 }) 
# Sentence pair (1131) source length 11 target length 11 alignment score : 0.000259088
We demonstrate its feasibility of a practical web mining application . 
NULL ({ }) We ({ 1 }) demonstrate ({ 2 }) its ({ 3 }) feasibility ({ 4 }) with ({ 5 }) a ({ 6 }) practical ({ 7 }) web ({ 8 }) mining ({ 9 }) application ({ 10 }) . ({ 11 }) 
# Sentence pair (1132) source length 22 target length 23 alignment score : 3.44937e-08
A comprehensive evaluation on a large face dataset of many people was carried out and it confirmed that our approach is promising . 
NULL ({ }) A ({ 1 }) comprehensive ({ 2 }) evaluation ({ 3 }) on ({ 4 }) a ({ 5 }) large ({ 6 }) face ({ 7 }) dataset ({ 8 }) of ({ 9 }) many ({ 10 }) people ({ 11 }) was ({ 12 }) carried ({ 13 }) out ({ 14 }) and ({ 15 }) confirmed ({ 16 17 }) that ({ 18 }) our ({ 19 }) approach ({ 20 }) is ({ 21 }) promising ({ 22 }) . ({ 23 }) 
# Sentence pair (1133) source length 13 target length 13 alignment score : 0.0107083
There are several approaches for re-ranking and learning models from web images . 
NULL ({ }) There ({ 1 }) are ({ 2 }) several ({ 3 }) approaches ({ 4 }) for ({ 5 }) re-ranking ({ 6 }) and ({ 7 }) learning ({ 8 }) models ({ 9 }) from ({ 10 }) web ({ 11 }) images ({ 12 }) . ({ 13 }) 
# Sentence pair (1134) source length 16 target length 16 alignment score : 0.00423961
Their underlying assumption is that text-based search engines return a large fraction of relevant images . 
NULL ({ }) Their ({ 1 }) underlying ({ 2 }) assumption ({ 3 }) is ({ 4 }) that ({ 5 }) text-based ({ 6 }) search ({ 7 }) engines ({ 8 }) return ({ 9 }) a ({ 10 }) large ({ 11 }) fraction ({ 12 }) of ({ 13 }) relevant ({ 14 }) images ({ 15 }) . ({ 16 }) 
# Sentence pair (1135) source length 14 target length 14 alignment score : 0.00190338
The challenge is how to model what is common in the relevant images . 
NULL ({ }) The ({ 1 }) challenge ({ 2 }) is ({ 3 }) how ({ 4 }) to ({ 5 }) model ({ 6 }) what ({ 7 }) is ({ 8 }) common ({ 9 }) in ({ 10 }) the ({ 11 }) relevant ({ 12 }) images ({ 13 }) . ({ 14 }) 
# Sentence pair (1136) source length 26 target length 26 alignment score : 7.00031e-05
One approach is to model this problem in a probabilistic framework in which the returned images are used to learn the parameters of the model . 
NULL ({ }) One ({ 1 }) approach ({ 2 }) is ({ 3 }) to ({ 4 }) model ({ 5 }) this ({ 6 }) problem ({ 7 }) in ({ 8 }) a ({ 9 }) probabilistic ({ 10 }) framework ({ 11 }) in ({ 12 }) which ({ 13 }) the ({ 14 }) returned ({ 15 }) images ({ 16 }) are ({ 17 }) used ({ 18 }) to ({ 19 }) learn ({ 20 }) the ({ 21 }) parameters ({ 22 }) of ({ 23 }) the ({ 24 }) model ({ 25 }) . ({ 26 }) 
# Sentence pair (1137) source length 23 target length 20 alignment score : 1.30165e-07
For examples , as described in \CITE , [Reference numbers generally should not be grammatically part of the sentence . 
NULL ({ }) For ({ 1 }) examples ({ 2 }) , ({ 3 }) as ({ 4 }) described ({ 5 }) by ({ }) Fergus ({ 6 }) et ({ }) al. ({ }) \CITE ({ 7 }) , ({ 8 }) [Reference ({ 9 }) numbers ({ 10 }) generally ({ 11 }) should ({ 12 }) not ({ 13 }) be ({ 14 }) grammatically ({ 15 }) part ({ 16 }) of ({ 17 }) the ({ 18 }) sentence ({ 19 }) . ({ 20 }) 
# Sentence pair (1138) source length 24 target length 23 alignment score : 1.09639e-08
It is better to use the authorsf names .]objects retrieved by an image search engine are re-ranked by extending the constellation model . 
NULL ({ }) It ({ 1 }) is ({ 2 }) better ({ 3 }) to ({ 4 }) use ({ 5 }) the ({ 6 }) authorsf ({ 7 }) names ({ 8 }) .] ({ 9 }) objects ({ }) retrieved ({ 10 }) using ({ 11 }) an ({ 12 }) image ({ 13 }) search ({ 14 }) engine ({ 15 }) are ({ 16 }) re-ranked ({ 17 }) by ({ 18 }) extending ({ 19 }) the ({ 20 }) constellation ({ 21 }) model ({ 22 }) . ({ 23 }) 
# Sentence pair (1139) source length 28 target length 28 alignment score : 1.5647e-05
Another proposal , described in \CITE , uses a non-parametric graphical model and an interactive framework to simultaneously learn object class models and collect object class datasets . 
NULL ({ }) Another ({ 1 }) proposal ({ 2 }) , ({ 3 }) described ({ 4 }) in ({ 5 }) \CITE ({ 6 }) , ({ 7 }) uses ({ 8 }) a ({ 9 }) non-parametric ({ 10 }) graphical ({ 11 }) model ({ 12 }) and ({ 13 }) an ({ 14 }) interactive ({ 15 }) framework ({ 16 }) to ({ 17 }) simultaneously ({ 18 }) learn ({ 19 }) object ({ 20 }) class ({ 21 }) models ({ 22 }) and ({ 23 }) collect ({ 24 }) object ({ 25 }) class ({ 26 }) datasets ({ 27 }) . ({ 28 }) 
# Sentence pair (1140) source length 21 target length 21 alignment score : 3.15955e-06
The main contribution of these approaches are probabilistic models that can be learned with a small number of training images . 
NULL ({ }) The ({ 1 }) main ({ 2 }) contribution ({ 3 }) of ({ 4 }) these ({ 5 }) approaches ({ 6 }) is ({ 7 }) probabilistic ({ 8 }) models ({ 9 }) that ({ 10 }) can ({ 11 }) be ({ 12 }) learned ({ 13 }) with ({ 14 }) a ({ 15 }) small ({ 16 }) number ({ 17 }) of ({ 18 }) training ({ 19 }) images ({ 20 }) . ({ 21 }) 
# Sentence pair (1141) source length 20 target length 23 alignment score : 3.31718e-14
However , these models are complicated , since they require several hundred parameters for learning , and they are susceptible to over-fitting . 
NULL ({ 7 16 18 }) However ({ 1 }) , ({ 2 }) these ({ 3 }) models ({ 4 }) are ({ 5 }) complicated ({ 6 }) since ({ 8 }) they ({ 9 }) require ({ 10 }) several ({ 11 }) hundred ({ 12 }) parameters ({ 13 }) for ({ 14 }) learning ({ 15 }) and ({ 17 }) are ({ 19 }) susceptible ({ 20 }) to ({ 21 }) over-fitting ({ 22 }) . ({ 23 }) 
# Sentence pair (1142) source length 19 target length 19 alignment score : 0.00111693
Furthermore , to obtain robust models , a small amount of supervision is required to select seed images . 
NULL ({ }) Furthermore ({ 1 }) , ({ 2 }) to ({ 3 }) obtain ({ 4 }) robust ({ 5 }) models ({ 6 }) , ({ 7 }) a ({ 8 }) small ({ 9 }) amount ({ 10 }) of ({ 11 }) supervision ({ 12 }) is ({ 13 }) required ({ 14 }) to ({ 15 }) select ({ 16 }) seed ({ 17 }) images ({ 18 }) . ({ 19 }) 
# Sentence pair (1143) source length 16 target length 16 alignment score : 0.00243407
Another study \CITE proposed a clustering-based method for associating names and faces in news photos . 
NULL ({ }) Another ({ 1 }) study ({ 2 }) \CITE ({ 3 }) proposed ({ 4 }) a ({ 5 }) clustering-based ({ 6 }) method ({ 7 }) for ({ 8 }) associating ({ 9 }) names ({ 10 }) and ({ 11 }) faces ({ 12 }) in ({ 13 }) news ({ 14 }) photos ({ 15 }) . ({ 16 }) 
# Sentence pair (1144) source length 43 target length 43 alignment score : 6.72742e-08
To solve the problem of ambiguity between several names and one face , a modified \MATH-means clustering process was used in which faces are assigned to the closest cluster ( each cluster corresponding to one name ) after a number of iterations . 
NULL ({ }) To ({ 1 }) solve ({ 2 }) the ({ 3 }) problem ({ 4 }) of ({ 5 }) ambiguity ({ 6 }) between ({ 7 }) several ({ 8 }) names ({ 9 }) and ({ 10 }) one ({ 11 }) face ({ 12 }) , ({ 13 }) a ({ 14 }) modified ({ 15 }) \MATH-means ({ 16 }) clustering ({ 17 }) process ({ 18 }) was ({ 19 }) used ({ 20 }) in ({ 21 }) which ({ 22 }) faces ({ 23 }) are ({ 24 }) assigned ({ 25 }) to ({ 26 }) the ({ 27 }) closest ({ 28 }) cluster ({ 29 }) ( ({ 30 }) each ({ 31 }) cluster ({ 32 }) corresponding ({ 33 }) to ({ 34 }) one ({ 35 }) name ({ 36 }) ) ({ 37 }) after ({ 38 }) a ({ 39 }) number ({ 40 }) of ({ 41 }) iterations ({ 42 }) . ({ 43 }) 
# Sentence pair (1145) source length 45 target length 48 alignment score : 1.35238e-17
Although the result was impressive , it is not easy to apply it to our problem since it is based on a strong assumption that requires a perfect alignment in the case that the news photo only has one face and its caption only has one name . 
NULL ({ 31 33 34 }) Although ({ 1 }) the ({ 2 }) result ({ 3 }) was ({ 4 }) impressive ({ 5 }) , ({ 6 }) it ({ 7 }) is ({ 8 }) not ({ 9 }) easy ({ 10 }) to ({ 11 }) apply ({ 12 }) it ({ 13 }) to ({ 14 }) our ({ 15 }) problem ({ 16 }) since ({ 17 }) it ({ 18 }) is ({ 19 }) based ({ 20 }) on ({ 21 }) a ({ 22 }) strong ({ 23 }) assumption ({ 24 }) that ({ 25 }) requires ({ 26 }) a ({ 27 }) perfect ({ 28 }) alignment ({ 29 }) when ({ 30 }) a ({ 32 }) news ({ 35 }) photo ({ 36 }) only ({ 37 }) has ({ 38 }) one ({ 39 }) face ({ 40 }) and ({ 41 }) its ({ 42 }) caption ({ 43 }) only ({ 44 }) has ({ 45 }) one ({ 46 }) name ({ 47 }) . ({ 48 }) 
# Sentence pair (1146) source length 21 target length 21 alignment score : 0.000608853
Furthermore , a large number of irrelevant faces ( more than 12\% ) have to be manually eliminated before clustering . 
NULL ({ }) Furthermore ({ 1 }) , ({ 2 }) a ({ 3 }) large ({ 4 }) number ({ 5 }) of ({ 6 }) irrelevant ({ 7 }) faces ({ 8 }) ( ({ 9 }) more ({ 10 }) than ({ 11 }) 12\% ({ 12 }) ) ({ 13 }) have ({ 14 }) to ({ 15 }) be ({ 16 }) manually ({ 17 }) eliminated ({ 18 }) before ({ 19 }) clustering ({ 20 }) . ({ 21 }) 
# Sentence pair (1147) source length 43 target length 40 alignment score : 2.16846e-14
A graph-based approach was proposed by \CITE , in which a graph is formed by faces as nodes , and the weights of edges linked between nodes are the similarity of faces , is closely related to our problem . 
NULL ({ }) A ({ 1 }) graph-based ({ 2 }) approach ({ 3 }) was ({ 4 }) proposed ({ 5 }) by ({ }) Ozkan ({ }) and ({ }) Duygu ({ 6 }) \CITE ({ 7 }) , ({ 8 }) in ({ 9 }) which ({ 10 }) a ({ 11 }) graph ({ 12 }) is ({ 13 }) formed ({ 14 }) from ({ 15 }) faces ({ 16 }) as ({ 17 }) nodes ({ 18 }) , ({ 19 }) and ({ 20 }) the ({ 21 }) weights ({ 22 }) of ({ 23 }) edges ({ 24 }) linked ({ 25 }) between ({ 26 }) nodes ({ 27 }) are ({ 28 }) the ({ 29 }) similarity ({ 30 }) of ({ 31 }) faces ({ 32 }) , ({ 33 }) is ({ 34 }) closely ({ 35 }) related ({ 36 }) to ({ 37 }) our ({ 38 }) problem ({ 39 }) . ({ 40 }) 
# Sentence pair (1148) source length 89 target length 78 alignment score : 5.55435e-31
Assuming that the number of faces of the queried person is larger than that of others and that these faces tend to form the most similar subset among the set of retrieved faces , this problem is considered equal to the problem of finding the densest subgraph of a full graph ; and therefore can be solved by taking an available solution .[It might be unclear as to what " available solution " you are talking about . 
NULL ({ }) Assuming ({ 1 }) that ({ 2 }) the ({ 3 }) number ({ 4 }) of ({ 5 }) faces ({ 6 }) of ({ 7 }) the ({ 8 }) queried ({ 9 }) person ({ 10 }) is ({ 11 }) larger ({ 12 }) than ({ 13 }) that ({ 14 }) of ({ 15 }) others ({ 16 }) and ({ 17 }) that ({ 18 }) these ({ 19 }) faces ({ 20 }) tend ({ 21 }) to ({ 22 }) form ({ 23 }) the ({ 24 }) most ({ 25 }) similar ({ 26 }) subset ({ 27 }) among ({ 28 }) the ({ 29 }) set ({ 30 }) of ({ 31 }) retrieved ({ 32 }) faces ({ 33 }) , ({ 34 }) this ({ 35 }) problem ({ 36 }) is ({ 37 }) considered ({ 38 }) equal ({ 39 }) to ({ 40 }) the ({ 41 }) problem ({ 42 }) of ({ 43 }) finding ({ 44 }) the ({ 45 }) densest ({ 46 }) subgraph ({ 47 }) of ({ 48 }) a ({ 49 }) full ({ 50 }) graph ({ 51 }) ; ({ 52 }) and ({ 53 }) can ({ 55 }) therefore ({ 54 }) , ({ }) be ({ 56 }) solved ({ 57 }) by ({ 58 }) taking ({ 59 }) an ({ 60 }) available ({ 61 }) solution ({ 62 }) . ({ }) //It ({ 63 }) might ({ 64 }) be ({ 65 }) unclear ({ 66 }) as ({ 67 }) to ({ 68 }) what ({ 69 }) " ({ 70 }) available ({ 71 }) solution ({ 72 }) " ({ 73 }) you ({ 74 }) are ({ 75 }) talking ({ 76 }) about ({ 77 }) . ({ 78 }) You ({ }) might ({ }) want ({ }) to ({ }) give ({ }) more ({ }) detail ({ }) here ({ }) . ({ }) 
# Sentence pair (1149) source length 40 target length 49 alignment score : 2.19782e-30
You might want to give more detail here .] Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person and it is easy to extend for the ranking problem . 
NULL ({ 4 11 }) Although ({ 10 }) experimental ({ 12 }) results ({ 13 }) showed ({ 14 }) the ({ 15 }) effectiveness ({ 16 }) of ({ 17 }) this ({ 18 }) method ({ 19 }) , ({ 20 }) it ({ 21 }) is ({ 22 }) still ({ 23 }) questionable ({ 24 }) whether ({ 25 }) the ({ 26 }) densest ({ 27 }) subgraph ({ 28 }) intuitively ({ 29 }) describes ({ 30 }) most ({ 31 }) of ({ 32 }) the ({ }) relevant ({ 33 }) faces ({ 34 }) of ({ 35 }) the ({ 36 }) queried ({ 37 }) person ({ 38 }) and ({ 39 }) it ({ 40 }) is ({ 41 }) easy ({ 42 }) to ({ 43 }) extend ({ 1 2 3 5 6 7 8 9 44 }) for ({ 45 }) the ({ 46 }) ranking ({ 47 }) problem ({ 48 }) . ({ 49 }) 
# Sentence pair (1150) source length 25 target length 28 alignment score : 3.9054e-13
Furthermore , choosing an optimal threshold to convert the initial graph into a binary graph is difficult and rather ad hoc due to the curse of dimensionality . 
NULL ({ 24 26 }) Furthermore ({ 1 }) , ({ 2 }) choosing ({ 3 }) an ({ 4 }) optimal ({ 5 }) threshold ({ 6 }) to ({ 7 }) convert ({ 8 }) the ({ 9 }) initial ({ 10 }) graph ({ 11 }) into ({ 12 }) a ({ 13 }) binary ({ 14 }) one ({ 15 }) is ({ 16 }) difficult ({ 17 }) and ({ 18 }) rather ({ 19 }) ad ({ 20 }) hoc ({ 21 }) due ({ 22 }) to ({ 23 }) dimensionality ({ 25 27 }) . ({ 28 }) 
# Sentence pair (1151) source length 12 target length 13 alignment score : 1.21324e-12
The good point of the methods \CITE is they are fully unsupervised . 
NULL ({ 4 5 }) An ({ 1 }) advantage ({ 2 }) of ({ }) these ({ 3 }) methods ({ 6 }) \CITE ({ 7 }) is ({ 8 }) they ({ 9 }) are ({ 10 }) fully ({ 11 }) unsupervised ({ 12 }) . ({ 13 }) 
# Sentence pair (1152) source length 19 target length 19 alignment score : 2.21046e-11
However , the bad point is no model is learned to predict new images of the same category . 
NULL ({ }) However ({ 1 }) , ({ 2 }) a ({ 3 }) disadvantage ({ 4 5 }) is ({ 6 }) that ({ }) no ({ 7 }) model ({ 8 }) is ({ 9 }) learned ({ 10 }) for ({ 11 }) predicting ({ 12 }) new ({ 13 }) images ({ 14 }) of ({ 15 }) the ({ 16 }) same ({ 17 }) category ({ 18 }) . ({ 19 }) 
# Sentence pair (1153) source length 39 target length 36 alignment score : 1.035e-18
Furthermore , they perform hard categorization on input images that is [It is not clear if " hard categorization " is inapplicable or if the " input images " are inapplicable .]in applicable for re-ranking . 
NULL ({ }) Furthermore ({ 1 }) , ({ 2 }) they ({ 3 }) are ({ }) used ({ }) for ({ }) performing ({ 4 }) hard ({ 5 }) categorization ({ 6 }) on ({ 7 }) input ({ 8 }) images ({ 9 }) that ({ 10 }) are ({ 11 }) inapplicable ({ 32 33 }) for ({ 34 }) re-ranking ({ 35 }) . ({ 36 }) //It ({ 12 }) is ({ 13 }) not ({ 14 }) clear ({ 15 }) if ({ 16 }) " ({ 17 }) hard ({ 18 }) categorization ({ 19 }) " ({ 20 }) is ({ 21 }) inapplicable ({ 22 }) or ({ 23 }) if ({ 24 }) the ({ 25 }) " ({ 26 }) input ({ 27 }) images ({ 28 }) " ({ 29 }) are ({ 30 }) inapplicable ({ 31 }) . ({ }) 
# Sentence pair (1154) source length 10 target length 10 alignment score : 0.012386
The balance of recall and precision was not addressed . 
NULL ({ }) The ({ 1 }) balance ({ 2 }) of ({ 3 }) recall ({ 4 }) and ({ 5 }) precision ({ 6 }) was ({ 7 }) not ({ 8 }) addressed ({ 9 }) . ({ 10 }) 
# Sentence pair (1155) source length 14 target length 14 alignment score : 0.00609977
Typically , these approaches tend to ignore the recall to obtain high precision . 
NULL ({ }) Typically ({ 1 }) , ({ 2 }) these ({ 3 }) approaches ({ 4 }) tend ({ 5 }) to ({ 6 }) ignore ({ 7 }) the ({ 8 }) recall ({ 9 }) to ({ 10 }) obtain ({ 11 }) high ({ 12 }) precision ({ 13 }) . ({ 14 }) 
# Sentence pair (1156) source length 12 target length 10 alignment score : 5.07905e-10
This leads the number of collected images is reduced . 
NULL ({ 8 }) This ({ 1 }) leads ({ 2 }) to ({ }) the ({ }) reduction ({ 9 }) in ({ }) the ({ 3 }) number ({ 4 }) of ({ 5 }) collected ({ 6 }) images ({ 7 }) . ({ 10 }) 
# Sentence pair (1157) source length 12 target length 12 alignment score : 0.00878582
Our approach combines a number of advances over the existing approaches . 
NULL ({ }) Our ({ 1 }) approach ({ 2 }) combines ({ 3 }) a ({ 4 }) number ({ 5 }) of ({ 6 }) advances ({ 7 }) over ({ 8 }) the ({ 9 }) existing ({ 10 }) approaches ({ 11 }) . ({ 12 }) 
# Sentence pair (1158) source length 23 target length 23 alignment score : 0.000143534
Specifically , we learn a model for each query from the returned images for purposes such as re-ranking and predicting new images . 
NULL ({ }) Specifically ({ 1 }) , ({ 2 }) we ({ 3 }) learn ({ 4 }) a ({ 5 }) model ({ 6 }) for ({ 7 }) each ({ 8 }) query ({ 9 }) from ({ 10 }) the ({ 11 }) returned ({ 12 }) images ({ 13 }) for ({ 14 }) purposes ({ 15 }) such ({ 16 }) as ({ 17 }) re-ranking ({ 18 }) and ({ 19 }) predicting ({ 20 }) new ({ 21 }) images ({ 22 }) . ({ 23 }) 
# Sentence pair (1159) source length 30 target length 20 alignment score : 4.86151e-23
However , different from the methods in \cite{xx} , we used an unsupervised method to select training samples automaticallyCITE . 
NULL ({ 7 }) However ({ 1 }) , ({ 9 }) we ({ 10 }) used ({ 11 }) an ({ 12 }) unsupervised ({ 13 }) method ({ 14 }) to ({ 15 }) select ({ 16 }) training ({ 17 }) samples ({ 18 }) automatically ({ }) , ({ 2 }) which ({ }) is ({ }) different ({ 3 }) from ({ 4 }) the ({ 5 }) methods ({ 6 }) proposed ({ }) by ({ }) Fergus ({ 8 }) et ({ }) al. ({ }) and ({ }) Li ({ 19 }) et ({ }) al. ({ }) \CITE ({ }) . ({ 20 }) 
# Sentence pair (1160) source length 23 target length 21 alignment score : 4.59574e-16
This unsupervised method is different from the one in \CITE in its way of modeling the distribution of relevant images . 
NULL ({ 9 14 }) This ({ 1 }) unsupervised ({ 2 }) method ({ 3 }) is ({ 4 }) different ({ 5 }) from ({ 6 }) the ({ 7 }) one ({ 8 }) by ({ }) Ozkan ({ 12 }) and ({ }) Dugyu ({ 13 }) \CITE ({ 10 }) in ({ 11 }) the ({ }) modeling ({ 15 }) of ({ }) the ({ 16 }) distribution ({ 17 }) of ({ 18 }) relevant ({ 19 }) images ({ 20 }) . ({ 21 }) 
# Sentence pair (1161) source length 10 target length 10 alignment score : 0.0165344
We use density-based estimation rather than the densest graph . 
NULL ({ }) We ({ 1 }) use ({ 2 }) density-based ({ 3 }) estimation ({ 4 }) rather ({ 5 }) than ({ 6 }) the ({ 7 }) densest ({ 8 }) graph ({ 9 }) . ({ 10 }) 
# Sentence pair (1162) source length 36 target length 36 alignment score : 1.18182e-06
Given a set of images returned by any text-based search engine for a queried person ( e.g. 'George Bush' ) , we perform a ranking process and learning of person |\MATH 's model as follows : 
NULL ({ }) Given ({ 1 }) a ({ 2 }) set ({ 3 }) of ({ 4 }) images ({ 5 }) returned ({ 6 }) by ({ 7 }) any ({ 8 }) text-based ({ 9 }) search ({ 10 }) engine ({ 11 }) for ({ 12 }) a ({ 13 }) queried ({ 14 }) person ({ 15 }) ( ({ 16 }) e.g. ({ 17 }) 'George ({ 18 }) Bush' ({ 19 }) ) ({ 20 }) , ({ 21 }) we ({ 22 }) perform ({ 23 }) a ({ 24 }) ranking ({ 25 }) process ({ 26 }) and ({ 27 }) learning ({ 28 }) of ({ 29 }) person ({ 30 }) |\MATH ({ 31 }) 's ({ 32 }) model ({ 33 }) as ({ 34 }) follows ({ 35 }) : ({ 36 }) 
# Sentence pair (1163) source length 15 target length 15 alignment score : 0.00387692
-Step 1 : Detect faces and eye positions , and then perform face normalizations . 
NULL ({ }) -Step ({ 1 }) 1 ({ 2 }) : ({ 3 }) Detect ({ 4 }) faces ({ 5 }) and ({ 6 }) eye ({ 7 }) positions ({ 8 }) , ({ 9 }) and ({ 10 }) then ({ 11 }) perform ({ 12 }) face ({ 13 }) normalizations ({ 14 }) . ({ 15 }) 
# Sentence pair (1164) source length 16 target length 16 alignment score : 0.00423336
-Step 2 : Compute an eigenface space and project the input faces into this subspace . 
NULL ({ }) -Step ({ 1 }) 2 ({ 2 }) : ({ 3 }) Compute ({ 4 }) an ({ 5 }) eigenface ({ 6 }) space ({ 7 }) and ({ 8 }) project ({ 9 }) the ({ 10 }) input ({ 11 }) faces ({ 12 }) into ({ 13 }) this ({ 14 }) subspace ({ 15 }) . ({ 16 }) 
# Sentence pair (1165) source length 14 target length 13 alignment score : 0.000273253
-Step 3 : Estimate the ranked list of these faces by Rank-By-Local-Density-Score . 
NULL ({ }) -Step ({ 1 }) 3 ({ 2 }) : ({ 3 }) Estimate ({ 4 }) the ({ 5 }) ranked ({ 6 }) list ({ 7 }) of ({ 8 }) these ({ 9 }) faces ({ 10 }) by ({ 11 }) rank-by-local-density ({ 12 }) score ({ }) . ({ 13 }) 
# Sentence pair (1166) source length 63 target length 64 alignment score : 9.09009e-16
-Step 4 : Improve this ranked list by Rank-By-Bagging-ProbSVM . //I found not hits for " rank-by-bagging-probSVM " on the Internet . You might want to double check to see if this is a standard term . The same is true for " rank-by-local-density score " . If this is your own term , you might want to specify this at some point . 
NULL ({ 22 }) -Step ({ 1 }) 4 ({ 2 }) : ({ 3 }) Improve ({ 4 }) this ({ 5 }) ranked ({ 6 }) list ({ 7 }) using ({ 8 }) rank-by-bagging-probSVM ({ 9 }) . ({ 10 }) //I ({ 11 }) found ({ 12 }) not ({ 13 }) hits ({ 14 }) for ({ 15 }) " ({ 16 }) rank-by-bagging-probSVM ({ 17 }) " ({ 18 }) on ({ 19 }) the ({ 20 }) Internet. ({ 21 }) You ({ 23 }) might ({ 24 }) want ({ 25 }) to ({ 26 }) double ({ 27 }) check ({ 28 }) to ({ 29 }) see ({ 30 }) if ({ 31 }) this ({ 32 }) is ({ 33 }) a ({ 34 }) standard ({ 35 }) term ({ 36 }) . ({ 37 }) The ({ 38 }) same ({ 39 }) is ({ 40 }) true ({ 41 }) for ({ 42 }) " ({ 43 }) rank-by-local-density ({ 44 }) score ({ 45 }) " ({ 46 }) . ({ 47 }) If ({ 48 }) this ({ 49 }) is ({ 50 }) your ({ 51 }) own ({ 52 }) term ({ 53 }) , ({ 54 }) you ({ 55 }) might ({ 56 }) want ({ 57 }) to ({ 58 }) specify ({ 59 }) this ({ 60 }) at ({ 61 }) some ({ 62 }) point ({ 63 }) . ({ 64 }) 
# Sentence pair (1167) source length 20 target length 20 alignment score : 0.000374275
Steps 1 and 2 are typical for any face processing system , and they are described in section \REF . 
NULL ({ }) Steps ({ 1 }) 1 ({ 2 }) and ({ 3 }) 2 ({ 4 }) are ({ 5 }) typical ({ 6 }) for ({ 7 }) any ({ 8 }) face ({ 9 }) processing ({ 10 }) system ({ 11 }) , ({ 12 }) and ({ 13 }) they ({ 14 }) are ({ 15 }) described ({ 16 }) in ({ 17 }) section ({ 18 }) \REF ({ 19 }) . ({ 20 }) 
# Sentence pair (1168) source length 19 target length 18 alignment score : 1.73732e-10
The algorithms used in Step 3 and Step 4 are described in section \REF and section \REF . 
NULL ({ 8 }) The ({ 1 }) algorithms ({ 2 }) used ({ 3 }) in ({ 4 }) Steps ({ 5 }) 3 ({ 6 }) and ({ 7 }) 4 ({ 9 }) are ({ 10 }) described ({ 11 }) in ({ 12 }) section ({ 13 }) \REF ({ 14 }) and ({ 15 }) section ({ 16 }) \REF ({ 17 }) , ({ }) respectively ({ }) . ({ 18 }) 
# Sentence pair (1169) source length 7 target length 7 alignment score : 0.0441887
Figure \REF illustrates the proposed framework . 
NULL ({ }) Figure ({ 1 }) \REF ({ 2 }) illustrates ({ 3 }) the ({ 4 }) proposed ({ 5 }) framework ({ 6 }) . ({ 7 }) 
# Sentence pair (1170) source length 31 target length 33 alignment score : 1.49103e-12
Among the faces retrieved by the text-based search engines for a query of person-\MATH , as shown in Figure \REF , relevant faces usually look similar and can form the largest cluster . 
NULL ({ 6 28 }) Among ({ 1 }) the ({ 2 }) faces ({ 3 }) retrieved ({ 4 }) by ({ 5 }) text-based ({ 7 }) search ({ 8 }) engines ({ 9 }) for ({ 10 }) a ({ 11 }) query ({ 12 }) of ({ 13 }) person-\MATH ({ 14 }) , ({ 15 }) as ({ 16 }) shown ({ 17 }) in ({ 18 }) Figure ({ 19 }) \REF ({ 20 }) , ({ 21 }) relevant ({ 22 }) faces ({ 23 }) usually ({ 24 }) look ({ 25 }) similar ({ 26 }) and ({ 27 }) forms ({ 29 }) the ({ 30 }) largest ({ 31 }) cluster ({ 32 }) . ({ 33 }) 
# Sentence pair (1171) source length 14 target length 15 alignment score : 9.0671e-11
One approach to re-rank these faces is to do clustering based on visual similarity . 
NULL ({ }) One ({ 1 }) approach ({ 2 }) of ({ 3 }) re-ranking ({ 4 }) these ({ 5 }) faces ({ 6 }) is ({ 7 }) to ({ 8 }) cluster ({ 9 10 }) based ({ 11 }) on ({ 12 }) visual ({ 13 }) similarity ({ 14 }) . ({ 15 }) 
# Sentence pair (1172) source length 29 target length 29 alignment score : 3.8775e-10
However , to get ideal clustering result is impossible , since these faces are high dimensional data and the clusters are in different shapes , sizes and densities . 
NULL ({ 10 }) However ({ 1 }) , ({ 2 }) to ({ 3 }) obtain ({ 4 }) ideal ({ 5 }) clustering ({ 6 }) results ({ 7 }) is ({ 8 }) impossible ({ 9 }) since ({ 11 }) these ({ 12 }) faces ({ 13 }) are ({ 14 }) high ({ 15 }) dimensional ({ 16 }) data ({ 17 }) and ({ 18 }) the ({ 19 }) clusters ({ 20 }) are ({ 21 }) in ({ 22 }) different ({ 23 }) shapes ({ 24 }) , ({ 25 }) sizes ({ 26 }) , ({ }) and ({ 27 }) densities ({ 28 }) . ({ 29 }) 
# Sentence pair (1173) source length 28 target length 27 alignment score : 1.38909e-22
Instead , in \cite{xx} , a graph based approach was proposed CITEin which the nodes are faces and edge weights are the similarities between two faces . 
NULL ({ 5 6 }) Instead ({ 1 }) , ({ 2 }) a ({ }) graph-based ({ 4 7 8 }) approach ({ 9 }) was ({ 10 }) proposed ({ 11 }) by ({ }) Ozkan ({ 12 }) and ({ }) Dugyu ({ 3 }) \CITE ({ }) in ({ }) which ({ 13 }) the ({ 14 }) nodes ({ 15 }) are ({ 16 }) faces ({ 17 }) and ({ 18 }) edge ({ 19 }) weights ({ 20 }) are ({ 21 }) the ({ 22 }) similarities ({ 23 }) between ({ 24 }) two ({ 25 }) faces ({ 26 }) . ({ 27 }) 
# Sentence pair (1174) source length 55 target length 55 alignment score : 1.40062e-10
With the observation that the nodes ( faces ) of the queried person are similar to each other and different from other nodes in the graph , the densest component of the full graph ? the set of highly connected nodes in the graph ? will correspond to the face of the queried person . 
NULL ({ }) With ({ 1 }) the ({ 2 }) observation ({ 3 }) that ({ 4 }) the ({ 5 }) nodes ({ 6 }) ( ({ 7 }) faces ({ 8 }) ) ({ 9 }) of ({ 10 }) the ({ 11 }) queried ({ 12 }) person ({ 13 }) are ({ 14 }) similar ({ 15 }) to ({ 16 }) each ({ 17 }) other ({ 18 }) and ({ 19 }) different ({ 20 }) from ({ 21 }) other ({ 22 }) nodes ({ 23 }) in ({ 24 }) the ({ 25 }) graph ({ 26 }) , ({ 27 }) the ({ 28 }) densest ({ 29 }) component ({ 30 }) of ({ 31 }) the ({ 32 }) full ({ 33 }) graph ({ 34 }) ? ({ 35 }) the ({ 36 }) set ({ 37 }) of ({ 38 }) highly ({ 39 }) connected ({ 40 }) nodes ({ 41 }) in ({ 42 }) the ({ 43 }) graph ({ 44 }) ? ({ 45 }) will ({ 46 }) correspond ({ 47 }) to ({ 48 }) the ({ 49 }) face ({ 50 }) of ({ 51 }) the ({ 52 }) queried ({ 53 }) person ({ 54 }) . ({ 55 }) 
# Sentence pair (1175) source length 22 target length 22 alignment score : 0.000255676
The main drawback of this approach is it needs a threshold to convert the initial weighted graph to a binary graph . 
NULL ({ }) The ({ 1 }) main ({ 2 }) drawback ({ 3 }) of ({ 4 }) this ({ 5 }) approach ({ 6 }) is ({ 7 }) it ({ 8 }) needs ({ 9 }) a ({ 10 }) threshold ({ 11 }) to ({ 12 }) convert ({ 13 }) the ({ 14 }) initial ({ 15 }) weighted ({ 16 }) graph ({ 17 }) to ({ 18 }) a ({ 19 }) binary ({ 20 }) graph ({ 21 }) . ({ 22 }) 
# Sentence pair (1176) source length 18 target length 18 alignment score : 0.000950324
Choosing this threshold in high dimensional spaces is difficult since different persons might have different optimal thresholds . 
NULL ({ }) Choosing ({ 1 }) this ({ 2 }) threshold ({ 3 }) in ({ 4 }) high ({ 5 }) dimensional ({ 6 }) spaces ({ 7 }) is ({ 8 }) difficult ({ 9 }) since ({ 10 }) different ({ 11 }) persons ({ 12 }) might ({ 13 }) have ({ 14 }) different ({ 15 }) optimal ({ 16 }) thresholds ({ 17 }) . ({ 18 }) 
# Sentence pair (1177) source length 25 target length 15 alignment score : 3.92934e-14
We use the idea of density-based clustering described in \CITE to solve this problem . 
NULL ({ }) We ({ 1 }) use ({ 2 }) the ({ 3 }) idea ({ 4 }) of ({ 5 }) density-based ({ 6 }) clustering ({ 7 }) described ({ 8 }) by ({ }) Ester ({ 9 }) et ({ }) al. ({ }) and ({ }) Breunig ({ }) et ({ }) al. ({ }) \CITE ({ 10 }) to ({ 11 }) solve ({ 12 }) this ({ 13 }) problem ({ 14 }) . ({ 15 }) //idea ({ }) / ({ }) concept? ({ }) 
# Sentence pair (1178) source length 28 target length 27 alignment score : 2.04687e-08
Specifically , we define local density score ( LDS ) of a point \MATH( i.e. a face ) as the average distance to its k-nearest neighbors : 
NULL ({ }) Specifically ({ 1 }) , ({ 2 }) we ({ 3 }) define ({ 4 }) the ({ }) local ({ 5 }) density ({ 6 }) score ({ 7 }) ( ({ 8 }) LDS ({ 9 }) ) ({ 10 }) of ({ 11 }) a ({ 12 }) point ({ 13 }) \MATH( ({ 14 }) i.e. ({ 15 }) a ({ 16 }) face ({ 17 }) ) ({ 18 }) as ({ 19 }) the ({ 20 }) average ({ 21 }) distance ({ 22 }) to ({ 23 }) its ({ 24 }) k-nearest ({ 25 }) neighbors ({ 26 }) . ({ 27 }) 
# Sentence pair (1179) source length 22 target length 22 alignment score : 0.000981889
where \MATH is the set of \MATH - neighbors of \MATH , and \MATH is the similarity between \MATH and \MATH . 
NULL ({ }) where ({ 1 }) \MATH ({ 2 }) is ({ 3 }) the ({ 4 }) set ({ 5 }) of ({ 6 }) \MATH ({ 7 }) - ({ 8 }) neighbors ({ 9 }) of ({ 10 }) \MATH ({ 11 }) , ({ 12 }) and ({ 13 }) \MATH ({ 14 }) is ({ 15 }) the ({ 16 }) similarity ({ 17 }) between ({ 18 }) \MATH ({ 19 }) and ({ 20 }) \MATH ({ 21 }) . ({ 22 }) 
# Sentence pair (1180) source length 41 target length 40 alignment score : 3.40325e-15
Since faces are represented in high dimensional feature space , and face clusters might have different sizes , shapes and densities ; we do not use directly the Euclidean distance between two points in this feature space for \MATH . 
NULL ({ 28 }) Since ({ 1 }) faces ({ 2 }) are ({ 3 }) represented ({ 4 }) in ({ 5 }) high ({ 6 }) dimensional ({ 7 }) feature ({ 8 }) space ({ 9 }) , ({ 10 }) and ({ 11 }) face ({ 12 }) clusters ({ 13 }) might ({ 14 }) have ({ 15 }) different ({ 16 }) sizes ({ 17 }) , ({ 18 }) shapes ({ 19 }) , ({ }) and ({ 20 }) densities ({ 21 }) , ({ 22 }) we ({ 23 }) do ({ 24 }) not ({ 25 }) directly ({ 27 }) use ({ 26 }) the ({ }) Euclidean ({ 29 }) distance ({ 30 }) between ({ 31 }) two ({ 32 }) points ({ 33 }) in ({ 34 }) this ({ 35 }) feature ({ 36 }) space ({ 37 }) for ({ 38 }) \MATH ({ 39 }) . ({ 40 }) 
# Sentence pair (1181) source length 18 target length 18 alignment score : 0.00269563
Instead , we use another similarity measure defined by the number of shared neighbors between two points . 
NULL ({ }) Instead ({ 1 }) , ({ 2 }) we ({ 3 }) use ({ 4 }) another ({ 5 }) similarity ({ 6 }) measure ({ 7 }) defined ({ 8 }) by ({ 9 }) the ({ 10 }) number ({ 11 }) of ({ 12 }) shared ({ 13 }) neighbors ({ 14 }) between ({ 15 }) two ({ 16 }) points ({ 17 }) . ({ 18 }) 
# Sentence pair (1182) source length 67 target length 67 alignment score : 3.63532e-18
The efficiency of this similarity measure for density-based clustering methods was described . //There is no period here , so it is not clear if there should be a period or there should be more to this sentence that is not here . If the sentence does end here , you might want to go into more detail about who or what " described " this .] 
NULL ({ 67 }) The ({ 1 }) efficiency ({ 2 }) of ({ 3 }) this ({ 4 }) similarity ({ 5 }) measure ({ 6 }) for ({ 7 }) density-based ({ 8 }) clustering ({ 9 }) methods ({ 10 }) was ({ 11 }) described ({ 12 }) . ({ 13 }) //There ({ 14 }) is ({ 15 }) no ({ 16 }) period ({ 17 }) here ({ 18 }) , ({ 19 }) so ({ 20 }) it ({ 21 }) is ({ 22 }) not ({ 23 }) clear ({ 24 }) if ({ 25 }) there ({ 26 }) should ({ 27 }) be ({ 28 }) a ({ 29 }) period ({ 30 }) or ({ 31 }) there ({ 32 }) should ({ 33 }) be ({ 34 }) more ({ 35 }) to ({ 36 }) this ({ 37 }) sentence ({ 38 }) that ({ 39 }) is ({ 40 }) not ({ 41 }) here ({ 42 }) . ({ 43 }) If ({ 44 }) the ({ 45 }) sentence ({ 46 }) does ({ 47 }) end ({ 48 }) here ({ 49 }) , ({ 50 }) you ({ 51 }) might ({ 52 }) want ({ 53 }) to ({ 54 }) go ({ 55 }) into ({ 56 }) more ({ 57 }) detail ({ 58 }) about ({ 59 }) who ({ 60 }) or ({ 61 }) what ({ 62 }) " ({ 63 }) described ({ 64 }) " ({ 65 }) this ({ 66 }) . ({ }) 
# Sentence pair (1183) source length 15 target length 15 alignment score : 0.00443571
A high value of \MATH indicates a strong association between \MATH and its neighbors . 
NULL ({ }) A ({ 1 }) high ({ 2 }) value ({ 3 }) of ({ 4 }) \MATH ({ 5 }) indicates ({ 6 }) a ({ 7 }) strong ({ 8 }) association ({ 9 }) between ({ 10 }) \MATH ({ 11 }) and ({ 12 }) its ({ 13 }) neighbors ({ 14 }) . ({ 15 }) 
# Sentence pair (1184) source length 13 target length 13 alignment score : 0.0114724
Therefore , we can use this local density score to rank faces . 
NULL ({ }) Therefore ({ 1 }) , ({ 2 }) we ({ 3 }) can ({ 4 }) use ({ 5 }) this ({ 6 }) local ({ 7 }) density ({ 8 }) score ({ 9 }) to ({ 10 }) rank ({ 11 }) faces ({ 12 }) . ({ 13 }) 
# Sentence pair (1185) source length 33 target length 33 alignment score : 2.65128e-06
Faces with higher scores are considered to be potential candidates that are relevant to person-\MATH , while faces with lower scores are considered as outliers and thus are potential candidates for non-person-\MATH . 
NULL ({ }) Faces ({ 1 }) with ({ 2 }) higher ({ 3 }) scores ({ 4 }) are ({ 5 }) considered ({ 6 }) to ({ 7 }) be ({ 8 }) potential ({ 9 }) candidates ({ 10 }) that ({ 11 }) are ({ 12 }) relevant ({ 13 }) to ({ 14 }) person-\MATH ({ 15 }) , ({ 16 }) while ({ 17 }) faces ({ 18 }) with ({ 19 }) lower ({ 20 }) scores ({ 21 }) are ({ 22 }) considered ({ 23 }) as ({ 24 }) outliers ({ 25 }) and ({ 26 }) thus ({ 27 }) are ({ 28 }) potential ({ 29 }) candidates ({ 30 }) for ({ 31 }) non-person-\MATH ({ 32 }) . ({ 33 }) 
# Sentence pair (1186) source length 37 target length 37 alignment score : 1.3189e-06
Algorithm 1 : Rank-By-Local-Density-Score Step 1 : For each face p , compute LDS( p , k ) , where k is the number of neighbors of p and is the input of the ranking process . 
NULL ({ }) Algorithm ({ 1 }) 1 ({ 2 }) : ({ 3 }) Rank-By-Local-Density-Score ({ 4 }) Step ({ 5 }) 1 ({ 6 }) : ({ 7 }) For ({ 8 }) each ({ 9 }) face ({ 10 }) p ({ 11 }) , ({ 12 }) compute ({ 13 }) LDS( ({ 14 }) p ({ 15 }) , ({ 16 }) k ({ 17 }) ) ({ 18 }) , ({ 19 }) where ({ 20 }) k ({ 21 }) is ({ 22 }) the ({ 23 }) number ({ 24 }) of ({ 25 }) neighbors ({ 26 }) of ({ 27 }) p ({ 28 }) and ({ 29 }) is ({ 30 }) the ({ 31 }) input ({ 32 }) of ({ 33 }) the ({ 34 }) ranking ({ 35 }) process ({ 36 }) . ({ 37 }) 
# Sentence pair (1187) source length 22 target length 20 alignment score : 4.58102e-06
Step 2 : Rank these faces using LDS( p , k ) ( The higher the more relevant ) . 
NULL ({ }) Step ({ 1 }) 2 ({ 2 }) : ({ 3 }) Rank ({ 4 }) these ({ 5 }) faces ({ 6 }) using ({ 7 }) LDS( ({ 8 }) p ({ 9 }) , ({ 10 }) k ({ 11 }) ) ({ 12 }) ( ({ 13 }) The ({ 14 }) higher ({ 15 }) the ({ }) score ({ }) the ({ 16 }) more ({ 17 }) relevant ({ 18 }) ) ({ 19 }) . ({ 20 }) 
# Sentence pair (1188) source length 31 target length 35 alignment score : 1.19263e-21
One limitation of the local density score based ranking is it could not handle the case that faces of another person have strong association in \MATH-neighbor set ( for example , many duplicates ) . 
NULL ({ 15 16 17 22 }) One ({ 1 }) limitation ({ 2 }) of ({ 3 }) the ({ 4 }) local ({ 5 }) density ({ 6 }) score ({ 7 }) based ({ 8 }) ranking ({ 9 }) is ({ 10 }) it ({ 11 }) cannot ({ 12 13 }) handle ({ 14 }) faces ({ 18 }) of ({ 19 }) another ({ 20 }) person ({ 21 }) strongly ({ 23 }) associated ({ 24 }) in ({ 25 }) the ({ }) \MATH-neighbor ({ 26 }) set ({ 27 }) ( ({ 28 }) for ({ 29 }) example ({ 30 }) , ({ 31 }) many ({ 32 }) duplicates ({ 33 }) ) ({ 34 }) . ({ 35 }) 
# Sentence pair (1189) source length 11 target length 11 alignment score : 0.000158714
Therefore , another step is proposed to handle this case . 
NULL ({ }) Therefore ({ 1 }) , ({ 2 }) another ({ 3 }) step ({ 4 }) is ({ 5 }) proposed ({ 6 }) for ({ 7 }) handling ({ 8 }) this ({ 9 }) case ({ 10 }) . ({ 11 }) 
# Sentence pair (1190) source length 23 target length 23 alignment score : 0.000161769
As a result , we have a model that can be used for both re-ranking current faces and predicting new incoming faces . 
NULL ({ }) As ({ 1 }) a ({ 2 }) result ({ 3 }) , ({ 4 }) we ({ 5 }) have ({ 6 }) a ({ 7 }) model ({ 8 }) that ({ 9 }) can ({ 10 }) be ({ 11 }) used ({ 12 }) for ({ 13 }) both ({ 14 }) re-ranking ({ 15 }) current ({ 16 }) faces ({ 17 }) and ({ 18 }) predicting ({ 19 }) new ({ 20 }) incoming ({ 21 }) faces ({ 22 }) . ({ 23 }) 
# Sentence pair (1191) source length 21 target length 21 alignment score : 0.000163675
The main idea is to use a probabilistic model to measure the relevancy of a face to person-\MATH , \MATH . 
NULL ({ }) The ({ 1 }) main ({ 2 }) idea ({ 3 }) is ({ 4 }) to ({ 5 }) use ({ 6 }) a ({ 7 }) probabilistic ({ 8 }) model ({ 9 }) to ({ 10 }) measure ({ 11 }) the ({ 12 }) relevancy ({ 13 }) of ({ 14 }) a ({ 15 }) face ({ 16 }) to ({ 17 }) person-\MATH ({ 18 }) , ({ 19 }) \MATH ({ 20 }) . ({ 21 }) 
# Sentence pair (1192) source length 42 target length 42 alignment score : 2.49088e-07
Since the labels are not available for training , we use the input rank list found from the previous step to extract a subset of faces lying at the top and bottom of the ranked list to form the training set . 
NULL ({ }) Since ({ 1 }) the ({ 2 }) labels ({ 3 }) are ({ 4 }) not ({ 5 }) available ({ 6 }) for ({ 7 }) training ({ 8 }) , ({ 9 }) we ({ 10 }) use ({ 11 }) the ({ 12 }) input ({ 13 }) rank ({ 14 }) list ({ 15 }) found ({ 16 }) from ({ 17 }) the ({ 18 }) previous ({ 19 }) step ({ 20 }) to ({ 21 }) extract ({ 22 }) a ({ 23 }) subset ({ 24 }) of ({ 25 }) faces ({ 26 }) lying ({ 27 }) at ({ 28 }) the ({ 29 }) top ({ 30 }) and ({ 31 }) bottom ({ 32 }) of ({ 33 }) the ({ 34 }) ranked ({ 35 }) list ({ 36 }) to ({ 37 }) form ({ 38 }) the ({ 39 }) training ({ 40 }) set ({ 41 }) . ({ 42 }) 
# Sentence pair (1193) source length 21 target length 20 alignment score : 2.52132e-05
After that , we use SVM with probabilistic output \CITE implemented in LibSVM \CITE to learn the person-\MATH model . 
NULL ({ }) After ({ 1 }) that ({ 2 }) , ({ 3 }) we ({ 4 }) use ({ 5 }) an ({ }) SVM ({ 6 }) with ({ 7 }) probabilistic ({ 8 }) output ({ 9 }) \CITE ({ 10 }) implemented ({ 11 }) in ({ 12 }) LibSVM ({ 13 }) \CITE ({ 14 }) to ({ 15 }) learn ({ 16 }) the ({ 17 }) person-\MATH ({ 18 }) model ({ 19 }) . ({ 20 }) 
# Sentence pair (1194) source length 23 target length 22 alignment score : 5.76151e-05
This model is applied to faces of the original set and the output probabilistic scores are used to re-rank these faces . 
NULL ({ }) This ({ 1 }) model ({ 2 }) is ({ 3 }) applied ({ 4 }) to ({ 5 }) faces ({ 6 }) of ({ 7 }) the ({ 8 }) original ({ 9 }) set ({ 10 }) , ({ }) and ({ 11 }) the ({ 12 }) output ({ 13 }) probabilistic ({ 14 }) scores ({ 15 }) are ({ 16 }) used ({ 17 }) to ({ 18 }) re-rank ({ 19 }) these ({ 20 }) faces ({ 21 }) . ({ 22 }) 
# Sentence pair (1195) source length 65 target length 62 alignment score : 1.91855e-14
Since it is not guaranteed that faces lying at two ends of the input rank list correctly correspond to the faces of person-\MATH and faces of non person-\MATH , we adopt the idea of bagging framework \CITE in which randomly selecting subsets to train weak classifiers , and then combining these classifiers help reduce the risk of using noisy training sets . 
NULL ({ }) Since ({ 1 }) it ({ 2 }) is ({ 3 }) not ({ 4 }) guaranteed ({ 5 }) that ({ 6 }) faces ({ 7 }) lying ({ 8 }) at ({ 9 }) two ({ 10 }) ends ({ 11 }) of ({ 12 }) the ({ 13 }) input ({ 14 }) rank ({ 15 }) list ({ 16 }) correctly ({ 17 }) correspond ({ 18 }) to ({ 19 }) the ({ 20 }) faces ({ 21 }) of ({ 22 }) person-\MATH ({ 23 }) and ({ 24 }) faces ({ 25 }) of ({ 26 }) non ({ 27 }) person-\MATH ({ 28 }) , ({ 29 }) we ({ 30 }) adopt ({ 31 }) the ({ 32 }) [idea ({ }) / ({ }) concept?] ({ 33 }) of ({ 34 }) a ({ }) bagging ({ 35 }) framework ({ 36 }) \CITE ({ 37 }) in ({ 38 }) which ({ 39 }) randomly ({ 40 }) selecting ({ 41 }) subsets ({ 42 }) to ({ 43 }) train ({ 44 }) weak ({ 45 }) classifiers ({ 46 }) , ({ 47 }) and ({ 48 }) then ({ 49 }) combining ({ 50 }) these ({ 51 }) classifiers ({ 52 }) help ({ 53 }) reduce ({ 54 }) the ({ 55 }) risk ({ 56 }) of ({ 57 }) using ({ 58 }) noisy ({ 59 }) training ({ 60 }) sets ({ 61 }) . ({ 62 }) 
# Sentence pair (1196) source length 31 target length 29 alignment score : 4.31995e-07
The details of Rank-By-Bagging-ProbSVM-InnerLoop method , improving an input rank list by combining weak classifiers trained from subsets annotated by that rank list are described in Algorithm 2 . 
NULL ({ }) The ({ 1 }) details ({ 2 }) of ({ 3 }) the ({ }) Rank-By-Bagging-ProbSVM-InnerLoop ({ 4 }) method ({ 5 }) , ({ 6 }) improving ({ 7 }) an ({ 8 }) input ({ 9 }) rank ({ 10 }) list ({ 11 }) by ({ 12 }) combining ({ 13 }) weak ({ 14 }) classifiers ({ 15 }) trained ({ 16 }) from ({ 17 }) subsets ({ 18 }) annotated ({ 19 }) by ({ 20 }) that ({ 21 }) rank ({ 22 }) list ({ 23 }) , ({ }) are ({ 24 }) described ({ 25 }) in ({ 26 }) Algorithm ({ 27 }) 2 ({ 28 }) . ({ 29 }) 
# Sentence pair (1197) source length 10 target length 9 alignment score : 0.00957573
Step 1 : Train a weak classifier hi . 
NULL ({ }) Step ({ 1 }) 1 ({ 2 }) : ({ 3 }) Train ({ 4 }) a ({ 5 }) weak ({ 6 }) classifier ({ 7 }) , ({ }) hi ({ 8 }) . ({ 9 }) 
# Sentence pair (1198) source length 24 target length 23 alignment score : 2.91098e-05
Step 1 .1 : Select a set Spos including p% top ranked faces and then randomly select a subset S?pos from Spos . 
NULL ({ }) Step ({ 1 }) 1 ({ 2 }) .1 ({ 3 }) : ({ 4 }) Select ({ 5 }) a ({ 6 }) set ({ 7 }) Spos ({ 8 }) including ({ 9 }) p% ({ 10 }) of ({ }) top ({ 11 }) ranked ({ 12 }) faces ({ 13 }) and ({ 14 }) then ({ 15 }) randomly ({ 16 }) select ({ 17 }) a ({ 18 }) subset ({ 19 }) S?pos ({ 20 }) from ({ 21 }) Spos ({ 22 }) . ({ 23 }) 
# Sentence pair (1199) source length 8 target length 8 alignment score : 0.0898372
Label faces in S?pos as positive samples . 
NULL ({ }) Label ({ 1 }) faces ({ 2 }) in ({ 3 }) S?pos ({ 4 }) as ({ 5 }) positive ({ 6 }) samples ({ 7 }) . ({ 8 }) 
# Sentence pair (1200) source length 25 target length 24 alignment score : 1.89782e-05
Step 1 .2 : Select a set Sneg including p% bottom ranked faces and then randomly select a subset S? neg from Sneg . 
NULL ({ }) Step ({ 1 }) 1 ({ 2 }) .2 ({ 3 }) : ({ 4 }) Select ({ 5 }) a ({ 6 }) set ({ 7 }) Sneg ({ 8 }) including ({ 9 }) p% ({ 10 }) of ({ }) bottom ({ 11 }) ranked ({ 12 }) faces ({ 13 }) and ({ 14 }) then ({ 15 }) randomly ({ 16 }) select ({ 17 }) a ({ 18 }) subset ({ 19 }) S? ({ 20 }) neg ({ 21 }) from ({ 22 }) Sneg ({ 23 }) . ({ 24 }) 
# Sentence pair (1201) source length 9 target length 9 alignment score : 0.0270532
Label faces in S? neg as negative samples . 
NULL ({ }) Label ({ 1 }) faces ({ 2 }) in ({ 3 }) S? ({ 4 }) neg ({ 5 }) as ({ 6 }) negative ({ 7 }) samples ({ 8 }) . ({ 9 }) 
# Sentence pair (1202) source length 24 target length 22 alignment score : 3.84136e-06
Step 1 .3 : Use S?pos and S? neg to train a weak classifier hj using LibSVM [8] with probability outputs . 
NULL ({ }) Step ({ 1 }) 1 ({ 2 }) .3 ({ 3 }) : ({ 4 }) Use ({ 5 }) S?pos ({ 6 }) and ({ 7 }) S? ({ 8 }) neg ({ 9 }) to ({ 10 }) train ({ 11 }) a ({ 12 }) weak ({ 13 }) classifier ({ 14 }) , ({ }) hj ({ 15 }) , ({ }) using ({ 16 }) LibSVM ({ 17 }) [8] ({ 18 }) with ({ 19 }) probability ({ 20 }) outputs ({ 21 }) . ({ 22 }) 
# Sentence pair (1203) source length 11 target length 11 alignment score : 0.0306493
Step 2 : Compute ensemble classifier Hi = Pij=1 hj . 
NULL ({ }) Step ({ 1 }) 2 ({ 2 }) : ({ 3 }) Compute ({ 4 }) ensemble ({ 5 }) classifier ({ 6 }) Hi ({ 7 }) = ({ 8 }) Pij=1 ({ 9 }) hj ({ 10 }) . ({ 11 }) 
# Sentence pair (1204) source length 24 target length 23 alignment score : 2.70533e-08
Step 3 : Apply Hi to the original face set and form the rank list Ranki by using the output probabilistic scores . 
NULL ({ }) Step ({ 1 }) 3 ({ 2 }) : ({ 3 }) Apply ({ 4 }) Hi ({ 5 }) to ({ 6 }) the ({ 7 }) original ({ 8 }) face ({ 9 }) set ({ 10 }) and ({ 11 }) form ({ 12 }) the ({ 13 }) rank ({ 14 }) list ({ 15 }) , ({ }) Ranki ({ 16 17 }) , ({ }) using ({ 18 }) the ({ 19 }) output ({ 20 }) probabilistic ({ 21 }) scores ({ 22 }) . ({ 23 }) 
# Sentence pair (1205) source length 16 target length 19 alignment score : 2.63463e-12
Step 4 : Repeat steps from Step 1 to Step 3 until Dist2RankList( Ranki?1 ,Ranki ) <= ? . 
NULL ({ 6 }) Step ({ 1 7 10 }) 4 ({ 2 }) : ({ 3 }) Repeat ({ 4 }) steps ({ 5 }) 1 ({ 8 }) to ({ 9 }) 3 ({ 11 }) until ({ 12 }) Dist2RankList( ({ 13 }) Ranki?1 ({ 14 }) ,Ranki ({ 15 }) ) ({ 16 }) <= ({ 17 }) ? ({ 18 }) . ({ 19 }) 
# Sentence pair (1206) source length 9 target length 9 alignment score : 0.0574472
Step 5 : Return Hi = Pij=1 hj . 
NULL ({ }) Step ({ 1 }) 5 ({ 2 }) : ({ 3 }) Return ({ 4 }) Hi ({ 5 }) = ({ 6 }) Pij=1 ({ 7 }) hj ({ 8 }) . ({ 9 }) 
# Sentence pair (1207) source length 10 target length 9 alignment score : 0.000851891
Step 1 : Rankcur = Rank-By-Bagging-ProbSVM-InnerLoop( Rankprev ) . 
NULL ({ }) Step ({ 1 }) 1 ({ 2 }) : ({ 3 }) Rankcur ({ 4 }) = ({ 5 }) Rank-By-Bagging-ProbSVM-InnerLoop ({ 6 }) ( ({ }) Rankprev ({ 7 }) ) ({ 8 }) . ({ 9 }) 
# Sentence pair (1208) source length 11 target length 10 alignment score : 0.00260219
Step 2 : dist = Dist2RankList( Rankprev ,Rankcur ) . 
NULL ({ }) Step ({ 1 }) 2 ({ 2 }) : ({ 3 }) dist ({ 4 }) = ({ 5 }) Dist2RankList ({ 6 }) ( ({ }) Rankprev ({ 7 }) ,Rankcur ({ 8 }) ) ({ 9 }) . ({ 10 }) 
# Sentence pair (1209) source length 7 target length 7 alignment score : 0.11496
Step 3 : Rankfinal = Rankcur . 
NULL ({ }) Step ({ 1 }) 3 ({ 2 }) : ({ 3 }) Rankfinal ({ 4 }) = ({ 5 }) Rankcur ({ 6 }) . ({ 7 }) 
# Sentence pair (1210) source length 7 target length 7 alignment score : 0.0871842
Step 4 : Rankprev = Rankcur . 
NULL ({ }) Step ({ 1 }) 4 ({ 2 }) : ({ 3 }) Rankprev ({ 4 }) = ({ 5 }) Rankcur ({ 6 }) . ({ 7 }) 
# Sentence pair (1211) source length 13 target length 16 alignment score : 5.41416e-12
Step 5 : Repeat steps from Step 1 to Step 4 until dist <= ? . 
NULL ({ 6 }) Step ({ 1 7 10 }) 5 ({ 2 }) : ({ 3 }) Repeat ({ 4 }) steps ({ 5 }) 1 ({ 8 }) to ({ 9 }) 4 ({ 11 }) until ({ 12 }) dist ({ 13 }) <= ({ 14 }) ? ({ 15 }) . ({ 16 }) 
# Sentence pair (1212) source length 6 target length 6 alignment score : 0.00747243
Step 5 : Return Rankfinal . 
NULL ({ }) Step ({ 1 }) 6 ({ 2 }) : ({ 3 }) Return ({ 4 }) Rankfinal ({ 5 }) . ({ 6 }) 
# Sentence pair (1213) source length 14 target length 15 alignment score : 1.49635e-07
Given an input ranked list , Rank-By-Bagging-ProbSVM-InnerLoop is used to improve this rank list . 
NULL ({ }) Given ({ 1 }) an ({ 2 }) input ({ 3 }) ranked ({ 4 }) list ({ 5 }) , ({ 6 }) Rank-By-Bagging-ProbSVM-InnerLoop ({ 7 }) is ({ 8 }) used ({ 9 }) to ({ 10 }) improve ({ 11 }) this ({ 12 }) list ({ 13 14 }) . ({ 15 }) 
# Sentence pair (1214) source length 29 target length 29 alignment score : 6.66473e-06
We repeat the process a number of times whereby the ranked list output from the previous step is used as the input ranked list of the next step . 
NULL ({ }) We ({ 1 }) repeat ({ 2 }) the ({ 3 }) process ({ 4 }) a ({ 5 }) number ({ 6 }) of ({ 7 }) times ({ 8 }) whereby ({ 9 }) the ({ 10 }) ranked ({ 11 }) list ({ 12 }) output ({ 13 }) from ({ 14 }) the ({ 15 }) previous ({ 16 }) step ({ 17 }) is ({ 18 }) used ({ 19 }) as ({ 20 }) the ({ 21 }) input ({ 22 }) ranked ({ 23 }) list ({ 24 }) of ({ 25 }) the ({ 26 }) next ({ 27 }) step ({ 28 }) . ({ 29 }) 
# Sentence pair (1215) source length 13 target length 13 alignment score : 0.00691637
In this way , the iterations significantly improve the final ranked list . 
NULL ({ }) In ({ 1 }) this ({ 2 }) way ({ 3 }) , ({ 4 }) the ({ 5 }) iterations ({ 6 }) significantly ({ 7 }) improve ({ 8 }) the ({ 9 }) final ({ 10 }) ranked ({ 11 }) list ({ 12 }) . ({ 13 }) 
# Sentence pair (1216) source length 8 target length 8 alignment score : 0.0498702
The details are described in Algorithm 3 . 
NULL ({ }) The ({ 1 }) details ({ 2 }) are ({ 3 }) described ({ 4 }) in ({ 5 }) Algorithm ({ 6 }) 3 ({ 7 }) . ({ 8 }) 
# Sentence pair (1217) source length 33 target length 33 alignment score : 1.40575e-06
To determine the number of iterations of Rank-By-Bagging-ProbSVM-InnerLoop and Rank-By-Bagging-ProbSVM-OuterLoop , we use the \MATH distance \CITE , which is a metric that counts the number of pairwise disagreements between two lists . 
NULL ({ }) To ({ 1 }) determine ({ 2 }) the ({ 3 }) number ({ 4 }) of ({ 5 }) iterations ({ 6 }) of ({ 7 }) Rank-By-Bagging-ProbSVM-InnerLoop ({ 8 }) and ({ 9 }) Rank-By-Bagging-ProbSVM-OuterLoop ({ 10 }) , ({ 11 }) we ({ 12 }) use ({ 13 }) the ({ 14 }) \MATH ({ 15 }) distance ({ 16 }) \CITE ({ 17 }) , ({ 18 }) which ({ 19 }) is ({ 20 }) a ({ 21 }) metric ({ 22 }) that ({ 23 }) counts ({ 24 }) the ({ 25 }) number ({ 26 }) of ({ 27 }) pairwise ({ 28 }) disagreements ({ 29 }) between ({ 30 }) two ({ 31 }) lists ({ 32 }) . ({ 33 }) 
# Sentence pair (1218) source length 13 target length 13 alignment score : 0.00325938
The larger the distance , the more dissimilar the two lists are . 
NULL ({ }) The ({ 1 }) larger ({ 2 }) the ({ 3 }) distance ({ 4 }) , ({ 5 }) the ({ 6 }) more ({ 7 }) dissimilar ({ 8 }) the ({ 9 }) two ({ 10 }) lists ({ 11 }) are ({ 12 }) . ({ 13 }) 
# Sentence pair (1219) source length 16 target length 14 alignment score : 3.71911e-05
The \MATH distance between two list \MATH and \MATH is defined as follows : 
NULL ({ }) The ({ 1 }) \MATH ({ 2 }) distance ({ 3 }) between ({ 4 }) two ({ 5 }) lists ({ 6 }) , ({ }) \MATH ({ 7 }) and ({ 8 }) \MATH ({ 9 }) , ({ }) is ({ 10 }) defined ({ 11 }) as ({ 12 }) follows ({ 13 }) : ({ 14 }) 
# Sentence pair (1220) source length 31 target length 30 alignment score : 4.27626e-06
Since the maximum value of \MATH is \MATH where \MATH is the number of members of the list , the normalized Kendall tau distance can be written as follows : 
NULL ({ }) Since ({ 1 }) the ({ 2 }) maximum ({ 3 }) value ({ 4 }) of ({ 5 }) \MATH ({ 6 }) is ({ 7 }) \MATH ({ 8 }) , ({ }) where ({ 9 }) \MATH ({ 10 }) is ({ 11 }) the ({ 12 }) number ({ 13 }) of ({ 14 }) members ({ 15 }) of ({ 16 }) the ({ 17 }) list ({ 18 }) , ({ 19 }) the ({ 20 }) normalized ({ 21 }) Kendall ({ 22 }) tau ({ 23 }) distance ({ 24 }) can ({ 25 }) be ({ 26 }) written ({ 27 }) as ({ 28 }) follows ({ 29 }) : ({ 30 }) 
# Sentence pair (1221) source length 31 target length 31 alignment score : 1.96593e-06
Using this measure for checking when the loops stop means that if the ranked list does not change significantly after a number of iterations , it is reasonable to stop . 
NULL ({ }) Using ({ 1 }) this ({ 2 }) measure ({ 3 }) for ({ 4 }) checking ({ 5 }) when ({ 6 }) the ({ 7 }) loops ({ 8 }) stop ({ 9 }) means ({ 10 }) that ({ 11 }) if ({ 12 }) the ({ 13 }) ranked ({ 14 }) list ({ 15 }) does ({ 16 }) not ({ 17 }) change ({ 18 }) significantly ({ 19 }) after ({ 20 }) a ({ 21 }) number ({ 22 }) of ({ 23 }) iterations ({ 24 }) , ({ 25 }) it ({ 26 }) is ({ 27 }) reasonable ({ 28 }) to ({ 29 }) stop ({ 30 }) . ({ 31 }) 
# Sentence pair (1222) source length 14 target length 11 alignment score : 1.52653e-05
We used the dataset described in \CITE for our experiments . 
NULL ({ }) We ({ 1 }) used ({ 2 }) the ({ 3 }) dataset ({ 4 }) described ({ 5 }) by ({ }) Berg ({ 6 }) et ({ }) al. ({ }) \CITE ({ 7 }) for ({ 8 }) our ({ 9 }) experiments ({ 10 }) . ({ 11 }) 
# Sentence pair (1223) source length 24 target length 26 alignment score : 1.99979e-10
This dataset consists of approximately half a million news [pictures / photos?] and captions from Yahoo News collected over a period of roughly two years . 
NULL ({ }) This ({ 1 }) dataset ({ 2 }) consists ({ 3 }) of ({ 4 }) approximately ({ 5 }) half ({ 6 }) a ({ 7 }) million ({ 8 }) news ({ 9 }) pictures ({ 10 11 12 }) and ({ 13 }) captions ({ 14 }) from ({ 15 }) Yahoo ({ 16 }) News ({ 17 }) collected ({ 18 }) over ({ 19 }) a ({ 20 }) period ({ 21 }) of ({ 22 }) roughly ({ 23 }) two ({ 24 }) years ({ 25 }) . ({ 26 }) 
# Sentence pair (1224) source length 27 target length 27 alignment score : 2.21453e-05
This dataset is better than datasets collected from image search engines such as Google that usually limit the total number of returned images to 1 ,000 . 
NULL ({ }) This ({ 1 }) dataset ({ 2 }) is ({ 3 }) better ({ 4 }) than ({ 5 }) datasets ({ 6 }) collected ({ 7 }) from ({ 8 }) image ({ 9 }) search ({ 10 }) engines ({ 11 }) such ({ 12 }) as ({ 13 }) Google ({ 14 }) that ({ 15 }) usually ({ 16 }) limit ({ 17 }) the ({ 18 }) total ({ 19 }) number ({ 20 }) of ({ 21 }) returned ({ 22 }) images ({ 23 }) to ({ 24 }) 1 ({ 25 }) ,000 ({ 26 }) . ({ 27 }) 
# Sentence pair (1225) source length 13 target length 13 alignment score : 0.00642203
Furthermore , it has annotations that are valuable for evaluation of methods . 
NULL ({ }) Furthermore ({ 1 }) , ({ 2 }) it ({ 3 }) has ({ 4 }) annotations ({ 5 }) that ({ 6 }) are ({ 7 }) valuable ({ 8 }) for ({ 9 }) evaluation ({ 10 }) of ({ 11 }) methods ({ 12 }) . ({ 13 }) 
# Sentence pair (1226) source length 11 target length 11 alignment score : 0.0170284
Note that these annotations are used for evaluation purpose only . 
NULL ({ }) Note ({ 1 }) that ({ 2 }) these ({ 3 }) annotations ({ 4 }) are ({ 5 }) used ({ 6 }) for ({ 7 }) evaluation ({ 8 }) purpose ({ 9 }) only ({ 10 }) . ({ 11 }) 
# Sentence pair (1227) source length 18 target length 18 alignment score : 0.00130796
Our method is fully unsupervised , so it assumes the annotations are not available at running time . 
NULL ({ }) Our ({ 1 }) method ({ 2 }) is ({ 3 }) fully ({ 4 }) unsupervised ({ 5 }) , ({ 6 }) so ({ 7 }) it ({ 8 }) assumes ({ 9 }) the ({ 10 }) annotations ({ 11 }) are ({ 12 }) not ({ 13 }) available ({ 14 }) at ({ 15 }) running ({ 16 }) time ({ 17 }) . ({ 18 }) 
# Sentence pair (1228) source length 24 target length 23 alignment score : 1.56102e-09
Only frontal faces were considered since current frontal face detection systems \CITE can work in real time and have accuracies exceeding 95\% . 
NULL ({ 13 }) Only ({ 1 }) the ({ }) front ({ 2 }) of ({ }) faces ({ 3 }) were ({ 4 }) considered ({ 5 }) since ({ 6 }) current ({ 7 }) frontal ({ 8 }) face ({ 9 }) detection ({ 10 }) systems ({ 11 }) \CITE ({ 12 }) work ({ 14 }) in ({ 15 }) real ({ 16 }) time ({ 17 }) and ({ 18 }) have ({ 19 }) accuracies ({ 20 }) exceeding ({ 21 }) 95\% ({ 22 }) . ({ 23 }) 
# Sentence pair (1229) source length 11 target length 14 alignment score : 3.66869e-10
44 ,773 faces were detected and normalized to the size of 86\MATH86 pixels . 
NULL ({ 9 11 }) 44 ({ 1 }) ,773 ({ 2 }) faces ({ 3 }) were ({ 4 }) detected ({ 5 }) and ({ 6 }) normalized ({ 7 }) to ({ 8 }) 86\MATH86 ({ 10 12 }) pixels ({ 13 }) . ({ 14 }) 
# Sentence pair (1230) source length 82 target length 83 alignment score : 1.88464e-17
We selected fifteen government leaders , including George W. Bush ( US ) , Vladimir Putin ( Russia ) , Ziang Jemin ( China ) , Tony Blair ( UK ) , Junichiro Koizumi ( Japan ) , Roh Moo-hyun ( Korea ) , and Abdullah Gul ( Turkey ) , and other key individuals , such as John Paul II ( the Former Pope ) and Hans Blix ( UN ) , because their images frequently appear in the dataset \CITE . 
NULL ({ 45 }) We ({ 1 }) selected ({ 2 }) fifteen ({ 3 }) government ({ 4 }) leaders ({ 5 }) , ({ 6 }) including ({ 7 }) George ({ 8 }) W. ({ 9 }) Bush ({ 10 }) ( ({ 11 }) US ({ 12 }) ) ({ 13 }) , ({ 14 }) Vladimir ({ 15 }) Putin ({ 16 }) ( ({ 17 }) Russia ({ 18 }) ) ({ 19 }) , ({ 20 }) Ziang ({ 21 }) Jemin ({ 22 }) ( ({ 23 }) China ({ 24 }) ) ({ 25 }) , ({ 26 }) Tony ({ 27 }) Blair ({ 28 }) ( ({ 29 }) UK ({ 30 }) ) ({ 31 }) , ({ 32 }) Junichiro ({ 33 }) Koizumi ({ 34 }) ( ({ 35 }) Japan ({ 36 }) ) ({ 37 }) , ({ 38 }) Roh ({ 39 }) Moo-hyun ({ 40 }) ( ({ 41 }) Korea ({ 42 }) ) ({ 43 }) , ({ 44 }) Abdullah ({ 46 }) Gul ({ 47 }) ( ({ 48 }) Turkey ({ 49 }) ) ({ 50 }) , ({ 51 }) and ({ 52 }) other ({ 53 }) key ({ 54 }) individuals ({ 55 }) , ({ 56 }) such ({ 57 }) as ({ 58 }) John ({ 59 }) Paul ({ 60 }) II ({ 61 }) ( ({ 62 }) the ({ 63 }) Former ({ 64 }) Pope ({ 65 }) ) ({ 66 }) and ({ 67 }) Hans ({ 68 }) Blix ({ 69 }) ( ({ 70 }) UN ({ 71 }) ) ({ 72 }) , ({ 73 }) because ({ 74 }) their ({ 75 }) images ({ 76 }) frequently ({ 77 }) appear ({ 78 }) in ({ 79 }) the ({ 80 }) dataset ({ 81 }) \CITE ({ 82 }) . ({ 83 }) 
# Sentence pair (1231) source length 9 target length 10 alignment score : 5.18899e-05
The variations in each person 's name were collected . 
NULL ({ }) Variations ({ 1 2 }) in ({ 3 }) each ({ 4 }) person ({ 5 }) 's ({ 6 }) name ({ 7 }) were ({ 8 }) collected ({ 9 }) . ({ 10 }) 
# Sentence pair (1232) source length 23 target length 23 alignment score : 0.000203766
For example , George W. Bush , President Bush , U.S. President , etc. , all refer to the current U.S. president . 
NULL ({ }) For ({ 1 }) example ({ 2 }) , ({ 3 }) George ({ 4 }) W. ({ 5 }) Bush ({ 6 }) , ({ 7 }) President ({ 8 }) Bush ({ 9 }) , ({ 10 }) U.S. ({ 11 }) President ({ 12 }) , ({ 13 }) etc. ({ 14 }) , ({ 15 }) all ({ 16 }) refer ({ 17 }) to ({ 18 }) the ({ 19 }) current ({ 20 }) U.S. ({ 21 }) president ({ 22 }) . ({ 23 }) 
# Sentence pair (1233) source length 18 target length 18 alignment score : 0.000425967
We performed simple string search in captions to check whether a caption contains one of these names . 
NULL ({ }) We ({ 1 }) performed ({ 2 }) simple ({ 3 }) string ({ 4 }) search ({ 5 }) in ({ 6 }) captions ({ 7 }) to ({ 8 }) check ({ 9 }) whether ({ 10 }) a ({ 11 }) caption ({ 12 }) contained ({ 13 }) one ({ 14 }) of ({ 15 }) these ({ 16 }) names ({ 17 }) . ({ 18 }) 
# Sentence pair (1234) source length 14 target length 14 alignment score : 0.00432213
The faces extracted from the corresponding image associated with this caption were returned . 
NULL ({ }) The ({ 1 }) faces ({ 2 }) extracted ({ 3 }) from ({ 4 }) the ({ 5 }) corresponding ({ 6 }) image ({ 7 }) associated ({ 8 }) with ({ 9 }) this ({ 10 }) caption ({ 11 }) were ({ 12 }) returned ({ 13 }) . ({ 14 }) 
# Sentence pair (1235) source length 20 target length 20 alignment score : 0.000653123
The faces retrieved from the different name queries were merged into one set and used as input for ranking . 
NULL ({ }) The ({ 1 }) faces ({ 2 }) retrieved ({ 3 }) from ({ 4 }) the ({ 5 }) different ({ 6 }) name ({ 7 }) queries ({ 8 }) were ({ 9 }) merged ({ 10 }) into ({ 11 }) one ({ 12 }) set ({ 13 }) and ({ 14 }) used ({ 15 }) as ({ 16 }) input ({ 17 }) for ({ 18 }) ranking ({ 19 }) . ({ 20 }) 
# Sentence pair (1236) source length 23 target length 23 alignment score : 0.000264045
Figure \REF shows the distribution of retrieved faces from this method and the corresponding number of relevant faces for these fifteen individuals . 
NULL ({ }) Figure ({ 1 }) \REF ({ 2 }) shows ({ 3 }) the ({ 4 }) distribution ({ 5 }) of ({ 6 }) retrieved ({ 7 }) faces ({ 8 }) from ({ 9 }) this ({ 10 }) method ({ 11 }) and ({ 12 }) the ({ 13 }) corresponding ({ 14 }) number ({ 15 }) of ({ 16 }) relevant ({ 17 }) faces ({ 18 }) for ({ 19 }) these ({ 20 }) fifteen ({ 21 }) individuals ({ 22 }) . ({ 23 }) 
# Sentence pair (1237) source length 16 target length 16 alignment score : 0.00130481
In total , 5 ,603 faces were retrieved in which 3 ,374 faces were relevant . 
NULL ({ }) In ({ 1 }) total ({ 2 }) , ({ 3 }) 5 ({ 4 }) ,603 ({ 5 }) faces ({ 6 }) were ({ 7 }) retrieved ({ 8 }) in ({ 9 }) which ({ 10 }) 3 ({ 11 }) ,374 ({ 12 }) faces ({ 13 }) were ({ 14 }) relevant ({ 15 }) . ({ 16 }) 
# Sentence pair (1238) source length 9 target length 9 alignment score : 0.0152274
On average , the accuracy was 60 .22\% . 
NULL ({ }) On ({ 1 }) average ({ 2 }) , ({ 3 }) the ({ 4 }) accuracy ({ 5 }) was ({ 6 }) 60 ({ 7 }) .22\% ({ 8 }) . ({ 9 }) 
# Sentence pair (1239) source length 17 target length 17 alignment score : 1.62374e-06
We used an eye detector to detect the positions of the eyes in the detected faces . 
NULL ({ 13 }) We ({ 1 }) used ({ 2 }) an ({ 3 }) eye ({ 4 }) detector ({ 5 }) to ({ 6 }) detect ({ 7 }) the ({ 8 }) positions ({ 9 }) of ({ 10 }) the ({ 11 }) eyes ({ 12 }) of ({ }) the ({ 14 }) detected ({ 15 }) faces ({ 16 }) . ({ 17 }) 
# Sentence pair (1240) source length 25 target length 21 alignment score : 5.07803e-09
The eye detector , built with the same approach as in \CITE , had an accuracy of more than 95\% . 
NULL ({ }) The ({ 1 }) eye ({ 2 }) detector ({ 3 }) , ({ 4 }) built ({ 5 }) with ({ 6 }) the ({ 7 }) same ({ 8 }) approach ({ 9 }) as ({ 10 }) that ({ }) of ({ }) Viola ({ }) and ({ }) jones ({ 11 }) \CITE ({ 12 }) , ({ 13 }) had ({ 14 }) an ({ 15 }) accuracy ({ 16 }) of ({ 17 }) more ({ 18 }) than ({ 19 }) 95\% ({ 20 }) . ({ 21 }) 
# Sentence pair (1241) source length 14 target length 14 alignment score : 0.00137075
If the eye positions were not detected , predefined eye locations were assigned . 
NULL ({ }) If ({ 1 }) the ({ 2 }) eye ({ 3 }) positions ({ 4 }) were ({ 5 }) not ({ 6 }) detected ({ 7 }) , ({ 8 }) predefined ({ 9 }) eye ({ 10 }) locations ({ 11 }) were ({ 12 }) assigned ({ 13 }) . ({ 14 }) 
# Sentence pair (1242) source length 14 target length 14 alignment score : 0.00392517
The eye positions were used to align faces to a predefined canonical pose . 
NULL ({ }) The ({ 1 }) eye ({ 2 }) positions ({ 3 }) were ({ 4 }) used ({ 5 }) to ({ 6 }) align ({ 7 }) faces ({ 8 }) to ({ 9 }) a ({ 10 }) predefined ({ 11 }) canonical ({ 12 }) pose ({ 13 }) . ({ 14 }) 
# Sentence pair (1243) source length 20 target length 20 alignment score : 0.000229248
To compensate for illumination effects , the subtraction of the bestfit brightness plane followed by histogram equalization was applied . 
NULL ({ }) To ({ 1 }) compensate ({ 2 }) for ({ 3 }) illumination ({ 4 }) effects ({ 5 }) , ({ 6 }) the ({ 7 }) subtraction ({ 8 }) of ({ 9 }) the ({ 10 }) best-fit ({ 11 }) brightness ({ 12 }) plane ({ 13 }) followed ({ 14 }) by ({ 15 }) histogram ({ 16 }) equalization ({ 17 }) was ({ 18 }) applied ({ 19 }) . ({ 20 }) 
# Sentence pair (1244) source length 9 target length 9 alignment score : 0.0500067
This normalization process is shown in Figure \REF . 
NULL ({ }) This ({ 1 }) normalization ({ 2 }) process ({ 3 }) is ({ 4 }) shown ({ 5 }) in ({ 6 }) Figure ({ 7 }) \REF ({ 8 }) . ({ 9 }) 
# Sentence pair (1245) source length 21 target length 21 alignment score : 0.000350639
We then used principle component analysis \CITE to reduce the number of dimensions of the feature vector for face representation . 
NULL ({ }) We ({ 1 }) then ({ 2 }) used ({ 3 }) principle ({ 4 }) component ({ 5 }) analysis ({ 6 }) \CITE ({ 7 }) to ({ 8 }) reduce ({ 9 }) the ({ 10 }) number ({ 11 }) of ({ 12 }) dimensions ({ 13 }) of ({ 14 }) the ({ 15 }) feature ({ 16 }) vector ({ 17 }) for ({ 18 }) face ({ 19 }) representation ({ 20 }) . ({ 21 }) 
# Sentence pair (1246) source length 15 target length 15 alignment score : 9.87429e-05
Eigenfaces were computed from the original face set returned by the text-based query method . 
NULL ({ }) Eigenfaces ({ 1 }) were ({ 2 }) computed ({ 3 }) from ({ 4 }) the ({ 5 }) original ({ 6 }) face ({ 7 }) set ({ 8 }) returned ({ 9 }) using ({ 10 }) the ({ 11 }) text-based ({ 12 }) query ({ 13 }) method ({ 14 }) . ({ 15 }) 
# Sentence pair (1247) source length 62 target length 23 alignment score : 6.32857e-46
The number of eigenfaces used to form the eigen space was selected so that 97\% of the total energy was retained \CITE . 
NULL ({ }) The ({ 1 }) number ({ 2 }) of ({ 3 }) eigenfaces ({ 4 }) used ({ 5 }) to ({ 6 }) form ({ 7 }) the ({ 8 }) eigen ({ 9 }) space ({ 10 }) was ({ 11 }) selected ({ 12 }) so ({ 13 }) that ({ 14 }) 97\% ({ 15 }) of ({ 16 }) the ({ 17 }) total ({ 18 }) energy ({ 19 }) was ({ 20 }) retained ({ 21 }) \CITE ({ 22 }) . ({ 23 }) //It ({ }) is ({ }) not ({ }) clear ({ }) what ({ }) you ({ }) mean ({ }) by ({ }) " ({ }) energy ({ }) " ({ }) in ({ }) this ({ }) context ({ }) . ({ }) This ({ }) is ({ }) the ({ }) first ({ }) time ({ }) you ({ }) mention ({ }) this ({ }) term ({ }) . ({ }) You ({ }) might ({ }) want ({ }) to ({ }) specify ({ }) what ({ }) kind ({ }) of ({ }) energy ({ }) you ({ }) are ({ }) talking ({ }) about ({ }) . ({ }) 
# Sentence pair (1248) source length 14 target length 14 alignment score : 0.00445995
The number of dimensions of these feature spaces ranged from 80 to 500 . 
NULL ({ }) The ({ 1 }) number ({ 2 }) of ({ 3 }) dimensions ({ 4 }) of ({ 5 }) these ({ 6 }) feature ({ 7 }) spaces ({ 8 }) ranged ({ 9 }) from ({ 10 }) 80 ({ 11 }) to ({ 12 }) 500 ({ 13 }) . ({ 14 }) 
# Sentence pair (1249) source length 25 target length 25 alignment score : 5.68131e-05
We evaluated the retrieval performance with measures that are commonly used in information retrieval , such as precision , recall , and average precision . 
NULL ({ }) We ({ 1 }) evaluated ({ 2 }) the ({ 3 }) retrieval ({ 4 }) performance ({ 5 }) with ({ 6 }) measures ({ 7 }) that ({ 8 }) are ({ 9 }) commonly ({ 10 }) used ({ 11 }) in ({ 12 }) information ({ 13 }) retrieval ({ 14 }) , ({ 15 }) such ({ 16 }) as ({ 17 }) precision ({ 18 }) , ({ 19 }) recall ({ 20 }) , ({ 21 }) and ({ 22 }) average ({ 23 }) precision ({ 24 }) . ({ 25 }) 
# Sentence pair (1250) source length 40 target length 40 alignment score : 1.04315e-06
Given a queried person and letting \MATH be the total number of faces returned , \MATH the number of relevant faces , and \MATH the total number of relevant faces , recall and precision can be calculated as follows : 
NULL ({ }) Given ({ 1 }) a ({ 2 }) queried ({ 3 }) person ({ 4 }) and ({ 5 }) letting ({ 6 }) \MATH ({ 7 }) be ({ 8 }) the ({ 9 }) total ({ 10 }) number ({ 11 }) of ({ 12 }) faces ({ 13 }) returned ({ 14 }) , ({ 15 }) \MATH ({ 16 }) the ({ 17 }) number ({ 18 }) of ({ 19 }) relevant ({ 20 }) faces ({ 21 }) , ({ 22 }) and ({ 23 }) \MATH ({ 24 }) the ({ 25 }) total ({ 26 }) number ({ 27 }) of ({ 28 }) relevant ({ 29 }) faces ({ 30 }) , ({ 31 }) recall ({ 32 }) and ({ 33 }) precision ({ 34 }) can ({ 35 }) be ({ 36 }) calculated ({ 37 }) as ({ 38 }) follows ({ 39 }) : ({ 40 }) 
# Sentence pair (1251) source length 18 target length 15 alignment score : 2.94638e-06
Precision and recall only evaluate the quality of an unordered set of retrieved faces . 
NULL ({ }) Precision ({ 1 }) and ({ 2 }) recall ({ 3 }) are ({ }) only ({ 4 }) used ({ }) to ({ }) evaluate ({ 5 }) the ({ 6 }) quality ({ 7 }) of ({ 8 }) an ({ 9 }) unordered ({ 10 }) set ({ 11 }) of ({ 12 }) retrieved ({ 13 }) faces ({ 14 }) . ({ 15 }) 
# Sentence pair (1252) source length 21 target length 22 alignment score : 8.06082e-06
To evaluate ranked lists in which both recall and precision are taken into account , the average precision is usually used . 
NULL ({ 16 }) To ({ 1 }) evaluate ({ 2 }) ranked ({ 3 }) lists ({ 4 }) in ({ 5 }) which ({ 6 }) both ({ 7 }) recall ({ 8 }) and ({ 9 }) precision ({ 10 }) are ({ 11 }) taken ({ 12 }) into ({ 13 }) account ({ 14 }) , ({ 15 }) average ({ 17 }) precision ({ 18 }) is ({ 19 }) usually ({ 20 }) used ({ 21 }) . ({ 22 }) 
# Sentence pair (1253) source length 36 target length 36 alignment score : 2.22976e-06
The average precision is computed by taking the average of the interpolated precision measured at the 11 recall levels of 0 .0 , 0 .1 , 0 .2 , . . . , 1 .0 . 
NULL ({ }) The ({ 1 }) average ({ 2 }) precision ({ 3 }) is ({ 4 }) computed ({ 5 }) by ({ 6 }) taking ({ 7 }) the ({ 8 }) average ({ 9 }) of ({ 10 }) the ({ 11 }) interpolated ({ 12 }) precision ({ 13 }) measured ({ 14 }) at ({ 15 }) the ({ 16 }) 11 ({ 17 }) recall ({ 18 }) levels ({ 19 }) of ({ 20 }) 0 ({ 21 }) .0 ({ 22 }) , ({ 23 }) 0 ({ 24 }) .1 ({ 25 }) , ({ 26 }) 0 ({ 27 }) .2 ({ 28 }) , ({ 29 }) . ({ 30 }) . ({ 31 }) . ({ 32 }) , ({ 33 }) 1 ({ 34 }) .0 ({ 35 }) . ({ 36 }) 
# Sentence pair (1254) source length 23 target length 23 alignment score : 0.000377846
The interpolated precision \MATH at a certain recall level \MATH is defined as the highest precision found for any recall level \MATH : 
NULL ({ }) The ({ 1 }) interpolated ({ 2 }) precision ({ 3 }) \MATH ({ 4 }) at ({ 5 }) a ({ 6 }) certain ({ 7 }) recall ({ 8 }) level ({ 9 }) \MATH ({ 10 }) is ({ 11 }) defined ({ 12 }) as ({ 13 }) the ({ 14 }) highest ({ 15 }) precision ({ 16 }) found ({ 17 }) for ({ 18 }) any ({ 19 }) recall ({ 20 }) level ({ 21 }) \MATH ({ 22 }) : ({ 23 }) 
# Sentence pair (1255) source length 27 target length 27 alignment score : 3.63347e-05
In addition , to evaluate the performance of multiple queries , we used mean average precision , which is the mean of average precisions computed from queries 
NULL ({ }) In ({ 1 }) addition ({ 2 }) , ({ 3 }) to ({ 4 }) evaluate ({ 5 }) the ({ 6 }) performance ({ 7 }) of ({ 8 }) multiple ({ 9 }) queries ({ 10 }) , ({ 11 }) we ({ 12 }) used ({ 13 }) mean ({ 14 }) average ({ 15 }) precision ({ 16 }) , ({ 17 }) which ({ 18 }) is ({ 19 }) the ({ 20 }) mean ({ 21 }) of ({ 22 }) average ({ 23 }) precisions ({ 24 }) computed ({ 25 }) from ({ 26 }) queries ({ 27 }) 
# Sentence pair (1256) source length 7 target length 7 alignment score : 0.0677951
The parameters of our method include : 
NULL ({ }) The ({ 1 }) parameters ({ 2 }) of ({ 3 }) our ({ 4 }) method ({ 5 }) include ({ 6 }) : ({ 7 }) 
# Sentence pair (1257) source length 35 target length 36 alignment score : 8.4129e-11
-\MATH : the fraction of faces lying at the top and bottom of the ranked list that are used to form a positive set \MATH and negative set \MATH for training weak classifiers in Rank-By-Bagging-ProbSVM-InnerLoop . 
NULL ({ 7 }) -\MATH ({ 1 }) : ({ 2 }) the ({ 3 }) fraction ({ 4 }) of ({ 5 }) faces ({ 6 }) at ({ 8 }) the ({ 9 }) top ({ 10 }) and ({ 11 }) bottom ({ 12 }) of ({ 13 }) the ({ 14 }) ranked ({ 15 }) list ({ 16 }) that ({ 17 }) are ({ 18 }) used ({ 19 }) to ({ 20 }) form ({ 21 }) a ({ 22 }) positive ({ 23 }) set ({ 24 }) \MATH ({ 25 }) and ({ 26 }) negative ({ 27 }) set ({ 28 }) \MATH ({ 29 }) for ({ 30 }) training ({ 31 }) weak ({ 32 }) classifiers ({ 33 }) in ({ 34 }) Rank-By-Bagging-ProbSVM-InnerLoop ({ 35 }) . ({ 36 }) 
# Sentence pair (1258) source length 36 target length 33 alignment score : 1.70483e-08
We empirically selected \MATH ( i .e 40\% samples of the rank list were used ) since larger \MATH will increase the number of incorrect labels and smaller \MATH will cause over-fitting . 
NULL ({ }) We ({ 1 }) empirically ({ 2 }) selected ({ 3 }) \MATH ({ 4 }) ( ({ 5 }) i ({ 6 }) .e ({ 7 }) 40\% ({ 8 }) samples ({ 9 }) of ({ 10 }) the ({ 11 }) rank ({ 12 }) list ({ 13 }) were ({ 14 }) used ({ 15 }) ) ({ 16 }) since ({ 17 }) a ({ }) larger ({ 18 }) \MATH ({ 19 }) will ({ 20 }) increase ({ 21 }) the ({ 22 }) number ({ 23 }) of ({ 24 }) incorrect ({ 25 }) labels ({ 26 }) , ({ }) and ({ 27 }) a ({ }) smaller ({ 28 }) \MATH ({ 29 }) will ({ 30 }) cause ({ 31 }) over-fitting ({ 32 }) . ({ 33 }) 
# Sentence pair (1259) source length 17 target length 17 alignment score : 0.00320673
In addition , \MATH consists of \MATH samples that are selected randomly with replacement from \MATH . 
NULL ({ }) In ({ 1 }) addition ({ 2 }) , ({ 3 }) \MATH ({ 4 }) consists ({ 5 }) of ({ 6 }) \MATH ({ 7 }) samples ({ 8 }) that ({ 9 }) are ({ 10 }) selected ({ 11 }) randomly ({ 12 }) with ({ 13 }) replacement ({ 14 }) from ({ 15 }) \MATH ({ 16 }) . ({ 17 }) 
# Sentence pair (1260) source length 11 target length 11 alignment score : 0.0250627
This sampling strategy is adopted from the bagging framework \CITE . 
NULL ({ }) This ({ 1 }) sampling ({ 2 }) strategy ({ 3 }) is ({ 4 }) adopted ({ 5 }) from ({ 6 }) the ({ 7 }) bagging ({ 8 }) framework ({ 9 }) \CITE ({ 10 }) . ({ 11 }) 
# Sentence pair (1261) source length 8 target length 8 alignment score : 0.0378479
The same setting was used for \MATH . 
NULL ({ }) The ({ 1 }) same ({ 2 }) setting ({ 3 }) was ({ 4 }) used ({ 5 }) for ({ 6 }) \MATH ({ 7 }) . ({ 8 }) 
# Sentence pair (1262) source length 16 target length 16 alignment score : 0.00508308
-\MATH : the maximum Kendall tau distance \MATH between two rank lists \MATH and \MATH . 
NULL ({ }) -\MATH ({ 1 }) : ({ 2 }) the ({ 3 }) maximum ({ 4 }) Kendall ({ 5 }) tau ({ 6 }) distance ({ 7 }) \MATH ({ 8 }) between ({ 9 }) two ({ 10 }) rank ({ 11 }) lists ({ 12 }) \MATH ({ 13 }) and ({ 14 }) \MATH ({ 15 }) . ({ 16 }) 
# Sentence pair (1263) source length 16 target length 17 alignment score : 3.07197e-06
This value is used to determine when the inner loop and the outer loop are stopped . 
NULL ({ 15 }) This ({ 1 }) value ({ 2 }) is ({ 3 }) used ({ 4 }) to ({ 5 }) determine ({ 6 }) when ({ 7 }) the ({ 8 }) inner ({ 9 }) loop ({ 10 }) and ({ 11 }) the ({ 12 }) outer ({ 13 }) loop ({ 14 }) stop ({ 16 }) . ({ 17 }) 
# Sentence pair (1264) source length 11 target length 11 alignment score : 0.0104844
We set \MATH for balance between accuracy and processing time . 
NULL ({ }) We ({ 1 }) set ({ 2 }) \MATH ({ 3 }) for ({ 4 }) balancing ({ 5 }) between ({ 6 }) accuracy ({ 7 }) and ({ 8 }) processing ({ 9 }) time ({ 10 }) . ({ 11 }) 
# Sentence pair (1265) source length 16 target length 16 alignment score : 2.01185e-10
Note that smaller \MATH requires more number of iterations making the system 's speed slower . 
NULL ({ 8 }) Note ({ 1 }) that ({ 2 }) a ({ }) smaller ({ 3 }) \MATH ({ 4 }) requires ({ 5 }) more ({ 6 }) iterations ({ 7 9 }) , ({ }) making ({ 10 }) the ({ 11 }) system ({ 12 }) 's ({ 13 }) speed ({ 14 }) slower ({ 15 }) . ({ 16 }) 
# Sentence pair (1266) source length 11 target length 10 alignment score : 0.0063628
-\MATH : the kernel type is used for SVM . 
NULL ({ }) -\MATH ({ 1 }) : ({ 2 }) the ({ 3 }) kernel ({ 4 }) type ({ 5 }) is ({ 6 }) used ({ 7 }) for ({ 8 }) the ({ }) SVM ({ 9 }) . ({ 10 }) 
# Sentence pair (1267) source length 13 target length 12 alignment score : 0.00237668
The default is linear kernel that is defined as : \MATH . 
NULL ({ }) The ({ 1 }) default ({ 2 }) is ({ 3 }) a ({ }) linear ({ 4 }) kernel ({ 5 }) that ({ 6 }) is ({ 7 }) defined ({ 8 }) as ({ 9 }) : ({ 10 }) \MATH ({ 11 }) . ({ 12 }) 
# Sentence pair (1268) source length 21 target length 20 alignment score : 1.87738e-09
We have tested other kernel types such as RBF or polynomial , the performance did not change so much . 
NULL ({ 18 }) We ({ 1 }) have ({ 2 }) tested ({ 3 }) other ({ 4 }) kernel ({ 5 }) types ({ 6 }) , ({ }) such ({ 7 }) as ({ 8 }) RBF ({ 9 }) or ({ 10 }) polynomial ({ 11 }) , ({ 12 }) but ({ }) the ({ 13 }) performance ({ 14 }) did ({ 15 }) not ({ 16 }) change ({ 17 }) much ({ 19 }) . ({ 20 }) 
# Sentence pair (1269) source length 10 target length 10 alignment score : 0.0312281
Therefore , we used the linear kernel for simplicity . 
NULL ({ }) Therefore ({ 1 }) , ({ 2 }) we ({ 3 }) used ({ 4 }) the ({ 5 }) linear ({ 6 }) kernel ({ 7 }) for ({ 8 }) simplicity ({ 9 }) . ({ 10 }) 
# Sentence pair (1270) source length 12 target length 13 alignment score : 3.51943e-07
We performed a comparison between our proposed method with other existing approaches . 
NULL ({ }) We ({ 1 }) performed ({ 2 }) a ({ 3 }) comparison ({ 4 }) between ({ 5 }) our ({ 6 }) proposed ({ 7 }) method ({ 8 }) with ({ 9 }) other ({ 10 }) ones ({ 11 12 }) . ({ 13 }) 
# Sentence pair (1271) source length 28 target length 29 alignment score : 1.1292e-09
Text Based Baseline ( TBL ) : Once faces corresponding with images whose captions contain the query name are returned , they are ranked by the time order . 
NULL ({ 26 }) Text ({ 1 }) Based ({ 2 }) Baseline ({ 3 }) ( ({ 4 }) TBL ({ 5 }) ) ({ 6 }) : ({ 7 }) Once ({ 8 }) faces ({ 9 }) corresponding ({ 10 }) with ({ 11 }) images ({ 12 }) whose ({ 13 }) captions ({ 14 }) contain ({ 15 }) the ({ 16 }) query ({ 17 }) name ({ 18 }) are ({ 19 }) returned ({ 20 }) , ({ 21 }) they ({ 22 }) are ({ 23 }) ranked ({ 24 }) in ({ 25 }) time ({ 27 }) order ({ 28 }) . ({ 29 }) 
# Sentence pair (1272) source length 18 target length 17 alignment score : 1.34445e-05
This is very naive method in which no prior knowledge between names and faces is used . 
NULL ({ }) This ({ 1 }) is ({ 2 }) a ({ }) rather ({ 3 }) naive ({ 4 }) method ({ 5 }) in ({ 6 }) which ({ 7 }) no ({ 8 }) prior ({ 9 }) knowledge ({ 10 }) between ({ 11 }) names ({ 12 }) and ({ 13 }) faces ({ 14 }) is ({ 15 }) used ({ 16 }) . ({ 17 }) 
# Sentence pair (1273) source length 18 target length 18 alignment score : 0.00121607
Distance-Based Outlier ( DBO ) : We adopted the idea of distance-based outliers detection for ranking \CITE . 
NULL ({ }) Distance-Based ({ 1 }) Outlier ({ 2 }) ( ({ 3 }) DBO ({ 4 }) ) ({ 5 }) : ({ 6 }) We ({ 7 }) adopted ({ 8 }) the ({ 9 }) idea ({ 10 }) of ({ 11 }) distance-based ({ 12 }) outlier ({ 13 }) detection ({ 14 }) for ({ 15 }) ranking ({ 16 }) \CITE ({ 17 }) . ({ 18 }) 
# Sentence pair (1274) source length 40 target length 40 alignment score : 1.30568e-06
Given a threshold \MATH , for each point \MATH , we counted the number of points \MATH so that \MATH , where \MATH is the Euclidean distance between \MATH and \MATH in the feature space mentioned in section \REF . 
NULL ({ }) Given ({ 1 }) a ({ 2 }) threshold ({ 3 }) \MATH ({ 4 }) , ({ 5 }) for ({ 6 }) each ({ 7 }) point ({ 8 }) \MATH ({ 9 }) , ({ 10 }) we ({ 11 }) counted ({ 12 }) the ({ 13 }) number ({ 14 }) of ({ 15 }) points ({ 16 }) \MATH ({ 17 }) so ({ 18 }) that ({ 19 }) \MATH ({ 20 }) , ({ 21 }) where ({ 22 }) \MATH ({ 23 }) is ({ 24 }) the ({ 25 }) Euclidean ({ 26 }) distance ({ 27 }) between ({ 28 }) \MATH ({ 29 }) and ({ 30 }) \MATH ({ 31 }) in ({ 32 }) the ({ 33 }) feature ({ 34 }) space ({ 35 }) mentioned ({ 36 }) in ({ 37 }) section ({ 38 }) \REF ({ 39 }) . ({ 40 }) 
# Sentence pair (1275) source length 12 target length 12 alignment score : 6.21742e-07
This number then was used as the score to rank faces . 
NULL ({ }) This ({ 1 }) number ({ 2 }) was ({ 4 }) then ({ 3 }) used ({ 5 }) as ({ 6 }) the ({ 7 }) score ({ 8 }) to ({ 9 }) rank ({ 10 }) faces ({ 11 }) . ({ 12 }) 
# Sentence pair (1276) source length 12 target length 12 alignment score : 0.0179309
We selected a range of \MATH values for experiments : \MATH .} 
NULL ({ }) We ({ 1 }) selected ({ 2 }) a ({ 3 }) range ({ 4 }) of ({ 5 }) \MATH ({ 6 }) values ({ 7 }) for ({ 8 }) experiments ({ 9 }) : ({ 10 }) \MATH ({ 11 }) .} ({ 12 }) 
# Sentence pair (1277) source length 19 target length 19 alignment score : 0.00199359
Densest Sub-Graph based Method ( DSG ) : We re-implemented the densest sub-graph based method \CITE for ranking . 
NULL ({ }) Densest ({ 1 }) Sub-Graph ({ 2 }) based ({ 3 }) Method ({ 4 }) ( ({ 5 }) DSG ({ 6 }) ) ({ 7 }) : ({ 8 }) We ({ 9 }) re-implemented ({ 10 }) the ({ 11 }) densest ({ 12 }) sub-graph ({ 13 }) based ({ 14 }) method ({ 15 }) \CITE ({ 16 }) for ({ 17 }) ranking ({ 18 }) . ({ 19 }) 
# Sentence pair (1278) source length 36 target length 37 alignment score : 2.25004e-13
Once the densest subgraph was found after an edge elimination process , we counted the number of surviving edge of each node ( i .e face ) and used this number as the score for ranking . 
NULL ({ 35 }) Once ({ 1 }) the ({ 2 }) densest ({ 3 }) subgraph ({ 4 }) was ({ 5 }) found ({ 6 }) after ({ 7 }) an ({ 8 }) edge ({ 9 }) elimination ({ 10 }) process ({ 11 }) , ({ 12 }) we ({ 13 }) counted ({ 14 }) the ({ 15 }) number ({ 16 }) of ({ 17 }) surviving ({ 18 }) edges ({ 19 }) of ({ 20 }) each ({ 21 }) node ({ 22 }) ( ({ 23 }) i ({ 24 }) .e ({ 25 }) face ({ 26 }) ) ({ 27 }) and ({ 28 }) used ({ 29 }) this ({ 30 }) number ({ 31 }) as ({ 32 }) the ({ 33 }) ranking ({ 36 }) score ({ 34 }) . ({ 37 }) 
# Sentence pair (1279) source length 26 target length 26 alignment score : 1.9464e-05
To form the graph , the Euclidean distance \MATH was used to assign the weight for the edge linked between node $p$ and node \MATH . 
NULL ({ }) To ({ 1 }) form ({ 2 }) the ({ 3 }) graph ({ 4 }) , ({ 5 }) the ({ 6 }) Euclidean ({ 7 }) distance ({ 8 }) \MATH ({ 9 }) was ({ 10 }) used ({ 11 }) to ({ 12 }) assign ({ 13 }) the ({ 14 }) weight ({ 15 }) for ({ 16 }) the ({ 17 }) edge ({ 18 }) linked ({ 19 }) between ({ 20 }) node ({ 21 }) $p$ ({ 22 }) and ({ 23 }) node ({ 24 }) \MATH ({ 25 }) . ({ 26 }) 
# Sentence pair (1280) source length 21 target length 21 alignment score : 2.82475e-05
DSG require a threshold \MATH to convert the weighted graph to the binary graph before searching for the densest subgraph . 
NULL ({ }) DSG ({ 1 }) requires ({ 2 }) a ({ 3 }) threshold ({ 4 }) \MATH ({ 5 }) to ({ 6 }) convert ({ 7 }) the ({ 8 }) weighted ({ 9 }) graph ({ 10 }) to ({ 11 }) the ({ 12 }) binary ({ 13 }) graph ({ 14 }) before ({ 15 }) searching ({ 16 }) for ({ 17 }) the ({ 18 }) densest ({ 19 }) subgraph ({ 20 }) . ({ 21 }) 
# Sentence pair (1281) source length 20 target length 20 alignment score : 0.000750086
We selected a range of \MATH values that are the same as the values used in DBO : \MATH . 
NULL ({ }) We ({ 1 }) selected ({ 2 }) a ({ 3 }) range ({ 4 }) of ({ 5 }) \MATH ({ 6 }) values ({ 7 }) that ({ 8 }) are ({ 9 }) the ({ 10 }) same ({ 11 }) as ({ 12 }) the ({ 13 }) values ({ 14 }) used ({ 15 }) in ({ 16 }) DBO ({ 17 }) : ({ 18 }) \MATH ({ 19 }) . ({ 20 }) 
# Sentence pair (1282) source length 17 target length 17 alignment score : 0.00357281
Local Density Score ( LDS ) : This is the first stage of our proposed method . 
NULL ({ }) Local ({ 1 }) Density ({ 2 }) Score ({ 3 }) ( ({ 4 }) LDS ({ 5 }) ) ({ 6 }) : ({ 7 }) This ({ 8 }) is ({ 9 }) the ({ 10 }) first ({ 11 }) stage ({ 12 }) of ({ 13 }) our ({ 14 }) proposed ({ 15 }) method ({ 16 }) . ({ 17 }) 
# Sentence pair (1283) source length 13 target length 13 alignment score : 0.0080432
It requires the input value \MATH to compute the local density score . 
NULL ({ }) It ({ 1 }) requires ({ 2 }) the ({ 3 }) input ({ 4 }) value ({ 5 }) \MATH ({ 6 }) to ({ 7 }) compute ({ 8 }) the ({ 9 }) local ({ 10 }) density ({ 11 }) score ({ 12 }) . ({ 13 }) 
# Sentence pair (1284) source length 47 target length 46 alignment score : 5.59479e-13
Since we do not know the number of returned faces from text based search engines , we used another input value \MATH defined as the fraction of neighbors and estimated \MATH by the formula : \MATH , where \MATH is the number of returned faces . 
NULL ({ }) Since ({ 1 }) we ({ 2 }) do ({ 3 }) not ({ 4 }) know ({ 5 }) the ({ 6 }) number ({ 7 }) of ({ 8 }) returned ({ 9 }) faces ({ 10 }) from ({ 11 }) text-based ({ 12 13 }) search ({ 14 }) engines ({ 15 }) , ({ 16 }) we ({ 17 }) used ({ 18 }) another ({ 19 }) input ({ 20 }) value ({ 21 }) \MATH ({ 22 }) , ({ }) defined ({ 23 }) as ({ 24 }) the ({ 25 }) fraction ({ 26 }) of ({ 27 }) neighbors ({ 28 }) , ({ }) and ({ 29 }) estimated ({ 30 }) \MATH ({ 31 }) by ({ 32 }) the ({ 33 }) formula ({ 34 }) : ({ 35 }) \MATH ({ 36 }) , ({ 37 }) where ({ 38 }) \MATH ({ 39 }) is ({ 40 }) the ({ 41 }) number ({ 42 }) of ({ 43 }) returned ({ 44 }) faces ({ 45 }) . ({ 46 }) 
# Sentence pair (1285) source length 12 target length 12 alignment score : 0.0139504
We used a range of $fraction$ values for experiments : \MATH . 
NULL ({ }) We ({ 1 }) used ({ 2 }) a ({ 3 }) range ({ 4 }) of ({ 5 }) $fraction$ ({ 6 }) values ({ 7 }) for ({ 8 }) experiments ({ 9 }) : ({ 10 }) \MATH ({ 11 }) . ({ 12 }) 
# Sentence pair (1286) source length 20 target length 22 alignment score : 1.4623e-12
In the case of large number of returned faces , we set \MATH to the maximum value of 200 : \MATH . 
NULL ({ 2 3 4 }) For ({ 1 }) a ({ }) large ({ 5 }) number ({ 6 }) of ({ 7 }) returned ({ 8 }) faces ({ 9 }) , ({ 10 }) we ({ 11 }) set ({ 12 }) \MATH ({ 13 }) to ({ 14 }) the ({ 15 }) maximum ({ 16 }) value ({ 17 }) of ({ 18 }) 200 ({ 19 }) : ({ 20 }) \MATH ({ 21 }) . ({ 22 }) 
# Sentence pair (1287) source length 38 target length 39 alignment score : 5.00848e-24
Unsupervised Ensemble Learning Using Local Density Score ( UEL-LDS ) : This is a combination of ranking by local density scores and then the ranked list is used for training classifier [Singular or plural?]to boost the rank list . 
NULL ({ 23 }) Unsupervised ({ 1 32 }) Ensemble ({ 2 33 }) Learning ({ 3 34 }) Using ({ 4 }) Local ({ 5 }) Density ({ 6 }) Score ({ 7 }) ( ({ 8 }) UEL-LDS ({ 9 }) ) ({ 10 }) : ({ 11 }) This ({ 12 }) is ({ 13 }) a ({ 14 }) combination ({ 15 }) of ({ 16 }) ranking ({ 17 }) by ({ 18 }) local ({ 19 }) density ({ 20 }) scores ({ 21 }) , ({ }) and ({ 22 }) the ({ 24 }) ranked ({ 25 }) list ({ 26 }) is ({ 27 }) used ({ 28 }) for ({ 29 }) training ({ 30 }) a ({ }) classifier ({ 31 }) to ({ }) boost ({ 35 }) the ({ 36 }) rank ({ 37 }) list ({ 38 }) . ({ 39 }) 
# Sentence pair (1288) source length 33 target length 32 alignment score : 3.98197e-07
Supervised Learning ( SVM-SUP ) : We randomly selected a portion \MATH of the data with annotations to train the classifier ; and then used this classifier to re-rank remaining faces . 
NULL ({ }) Supervised ({ 1 }) Learning ({ 2 }) ( ({ 3 }) SVM-SUP ({ 4 }) ) ({ 5 }) : ({ 6 }) We ({ 7 }) randomly ({ 8 }) selected ({ 9 }) a ({ 10 }) portion ({ 11 }) \MATH ({ 12 }) of ({ 13 }) the ({ 14 }) data ({ 15 }) with ({ 16 }) annotations ({ 17 }) to ({ 18 }) train ({ 19 }) the ({ 20 }) classifier ({ 21 }) ; ({ 22 }) and ({ 23 }) then ({ 24 }) used ({ 25 }) this ({ 26 }) classifier ({ 27 }) to ({ 28 }) re-rank ({ 29 }) the ({ }) remaining ({ 30 }) faces ({ 31 }) . ({ 32 }) 
# Sentence pair (1289) source length 13 target length 13 alignment score : 0.00224012
This process was repeated five times and the average performance was reported . 
NULL ({ }) This ({ 1 }) process ({ 2 }) was ({ 3 }) repeated ({ 4 }) five ({ 5 }) times ({ 6 }) and ({ 7 }) the ({ 8 }) average ({ 9 }) performance ({ 10 }) was ({ 11 }) reported ({ 12 }) . ({ 13 }) 
# Sentence pair (1290) source length 13 target length 13 alignment score : 0.0106851
We used a range of portion \MATH values for experiments : \MATH . 
NULL ({ }) We ({ 1 }) used ({ 2 }) a ({ 3 }) range ({ 4 }) of ({ 5 }) portion ({ 6 }) \MATH ({ 7 }) values ({ 8 }) for ({ 9 }) experiments ({ 10 }) : ({ 11 }) \MATH ({ 12 }) . ({ 13 }) 
# Sentence pair (1291) source length 10 target length 10 alignment score : 0.022757
Figure \REF shows a performance comparison of these methods . 
NULL ({ }) Figure ({ 1 }) \REF ({ 2 }) shows ({ 3 }) a ({ 4 }) performance ({ 5 }) comparison ({ 6 }) of ({ 7 }) these ({ 8 }) methods ({ 9 }) . ({ 10 }) 
# Sentence pair (1292) source length 21 target length 20 alignment score : 0.000168058
Our proposed methods ( LDS and UEL-LDS ) outperform other unsupervised methods such as TBL , DBO and DSG . 
NULL ({ }) Our ({ 1 }) proposed ({ 2 }) methods ({ 3 }) ( ({ 4 }) LDS ({ 5 }) and ({ 6 }) UEL-LDS ({ 7 }) ) ({ 8 }) outperform ({ 9 }) other ({ 10 }) unsupervised ({ 11 }) methods ({ 12 }) such ({ 13 }) as ({ 14 }) TBL ({ 15 }) , ({ 16 }) DBO ({ 17 }) , ({ }) and ({ 18 }) DSG ({ 19 }) . ({ 20 }) 
# Sentence pair (1293) source length 25 target length 27 alignment score : 2.76371e-15
Furthermore , the performance of methods DBO and DSG are sensitive to the distance threshold ; while the performance of our proposed method is less sensitive . 
NULL ({ 4 5 }) Furthermore ({ 1 }) , ({ 2 }) the ({ 3 }) DBO ({ 7 }) and ({ 8 }) DSG ({ 9 }) methods ({ 6 }) are ({ 10 }) sensitive ({ 11 }) to ({ 12 }) the ({ 13 }) distance ({ 14 }) threshold ({ 15 }) , ({ 16 }) while ({ 17 }) the ({ 18 }) performance ({ 19 }) of ({ 20 }) our ({ 21 }) proposed ({ 22 }) method ({ 23 }) is ({ 24 }) less ({ 25 }) sensitive ({ 26 }) . ({ 27 }) 
# Sentence pair (1294) source length 20 target length 20 alignment score : 0.000110392
It confirms that the similarity measure using shared nearest neighbors is relieable for estimation of the local density score . 
NULL ({ }) It ({ 1 }) confirms ({ 2 }) that ({ 3 }) the ({ 4 }) similarity ({ 5 }) measure ({ 6 }) using ({ 7 }) shared ({ 8 }) nearest ({ 9 }) neighbors ({ 10 }) is ({ 11 }) reliable ({ 12 }) for ({ 13 }) estimation ({ 14 }) of ({ 15 }) the ({ 16 }) local ({ 17 }) density ({ 18 }) score ({ 19 }) . ({ 20 }) 
# Sentence pair (1295) source length 22 target length 22 alignment score : 0.000478868
The performance of UEL-LDS is slightly better than LDS since the training sets labeled automatically from the ranked list are noisy . 
NULL ({ }) The ({ 1 }) performance ({ 2 }) of ({ 3 }) UEL-LDS ({ 4 }) is ({ 5 }) slightly ({ 6 }) better ({ 7 }) than ({ 8 }) LDS ({ 9 }) since ({ 10 }) the ({ 11 }) training ({ 12 }) sets ({ 13 }) labeled ({ 14 }) automatically ({ 15 }) from ({ 16 }) the ({ 17 }) ranked ({ 18 }) list ({ 19 }) are ({ 20 }) noisy ({ 21 }) . ({ 22 }) 
# Sentence pair (1296) source length 14 target length 16 alignment score : 9.92312e-13
However , UEL-LDS improves the performance significantly even when the performance of LDS is poor . 
NULL ({ 10 11 }) However ({ 1 }) , ({ 2 }) UEL-LDS ({ 3 }) improves ({ 4 }) significantly ({ 7 }) even ({ 8 }) when ({ 9 }) the ({ 5 }) performance ({ 6 }) of ({ 12 }) LDS ({ 13 }) is ({ 14 }) poor ({ 15 }) . ({ 16 }) 
# Sentence pair (1297) source length 16 target length 16 alignment score : 0.00176845
These performances are worse than that of SVM-SUP using a small number of labeled samples . 
NULL ({ }) These ({ 1 }) performances ({ 2 }) are ({ 3 }) worse ({ 4 }) than ({ 5 }) that ({ 6 }) of ({ 7 }) SVM-SUP ({ 8 }) using ({ 9 }) a ({ 10 }) small ({ 11 }) number ({ 12 }) of ({ 13 }) labeled ({ 14 }) samples ({ 15 }) . ({ 16 }) 
# Sentence pair (1298) source length 23 target length 21 alignment score : 6.39641e-09
Figure \REF shows an examples of top 50 faces ranked by the methods TBL , DBO , DSG and LDS . 
NULL ({ }) Figure ({ 1 }) \REF ({ 2 }) shows ({ 3 }) an ({ 4 }) examples ({ 5 }) of ({ 6 }) the ({ }) top ({ 7 }) 50 ({ 8 }) faces ({ 9 }) ranked ({ 10 }) using ({ 11 }) the ({ 12 }) TBL ({ 14 }) , ({ 15 }) DBO ({ 16 }) , ({ 17 }) DSG ({ 18 }) , ({ }) and ({ 19 }) LDS ({ 20 }) methods ({ 13 }) . ({ 21 }) 
# Sentence pair (1299) source length 13 target length 13 alignment score : 0.00906591
The performance of DBO is poor since a low threshold is used . 
NULL ({ }) The ({ 1 }) performance ({ 2 }) of ({ 3 }) DBO ({ 4 }) is ({ 5 }) poor ({ 6 }) since ({ 7 }) a ({ 8 }) low ({ 9 }) threshold ({ 10 }) is ({ 11 }) used ({ 12 }) . ({ 13 }) 
# Sentence pair (1300) source length 24 target length 26 alignment score : 2.26734e-13
This makes irrelevant faces that are near duplicates ( row 2 and row 3 in Figure \REF( b ) ) ranked higher than relevant faces . 
NULL ({ }) This ({ 1 }) ranks ({ 2 }) irrelevant ({ 3 }) faces ({ 4 }) that ({ 5 }) are ({ 6 }) near ({ 7 }) duplicates ({ 8 }) ( ({ 9 }) rows ({ 10 13 }) 2 ({ 11 }) and ({ 12 }) 3 ({ 14 }) in ({ 15 }) Figure ({ 16 }) \REF( ({ 17 }) b ({ 18 }) ) ({ 19 }) ) ({ 20 }) higher ({ 21 22 }) than ({ 23 }) relevant ({ 24 }) faces ({ 25 }) . ({ 26 }) 
# Sentence pair (1301) source length 8 target length 8 alignment score : 0.0327903
This explains the same situation with DSG . 
NULL ({ }) This ({ 1 }) explains ({ 2 }) the ({ 3 }) same ({ 4 }) situation ({ 5 }) with ({ 6 }) DSG ({ 7 }) . ({ 8 }) 
# Sentence pair (1302) source length 19 target length 19 alignment score : 0.000582563
In Figure \REF , we show the performance of five single classifiers and that of five ensemble classifiers . 
NULL ({ }) In ({ 1 }) Figure ({ 2 }) \REF ({ 3 }) , ({ 4 }) we ({ 5 }) show ({ 6 }) the ({ 7 }) performance ({ 8 }) of ({ 9 }) five ({ 10 }) single ({ 11 }) classifiers ({ 12 }) and ({ 13 }) that ({ 14 }) of ({ 15 }) five ({ 16 }) ensemble ({ 17 }) classifiers ({ 18 }) . ({ 19 }) 
# Sentence pair (1303) source length 15 target length 16 alignment score : 5.99306e-07
The ensemble classifier \MATH is formed by combination of single classifiers from \MATH to \MATH . 
NULL ({ 9 }) The ({ 1 }) ensemble ({ 2 }) classifier ({ 3 }) \MATH ({ 4 }) is ({ 5 }) formed ({ 6 }) by ({ 7 }) combining ({ 8 }) single ({ 10 }) classifiers ({ 11 }) from ({ 12 }) \MATH ({ 13 }) to ({ 14 }) \MATH ({ 15 }) . ({ 16 }) 
# Sentence pair (1304) source length 58 target length 15 alignment score : 5.4686e-52
It clearly indicates that the ensemble classifier is more stable that single weak classifiers . 
NULL ({ }) It ({ 1 }) clearly ({ 2 }) indicates ({ 3 }) that ({ 4 }) the ({ 5 }) ensemble ({ 6 }) classifier ({ 7 }) is ({ 8 }) more ({ 9 }) stable ({ 10 }) than ({ }) single ({ }) weak ({ 13 }) classifiers ({ 14 }) . ({ 15 }) //You ({ }) use ({ }) both ({ }) plural ({ }) and ({ }) singular ({ }) forms ({ }) of ({ }) " ({ }) classifier ({ }) " ({ }) here ({ }) , ({ }) so ({ 11 }) it ({ }) is ({ }) a ({ }) bit ({ }) confusing ({ }) if ({ }) you ({ }) are ({ }) talking ({ }) about ({ }) a ({ }) single ({ 12 }) classifier ({ }) or ({ }) more ({ }) than ({ }) one ({ }) . ({ }) I ({ }) suggest ({ }) you ({ }) use ({ }) the ({ }) same ({ }) form ({ }) throughout ({ }) if ({ }) applicable ({ }) .] ({ }) 
# Sentence pair (1305) source length 25 target length 26 alignment score : 6.10813e-13
We conducted another experiment to show the effectiveness of our approach in which learned models can be used to annotate new faces of other databases . 
NULL ({ }) We ({ 1 }) conducted ({ 2 }) another ({ 3 }) experiment ({ 4 }) to ({ 5 }) show ({ 6 }) the ({ 7 }) effectiveness ({ 8 }) of ({ 9 }) our ({ 10 }) approach ({ 11 }) in ({ 12 }) which ({ 13 }) learned ({ 14 }) models ({ 15 }) are ({ }) used ({ 18 }) to ({ 19 }) annotate ({ 16 17 20 }) new ({ 21 }) faces ({ 22 }) of ({ 23 }) other ({ 24 }) databases ({ 25 }) . ({ 26 }) 
# Sentence pair (1306) source length 26 target length 24 alignment score : 3.11331e-23
For each name in the list , we used it as the query to obtain top 500 images from Google Image Search Engine . 
NULL ({ 7 8 10 }) We ({ 1 }) used ({ 9 }) each ({ 2 }) name ({ 3 }) in ({ 4 }) the ({ 5 }) list ({ 6 }) as ({ 11 }) a ({ 12 }) query ({ 13 }) to ({ 14 }) obtain ({ 15 }) the ({ }) top ({ 16 }) 500 ({ 17 }) images ({ 18 }) from ({ 19 }) the ({ }) Google ({ 20 }) Image ({ 21 }) Search ({ 22 }) Engine ({ 23 }) ( ({ }) GoogleSE ({ }) ) ({ }) . ({ 24 }) 
# Sentence pair (1307) source length 24 target length 23 alignment score : 4.87796e-08
Next , these images were processed as the steps described in section \REF : extracting faces , detecting eyes and doing normalization . 
NULL ({ }) Next ({ 1 }) , ({ 2 }) these ({ 3 }) images ({ 4 }) were ({ 5 }) processed ({ 6 }) using ({ 7 }) the ({ 8 }) steps ({ 9 }) described ({ 10 }) in ({ 11 }) section ({ 12 }) \REF ({ 13 }) : ({ 14 }) extracting ({ 15 }) faces ({ 16 }) , ({ 17 }) detecting ({ 18 }) eyes ({ 19 }) , ({ }) and ({ 20 }) doing ({ 21 }) normalization ({ 22 }) . ({ 23 }) 
# Sentence pair (1308) source length 21 target length 21 alignment score : 0.000364445
We projected these faces to the PCA subspace trained for that name and used the learned model to re-rank faces . 
NULL ({ }) We ({ 1 }) projected ({ 2 }) these ({ 3 }) faces ({ 4 }) to ({ 5 }) the ({ 6 }) PCA ({ 7 }) subspace ({ 8 }) trained ({ 9 }) for ({ 10 }) that ({ 11 }) name ({ 12 }) and ({ 13 }) used ({ 14 }) the ({ 15 }) learned ({ 16 }) model ({ 17 }) to ({ 18 }) re-rank ({ 19 }) faces ({ 20 }) . ({ 21 }) 
# Sentence pair (1309) source length 22 target length 23 alignment score : 1.67075e-06
There were 4 ,103 faces ( including false positives - non-faces were detected as faces ) detected from 7 ,500 returned images . 
NULL ({ }) There ({ 1 }) were ({ 2 }) 4 ({ 3 }) ,103 ({ 4 }) faces ({ 5 }) ( ({ 6 }) including ({ 7 }) false ({ 8 }) positives ({ 9 }) - ({ 10 }) non-faces ({ 11 12 }) detected ({ 13 }) as ({ 14 }) faces ({ 15 }) ) ({ 16 }) detected ({ 17 }) from ({ 18 }) 7 ({ 19 }) ,500 ({ 20 }) returned ({ 21 }) images ({ 22 }) . ({ 23 }) 
# Sentence pair (1310) source length 13 target length 13 alignment score : 0.00837922
We manually labeled these faces and there were 2 ,342 relevant faces . 
NULL ({ }) We ({ 1 }) manually ({ 2 }) labeled ({ 3 }) these ({ 4 }) faces ({ 5 }) and ({ 6 }) there ({ 7 }) were ({ 8 }) 2 ({ 9 }) ,342 ({ 10 }) relevant ({ 11 }) faces ({ 12 }) . ({ 13 }) 
# Sentence pair (1311) source length 12 target length 17 alignment score : 6.73265e-19
On average , the accuracy of the Google Search Engine ( GoogleSE ) is 57 .08\% . 
NULL ({ }) On ({ 1 }) average ({ 2 }) , ({ 3 }) the ({ 4 }) accuracy ({ 5 }) of ({ 6 }) the ({ 7 }) GoogleSE ({ 8 12 13 }) is ({ 14 }) 57 ({ 9 10 15 }) .08\% ({ 11 16 }) . ({ 17 }) 
# Sentence pair (1312) source length 12 target length 12 alignment score : 0.0143713
In Table \REF , we compare the performance of the methods . 
NULL ({ }) In ({ 1 }) Table ({ 2 }) \REF ({ 3 }) , ({ 4 }) we ({ 5 }) compare ({ 6 }) the ({ 7 }) performance ({ 8 }) of ({ 9 }) the ({ 10 }) methods ({ 11 }) . ({ 12 }) 
# Sentence pair (1313) source length 26 target length 25 alignment score : 1.5142e-05
The performance of UEL-LDS was obtained by running the best system , which is shown as the peak of UEL-LDS curve in Figure \REF . 
NULL ({ }) The ({ 1 }) performance ({ 2 }) of ({ 3 }) UEL-LDS ({ 4 }) was ({ 5 }) obtained ({ 6 }) by ({ 7 }) running ({ 8 }) the ({ 9 }) best ({ 10 }) system ({ 11 }) , ({ 12 }) which ({ 13 }) is ({ 14 }) shown ({ 15 }) as ({ 16 }) the ({ 17 }) peak ({ 18 }) of ({ 19 }) the ({ }) UEL-LDS ({ 20 }) curve ({ 21 }) in ({ 22 }) Figure ({ 23 }) \REF ({ 24 }) . ({ 25 }) 
# Sentence pair (1314) source length 27 target length 26 alignment score : 1.35283e-06
The performances of SVM-SUP-05 and SVM-SUP-10 correspond to the supervised systems ( cf . section \REF ) that used \MATH of the data set respectively . 
NULL ({ }) The ({ 1 }) performances ({ 2 }) of ({ 3 }) SVM-SUP-05 ({ 4 }) and ({ 5 }) SVM-SUP-10 ({ 6 }) correspond ({ 7 }) to ({ 8 }) the ({ 9 }) supervised ({ 10 }) systems ({ 11 }) ( ({ 12 }) cf ({ 13 }) . ({ 14 }) section ({ 15 }) \REF ({ 16 }) ) ({ 17 }) that ({ 18 }) used ({ 19 }) \MATH ({ 20 }) of ({ 21 }) the ({ 22 }) data ({ 23 }) set ({ 24 }) , ({ }) respectively ({ 25 }) . ({ 26 }) 
# Sentence pair (1315) source length 35 target length 35 alignment score : 7.21942e-15
We evaluated the performance by calculating the precision at top 20 returned faces , which is popular for image search engines ; and recall and precision on all detected faces of the test set . 
NULL ({ 22 }) We ({ 1 }) evaluated ({ 2 }) the ({ 3 }) performance ({ 4 }) by ({ 5 }) calculating ({ 6 }) the ({ 7 }) precision ({ 8 }) of ({ 9 }) the ({ }) top ({ 10 }) 20 ({ 11 }) returned ({ 12 }) faces ({ 13 }) , ({ 14 }) which ({ 15 }) is ({ 16 }) common ({ 17 }) for ({ 18 }) image ({ 19 }) search ({ 20 }) engines ({ 21 }) and ({ 23 }) recall ({ 24 }) and ({ 25 }) precision ({ 26 }) on ({ 27 }) all ({ 28 }) detected ({ 29 }) faces ({ 30 }) of ({ 31 }) the ({ 32 }) test ({ 33 }) set ({ 34 }) . ({ 35 }) 
# Sentence pair (1316) source length 14 target length 14 alignment score : 0.00219088
UEL-LDS achieved comparable performance to the supervised methods and outperformed the baseline GoogleSE . 
NULL ({ }) UEL-LDS ({ 1 }) achieved ({ 2 }) comparable ({ 3 }) performance ({ 4 }) to ({ 5 }) the ({ 6 }) supervised ({ 7 }) methods ({ 8 }) and ({ 9 }) outperformed ({ 10 }) the ({ 11 }) baseline ({ 12 }) GoogleSE ({ 13 }) . ({ 14 }) 
# Sentence pair (1317) source length 23 target length 22 alignment score : 5.19698e-11
The precision at top 20 of SVM-SUP-05 is poorer than that of UEL-LDS is due to small number of training samples . 
NULL ({ 14 }) The ({ 1 }) precision ({ 2 }) of ({ 3 }) the ({ }) top ({ 4 }) 20 ({ 5 }) of ({ 6 }) SVM-SUP-05 ({ 7 }) is ({ 8 }) poorer ({ 9 }) than ({ 10 }) that ({ 11 }) of ({ 12 }) UEL-LDS ({ 13 }) due ({ 15 }) to ({ 16 }) the ({ }) small ({ 17 }) number ({ 18 }) of ({ 19 }) training ({ 20 }) samples ({ 21 }) . ({ 22 }) 
# Sentence pair (1318) source length 12 target length 12 alignment score : 0.000930221
Figure \REF shows top 20 faces ranked by these two methods . 
NULL ({ }) Figure ({ 1 }) \REF ({ 2 }) shows ({ 3 }) top ({ 4 }) 20 ({ 5 }) faces ({ 6 }) ranked ({ 7 }) using ({ 8 }) these ({ 9 }) two ({ 10 }) methods ({ 11 }) . ({ 12 }) 
# Sentence pair (1319) source length 28 target length 28 alignment score : 4.91584e-06
Our approach works fairly well for well known people , where the main assumption that text-based search engines return a large fraction of relevant images is satisfied . 
NULL ({ }) Our ({ 1 }) approach ({ 2 }) works ({ 3 }) fairly ({ 4 }) well ({ 5 }) for ({ 6 }) well ({ 7 }) known ({ 8 }) people ({ 9 }) , ({ 10 }) where ({ 11 }) the ({ 12 }) main ({ 13 }) assumption ({ 14 }) that ({ 15 }) text-based ({ 16 }) search ({ 17 }) engines ({ 18 }) return ({ 19 }) a ({ 20 }) large ({ 21 }) fraction ({ 22 }) of ({ 23 }) relevant ({ 24 }) images ({ 25 }) is ({ 26 }) satisfied ({ 27 }) . ({ 28 }) 
# Sentence pair (1320) source length 11 target length 11 alignment score : 0.00901866
Figure \REF shows an example where this assumption is broken . 
NULL ({ }) Figure ({ 1 }) \REF ({ 2 }) shows ({ 3 }) an ({ 4 }) example ({ 5 }) where ({ 6 }) this ({ 7 }) assumption ({ 8 }) is ({ 9 }) broken ({ 10 }) . ({ 11 }) 
# Sentence pair (1321) source length 24 target length 25 alignment score : 1.5166e-09
Consequently , as shown in Figure \REF , the model learned by this set obtained poor performance in recognizing new faces returned by GoogleSE . 
NULL ({ }) Consequently ({ 1 }) , ({ 2 }) as ({ 3 }) shown ({ 4 }) in ({ 5 }) Figure ({ 6 }) \REF ({ 7 }) , ({ 8 }) the ({ 9 }) model ({ 10 }) learned ({ 11 }) by ({ 12 }) this ({ 13 }) set ({ 14 }) performed ({ 15 }) poorly ({ 16 17 }) in ({ 18 }) recognizing ({ 19 }) new ({ 20 }) faces ({ 21 }) returned ({ 22 }) by ({ 23 }) GoogleSE ({ 24 }) . ({ 25 }) 
# Sentence pair (1322) source length 23 target length 22 alignment score : 4.20762e-06
Our approach solely relies on the above assumption , therefore it is not affected by the ranking of text-based search engines . 
NULL ({ }) Our ({ 1 }) approach ({ 2 }) solely ({ 3 }) relies ({ 4 }) on ({ 5 }) the ({ 6 }) above ({ 7 }) assumption ({ 8 }) ; ({ 9 }) therefore ({ 10 }) , ({ }) it ({ 11 }) is ({ 12 }) not ({ 13 }) affected ({ 14 }) by ({ 15 }) the ({ 16 }) ranking ({ 17 }) of ({ 18 }) text-based ({ 19 }) search ({ 20 }) engines ({ 21 }) . ({ 22 }) 
# Sentence pair (1323) source length 15 target length 15 alignment score : 0.0049823
The iteration of bagging SVM classifiers does not guarantee a significant improvement in performance . 
NULL ({ }) The ({ 1 }) iteration ({ 2 }) of ({ 3 }) bagging ({ 4 }) SVM ({ 5 }) classifiers ({ 6 }) does ({ 7 }) not ({ 8 }) guarantee ({ 9 }) a ({ 10 }) significant ({ 11 }) improvement ({ 12 }) in ({ 13 }) performance ({ 14 }) . ({ 15 }) 
# Sentence pair (1324) source length 23 target length 20 alignment score : 1.82408e-08
Our future work is to study how to improve the quality of the training sets used in this iteration . 
NULL ({ }) The ({ }) aim ({ 1 }) of ({ }) our ({ }) future ({ 2 }) work ({ 3 }) is ({ 4 }) to ({ 5 }) study ({ 6 }) how ({ 7 }) to ({ 8 }) improve ({ 9 }) the ({ 10 }) quality ({ 11 }) of ({ 12 }) the ({ 13 }) training ({ 14 }) sets ({ 15 }) used ({ 16 }) in ({ 17 }) this ({ 18 }) iteration ({ 19 }) . ({ 20 }) 
# Sentence pair (1325) source length 19 target length 19 alignment score : 0.000198056
We presented a method for ranking faces retrieved using text-based correlation methods in searches for a specific person . 
NULL ({ }) We ({ 1 }) presented ({ 2 }) a ({ 3 }) method ({ 4 }) for ({ 5 }) ranking ({ 6 }) faces ({ 7 }) retrieved ({ 8 }) using ({ 9 }) text-based ({ 10 }) correlation ({ 11 }) methods ({ 12 }) in ({ 13 }) searches ({ 14 }) for ({ 15 }) a ({ 16 }) specific ({ 17 }) person ({ 18 }) . ({ 19 }) 
# Sentence pair (1326) source length 13 target length 14 alignment score : 1.35332e-05
This method learns the visual consistency among the faces in a two-stage process . 
NULL ({ 8 }) This ({ 1 }) method ({ 2 }) learns ({ 3 }) the ({ 4 }) visual ({ 5 }) consistency ({ 6 }) among ({ 7 }) faces ({ 9 }) in ({ 10 }) a ({ 11 }) two-stage ({ 12 }) process ({ 13 }) . ({ 14 }) 
# Sentence pair (1327) source length 39 target length 35 alignment score : 4.00537e-10
In the first stage , a relative density score is used to form a ranked list in which faces ranked at the top or bottom of the list are likely relevant or irrelevant faces . 
NULL ({ }) In ({ 1 }) the ({ 2 }) first ({ 3 }) stage ({ 4 }) , ({ 5 }) a ({ 6 }) relative ({ 7 }) density ({ 8 }) score ({ 9 }) is ({ 10 }) used ({ 11 }) to ({ 12 }) form ({ 13 }) a ({ 14 }) ranked ({ 15 }) list ({ 16 }) in ({ 17 }) which ({ 18 }) faces ({ 19 }) ranked ({ 20 }) at ({ 21 }) the ({ 22 }) top ({ 23 }) or ({ 24 }) bottom ({ 25 }) of ({ 26 }) the ({ 27 }) list ({ 28 }) are ({ 29 }) likely ({ 30 }) to ({ }) be ({ }) relevant ({ 31 }) or ({ 32 }) irrelevant ({ 33 }) faces ({ 34 }) , ({ }) respectively ({ }) . ({ 35 }) 
# Sentence pair (1328) source length 27 target length 27 alignment score : 8.30412e-05
In the second stage , a bagging framework is used to combine weak classifiers trained on subsets labeled from the ranked list into a strong classifier . 
NULL ({ }) In ({ 1 }) the ({ 2 }) second ({ 3 }) stage ({ 4 }) , ({ 5 }) a ({ 6 }) bagging ({ 7 }) framework ({ 8 }) is ({ 9 }) used ({ 10 }) to ({ 11 }) combine ({ 12 }) weak ({ 13 }) classifiers ({ 14 }) trained ({ 15 }) on ({ 16 }) subsets ({ 17 }) labeled ({ 18 }) from ({ 19 }) the ({ 20 }) ranked ({ 21 }) list ({ 22 }) into ({ 23 }) a ({ 24 }) strong ({ 25 }) classifier ({ 26 }) . ({ 27 }) 
# Sentence pair (1329) source length 22 target length 22 alignment score : 0.000344695
This strong classifier is then applied to the original set to re-rank faces on the basis of the output probabilistic scores . 
NULL ({ }) This ({ 1 }) strong ({ 2 }) classifier ({ 3 }) is ({ 4 }) then ({ 5 }) applied ({ 6 }) to ({ 7 }) the ({ 8 }) original ({ 9 }) set ({ 10 }) to ({ 11 }) re-rank ({ 12 }) faces ({ 13 }) on ({ 14 }) the ({ 15 }) basis ({ 16 }) of ({ 17 }) the ({ 18 }) output ({ 19 }) probabilistic ({ 20 }) scores ({ 21 }) . ({ 22 }) 
# Sentence pair (1330) source length 12 target length 12 alignment score : 0.00551212
Experiments on various face sets showed the effectiveness of this method . 
NULL ({ }) Experiments ({ 1 }) on ({ 2 }) various ({ 3 }) face ({ 4 }) sets ({ 5 }) showed ({ 6 }) the ({ 7 }) effectiveness ({ 8 }) of ({ 9 }) this ({ 10 }) method ({ 11 }) . ({ 12 }) 
# Sentence pair (1331) source length 20 target length 20 alignment score : 5.22885e-21
Our approach is beneficial in the case multiple faces residing in the returned image as shown in Figure \REF . 
NULL ({ 5 6 }) Our ({ 1 }) approach ({ 2 }) is ({ 3 }) beneficial ({ 4 7 10 }) when ({ }) there ({ }) are ({ }) several ({ 8 }) faces ({ 9 }) in ({ 11 }) a ({ 12 }) returned ({ 13 }) image ({ 14 }) , ({ }) as ({ 15 }) shown ({ 16 }) in ({ 17 }) Figure ({ 18 }) \REF ({ 19 }) . ({ 20 }) 
# Sentence pair (1332) source length 10 target length 10 alignment score : 0.0253469
A Text Segmentation Based Approach to Video Shot Boundary Detection 
NULL ({ }) A ({ 1 }) Text ({ 2 }) Segmentation ({ 3 }) Based ({ 4 }) Approach ({ 5 }) to ({ 6 }) Video ({ 7 }) Shot ({ 8 }) Boundary ({ 9 }) Detection ({ 10 }) 
# Sentence pair (1333) source length 17 target length 17 alignment score : 0.00334267
Video shot boundary detection is one of the fundamental tasks of video indexing and retrieval applications . 
NULL ({ }) Video ({ 1 }) shot ({ 2 }) boundary ({ 3 }) detection ({ 4 }) is ({ 5 }) one ({ 6 }) of ({ 7 }) the ({ 8 }) fundamental ({ 9 }) tasks ({ 10 }) of ({ 11 }) video ({ 12 }) indexing ({ 13 }) and ({ 14 }) retrieval ({ 15 }) applications ({ 16 }) . ({ 17 }) 
# Sentence pair (1334) source length 43 target length 41 alignment score : 6.62366e-09
Although many methods have been proposed for this task , finding a general and robust shot boundary method that is able to handle various transition types caused by photo flashes , rapid camera movement and object movement is still challenging . 
NULL ({ }) Although ({ 1 }) many ({ 2 }) methods ({ 3 }) have ({ 4 }) been ({ 5 }) proposed ({ 6 }) for ({ 7 }) this ({ 8 }) task ({ 9 }) , ({ 10 }) finding ({ 11 }) a ({ 12 }) general ({ 13 }) and ({ 14 }) robust ({ 15 }) shot ({ 16 }) boundary ({ 17 }) method ({ 18 }) that ({ 19 }) is ({ 20 }) able ({ 21 }) to ({ 22 }) handle ({ 23 }) the ({ }) various ({ 24 }) transition ({ 25 }) types ({ 26 }) caused ({ 27 }) by ({ 28 }) photo ({ 29 }) flashes ({ 30 }) , ({ 31 }) rapid ({ 32 }) camera ({ 33 }) movement ({ 34 }) , ({ }) and ({ 35 }) object ({ 36 }) movement ({ 37 }) is ({ 38 }) still ({ 39 }) challenging ({ 40 }) . ({ 41 }) 
# Sentence pair (1335) source length 34 target length 35 alignment score : 2.11832e-12
In this paper , we present a novel approach for detecting video shot boundaries in which we cast the problem of shot boundary detection into the problem of text segmentation in natural language processing . 
NULL ({ 2 4 }) We ({ 1 }) present ({ 6 }) a ({ 7 }) novel ({ 8 }) approach ({ 9 }) for ({ 10 }) detecting ({ 11 }) video ({ 12 }) shot ({ 13 }) boundaries ({ 14 }) in ({ 15 }) which ({ 16 }) we ({ 17 }) cast ({ 18 }) the ({ 19 }) problem ({ 20 }) of ({ 21 }) shot ({ 22 }) boundary ({ 23 }) detection ({ 24 }) into ({ 25 }) the ({ 26 }) problem ({ 27 }) of ({ 28 }) text ({ 29 }) segmentation ({ 30 }) in ({ 31 }) natural ({ 32 }) language ({ 33 }) processing ({ 34 }) . ({ 35 }) //detecting ({ 5 }) / ({ }) determining? ({ 3 }) 
# Sentence pair (1336) source length 27 target length 27 alignment score : 1.4578e-28
By the formulation that each frame is considered as a word and shot boundaries are treated as boundaries of text segments ( e .g topics ) . 
NULL ({ 2 9 19 }) This ({ 1 }) is ({ 7 }) possible ({ 8 }) by ({ }) assuming ({ 3 }) that ({ 4 }) each ({ 5 }) frame ({ 6 }) is ({ }) a ({ 10 }) word ({ 11 }) and ({ 12 }) then ({ }) the ({ }) shot ({ 13 }) boundaries ({ 14 }) are ({ 15 }) treated ({ 16 }) as ({ 17 }) text ({ 20 }) segment ({ 21 }) boundaries ({ 18 }) ( ({ 22 }) e.g. ({ 23 24 }) topics ({ 25 }) ) ({ 26 }) . ({ 27 }) 
# Sentence pair (1337) source length 13 target length 17 alignment score : 4.69813e-25
Text segmentation based approaches that have been well studied in natural language processing can be adopted . 
NULL ({ 5 }) The ({ }) text ({ 1 }) segmentation ({ 2 }) based ({ 3 }) approaches ({ 4 }) in ({ 10 }) natural ({ 6 8 11 }) language ({ 7 9 12 }) processing ({ 13 }) can ({ 14 }) be ({ 15 }) used ({ 16 }) . ({ 17 }) 
# Sentence pair (1338) source length 16 target length 14 alignment score : 1.19631e-08
Experimental results on various long video sequences show the effectiveness of our approach . 
NULL ({ }) The ({ }) experimental ({ 1 }) results ({ 2 }) from ({ 3 }) various ({ 4 }) long ({ 5 }) video ({ 6 }) sequences ({ 7 }) have ({ }) proven ({ 8 }) the ({ 9 }) effectiveness ({ 10 }) of ({ 11 }) our ({ 12 }) approach ({ 13 }) . ({ 14 }) 
# Sentence pair (1339) source length 13 target length 12 alignment score : 0.000332698
Recent advances in digital technology have made many video archives available . 
NULL ({ }) Recent ({ 1 }) advances ({ 2 }) in ({ 3 }) digital ({ 4 }) technology ({ 5 }) have ({ 6 }) made ({ 7 }) many ({ 8 }) video ({ 9 }) archives ({ 10 }) readily ({ }) available ({ 11 }) . ({ 12 }) 
# Sentence pair (1340) source length 16 target length 15 alignment score : 0.000350185
Therefore scalable , efficient and effective tools for indexing and retrieving video are needed . 
NULL ({ }) Therefore ({ 1 }) scalable ({ 2 }) , ({ 3 }) efficient ({ 4 }) , ({ }) and ({ 5 }) effective ({ 6 }) tools ({ 7 }) for ({ 8 }) indexing ({ 9 }) and ({ 10 }) retrieving ({ 11 }) video ({ 12 }) are ({ 13 }) needed ({ 14 }) . ({ 15 }) 
# Sentence pair (1341) source length 48 target length 46 alignment score : 3.20366e-12
With a large amount of information encoded in one video , typically the first step of any video processing tools is to segment the input video into elementary shots in which each shot is defined as continuous frames from a single camera at a time . 
NULL ({ }) With ({ 1 }) a ({ 2 }) large ({ 3 }) amount ({ 4 }) of ({ 5 }) information ({ 6 }) encoded ({ 7 }) in ({ 8 }) one ({ 9 }) video ({ 10 }) , ({ 11 }) typically ({ 12 }) the ({ 13 }) first ({ 14 }) step ({ 15 }) of ({ 16 }) any ({ 17 }) video ({ 18 }) processing ({ 19 }) tools ({ 20 }) is ({ 21 }) to ({ 22 }) segment ({ 23 }) the ({ 24 }) input ({ 25 }) video ({ 26 }) into ({ 27 }) elementary ({ 28 }) shots ({ 29 }) in ({ 30 }) which ({ 31 }) each ({ 32 }) shot ({ 33 }) is ({ 34 }) defined ({ 35 }) as ({ 36 }) a ({ }) continuous ({ 37 }) frame ({ 38 }) from ({ 39 }) a ({ 40 }) single ({ 41 }) camera ({ 42 }) at ({ 43 }) a ({ 44 }) given ({ }) moment ({ 45 }) . ({ 46 }) 
# Sentence pair (1342) source length 59 target length 53 alignment score : 4.40135e-23
By decomposing a video into shots and then extracting keyframes from these shots , a 30-minute video with 54 ,000 frames can be represented by around 500 keyframes ( 108 times smaller ) which are easily manageable for many video applications in indexing , browsing , summarization , retrieval and so on . 
NULL ({ 50 }) By ({ 1 }) breaking ({ 2 }) down ({ }) a ({ 3 }) video ({ 4 }) into ({ 5 }) individual ({ }) shots ({ 6 }) and ({ 7 }) then ({ 8 }) extracting ({ 9 }) the ({ }) keyframes ({ 10 }) from ({ 11 }) these ({ 12 }) shots ({ 13 }) , ({ 14 }) a ({ 15 }) 30-minute ({ 16 }) video ({ 17 }) containing ({ 18 }) 54 ({ 19 }) ,000 ({ 20 }) frames ({ 21 }) can ({ 22 }) be ({ 23 }) represented ({ 24 }) by ({ 25 }) around ({ 26 }) 500 ({ 27 }) keyframes ({ 28 }) ( ({ 29 }) 108 ({ 30 }) times ({ 31 }) smaller ({ 32 }) ) ({ 33 }) that ({ 34 }) are ({ 35 }) easily ({ 36 }) manageable ({ 37 }) for ({ 38 }) many ({ 39 }) video ({ 40 }) applications ({ 41 }) [in ({ 42 }) / ({ }) such ({ }) as? ({ 51 }) / ({ }) including?] ({ 52 }) indexing ({ 43 }) , ({ 44 }) browsing ({ 45 }) , ({ 46 }) summarization ({ 47 }) , ({ 48 }) and ({ }) retrieval ({ 49 }) . ({ 53 }) 
# Sentence pair (1343) source length 9 target length 9 alignment score : 0.0380241
There are many types of transitions between shots . 
NULL ({ }) There ({ 1 }) are ({ 2 }) many ({ 3 }) types ({ 4 }) of ({ 5 }) transitions ({ 6 }) between ({ 7 }) shots ({ 8 }) . ({ 9 }) 
# Sentence pair (1344) source length 21 target length 21 alignment score : 0.000765753
According to TRECVID 's categorization \CITE , shot boundaries can be classified into two main categories : cut and gradual . 
NULL ({ }) According ({ 1 }) to ({ 2 }) TRECVID ({ 3 }) 's ({ 4 }) categorization ({ 5 }) \CITE ({ 6 }) , ({ 7 }) shot ({ 8 }) boundaries ({ 9 }) can ({ 10 }) be ({ 11 }) classified ({ 12 }) into ({ 13 }) two ({ 14 }) main ({ 15 }) categories ({ 16 }) : ({ 17 }) cut ({ 18 }) and ({ 19 }) gradual ({ 20 }) . ({ 21 }) 
# Sentence pair (1345) source length 29 target length 29 alignment score : 7.05301e-07
A cut is an abrupt shot change that occurs in a single frame while a gradual is a slow change that occurs in a number of consecutive frames . 
NULL ({ }) A ({ 1 }) cut ({ 2 }) is ({ 3 }) an ({ 4 }) abrupt ({ 5 }) shot ({ 6 }) change ({ 7 }) that ({ 8 }) occurs ({ 9 }) in ({ 10 }) a ({ 11 }) single ({ 12 }) frame ({ 13 }) while ({ 14 }) a ({ 15 }) gradual ({ 16 }) is ({ 17 }) a ({ 18 }) slow ({ 19 }) change ({ 20 }) that ({ 21 }) occurs ({ 22 }) over ({ 23 }) a ({ 24 }) number ({ 25 }) of ({ 26 }) consecutive ({ 27 }) frames ({ 28 }) . ({ 29 }) 
# Sentence pair (1346) source length 11 target length 11 alignment score : 0.0168977
With the gradual type , fades and dissolves are common . 
NULL ({ }) With ({ 1 }) the ({ 2 }) gradual ({ 3 }) type ({ 4 }) , ({ 5 }) fades ({ 6 }) and ({ 7 }) dissolves ({ 8 }) are ({ 9 }) common ({ 10 }) . ({ 11 }) 
# Sentence pair (1347) source length 45 target length 42 alignment score : 9.64983e-11
A fade is usually a change in brightness with one or several solid black frames in between , while a dissolve occurs when the images in the current shot get dimmer and the images of the next shot get brighter \CITE . 
NULL ({ }) A ({ 1 }) fade ({ 2 }) is ({ 3 }) usually ({ 4 }) a ({ 5 }) change ({ 6 }) in ({ 7 }) brightness ({ 8 }) with ({ 9 }) one ({ 10 }) or ({ 11 }) several ({ 12 }) solid ({ 13 }) black ({ 14 }) frames ({ 15 }) in ({ 16 }) between ({ 17 }) the ({ }) key ({ }) frames ({ }) , ({ 18 }) while ({ 19 }) a ({ 20 }) dissolve ({ 21 }) occurs ({ 22 }) when ({ 23 }) the ({ 24 }) images ({ 25 }) in ({ 26 }) the ({ 27 }) current ({ 28 }) shot ({ 29 }) get ({ 30 }) dimmer ({ 31 }) and ({ 32 }) the ({ 33 }) images ({ 34 }) of ({ 35 }) the ({ 36 }) next ({ 37 }) shot ({ 38 }) get ({ 39 }) brighter ({ 40 }) \CITE ({ 41 }) . ({ 42 }) 
# Sentence pair (1348) source length 9 target length 9 alignment score : 0.0633403
Figure \REF shows examples of shot boundary types . 
NULL ({ }) Figure ({ 1 }) \REF ({ 2 }) shows ({ 3 }) examples ({ 4 }) of ({ 5 }) shot ({ 6 }) boundary ({ 7 }) types ({ 8 }) . ({ 9 }) 
# Sentence pair (1349) source length 10 target length 10 alignment score : 0.0135611
Many approaches have been proposed for shot boundary detection . 
NULL ({ }) Many ({ 1 }) approaches ({ 2 }) have ({ 3 }) been ({ 4 }) proposed ({ 5 }) for ({ 6 }) shot ({ 7 }) boundary ({ 8 }) detection ({ 9 }) . ({ 10 }) 
# Sentence pair (1350) source length 27 target length 26 alignment score : 1.22059e-05
The simplest approach is to compute the differences between color distributions of consecutive frames and use a threshold to classify whether a hard cut occurs . 
NULL ({ }) The ({ 1 }) simplest ({ 2 }) approach ({ 3 }) is ({ 4 }) to ({ 5 }) compute ({ 6 }) the ({ 7 }) differences ({ 8 }) between ({ 9 }) the ({ }) color ({ 10 }) distributions ({ 11 }) of ({ 12 }) consecutive ({ 13 }) frames ({ 14 }) and ({ 15 }) use ({ 16 }) a ({ 17 }) threshold ({ 18 }) to ({ 19 }) classify ({ 20 }) whether ({ 21 }) a ({ 22 }) hard ({ 23 }) cut ({ 24 }) occurs ({ 25 }) . ({ 26 }) 
# Sentence pair (1351) source length 18 target length 18 alignment score : 0.000633488
In order to detect gradual transitions , edge change ratio or motion vectors can be used \CITE . 
NULL ({ }) In ({ 1 }) order ({ 2 }) to ({ 3 }) detect ({ 4 }) gradual ({ 5 }) transitions ({ 6 }) , ({ 7 }) edge ({ 8 }) change ({ 9 }) ratios ({ 10 }) or ({ 11 }) motion ({ 12 }) vectors ({ 13 }) can ({ 14 }) be ({ 15 }) used ({ 16 }) \CITE ({ 17 }) . ({ 18 }) 
# Sentence pair (1352) source length 16 target length 15 alignment score : 1.3552e-07
Since these approaches use threshold-based models for detection , their advantage is fast speed . 
NULL ({ }) Since ({ 1 }) these ({ 2 }) approaches ({ 3 }) use ({ 4 }) threshold-based ({ 5 }) models ({ 6 }) for ({ 7 }) detection ({ 8 }) , ({ 9 }) their ({ 10 }) advantage ({ 11 }) is ({ 12 }) they ({ 14 }) are ({ }) fast ({ 13 }) . ({ 15 }) 
# Sentence pair (1353) source length 12 target length 12 alignment score : 6.13194e-05
Nevertheless , they are sensitive to changes of illumination and motion . 
NULL ({ }) Nevertheless ({ 1 }) , ({ 2 }) they ({ 3 }) are ({ 4 }) sensitive ({ 5 }) to ({ 6 }) changes ({ 7 }) in ({ 8 }) illumination ({ 9 }) and ({ 10 }) motion ({ 11 }) . ({ 12 }) 
# Sentence pair (1354) source length 11 target length 11 alignment score : 0.0138419
Furthermore , they are difficult to generalize for new datasets . 
NULL ({ }) Furthermore ({ 1 }) , ({ 2 }) they ({ 3 }) are ({ 4 }) difficult ({ 5 }) to ({ 6 }) generalize ({ 7 }) for ({ 8 }) new ({ 9 }) datasets ({ 10 }) . ({ 11 }) 
# Sentence pair (1355) source length 39 target length 35 alignment score : 1.27497e-14
Recent works \CITE use machine learning methods for making decision and show impressive results on test videos of TRECVID \CITE which is a de-facto benchmark for evaluation of various techniques in shot boundary detection . 
NULL ({ 28 }) Recent ({ 1 }) works ({ 2 }) \CITE ({ 3 }) use ({ 4 }) machine ({ 5 }) learning ({ 6 }) methods ({ 7 }) for ({ 8 }) making ({ 9 }) decisions ({ 10 }) and ({ 11 }) have ({ }) received ({ 12 }) impressive ({ 13 }) results ({ 14 }) on ({ 15 }) the ({ }) test ({ 16 }) videos ({ 17 }) of ({ 18 }) TRECVID ({ 19 }) \CITE ({ 20 }) , ({ }) which ({ 21 }) is ({ 22 }) a ({ 23 }) de-facto ({ 24 }) benchmark ({ 25 }) for ({ 26 }) evaluating ({ 27 }) the ({ }) various ({ 29 }) techniques ({ 30 }) used ({ }) in ({ 31 }) shot ({ 32 }) boundary ({ 33 }) detection ({ 34 }) . ({ 35 }) 
# Sentence pair (1356) source length 38 target length 35 alignment score : 4.47885e-13
In this study , we propose a new approach inspired from natural language processing text segmentation techniques in which the problem of shot boundary detection is treated similarly to the problem of text segmentation . 
NULL ({ }) In ({ 1 }) this ({ 2 }) study ({ 3 }) , ({ 4 }) we ({ 5 }) propose ({ 6 }) a ({ 7 }) new ({ 8 }) approach ({ 9 }) that ({ }) was ({ }) inspired ({ 10 }) by ({ 11 }) the ({ }) natural ({ 12 }) language ({ 13 }) processing ({ 14 }) text ({ 15 }) segmentation ({ 16 }) techniques ({ 17 }) in ({ 18 }) which ({ 19 }) the ({ 20 }) problem ({ 21 }) of ({ 22 }) shot ({ 23 }) boundary ({ 24 }) detection ({ 25 }) is ({ 26 }) treated ({ 27 }) similarly ({ 28 }) to ({ 29 }) the ({ 30 }) problem ({ 31 }) in ({ 32 }) text ({ 33 }) segmentation ({ 34 }) . ({ 35 }) 
# Sentence pair (1357) source length 25 target length 27 alignment score : 4.89653e-11
Specifically , each frame is considered as a word and a set of consecutive frames , forming a shot , is considered as a text segment . 
NULL ({ 7 23 }) Specifically ({ 1 }) , ({ 2 }) each ({ 3 }) frame ({ 4 }) is ({ 5 }) considered ({ 6 }) a ({ 8 }) word ({ 9 }) and ({ 10 }) a ({ 11 }) set ({ 12 }) of ({ 13 }) consecutive ({ 14 }) frames ({ 15 }) , ({ 16 }) forming ({ 17 }) a ({ 18 }) shot ({ 19 }) , ({ 20 }) is ({ 21 }) considered ({ 22 }) a ({ 24 }) text ({ 25 }) segment ({ 26 }) . ({ 27 }) 
# Sentence pair (1358) source length 26 target length 25 alignment score : 2.28331e-11
Then , the text segmentation problem can be considered a sequential tagging problem in which each word is labeled by one of labels such as 
NULL ({ 25 }) Then ({ 1 }) , ({ 2 }) the ({ 3 }) text ({ 4 }) segmentation ({ 5 }) problem ({ 6 }) can ({ 7 }) be ({ 8 }) considered ({ 9 }) a ({ 10 }) sequential ({ 11 }) tagging ({ 12 }) problem ({ 13 }) in ({ 14 }) which ({ 15 }) each ({ 16 }) word ({ 17 }) is ({ 18 }) labeled ({ 19 }) by ({ 20 }) one ({ 21 }) of ({ 22 }) the ({ }) following ({ 24 }) labels ({ 23 }) : ({ }) 
# Sentence pair (1359) source length 26 target length 25 alignment score : 3.95923e-05
PRESEG ( word beginning of a segment ) , INSEG ( word inside a segment ) and POSTSEG ( word outside a segment ) . 
NULL ({ }) PRESEG ({ 1 }) ( ({ 2 }) word ({ 3 }) beginning ({ 4 }) of ({ 5 }) a ({ 6 }) segment ({ 7 }) ) ({ 8 }) , ({ 9 }) INSEG ({ 10 }) ( ({ 11 }) word ({ 12 }) inside ({ 13 }) a ({ 14 }) segment ({ 15 }) ) ({ 16 }) , ({ }) and ({ 17 }) POSTSEG ({ 18 }) ( ({ 19 }) word ({ 20 }) outside ({ 21 }) a ({ 22 }) segment ({ 23 }) ) ({ 24 }) . ({ 25 }) 
# Sentence pair (1360) source length 16 target length 16 alignment score : 0.00415378
Given a sequence of labeled words , the boundary between text segments can be identified . 
NULL ({ }) Given ({ 1 }) a ({ 2 }) sequence ({ 3 }) of ({ 4 }) labeled ({ 5 }) words ({ 6 }) , ({ 7 }) the ({ 8 }) boundary ({ 9 }) between ({ 10 }) text ({ 11 }) segments ({ 12 }) can ({ 13 }) be ({ 14 }) identified ({ 15 }) . ({ 16 }) 
# Sentence pair (1361) source length 10 target length 10 alignment score : 0.000330856
The remaining of the paper is organized as follows . 
NULL ({ }) The ({ 1 }) remainder ({ 2 }) of ({ 3 }) this ({ 4 }) paper ({ 5 }) is ({ 6 }) organized ({ 7 }) as ({ 8 }) follows ({ 9 }) . ({ 10 }) 
# Sentence pair (1362) source length 12 target length 12 alignment score : 0.00905616
In section \REF , we present an overview of our framework . 
NULL ({ }) In ({ 1 }) section ({ 2 }) \REF ({ 3 }) , ({ 4 }) we ({ 5 }) present ({ 6 }) an ({ 7 }) overview ({ 8 }) of ({ 9 }) our ({ 10 }) framework ({ 11 }) . ({ 12 }) 
# Sentence pair (1363) source length 15 target length 13 alignment score : 0.000175015
Section \REF introduces experiments on different long video sequences from TRECVID dataset . 
NULL ({ }) Section ({ 1 }) \REF ({ 2 }) introduces ({ 3 }) our ({ }) experiments ({ 4 }) on ({ 5 }) different ({ 6 }) long ({ 7 }) video ({ 8 }) sequences ({ 9 }) from ({ 10 }) the ({ }) TRECVID ({ 11 }) dataset ({ 12 }) . ({ 13 }) 
# Sentence pair (1364) source length 6 target length 6 alignment score : 0.141138
Section \REF concludes the paper . 
NULL ({ }) Section ({ 1 }) \REF ({ 2 }) concludes ({ 3 }) the ({ 4 }) paper ({ 5 }) . ({ 6 }) 
# Sentence pair (1365) source length 17 target length 17 alignment score : 9.40553e-14
Given a video , the shot boundary detection process is carried out through two main stages . 
NULL ({ 4 5 }) The ({ 1 }) shot ({ 6 }) boundary ({ 7 }) detection ({ 8 }) process ({ 9 }) for ({ }) a ({ 2 }) given ({ }) video ({ 3 }) is ({ 10 }) carried ({ 11 }) out ({ 12 }) through ({ 13 }) two ({ 14 }) main ({ 15 }) stages ({ 16 }) . ({ 17 }) 
# Sentence pair (1366) source length 14 target length 14 alignment score : 0.000156794
In the first stage , frames are extracted and labeled by pre-defined labels . 
NULL ({ }) In ({ 1 }) the ({ 2 }) first ({ 3 }) stage ({ 4 }) , ({ 5 }) frames ({ 6 }) are ({ 7 }) extracted ({ 8 }) and ({ 9 }) labeled ({ 10 }) with ({ 11 }) pre-defined ({ 12 }) labels ({ 13 }) . ({ 14 }) 
# Sentence pair (1367) source length 18 target length 16 alignment score : 0.000133322
In the second stage , shot boundaries are identified by grouping labeled frames into segments . 
NULL ({ }) In ({ 1 }) the ({ 2 }) second ({ 3 }) stage ({ 4 }) , ({ 5 }) the ({ }) shot ({ 6 }) boundaries ({ 7 }) are ({ 8 }) identified ({ 9 }) by ({ 10 }) grouping ({ 11 }) the ({ }) labeled ({ 12 }) frames ({ 13 }) into ({ 14 }) segments ({ 15 }) . ({ 16 }) 
# Sentence pair (1368) source length 74 target length 72 alignment score : 1.23505e-13
We use the following six labels to label frames in video : NORM -FRM ( frame of a normal shot ) , PRE -CUT ( pre-frame of a CUT transition ) , POST -CUT ( post-frame of a CUT transition ) , PRE -GRAD ( pre-frame of a GRADUAL transition ) , IN -GRAD ( frame inside a GRADUAL transition ) , POST -GRAD ( post-frame of a GRADUAL transition ) . 
NULL ({ }) We ({ 1 }) use ({ 2 }) the ({ 3 }) following ({ 4 }) six ({ 5 }) labels ({ 6 }) to ({ 7 }) label ({ 8 }) frames ({ 9 }) in ({ 10 }) a ({ }) video ({ 11 }) : ({ 12 }) NORM ({ 13 }) -FRM ({ 14 }) ( ({ 15 }) frame ({ 16 }) of ({ 17 }) a ({ 18 }) normal ({ 19 }) shot ({ 20 }) ) ({ 21 }) , ({ 22 }) PRE ({ 23 }) -CUT ({ 24 }) ( ({ 25 }) pre-frame ({ 26 }) of ({ 27 }) a ({ 28 }) CUT ({ 29 }) transition ({ 30 }) ) ({ 31 }) , ({ 32 }) POST ({ 33 }) -CUT ({ 34 }) ( ({ 35 }) post-frame ({ 36 }) of ({ 37 }) a ({ 38 }) CUT ({ 39 }) transition ({ 40 }) ) ({ 41 }) , ({ 42 }) PRE ({ 43 }) -GRAD ({ 44 }) ( ({ 45 }) pre-frame ({ 46 }) of ({ 47 }) a ({ 48 }) GRADUAL ({ 49 }) transition ({ 50 }) ) ({ 51 }) , ({ 52 }) IN ({ 53 }) -GRAD ({ 54 }) ( ({ 55 }) frame ({ 56 }) inside ({ 57 }) a ({ 58 }) GRADUAL ({ 59 }) transition ({ 60 }) ) ({ 61 }) , ({ 62 }) and ({ }) POST ({ 63 }) -GRAD ({ 64 }) ( ({ 65 }) post-frame ({ 66 }) of ({ 67 }) a ({ 68 }) GRADUAL ({ 69 }) transition ({ 70 }) ) ({ 71 }) . ({ 72 }) 
# Sentence pair (1369) source length 30 target length 27 alignment score : 1.10842e-08
Given a sequence of labeled frames , shot boundaries and transition types are identified by looking up and processing frames marked by non NORM -FRM label . 
NULL ({ }) Given ({ 1 }) a ({ 2 }) sequence ({ 3 }) of ({ 4 }) labeled ({ 5 }) frames ({ 6 }) , ({ 7 }) the ({ }) shot ({ 8 }) boundaries ({ 9 }) and ({ 10 }) transition ({ 11 }) types ({ 12 }) are ({ 13 }) identified ({ 14 }) by ({ 15 }) looking ({ 16 }) up ({ 17 }) and ({ 18 }) processing ({ 19 }) the ({ }) frames ({ 20 }) marked ({ 21 }) with ({ 22 }) a ({ }) non ({ 23 }) NORM ({ 24 }) -FRM ({ 25 }) label ({ 26 }) . ({ 27 }) 
# Sentence pair (1370) source length 35 target length 34 alignment score : 4.18034e-10
For example , if we encounter two consecutive frames marked by IN-CUT and POST-CUT respectively , we can declare that a shot boundary occurs at these frames and the transition type is CUT . 
NULL ({ }) For ({ 1 }) example ({ 2 }) , ({ 3 }) if ({ 4 }) we ({ 5 }) encounter ({ 6 }) two ({ 7 }) consecutive ({ 8 }) frames ({ 9 }) respectively ({ 15 }) marked ({ 10 }) by ({ 11 }) IN-CUT ({ 12 }) and ({ 13 }) POST-CUT ({ 14 }) , ({ 16 }) we ({ 17 }) can ({ 18 }) declare ({ 19 }) that ({ 20 }) a ({ 21 }) shot ({ 22 }) boundary ({ 23 }) occurs ({ 24 }) at ({ 25 }) these ({ 26 }) frames ({ 27 }) and ({ 28 }) the ({ 29 }) transition ({ 30 }) type ({ 31 }) is ({ 32 }) a ({ }) CUT ({ 33 }) . ({ 34 }) 
# Sentence pair (1371) source length 28 target length 27 alignment score : 1.17932e-05
In another case , if we encounter a number of frames marked by xxx-GRAD , we can declare a GRADUAL shot boundary occurs at these frames . 
NULL ({ }) In ({ 1 }) another ({ 2 }) case ({ 3 }) , ({ 4 }) if ({ 5 }) we ({ 6 }) encounter ({ 7 }) a ({ 8 }) number ({ 9 }) of ({ 10 }) frames ({ 11 }) marked ({ 12 }) by ({ 13 }) xxx-GRAD ({ 14 }) , ({ 15 }) we ({ 16 }) can ({ 17 }) declare ({ 18 }) that ({ }) a ({ 19 }) GRADUAL ({ 20 }) shot ({ 21 }) boundary ({ 22 }) occurs ({ 23 }) at ({ 24 }) these ({ 25 }) frames ({ 26 }) . ({ 27 }) 
# Sentence pair (1372) source length 14 target length 13 alignment score : 0.00287604
Figure \REF shows an example of labeled frames of a shot transition . 
NULL ({ }) Figure ({ 1 }) \REF ({ 2 }) shows ({ 3 }) an ({ 4 }) example ({ 5 }) of ({ 6 }) the ({ }) labeled ({ 7 }) frames ({ 8 }) of ({ 9 }) a ({ 10 }) shot ({ 11 }) transition ({ 12 }) . ({ 13 }) 
# Sentence pair (1373) source length 46 target length 41 alignment score : 9.58886e-20
To label a frame in video , firstly we extract features for that frame and then use a classifier , that has been trained by annotated frames in advance , to classify it into one of six categories mentioned above . 
NULL ({ 7 }) To ({ 1 }) label ({ 2 }) a ({ 3 }) frame ({ 4 }) in ({ 5 }) a ({ }) video ({ 6 }) , ({ }) we ({ 9 }) must ({ }) firstly ({ 8 }) extract ({ 10 }) the ({ }) features ({ 11 }) for ({ 12 }) that ({ 13 }) frame ({ 14 }) and ({ 15 }) then ({ 16 }) use ({ 17 }) a ({ 18 }) classifier ({ 19 }) , ({ 20 }) which ({ 21 }) has ({ 22 }) been ({ 23 }) trained ({ 24 }) in ({ 28 }) advance ({ 29 }) by ({ 25 }) the ({ }) annotated ({ 26 }) frames ({ 27 }) , ({ 30 }) to ({ 31 }) classify ({ 32 }) it ({ 33 }) into ({ 34 }) one ({ 35 }) of ({ 36 }) the ({ }) six ({ 37 }) categories ({ 38 }) mentioned ({ 39 }) above ({ 40 }) . ({ 41 }) 
# Sentence pair (1374) source length 21 target length 20 alignment score : 7.63328e-05
The feature extraction process and classifier learning using support vector machine ( SVM ) are described in details below . 
NULL ({ }) The ({ 1 }) feature ({ 2 }) extraction ({ 3 }) process ({ 4 }) and ({ 5 }) classifier ({ 6 }) learning ({ 7 }) using ({ 8 }) a ({ }) support ({ 9 }) vector ({ 10 }) machine ({ 11 }) ( ({ 12 }) SVM ({ 13 }) ) ({ 14 }) are ({ 15 }) described ({ 16 }) in ({ 17 }) detail ({ 18 }) below ({ 19 }) . ({ 20 }) 
# Sentence pair (1375) source length 25 target length 21 alignment score : 3.87255e-13
We use two typical features that are color moments , edge direction histogram for representing visual information of each frame . 
NULL ({ 10 }) We ({ 1 }) use ({ 2 }) two ({ 3 }) typical ({ 4 }) features ({ 5 }) , ({ }) which ({ 6 }) are ({ 7 }) the ({ }) color ({ 8 }) moments ({ 9 }) and ({ }) edge ({ 11 }) direction ({ 12 }) histogram ({ 13 }) , ({ }) to ({ 14 }) represent ({ 15 }) the ({ }) visual ({ 16 }) information ({ 17 }) of ({ 18 }) each ({ 19 }) frame ({ 20 }) . ({ 21 }) 
# Sentence pair (1376) source length 27 target length 27 alignment score : 3.12577e-09
However , using this representation is not discriminative enough for frame categorization since frames of a shot transition usually have strong relation to their neighbor frames . 
NULL ({ }) However ({ 1 }) , ({ 2 }) using ({ 3 }) this ({ 4 }) representation ({ 5 }) is ({ 6 }) not ({ 7 }) discriminative ({ 8 }) enough ({ 9 }) for ({ 10 }) frame ({ 11 }) categorization ({ 12 }) since ({ 13 }) the ({ }) frames ({ 14 }) of ({ 15 }) a ({ 16 }) shot ({ 17 }) transition ({ 18 }) usually ({ 19 }) strongly ({ 20 }) relate ({ 21 22 }) to ({ 23 }) their ({ 24 }) neighboring ({ 25 }) frames ({ 26 }) . ({ 27 }) 
# Sentence pair (1377) source length 42 target length 42 alignment score : 6.32685e-09
For example , an abrupt change in illumination between two consecutive frames is a strong cue for a hard cut , or one solid black frames in between dark and then bright frames might help to identify a fade shot transition . 
NULL ({ }) For ({ 1 }) example ({ 2 }) , ({ 3 }) an ({ 4 }) abrupt ({ 5 }) change ({ 6 }) in ({ 7 }) illumination ({ 8 }) between ({ 9 }) two ({ 10 }) consecutive ({ 11 }) frames ({ 12 }) is ({ 13 }) a ({ 14 }) strong ({ 15 }) cue ({ 16 }) for ({ 17 }) a ({ 18 }) hard ({ 19 }) cut ({ 20 }) , ({ 21 }) or ({ 22 }) one ({ 23 }) solid ({ 24 }) black ({ 25 }) frame ({ 26 }) in ({ 27 }) between ({ 28 }) dark ({ 29 }) and ({ 30 }) then ({ 31 }) bright ({ 32 }) frames ({ 33 }) might ({ 34 }) help ({ 35 }) to ({ 36 }) identify ({ 37 }) a ({ 38 }) fade ({ 39 }) shot ({ 40 }) transition ({ 41 }) . ({ 42 }) 
# Sentence pair (1378) source length 15 target length 14 alignment score : 0.000998141
Therefore , in this study , we do not directly use above features . 
NULL ({ }) Therefore ({ 1 }) , ({ 2 }) in ({ 3 }) this ({ 4 }) study ({ 5 }) , ({ 6 }) we ({ 7 }) do ({ 8 }) not ({ 9 }) directly ({ 10 }) use ({ 11 }) the ({ }) above ({ 12 }) features ({ 13 }) . ({ 14 }) 
# Sentence pair (1379) source length 21 target length 21 alignment score : 0.000232831
Instead , we use them indirectly to model the difference and motion between the current frame and its neighbor frames . 
NULL ({ }) Instead ({ 1 }) , ({ 2 }) we ({ 3 }) use ({ 4 }) them ({ 5 }) indirectly ({ 6 }) to ({ 7 }) model ({ 8 }) the ({ 9 }) difference ({ 10 }) and ({ 11 }) motion ({ 12 }) between ({ 13 }) the ({ 14 }) current ({ 15 }) frame ({ 16 }) and ({ 17 }) its ({ 18 }) neighboring ({ 19 }) frames ({ 20 }) . ({ 21 }) 
# Sentence pair (1380) source length 23 target length 22 alignment score : 9.30589e-07
Specifically , for each frame , we compute \MATH distances between the current frame \MATH and neighbor frames ranging from \MATH . 
NULL ({ }) In ({ }) particular ({ 1 }) , ({ 2 }) for ({ 3 }) each ({ 4 }) frame ({ 5 }) , ({ 6 }) we ({ 7 }) compute ({ 8 }) \MATH ({ 9 }) distances ({ 10 }) between ({ 11 }) the ({ 12 }) current ({ 13 }) frame ({ 14 }) \MATH ({ 15 }) and ({ 16 }) neighboring ({ 17 }) frames ({ 18 }) ranging ({ 19 }) from ({ 20 }) \MATH ({ 21 }) . ({ 22 }) 
# Sentence pair (1381) source length 20 target length 19 alignment score : 0.000287576
These distances are used to form a feature vector for frame \MATH in training and testing process later . 
NULL ({ }) These ({ 1 }) distances ({ 2 }) are ({ 3 }) used ({ 4 }) to ({ 5 }) form ({ 6 }) a ({ 7 }) feature ({ 8 }) vector ({ 9 }) for ({ 10 }) frame ({ 11 }) \MATH ({ 12 }) in ({ 13 }) the ({ }) training ({ 14 }) and ({ 15 }) testing ({ 16 }) process ({ 17 }) later ({ 18 }) . ({ 19 }) 
# Sentence pair (1382) source length 43 target length 37 alignment score : 7.66562e-17
By this way , we can have a unified framework for shot boundary detection and consequently avoid to have special treatments for different shot boundary types as described in many works participated the TRECVID benchmark \CITE . 
NULL ({ }) In ({ 1 }) this ({ 2 }) way ({ 3 }) , ({ 4 }) we ({ 5 }) can ({ 6 }) have ({ 7 }) a ({ 8 }) unified ({ 9 }) framework ({ 10 }) for ({ 11 }) the ({ }) shot ({ 12 }) boundary ({ 13 }) detection ({ 14 }) and ({ 15 }) consequently ({ 16 }) avoid ({ 17 }) having ({ }) to ({ 18 }) give ({ 19 }) special ({ 20 }) treatment ({ 21 }) to ({ 22 }) the ({ }) different ({ 23 }) shot ({ 24 }) boundary ({ 25 }) types ({ 26 }) as ({ 27 }) described ({ 28 }) in ({ 29 }) many ({ 30 }) of ({ }) the ({ }) works ({ 31 }) that ({ }) participated ({ 32 }) the ({ 33 }) TRECVID ({ 34 }) benchmark ({ 35 }) \CITE ({ 36 }) . ({ 37 }) 
# Sentence pair (1383) source length 25 target length 24 alignment score : 1.21491e-05
Color moments have been successfully used in retrieval systems and proved to be efficient and effective in representing color distributions of images \CITE . 
NULL ({ }) Color ({ 1 }) moments ({ 2 }) have ({ 3 }) been ({ 4 }) successfully ({ 5 }) used ({ 6 }) in ({ 7 }) retrieval ({ 8 }) systems ({ 9 }) and ({ 10 }) proved ({ 11 }) to ({ 12 }) be ({ 13 }) efficient ({ 14 }) and ({ 15 }) effective ({ 16 }) in ({ 17 }) representing ({ 18 }) the ({ }) color ({ 19 }) distributions ({ 20 }) of ({ 21 }) images ({ 22 }) \CITE ({ 23 }) . ({ 24 }) 
# Sentence pair (1384) source length 27 target length 26 alignment score : 7.1308e-06
The first order ( mean ) , the second order ( variance ) and the third order ( skewness ) color moments are defined as : 
NULL ({ }) The ({ 1 }) first ({ 2 }) order ({ 3 }) ( ({ 4 }) mean ({ 5 }) ) ({ 6 }) , ({ 7 }) the ({ 8 }) second ({ 9 }) order ({ 10 }) ( ({ 11 }) variance ({ 12 }) ) ({ 13 }) , ({ }) and ({ 14 }) the ({ 15 }) third ({ 16 }) order ({ 17 }) ( ({ 18 }) skewness ({ 19 }) ) ({ 20 }) color ({ 21 }) moments ({ 22 }) are ({ 23 }) defined ({ 24 }) as ({ 25 }) : ({ 26 }) 
# Sentence pair (1385) source length 27 target length 28 alignment score : 4.34899e-06
where \MATH is the value of the \MATH -th color component of the image pixel \MATH , and \MATH is the number of pixels in the image . 
NULL ({ 13 }) where ({ 1 }) \MATH ({ 2 }) is ({ 3 }) the ({ 4 }) value ({ 5 }) of ({ 6 }) the ({ 7 }) \MATH ({ 8 }) -th ({ 9 }) color ({ 10 }) component ({ 11 }) of ({ 12 }) image ({ 14 }) pixel ({ 15 }) \MATH ({ 16 }) , ({ 17 }) and ({ 18 }) \MATH ({ 19 }) is ({ 20 }) the ({ 21 }) number ({ 22 }) of ({ 23 }) pixels ({ 24 }) in ({ 25 }) the ({ 26 }) image ({ 27 }) . ({ 28 }) 
# Sentence pair (1386) source length 14 target length 14 alignment score : 4.20328e-07
Edge orientation histogram has also been used widely in shot boundary detection \CITE . 
NULL ({ }) Edge ({ 1 }) orientation ({ 2 }) histogram ({ 3 }) has ({ 4 }) also ({ 5 }) been ({ 6 }) widely ({ 8 }) used ({ 7 }) in ({ 9 }) shot ({ 10 }) boundary ({ 11 }) detection ({ 12 }) \CITE ({ 13 }) . ({ 14 }) 
# Sentence pair (1387) source length 14 target length 13 alignment score : 1.10582e-07
The basic steps to compute edge orientation histogram feature are as follows : 
NULL ({ }) The ({ 1 }) basic ({ 2 }) steps ({ 3 }) for ({ 4 }) computing ({ 5 }) the ({ }) edge ({ 6 }) orientation ({ 7 }) histogram ({ 8 }) features ({ 9 }) are ({ 10 }) as ({ 11 }) follows ({ 12 }) : ({ 13 }) 
# Sentence pair (1388) source length 12 target length 12 alignment score : 0.0162985
Extract edges from the input image by using Canny edge detector . 
NULL ({ }) Extract ({ 1 }) edges ({ 2 }) from ({ 3 }) the ({ 4 }) input ({ 5 }) image ({ 6 }) by ({ 7 }) using ({ 8 }) Canny ({ 9 }) edge ({ 10 }) detector ({ 11 }) . ({ 12 }) 
# Sentence pair (1389) source length 11 target length 11 alignment score : 0.031195
Compute a \MATH -bin histogram of edge and non-edge pixels . 
NULL ({ }) Compute ({ 1 }) a ({ 2 }) \MATH ({ 3 }) -bin ({ 4 }) histogram ({ 5 }) of ({ 6 }) edge ({ 7 }) and ({ 8 }) non-edge ({ 9 }) pixels ({ 10 }) . ({ 11 }) 
# Sentence pair (1390) source length 28 target length 25 alignment score : 4.79771e-07
The first \MATH bins are used to represent edge directions quantized at \MATH interval and the remaining bin is used for counting non-edge pixels . 
NULL ({ }) The ({ 1 }) first ({ 2 }) \MATH ({ 3 }) bins ({ 4 }) are ({ 5 }) used ({ 6 }) to ({ 7 }) represent ({ 8 }) the ({ }) edge ({ 9 }) directions ({ 10 }) quantized ({ 11 }) at ({ 12 }) a ({ }) \MATH ({ 13 }) interval ({ 14 }) and ({ 15 }) the ({ 16 }) remaining ({ 17 }) bin ({ 18 }) is ({ 19 }) used ({ 20 }) for ({ 21 }) counting ({ 22 }) the ({ }) non-edge ({ 23 }) pixels ({ 24 }) . ({ 25 }) 
# Sentence pair (1391) source length 19 target length 17 alignment score : 2.32936e-05
The histogram is normalized by the number of all pixels to compensate for different image sizes . 
NULL ({ }) The ({ 1 }) histogram ({ 2 }) is ({ 3 }) normalized ({ 4 }) by ({ 5 }) the ({ 6 }) total ({ }) number ({ 7 }) of ({ 8 }) all ({ 9 }) the ({ }) pixels ({ 10 }) to ({ 11 }) compensate ({ 12 }) for ({ 13 }) different ({ 14 }) image ({ 15 }) sizes ({ 16 }) . ({ 17 }) 
# Sentence pair (1392) source length 25 target length 23 alignment score : 4.45532e-08
We use color moments and edge orientation histogram to compute distances between the current frame \MATH and it neighbor frames as follows : 
NULL ({ }) We ({ 1 }) use ({ 2 }) color ({ 3 }) moments ({ 4 }) and ({ 5 }) an ({ }) edge ({ 6 }) orientation ({ 7 }) histogram ({ 8 }) to ({ 9 }) compute ({ 10 }) the ({ }) distances ({ 11 }) between ({ 12 }) the ({ 13 }) current ({ 14 }) frame ({ 15 }) \MATH ({ 16 }) and ({ 17 }) its ({ 18 }) neighboring ({ 19 }) frames ({ 20 }) as ({ 21 }) follows ({ 22 }) : ({ 23 }) 
# Sentence pair (1393) source length 30 target length 29 alignment score : 8.01945e-06
The input image is converted to LUV color space ( for GCM ) or grayscale ( for EOH ) and then divided into sub-images by a \MATH grid . 
NULL ({ }) The ({ 1 }) input ({ 2 }) image ({ 3 }) is ({ 4 }) converted ({ 5 }) to ({ 6 }) a ({ }) LUV ({ 7 }) color ({ 8 }) space ({ 9 }) ( ({ 10 }) for ({ 11 }) GCM ({ 12 }) ) ({ 13 }) or ({ 14 }) grayscale ({ 15 }) ( ({ 16 }) for ({ 17 }) EOH ({ 18 }) ) ({ 19 }) and ({ 20 }) then ({ 21 }) divided ({ 22 }) into ({ 23 }) sub-images ({ 24 }) by ({ 25 }) a ({ 26 }) \MATH ({ 27 }) grid ({ 28 }) . ({ 29 }) 
# Sentence pair (1394) source length 13 target length 13 alignment score : 0.0154286
The color moments and edge orientation histogram are extracted from these sub-images . 
NULL ({ }) The ({ 1 }) color ({ 2 }) moments ({ 3 }) and ({ 4 }) edge ({ 5 }) orientation ({ 6 }) histogram ({ 7 }) are ({ 8 }) extracted ({ 9 }) from ({ 10 }) these ({ 11 }) sub-images ({ 12 }) . ({ 13 }) 
# Sentence pair (1395) source length 9 target length 9 alignment score : 0.0577782
For color moments , there are \MATH values . 
NULL ({ }) For ({ 1 }) color ({ 2 }) moments ({ 3 }) , ({ 4 }) there ({ 5 }) are ({ 6 }) \MATH ({ 7 }) values ({ 8 }) . ({ 9 }) 
# Sentence pair (1396) source length 16 target length 15 alignment score : 0.0011957
For edge orientation histogram , there are \MATH values for each input frame image . 
NULL ({ }) For ({ 1 }) the ({ }) edge ({ 2 }) orientation ({ 3 }) histogram ({ 4 }) , ({ 5 }) there ({ 6 }) are ({ 7 }) \MATH ({ 8 }) values ({ 9 }) for ({ 10 }) each ({ 11 }) input ({ 12 }) frame ({ 13 }) image ({ 14 }) . ({ 15 }) 
# Sentence pair (1397) source length 22 target length 20 alignment score : 1.88222e-06
Compute \MATH values which are the Euclidean distance between current frame \MATH and its neighbor frames ranging from \MATH . 
NULL ({ }) Compute ({ 1 }) \MATH ({ 2 }) values ({ 3 }) , ({ }) which ({ 4 }) are ({ 5 }) the ({ 6 }) Euclidean ({ 7 }) distances ({ 8 }) between ({ 9 }) the ({ }) current ({ 10 }) frame ({ 11 }) \MATH ({ 12 }) and ({ 13 }) its ({ 14 }) neighboring ({ 15 }) frames ({ 16 }) ranging ({ 17 }) from ({ 18 }) \MATH ({ 19 }) . ({ 20 }) 
# Sentence pair (1398) source length 11 target length 10 alignment score : 0.00600616
In other words , we compute \MATH where \MATH . 
NULL ({ }) In ({ 1 }) other ({ 2 }) words ({ 3 }) , ({ 4 }) we ({ 5 }) compute ({ 6 }) \MATH ({ 7 }) , ({ }) where ({ 8 }) \MATH ({ 9 }) . ({ 10 }) 
# Sentence pair (1399) source length 15 target length 15 alignment score : 0.00501938
These values \MATH are then used to form the feature vector for frame \MATH . 
NULL ({ }) These ({ 1 }) values ({ 2 }) \MATH ({ 3 }) are ({ 4 }) then ({ 5 }) used ({ 6 }) to ({ 7 }) form ({ 8 }) the ({ 9 }) feature ({ 10 }) vector ({ 11 }) for ({ 12 }) frame ({ 13 }) \MATH ({ 14 }) . ({ 15 }) 
# Sentence pair (1400) source length 20 target length 21 alignment score : 9.96103e-08
The Support Vector Machines ( SVM ) is a statistical learning method based on the structure risk minimization principle \CITE . 
NULL ({ }) Support ({ 1 2 }) Vector ({ 3 }) Machines ({ 4 }) ( ({ 5 }) SVM ({ 6 }) ) ({ 7 }) are ({ 8 }) a ({ 9 }) statistical ({ 10 }) learning ({ 11 }) method ({ 12 }) based ({ 13 }) on ({ 14 }) the ({ 15 }) structure ({ 16 }) risk ({ 17 }) minimization ({ 18 }) principle ({ 19 }) \CITE ({ 20 }) . ({ 21 }) 
# Sentence pair (1401) source length 16 target length 13 alignment score : 2.04982e-08
It has been very efficiently proved in many pattern recognition applications \CITE . 
NULL ({ }) They ({ 1 }) have ({ 2 }) been ({ 3 }) very ({ 4 }) efficiently ({ 5 }) proved ({ 6 }) to ({ }) be ({ }) useful ({ }) in ({ 7 }) many ({ 8 }) pattern ({ 9 }) recognition ({ 10 }) applications ({ 11 }) \CITE ({ 12 }) . ({ 13 }) 
# Sentence pair (1402) source length 24 target length 23 alignment score : 1.1995e-11
In the binary classification case , the objective of the SVM is to find a best separating hyperplane with a maximum margin . 
NULL ({ 15 }) In ({ 1 }) the ({ 2 }) case ({ 5 }) of ({ }) binary ({ 3 }) classification ({ 4 }) , ({ 6 }) the ({ 7 }) objective ({ 8 }) of ({ 9 }) the ({ 10 }) SVM ({ 11 }) is ({ 12 }) to ({ 13 }) find ({ 14 }) the ({ }) best ({ 16 }) separating ({ 17 }) hyperplane ({ 18 }) with ({ 19 }) a ({ 20 }) maximum ({ 21 }) margin ({ 22 }) . ({ 23 }) 
# Sentence pair (1403) source length 9 target length 8 alignment score : 0.0133979
The form of SVM classifiers is : \MATH 
NULL ({ }) The ({ 1 }) form ({ 2 }) of ({ 3 }) the ({ }) SVM ({ 4 }) classifiers ({ 5 }) is ({ 6 }) : ({ 7 }) \MATH ({ 8 }) 
# Sentence pair (1404) source length 50 target length 50 alignment score : 5.23719e-11
where \MATH is the d-dimensional vector of an observation example , \MATH is a class label , \MATH is the vector of the \MATH training example , \MATH is the number of training examples , and \MATH is a kernel function , \MATH is learned through the learning process . 
NULL ({ }) where ({ 1 }) \MATH ({ 2 }) is ({ 3 }) the ({ 4 }) d-dimensional ({ 5 }) vector ({ 6 }) of ({ 7 }) an ({ 8 }) observation ({ 9 }) example ({ 10 }) , ({ 11 }) \MATH ({ 12 }) is ({ 13 }) the ({ 14 }) class ({ 15 }) label ({ 16 }) , ({ 17 }) \MATH ({ 18 }) is ({ 19 }) the ({ 20 }) vector ({ 21 }) of ({ 22 }) the ({ 23 }) \MATH ({ 24 }) training ({ 25 }) example ({ 26 }) , ({ 27 }) \MATH ({ 28 }) is ({ 29 }) the ({ 30 }) number ({ 31 }) of ({ 32 }) training ({ 33 }) examples ({ 34 }) , ({ 35 }) and ({ 36 }) \MATH ({ 37 }) is ({ 38 }) a ({ 39 }) kernel ({ 40 }) function ({ 41 }) , ({ 42 }) \MATH ({ 43 }) is ({ 44 }) learned ({ 45 }) through ({ 46 }) the ({ 47 }) learning ({ 48 }) process ({ 49 }) . ({ 50 }) 
# Sentence pair (1405) source length 8 target length 8 alignment score : 0.0481925
SVM were originally designed for binary classification . 
NULL ({ }) SVMs ({ 1 }) were ({ 2 }) originally ({ 3 }) designed ({ 4 }) for ({ 5 }) binary ({ 6 }) classification ({ 7 }) . ({ 8 }) 
# Sentence pair (1406) source length 10 target length 14 alignment score : 1.14998e-21
To handle the case of multi-class classification , there are two common approaches . 
NULL ({ 3 8 }) There ({ 1 }) are ({ 10 }) two ({ 11 }) common ({ 12 }) approaches ({ 13 }) for ({ 5 }) handling ({ 2 }) multi-class ({ 4 6 9 }) classification ({ 7 }) . ({ 14 }) 
# Sentence pair (1407) source length 21 target length 20 alignment score : 0.000103939
The first one is the one-against-all method that combines \MATH binary classifiers where \MATH is the number of classes . 
NULL ({ }) The ({ 1 }) first ({ 2 }) one ({ 3 }) is ({ 4 }) the ({ 5 }) one-against-all ({ 6 }) method ({ 7 }) that ({ 8 }) combines ({ 9 }) \MATH ({ 10 }) binary ({ 11 }) classifiers ({ 12 }) , ({ }) where ({ 13 }) \MATH ({ 14 }) is ({ 15 }) the ({ 16 }) number ({ 17 }) of ({ 18 }) classes ({ 19 }) . ({ 20 }) 
# Sentence pair (1408) source length 26 target length 25 alignment score : 1.9054e-11
The \MATH SVM classifier is trained by positive samples being examples of the \MATH class and negative samples being examples of the other classes . 
NULL ({ }) The ({ 1 }) \MATH ({ 2 }) SVM ({ 3 }) classifier ({ 4 }) is ({ 5 }) trained ({ 6 }) using ({ 7 }) positive ({ 8 }) samples ({ 9 }) as ({ 10 }) examples ({ 11 }) of ({ 12 }) the ({ 13 }) \MATH ({ 14 }) class ({ 15 }) and ({ 16 }) negative ({ 17 }) samples ({ 18 }) as ({ 19 }) the ({ }) examples ({ 20 }) of ({ 21 }) the ({ 22 }) other ({ 23 }) classes ({ 24 }) . ({ 25 }) 
# Sentence pair (1409) source length 25 target length 24 alignment score : 1.40904e-06
The second one is the one-against-one method that combines \MATH binary classifiers in which each classifier is trained on examples of two classes . 
NULL ({ }) The ({ 1 }) second ({ 2 }) one ({ 3 }) is ({ 4 }) the ({ 5 }) one-against-one ({ 6 }) method ({ 7 }) that ({ 8 }) combines ({ 9 }) \MATH ({ 10 }) binary ({ 11 }) classifiers ({ 12 }) in ({ 13 }) which ({ 14 }) each ({ 15 }) classifier ({ 16 }) is ({ 17 }) trained ({ 18 }) on ({ 19 }) examples ({ 20 }) from ({ 21 }) the ({ }) two ({ 22 }) classes ({ 23 }) . ({ 24 }) 
# Sentence pair (1410) source length 32 target length 32 alignment score : 1.16465e-05
There are seven classes in our framework : NORM FRM ( frame of a normal shot ) , PRE CUT ( pre-frame of a CUT transition ) , POST CUT ( postframe 
NULL ({ }) There ({ 1 }) are ({ 2 }) seven ({ 3 }) classes ({ 4 }) in ({ 5 }) our ({ 6 }) framework ({ 7 }) : ({ 8 }) NORM ({ 9 }) FRM ({ 10 }) ( ({ 11 }) frame ({ 12 }) of ({ 13 }) a ({ 14 }) normal ({ 15 }) shot ({ 16 }) ) ({ 17 }) , ({ 18 }) PRE ({ 19 }) CUT ({ 20 }) ( ({ 21 }) pre-frame ({ 22 }) of ({ 23 }) a ({ 24 }) CUT ({ 25 }) transition ({ 26 }) ) ({ 27 }) , ({ 28 }) POST ({ 29 }) CUT ({ 30 }) ( ({ 31 }) postframe ({ 32 }) 
# Sentence pair (1411) source length 50 target length 49 alignment score : 3.3538e-10
of a CUT transition ) , PRE GRAD ( pre-frame of a GRADUAL transition ) , IN GRAD ( frame inside a GRADUALtransition ) , POST GRAD ( post-frame of a GRADUAL transition ) and NORM-FRM ( normal frame which does not belong to any shot transitions ) . 
NULL ({ }) of ({ 1 }) a ({ 2 }) CUT ({ 3 }) transition ({ 4 }) ) ({ 5 }) , ({ 6 }) PRE ({ 7 }) GRAD ({ 8 }) ( ({ 9 }) pre-frame ({ 10 }) of ({ 11 }) a ({ 12 }) GRADUAL ({ 13 }) transition ({ 14 }) ) ({ 15 }) , ({ 16 }) IN ({ 17 }) GRAD ({ 18 }) ( ({ 19 }) frame ({ 20 }) inside ({ 21 }) a ({ 22 }) GRADUALtransition ({ 23 }) ) ({ 24 }) , ({ 25 }) POST ({ 26 }) GRAD ({ 27 }) ( ({ 28 }) post-frame ({ 29 }) of ({ 30 }) a ({ 31 }) GRADUAL ({ 32 }) transition ({ 33 }) ) ({ 34 }) , ({ }) and ({ 35 }) NORM-FRM ({ 36 }) ( ({ 37 }) normal ({ 38 }) frame ({ 39 }) that ({ 40 }) does ({ 41 }) not ({ 42 }) belong ({ 43 }) to ({ 44 }) any ({ 45 }) shot ({ 46 }) transitions ({ 47 }) ) ({ 48 }) . ({ 49 }) 
# Sentence pair (1412) source length 26 target length 14 alignment score : 1.21748e-16
To learn this classifier , we manually annotate frames in the training data . 
NULL ({ }) To ({ 1 }) train ({ }) this ({ 3 }) classifier ({ 4 }) , ({ 5 }) we ({ 6 }) manually ({ 7 }) annotated ({ }) frames ({ 9 }) in ({ 10 }) the ({ 11 }) training ({ 12 }) data ({ 13 }) . ({ }) //learn ({ 14 }) / ({ }) learn ({ 2 }) about? ({ }) / ({ }) find? ({ }) / ({ }) educate? ({ 8 }) / ({ }) develop? ({ }) / ({ }) train? ({ }) 
# Sentence pair (1413) source length 18 target length 17 alignment score : 0.000389996
Using the trained classifier , we can label a sequence of frames with tags mentioned above . 
NULL ({ }) Using ({ 1 }) the ({ 2 }) trained ({ 3 }) classifier ({ 4 }) , ({ 5 }) we ({ 6 }) can ({ 7 }) label ({ 8 }) a ({ 9 }) sequence ({ 10 }) of ({ 11 }) frames ({ 12 }) with ({ 13 }) the ({ }) tags ({ 14 }) mentioned ({ 15 }) above ({ 16 }) . ({ 17 }) 
# Sentence pair (1414) source length 63 target length 64 alignment score : 1.8925e-18
A gradual transition usually has the pattern " ` . . . , PRE-GRAD , IN-GRAD , IN-GRAD , . . . , IN-GRAD , POS-GRAD , . . . " ' and a cut transition usually has the pattern " ` . . . , PRE-CUT , IN-CUT , . . . , IN-CUT , POST-CUT , . . . " ' . 
NULL ({ 6 39 }) A ({ 1 }) gradual ({ 2 }) transition ({ 3 }) usually ({ 4 }) has ({ 5 }) a ({ }) " ({ 8 }) ` ({ 9 }) . ({ 10 }) . ({ 11 }) . ({ 12 }) , ({ 13 }) PRE-GRAD ({ 14 }) , ({ 15 }) IN-GRAD ({ 16 }) , ({ 17 }) IN-GRAD ({ 18 }) , ({ 19 }) . ({ 20 }) . ({ 21 }) . ({ 22 }) , ({ 23 }) IN-GRAD ({ 24 }) , ({ 25 }) POS-GRAD ({ 26 }) , ({ 27 }) . ({ 28 }) . ({ 29 }) . ({ 30 }) " ({ 31 }) ' ({ 32 }) pattern ({ 7 40 }) and ({ 33 }) a ({ 34 }) cut ({ 35 }) transition ({ 36 }) usually ({ 37 }) has ({ 38 }) a ({ }) " ({ 41 }) ` ({ 42 }) . ({ 43 }) . ({ 44 }) . ({ 45 }) , ({ 46 }) PRE-CUT ({ 47 }) , ({ 48 }) IN-CUT ({ 49 }) , ({ 50 }) . ({ 51 }) . ({ 52 }) . ({ 53 }) , ({ 54 }) IN-CUT ({ 55 }) , ({ 56 }) POST-CUT ({ 57 }) , ({ 58 }) . ({ 59 }) . ({ 60 }) . ({ 61 }) " ({ 62 }) 'pattern ({ 63 }) . ({ 64 }) 
# Sentence pair (1415) source length 18 target length 17 alignment score : 0.00011023
The shot boundary detection process is started by checking these transition patterns in the tagged sequence . 
NULL ({ }) The ({ 1 }) shot ({ 2 }) boundary ({ 3 }) detection ({ 4 }) process ({ 5 }) is ({ 6 }) started ({ 7 }) by ({ 8 }) checking ({ 9 }) for ({ }) these ({ 10 }) transition ({ 11 }) patterns ({ 12 }) in ({ 13 }) the ({ 14 }) tagged ({ 15 }) sequence ({ 16 }) . ({ 17 }) 
# Sentence pair (1416) source length 26 target length 26 alignment score : 3.37749e-05
Once a pattern is encountered , PRE-xxx and POST-xxx tags are used to identify the shot boundary and the two ends of the shot transition . 
NULL ({ }) Once ({ 1 }) a ({ 2 }) pattern ({ 3 }) is ({ 4 }) encountered ({ 5 }) , ({ 6 }) PRE-xxx ({ 7 }) and ({ 8 }) POST-xxx ({ 9 }) tags ({ 10 }) are ({ 11 }) used ({ 12 }) to ({ 13 }) identify ({ 14 }) the ({ 15 }) shot ({ 16 }) boundary ({ 17 }) and ({ 18 }) the ({ 19 }) two ({ 20 }) ends ({ 21 }) of ({ 22 }) the ({ 23 }) shot ({ 24 }) transition ({ 25 }) . ({ 26 }) 
# Sentence pair (1417) source length 44 target length 40 alignment score : 1.01412e-11
Since the classifier occasionally produce false predictions due to variations caused by photo flashes , rapid camera movement and object movement , only using the perfect match between the predefined patterns and sub-sequences usually skips many truth shot boundaries . 
NULL ({ }) Since ({ 1 }) the ({ 2 }) classifier ({ 3 }) occasionally ({ 4 }) produces ({ 5 }) false ({ 6 }) predictions ({ 7 }) due ({ 8 }) to ({ 9 }) the ({ }) variations ({ 10 }) caused ({ 11 }) by ({ 12 }) photo ({ 13 }) flashes ({ 14 }) , ({ 15 }) rapid ({ 16 }) camera ({ 17 }) movement ({ 18 }) , ({ }) and ({ 19 }) object ({ 20 }) movement ({ 21 }) , ({ 22 }) only ({ 23 }) using ({ 24 }) the ({ 25 }) perfect ({ 26 }) match ({ 27 }) between ({ 28 }) the ({ 29 }) predefined ({ 30 }) patterns ({ 31 }) and ({ 32 }) sub-sequences ({ 33 }) usually ({ 34 }) skips ({ 35 }) many ({ 36 }) of ({ }) the ({ }) true ({ 37 }) shot ({ 38 }) boundaries ({ 39 }) . ({ 40 }) 
# Sentence pair (1418) source length 29 target length 29 alignment score : 2.26822e-05
Instead , we use a more flexible matching algorithm in which a match is declared if a portion of the predefined pattern is found in the input sub-sequence . 
NULL ({ }) Instead ({ 1 }) , ({ 2 }) we ({ 3 }) use ({ 4 }) a ({ 5 }) more ({ 6 }) flexible ({ 7 }) matching ({ 8 }) algorithm ({ 9 }) in ({ 10 }) which ({ 11 }) a ({ 12 }) match ({ 13 }) is ({ 14 }) declared ({ 15 }) if ({ 16 }) a ({ 17 }) portion ({ 18 }) of ({ 19 }) the ({ 20 }) predefined ({ 21 }) pattern ({ 22 }) is ({ 23 }) found ({ 24 }) in ({ 25 }) the ({ 26 }) input ({ 27 }) sub-sequence ({ 28 }) . ({ 29 }) 
# Sentence pair (1419) source length 17 target length 15 alignment score : 0.000361931
We used annotated data sets from TRECVID 2003 test sets for training and testing . 
NULL ({ }) We ({ 1 }) used ({ 2 }) annotated ({ 3 }) data ({ 4 }) sets ({ 5 }) from ({ 6 }) the ({ }) TRECVID ({ 7 }) 2003 ({ 8 }) test ({ 9 }) sets ({ 10 }) for ({ 11 }) the ({ }) training ({ 12 }) and ({ 13 }) testing ({ 14 }) . ({ 15 }) 
# Sentence pair (1420) source length 21 target length 19 alignment score : 1.57518e-08
We divided 8 videos , each 30-minute length , into two sets : training set and testing set . 
NULL ({ }) We ({ 1 }) divided ({ 2 }) eight ({ 3 }) videos ({ 4 }) , ({ 5 }) each ({ 6 }) 30-minute ({ 7 }) long ({ 8 }) , ({ 9 }) into ({ 10 }) two ({ 11 }) sets ({ 12 }) : ({ 13 }) a ({ }) training ({ 14 }) set ({ 15 }) and ({ 16 }) a ({ }) test ({ 17 }) set ({ 18 }) . ({ 19 }) 
# Sentence pair (1421) source length 23 target length 21 alignment score : 2.57793e-05
The number of frames , the number of shot boundaries and types of these sets are shown in Table \REF . 
NULL ({ }) The ({ 1 }) number ({ 2 }) of ({ 3 }) frames ({ 4 }) , ({ 5 }) the ({ 6 }) number ({ 7 }) of ({ 8 }) shot ({ 9 }) boundaries ({ 10 }) , ({ }) and ({ 11 }) the ({ }) types ({ 12 }) of ({ 13 }) these ({ 14 }) sets ({ 15 }) are ({ 16 }) shown ({ 17 }) in ({ 18 }) Table ({ 19 }) \REF ({ 20 }) . ({ 21 }) 
# Sentence pair (1422) source length 46 target length 43 alignment score : 2.35278e-11
Note that , the number of shot boundaries is equal to the number of frames with PRE-CUT / GRAD label and the number of frames with PRE-CUT / GRAD label is equal to the number of frames with POST-CUT / GRAD label . 
NULL ({ }) Note ({ 1 }) that ({ 2 }) , ({ 3 }) the ({ 4 }) number ({ 5 }) of ({ 6 }) shot ({ 7 }) boundaries ({ 8 }) is ({ 9 }) equal ({ 10 }) to ({ 11 }) the ({ 12 }) number ({ 13 }) of ({ 14 }) frames ({ 15 }) with ({ 16 }) a ({ }) PRE-CUT ({ 17 }) / ({ 18 }) GRAD ({ 19 }) label ({ 20 }) and ({ 21 }) the ({ 22 }) number ({ 23 }) of ({ 24 }) frames ({ 25 }) with ({ 26 }) a ({ }) PRE-CUT ({ 27 }) / ({ 28 }) GRAD ({ 29 }) label ({ 30 }) is ({ 31 }) equal ({ 32 }) to ({ 33 }) the ({ 34 }) number ({ 35 }) of ({ 36 }) frames ({ 37 }) within ({ 38 }) a ({ }) POST-CUT ({ 39 }) / ({ 40 }) GRAD ({ 41 }) label ({ 42 }) . ({ 43 }) 
# Sentence pair (1423) source length 12 target length 12 alignment score : 7.73906e-05
We used \MATH grid for dividing the input image into sub-images . 
NULL ({ }) We ({ 1 }) used ({ 2 }) \MATH ({ 3 }) grid ({ 4 }) to ({ 5 }) divide ({ 6 }) the ({ 7 }) input ({ 8 }) image ({ 9 }) into ({ 10 }) sub-images ({ 11 }) . ({ 12 }) 
# Sentence pair (1424) source length 22 target length 19 alignment score : 1.22323e-05
As for edge orientation histogram , we used 12-bins for edge pixels and one bin for non-edge pixels . 
NULL ({ }) As ({ 1 }) for ({ 2 }) the ({ }) edge ({ 3 }) orientation ({ 4 }) histogram ({ 5 }) , ({ 6 }) we ({ 7 }) used ({ 8 }) 12-bins ({ 9 }) for ({ 10 }) the ({ }) edge ({ 11 }) pixels ({ 12 }) and ({ 13 }) one ({ 14 }) bin ({ 15 }) for ({ 16 }) the ({ }) non-edge ({ 17 }) pixels ({ 18 }) . ({ 19 }) 
# Sentence pair (1425) source length 21 target length 21 alignment score : 0.00029523
Furthermore , we used 20 neighbor frames before and after the current frame ( \MATH ) for computing the distances . 
NULL ({ }) Furthermore ({ 1 }) , ({ 2 }) we ({ 3 }) used ({ 4 }) 20 ({ 5 }) neighboring ({ 6 }) frames ({ 7 }) before ({ 8 }) and ({ 9 }) after ({ 10 }) the ({ 11 }) current ({ 12 }) frame ({ 13 }) ( ({ 14 }) \MATH ({ 15 }) ) ({ 16 }) for ({ 17 }) computing ({ 18 }) the ({ 19 }) distances ({ 20 }) . ({ 21 }) 
# Sentence pair (1426) source length 15 target length 14 alignment score : 0.000263841
These parameters were selected from our empirical studies when participating TRECVID 's tasks . 
NULL ({ }) These ({ 1 }) parameters ({ 2 }) were ({ 3 }) selected ({ 4 }) from ({ 5 }) our ({ 6 }) empirical ({ 7 }) studies ({ 8 }) when ({ 9 }) participating ({ 10 }) in ({ }) TRECVID ({ 11 }) 's ({ 12 }) tasks ({ 13 }) . ({ 14 }) 
# Sentence pair (1427) source length 21 target length 20 alignment score : 0.000152976
The extracted features are normalized to zero mean and unit standard deviation and then stored for training and testing . 
NULL ({ }) The ({ 1 }) extracted ({ 2 }) features ({ 3 }) are ({ 4 }) normalized ({ 5 }) to ({ 6 }) zero ({ 7 }) mean ({ 8 }) and ({ 9 }) a ({ }) unit ({ 10 }) standard ({ 11 }) deviation ({ 12 }) and ({ 13 }) then ({ 14 }) stored ({ 15 }) for ({ 16 }) training ({ 17 }) and ({ 18 }) testing ({ 19 }) . ({ 20 }) 
# Sentence pair (1428) source length 6 target length 6 alignment score : 0.134367
Specifically , the normalized vector \MATH 
NULL ({ }) Specifically ({ 1 }) , ({ 2 }) the ({ 3 }) normalized ({ 4 }) vector ({ 5 }) \MATH ({ 6 }) 
# Sentence pair (1429) source length 22 target length 20 alignment score : 5.89301e-06
where \MATH is the \MATH-th element of the feature vectors \MATH respectively , \MATH is the number of dimensions . 
NULL ({ }) where ({ 1 }) \MATH ({ 2 }) is ({ 3 }) the ({ 4 }) \MATH-th ({ 5 }) element ({ 6 }) of ({ 7 }) the ({ 8 }) feature ({ 9 }) vectors ({ 10 }) \MATH ({ 11 }) , ({ }) respectively ({ 12 }) , ({ 13 }) and ({ }) \MATH ({ 14 }) is ({ 15 }) the ({ 16 }) number ({ 17 }) of ({ 18 }) dimensions ({ 19 }) . ({ 20 }) 
# Sentence pair (1430) source length 43 target length 42 alignment score : 8.18841e-08
In order to handle the problem of imbalanced training sets where the number of NORM-FRM frames is much larger than other frames , we randomly take \MATH of NORM-FRM frames and 100\% of the other frames to form the training set . 
NULL ({ }) In ({ 1 }) order ({ 2 }) to ({ 3 }) handle ({ 4 }) the ({ 5 }) problem ({ 6 }) of ({ 7 }) imbalanced ({ 8 }) training ({ 9 }) sets ({ 10 }) where ({ 11 }) the ({ 12 }) number ({ 13 }) of ({ 14 }) NORM-FRM ({ 15 }) frames ({ 16 }) is ({ 17 }) much ({ 18 }) larger ({ 19 }) than ({ 20 }) other ({ 21 }) frames ({ 22 }) , ({ 23 }) we ({ 24 }) randomly ({ 25 }) take ({ 26 }) the ({ }) \MATH ({ 27 }) of ({ 28 }) NORM-FRM ({ 29 }) frames ({ 30 }) and ({ 31 }) 100\% ({ 32 }) of ({ 33 }) the ({ 34 }) other ({ 35 }) frames ({ 36 }) to ({ 37 }) form ({ 38 }) the ({ 39 }) training ({ 40 }) set ({ 41 }) . ({ 42 }) 
# Sentence pair (1431) source length 14 target length 12 alignment score : 0.000468856
We use LibSVM \CITE to train SVM classifiers with RBF kernel . 
NULL ({ }) We ({ 1 }) use ({ 2 }) LibSVM ({ 3 }) \CITE ({ 4 }) to ({ 5 }) train ({ 6 }) the ({ }) SVM ({ 7 }) classifiers ({ 8 }) with ({ 9 }) a ({ }) RBF ({ 10 }) kernel ({ 11 }) . ({ 12 }) 
# Sentence pair (1432) source length 30 target length 28 alignment score : 7.82229e-07
The optimal \MATH parameters are found by conducting a grid search with 5-fold cross validation on a subset 10 ,000 samples stratified selected from the original dataset . 
NULL ({ }) The ({ 1 }) optimal ({ 2 }) \MATH ({ 3 }) parameters ({ 4 }) are ({ 5 }) found ({ 6 }) by ({ 7 }) conducting ({ 8 }) a ({ 9 }) grid ({ 10 }) search ({ 11 }) with ({ 12 }) a ({ }) 5-fold ({ 13 }) cross ({ 14 }) validation ({ 15 }) on ({ 16 }) a ({ 17 }) subset ({ 18 }) of ({ }) 10 ({ 19 }) ,000 ({ 20 }) samples ({ 21 }) stratified ({ 22 }) selected ({ 23 }) from ({ 24 }) the ({ 25 }) original ({ 26 }) dataset ({ 27 }) . ({ 28 }) 
# Sentence pair (1433) source length 12 target length 11 alignment score : 0.00140927
As for multi-class classification , LibSVM used the one-against-one approach . 
NULL ({ }) As ({ 1 }) for ({ 2 }) the ({ }) multi-class ({ 3 }) classification ({ 4 }) , ({ 5 }) LibSVM ({ 6 }) used ({ 7 }) the ({ 8 }) one-against-one ({ 9 }) approach ({ 10 }) . ({ 11 }) 
# Sentence pair (1434) source length 48 target length 43 alignment score : 1.55889e-12
The results that were evaluated by a tool provided by TRECVID with standard measurement such as precision , recall and F1 score clearly show that our proposed method significantly outperforms the baseline method and the combination of GCM+EOH obtains the best result . 
NULL ({ }) The ({ 1 }) results ({ 2 }) that ({ 3 }) were ({ 4 }) evaluated ({ 5 }) by ({ 6 }) a ({ 7 }) tool ({ 8 }) provided ({ 9 }) by ({ 10 }) TRECVID ({ 11 }) with ({ 12 }) a ({ }) standard ({ 13 }) measurements ({ 14 }) , ({ }) such ({ 15 }) as ({ 16 }) the ({ }) precision ({ 17 }) , ({ 18 }) recall ({ 19 }) , ({ }) and ({ 20 }) F1 ({ 21 }) score ({ 22 }) , ({ }) clearly ({ 23 }) show ({ 24 }) that ({ 25 }) our ({ 26 }) proposed ({ 27 }) method ({ 28 }) significantly ({ 29 }) outperforms ({ 30 }) the ({ 31 }) baseline ({ 32 }) method ({ 33 }) and ({ 34 }) the ({ 35 }) combination ({ 36 }) of ({ 37 }) GCM+EOH ({ 38 }) obtains ({ 39 }) the ({ 40 }) best ({ 41 }) result ({ 42 }) . ({ 43 }) 
# Sentence pair (1435) source length 26 target length 23 alignment score : 3.43315e-07
We evaluated the performance of our system with different choices for taking the number of NORM -FRM frames used in training process . 
NULL ({ }) We ({ 1 }) evaluated ({ 2 }) the ({ 3 }) performance ({ 4 }) of ({ 5 }) our ({ 6 }) system ({ 7 }) with ({ 8 }) different ({ 9 }) choices ({ 10 }) for ({ 11 }) taking ({ 12 }) the ({ 13 }) number ({ 14 }) of ({ 15 }) NORM ({ 16 }) -FRM ({ 17 }) frames ({ 18 }) used ({ 19 }) in ({ 20 }) training ({ 21 }) process ({ 22 }) . ({ 23 }) //for ({ }) / ({ }) by? ({ }) 
# Sentence pair (1436) source length 15 target length 14 alignment score : 0.000397201
Specifically , we selected three sampling rates \MATH which are \MATH and \MATH . 
NULL ({ }) Specifically ({ 1 }) , ({ 2 }) we ({ 3 }) selected ({ 4 }) three ({ 5 }) sampling ({ 6 }) rates ({ 7 }) \MATH ({ 8 }) , ({ }) which ({ 9 }) were ({ 10 }) \MATH ({ 11 }) and ({ 12 }) \MATH ({ 13 }) . ({ 14 }) 
# Sentence pair (1437) source length 18 target length 18 alignment score : 3.3915e-07
As shown in Figure \REF , the best performance is obtained with the sampling rate of \MATH . 
NULL ({ }) As ({ 1 }) shown ({ 2 }) in ({ 3 }) Figure ({ 4 }) \REF ({ 5 }) , ({ 6 }) the ({ 7 }) best ({ 8 }) performance ({ 9 }) was ({ 10 }) obtained ({ 11 }) at ({ 12 }) a ({ 13 }) sampling ({ 14 }) rate ({ 15 }) of ({ 16 }) \MATH ({ 17 }) . ({ 18 }) 
# Sentence pair (1438) source length 29 target length 25 alignment score : 1.52236e-17
In Table \REF we show the evaluation of using different features for forming the feature vector using distances between current frames and its neighbors . 
NULL ({ 8 }) In ({ 1 }) Table ({ 2 }) \REF ({ 3 }) , ({ }) we ({ 4 }) list ({ 5 }) the ({ 6 }) evaluation ({ 7 }) results ({ }) when ({ }) using ({ 9 }) different ({ 10 }) features ({ 11 }) to ({ 12 }) form ({ 13 }) the ({ 14 }) feature ({ 15 }) vector ({ 16 }) using ({ 17 }) the ({ }) distances ({ 18 }) between ({ 19 }) the ({ }) current ({ 20 }) frames ({ 21 }) and ({ 22 }) their ({ 23 }) neighbors ({ 24 }) . ({ 25 }) 
# Sentence pair (1439) source length 31 target length 27 alignment score : 1.27735e-08
The first one is GCM , the second one is EOH and the last one GCM+EOH is combination of distances using GCM and distances using EOH . 
NULL ({ }) The ({ 1 }) first ({ 2 }) one ({ 3 }) is ({ 4 }) GCM ({ 5 }) , ({ 6 }) the ({ 7 }) second ({ 8 }) one ({ 9 }) is ({ 10 }) EOH ({ 11 }) , ({ }) and ({ 12 }) the ({ 13 }) last ({ 14 }) one ({ 15 }) GCM+EOH ({ 16 }) is ({ 17 }) a ({ }) combination ({ 18 }) of ({ 19 }) the ({ }) distances ({ 20 }) using ({ 21 }) GCM ({ 22 }) and ({ 23 }) the ({ }) distances ({ 24 }) using ({ 25 }) EOH ({ 26 }) . ({ 27 }) 
# Sentence pair (1440) source length 25 target length 23 alignment score : 9.38586e-07
The number of dimensions of feature vectors using GCM and EOH is 20 while that of feature vectors using GCM+EOH is 40 . 
NULL ({ }) The ({ 1 }) number ({ 2 }) of ({ 3 }) dimensions ({ 4 }) of ({ 5 }) the ({ }) feature ({ 6 }) vectors ({ 7 }) using ({ 8 }) GCM ({ 9 }) and ({ 10 }) EOH ({ 11 }) was ({ 12 }) 20 ({ 13 }) , ({ }) while ({ 14 }) that ({ 15 }) of ({ 16 }) feature ({ 17 }) vectors ({ 18 }) using ({ 19 }) GCM+EOH ({ 20 }) was ({ 21 }) 40 ({ 22 }) . ({ 23 }) 
# Sentence pair (1441) source length 35 target length 32 alignment score : 1.52442e-12
We also compare the proposed method with the baseline method that computes differences in color histograms between two consecutive frames and then decides a shot transitition by using a predefined threshold . 
NULL ({ 24 }) We ({ 1 }) also ({ 2 }) compared ({ 3 }) the ({ 4 }) proposed ({ 5 }) method ({ 6 }) with ({ 7 }) the ({ 8 }) baseline ({ 9 }) method ({ 10 }) that ({ 11 }) computes ({ 12 }) the ({ }) differences ({ 13 }) in ({ 14 }) the ({ }) color ({ 15 }) histograms ({ 16 }) between ({ 17 }) two ({ 18 }) consecutive ({ 19 }) frames ({ 20 }) , ({ }) and ({ 21 }) then ({ 22 }) decides ({ 23 }) the ({ }) shot ({ 25 }) transition ({ 26 }) by ({ 27 }) using ({ 28 }) a ({ 29 }) predefined ({ 30 }) threshold ({ 31 }) . ({ 32 }) 
# Sentence pair (1442) source length 22 target length 22 alignment score : 0.000448812
In Figure \REF , we superimpose our result on the results reported in the shot boundary detection task of TRECVID 2003 . 
NULL ({ }) In ({ 1 }) Figure ({ 2 }) \REF ({ 3 }) , ({ 4 }) we ({ 5 }) superimposed ({ 6 }) our ({ 7 }) result ({ 8 }) on ({ 9 }) the ({ 10 }) results ({ 11 }) reported ({ 12 }) in ({ 13 }) the ({ 14 }) shot ({ 15 }) boundary ({ 16 }) detection ({ 17 }) task ({ 18 }) of ({ 19 }) TRECVID ({ 20 }) 2003 ({ 21 }) . ({ 22 }) 
# Sentence pair (1443) source length 22 target length 21 alignment score : 8.69454e-09
Our system achieves high precision and recall for the CUT transition and the result is comparable with the third-ranked system . 
NULL ({ }) Our ({ 1 }) system ({ 2 }) achieves ({ 3 }) a ({ }) high ({ 4 }) precision ({ 5 }) and ({ 6 }) recall ({ 7 }) for ({ 8 }) the ({ 9 }) CUT ({ 10 }) transition ({ 11 }) and ({ 12 }) this ({ 13 }) result ({ 14 }) is ({ 15 }) comparable ({ 16 }) to ({ 17 }) the ({ 18 }) third-ranked ({ 19 }) system ({ 20 }) . ({ 21 }) 
# Sentence pair (1444) source length 16 target length 16 alignment score : 0.000224332
Note that our system is general and has no special treatment for particular shot transition . 
NULL ({ }) Note ({ 1 }) that ({ 2 }) our ({ 3 }) system ({ 4 }) is ({ 5 }) general ({ 6 }) and ({ 7 }) has ({ 8 }) no ({ 9 }) special ({ 10 }) treatment ({ 11 }) for ({ 12 }) particular ({ 13 }) shot ({ 14 }) transitions ({ 15 }) . ({ 16 }) 
# Sentence pair (1445) source length 25 target length 25 alignment score : 5.01566e-08
Many previous shot boundary detectors usually divided the system into sub-systems in which special treatments were proposed to handle different types of shot transitions . 
NULL ({ }) Many ({ 1 }) previous ({ 2 }) shot ({ 3 }) boundary ({ 4 }) detectors ({ 5 }) usually ({ 6 }) divide ({ 7 }) the ({ 8 }) system ({ 9 }) into ({ 10 }) sub-systems ({ 11 }) in ({ 12 }) which ({ 13 }) special ({ 14 }) treatments ({ 15 }) are ({ 16 }) proposed ({ 17 }) to ({ 18 }) handle ({ 19 }) different ({ 20 }) types ({ 21 }) of ({ 22 }) shot ({ 23 }) transitions ({ 24 }) . ({ 25 }) 
# Sentence pair (1446) source length 12 target length 12 alignment score : 2.65549e-07
Therefore , it is difficult to generalize for new test sets . 
NULL ({ 6 }) Therefore ({ 1 }) , ({ 2 }) it ({ 3 }) is ({ 4 }) generalization ({ 5 }) is ({ }) difficult ({ 7 }) for ({ 8 }) new ({ 9 }) test ({ 10 }) sets ({ 11 }) . ({ 12 }) 
# Sentence pair (1447) source length 20 target length 28 alignment score : 9.67908e-27
Different from these approaches , in this paper , we have proposed a unified and general framework for shot boundary detection using a text segmentation based approach . 
NULL ({ 5 6 9 10 }) We ({ }) have ({ 11 }) proposed ({ 12 }) a ({ 13 }) unified ({ 1 2 3 4 7 8 14 }) and ({ 15 }) general ({ 16 }) framework ({ 17 }) for ({ 18 }) shot ({ 19 }) boundary ({ 20 }) detection ({ 21 }) that ({ }) uses ({ 22 }) a ({ 23 }) text ({ 24 }) segmentation ({ 25 }) based ({ 26 }) approach ({ 27 }) . ({ 28 }) 
# Sentence pair (1448) source length 38 target length 35 alignment score : 2.93843e-10
Firstly , we label frames by one of six labels defined for different types of frames : NORM -FRM , PRE -CUT , POST -CUT , PRE -GRAD , IN -GRAD and POST -GRAD . 
NULL ({ }) Firstly ({ 1 }) , ({ 2 }) we ({ 3 }) label ({ 4 }) the ({ }) frames ({ 5 }) with ({ 6 }) one ({ 7 }) of ({ 8 }) the ({ }) six ({ 9 }) labels ({ 10 }) defined ({ 11 }) for ({ 12 }) different ({ 13 }) types ({ 14 }) of ({ 15 }) frames ({ 16 }) : ({ 17 }) NORM ({ 18 }) -FRM ({ 19 }) , ({ 20 }) PRE ({ 21 }) -CUT ({ 22 }) , ({ 23 }) POST ({ 24 }) -CUT ({ 25 }) , ({ 26 }) PRE ({ 27 }) -GRAD ({ 28 }) , ({ 29 }) IN ({ 30 }) -GRAD ({ 31 }) , ({ }) and ({ 32 }) POST ({ 33 }) -GRAD ({ 34 }) . ({ 35 }) 
# Sentence pair (1449) source length 13 target length 12 alignment score : 0.0041736
Then we extract shot boundaries and types from these labeled frames . 
NULL ({ }) Then ({ 1 }) we ({ 2 }) extract ({ 3 }) the ({ }) shot ({ 4 }) boundaries ({ 5 }) and ({ 6 }) types ({ 7 }) from ({ 8 }) these ({ 9 }) labeled ({ 10 }) frames ({ 11 }) . ({ 12 }) 
# Sentence pair (1450) source length 36 target length 33 alignment score : 7.85956e-09
In order to label frames , we proposed a new feature type to model the difference and motion in color and edge between frames and used it in classification with SVM classifiers . 
NULL ({ }) In ({ 1 }) order ({ 2 }) to ({ 3 }) label ({ 4 }) frames ({ 5 }) , ({ 6 }) we ({ 7 }) proposed ({ 8 }) a ({ 9 }) new ({ 10 }) feature ({ 11 }) type ({ 12 }) to ({ 13 }) model ({ 14 }) the ({ 15 }) difference ({ 16 }) and ({ 17 }) motion ({ 18 }) in ({ 19 }) color ({ 20 }) and ({ 21 }) the ({ }) edges ({ 22 }) between ({ 23 }) the ({ }) frames ({ 24 }) and ({ 25 }) used ({ 26 }) it ({ 27 }) in ({ 28 }) the ({ }) classification ({ 29 }) with ({ 30 }) SVM ({ 31 }) classifiers ({ 32 }) . ({ 33 }) 
# Sentence pair (1451) source length 18 target length 15 alignment score : 1.05323e-09
Experiments on various videos of TRECVID 2003 have shown that our approach is effective . 
NULL ({ }) The ({ }) experiments ({ }) we ({ }) conducted ({ 1 }) on ({ 2 }) various ({ 3 }) videos ({ 4 }) from ({ 5 }) TRECVID ({ 6 }) 2003 ({ 7 }) have ({ 8 }) shown ({ 9 }) that ({ 10 }) our ({ 11 }) approach ({ 12 }) is ({ 13 }) effective ({ 14 }) . ({ 15 }) 
# Sentence pair (1452) source length 6 target length 6 alignment score : 0.144771
Ent-Boost : Boosting Using Entropy Measure 
NULL ({ }) Ent-Boost ({ 1 }) : ({ 2 }) Boosting ({ 3 }) Using ({ 4 }) Entropy ({ 5 }) Measures ({ 6 }) 
# Sentence pair (1453) source length 4 target length 4 alignment score : 0.280131
for Robust Object Detection 
NULL ({ }) for ({ 1 }) Robust ({ 2 }) Object ({ 3 }) Detection ({ 4 }) 
# Sentence pair (1454) source length 24 target length 21 alignment score : 5.88265e-08
Recently , boosting is used widely in object detection applications because of its impressive performance in both speed and accuracy . 
NULL ({ }) Recently ({ 1 }) , ({ 2 }) boosting ({ 3 }) has ({ 4 }) come ({ }) to ({ }) be ({ }) used ({ 5 }) widely ({ 6 }) in ({ 7 }) object ({ 8 }) detection ({ 9 }) applications ({ 10 }) because ({ 11 }) of ({ 12 }) its ({ 13 }) impressive ({ 14 }) performance ({ 15 }) in ({ 16 }) both ({ 17 }) speed ({ 18 }) and ({ 19 }) accuracy ({ 20 }) . ({ 21 }) 
# Sentence pair (1455) source length 59 target length 21 alignment score : 5.57398e-45
However , learning weak classifiers which is one of the most significant tasks in using boosting is left for users . 
NULL ({ }) However ({ 1 }) , ({ 2 }) learning ({ 3 }) weak ({ 4 }) classifiers ({ 5 }) , ({ }) which ({ 6 }) is ({ 7 }) one ({ 8 }) of ({ 9 }) the ({ 10 }) most ({ 11 }) significant ({ 12 }) tasks ({ 13 }) in ({ 14 }) using ({ 15 }) boosting ({ 16 }) , ({ }) is ({ 17 }) left ({ 18 }) to ({ 19 }) users ({ 20 }) . ({ 21 }) //learning ({ }) / ({ }) training ({ }) / ({ }) identifying ({ }) / ({ }) finding?<--Here ({ }) and ({ }) throughout ({ }) , ({ }) I ({ }) am ({ }) not ({ }) sure ({ }) that ({ }) " ({ }) learning ({ }) " ({ }) is ({ }) the ({ }) best ({ }) word ({ }) choice ({ }) . ({ }) If ({ }) you ({ }) change ({ }) it ({ }) here ({ }) , ({ }) it ({ }) should ({ }) be ({ }) changed ({ }) throughout ({ }) . ({ }) 
# Sentence pair (1456) source length 21 target length 21 alignment score : 0.00067254
In Discrete AdaBoost , weak classifiers with binary output are too weak to boost when the training data is complex . 
NULL ({ }) In ({ 1 }) Discrete ({ 2 }) AdaBoost ({ 3 }) , ({ 4 }) weak ({ 5 }) classifiers ({ 6 }) with ({ 7 }) binary ({ 8 }) output ({ 9 }) are ({ 10 }) too ({ 11 }) weak ({ 12 }) to ({ 13 }) boost ({ 14 }) when ({ 15 }) the ({ 16 }) training ({ 17 }) data ({ 18 }) is ({ 19 }) complex ({ 20 }) . ({ 21 }) 
# Sentence pair (1457) source length 45 target length 44 alignment score : 1.03491e-10
Meanwhile , determining the appropriate number of bins for weak classifiers learned by Real AdaBoost is a challenging task because small one might not well approximate the real distribution while large one might cause over-fitting , increase computation time and waste storage space . 
NULL ({ }) Meanwhile ({ 1 }) , ({ 2 }) determining ({ 3 }) the ({ 4 }) appropriate ({ 5 }) number ({ 6 }) of ({ 7 }) bins ({ 8 }) for ({ 9 }) weak ({ 10 }) classifiers ({ 11 }) learned ({ 12 }) by ({ 13 }) Real ({ 14 }) AdaBoost ({ 15 }) is ({ 16 }) a ({ 17 }) challenging ({ 18 }) task ({ 19 }) because ({ 20 }) small ({ 21 }) ones ({ 22 }) might ({ 23 }) not ({ 24 }) accurately ({ 25 }) approximate ({ 26 }) the ({ 27 }) real ({ 28 }) distribution ({ 29 }) while ({ 30 }) large ({ 31 }) ones ({ 32 }) might ({ 33 }) cause ({ 34 }) over-fitting ({ 35 }) , ({ 36 }) increase ({ 37 }) computation ({ 38 }) time ({ 39 }) , ({ }) and ({ 40 }) waste ({ 41 }) storage ({ 42 }) space ({ 43 }) . ({ 44 }) 
# Sentence pair (1458) source length 21 target length 18 alignment score : 3.40361e-17
This paper describes a novel method for efficiently learning weak classifiers using entropy measures , called Ent-Boost . 
NULL ({ 15 }) We ({ }) have ({ 2 }) developed ({ 3 }) Ent-Boost ({ }) , ({ }) a ({ 4 }) novel ({ 5 }) method ({ 6 }) for ({ 7 }) efficiently ({ 8 }) learning ({ 9 }) weak ({ 10 }) classifiers ({ 11 }) using ({ 12 }) entropy ({ 13 }) measures ({ 14 }) . ({ 18 }) //method ({ 1 }) / ({ }) boosting ({ 17 }) scheme? ({ 16 }) 
# Sentence pair (1459) source length 16 target length 18 alignment score : 8.094e-14
The class entropy information is used to estimate the optimal number of bins automatically through discretization process . 
NULL ({ }) Class ({ 1 2 }) entropy ({ 3 }) information ({ 4 }) is ({ 5 }) used ({ 6 }) to ({ 7 }) automatically ({ 14 }) estimate ({ 8 }) the ({ 9 }) optimal ({ 10 }) number ({ 11 }) of ({ 12 }) bins ({ 13 }) through ({ 15 }) discretization ({ 16 17 }) . ({ 18 }) 
# Sentence pair (1460) source length 32 target length 30 alignment score : 4.99848e-09
Then Kullback-Leibler divergence which is the relative entropy between probability distributions of positive and negative samples is employed to select the best weak classifier in the weak classifier set . 
NULL ({ }) Then ({ 1 }) Kullback-Leibler ({ 2 }) divergence ({ 3 }) , ({ }) which ({ 4 }) is ({ 5 }) the ({ 6 }) relative ({ 7 }) entropy ({ 8 }) between ({ 9 }) probability ({ 10 }) distributions ({ 11 }) of ({ 12 }) positive ({ 13 }) and ({ 14 }) negative ({ 15 }) samples ({ 16 }) , ({ }) is ({ 17 }) used ({ 18 }) to ({ 19 }) select ({ 20 }) the ({ 21 }) best ({ 22 }) weak ({ 23 }) classifier ({ 24 }) in ({ 25 }) the ({ 26 }) weak ({ 27 }) classifier ({ 28 }) set ({ 29 }) . ({ 30 }) 
# Sentence pair (1461) source length 24 target length 20 alignment score : 5.23746e-17
Experiments have shown that strong classifiers learned by Ent-Boost can achieve good performance , and have compact storage space . 
NULL ({ 14 }) Experiments ({ 1 }) showed ({ 2 3 }) that ({ 4 }) strong ({ 5 }) classifiers ({ 6 }) learned ({ 7 }) by ({ 8 }) Ent-Boost ({ 9 }) can ({ 10 }) achieve ({ 11 }) good ({ 12 }) performance ({ 13 }) and ({ 15 }) be ({ }) stored ({ }) compactly ({ 19 }) . ({ 20 }) //[be ({ 16 }) stored ({ }) compactly ({ }) / ({ }) achieve ({ }) compact ({ 17 }) storage?] ({ 18 }) 
# Sentence pair (1462) source length 18 target length 11 alignment score : 1.20275e-17
Results on building a robust face detector are also reported . 
NULL ({ }) The ({ }) results ({ }) of ({ }) building ({ 3 }) a ({ 4 }) robust ({ 5 }) face ({ 6 }) detector ({ 7 }) using ({ 8 }) Ent-Boost ({ 9 }) showed ({ 2 }) the ({ }) boosting ({ 1 }) scheme ({ }) to ({ }) be ({ }) effective ({ 10 }) . ({ 11 }) 
# Sentence pair (1463) source length 15 target length 15 alignment score : 0.00337216
Building a robust and reliable classifier is always a fundamental problem of pattern recognition . 
NULL ({ }) Building ({ 1 }) a ({ 2 }) robust ({ 3 }) and ({ 4 }) reliable ({ 5 }) classifier ({ 6 }) is ({ 7 }) always ({ 8 }) a ({ 9 }) fundamental ({ 10 }) problem ({ 11 }) of ({ 12 }) pattern ({ 13 }) recognition ({ 14 }) . ({ 15 }) 
# Sentence pair (1464) source length 27 target length 27 alignment score : 1.11243e-08
Several kinds of classifiers , such as Neural Network [1] and Support Vector Machines [2] , have been proposed and applied successfully in many object-detection systems . 
NULL ({ }) Several ({ 1 }) kinds ({ 2 }) of ({ 3 }) classifiers ({ 4 }) , ({ 5 }) such ({ 6 }) as ({ 7 }) neural ({ 8 }) networks ({ 9 }) [1] ({ 10 }) and ({ 11 }) support ({ 12 }) vector ({ 13 }) machines ({ 14 }) [2] ({ 15 }) , ({ 16 }) have ({ 17 }) been ({ 18 }) proposed ({ 19 }) and ({ 20 }) applied ({ 21 }) successfully ({ 22 }) in ({ 23 }) many ({ 24 }) object-detection ({ 25 }) systems ({ 26 }) . ({ 27 }) 
# Sentence pair (1465) source length 21 target length 27 alignment score : 1.97708e-25
Boosting [3] and its variants [4] ,[5] ,[6] ,[7] ,[8] ,[9] ,[10] have recently gained a lot of attentions from researchers because of its excellent performance . 
NULL ({ 16 18 }) Boosting ({ 1 }) [3] ({ 2 }) and ({ 3 }) its ({ 4 }) variants ({ 5 }) [4] ({ 6 }) ? ({ 7 }) [10] ({ 8 12 }) have ({ 13 }) recently ({ 14 }) gained ({ 9 10 11 15 }) much ({ 17 }) attention ({ 19 }) from ({ 20 }) researchers ({ 21 }) because ({ 22 }) of ({ 23 }) their ({ 24 }) excellent ({ 25 }) performance ({ 26 }) . ({ 27 }) 
# Sentence pair (1466) source length 30 target length 33 alignment score : 1.69844e-27
In regards to face detection , for example , the methods described in works [4] ,[5] ,[10] represent the state of the art in terms of both high accuracy and running speed . 
NULL ({ 19 21 22 28 }) In ({ 1 }) regard ({ 2 }) to ({ 3 }) face ({ 4 }) detection ({ 5 }) , ({ 6 }) for ({ 7 }) example ({ 8 }) , ({ 9 }) the ({ 10 }) methods ({ 11 }) described ({ 12 }) in ({ 13 }) [4] ({ 14 15 }) , ({ }) [5] ({ 16 }) , ({ }) and ({ }) [10] ({ 17 18 }) are ({ }) state-of-the-art ({ 20 23 }) in ({ 24 }) terms ({ 25 }) of ({ 26 }) both ({ 27 }) accuracy ({ 29 }) and ({ 30 }) running ({ 31 }) speed ({ 32 }) . ({ 33 }) 
# Sentence pair (1467) source length 19 target length 19 alignment score : 0.00111725
The main idea of boosting is to combine the performance of weak classifiers to form a strong classifier . 
NULL ({ }) The ({ 1 }) main ({ 2 }) idea ({ 3 }) of ({ 4 }) boosting ({ 5 }) is ({ 6 }) to ({ 7 }) combine ({ 8 }) the ({ 9 }) performance ({ 10 }) of ({ 11 }) weak ({ 12 }) classifiers ({ 13 }) to ({ 14 }) form ({ 15 }) a ({ 16 }) strong ({ 17 }) classifier ({ 18 }) . ({ 19 }) 
# Sentence pair (1468) source length 28 target length 27 alignment score : 7.83457e-09
Typically , each weak classifier is any classifier whose performance is better than random guessing ( i.e. , error rate is less than 0 .5 ) . 
NULL ({ }) Typically ({ 1 }) , ({ 2 }) a ({ 3 }) weak ({ 4 }) classifier ({ 5 }) is ({ 6 }) any ({ 7 }) classifier ({ 8 }) whose ({ 9 }) performance ({ 10 }) is ({ 11 }) better ({ 12 }) than ({ 13 }) random ({ 14 }) guessing ({ 15 }) ( ({ 16 }) i.e. ({ 17 }) , ({ 18 }) its ({ }) error ({ 19 }) rate ({ 20 }) is ({ 21 }) less ({ 22 }) than ({ 23 }) 0 ({ 24 }) .5 ({ 25 }) ) ({ 26 }) . ({ 27 }) 
# Sentence pair (1469) source length 33 target length 31 alignment score : 1.48116e-10
Performances of weak classifiers are integrated into the final form of the strong classifier through a learning process in which more accurate weak classifiers have larger weights in final voting . 
NULL ({ }) The ({ }) performances ({ 1 }) of ({ 2 }) these ({ }) weak ({ 3 }) classifiers ({ 4 }) are ({ 5 }) integrated ({ 6 }) into ({ 7 }) the ({ 8 }) final ({ 9 }) form ({ 10 }) of ({ 11 }) a ({ 12 }) strong ({ 13 }) classifier ({ 14 }) through ({ 15 }) a ({ 16 }) learning ({ 17 }) process ({ 18 }) in ({ 19 }) which ({ 20 }) more ({ 21 }) accurate ({ 22 }) weak ({ 23 }) classifiers ({ 24 }) have ({ 25 }) larger ({ 26 }) weights ({ 27 }) in ({ 28 }) final ({ 29 }) voting ({ 30 }) . ({ 31 }) 
# Sentence pair (1470) source length 22 target length 24 alignment score : 2.04544e-10
In practical problems , designing and learning weak classifiers are left for practitioners with two main challenges : computational evaluation and discriminant power . 
NULL ({ 12 }) In ({ 1 }) practical ({ 2 }) problems ({ 3 }) , ({ 4 }) designing ({ 5 }) and ({ 6 }) learning ({ 7 }) weak ({ 8 }) classifiers ({ 9 }) leave ({ 10 }) practitioners ({ 11 13 }) with ({ 14 }) two ({ 15 }) main ({ 16 }) challenges ({ 17 }) : ({ 18 }) computational ({ 19 }) evaluation ({ 20 }) and ({ 21 }) discriminant ({ 22 }) power ({ 23 }) . ({ 24 }) 
# Sentence pair (1471) source length 28 target length 27 alignment score : 7.13457e-10
Generally , for efficient computation , the dimension of the input space of weak classifiers is reduced to much lower than that of the strong classifier . 
NULL ({ }) Generally ({ 1 }) , ({ 2 }) for ({ 3 }) efficient ({ 4 }) computation ({ 5 }) , ({ 6 }) the ({ 7 }) dimensions ({ 8 }) of ({ 9 }) the ({ 10 }) input ({ 11 }) space ({ 12 }) of ({ 13 }) weak ({ 14 }) classifiers ({ 15 }) are ({ 16 }) reduced ({ 17 }) be ({ }) to ({ 18 }) much ({ 19 }) smaller ({ 20 }) than ({ 21 }) those ({ 22 }) of ({ 23 }) the ({ 24 }) strong ({ 25 }) classifier[s?] ({ 26 }) . ({ 27 }) 
# Sentence pair (1472) source length 22 target length 19 alignment score : 8.38173e-09
In object-detection frameworks [4] ,[5] ,[11] ,[12] ,[13] weak classifiers are usually constructed from one or several features . 
NULL ({ }) In ({ 1 }) object-detection ({ 2 }) frameworks ({ 3 }) [4] ({ 4 }) , ({ }) [5] ({ 5 }) , ({ }) [11] ({ 6 }) ? ({ 7 }) [13] ({ 8 }) , ({ }) weak ({ 9 }) classifiers ({ 10 }) are ({ 11 }) usually ({ 12 }) constructed ({ 13 }) from ({ 14 }) one ({ 15 }) or ({ 16 }) several ({ 17 }) features ({ 18 }) . ({ 19 }) 
# Sentence pair (1473) source length 25 target length 25 alignment score : 7.90649e-05
For example , a weak classifier can be constructed from one Haar wavelet feature that is evaluated very rapidly through an integral image [4] . 
NULL ({ }) For ({ 1 }) example ({ 2 }) , ({ 3 }) a ({ 4 }) weak ({ 5 }) classifier ({ 6 }) can ({ 7 }) be ({ 8 }) constructed ({ 9 }) from ({ 10 }) one ({ 11 }) Haar ({ 12 }) wavelet ({ 13 }) feature ({ 14 }) that ({ 15 }) is ({ 16 }) evaluated ({ 17 }) very ({ 18 }) rapidly ({ 19 }) through ({ 20 }) an ({ 21 }) integral ({ 22 }) image ({ 23 }) [4] ({ 24 }) . ({ 25 }) 
# Sentence pair (1474) source length 26 target length 26 alignment score : 6.84435e-07
Given a feature type , choosing the suitable way to form a weak classifier that balance efficiency and computation is still a open problem [14] . 
NULL ({ }) Given ({ 1 }) a ({ 2 }) feature ({ 3 }) type ({ 4 }) , ({ 5 }) choosing ({ 6 }) the ({ 7 }) suitable ({ 8 }) way ({ 9 }) to ({ 10 }) form ({ 11 }) a ({ 12 }) weak ({ 13 }) classifier ({ 14 }) that ({ 15 }) balances ({ 16 }) efficiency ({ 17 }) and ({ 18 }) computation ({ 19 }) is ({ 20 }) still ({ 21 }) an ({ 22 }) open ({ 23 }) problem ({ 24 }) [14] ({ 25 }) . ({ 26 }) 
# Sentence pair (1475) source length 12 target length 13 alignment score : 4.28598e-08
There are two key trends for seeking the most discriminant weak classifier . 
NULL ({ 2 }) Two ({ 1 }) key ({ 4 }) trends ({ 3 }) exist ({ 5 }) for ({ 6 }) seeking ({ 7 }) the ({ 8 }) most ({ 9 }) discriminant ({ 10 }) weak ({ 11 }) classifier ({ 12 }) . ({ 13 }) 
# Sentence pair (1476) source length 20 target length 21 alignment score : 3.96623e-08
The first trend is dealing with the problem of how to design features for best representation of the target object . 
NULL ({ 17 }) The ({ 1 }) first ({ 2 }) trend ({ 3 }) is ({ 4 }) dealing ({ 5 }) with ({ 6 }) the ({ 7 }) problem ({ 8 }) of ({ 9 }) how ({ 10 }) to ({ 11 }) design ({ 12 }) features ({ 13 }) for ({ 14 }) best ({ 15 }) representing ({ 16 }) the ({ 18 }) target ({ 19 }) object ({ 20 }) . ({ 21 }) 
# Sentence pair (1477) source length 46 target length 44 alignment score : 2.48157e-13
Besides Haar wavelet features [4] , Gabor wavelets [5] , edge orientation histogram ( EOH ) [11] , orientation dominants [12] , scale invariant feature transform ( SIFT )-based-high-level features [13] and local binary pattern ( LBP ) [15] have also been used . 
NULL ({ }) Besides ({ 1 }) Haar ({ 2 }) wavelet ({ 3 }) features ({ 4 }) [4] ({ 5 }) , ({ 6 }) Gabor ({ 7 }) wavelets ({ 8 }) [5] ({ 9 }) , ({ 10 }) edge ({ 11 }) orientation ({ 12 }) histograms ({ 13 }) ( ({ 14 }) EOH ({ 15 }) ) ({ 16 }) [11] ({ 17 }) , ({ 18 }) orientation ({ 19 }) dominants ({ 20 }) [12] ({ 21 }) , ({ 22 }) scale ({ 23 }) invariant ({ 24 }) feature ({ 25 }) transform ({ 26 }) ( ({ 27 }) SIFT ({ 28 }) )-based ({ }) high-level ({ 29 }) features ({ 30 }) [13] ({ 31 }) , ({ }) and ({ 32 }) local ({ 33 }) binary ({ 34 }) patterns ({ 35 }) ( ({ 36 }) LBP ({ 37 }) ) ({ 38 }) [15] ({ 39 }) have ({ 40 }) also ({ 41 }) been ({ 42 }) used ({ 43 }) . ({ 44 }) 
# Sentence pair (1478) source length 19 target length 19 alignment score : 0.00135182
The second trend is studying how to optimally select the best weak classifier from a weak classifier set . 
NULL ({ }) The ({ 1 }) second ({ 2 }) trend ({ 3 }) is ({ 4 }) studying ({ 5 }) how ({ 6 }) to ({ 7 }) optimally ({ 8 }) select ({ 9 }) the ({ 10 }) best ({ 11 }) weak ({ 12 }) classifier ({ 13 }) from ({ 14 }) a ({ 15 }) weak ({ 16 }) classifier ({ 17 }) set ({ 18 }) . ({ 19 }) 
# Sentence pair (1479) source length 26 target length 17 alignment score : 1.25394e-15
In Discrete AdaBoost [16] , weak classifiers are threshold-functions whose the output is restricted to binary . 
NULL ({ 11 }) In ({ 1 }) Discrete ({ 2 }) AdaBoost ({ 3 }) [16] ({ 4 }) , ({ 5 }) weak ({ 6 }) classifiers ({ 7 }) are ({ 8 }) threshold-functions ({ 9 }) whose ({ 10 }) output ({ 12 }) is ({ 13 }) restricted ({ 14 }) to ({ }) binary ({ }) data. ({ }) //[data ({ }) / ({ }) values??I ({ 15 }) think ({ }) you ({ }) need ({ }) a ({ }) noun ({ }) here?binary ({ 16 }) what?] ({ 17 }) 
# Sentence pair (1480) source length 16 target length 15 alignment score : 2.28626e-07
This leads weak classifiers are too weak to boost when handling complex data sets . 
NULL ({ 5 }) This ({ 1 }) leads ({ 2 }) weak ({ 3 }) classifiers ({ 4 }) to ({ }) be ({ }) too ({ 6 }) weak ({ 7 }) to ({ 8 }) boost ({ 9 }) when ({ 10 }) handling ({ 11 }) complex ({ 12 }) data ({ 13 }) sets ({ 14 }) . ({ 15 }) 
# Sentence pair (1481) source length 27 target length 27 alignment score : 5.19261e-05
For example , in later layers of the cascaded face classifiers [4] , the error rate of weak classifiers is between 0 .4 and 0 .5 . 
NULL ({ }) For ({ 1 }) example ({ 2 }) , ({ 3 }) in ({ 4 }) later ({ 5 }) layers ({ 6 }) of ({ 7 }) the ({ 8 }) cascaded ({ 9 }) face ({ 10 }) classifiers ({ 11 }) [4] ({ 12 }) , ({ 13 }) the ({ 14 }) error ({ 15 }) rate ({ 16 }) of ({ 17 }) weak ({ 18 }) classifiers ({ 19 }) is ({ 20 }) between ({ 21 }) 0 ({ 22 }) .4 ({ 23 }) and ({ 24 }) 0 ({ 25 }) .5 ({ 26 }) . ({ 27 }) 
# Sentence pair (1482) source length 30 target length 31 alignment score : 2.77694e-07
Meanwhile , in Real AdaBoost [3] , a generalized version of Discrete AdaBoost , weak classifiers are piece-wise functions whose the output is a real value representing the confidence-rated prediction . 
NULL ({ 21 }) Meanwhile ({ 1 }) , ({ 2 }) in ({ 3 }) Real ({ 4 }) AdaBoost ({ 5 }) [3] ({ 6 }) , ({ 7 }) a ({ 8 }) generalized ({ 9 }) version ({ 10 }) of ({ 11 }) Discrete ({ 12 }) AdaBoost ({ 13 }) , ({ 14 }) weak ({ 15 }) classifiers ({ 16 }) are ({ 17 }) piece-wise ({ 18 }) functions ({ 19 }) whose ({ 20 }) output ({ 22 }) is ({ 23 }) a ({ 24 }) real ({ 25 }) value ({ 26 }) representing ({ 27 }) the ({ 28 }) confidence-rated ({ 29 }) prediction ({ 30 }) . ({ 31 }) 
# Sentence pair (1483) source length 50 target length 50 alignment score : 1.31934e-08
Normally , to construct such weak classifiers , one splits the input space \MATH into non-overlapping blocks ( or subspaces ) \MATH , \MATH , . . . , \MATH so that the predictions of the weak classifier are the same for all instances falling into the same block . 
NULL ({ }) Normally ({ 1 }) , ({ 2 }) to ({ 3 }) construct ({ 4 }) such ({ 5 }) weak ({ 6 }) classifiers ({ 7 }) , ({ 8 }) one ({ 9 }) splits ({ 10 }) the ({ 11 }) input ({ 12 }) space ({ 13 }) \MATH ({ 14 }) into ({ 15 }) non-overlapping ({ 16 }) blocks ({ 17 }) ( ({ 18 }) or ({ 19 }) subspaces ({ 20 }) ) ({ 21 }) \MATH ({ 22 }) , ({ 23 }) \MATH ({ 24 }) , ({ 25 }) . ({ 26 }) . ({ 27 }) . ({ 28 }) , ({ 29 }) \MATH ({ 30 }) so ({ 31 }) that ({ 32 }) the ({ 33 }) predictions ({ 34 }) of ({ 35 }) the ({ 36 }) weak ({ 37 }) classifier ({ 38 }) are ({ 39 }) the ({ 40 }) same ({ 41 }) for ({ 42 }) all ({ 43 }) instances ({ 44 }) falling ({ 45 }) into ({ 46 }) the ({ 47 }) same ({ 48 }) block ({ 49 }) . ({ 50 }) 
# Sentence pair (1484) source length 19 target length 19 alignment score : 0.001182
In the case of one-feature-based weak classifiers , this is equivalent to dividing the real line into intervals . 
NULL ({ }) In ({ 1 }) the ({ 2 }) case ({ 3 }) of ({ 4 }) one-feature-based ({ 5 }) weak ({ 6 }) classifiers ({ 7 }) , ({ 8 }) this ({ 9 }) is ({ 10 }) equivalent ({ 11 }) to ({ 12 }) dividing ({ 13 }) the ({ 14 }) real ({ 15 }) line ({ 16 }) into ({ 17 }) intervals ({ 18 }) . ({ 19 }) 
# Sentence pair (1485) source length 37 target length 26 alignment score : 3.17444e-19
Typically , most current works [5] ,[17] ,[6] ,[8] ,[10] split the data into \MATH bins that are equal width which suffers from following limitations : 
NULL ({ }) Typically ({ 1 }) , ({ 2 }) most ({ 3 }) current ({ 4 }) works ({ 5 }) [5] ({ 6 }) , ({ }) [6] ({ 8 }) , ({ }) [8] ({ 9 }) , ({ }) [10] ({ 10 }) , ({ }) [17] ({ }) split ({ 11 }) the ({ 12 }) data ({ 13 }) into ({ 14 }) \MATH ({ 15 }) bins ({ 16 }) that ({ 17 }) are ({ 18 }) equal ({ 19 }) in ({ }) width ({ 20 }) . ({ }) This ({ }) method ({ }) suffers ({ 22 }) from ({ 23 }) the ({ }) following ({ 24 }) limitations ({ 25 }) : ({ 26 }) //[works ({ 7 }) / ({ }) systems?] ({ 21 }) 
# Sentence pair (1486) source length 12 target length 9 alignment score : 2.56636e-06
-Choosing the appropriate number of bins is undetermined . 
NULL ({ }) -The ({ 1 }) way ({ }) to ({ }) choose ({ }) the ({ 2 }) appropriate ({ 3 }) number ({ 4 }) of ({ 5 }) bins ({ 6 }) is ({ 7 }) undetermined ({ 8 }) . ({ 9 }) 
# Sentence pair (1487) source length 18 target length 17 alignment score : 2.75116e-07
Normally , it has been done by trials and errors [6] ,[17] - a tedious task . 
NULL ({ }) Normally ({ 1 }) , ({ 2 }) it ({ 3 }) has ({ 4 }) been ({ 5 }) done ({ 6 }) by ({ 7 }) trial ({ 8 }) and ({ 9 }) error ({ 10 }) [6] ({ 11 }) , ({ }) [17] ({ 12 }) ? ({ 13 }) a ({ 14 }) tedious ({ 15 }) task ({ 16 }) . ({ 17 }) 
# Sentence pair (1488) source length 35 target length 34 alignment score : 5.3234e-09
In the training cascade of classifiers [6] ,[17] , when the complexity of the training data changes over time , using the same number of bins for training every layers is not optimal . 
NULL ({ }) In ({ 1 }) the ({ 2 }) training ({ 3 }) cascade ({ 4 }) of ({ 5 }) classifiers ({ 6 }) [6] ({ 7 }) , ({ }) [17] ({ 8 }) , ({ 9 }) when ({ 10 }) the ({ 11 }) complexity ({ 12 }) of ({ 13 }) the ({ 14 }) training ({ 15 }) data ({ 16 }) changes ({ 17 }) over ({ 18 }) time ({ 19 }) , ({ 20 }) using ({ 21 }) the ({ 22 }) same ({ 23 }) number ({ 24 }) of ({ 25 }) bins ({ 26 }) for ({ 27 }) training ({ 28 }) every ({ 29 }) layer ({ 30 }) is ({ 31 }) not ({ 32 }) optimal ({ 33 }) . ({ 34 }) 
# Sentence pair (1489) source length 20 target length 20 alignment score : 0.000492488
-Choosing a large number of bins might cause over-fitting because of outliers in the case of noisy data [18] . 
NULL ({ }) -Choosing ({ 1 }) a ({ 2 }) large ({ 3 }) number ({ 4 }) of ({ 5 }) bins ({ 6 }) might ({ 7 }) cause ({ 8 }) over-fitting ({ 9 }) because ({ 10 }) of ({ 11 }) outliers ({ 12 }) in ({ 13 }) the ({ 14 }) case ({ 15 }) of ({ 16 }) noisy ({ 17 }) data ({ 18 }) [18] ({ 19 }) . ({ 20 }) 
# Sentence pair (1490) source length 32 target length 30 alignment score : 2.368e-09
Furthermore it might increase computation and training time , waste storage space which is critical in applications with limited resources , for example , face detection on mobile phones . 
NULL ({ 9 }) Furthermore ({ 1 }) , ({ }) it ({ 2 }) might ({ 3 }) lengthen ({ 4 }) computation ({ 5 }) and ({ 6 }) training ({ 7 }) time ({ 8 }) and ({ }) waste ({ 10 }) storage ({ 11 }) space ({ 12 }) , ({ }) which ({ 13 }) is ({ 14 }) critical ({ 15 }) in ({ 16 }) applications ({ 17 }) with ({ 18 }) limited ({ 19 }) resources ({ 20 }) , ({ 21 }) for ({ 22 }) example ({ 23 }) , ({ 24 }) face ({ 25 }) detection ({ 26 }) on ({ 27 }) mobile ({ 28 }) phones ({ 29 }) . ({ 30 }) 
# Sentence pair (1491) source length 31 target length 28 alignment score : 5.57913e-13
Meanwhile choosing a small number of bins might not well approximate the real densities of the data distribution and thus influence selection of the best weak classifier . 
NULL ({ }) Choosing ({ 1 2 }) a ({ 3 }) small ({ 4 }) number ({ 5 }) of ({ 6 }) bins ({ 7 }) , ({ }) however ({ }) , ({ }) might ({ 8 }) not ({ 9 }) accurately ({ 10 }) approximate ({ 11 }) the ({ 12 }) real ({ 13 }) densities ({ 14 }) of ({ 15 }) the ({ 16 }) data ({ 17 }) distribution ({ 18 }) and ({ 19 }) could ({ 20 }) influence ({ 21 }) the ({ }) selection ({ 22 }) of ({ 23 }) the ({ 24 }) best ({ 25 }) weak ({ 26 }) classifier ({ 27 }) . ({ 28 }) 
# Sentence pair (1492) source length 16 target length 19 alignment score : 6.17892e-24
It is therefore necessary to have a deterministic method to choose this number of bins automatically and optimally . 
NULL ({ 6 7 10 }) A ({ 1 }) deterministic ({ 8 }) method ({ 9 }) is ({ 2 }) therefore ({ 3 }) needed ({ 4 }) to ({ 5 }) automatically ({ 16 }) and ({ 17 }) optimally ({ 18 }) choose ({ 11 }) the ({ 12 }) number ({ 13 }) of ({ 14 }) bins ({ 15 }) . ({ 19 }) 
# Sentence pair (1493) source length 31 target length 19 alignment score : 5.97179e-17
This problem can be formulated as a discretization problem in which subspace boundaries are found by some criteria . 
NULL ({ }) This ({ 1 }) problem ({ 2 }) can ({ 3 }) be ({ 4 }) formulated ({ 5 }) as ({ 6 }) a ({ 7 }) discretization ({ 8 }) problem ({ 9 }) in ({ 10 }) which ({ 11 }) subspace ({ 12 }) boundaries ({ 13 }) are ({ 14 }) found ({ 15 }) by ({ 16 }) some ({ 17 }) criteria ({ 18 }) . ({ }) //[some ({ }) criteria?This ({ }) sounds ({ }) a ({ }) bit ({ }) vague ({ }) . ({ }) Could ({ }) you ({ }) be ({ }) more ({ }) specific?] ({ 19 }) 
# Sentence pair (1494) source length 25 target length 26 alignment score : 4.86418e-13
Among discretization methods , the entropy based method [19] has been proved most efficiently ; hence , we propose using it to solve the problem . 
NULL ({ }) Among ({ 1 }) discretization ({ 2 }) methods ({ 3 }) , ({ 4 }) the ({ 5 }) entropy-based ({ 6 7 }) method ({ 8 }) [19] ({ 9 }) has ({ 10 }) been ({ 11 }) proved ({ 12 }) most ({ 13 }) efficient ({ 14 }) . ({ 15 }) Hence ({ 16 }) , ({ 17 }) we ({ 18 }) propose ({ 19 }) using ({ 20 }) it ({ 21 }) to ({ 22 }) solve ({ 23 }) the ({ 24 }) problem ({ 25 }) . ({ 26 }) 
# Sentence pair (1495) source length 24 target length 25 alignment score : 1.24623e-07
The entropy based discretization method is an algorithm that automatically selects appropriate thresholds to split feature values into optimal bins by using entropy measurement . 
NULL ({ }) The ({ 1 }) entropy-based ({ 2 3 }) discretization ({ 4 }) method ({ 5 }) is ({ 6 }) an ({ 7 }) algorithm ({ 8 }) that ({ 9 }) automatically ({ 10 }) selects ({ 11 }) appropriate ({ 12 }) thresholds ({ 13 }) to ({ 14 }) split ({ 15 }) feature ({ 16 }) values ({ 17 }) into ({ 18 }) optimal ({ 19 }) bins ({ 20 }) by ({ 21 }) using ({ 22 }) entropy ({ 23 }) measurement ({ 24 }) . ({ 25 }) 
# Sentence pair (1496) source length 31 target length 31 alignment score : 2.09342e-09
It is a supervised discretization method which takes into account class information and data distribution , so it is generic and can be applied for any kinds of input data . 
NULL ({ }) It ({ 1 }) is ({ 2 }) a ({ 3 }) supervised ({ 4 }) discretization ({ 5 }) method ({ 6 }) that ({ 7 }) takes ({ 8 }) into ({ 9 }) account ({ 10 }) class ({ 11 }) information ({ 12 }) and ({ 13 }) data ({ 14 }) distribution ({ 15 }) , ({ 16 }) so ({ 17 }) it ({ 18 }) is ({ 19 }) generic ({ 20 }) and ({ 21 }) can ({ 22 }) be ({ 23 }) applied ({ 24 }) to ({ 25 }) any ({ 26 }) kind ({ 27 }) of ({ 28 }) input ({ 29 }) data ({ 30 }) . ({ 31 }) 
# Sentence pair (1497) source length 40 target length 40 alignment score : 9.87597e-21
Furthermore , many studies have been shown that discretization process might help to improve performance in induction tasks [18] , it can also work with a weighted data distribution ; therefore , it is most appropriate for boosting-based methods . 
NULL ({ 20 }) Furthermore ({ 1 }) , ({ 2 }) many ({ 3 }) studies ({ 4 }) have ({ 5 }) shown ({ 6 7 }) that ({ 8 }) the ({ }) discretization ({ 9 }) process ({ 10 }) might ({ 11 }) help ({ 12 }) to ({ 13 }) improve ({ 14 }) performance ({ 15 }) in ({ 16 }) induction ({ 17 }) tasks ({ 18 }) [18] ({ 19 }) and ({ }) it ({ 21 }) can ({ 22 }) also ({ 23 }) work ({ 24 }) with ({ 25 }) a ({ 26 }) weighted ({ 27 }) data ({ 28 }) distribution ({ 29 }) . ({ 30 }) Therefore ({ 31 }) , ({ 32 }) it ({ 33 }) is ({ 34 }) most ({ 35 }) appropriate ({ 36 }) for ({ 37 }) boosting-based ({ 38 }) methods ({ 39 }) . ({ 40 }) 
# Sentence pair (1498) source length 26 target length 25 alignment score : 2.05661e-10
Besides learning weak classifiers , selecting the best weak classifier in the large weak classifier set in each round of boosting is also important . 
NULL ({ }) Besides ({ 1 }) learning ({ 2 }) weak ({ 3 }) classifiers ({ 4 }) , ({ 5 }) selecting ({ 6 }) the ({ 7 }) best ({ 8 }) weak ({ 9 }) classifier ({ 10 }) in ({ 11 }) the ({ 12 }) large ({ 13 }) set ({ 16 }) of ({ }) weak ({ 14 }) classifiers ({ 15 }) in ({ 17 }) each ({ 18 }) round ({ 19 }) of ({ 20 }) boosting ({ 21 }) is ({ 22 }) also ({ 23 }) important ({ 24 }) . ({ 25 }) 
# Sentence pair (1499) source length 35 target length 27 alignment score : 5.13344e-14
Adopting [5] , it is done by choosing the weak classifier that maximizes Kullback-Leibler ( KL ) divergence between two distributions of positive and negative samples . 
NULL ({ }) Following ({ 1 }) the ({ }) method ({ }) used ({ }) in ({ }) [5] ({ 2 }) , ({ 3 }) it ({ 4 }) is ({ 5 }) done ({ 6 }) by ({ 7 }) choosing ({ 8 }) the ({ 9 }) weak ({ 10 }) classifier ({ 11 }) that ({ 12 }) maximizes ({ 13 }) Kullback-Leibler ({ 14 }) ( ({ 15 }) KL ({ 16 }) ) ({ 17 }) divergence ({ 18 }) between ({ 19 }) two ({ 20 }) distributions ({ 21 }) of ({ 22 }) positive ({ 23 }) and ({ 24 }) negative ({ 25 }) samples ({ 26 }) . ({ }) // ({ }) [used ({ }) / ({ }) proposed?] ({ 27 }) 
# Sentence pair (1500) source length 27 target length 26 alignment score : 1.5947e-06
The integration of entropy-based discretization process and optimal weak classifier selection into the current boosting framework forms a new variant of AdaBoost , called Ent-Boost . 
NULL ({ }) The ({ 1 }) integration ({ 2 }) of ({ 3 }) the ({ }) entropy-based ({ 4 }) discretization ({ 5 }) process ({ 6 }) and ({ 7 }) optimal ({ 8 }) weak ({ 9 }) classifier ({ 10 }) selection ({ 11 }) into ({ 12 }) the ({ 13 }) current ({ 14 }) boosting ({ 15 }) framework ({ 16 }) formed ({ 17 }) a ({ 18 }) new ({ 19 }) variant ({ 20 }) of ({ 21 }) AdaBoost ({ 22 }) , ({ 23 }) called ({ 24 }) Ent-Boost ({ 25 }) . ({ 26 }) 
# Sentence pair (1501) source length 17 target length 16 alignment score : 0.000502512
Experiments on building a robust face detector have shown effectiveness of this new boosting scheme . 
NULL ({ }) Experiments ({ 1 }) on ({ 2 }) building ({ 3 }) a ({ 4 }) robust ({ 5 }) face ({ 6 }) detector ({ 7 }) have ({ 8 }) shown ({ 9 }) the ({ }) effectiveness ({ 10 }) of ({ 11 }) this ({ 12 }) new ({ 13 }) boosting ({ 14 }) scheme ({ 15 }) . ({ 16 }) 
# Sentence pair (1502) source length 26 target length 23 alignment score : 2.88214e-07
Originally , Discrete AdaBoost proposed by Freund and Schapire [16] is a learning method of combining weak classifiers to a strong classier . 
NULL ({ }) Originally ({ 1 }) , ({ 2 }) Discrete ({ 3 }) AdaBoost ({ 4 }) , ({ }) proposed ({ 5 }) by ({ 6 }) Freund ({ 7 }) and ({ 8 }) Schapire ({ 9 }) [16] ({ 10 }) , ({ }) was ({ 11 }) a ({ 12 }) learning ({ 13 }) method ({ 14 }) of ({ 15 }) combining ({ 16 }) weak ({ 17 }) classifiers ({ 18 }) to ({ 19 }) form ({ }) a ({ 20 }) strong ({ 21 }) classier ({ 22 }) . ({ 23 }) 
# Sentence pair (1503) source length 20 target length 19 alignment score : 0.00024039
Given a training set \MATH where \MATH and \MATH , a weak classifier \MATH has the form \MATH . 
NULL ({ }) Given ({ 1 }) a ({ 2 }) training ({ 3 }) set ({ 4 }) \MATH ({ 5 }) , ({ }) where ({ 6 }) \MATH ({ 7 }) and ({ 8 }) \MATH ({ 9 }) , ({ 10 }) a ({ 11 }) weak ({ 12 }) classifier ({ 13 }) \MATH ({ 14 }) has ({ 15 }) the ({ 16 }) form ({ 17 }) \MATH ({ 18 }) . ({ 19 }) 
# Sentence pair (1504) source length 20 target length 20 alignment score : 0.00078248
Normally , a weak classifier is any classifier whose performance measured by error rate is less than 0 .5 . 
NULL ({ }) Normally ({ 1 }) , ({ 2 }) a ({ 3 }) weak ({ 4 }) classifier ({ 5 }) is ({ 6 }) any ({ 7 }) classifier ({ 8 }) whose ({ 9 }) performance ({ 10 }) measured ({ 11 }) by ({ 12 }) error ({ 13 }) rate ({ 14 }) is ({ 15 }) less ({ 16 }) than ({ 17 }) 0 ({ 18 }) .5 ({ 19 }) . ({ 20 }) 
# Sentence pair (1505) source length 21 target length 19 alignment score : 1.13695e-08
Therefore , in many applications [4] ,[5] ,[7] , it is simplified by associating to one feature \MATH . 
NULL ({ }) Therefore ({ 1 }) , ({ 2 }) in ({ 3 }) many ({ 4 }) applications ({ 5 }) [4] ({ 6 }) , ({ }) [5] ({ 7 }) , ({ }) [7] ({ 8 }) , ({ 9 }) it ({ 10 }) is ({ 11 }) simplified ({ 12 }) by ({ 13 }) associating ({ 14 }) with ({ 15 }) one ({ 16 }) feature ({ 17 }) \MATH ({ 18 }) . ({ 19 }) 
# Sentence pair (1506) source length 27 target length 26 alignment score : 6.64203e-06
Through boosting processing , weak classifiers are combined into a strong classifier \MATH where \MATH are values that measure performance of the selected weak classifier . 
NULL ({ }) Through ({ 1 }) boosting ({ 2 }) processing ({ 3 }) , ({ 4 }) weak ({ 5 }) classifiers ({ 6 }) are ({ 7 }) combined ({ 8 }) into ({ 9 }) a ({ 10 }) strong ({ 11 }) classifier ({ 12 }) \MATH ({ 13 }) where ({ 14 }) \MATH ({ 15 }) are ({ 16 }) values ({ 17 }) that ({ 18 }) measure ({ 19 }) the ({ }) performance ({ 20 }) of ({ 21 }) the ({ 22 }) selected ({ 23 }) weak ({ 24 }) classifier ({ 25 }) . ({ 26 }) 
# Sentence pair (1507) source length 34 target length 31 alignment score : 1.41574e-10
In boosting process , a distribution \MATH or set of weights over the training samples are maintained and updated so that subsequent weak classifiers focus on the hard classified samples . 
NULL ({ }) In ({ 1 }) the ({ }) boosting ({ 2 }) process ({ 3 }) , ({ 4 }) a ({ 5 }) distribution ({ 6 }) \MATH ({ 7 }) or ({ 8 }) set ({ 9 }) of ({ 10 }) weights ({ 11 }) over ({ 12 }) the ({ 13 }) training ({ 14 }) samples ({ 15 }) are ({ 16 }) maintained ({ 17 }) and ({ 18 }) updated ({ 19 }) so ({ 20 }) that ({ 21 }) subsequent ({ 22 }) weak ({ 23 }) classifiers ({ 24 }) focus ({ 25 }) on ({ 26 }) the ({ 27 }) strong-classified ({ 28 }) samples ({ 30 }) . ({ 31 }) //[hard ({ 29 }) / ({ }) strong?] ({ }) 
# Sentence pair (1508) source length 42 target length 32 alignment score : 3.01718e-23
Real AdaBoost [3] is a generalized version of Discrete AdaBoost in that weak classifiers are real-valued functions instead of binary ones and \MATH is found numerically in general instead of predescription . 
NULL ({ }) Real ({ 1 }) AdaBoost ({ 2 }) [3] ({ 3 }) is ({ 4 }) a ({ 5 }) generalized ({ 6 }) version ({ 7 }) of ({ 8 }) Discrete ({ 9 }) AdaBoost ({ 10 }) in ({ }) that ({ 12 }) weak ({ 13 }) classifiers ({ 14 }) are ({ 15 }) real-valued ({ 16 }) functions ({ 17 }) instead ({ 18 }) of ({ 19 }) binary ({ 20 }) ones ({ 21 }) and ({ 22 }) \MATH ({ 23 }) is ({ 24 }) found ({ 25 }) numerically ({ 26 28 }) instead ({ 29 }) of ({ 30 }) by ({ }) predescription ({ 31 }) . ({ 32 }) //[This ({ 27 }) method ({ }) also ({ }) involves?NOTE ({ 11 }) : ({ }) A ({ }) method ({ }) cannot ({ }) propose ({ }) something ({ }) . ({ }) 
# Sentence pair (1509) source length 31 target length 24 alignment score : 5.63153e-16
This method also proposes designing weak classifiers that partition the input space into subspaces so that its predictions are unique in each subspace . 
NULL ({ }) Do ({ 1 }) you ({ 2 }) mean ({ }) that ({ }) the ({ }) creators ({ 3 }) of ({ }) this ({ }) system ({ }) proposed ({ }) this?] ({ 4 }) designing ({ 5 }) weak ({ 6 }) classifiers ({ 7 }) that ({ 8 }) partition ({ 9 }) the ({ 10 }) input ({ 11 }) space ({ 12 }) into ({ 13 }) subspaces ({ 14 }) so ({ 15 }) that ({ 16 }) the ({ }) predictions ({ 17 18 }) are ({ 19 }) unique ({ 20 }) in ({ 21 }) each ({ 22 }) subspace ({ 23 }) . ({ 24 }) 
# Sentence pair (1510) source length 18 target length 19 alignment score : 1.29431e-15
Such weak classifiers are used widely in current state of the art object detection systems [5] ,[17] ,[8] . 
NULL ({ 10 11 }) Such ({ 1 }) weak ({ 2 }) classifiers ({ 3 }) are ({ 4 }) used ({ 5 }) widely ({ 6 }) in ({ 7 }) current ({ 8 }) state-of-the-art ({ 9 12 }) object ({ 13 }) detection ({ 14 }) systems ({ 15 }) [5] ({ 16 17 }) , ({ }) [8] ({ 18 }) , ({ }) [17] ({ }) . ({ 19 }) 
# Sentence pair (1511) source length 27 target length 27 alignment score : 0.00010572
Suppose that \MATH , \MATH , . . . , \MATH is a partition of the domain \MATH on which such weak classifiers $h$ are defined . 
NULL ({ }) Suppose ({ 1 }) that ({ 2 }) \MATH ({ 3 }) , ({ 4 }) \MATH ({ 5 }) , ({ 6 }) . ({ 7 }) . ({ 8 }) . ({ 9 }) , ({ 10 }) \MATH ({ 11 }) is ({ 12 }) a ({ 13 }) partition ({ 14 }) of ({ 15 }) the ({ 16 }) domain ({ 17 }) \MATH ({ 18 }) on ({ 19 }) which ({ 20 }) such ({ 21 }) weak ({ 22 }) classifiers ({ 23 }) $h$ ({ 24 }) are ({ 25 }) defined ({ 26 }) . ({ 27 }) 
# Sentence pair (1512) source length 16 target length 16 alignment score : 0.00165514
The prediction of \MATH depends only on which block \MATH a given instance falls into . 
NULL ({ }) The ({ 1 }) prediction ({ 2 }) of ({ 3 }) \MATH ({ 4 }) depends ({ 5 }) only ({ 6 }) on ({ 7 }) which ({ 8 }) block ({ 9 }) \MATH ({ 10 }) a ({ 11 }) given ({ 12 }) instance ({ 13 }) falls ({ 14 }) into ({ 15 }) . ({ 16 }) 
# Sentence pair (1513) source length 10 target length 10 alignment score : 0.031779
On the other hand , \MATH for all \MATH . 
NULL ({ }) On ({ 1 }) the ({ 2 }) other ({ 3 }) hand ({ 4 }) , ({ 5 }) \MATH ({ 6 }) for ({ 7 }) all ({ 8 }) \MATH ({ 9 }) . ({ 10 }) 
# Sentence pair (1514) source length 23 target length 23 alignment score : 1.94854e-06
In the case of one-feature-based weak classifiers , the histograms of positive and negative samples are computed as follows \MATH where \MATH . 
NULL ({ }) In ({ 1 }) the ({ 2 }) case ({ 3 }) of ({ 4 }) one-feature-based ({ 5 }) weak ({ 6 }) classifier ({ 7 }) , ({ 8 }) the ({ 9 }) histograms ({ 10 }) of ({ 11 }) positive ({ 12 }) and ({ 13 }) negative ({ 14 }) samples ({ 15 }) are ({ 16 }) computed ({ 17 }) as ({ 18 }) follows ({ 19 }) \MATH ({ 20 }) where ({ 21 }) \MATH ({ 22 }) . ({ 23 }) 
# Sentence pair (1515) source length 47 target length 46 alignment score : 3.49909e-11
It is proved in [3] that the most appropriate choice for the prediction of the weak classifier on block \MATH to maximize the margin is \MATH where \MATH is a smoothed value in order to handle cases that \MATH is very small or even zero . 
NULL ({ }) It ({ 1 }) is ({ 2 }) proven ({ 3 }) in ({ 4 }) [3] ({ 5 }) that ({ 6 }) the ({ 7 }) most ({ 8 }) appropriate ({ 9 }) choice ({ 10 }) for ({ 11 }) the ({ 12 }) prediction ({ 13 }) of ({ 14 }) the ({ 15 }) weak ({ 16 }) classifier ({ 17 }) on ({ 18 }) block ({ 19 }) \MATH ({ 20 }) to ({ 21 }) maximize ({ 22 }) the ({ 23 }) margin ({ 24 }) is ({ 25 }) \MATH ({ 26 }) where ({ 27 }) \MATH ({ 28 }) is ({ 29 }) a ({ 30 }) smoothed ({ 31 }) value ({ 32 }) in ({ 33 }) order ({ 34 }) to ({ 35 }) handle ({ 36 }) cases ({ 37 }) in ({ }) which ({ 38 }) \MATH ({ 39 }) is ({ 40 }) very ({ 41 }) small ({ 42 }) or ({ 43 }) even ({ 44 }) zero ({ 45 }) . ({ 46 }) 
# Sentence pair (1516) source length 13 target length 13 alignment score : 0.0103663
A summary of the Real AdaBoost algorithm is given in Algorithm 1 . 
NULL ({ }) A ({ 1 }) summary ({ 2 }) of ({ 3 }) the ({ 4 }) Real ({ 5 }) AdaBoost ({ 6 }) algorithm ({ 7 }) is ({ 8 }) given ({ 9 }) in ({ 10 }) Algorithm ({ 11 }) 1 ({ 12 }) . ({ 13 }) 
# Sentence pair (1517) source length 22 target length 23 alignment score : 4.28269e-10
Real AdaBoost is easy to implement ; however , in practical applications , designing and learning weak classifiers depend on specific applications . 
NULL ({ }) Real ({ 1 }) AdaBoost ({ 2 }) is ({ 3 }) easy ({ 4 }) to ({ 5 }) implement ({ 6 7 8 }) , ({ 9 }) but ({ }) in ({ 10 }) practical ({ 11 }) applications ({ 12 }) , ({ 13 }) designing ({ 14 }) and ({ 15 }) learning ({ 16 }) weak ({ 17 }) classifiers ({ 18 }) depend ({ 19 }) on ({ 20 }) specific ({ 21 }) applications ({ 22 }) . ({ 23 }) 
# Sentence pair (1518) source length 27 target length 20 alignment score : 2.0121e-12
In such face detection systems as [5] ,[6] ,[17] ,[8] , weak classifiers are usually associated with one feature . 
NULL ({ }) In ({ 1 }) such ({ 2 }) face ({ 3 }) detection ({ 4 }) systems ({ 5 }) as ({ 6 }) [those ({ 7 }) described ({ }) in?] ({ 8 }) [5] ({ 9 }) , ({ }) [6] ({ }) , ({ }) [8] ({ 10 }) , ({ }) and ({ }) [17] ({ }) , ({ 11 }) weak ({ 12 }) classifiers ({ 13 }) are ({ 14 }) usually ({ 15 }) associated ({ 16 }) with ({ 17 }) one ({ 18 }) feature ({ 19 }) . ({ 20 }) 
# Sentence pair (1519) source length 37 target length 30 alignment score : 4.31958e-22
With a very large number of available features , hundreds of thousands , there are a lot of choices to choose one weak classifier for each round of boosting . 
NULL ({ 16 }) With ({ 1 }) a ({ 2 }) very ({ 3 }) large ({ 4 }) number ({ 5 }) of ({ 6 }) available ({ 7 }) features ({ 8 }) ? ({ 9 }) hundreds ({ 10 }) of ({ 11 }) thousands ({ 12 }) ? ({ 13 }) [there ({ 14 }) are ({ 15 }) many ({ 17 }) candidates ({ }) from ({ 18 }) which ({ }) to ({ 20 }) / ({ }) many ({ }) choices ({ 19 }) must ({ }) be ({ }) made ({ }) to?] ({ 21 }) select ({ }) one ({ 22 }) weak ({ 23 }) classifier ({ 24 }) for ({ 25 }) each ({ 26 }) round ({ 27 }) of ({ 28 }) boosting ({ 29 }) . ({ 30 }) 
# Sentence pair (1520) source length 16 target length 19 alignment score : 3.7656e-13
Generally , optimally selecting the suitable weak classifier will make the final strong classifier more robust and efficient . 
NULL ({ 2 }) Optimally ({ 1 3 10 }) selecting ({ 4 }) the ({ 5 }) suitable ({ 6 }) weak ({ 7 }) classifier ({ 8 }) makes ({ 9 }) the ({ 11 }) final ({ 12 }) strong ({ 13 }) classifier ({ 14 }) more ({ 15 }) robust ({ 16 }) and ({ 17 }) efficient ({ 18 }) . ({ 19 }) 
# Sentence pair (1521) source length 18 target length 16 alignment score : 8.73556e-08
Furthermore , it can reduce the number of boosting rounds that directly shorten training time . 
NULL ({ }) Furthermore ({ 1 }) , ({ 2 }) optimal ({ 3 }) selection ({ }) can ({ 4 }) reduce ({ 5 }) the ({ 6 }) number ({ 7 }) of ({ 8 }) boosting ({ 9 }) rounds ({ 10 }) , ({ }) thus ({ 11 }) directly ({ 12 }) shortening ({ 13 }) training ({ 14 }) time ({ 15 }) . ({ 16 }) 
# Sentence pair (1522) source length 26 target length 28 alignment score : 5.50844e-15
So far , most current studies have been focused on how to measure the discriminant power of weak classifiers in order to select the best weak classifier . 
NULL ({ 3 }) Most ({ 1 5 }) studies ({ 6 }) so ({ 4 }) far ({ 2 }) have ({ 7 }) been ({ 8 }) focused ({ 9 }) on ({ 10 }) how ({ 11 }) to ({ 12 }) measure ({ 13 }) the ({ 14 }) discriminant ({ 15 }) power ({ 16 }) of ({ 17 }) weak ({ 18 }) classifiers ({ 19 }) in ({ 20 }) order ({ 21 }) to ({ 22 }) select ({ 23 }) the ({ 24 }) best ({ 25 }) weak ({ 26 }) classifier ({ 27 }) . ({ 28 }) 
# Sentence pair (1523) source length 32 target length 33 alignment score : 5.23546e-22
Many measurements have been proposed ; for example , Bhattacharyya distance [6] , Kullback-Leibler divergence [5] and , recently , Jensen-Shannon divergence [8] and mutual information [9] ( cf . Table 1 . 
NULL ({ 18 30 }) Many ({ 1 }) measurements ({ 2 }) have ({ 3 }) been ({ 4 }) proposed ({ 5 }) , ({ 6 }) for ({ 7 }) example ({ 8 }) , ({ 9 }) Bhattacharyya ({ 10 }) distance ({ 11 }) [6] ({ 12 }) , ({ 13 }) Kullback-Leibler ({ 14 }) divergence ({ 15 }) [5] ({ 16 }) , ({ }) and ({ 17 }) recently ({ 19 }) , ({ 20 }) Jensen-Shannon ({ 21 29 }) divergence ({ 22 }) [8] ({ 23 }) and ({ 24 }) mutual ({ 25 }) information ({ 26 }) [9] ({ 27 }) ( ({ 28 }) Table ({ 31 }) 1 ({ 32 }) ) ({ }) . ({ 33 }) 
# Sentence pair (1524) source length 12 target length 12 alignment score : 5.20389e-05
Meanwhile , few studies have been made for efficiently partitioning subspaces . 
NULL ({ }) Meanwhile ({ 1 }) , ({ 2 }) few ({ 3 }) studies ({ 4 }) have ({ 5 }) been ({ 6 }) made ({ 7 }) on ({ 8 }) efficiently ({ 9 }) partitioning ({ 10 }) subspaces ({ 11 }) . ({ 12 }) 
# Sentence pair (1525) source length 27 target length 23 alignment score : 3.52532e-10
As shown in Figure 1 , using a fixed number of bins , strong classifiers trained by above measurements give comparable performance . 
NULL ({ }) As ({ 1 }) shown ({ 2 }) in ({ 3 }) Figure ({ 4 }) 1 ({ 5 }) , ({ 6 }) using ({ 7 }) a ({ 8 }) fixed ({ 9 }) number ({ 10 }) of ({ 11 }) bins ({ 12 }) , ({ 13 }) strong ({ 14 }) classifiers ({ 15 }) trained ({ 16 }) by ({ 17 }) the ({ }) above ({ 18 }) measures ({ }) give ({ 20 }) similar ({ }) performances ({ 22 }) . ({ 23 }) //[measurements ({ 19 }) / ({ }) measures?] ({ 21 }) 
# Sentence pair (1526) source length 21 target length 23 alignment score : 2.18198e-16
However , it will be shown in section 5 , these performances are affected seriously if different subspace splitting methods are used . 
NULL ({ 5 7 }) However ({ 1 }) , ({ 2 }) as ({ 3 }) section ({ 8 }) 5 ({ 9 }) will ({ 4 }) show ({ 6 }) , ({ 10 }) these ({ 11 }) performances ({ 12 }) are ({ 13 }) affected ({ 14 }) dramatically ({ 15 }) if ({ 16 }) different ({ 17 }) subspace ({ 18 }) splitting ({ 19 }) methods ({ 20 }) are ({ 21 }) used ({ 22 }) . ({ 23 }) 
# Sentence pair (1527) source length 24 target length 22 alignment score : 6.29386e-06
The proposed boosting scheme Ent-Boost is an integration of adaptive entropy-based subspace splitting and the symmetric KL divergence-based weak classifier selection . 
NULL ({ }) The ({ 1 }) proposed ({ 2 }) boosting ({ 3 }) scheme ({ 4 }) , ({ }) Ent-Boost ({ 5 }) , ({ }) is ({ 6 }) an ({ 7 }) integration ({ 8 }) of ({ 9 }) adaptive ({ 10 }) entropy-based ({ 11 }) subspace ({ 12 }) splitting ({ 13 }) and ({ 14 }) the ({ 15 }) symmetric ({ 16 }) KL ({ 17 }) divergence-based ({ 18 }) weak ({ 19 }) classifier ({ 20 }) selection ({ 21 }) . ({ 22 }) 
# Sentence pair (1528) source length 25 target length 23 alignment score : 5.14811e-09
In Ent-Boost , each weak classifier is constructed from one feature and trained on the weighted training samples similar to Real AdaBoost . 
NULL ({ 15 }) In ({ 1 }) Ent-Boost ({ 2 }) , ({ 3 }) each ({ 4 }) weak ({ 5 }) classifier ({ 6 }) is ({ 7 }) constructed ({ 8 }) from ({ 9 }) one ({ 10 }) feature ({ 11 }) and ({ 12 }) trained ({ 13 }) on ({ 14 }) weighted ({ 16 }) training ({ 17 }) samples ({ 18 }) similar ({ 19 }) to ({ 20 }) [those ({ }) used ({ }) in?] ({ }) Real ({ 21 }) AdaBoost ({ 22 }) . ({ 23 }) 
# Sentence pair (1529) source length 45 target length 40 alignment score : 1.2146e-20
However , instead of using equal-width binning method like Real AdaBoost [6] ,[17] which is hard to know the suitable number of bins in advance , we use entropy-based discretization method [19] to split the input space into subspaces . 
NULL ({ 17 }) However ({ 1 }) , ({ 2 }) instead ({ 3 }) of ({ 4 }) using ({ 5 }) the ({ }) equal-width ({ 6 }) binning ({ 7 9 }) method ({ 8 }) used ({ }) in ({ }) Real ({ 10 }) AdaBoost ({ 11 }) [6] ({ 12 }) , ({ }) [17] ({ 13 }) which ({ 14 }) has ({ 15 }) a ({ }) hard ({ 16 }) time ({ }) predicting ({ 18 }) the ({ 19 }) suitable ({ 20 }) number ({ 21 }) of ({ 22 }) bins ({ 23 }) in ({ 24 }) advance ({ 25 }) , ({ 26 }) we ({ 27 }) use ({ 28 }) the ({ }) entropy-based ({ 29 }) discretization ({ 30 }) method ({ 31 }) [19] ({ 32 }) to ({ 33 }) split ({ 34 }) the ({ 35 }) input ({ 36 }) space ({ 37 }) into ({ 38 }) subspaces ({ 39 }) . ({ 40 }) 
# Sentence pair (1530) source length 39 target length 33 alignment score : 4.30412e-34
This subspace splitting process is totally automatically in which the stopping criteria of splitting process is determined through using Minimum Description Length Principles ( MDLP ) ( see the next section ) . 
NULL ({ 29 }) This ({ 1 }) subspace ({ 2 }) splitting ({ 3 }) process ({ 4 }) is ({ 5 }) totally ({ 6 }) automatic ({ 7 }) ; ({ 9 }) the ({ 10 }) stopping ({ 11 }) criteria ({ 12 }) of ({ 13 }) the ({ }) splitting ({ 14 }) process ({ 15 }) are ({ 16 }) determined ({ 17 18 }) using ({ 19 }) minimum ({ 20 }) description ({ 21 }) length ({ 22 }) principles ({ 23 }) ( ({ 24 }) MDLP ({ 25 }) ) ({ 26 }) . ({ }) This ({ 27 }) process ({ 28 }) will ({ }) be ({ }) described ({ }) in ({ }) greater ({ 32 }) detail ({ }) in ({ 8 }) the ({ }) next ({ 30 }) section ({ 31 }) . ({ 33 }) 
# Sentence pair (1531) source length 46 target length 45 alignment score : 1.04131e-08
To select the best weak classifier from the input weak classifier set , we use symmetric KL divergence as in [5] which measures the distance between two distributions as follows : \MATH where \MATH and \MATH are probability distributions of a discrete random variable . 
NULL ({ }) To ({ 1 }) select ({ 2 }) the ({ 3 }) best ({ 4 }) weak ({ 5 }) classifier ({ 6 }) from ({ 7 }) the ({ 8 }) input ({ 9 }) weak ({ 10 }) classifier ({ 11 }) set ({ 12 }) , ({ 13 }) we ({ 14 }) use ({ 15 }) symmetric ({ 16 }) KL ({ 17 }) divergence ({ 18 }) as ({ 19 }) in ({ 20 }) [5] ({ 21 }) , ({ }) which ({ 22 }) measures ({ 23 }) the ({ 24 }) distance ({ 25 }) between ({ 26 }) two ({ 27 }) distributions ({ 28 }) as ({ 29 }) follows ({ 30 }) : ({ 31 }) \MATH ({ 32 }) where ({ 33 }) \MATH ({ 34 }) and ({ 35 }) \MATH ({ 36 }) are ({ 37 }) probability ({ 38 }) distributions ({ 39 }) of ({ 40 }) a ({ 41 }) discrete ({ 42 }) random ({ 43 }) variable ({ 44 }) . ({ 45 }) 
# Sentence pair (1532) source length 28 target length 29 alignment score : 1.25503e-06
This formula can be rewritten in entropy terms : \MATH or \MATH where \MATH and \MATH are entropy , and \MATH is cross entropy of \MATH and \MATH . 
NULL ({ 19 }) This ({ 1 }) formula ({ 2 }) can ({ 3 }) be ({ 4 }) rewritten ({ 5 }) in ({ 6 }) entropy ({ 7 }) terms ({ 8 }) : ({ 9 }) \MATH ({ 10 }) or ({ 11 }) \MATH ({ 12 }) where ({ 13 }) \MATH ({ 14 }) and ({ 15 }) \MATH ({ 16 }) are ({ 17 }) entropy ({ 18 }) and ({ 20 }) \MATH ({ 21 }) is ({ 22 }) cross ({ 23 }) entropy ({ 24 }) of ({ 25 }) \MATH ({ 26 }) and ({ 27 }) \MATH ({ 28 }) . ({ 29 }) 
# Sentence pair (1533) source length 10 target length 10 alignment score : 0.0322858
The outline of Ent-Boost is shown in Algorithm 2 . 
NULL ({ }) The ({ 1 }) outline ({ 2 }) of ({ 3 }) Ent-Boost ({ 4 }) is ({ 5 }) shown ({ 6 }) in ({ 7 }) Algorithm ({ 8 }) 2 ({ 9 }) . ({ 10 }) 
# Sentence pair (1534) source length 20 target length 20 alignment score : 0.000227657
Note that the discretization process is performed in every round of boosting to adapt to new distributions of samples . 
NULL ({ }) Note ({ 1 }) that ({ 2 }) the ({ 3 }) discretization ({ 4 }) process ({ 5 }) is ({ 6 }) performed ({ 7 }) in ({ 8 }) every ({ 9 }) round ({ 10 }) of ({ 11 }) boosting ({ 12 }) to ({ 13 }) adapt ({ 14 }) to ({ 15 }) new ({ 16 }) distributions ({ 17 }) of ({ 18 }) samples ({ 19 }) . ({ 20 }) 
# Sentence pair (1535) source length 20 target length 14 alignment score : 1.82728e-10
As a result , the number of intervals of selected weak classifier varies . 
NULL ({ }) As ({ 1 }) a ({ 2 }) result ({ 3 }) , ({ 4 }) the ({ 5 }) number ({ 6 }) of ({ 7 }) intervals ({ 8 }) of ({ 9 }) the ({ }) selected ({ 10 }) weak ({ 11 }) classifier ({ 12 }) varies ({ 13 }) . ({ 14 }) //[classifier ({ }) varies ({ }) / ({ }) classifiers ({ }) vary?] ({ }) 
# Sentence pair (1536) source length 17 target length 16 alignment score : 1.15969e-05
This is different from previous methods that fix the number of equal-width intervals in advance . 
NULL ({ }) This ({ 1 }) is ({ 2 }) different ({ 3 }) from ({ 4 }) previous ({ 5 }) methods ({ 6 }) , ({ }) which ({ 7 }) fix ({ 8 }) the ({ 9 }) number ({ 10 }) of ({ 11 }) equal-width ({ 12 }) intervals ({ 13 }) in ({ 14 }) advance ({ 15 }) . ({ 16 }) 
# Sentence pair (1537) source length 11 target length 14 alignment score : 3.98322e-14
This section gives a brief introduction on automatic subspace splitting using entropy-based discretization . 
NULL ({ 4 7 }) This ({ 1 }) section ({ 2 }) briefly ({ 3 6 }) describes ({ 5 }) automatic ({ 8 }) subspace ({ 9 }) splitting ({ 10 }) using ({ 11 }) entropy-based ({ 12 }) discretization ({ 13 }) . ({ 14 }) 
# Sentence pair (1538) source length 21 target length 23 alignment score : 5.0702e-17
Basically , discretization is a quantizing process that converts continuous values into discrete values ; it typically consists of four steps [18] : 
NULL ({ 2 }) Discretization ({ 1 3 }) is ({ 4 }) a ({ 5 }) quantizing ({ 6 }) process ({ 7 }) that ({ 8 }) converts ({ 9 }) continuous ({ 10 }) values ({ 11 }) into ({ 12 }) discrete ({ 13 }) values ({ 14 }) . ({ 15 }) It ({ 16 }) typically ({ 17 }) consists ({ 18 }) of ({ 19 }) four ({ 20 }) steps ({ 21 }) [18] ({ 22 }) . ({ 23 }) 
# Sentence pair (1539) source length 14 target length 14 alignment score : 0.00676668
Step 1 : Sorting the continuous values of the feature to be discretized . 
NULL ({ }) Step ({ 1 }) 1 ({ 2 }) : ({ 3 }) Sorting ({ 4 }) the ({ 5 }) continuous ({ 6 }) values ({ 7 }) of ({ 8 }) the ({ 9 }) feature ({ 10 }) to ({ 11 }) be ({ 12 }) discretized ({ 13 }) . ({ 14 }) 
# Sentence pair (1540) source length 14 target length 14 alignment score : 0.00245163
Step 2 : valuating candidate cut-points and selecting the best cut-point for splitting . 
NULL ({ }) Step ({ 1 }) 2 ({ 2 }) : ({ 3 }) Evaluating ({ 4 }) candidate ({ 5 }) cut-points ({ 6 }) and ({ 7 }) selecting ({ 8 }) the ({ 9 }) best ({ 10 }) cut-point ({ 11 }) for ({ 12 }) splitting ({ 13 }) . ({ 14 }) 
# Sentence pair (1541) source length 38 target length 38 alignment score : 2.98733e-07
A cut-point is a threshold value that divides the range of continuous values into two intervals ; one interval is less than or equal to the threshold , and the other interval is greater than the threshold . 
NULL ({ }) A ({ 1 }) cut-point ({ 2 }) is ({ 3 }) a ({ 4 }) threshold ({ 5 }) value ({ 6 }) that ({ 7 }) divides ({ 8 }) the ({ 9 }) range ({ 10 }) of ({ 11 }) continuous ({ 12 }) values ({ 13 }) into ({ 14 }) two ({ 15 }) intervals ({ 16 }) ; ({ 17 }) one ({ 18 }) interval ({ 19 }) is ({ 20 }) less ({ 21 }) than ({ 22 }) or ({ 23 }) equal ({ 24 }) to ({ 25 }) the ({ 26 }) threshold ({ 27 }) , ({ 28 }) and ({ 29 }) the ({ 30 }) other ({ 31 }) interval ({ 32 }) is ({ 33 }) greater ({ 34 }) than ({ 35 }) the ({ 36 }) threshold ({ 37 }) . ({ 38 }) 
# Sentence pair (1542) source length 17 target length 17 alignment score : 2.59119e-07
Step 3 : Splitting the data into two intervals using the selected cut-point in step 2 . 
NULL ({ }) Step ({ 1 }) 3 ({ 2 }) : ({ 3 }) Splitting ({ 4 }) the ({ 5 }) data ({ 6 }) into ({ 7 }) two ({ 8 }) intervals ({ 9 }) using ({ 10 }) the ({ 11 }) cut-point ({ 13 }) selected ({ 12 }) in ({ 14 }) step ({ 15 }) 2 ({ 16 }) . ({ 17 }) 
# Sentence pair (1543) source length 15 target length 15 alignment score : 0.00470149
Step 4 : Continuing discretization with each interval until a stopping criteria is satisfied . 
NULL ({ }) Step ({ 1 }) 4 ({ 2 }) : ({ 3 }) Continuing ({ 4 }) discretization ({ 5 }) with ({ 6 }) each ({ 7 }) interval ({ 8 }) until ({ 9 }) a ({ 10 }) stopping ({ 11 }) criteria ({ 12 }) is ({ 13 }) satisfied ({ 14 }) . ({ 15 }) 
# Sentence pair (1544) source length 34 target length 34 alignment score : 3.26386e-11
The stopping criteria are usually selected according to a trade-off between lower arity ( the number of intervals or the number of bins ) and its effect on the accuracy of classification tasks . 
NULL ({ 8 }) The ({ 1 }) stopping ({ 2 }) criteria ({ 3 }) are ({ 4 }) usually ({ 5 }) selected ({ 6 }) by ({ }) considering ({ 7 }) a ({ 9 }) trade-off ({ 10 }) between ({ 11 }) lower ({ 12 }) arity ({ 13 }) ( ({ 14 }) the ({ 15 }) number ({ 16 }) of ({ 17 }) intervals ({ 18 }) or ({ 19 }) the ({ 20 }) number ({ 21 }) of ({ 22 }) bins ({ 23 }) ) ({ 24 }) and ({ 25 }) its ({ 26 }) effect ({ 27 }) on ({ 28 }) the ({ 29 }) accuracy ({ 30 }) of ({ 31 }) classification ({ 32 }) tasks ({ 33 }) . ({ 34 }) 
# Sentence pair (1545) source length 23 target length 24 alignment score : 2.89051e-12
A higher arity can make the understanding of an attribute more difficult , while a very low arity may affect predictive accuracy negatively . 
NULL ({ }) A ({ 1 }) higher ({ 2 }) arity ({ 3 }) can ({ 4 }) make ({ 5 }) the ({ 6 }) complicate ({ 23 }) the ({ }) understanding ({ 7 }) of ({ 8 }) an ({ 9 }) attribute ({ 10 11 12 }) , ({ 13 }) while ({ 14 }) a ({ 15 }) very ({ 16 }) low ({ 17 }) arity ({ 18 }) may ({ 19 }) damage ({ 20 }) predictive ({ 21 }) accuracy ({ 22 }) . ({ 24 }) 
# Sentence pair (1546) source length 24 target length 24 alignment score : 0.000283173
Given a set \MATH of sorted continuous values \MATH , candidate cut-points are usually selected as mid-points of every successive pair of \MATH . 
NULL ({ }) Given ({ 1 }) a ({ 2 }) set ({ 3 }) \MATH ({ 4 }) of ({ 5 }) sorted ({ 6 }) continuous ({ 7 }) values ({ 8 }) \MATH ({ 9 }) , ({ 10 }) candidate ({ 11 }) cut-points ({ 12 }) are ({ 13 }) usually ({ 14 }) selected ({ 15 }) as ({ 16 }) mid-points ({ 17 }) of ({ 18 }) every ({ 19 }) successive ({ 20 }) pair ({ 21 }) of ({ 22 }) \MATH ({ 23 }) . ({ 24 }) 
# Sentence pair (1547) source length 10 target length 10 alignment score : 0.02975
On the other hand , candidate cut-points are \MATH . 
NULL ({ }) On ({ 1 }) the ({ 2 }) other ({ 3 }) hand ({ 4 }) , ({ 5 }) candidate ({ 6 }) cut-points ({ 7 }) are ({ 8 }) \MATH ({ 9 }) . ({ 10 }) 
# Sentence pair (1548) source length 47 target length 47 alignment score : 4.40316e-08
For each cut-point \MATH that splits set \MATH into two subsets \MATH , the class entropy of a subset \MATH is defined as \MATH where \MATH is the number of classes \MATH , and \MATH is the proportion of examples in \MATH that have class \MATH . 
NULL ({ }) For ({ 1 }) each ({ 2 }) cut-point ({ 3 }) \MATH ({ 4 }) that ({ 5 }) splits ({ 6 }) set ({ 7 }) \MATH ({ 8 }) into ({ 9 }) two ({ 10 }) subsets ({ 11 }) \MATH ({ 12 }) , ({ 13 }) the ({ 14 }) class ({ 15 }) entropy ({ 16 }) of ({ 17 }) a ({ 18 }) subset ({ 19 }) \MATH ({ 20 }) is ({ 21 }) defined ({ 22 }) as ({ 23 }) \MATH ({ 24 }) where ({ 25 }) \MATH ({ 26 }) is ({ 27 }) the ({ 28 }) number ({ 29 }) of ({ 30 }) classes ({ 31 }) \MATH ({ 32 }) , ({ 33 }) and ({ 34 }) \MATH ({ 35 }) is ({ 36 }) the ({ 37 }) proportion ({ 38 }) of ({ 39 }) examples ({ 40 }) in ({ 41 }) \MATH ({ 42 }) that ({ 43 }) have ({ 44 }) class ({ 45 }) \MATH ({ 46 }) . ({ 47 }) 
# Sentence pair (1549) source length 63 target length 63 alignment score : 5.47394e-12
To evaluate the resulting class entropy after set \MATH is partitioned into two sets \MATH and \MATH , the class-information entropy of the partition induced by cut-point T is defined by taking the weighted average of their resulting class entropies \MATH he best cut-point selected in step 2 is the cut-point \MATH for which \MATH is minimal amongst all the candidate cut-points . 
NULL ({ }) To ({ 1 }) evaluate ({ 2 }) the ({ 3 }) resulting ({ 4 }) class ({ 5 }) entropy ({ 6 }) after ({ 7 }) set ({ 8 }) \MATH ({ 9 }) is ({ 10 }) partitioned ({ 11 }) into ({ 12 }) two ({ 13 }) sets ({ 14 }) \MATH ({ 15 }) and ({ 16 }) \MATH ({ 17 }) , ({ 18 }) the ({ 19 }) class-information ({ 20 }) entropy ({ 21 }) of ({ 22 }) the ({ 23 }) partition ({ 24 }) induced ({ 25 }) by ({ 26 }) cut-point ({ 27 }) T ({ 28 }) is ({ 29 }) defined ({ 30 }) by ({ 31 }) taking ({ 32 }) the ({ 33 }) weighted ({ 34 }) average ({ 35 }) of ({ 36 }) their ({ 37 }) resulting ({ 38 }) class ({ 39 }) entropies ({ 40 }) \MATH ({ 41 }) he ({ 42 }) best ({ 43 }) cut-point ({ 44 }) selected ({ 45 }) in ({ 46 }) step ({ 47 }) 2 ({ 48 }) is ({ 49 }) the ({ 50 }) cut-point ({ 51 }) \MATH ({ 52 }) for ({ 53 }) which ({ 54 }) \MATH ({ 55 }) is ({ 56 }) minimal ({ 57 }) amongst ({ 58 }) all ({ 59 }) the ({ 60 }) candidate ({ 61 }) cut-points ({ 62 }) . ({ 63 }) 
# Sentence pair (1550) source length 35 target length 36 alignment score : 3.78882e-08
Given set S and a potential binary partition , \MATH , specified on S by the given cut-point \MATH , a stopping criteria is used to decide whether or not this partition should be accepted . 
NULL ({ 9 }) Given ({ 1 }) set ({ 2 }) S ({ 3 }) and ({ 4 }) a ({ 5 }) potential ({ 6 }) binary ({ 7 }) partition ({ 8 }) \MATH ({ 10 }) , ({ 11 }) specified ({ 12 }) on ({ 13 }) S ({ 14 }) by ({ 15 }) the ({ 16 }) given ({ 17 }) cut-point ({ 18 }) \MATH ({ 19 }) , ({ 20 }) a ({ 21 }) stopping ({ 22 }) criteria ({ 23 }) is ({ 24 }) used ({ 25 }) to ({ 26 }) decide ({ 27 }) whether ({ 28 }) or ({ 29 }) not ({ 30 }) this ({ 31 }) partition ({ 32 }) should ({ 33 }) be ({ 34 }) accepted ({ 35 }) . ({ 36 }) 
# Sentence pair (1551) source length 25 target length 25 alignment score : 1.08887e-05
If the answer is YES , the discretization will continue with each partition given by \MATH ; otherwise , the discretization process will stop . 
NULL ({ }) If ({ 1 }) the ({ 2 }) answer ({ 3 }) is ({ 4 }) YES ({ 5 }) , ({ 6 }) the ({ 7 }) discretization ({ 8 }) will ({ 9 }) continue ({ 10 }) with ({ 11 }) each ({ 12 }) partition ({ 13 }) given ({ 14 }) by ({ 15 }) \MATH ({ 16 }) ; ({ 17 }) otherwise ({ 18 }) , ({ 19 }) the ({ 20 }) discretization ({ 21 }) process ({ 22 }) will ({ 23 }) stop ({ 24 }) . ({ 25 }) 
# Sentence pair (1552) source length 20 target length 20 alignment score : 2.16331e-05
Suppose \MATH is the probability of a \MATH answer , and \MATH is the probability of the \MATH answer . 
NULL ({ }) Suppose ({ 1 }) \MATH ({ 2 }) is ({ 3 }) the ({ 4 }) probability ({ 5 }) of ({ 6 }) a ({ 7 }) \MATH ({ 8 }) answer ({ 9 }) , ({ 10 }) and ({ 11 }) \MATH ({ 12 }) is ({ 13 }) the ({ 14 }) probability ({ 15 }) of ({ 16 }) a ({ 17 }) \MATH ({ 18 }) answer ({ 19 }) . ({ 20 }) 
# Sentence pair (1553) source length 8 target length 8 alignment score : 0.0765703
Partition \MATH is only accepted if \MATH . 
NULL ({ }) Partition ({ 1 }) \MATH ({ 2 }) is ({ 3 }) only ({ 4 }) accepted ({ 5 }) if ({ 6 }) \MATH ({ 7 }) . ({ 8 }) 
# Sentence pair (1554) source length 16 target length 16 alignment score : 0.00337517
However , in practice , there is no easy way to estimate these probabilities directly . 
NULL ({ }) However ({ 1 }) , ({ 2 }) in ({ 3 }) practice ({ 4 }) , ({ 5 }) there ({ 6 }) is ({ 7 }) no ({ 8 }) easy ({ 9 }) way ({ 10 }) to ({ 11 }) estimate ({ 12 }) these ({ 13 }) probabilities ({ 14 }) directly ({ 15 }) . ({ 16 }) 
# Sentence pair (1555) source length 14 target length 14 alignment score : 0.00570905
Instead , Fayyad and Irani [19] proposed using MDLP to indirectly estimate them . 
NULL ({ }) Instead ({ 1 }) , ({ 2 }) Fayyad ({ 3 }) and ({ 4 }) Irani ({ 5 }) [19] ({ 6 }) proposed ({ 7 }) using ({ 8 }) MDLP ({ 9 }) to ({ 10 }) indirectly ({ 11 }) estimate ({ 12 }) them ({ 13 }) . ({ 14 }) 
# Sentence pair (1556) source length 29 target length 31 alignment score : 5.05417e-12
Originally , the minimum description length of an object is defined as the minimum number of bits required to uniquely specify that object out of the universe of all objects . 
NULL ({ 2 3 }) The ({ 1 }) minimum ({ 4 }) description ({ 5 }) length ({ 6 }) of ({ 7 }) an ({ 8 }) object ({ 9 }) is ({ 10 }) defined ({ 11 }) as ({ 12 }) the ({ 13 }) minimum ({ 14 }) number ({ 15 }) of ({ 16 }) bits ({ 17 }) required ({ 18 }) to ({ 19 }) uniquely ({ 20 }) specify ({ 21 }) that ({ 22 }) object ({ 23 }) out ({ 24 }) of ({ 25 }) the ({ 26 }) universe ({ 27 }) of ({ 28 }) all ({ 29 }) objects ({ 30 }) . ({ 31 }) 
# Sentence pair (1557) source length 27 target length 27 alignment score : 4.8276e-05
To employ MDLP in choosing the stopping criteria , Fayyad and Irani formulated the above problem as a communication problem between a sender and a receiver . 
NULL ({ }) To ({ 1 }) employ ({ 2 }) MDLP ({ 3 }) in ({ 4 }) choosing ({ 5 }) the ({ 6 }) stopping ({ 7 }) criteria ({ 8 }) , ({ 9 }) Fayyad ({ 10 }) and ({ 11 }) Irani ({ 12 }) formulated ({ 13 }) the ({ 14 }) above ({ 15 }) problem ({ 16 }) as ({ 17 }) a ({ 18 }) communication ({ 19 }) problem ({ 20 }) between ({ 21 }) a ({ 22 }) sender ({ 23 }) and ({ 24 }) a ({ 25 }) receiver ({ 26 }) . ({ 27 }) 
# Sentence pair (1558) source length 25 target length 25 alignment score : 7.82982e-06
It is assumed that the sender has the entire set of training examples , while the receiver has the examples without their class labels . 
NULL ({ }) It ({ 1 }) is ({ 2 }) assumed ({ 3 }) that ({ 4 }) the ({ 5 }) sender ({ 6 }) has ({ 7 }) the ({ 8 }) entire ({ 9 }) set ({ 10 }) of ({ 11 }) training ({ 12 }) examples ({ 13 }) , ({ 14 }) while ({ 15 }) the ({ 16 }) receiver ({ 17 }) has ({ 18 }) the ({ 19 }) examples ({ 20 }) without ({ 21 }) their ({ 22 }) class ({ 23 }) labels ({ 24 }) . ({ 25 }) 
# Sentence pair (1559) source length 20 target length 17 alignment score : 3.0631e-08
The sender needs to convey to proper class labeling of the example set to the receiver . 
NULL ({ }) The ({ 1 }) sender ({ 2 }) needs ({ 3 }) to ({ 4 }) convey ({ 5 }) needed ({ 6 }) information ({ }) for ({ }) the ({ }) proper ({ 7 }) class ({ 8 }) labeling ({ 9 }) of ({ 10 }) the ({ 11 }) example ({ 12 }) set ({ 13 }) to ({ 14 }) the ({ 15 }) receiver ({ 16 }) . ({ 17 }) 
# Sentence pair (1560) source length 43 target length 39 alignment score : 5.45144e-10
It says that the partition induced by a cut-point is accepted if and only if the length of the message required to send before partition is more than the length of the message required to send after partition . 
NULL ({ }) It ({ 1 }) says ({ 2 }) that ({ 3 }) the ({ 4 }) partition ({ 5 }) induced ({ 6 }) by ({ 7 }) a ({ 8 }) cut-point ({ 9 }) is ({ 10 }) accepted ({ 11 }) if ({ 12 }) and ({ 13 }) only ({ 14 }) if ({ 15 }) the ({ 16 }) length ({ 17 }) of ({ 18 }) the ({ 19 }) message ({ 20 }) required ({ 21 }) to ({ 22 }) be ({ }) sent ({ 23 }) before ({ 24 }) the ({ }) partition ({ 25 }) is ({ 26 }) more ({ 27 }) than ({ 28 }) the ({ 29 }) length ({ 30 }) of ({ 31 }) the ({ 32 }) message ({ 33 }) required ({ 34 }) to ({ 35 }) be ({ }) sent ({ 36 }) after ({ 37 }) the ({ }) partition ({ 38 }) . ({ 39 }) 
# Sentence pair (1561) source length 33 target length 33 alignment score : 1.52496e-05
By inferring from coding hypothesis , the stopping criteria is defined as follows : MDLP Criteria :A partition induced by cut-point \MATH for a set \MATH of \MATH examples is accepted iff :\MATH 
NULL ({ }) By ({ 1 }) inferring ({ 2 }) from ({ 3 }) coding ({ 4 }) hypothesis ({ 5 }) , ({ 6 }) the ({ 7 }) stopping ({ 8 }) criteria ({ 9 }) is ({ 10 }) defined ({ 11 }) as ({ 12 }) follows ({ 13 }) : ({ 14 }) MDLP ({ 15 }) Criteria ({ 16 }) :A ({ 17 }) partition ({ 18 }) induced ({ 19 }) by ({ 20 }) cut-point ({ 21 }) \MATH ({ 22 }) for ({ 23 }) a ({ 24 }) set ({ 25 }) \MATH ({ 26 }) of ({ 27 }) \MATH ({ 28 }) examples ({ 29 }) is ({ 30 }) accepted ({ 31 }) iff ({ 32 }) :\MATH ({ 33 }) 
# Sentence pair (1562) source length 41 target length 39 alignment score : 3.98484e-10
where \MATH and \MATH \MATH is the number of classes in \MATH Extensive experiments [19] ,[18] recommended that this method should be the first choice for variable discretization because it gives small number of cut-points while maintaining consistency . 
NULL ({ }) where ({ 1 }) \MATH ({ 2 }) and ({ 3 }) \MATH ({ 4 }) where\MATH ({ 5 }) is ({ 6 }) the ({ 7 }) number ({ 8 }) of ({ 9 }) classes ({ 10 }) in ({ 11 }) \MATH ({ 12 }) Extensive ({ 13 }) experiments ({ 14 }) [18] ({ 15 }) , ({ }) [19] ({ 16 }) recommended ({ 17 }) that ({ 18 }) this ({ 19 }) method ({ 20 }) should ({ 21 }) be ({ 22 }) the ({ 23 }) first ({ 24 }) choice ({ 25 }) for ({ 26 }) variable ({ 27 }) discretization ({ 28 }) because ({ 29 }) it ({ 30 }) gives ({ 31 }) a ({ }) small ({ 32 }) number ({ 33 }) of ({ 34 }) cut-points ({ 35 }) while ({ 36 }) maintaining ({ 37 }) consistency ({ 38 }) . ({ 39 }) 
# Sentence pair (1563) source length 18 target length 12 alignment score : 6.79529e-10
For experiments , face and non-face patterns are of size 24x24 . 
NULL ({ }) For ({ 1 }) our ({ }) experiments ({ 2 }) , ({ 3 }) face ({ 4 }) and ({ 5 }) non-face ({ 6 }) patterns ({ 7 }) were ({ 8 }) of ({ 9 }) size ({ 10 }) 24x24 ({ 11 }) . ({ 12 }) //[what ({ }) is ({ }) the ({ }) unit ({ }) here?] ({ }) 
# Sentence pair (1564) source length 13 target length 13 alignment score : 0.005342
A set of 10 ,000 face patterns were collected from the Internet . 
NULL ({ }) A ({ 1 }) set ({ 2 }) of ({ 3 }) 10 ({ 4 }) ,000 ({ 5 }) face ({ 6 }) patterns ({ 7 }) were ({ 8 }) collected ({ 9 }) from ({ 10 }) the ({ 11 }) Internet ({ 12 }) . ({ 13 }) 
# Sentence pair (1565) source length 50 target length 50 alignment score : 1.22819e-08
Another set of 10 ,000 hard non-face patterns were false positives collected by running a cascade of 17 AdaBoost classifiers at different locations and scales on 8 ,440 images with various subjects , such as rocks , trees , buildings , scenery , and flowers , containing no faces . 
NULL ({ }) Another ({ 1 }) set ({ 2 }) of ({ 3 }) 10 ({ 4 }) ,000 ({ 5 }) hard ({ 6 }) non-face ({ 7 }) patterns ({ 8 }) were ({ 9 }) false ({ 10 }) positives ({ 11 }) collected ({ 12 }) by ({ 13 }) running ({ 14 }) a ({ 15 }) cascade ({ 16 }) of ({ 17 }) 17 ({ 18 }) AdaBoost ({ 19 }) classifiers ({ 20 }) at ({ 21 }) different ({ 22 }) locations ({ 23 }) and ({ 24 }) scales ({ 25 }) on ({ 26 }) 8 ({ 27 }) ,440 ({ 28 }) images ({ 29 }) with ({ 30 }) various ({ 31 }) subjects ({ 32 }) , ({ 33 }) such ({ 34 }) as ({ 35 }) rocks ({ 36 }) , ({ 37 }) trees ({ 38 }) , ({ 39 }) buildings ({ 40 }) , ({ 41 }) scenery ({ 42 }) , ({ 43 }) and ({ 44 }) flowers ({ 45 }) , ({ 46 }) containing ({ 47 }) no ({ 48 }) faces ({ 49 }) . ({ 50 }) 
# Sentence pair (1566) source length 26 target length 26 alignment score : 3.83491e-05
The 10 ,000 patterns in each set are divided into a training set of 6 ,000 patterns and a test set of 4 ,000 examples . 
NULL ({ }) The ({ 1 }) 10 ({ 2 }) ,000 ({ 3 }) patterns ({ 4 }) in ({ 5 }) each ({ 6 }) set ({ 7 }) were ({ 8 }) divided ({ 9 }) into ({ 10 }) a ({ 11 }) training ({ 12 }) set ({ 13 }) of ({ 14 }) 6 ({ 15 }) ,000 ({ 16 }) patterns ({ 17 }) and ({ 18 }) a ({ 19 }) test ({ 20 }) set ({ 21 }) of ({ 22 }) 4 ({ 23 }) ,000 ({ 24 }) examples ({ 25 }) . ({ 26 }) 
# Sentence pair (1567) source length 16 target length 16 alignment score : 0.00379283
Some examples of the collected 24x24 face and non-face patterns are shown in Figure 2 . 
NULL ({ }) Some ({ 1 }) examples ({ 2 }) of ({ 3 }) the ({ 4 }) collected ({ 5 }) 24x24 ({ 6 }) face ({ 7 }) and ({ 8 }) non-face ({ 9 }) patterns ({ 10 }) are ({ 11 }) shown ({ 12 }) in ({ 13 }) Figure ({ 14 }) 2 ({ 15 }) . ({ 16 }) 
# Sentence pair (1568) source length 25 target length 22 alignment score : 3.41002e-20
Haar wavelet feature that has been widely used in many face detection systems [4] ,[6] ,[14] is used in our experiments . 
NULL ({ 17 }) Haar ({ 1 }) wavelet ({ 2 }) features ({ 3 }) , ({ }) which ({ 4 }) have ({ 5 }) been ({ 6 7 }) used ({ 8 }) in ({ 9 }) many ({ 10 }) face ({ 11 }) detection ({ 12 }) systems ({ 13 }) [4] ({ 14 }) , ({ }) [6] ({ 15 }) , ({ }) [14] ({ 16 }) , ({ }) were ({ }) used ({ 18 }) in ({ 19 }) our ({ 20 }) experiments ({ 21 }) . ({ 22 }) 
# Sentence pair (1569) source length 19 target length 19 alignment score : 2.80256e-05
It consists of four kinds of features modeled from adjacent basic rectangles with the same size and shape . 
NULL ({ }) These ({ 1 }) consisted ({ 2 }) of ({ 3 }) four ({ 4 }) kinds ({ 5 }) of ({ 6 }) features ({ 7 }) modeled ({ 8 }) from ({ 9 }) adjacent ({ 10 }) basic ({ 11 }) rectangles ({ 12 }) with ({ 13 }) the ({ 14 }) same ({ 15 }) size ({ 16 }) and ({ 17 }) shape ({ 18 }) . ({ 19 }) 
# Sentence pair (1570) source length 21 target length 22 alignment score : 1.57807e-12
The feature value is defined as the difference of sum of the pixels within rectangles ( cf . Figure 3 ) . 
NULL ({ 18 }) The ({ 1 }) feature ({ 2 }) value ({ 3 }) was ({ 4 }) defined ({ 5 }) as ({ 6 }) the ({ 7 }) difference ({ 8 }) of ({ 9 }) the ({ }) sum ({ 10 }) of ({ 11 }) the ({ 12 }) pixels ({ 13 }) within ({ 14 }) rectangles ({ 15 17 }) ( ({ 16 }) Figure ({ 19 }) 3 ({ 20 }) ) ({ 21 }) . ({ 22 }) 
# Sentence pair (1571) source length 12 target length 12 alignment score : 0.00945236
In total , 134 ,736 features were used for training classifiers . 
NULL ({ }) In ({ 1 }) total ({ 2 }) , ({ 3 }) 134 ({ 4 }) ,736 ({ 5 }) features ({ 6 }) were ({ 7 }) used ({ 8 }) for ({ 9 }) training ({ 10 }) classifiers ({ 11 }) . ({ 12 }) 
# Sentence pair (1572) source length 28 target length 26 alignment score : 1.15732e-12
Figure 4 shows a comparison of performances of strong classifiers trained by different boosting schemes that are AdaBoost [4] , Real AdaBoost [17] and Ent-Boost . 
NULL ({ 16 17 }) Figure ({ 1 }) 4 ({ 2 }) shows ({ 3 }) a ({ 4 }) comparison ({ 5 }) of ({ 6 }) the ({ }) performances ({ 7 }) of ({ 8 }) strong ({ 9 }) classifiers ({ 10 }) trained ({ 11 }) by ({ 12 }) the ({ }) different ({ 13 }) boosting ({ 14 }) schemes ({ 15 }) : ({ }) AdaBoost ({ 18 }) [4] ({ 19 }) , ({ 20 }) Real ({ 21 }) AdaBoost ({ 22 }) [17] ({ 23 }) , ({ }) and ({ 24 }) Ent-Boost ({ 25 }) . ({ 26 }) 
# Sentence pair (1573) source length 23 target length 23 alignment score : 9.77406e-09
Each strong classifier is a combination of 80 weak classifiers ( using more weak classifiers does not improve much the performance ) . 
NULL ({ }) Each ({ 1 }) strong ({ 2 }) classifier ({ 3 }) is ({ 4 }) a ({ 5 }) combination ({ 6 }) of ({ 7 }) 80 ({ 8 }) weak ({ 9 }) classifiers ({ 10 }) ( ({ 11 }) using ({ 12 }) more ({ 13 }) weak ({ 14 }) classifiers ({ 15 }) does ({ 16 }) not ({ 17 }) much ({ 19 }) improve ({ 18 }) the ({ 20 }) performance ({ 21 }) ) ({ 22 }) . ({ 23 }) 
# Sentence pair (1574) source length 26 target length 29 alignment score : 4.63509e-15
As for Real AdaBoost , the subspace splitting is done by equal width binning in which the number of bins is arbitrarily selected to be 64 and 128 . 
NULL ({ 2 6 }) For ({ 1 }) Real ({ 3 }) AdaBoost ({ 4 }) , ({ 5 }) subspace ({ 7 }) splitting ({ 8 }) is ({ 9 }) done ({ 10 }) by ({ 11 }) equal-width ({ 12 }) binning ({ 13 14 }) in ({ 15 }) which ({ 16 }) the ({ 17 }) number ({ 18 }) of ({ 19 }) bins ({ 20 }) is ({ 21 }) arbitrarily ({ 22 }) selected ({ 23 }) to ({ 24 }) be ({ 25 }) 64 ({ 26 }) and ({ 27 }) 128 ({ 28 }) . ({ 29 }) 
# Sentence pair (1575) source length 18 target length 18 alignment score : 0.000246775
The curves indicate that the performances of Real AdaBoost and Ent-Boost are better than that of AdaBoost . 
NULL ({ }) The ({ 1 }) curves ({ 2 }) indicate ({ 3 }) that ({ 4 }) the ({ 5 }) performances ({ 6 }) of ({ 7 }) Real ({ 8 }) AdaBoost ({ 9 }) and ({ 10 }) Ent-Boost ({ 11 }) were ({ 12 }) better ({ 13 }) than ({ 14 }) that ({ 15 }) of ({ 16 }) AdaBoost ({ 17 }) . ({ 18 }) 
# Sentence pair (1576) source length 17 target length 17 alignment score : 0.000556961
In addition , the performance of Real AdaBoost classifiers varies when using different number of bins . 
NULL ({ }) In ({ 1 }) addition ({ 2 }) , ({ 3 }) the ({ 4 }) performance ({ 5 }) of ({ 6 }) Real ({ 7 }) AdaBoost ({ 8 }) classifiers ({ 9 }) varied ({ 10 }) when ({ 11 }) using ({ 12 }) different ({ 13 }) numbers ({ 14 }) of ({ 15 }) bins ({ 16 }) . ({ 17 }) 
# Sentence pair (1577) source length 8 target length 8 alignment score : 0.00640461
Overall , Ent-Boost has the best result . 
NULL ({ }) Overall ({ 1 }) , ({ 2 }) Ent-Boost ({ 3 }) produced ({ 4 }) the ({ 5 }) best ({ 6 }) result ({ 7 }) . ({ 8 }) 
# Sentence pair (1578) source length 29 target length 27 alignment score : 5.16116e-16
As for storage space , the Ent-Boost based classifier only employs 6 .79 bins on average which is much smaller than that of Real AdaBoost-based classifiers . 
NULL ({ 23 }) As ({ 1 }) for ({ 2 }) storage ({ 3 }) space ({ 4 }) , ({ 5 }) the ({ 6 }) Ent-Boost-based ({ 7 8 }) classifier ({ 9 }) only ({ 10 }) uses ({ 11 }) 6 ({ 12 }) .79 ({ 13 }) bins ({ 14 }) on ({ 15 }) average ({ 16 }) , ({ }) which ({ 17 }) is ({ 18 }) much ({ 19 }) fewer ({ 20 }) than ({ 21 }) the ({ }) number ({ 22 }) used ({ }) by ({ }) Real ({ 24 }) AdaBoost-based ({ 25 }) classifiers ({ 26 }) . ({ 27 }) 
# Sentence pair (1579) source length 10 target length 10 alignment score : 0.0113371
Using Ent-Boost , a robust face detector was built . 
NULL ({ }) Using ({ 1 }) Ent-Boost ({ 2 }) , ({ 3 }) a ({ 4 }) robust ({ 5 }) face ({ 6 }) detector ({ 7 }) was ({ 8 }) built ({ 9 }) . ({ 10 }) 
# Sentence pair (1580) source length 20 target length 15 alignment score : 1.15143e-11
It was a cascade of Ent-Boost based classifiers that were trained similar to [4] . 
NULL ({ }) It ({ 1 }) was ({ 2 }) a ({ 3 }) cascade ({ 4 }) of ({ 5 }) Ent-Boost-based ({ 6 7 }) classifiers ({ 8 }) that ({ 9 }) were ({ 10 }) trained ({ 11 }) [through ({ }) a ({ }) process ({ }) similar ({ 12 }) to ({ 13 }) that ({ }) used ({ }) in] ({ }) [4] ({ 14 }) . ({ 15 }) 
# Sentence pair (1581) source length 11 target length 11 alignment score : 1.33266e-05
The result cascade has 25 layers employing 3 ,850 features . 
NULL ({ }) The ({ 1 }) resulting ({ 2 }) cascade ({ 3 }) has ({ 4 }) 25 ({ 5 }) layers ({ 6 }) using ({ 7 }) 3 ({ 8 }) ,850 ({ 9 }) features ({ 10 }) . ({ 11 }) 
# Sentence pair (1582) source length 32 target length 30 alignment score : 5.9003e-23
Performances of AdaBoost-based face detector [4] and Ent-Boost based face detector on MIT+CMU test set [1] shown in Table 2 has confirmed the effectiveness of our proposed boosting scheme . 
NULL ({ 18 }) The ({ }) performances ({ 1 }) of ({ 2 }) the ({ }) AdaBoost-based ({ 3 }) face ({ 4 }) detector ({ 5 }) [4] ({ 6 }) and ({ 7 }) our ({ }) Ent-Boost-based ({ 8 9 }) face ({ 10 }) detector ({ 11 }) on ({ 12 }) the ({ }) MIT+CMU ({ 13 }) test ({ 14 }) set ({ 15 }) [1] ({ 16 }) confirmed ({ 17 21 22 }) the ({ 23 }) effectiveness ({ 24 }) of ({ 25 }) our ({ 26 }) proposed ({ 27 }) boosting ({ 28 }) scheme ({ 29 }) ( ({ }) Table ({ 19 }) 2 ({ 20 }) ) ({ }) . ({ 30 }) 
# Sentence pair (1583) source length 9 target length 9 alignment score : 0.0398553
Some detection results are given in Figure 5 . 
NULL ({ }) Some ({ 1 }) detection ({ 2 }) results ({ 3 }) are ({ 4 }) given ({ 5 }) in ({ 6 }) Figure ({ 7 }) 5 ({ 8 }) . ({ 9 }) 
# Sentence pair (1584) source length 24 target length 24 alignment score : 1.71325e-07
We have presented Ent-Boost , a variant of AdaBoost , which uses entropy measure for automatic subspace splitting and optimal weak classifier selection . 
NULL ({ }) We ({ 1 }) have ({ 2 }) described ({ 3 }) Ent-Boost ({ 4 }) , ({ 5 }) a ({ 6 }) variant ({ 7 }) of ({ 8 }) AdaBoost ({ 9 }) , ({ 10 }) which ({ 11 }) uses ({ 12 }) entropy ({ 13 }) measures ({ 14 }) for ({ 15 }) automatic ({ 16 }) subspace ({ 17 }) splitting ({ 18 }) and ({ 19 }) optimal ({ 20 }) weak ({ 21 }) classifier ({ 22 }) selection ({ 23 }) . ({ 24 }) 
# Sentence pair (1585) source length 12 target length 11 alignment score : 0.00064498
The resulted strong classifier has good performance and compact storage . 
NULL ({ }) The ({ 1 }) resultant ({ 2 }) strong ({ 3 }) classifier ({ 4 }) has ({ 5 }) good ({ 6 }) performance ({ 7 }) and ({ 8 }) achieves ({ }) compact ({ 9 }) storage ({ 10 }) . ({ 11 }) 
# Sentence pair (1586) source length 28 target length 24 alignment score : 2.55427e-15
Furthermore , it overcomes the main limitation of Real AdaBoost which is hard to determine the suitable number of bins for subspace splitting . 
NULL ({ 14 }) Furthermore ({ 1 }) , ({ 2 }) this ({ 3 }) new ({ }) boosting ({ }) scheme ({ }) overcomes ({ 4 }) the ({ 5 }) main ({ 6 }) limitation ({ 7 }) of ({ 8 }) Real ({ 9 }) AdaBoost ({ 10 }) , ({ }) which ({ 11 }) is ({ 12 }) difficulty ({ 13 }) in ({ }) determining ({ 15 }) the ({ 16 }) suitable ({ 17 }) number ({ 18 }) of ({ 19 }) bins ({ 20 }) for ({ 21 }) subspace ({ 22 }) splitting ({ 23 }) . ({ 24 }) 
# Sentence pair (1587) source length 30 target length 28 alignment score : 2.38633e-12
By considering the class information and the distribution of the input data in splitting process , this method is generic and can be applied to other applications . 
NULL ({ }) Because ({ 1 }) it ({ }) considers ({ 2 }) the ({ 3 }) class ({ 4 }) information ({ 5 }) and ({ 6 }) the ({ 7 }) distribution ({ 8 }) of ({ 9 }) the ({ 10 }) input ({ 11 }) data ({ 12 }) in ({ 13 }) the ({ }) splitting ({ 14 }) process ({ 15 }) , ({ 16 }) this ({ 17 }) method ({ 18 }) is ({ 19 }) generic ({ 20 }) and ({ 21 }) can ({ 22 }) be ({ 23 }) used ({ 24 }) for ({ 25 }) other ({ 26 }) applications ({ 27 }) . ({ 28 }) 
# Sentence pair (1588) source length 16 target length 14 alignment score : 6.47828e-05
Experiments have shown promising results , especially in building a robust face detector . 
NULL ({ }) Experiments ({ 1 }) have ({ 2 }) shown ({ 3 }) promising ({ 4 }) results ({ 5 }) , ({ 6 }) especially ({ 7 }) in ({ 8 }) the ({ }) building ({ 9 }) of ({ }) a ({ 10 }) robust ({ 11 }) face ({ 12 }) detector ({ 13 }) . ({ 14 }) 
# Sentence pair (1589) source length 11 target length 11 alignment score : 0.0400055
ROBUST OBJECT DETECTION USING FAST FEATURE SELECTION FROM HUGE FEATURE SETS 
NULL ({ }) ROBUST ({ 1 }) OBJECT ({ 2 }) DETECTION ({ 3 }) USING ({ 4 }) FAST ({ 5 }) FEATURE ({ 6 }) SELECTION ({ 7 }) FROM ({ 8 }) HUGE ({ 9 }) FEATURE ({ 10 }) SETS ({ 11 }) 
# Sentence pair (1590) source length 37 target length 28 alignment score : 4.21581e-15
This paper describes an efficient feature selection method which quickly selects a small subset out of a given huge feature set for building robust object detection systems . 
NULL ({ }) This ({ 1 }) paper ({ 2 }) describes ({ 3 }) an ({ 4 }) efficient ({ 5 }) feature ({ 6 }) selection ({ 7 }) method ({ 8 }) which ({ 9 }) that ({ }) quickly ({ 10 }) selects ({ 11 }) a ({ 12 }) small ({ 13 }) subset ({ 14 }) out ({ 15 }) of ({ 16 }) a ({ 17 }) given ({ 18 }) huge ({ 19 }) feature ({ 20 }) set ({ 21 }) ; ({ }) the ({ }) proposed ({ }) method ({ }) for ({ }) will ({ }) be ({ }) useful ({ }) for ({ 22 }) building ({ 23 }) robust ({ 24 }) object ({ 25 }) detection ({ 26 }) systems ({ 27 }) . ({ 28 }) 
# Sentence pair (1591) source length 28 target length 26 alignment score : 5.17894e-07
In this filter-based method , features are selected so that not only maximizing their relevance with the target class but also minimizing their mutual dependency . 
NULL ({ }) In ({ 1 }) this ({ 2 }) filter-based ({ 3 }) method ({ 4 }) , ({ 5 }) features ({ 6 }) are ({ 7 }) selected ({ 8 }) so ({ 9 }) that ({ 10 }) not ({ 11 }) only ({ 12 }) to ({ }) maximizeing ({ 13 }) their ({ 14 }) relevance ({ 15 }) with ({ 16 }) the ({ 17 }) target ({ 18 }) class ({ 19 }) but ({ 20 }) also ({ 21 }) to ({ }) minimizeing ({ 22 }) their ({ 23 }) mutual ({ 24 }) dependency ({ 25 }) . ({ 26 }) 
# Sentence pair (1592) source length 31 target length 25 alignment score : 4.80715e-13
As a result , the selected feature set only contains highly informative and non-redundant features which when combined together , significantly improve classification performance . 
NULL ({ }) As ({ 1 }) a ({ 2 }) result ({ 3 }) , ({ 4 }) the ({ 5 }) selected ({ 6 }) feature ({ 7 }) set ({ 8 }) only ({ 9 }) contains ({ 10 }) only ({ }) highly ({ 11 }) informative ({ 12 }) and ({ 13 }) non-redundant ({ 14 }) features ({ 15 }) , ({ }) which ({ 16 }) significantly ({ }) improve ({ }) classification ({ }) performance ({ }) when ({ 17 }) combined ({ 18 }) together ({ 19 }) , ({ 20 }) significantly ({ 21 }) improve ({ 22 }) classification ({ 23 }) performance ({ 24 }) . ({ 25 }) 
# Sentence pair (1593) source length 44 target length 29 alignment score : 3.08027e-21
The relevance and mutual dependency of features are measured by using conditional mutual information ( CMI ) in which features and classes are treated as discrete random variables . 
NULL ({ }) The ({ 1 }) relevance ({ 2 }) and ({ 3 }) mutual ({ 4 }) dependency ({ 5 }) of ({ 6 }) features ({ 7 }) are ({ 8 }) measured ({ 9 }) by ({ 10 }) using ({ 11 }) conditional ({ 12 }) mutual ({ 13 }) information ({ 14 }) ( ({ 15 }) CMI ({ 16 }) ), ({ 17 }) in ({ 18 }) which ({ 19 }) features ({ 20 }) and ({ 21 }) classes ({ 22 }) are ({ 23 }) treated ({ 24 }) as ({ 25 }) discrete ({ 26 }) random ({ 27 }) variables ({ 28 }) . ({ 29 }) //[ ({ }) ,?<--A ({ }) comma ({ }) can ({ }) be ({ }) used ({ }) here ({ }) if ({ }) the ({ }) following ({ }) describes ({ }) CMI ({ }) in ({ }) general ({ }) .] ({ }) 
# Sentence pair (1594) source length 27 target length 26 alignment score : 2.74445e-06
Experiments on different huge feature sets have shown that the proposed CMI-based feature selection can both reduce significantly the training time and achieve high accuracy . 
NULL ({ }) Experiments ({ 1 }) on ({ 2 }) different ({ 3 }) huge ({ 4 }) feature ({ 5 }) sets ({ 6 }) have ({ 7 }) shown ({ 8 }) that ({ 9 }) the ({ 10 }) proposed ({ 11 }) CMI-based ({ 12 }) feature ({ 13 }) selection ({ 14 }) can ({ 15 }) both ({ 16 }) reduce ({ 17 }) significantly ({ 18 }) the ({ 19 }) training ({ 20 }) time ({ 21 }) significantly ({ }) and ({ 22 }) achieve ({ 23 }) high ({ 24 }) accuracy ({ 25 }) . ({ 26 }) 
# Sentence pair (1595) source length 31 target length 30 alignment score : 1.74228e-06
One of the fundamental research issues in pattern recognition is feature selection which is the task of finding a small subset out of a given large set of features . 
NULL ({ }) One ({ 1 }) of ({ 2 }) the ({ 3 }) fundamental ({ 4 }) research ({ 5 }) issues ({ 6 }) in ({ 7 }) pattern ({ 8 }) recognition ({ 9 }) is ({ 10 }) feature ({ 11 }) selection ({ 12 }) , ({ }) which ({ 13 }) is ({ 14 }) the ({ 15 }) task ({ 16 }) of ({ 17 }) finding ({ 18 }) a ({ 19 }) small ({ 20 }) subset ({ 21 }) out ({ 22 }) of ({ 23 }) a ({ 24 }) given ({ 25 }) large ({ 26 }) set ({ 27 }) of ({ 28 }) features ({ 29 }) . ({ 30 }) 
# Sentence pair (1596) source length 16 target length 10 alignment score : 4.28457e-11
It is significant due to the following three reasons . 
NULL ({ }) Improving ({ 1 }) the ({ }) method ({ }) of ({ }) accomplishing ({ 3 }) this ({ }) task ({ }) is ({ 2 }) important ({ }) due ({ 4 }) to ({ 5 }) the ({ 6 }) following ({ 7 }) three ({ 8 }) reasons ({ 9 }) . ({ 10 }) 
# Sentence pair (1597) source length 25 target length 19 alignment score : 1.0976e-10
First , there are many ways to represent a target object , leading to a huge feature set . 
NULL ({ }) First ({ 1 }) , ({ 2 }) there ({ 3 }) are ({ 4 }) many ({ 5 }) ways ({ 6 }) can ({ }) be ({ }) used ({ }) to ({ 7 }) represent ({ 8 }) a ({ 9 }) target ({ 10 }) object ({ 11 }) , ({ 12 }) and ({ }) this ({ }) variety ({ }) leadsleading ({ 13 }) to ({ 14 }) a ({ 15 }) huge ({ 16 }) feature ({ 17 }) set ({ 18 }) . ({ 19 }) 
# Sentence pair (1598) source length 20 target length 20 alignment score : 0.000614856
For example , the number of Haar wavelet features used in [1] for face detection is hundreds of thousands . 
NULL ({ }) For ({ 1 }) example ({ 2 }) , ({ 3 }) the ({ 4 }) number ({ 5 }) of ({ 6 }) Haar ({ 7 }) wavelet ({ 8 }) features ({ 9 }) used ({ 10 }) in ({ 11 }) [1] ({ 12 }) for ({ 13 }) face ({ 14 }) detection ({ 15 }) is ({ 16 }) hundreds ({ 17 }) of ({ 18 }) thousands ({ 19 }) . ({ 20 }) 
# Sentence pair (1599) source length 11 target length 11 alignment score : 0.0217346
However , only small and incomplete training sets are available . 
NULL ({ }) However ({ 1 }) , ({ 2 }) only ({ 3 }) small ({ 4 }) and ({ 5 }) incomplete ({ 6 }) training ({ 7 }) sets ({ 8 }) are ({ 9 }) available ({ 10 }) . ({ 11 }) 
# Sentence pair (1600) source length 15 target length 15 alignment score : 0.00219097
As a result , these systems suffer from the curse of dimensionality and over-fitting . 
NULL ({ }) As ({ 1 }) a ({ 2 }) result ({ 3 }) , ({ 4 }) these ({ 5 }) systems ({ 6 }) suffer ({ 7 }) from ({ 8 }) the ({ 9 }) curse ({ 10 }) of ({ 11 }) dimensionality ({ 12 }) and ({ 13 }) over-fitting ({ 14 }) . ({ 15 }) 
# Sentence pair (1601) source length 34 target length 33 alignment score : 4.9099e-07
Second , a huge feature set usually includes many irrelevant and redundant features that can degrade the generalization performance of classifiers , waste storage space and increase training time [2 , 3] . 
NULL ({ }) Second ({ 1 }) , ({ 2 }) a ({ 3 }) huge ({ 4 }) feature ({ 5 }) set ({ 6 }) usually ({ 7 }) includes ({ 8 }) many ({ 9 }) irrelevant ({ 10 }) and ({ 11 }) redundant ({ 12 }) features ({ 13 }) that ({ 14 }) can ({ 15 }) degrade ({ 16 }) the ({ 17 }) generalization ({ 18 }) performance ({ 19 }) of ({ 20 }) classifiers ({ 21 }) , ({ 22 }) waste ({ 23 }) storage ({ 24 }) space ({ 25 }) , ({ }) and ({ 26 }) increase ({ 27 }) training ({ 28 }) time ({ 29 }) [2 ({ 30 }) , ({ 31 }) 3] ({ 32 }) . ({ 33 }) 
# Sentence pair (1602) source length 21 target length 21 alignment score : 0.000494288
Third , selecting an optimal feature subset from a huge feature set can improve the performance and speed of classifiers . 
NULL ({ }) Third ({ 1 }) , ({ 2 }) selecting ({ 3 }) an ({ 4 }) optimal ({ 5 }) feature ({ 6 }) subset ({ 7 }) from ({ 8 }) a ({ 9 }) huge ({ 10 }) feature ({ 11 }) set ({ 12 }) can ({ 13 }) improve ({ 14 }) the ({ 15 }) performance ({ 16 }) and ({ 17 }) speed ({ 18 }) of ({ 19 }) classifiers ({ 20 }) . ({ 21 }) 
# Sentence pair (1603) source length 13 target length 12 alignment score : 9.7549e-06
Furthermore , less complex model is easier to understand and verify . 
NULL ({ }) Furthermore ({ 1 }) , ({ 2 }) less ({ 3 }) complex ({ 4 }) models ({ 5 }) is ({ 6 }) are ({ }) easier ({ 7 }) to ({ 8 }) understand ({ 9 }) and ({ 10 }) verify ({ 11 }) . ({ 12 }) 
# Sentence pair (1604) source length 23 target length 23 alignment score : 6.22931e-05
In face detection , the success of systems such as those in [1 , 4] comes mainly from efficient feature selection methods . 
NULL ({ }) In ({ 1 }) face ({ 2 }) detection ({ 3 }) , ({ 4 }) the ({ 5 }) success ({ 6 }) of ({ 7 }) systems ({ 8 }) such ({ 9 }) as ({ 10 }) those ({ 11 }) in ({ 12 }) [1 ({ 13 }) , ({ 14 }) 4] ({ 15 }) comes ({ 16 }) mainly ({ 17 }) from ({ 18 }) efficient ({ 19 }) feature ({ 20 }) selection ({ 21 }) methods ({ 22 }) . ({ 23 }) 
# Sentence pair (1605) source length 21 target length 19 alignment score : 3.73813e-05
Generally , feature selection methods can be categorized into two kinds : filter-based approach and wrapper-based approach [5] . 
NULL ({ }) Generally ({ 1 }) , ({ 2 }) feature ({ 3 }) selection ({ 4 }) methods ({ 5 }) can ({ 6 }) be ({ 7 }) categorized ({ 8 }) into ({ 9 }) two ({ 10 }) kinds ({ 11 }) : ({ 12 }) the ({ }) filter-based ({ 13 }) approach ({ 14 }) and ({ 15 }) the ({ }) wrapper-based ({ 16 }) approach ({ 17 }) [5] ({ 18 }) . ({ 19 }) 
# Sentence pair (1606) source length 84 target length 30 alignment score : 2.75121e-59
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset . 
NULL ({ }) The ({ 1 }) filter-based ({ 2 }) approach ({ 3 }) is ({ 4 }) independent ({ 5 }) of ({ 6 }) any ({ 7 }) induction ({ 8 }) algorithm ({ 9 }) , ({ }) while ({ 10 }) but ({ }) the ({ 11 }) wrapper-based ({ 12 }) approach ({ 13 }) is ({ 14 }) associated ({ 15 }) with ({ 16 }) a ({ 17 }) specific ({ 18 }) induction ({ 19 }) algorithm ({ 20 }) to ({ 21 }) evaluate ({ 22 }) the ({ 23 }) quality ({ }) of ({ 25 }) the ({ }) selected ({ 27 }) feature ({ 28 }) subset ({ 29 }) . ({ 30 }) //[goodness ({ 26 }) / ({ }) quality ({ }) / ({ }) appropriateness?<--If ({ }) " ({ }) goodness ({ }) " ({ }) is ({ }) the ({ }) word ({ }) you ({ }) would ({ }) usually ({ }) use ({ }) in ({ }) your ({ }) field ({ }) for ({ }) this ({ }) , ({ }) it ({ }) is ({ }) fine ({ }) , ({ }) but ({ }) I ({ }) would ({ }) suggest ({ }) a ({ }) different ({ }) word ({ }) choice ({ }) otherwise ({ }) . ({ }) " ({ }) Goodness ({ 24 }) " ({ }) seems ({ }) vague ({ }) , ({ }) so ({ }) in ({ }) what ({ }) sense ({ }) do ({ }) you ({ }) mean ({ }) " ({ }) good ({ }) " ({ }) ?] ({ }) 
# Sentence pair (1607) source length 33 target length 30 alignment score : 3.67005e-10
In the filter-based approach , features are normally selected based on their individual predictive power which is measured by Fisher scores , Pearson correlation [6] or mutual information [7] . 
NULL ({ }) In ({ 1 }) the ({ 2 }) filter-based ({ 3 }) approach ({ 4 }) , ({ 5 }) features ({ 6 }) are ({ 7 }) normally ({ 8 }) selected ({ 9 }) based ({ 10 }) on ({ 11 }) their ({ 12 }) individual ({ 13 }) predictive ({ 14 }) power ({ 15 }) . ({ }) This ({ }) power ({ 16 }) is ({ 17 }) measured ({ 18 }) by ({ 19 }) Fisher ({ 20 }) scores ({ 21 }) , ({ 22 }) Pearson ({ 23 }) correlation ({ 24 }) [6] ({ 25 }) , ({ }) or ({ 26 }) mutual ({ 27 }) information ({ 28 }) [7] ({ 29 }) . ({ 30 }) 
# Sentence pair (1608) source length 19 target length 18 alignment score : 2.3553e-05
The major advantage of these methods is their speed and ability to scale to huge feature sets . 
NULL ({ }) The ({ 1 }) major ({ 2 }) advantage ({ 3 }) of ({ 4 }) these ({ 5 }) measurement ({ }) methods ({ 6 }) is ({ 7 }) their ({ 8 }) speed ({ 9 }) and ({ 10 }) ability ({ 11 }) to ({ 12 }) scale ({ 13 }) to ({ 14 }) huge ({ 15 }) feature ({ 16 }) sets ({ 17 }) . ({ 18 }) 
# Sentence pair (1609) source length 77 target length 61 alignment score : 3.72855e-30
However , the mutual relationships between features is often not taken into account , leading selected features might be highly redundant and less informative because two features with high individual predict power when combined together might not bring significant performance improvement compared with two features which one of them has low predictive power but is useful when combined with others . 
NULL ({ }) However ({ 1 }) , ({ 2 }) because ({ }) the ({ 3 }) mutual ({ 4 }) relationships ({ 5 }) between ({ 6 }) features ({ 7 }) is ({ 8 }) are ({ }) often ({ 9 }) not ({ 10 }) taken ({ 11 }) into ({ 12 }) account ({ 13 }) , ({ 14 }) leading ({ 15 }) the ({ }) selected ({ 16 }) features ({ 17 }) might ({ 18 }) be ({ 19 }) highly ({ 20 }) redundant ({ 21 }) and ({ 22 }) less ({ 23 }) informative ({ 24 }) because ({ 25 }) two ({ 26 }) features ({ 27 }) with ({ 28 }) high ({ 29 }) individual ({ 30 }) predictive ({ 31 }) power ({ 32 }) , ({ }) when ({ 33 }) combined ({ 34 }) together ({ 35 }) , ({ }) might ({ 36 }) not ({ 37 }) bring ({ 38 }) significant ({ 39 }) performance ({ 40 }) improvement ({ 41 }) . ({ }) Combining ({ }) compared ({ 42 }) with ({ 43 }) two ({ 44 }) features ({ 45 }) of ({ }) which ({ 46 }) one ({ 47 }) of ({ 48 }) them ({ 49 }) has ({ 50 }) low ({ 51 }) predictive ({ 52 }) power ({ 53 }) but ({ 54 }) is ({ 55 }) useful ({ 56 }) when ({ 57 }) combined ({ 58 }) with ({ 59 }) others ({ 60 }) would ({ }) thus ({ }) be ({ }) more ({ }) effective ({ }) for ({ }) improving ({ }) performance ({ }) . ({ 61 }) 
# Sentence pair (1610) source length 40 target length 29 alignment score : 6.00277e-17
Since wrapper-based feature selection methods use machine learning algorithms as a black box in selection process , they can suffer from over-fitting in situations of small training sets . 
NULL ({ }) Since ({ 1 }) wrapper-based ({ 2 }) feature ({ 3 }) selection ({ 4 }) methods ({ 5 }) use ({ 6 }) machine ({ 7 }) learning ({ 8 }) algorithms ({ 9 }) as ({ 10 }) a ({ 11 }) black ({ 12 }) box ({ 13 }) in ({ 14 }) the ({ }) selection ({ 15 }) process ({ 16 }) , ({ 17 }) they ({ 18 }) can ({ 19 }) suffer ({ 20 }) from ({ 21 }) over-fitting ({ 22 }) in ({ 23 }) situations ({ 24 }) of ({ 25 }) when ({ }) applied ({ }) to ({ }) small ({ 26 }) training ({ 27 }) sets ({ 28 }) . ({ 29 }) //[when ({ }) used ({ }) with ({ }) / ({ }) when ({ }) applied ({ }) to?] ({ }) 
# Sentence pair (1611) source length 41 target length 36 alignment score : 4.57019e-12
Furthermore , in practical object detection systems as in [1 , 8] , the feature sets usually have hundreds of thousands features , using wrapper-based methods is obviously inefficient because of very high computation cost . 
NULL ({ }) Furthermore ({ 1 }) , ({ 2 }) in ({ 3 }) practical ({ 4 }) object ({ 5 }) detection ({ 6 }) systems ({ 7 }) as ({ 8 }) in ({ 9 }) [1 ({ 10 }) , ({ 11 }) 8] ({ 12 }) , ({ 13 }) the ({ 14 }) feature ({ 15 }) sets ({ 16 }) usually ({ 17 }) have ({ 18 }) hundreds ({ 19 }) of ({ 20 }) thousands ({ 21 }) of ({ }) features ({ 22 }) , ({ 23 }) so ({ }) using ({ 24 }) wrapper-based ({ 25 }) methods ({ 26 }) is ({ 27 }) obviously ({ 28 }) inefficient ({ 29 }) because ({ 30 }) of ({ 31 }) the ({ }) very ({ 32 }) high ({ 33 }) computation ({ 34 }) costs ({ }) they ({ }) incur ({ 35 }) . ({ 36 }) 
# Sentence pair (1612) source length 40 target length 33 alignment score : 3.91634e-14
For example , in the state of the art face detection system [1] , choosing a 6 ,061- feature set out of a 180 ,000-feature set by AdaBoost has taken several weeks . 
NULL ({ }) For ({ 1 }) example ({ 2 }) , ({ 3 }) in ({ 4 }) the ({ 5 }) state- ({ 6 }) of- ({ 7 }) the- ({ 8 }) art ({ 9 }) face ({ 10 }) detection ({ 11 }) system ({ 12 }) in ({ }) [1] ({ 13 }) , ({ 14 }) choosing ({ 15 }) a ({ 16 }) 6 ({ 17 }) ,061- ({ 18 }) feature ({ 19 }) set ({ 20 }) out ({ 21 }) of ({ 22 }) a ({ 23 }) 180 ({ 24 }) ,000-feature ({ 25 }) set ({ 26 }) by ({ 27 }) using ({ }) AdaBoost ({ 28 }) has ({ 29 }) takentook ({ 30 }) several ({ 31 }) weeks ({ 32 }) . ({ 33 }) //[by ({ }) using ({ }) / ({ }) generated ({ }) by?] ({ }) 
# Sentence pair (1613) source length 42 target length 36 alignment score : 8.67013e-15
Consequently , conditional mutual information ( CMI ) based feature selection methods have been proposed [9 , 8 , 7 , 10] to take full advantage of above approaches for handling large scale feature sets . 
NULL ({ }) Consequently ({ 1 }) , ({ 2 }) feature ({ }) selection ({ }) methods ({ }) based ({ }) on ({ }) conditional ({ 3 }) mutual ({ 4 }) information ({ 5 }) ( ({ 6 }) CMI ({ 7 }) ) ({ 8 }) based ({ 9 }) feature ({ 10 }) selection ({ 11 }) methods ({ 12 }) have ({ 13 }) been ({ 14 }) proposed ({ 15 }) [9 ({ 16 }) , ({ 17 }) 8 ({ 18 }) , ({ 19 }) 7 ({ 20 }) , ({ 21 }) 10] ({ 22 }) to ({ 23 }) take ({ 24 }) full ({ 25 }) advantage ({ 26 }) of ({ 27 }) the ({ }) above ({ 28 }) approaches ({ 29 }) for ({ 30 }) handling ({ 31 }) large ({ 32 }) scale ({ 33 }) feature ({ 34 }) sets ({ 35 }) . ({ 36 }) 
# Sentence pair (1614) source length 33 target length 27 alignment score : 2.31262e-12
The main idea of CMI-based methods is to select features which maximize their relevance with the target class and simultaneously minimize mutual dependency between selected ones . 
NULL ({ }) The ({ 1 }) main ({ 2 }) goal ({ 3 }) of ({ 4 }) these ({ }) CMI-based ({ 5 }) methods ({ 6 }) is ({ 7 }) to ({ 8 }) select ({ 9 }) features ({ 10 }) which ({ 11 }) that ({ }) maximize ({ 12 }) their ({ 13 }) relevance ({ 14 }) with ({ 15 }) the ({ 16 }) target ({ 17 }) class ({ 18 }) and ({ 19 }) to ({ }) simultaneously ({ 20 }) minimize ({ 21 }) mutual ({ 22 }) dependency ({ 23 }) between ({ 24 }) selected ({ 25 }) ones ({ 26 }) . ({ 27 }) //[idea ({ }) / ({ }) goal?] ({ }) 
# Sentence pair (1615) source length 41 target length 33 alignment score : 3.70288e-17
It does not select a feature similar to already selected ones , even if it is individual powerful , as selecting it might not increase much information about the target class [7] . 
NULL ({ }) It ({ 1 }) doesThese ({ 2 }) methods ({ }) do ({ }) not ({ 3 }) select ({ 4 }) a ({ 5 }) feature ({ 6 }) similar ({ 7 }) to ({ 8 }) ones ({ }) already ({ 9 }) selected ({ 10 }) ones ({ 11 }) , ({ 12 }) even ({ 13 }) if ({ 14 }) itthe ({ 15 }) feature ({ }) is ({ 16 }) individually ({ 17 }) powerful ({ 18 }) , ({ 19 }) as ({ 20 }) because ({ }) selecting ({ 21 }) it ({ 22 }) might ({ 23 }) not ({ 24 }) do ({ }) much ({ }) to ({ }) increase ({ 25 }) much ({ 26 }) information ({ 27 }) about ({ 28 }) the ({ 29 }) target ({ 30 }) class ({ 31 }) [7] ({ 32 }) . ({ 33 }) 
# Sentence pair (1616) source length 26 target length 24 alignment score : 2.62127e-06
One of the important tasks in using CMI-based methods is mutual information estimation which involves to compute probability densities of continuous random variables . 
NULL ({ }) One ({ 1 }) of ({ 2 }) the ({ 3 }) important ({ 4 }) tasks ({ 5 }) in ({ 6 }) using ({ 7 }) CMI-based ({ 8 }) methods ({ 9 }) is ({ 10 }) mutual ({ 11 }) information ({ 12 }) estimation ({ 13 }) , ({ }) which ({ 14 }) involves ({ 15 }) to ({ 16 }) computecomputing ({ 17 }) the ({ }) probability ({ 18 }) densities ({ 19 }) of ({ 20 }) continuous ({ 21 }) random ({ 22 }) variables ({ 23 }) . ({ 24 }) 
# Sentence pair (1617) source length 30 target length 29 alignment score : 2.48097e-06
In [9] , Kwak and Choi used Parzen windows based density estimation method in which many parameters such as kernel function and window width are complicated to determine . 
NULL ({ }) In ({ 1 }) [9] ({ 2 }) , ({ 3 }) Kwak ({ 4 }) and ({ 5 }) Choi ({ 6 }) used ({ 7 }) a ({ }) Parzen ({ 8 }) windows ({ 9 }) -based ({ 10 }) density ({ 11 }) estimation ({ 12 }) method ({ 13 }) in ({ 14 }) which ({ 15 }) many ({ 16 }) parameters ({ 17 }) such ({ 18 }) as ({ 19 }) kernel ({ 20 }) function ({ 21 }) and ({ 22 }) window ({ 23 }) width ({ 24 }) are ({ 25 }) complicated ({ 26 }) to ({ 27 }) determine ({ 28 }) . ({ 29 }) 
# Sentence pair (1618) source length 26 target length 9 alignment score : 3.27326e-22
For simplification , discretizing features is often used . 
NULL ({ }) For ({ 1 }) simplification ({ 2 }) , ({ 3 }) discretizing ({ 4 }) features ({ 5 }) is ({ 6 }) often ({ 7 }) used ({ 8 }) on ({ }) the ({ }) features ({ }) . ({ }) //[discretizing ({ 9 }) features ({ }) is ({ }) often ({ }) used ({ }) on ({ }) the ({ }) features ({ }) / ({ }) the ({ }) features ({ }) are ({ }) often ({ }) discretized?] ({ }) 
# Sentence pair (1619) source length 25 target length 24 alignment score : 7.10869e-06
So far , in object detection systems like [8 , 7] , features are treated as binary random variables by choosing appropriate thresholds . 
NULL ({ }) So ({ 1 }) far ({ 2 }) , ({ 3 }) in ({ 4 }) object ({ 5 }) detection ({ 6 }) systems ({ 7 }) like ({ 8 }) [8 ({ 9 }) , ({ 10 }) 7] ({ 11 }) treat ({ }) , ({ 12 }) features ({ 13 }) are ({ 14 }) treated ({ 15 }) as ({ 16 }) binary ({ 17 }) random ({ 18 }) variables ({ 19 }) by ({ 20 }) choosing ({ 21 }) appropriate ({ 22 }) thresholds ({ 23 }) . ({ 24 }) 
# Sentence pair (1620) source length 27 target length 25 alignment score : 1.86891e-08
However , binarizing features is not a suitable way to handle highly complex data for which it is hard to find the best threshold . 
NULL ({ }) However ({ 1 }) , ({ 2 }) binarizing ({ 3 }) features ({ 4 }) is ({ 5 }) not ({ 6 }) a ({ 7 }) suitable ({ 8 }) way ({ 9 }) to ({ 10 }) handle ({ 11 }) highly ({ 12 }) complex ({ 13 }) data ({ 14 }) for ({ 15 }) which ({ 16 }) it ({ 17 }) is ({ 18 }) hard ({ 19 }) to ({ 20 }) finding ({ 21 }) the ({ 22 }) best ({ 23 }) threshold ({ 24 }) is ({ }) difficult ({ }) . ({ 25 }) 
# Sentence pair (1621) source length 14 target length 12 alignment score : 7.92321e-20
It is better if multiple thresholds are used to discretize data . 
NULL ({ 7 }) Using ({ 1 }) multiple ({ 5 }) thresholds ({ 6 }) to ({ 9 }) discretize ({ 4 }) data ({ 11 }) is ({ 2 }) better ({ 3 }) than ({ 8 }) using ({ 10 }) a ({ }) binary ({ }) approach ({ }) . ({ 12 }) 
# Sentence pair (1622) source length 29 target length 28 alignment score : 1.63111e-06
Such a simple method is equal-width binning which divides the range of feature values into m equal sized bins , where m must be known in advance . 
NULL ({ }) Such ({ 1 }) a ({ 2 }) simple ({ 3 }) method ({ 4 }) is ({ 5 }) equal-width ({ 6 }) binning ({ 7 }) , ({ }) which ({ 8 }) divides ({ 9 }) the ({ 10 }) range ({ 11 }) of ({ 12 }) feature ({ 13 }) values ({ 14 }) into ({ 15 }) m ({ 16 }) equally ({ 17 }) sized ({ 18 }) bins ({ 19 }) , ({ 20 }) where ({ 21 }) m ({ 22 }) must ({ 23 }) be ({ 24 }) known ({ 25 }) in ({ 26 }) advance ({ 27 }) . ({ 28 }) 
# Sentence pair (1623) source length 10 target length 10 alignment score : 0.0258365
Our method is also a CMI-based feature selection method . 
NULL ({ }) Our ({ 1 }) method ({ 2 }) is ({ 3 }) also ({ 4 }) a ({ 5 }) CMI-based ({ 6 }) feature ({ 7 }) selection ({ 8 }) method ({ 9 }) . ({ 10 }) 
# Sentence pair (1624) source length 23 target length 19 alignment score : 1.49417e-08
However , the main distinguished point is that it employs the entropy-based discretization method [11] to discretize features . 
NULL ({ }) However ({ 1 }) , ({ 2 }) the ({ }) methodfs ({ 3 }) main ({ 4 }) distinguishing ({ 5 }) point ({ 6 }) is ({ 7 }) that ({ 8 }) it ({ 9 }) employs ({ 10 }) the ({ 11 }) entropy-based ({ 12 }) discretization ({ 13 }) method ({ 14 }) [11] ({ 15 }) to ({ 16 }) discretize ({ 17 }) features ({ 18 }) . ({ 19 }) //[distinguishing ({ }) / ({ }) unique?] ({ }) 
# Sentence pair (1625) source length 21 target length 19 alignment score : 1.38884e-05
This discretization method is simpler than Parzen windows based density estimation method and more efficient than binary discretization . 
NULL ({ }) This ({ 1 }) discretization ({ 2 }) method ({ 3 }) is ({ 4 }) simpler ({ 5 }) than ({ 6 }) the ({ }) Parzen ({ 7 }) window-s ({ 8 }) based ({ 9 }) density ({ 10 }) estimation ({ 11 }) method ({ 12 }) and ({ 13 }) is ({ }) more ({ 14 }) efficient ({ 15 }) than ({ 16 }) binary ({ 17 }) discretization ({ 18 }) . ({ 19 }) 
# Sentence pair (1626) source length 24 target length 21 alignment score : 3.99708e-08
Furthermore , contrary to equal-width binning , it can automatically evaluate the optimal number of bins based on data distribution . 
NULL ({ }) Furthermore ({ 1 }) , ({ 2 }) contrary ({ 3 }) to ({ 4 }) equal-width ({ 5 }) binning ({ 6 }) , ({ 7 }) it ({ 8 }) can ({ 9 }) automatically ({ 10 }) evaluate ({ 11 }) the ({ 12 }) optimal ({ 13 }) number ({ 14 }) of ({ 15 }) bins ({ 16 }) based ({ 17 }) on ({ 18 }) data ({ 19 }) distribution ({ 20 }) . ({ }) //[evaluate ({ }) / ({ }) determine?] ({ 21 }) 
# Sentence pair (1627) source length 39 target length 36 alignment score : 1.62124e-14
Experiments show that the proposed method can well handle huge feature sets for face detection such as Haar wavelets [1] and Gabor wavelets [12] , significantly reduce the training time while maintaining high classification performance . 
NULL ({ }) Experiments ({ 1 }) show ({ 2 }) that ({ 3 }) the ({ 4 }) proposed ({ 5 }) method ({ 6 }) can ({ 7 }) well ({ 8 }) capably ({ }) handle ({ 9 }) huge ({ 10 }) feature ({ 11 }) sets ({ 12 }) of ({ }) data ({ }) such ({ 16 }) as ({ 17 }) Haar ({ 18 }) wavelets ({ 19 }) [1] ({ 20 }) and ({ 21 }) Gabor ({ 22 }) wavelets ({ 23 }) [12] ({ 24 }) for ({ 13 }) face ({ 14 }) detection ({ 15 }) , ({ 25 }) significantly ({ 26 }) reducinge ({ 27 }) the ({ 28 }) training ({ 29 }) time ({ 30 }) while ({ 31 }) maintaining ({ 32 }) high ({ 33 }) classification ({ 34 }) performance ({ 35 }) . ({ 36 }) 
# Sentence pair (1628) source length 4 target length 4 alignment score : 0.260103
FEATURE SELECTION " > 
NULL ({ }) FEATURE ({ 1 }) SELECTION ({ 2 }) " ({ 3 }) > ({ 4 }) 
# Sentence pair (1629) source length 60 target length 58 alignment score : 1.99521e-11
Huge feature sets usually contain four kinds of features : ( i ) irrelevant features , ( ii ) weakly relevant and redundant features , ( iii ) weakly relevant but non-redundant features and ( iv ) strongly relevant features in which ( iii ) and ( iv ) are the objective of feature selection methods [13] . 
NULL ({ }) Huge ({ 1 }) feature ({ 2 }) sets ({ 3 }) usually ({ 4 }) contain ({ 5 }) four ({ 6 }) kinds ({ 7 }) of ({ 8 }) features ({ 9 }) : ({ 10 }) ( ({ 11 }) i ({ 12 }) ) ({ 13 }) irrelevant ({ 14 }) features ({ 15 }) , ({ 16 }) ( ({ 17 }) ii ({ 18 }) ) ({ 19 }) weakly ({ 20 }) relevant ({ 21 }) and ({ 22 }) redundant ({ 23 }) features ({ 24 }) , ({ 25 }) ( ({ 26 }) iii ({ 27 }) ) ({ 28 }) weakly ({ 29 }) relevant ({ 30 }) but ({ 31 }) non-redundant ({ 32 }) features ({ 33 }) , ({ }) and ({ 34 }) ( ({ 35 }) iv ({ 36 }) ) ({ 37 }) strongly ({ 38 }) relevant ({ 39 }) features ({ 40 }) ; ({ }) in ({ 41 }) which ({ 42 }) ( ({ 43 }) iii ({ 44 }) ) ({ 45 }) and ({ 46 }) ( ({ 47 }) iv ({ 48 }) ) ({ 49 }) are ({ 50 }) the ({ 51 }) objectives ({ 52 }) of ({ 53 }) feature ({ 54 }) selection ({ 55 }) methods ({ 56 }) [13] ({ 57 }) . ({ 58 }) 
# Sentence pair (1630) source length 24 target length 21 alignment score : 1.78192e-08
To measure relevance of a feature , the entropy-based measure which quantifies the uncertainty of random variables is normally used . 
NULL ({ }) To ({ 1 }) measure ({ 2 }) the ({ }) relevance ({ 3 }) of ({ 4 }) a ({ 5 }) feature ({ 6 }) , ({ 7 }) an ({ 8 }) entropy-based ({ 9 }) measure ({ 10 }) , ({ }) which ({ 11 }) quantifies ({ 12 }) the ({ 13 }) uncertainty ({ 14 }) of ({ 15 }) random ({ 16 }) variables ({ 17 }) , ({ }) is ({ 18 }) normally ({ 19 }) used ({ 20 }) . ({ 21 }) 
# Sentence pair (1631) source length 29 target length 29 alignment score : 2.41892e-05
The entropy of a discrete random variable X is defined as : \MATH and the conditional entropy of X after another variable Y is known is defined as \MATH 
NULL ({ }) The ({ 1 }) entropy ({ 2 }) of ({ 3 }) a ({ 4 }) discrete ({ 5 }) random ({ 6 }) variable ({ 7 }) X ({ 8 }) is ({ 9 }) defined ({ 10 }) as ({ 11 }) : ({ 12 }) \MATH ({ 13 }) and ({ 14 }) the ({ 15 }) conditional ({ 16 }) entropy ({ 17 }) of ({ 18 }) X ({ 19 }) after ({ 20 }) another ({ 21 }) variable ({ 22 }) Y ({ 23 }) is ({ 24 }) known ({ 25 }) is ({ 26 }) defined ({ 27 }) as ({ 28 }) \MATH ({ 29 }) 
# Sentence pair (1632) source length 15 target length 14 alignment score : 0.000939712
The mutual dependence between two random variables is measured by mutual information \MATH . 
NULL ({ }) The ({ 1 }) mutual ({ 2 }) dependence ({ 3 }) between ({ 4 }) two ({ 5 }) random ({ 6 }) variables ({ 7 }) is ({ 8 }) measured ({ 9 }) by ({ 10 }) mutual ({ 11 }) information ({ 12 }) : ({ }) \MATH ({ 13 }) . ({ 14 }) 
# Sentence pair (1633) source length 10 target length 9 alignment score : 0.00137801
The conditional mutual information is defined as : \MATH 
NULL ({ }) The ({ 1 }) conditional ({ 2 }) mutual ({ 3 }) information ({ 4 }) is ({ 5 }) defined ({ 6 }) as ({ 7 }) : ({ 8 }) \MATH ({ 9 }) . ({ }) 
# Sentence pair (1634) source length 24 target length 19 alignment score : 2.97087e-09
In the first step , the most relevant feature F1 which has the highest mutual information is selected . 
NULL ({ }) In ({ 1 }) the ({ 2 }) first ({ 3 }) step ({ 4 }) , ({ 5 }) the ({ 6 }) most ({ 7 }) relevant ({ 8 }) feature ({ 9 }) F1 ({ 10 }) , ({ }) which ({ 11 }) has ({ 12 }) the ({ 13 }) highest ({ 14 }) largest ({ }) amount ({ }) of ({ }) mutual ({ 15 }) information ({ 16 }) , ({ }) is ({ 17 }) selected ({ 18 }) . ({ 19 }) 
# Sentence pair (1635) source length 38 target length 36 alignment score : 4.10827e-09
However , in the second step , the condition to select feature F2 is not its mutual information alone , but how much information of F2 can add with respect to the already existing F1 . 
NULL ({ }) However ({ 1 }) , ({ 2 }) iIn ({ 3 }) the ({ 4 }) second ({ 5 }) step ({ 6 }) , ({ 7 }) however ({ }) , ({ }) the ({ 8 }) condition ({ 9 }) to ({ 10 }) select ({ 11 }) feature ({ 12 }) F2 ({ 13 }) is ({ 14 }) not ({ 15 }) its ({ 16 }) mutual ({ 17 }) information ({ 18 }) alone ({ 19 }) , ({ 20 }) but ({ 21 }) how ({ 22 }) much ({ 23 }) information ({ 24 }) of ({ 25 }) F2 ({ 26 }) can ({ 27 }) add ({ 28 }) with ({ 29 }) respect ({ 30 }) to ({ 31 }) the ({ 32 }) already ({ 33 }) existing ({ 34 }) F1 ({ 35 }) . ({ 36 }) 
# Sentence pair (1636) source length 17 target length 10 alignment score : 3.90145e-10
Therefore , F2 is selected so that maximizing :\MATH . 
NULL ({ }) Therefore ({ 1 }) , ({ 2 }) F2 ({ 3 }) is ({ 4 }) selected ({ 5 }) so ({ 6 }) that ({ 7 }) maximizingas ({ 8 }) to ({ }) maximize ({ }) the ({ }) information ({ }) it ({ }) can ({ }) add ({ }) :\MATH ({ 9 }) . ({ 10 }) 
# Sentence pair (1637) source length 43 target length 25 alignment score : 1.1204e-26
Following the same scheme , we iteratively add the feature that brings the highest increase of information content contained in current selected feature set . 
NULL ({ 5 }) Following ({ 1 }) the ({ 2 }) same ({ 3 }) scheme, ({ 4 }) we ({ 6 }) iteratively ({ 7 }) add ({ 8 }) the ({ 9 }) feature ({ 10 }) that ({ 11 }) brings ({ 12 }) the ({ 13 }) highest ({ 14 }) increase ({ 15 }) of ({ 16 }) the ({ }) information ({ 17 }) content ({ 18 }) contained ({ 19 }) in ({ 20 }) the ({ }) current ({ 21 }) selected ({ 22 }) feature ({ 23 }) set ({ 24 }) . ({ 25 }) //[the ({ }) / ({ }) an?<-- ({ }) " ({ }) An ({ }) " ({ }) is ({ }) correct ({ }) if ({ }) there ({ }) is ({ }) more ({ }) than ({ }) one ({ }) such ({ }) measure ({ }) .] ({ }) 
# Sentence pair (1638) source length 15 target length 15 alignment score : 0.006053
The next feature Ft to be added at iteration t is defined by :\MATH . 
NULL ({ }) The ({ 1 }) next ({ 2 }) feature ({ 3 }) Ft ({ 4 }) to ({ 5 }) be ({ 6 }) added ({ 7 }) at ({ 8 }) iteration ({ 9 }) t ({ 10 }) is ({ 11 }) defined ({ 12 }) by ({ 13 }) :\MATH ({ 14 }) . ({ 15 }) 
# Sentence pair (1639) source length 25 target length 25 alignment score : 6.22825e-14
In order to simply estimate mutual information , the easiest way is features are discretized in binary values by specifying thresholds [8 , 7] . 
NULL ({ 2 3 }) To ({ 1 }) simply ({ 4 }) estimate ({ 5 }) mutual ({ 6 }) information ({ 7 }) , ({ 8 }) the ({ 9 }) easiest ({ 10 }) way ({ 11 }) is ({ }) to ({ }) discretize ({ 12 }) features ({ 13 }) are ({ 14 }) discretized ({ 15 }) in ({ 16 }) binary ({ 17 }) values ({ 18 }) by ({ 19 }) specifying ({ 20 }) thresholds ({ 21 }) [8 ({ 22 }) , ({ 23 }) 7] ({ 24 }) . ({ 25 }) 
# Sentence pair (1640) source length 28 target length 26 alignment score : 8.84946e-08
However , for complex data , it is not efficient ; therefore , we use entropy-based method proposed by Fayyad and Irani [11] for discretization . 
NULL ({ }) However ({ 1 }) , ({ 2 }) for ({ 3 }) complex ({ 4 }) data ({ 5 }) , ({ 6 }) doing ({ }) thisit ({ 7 }) is ({ 8 }) not ({ 9 }) efficient ({ 10 }) ; ({ 11 }) therefore ({ 12 }) , ({ 13 }) we ({ 14 }) use ({ 15 }) the ({ }) entropy-based ({ 16 }) method ({ 17 }) proposed ({ 18 }) by ({ 19 }) Fayyad ({ 20 }) and ({ 21 }) Irani ({ 22 }) [11] ({ 23 }) for ({ 24 }) discretization ({ 25 }) . ({ 26 }) 
# Sentence pair (1641) source length 24 target length 23 alignment score : 3.36972e-06
This method is a supervised method , thus it is generic and can adapt very well to any kind of data distributions . 
NULL ({ }) This ({ 1 }) method ({ 2 }) is ({ 3 }) a ({ 4 }) supervised ({ 5 }) method ({ 6 }) , ({ 7 }) thus ({ 8 }) so ({ }) it ({ 9 }) is ({ 10 }) generic ({ 11 }) and ({ 12 }) can ({ 13 }) adapt ({ 14 }) very ({ 15 }) well ({ 16 }) to ({ 17 }) any ({ 18 }) kind ({ 19 }) of ({ 20 }) data ({ 21 }) distributions ({ 22 }) . ({ 23 }) 
# Sentence pair (1642) source length 14 target length 15 alignment score : 1.81408e-07
Basically , discretization is a quantizing process that converts continuous values into discrete values . 
NULL ({ 2 }) Discretization ({ 1 }) is ({ 4 }) essentially ({ 3 }) a ({ 5 }) quantizing ({ 6 }) process ({ 7 }) that ({ 8 }) converts ({ 9 }) continuous ({ 10 }) values ({ 11 }) into ({ 12 }) discrete ({ 13 }) values ({ 14 }) . ({ 15 }) 
# Sentence pair (1643) source length 61 target length 58 alignment score : 2.49074e-17
Suppose that we are given a set of instances S , a feature A and a cut-point T ( a cutpoint is a threshold value that divides the range of continuous values into two intervals ; one interval is less than or equal to the threshold , and the other interval is greater than the threshold ) . 
NULL ({ }) Suppose ({ 1 }) that ({ 2 }) we ({ 3 }) are ({ 4 }) given ({ 5 }) a ({ 6 }) set ({ 7 }) of ({ 8 }) instances ({ 9 }) S ({ 10 }) , ({ 11 }) a ({ 12 }) feature ({ 13 }) A ({ 14 }) , ({ }) and ({ 15 }) a ({ 16 }) cut-point ({ 17 }) T ({ 18 }) . ({ }) ( ({ 19 }) A ({ 20 }) cut-point ({ 21 }) is ({ 22 }) a ({ 23 }) threshold ({ 24 }) value ({ 25 }) that ({ 26 }) divides ({ 27 }) the ({ 28 }) range ({ 29 }) of ({ 30 }) continuous ({ 31 }) values ({ 32 }) into ({ 33 }) two ({ 34 }) intervals ({ 35 }) ; ({ 36 }) one ({ 37 }) interval ({ 38 }) is ({ 39 }) less ({ 40 }) than ({ 41 }) or ({ 42 }) equal ({ 43 }) to ({ 44 }) the ({ 45 }) threshold ({ 46 }) , ({ 47 }) and ({ 48 }) the ({ 49 }) other ({ 50 }) interval ({ 51 }) is ({ 52 }) greater ({ 53 }) than ({ 54 }) the ({ 55 }) threshold ({ 56 }) . ({ }) ) ({ 57 }) . ({ 58 }) 
# Sentence pair (1644) source length 13 target length 13 alignment score : 0.00977406
The class-information entropy of the partition induced by T is defined as : 
NULL ({ }) The ({ 1 }) class-information ({ 2 }) entropy ({ 3 }) of ({ 4 }) the ({ 5 }) partition ({ 6 }) induced ({ 7 }) by ({ 8 }) T ({ 9 }) is ({ 10 }) defined ({ 11 }) as ({ 12 }) : ({ 13 }) 
# Sentence pair (1645) source length 29 target length 27 alignment score : 1.26888e-06
Among candidate cut-points , the best candidate cut-point Tmin which minimizes the entropy function \MATH is selected to split \MATH into two partitions \MATH and \MATH . 
NULL ({ }) Among ({ 1 }) candidate ({ 2 }) cut-points ({ 3 }) , ({ 4 }) the ({ 5 }) best ({ 6 }) candidate ({ 7 }) cut-point ({ 8 }) Tmin ({ 9 }) , ({ }) which ({ 10 }) minimizes ({ 11 }) the ({ 12 }) entropy ({ 13 }) function ({ 14 }) \MATH ({ 15 }) , ({ }) is ({ 16 }) selected ({ 17 }) to ({ 18 }) split ({ 19 }) \MATH ({ 20 }) into ({ 21 }) two ({ 22 }) partitions ({ 23 }) \MATH ({ 24 }) and ({ 25 }) \MATH ({ 26 }) . ({ 27 }) 
# Sentence pair (1646) source length 27 target length 27 alignment score : 2.84556e-05
This process can then be repeated recursively to \MATH and \MATH until some stopping condition is satisfied , thus creating multiple intervals on the feature \MATH . 
NULL ({ }) This ({ 1 }) process ({ 2 }) can ({ 3 }) then ({ 4 }) be ({ 5 }) repeated ({ 6 }) recursively ({ 7 }) forto ({ 8 }) \MATH ({ 9 }) and ({ 10 }) \MATH ({ 11 }) until ({ 12 }) some ({ 13 }) stopping ({ 14 }) condition ({ 15 }) is ({ 16 }) satisfied ({ 17 }) , ({ 18 }) thus ({ 19 }) creating ({ 20 }) multiple ({ 21 }) intervals ({ 22 }) on ({ 23 }) the ({ 24 }) feature ({ 25 }) \MATH ({ 26 }) . ({ 27 }) 
# Sentence pair (1647) source length 17 target length 16 alignment score : 0.000169875
Using MDLP , the stopping criteria is proposed by Fayyad and Irani [11] as follows : 
NULL ({ }) Using ({ 1 }) MDLP ({ 2 }) , ({ 3 }) the ({ 4 }) stopping ({ 5 }) criteria ({ 6 }) is ({ 7 }) was ({ }) proposed ({ 8 }) by ({ 9 }) Fayyad ({ 10 }) and ({ 11 }) Irani ({ 12 }) [11] ({ 13 }) as ({ 14 }) follows ({ 15 }) : ({ 16 }) 
# Sentence pair (1648) source length 46 target length 41 alignment score : 5.18023e-13
MDLP Criteria : A partition induced by cut-point T for a set S of N examples is accepted if : \MATH Where \MATH ,where \MATH , \MATH , \MATH is the number of classes in \MATH , \MATH , \MATH . 
NULL ({ }) MDLP ({ 1 }) Criteria ({ 2 }) : ({ 3 }) A ({ 4 }) partition ({ 5 }) induced ({ 6 }) by ({ 7 }) cut-point ({ 8 }) T ({ 9 }) for ({ 10 }) a ({ 11 }) set ({ 12 }) S ({ 13 }) of ({ 14 }) N ({ 15 }) examples ({ 16 }) is ({ 17 }) accepted ({ 18 }) if ({ 19 }) : ({ 20 }) \MATH ({ 21 }) wWhere ({ 22 }) \MATH ({ 23 }) ,where ({ 24 }) \MATH ({ 25 }) , ({ 26 }) \MATH ({ 27 }) , ({ 28 }) and ({ }) \MATH ({ 29 }) is ({ 30 }) are ({ }) the ({ 31 }) numbers ({ 32 }) of ({ 33 }) classes ({ 34 }) in ({ 35 }) \MATH ({ 36 }) , ({ 37 }) \MATH ({ 38 }) , ({ 39 }) and ({ }) \MATH ({ 40 }) , ({ }) respectively ({ }) . ({ 41 }) 
# Sentence pair (1649) source length 31 target length 29 alignment score : 4.69981e-08
Extensive experiments [11 , 14] have shown that this method is one of the best variable discretization one because it gives small number of cut-points while maintaining consistency . 
NULL ({ }) Extensive ({ 1 }) experiments ({ 2 }) [11 ({ 3 }) , ({ 4 }) 14] ({ 5 }) have ({ 6 }) shown ({ 7 }) that ({ 8 }) this ({ 9 }) method ({ 10 }) is ({ 11 }) one ({ 12 }) of ({ 13 }) the ({ 14 }) best ({ 15 }) in ({ }) variable ({ 16 }) discretization ({ 17 }) one ({ 18 }) because ({ 19 }) it ({ 20 }) gives ({ 21 }) a ({ }) small ({ 22 }) number ({ 23 }) of ({ 24 }) cut-points ({ 25 }) while ({ 26 }) maintaining ({ 27 }) consistency ({ 28 }) . ({ 29 }) 
# Sentence pair (1650) source length 14 target length 14 alignment score : 0.00939557
The outline of the proposed feature selection method is shown in Algorithm 1 . 
NULL ({ }) The ({ 1 }) outline ({ 2 }) of ({ 3 }) the ({ 4 }) proposed ({ 5 }) feature ({ 6 }) selection ({ 7 }) method ({ 8 }) is ({ 9 }) shown ({ 10 }) in ({ 11 }) Algorithm ({ 12 }) 1 ({ 13 }) . ({ 14 }) 
# Sentence pair (1651) source length 16 target length 15 alignment score : 0.00019035
For experiments , a set face and non-face patterns of size 24x24 was used . 
NULL ({ }) For ({ 1 }) experiments ({ 2 }) , ({ 3 }) a ({ 4 }) set ({ 5 }) of ({ }) face ({ 6 }) and ({ 7 }) non-face ({ 8 }) patterns ({ 9 }) of ({ 10 }) size ({ 11 }) 24x24 ({ 12 }) was ({ 13 }) used ({ 14 }) . ({ 15 }) 
# Sentence pair (1652) source length 13 target length 13 alignment score : 0.005342
A set of 10 ,000 face patterns were collected from the Internet . 
NULL ({ }) A ({ 1 }) set ({ 2 }) of ({ 3 }) 10 ({ 4 }) ,000 ({ 5 }) face ({ 6 }) patterns ({ 7 }) were ({ 8 }) collected ({ 9 }) from ({ 10 }) the ({ 11 }) Internet ({ 12 }) . ({ 13 }) 
# Sentence pair (1653) source length 63 target length 55 alignment score : 1.26938e-19
Another set of 10 ,000 complex non-face patterns were false positives collected by running a face detector based on a cascade of 17 AdaBoost classifiers at different locations and scales on 8 ,440 images with various subjects , such as rocks , trees , buildings , scenery , and flowers , containing no faces . 
NULL ({ }) Another ({ 1 }) set ({ 2 }) of ({ 3 }) 10 ({ 4 }) ,000 ({ 5 }) complex ({ 6 }) non-face ({ 7 }) patterns ({ 8 }) were ({ 9 }) false ({ 10 }) positives ({ 11 }) collected ({ 12 }) by ({ 13 }) running ({ 14 }) a ({ 15 }) face ({ 16 }) detector ({ 17 }) based ({ 18 }) on ({ 19 }) a ({ 20 }) cascade ({ 21 }) of ({ 22 }) 17 ({ 23 }) AdaBoost ({ 24 }) classifiers ({ 25 }) at ({ 26 }) different ({ 27 }) locations ({ 28 }) and ({ 29 }) scales ({ 30 }) on ({ 31 }) 8 ({ 32 }) ,440 ({ 33 }) images ({ }) that ({ }) contained ({ }) no ({ }) faces ({ }) ; ({ }) the ({ }) images ({ 34 }) with ({ 35 }) included ({ }) various ({ 36 }) subjects ({ 37 }) , ({ 38 }) such ({ 39 }) as ({ 40 }) rocks ({ 41 }) , ({ 42 }) trees ({ 43 }) , ({ 44 }) buildings ({ 45 }) , ({ 46 }) scenery ({ 47 }) , ({ 48 }) and ({ 49 }) flowers ({ 50 }) , ({ 51 }) containing ({ 52 }) no ({ 53 }) faces ({ 54 }) . ({ 55 }) 
# Sentence pair (1654) source length 26 target length 26 alignment score : 9.24127e-05
The 10 ,000 patterns in each set were divided into a training set of 6 ,000 patterns and a test set of 4 ,000 patterns . 
NULL ({ }) The ({ 1 }) 10 ({ 2 }) ,000 ({ 3 }) patterns ({ 4 }) in ({ 5 }) each ({ 6 }) set ({ 7 }) were ({ 8 }) divided ({ 9 }) into ({ 10 }) a ({ 11 }) training ({ 12 }) set ({ 13 }) of ({ 14 }) 6 ({ 15 }) ,000 ({ 16 }) patterns ({ 17 }) and ({ 18 }) a ({ 19 }) test ({ 20 }) set ({ 21 }) of ({ 22 }) 4 ({ 23 }) ,000 ({ 24 }) patterns ({ 25 }) . ({ 26 }) 
# Sentence pair (1655) source length 16 target length 16 alignment score : 0.00378017
Some examples of the collected 24x24 face and non-face patterns are shown in Figure 1 . 
NULL ({ }) Some ({ 1 }) examples ({ 2 }) of ({ 3 }) the ({ 4 }) collected ({ 5 }) 24x24 ({ 6 }) face ({ 7 }) and ({ 8 }) non-face ({ 9 }) patterns ({ 10 }) are ({ 11 }) shown ({ 12 }) in ({ 13 }) Figure ({ 14 }) 1 ({ 15 }) . ({ 16 }) 
# Sentence pair (1656) source length 20 target length 18 alignment score : 1.00637e-08
Two types of features that are Haar wavelet feature and Gabor wavelet feature were used in experiments . 
NULL ({ }) Two ({ 1 }) types ({ 2 }) of ({ 3 }) features ({ 4 }) ?that ({ 5 }) are ({ 6 }) Haar ({ 7 }) wavelet ({ 8 }) features ({ 9 }) and ({ 10 }) Gabor ({ 11 }) wavelet ({ 12 }) features ({ 13 }) ? ({ }) were ({ 14 }) used ({ 15 }) in ({ 16 }) our ({ }) experiments ({ 17 }) . ({ 18 }) 
# Sentence pair (1657) source length 16 target length 16 alignment score : 0.00155439
Haar wavelet features have been widely used in many face detection systems [1 , 15] . 
NULL ({ }) Haar ({ 1 }) wavelet ({ 2 }) features ({ 3 }) have ({ 4 }) been ({ 5 }) widely ({ 6 }) used ({ 7 }) in ({ 8 }) many ({ 9 }) face ({ 10 }) detection ({ 11 }) systems ({ 12 }) [1 ({ 13 }) , ({ 14 }) 15] ({ 15 }) . ({ 16 }) 
# Sentence pair (1658) source length 57 target length 19 alignment score : 1.40038e-46
It consists of four kinds of features modeled from adjacent basic rectangles with the same size and shape . 
NULL ({ }) They ({ 1 }) consists ({ 2 }) of ({ 3 }) four ({ 4 }) kinds ({ 5 }) of ({ 6 }) features ({ 7 }) modeled ({ 8 }) from ({ 9 }) adjacent ({ 10 }) basic ({ 11 }) rectangles ({ 12 }) with ({ 13 }) the ({ }) same ({ 15 }) size ({ 16 }) and ({ 17 }) shape ({ 18 }) . ({ 19 }) //Ifm ({ }) not ({ }) 100 ({ }) percent ({ }) clear ({ }) on ({ }) what ({ }) " ({ }) they ({ }) " ({ }) points ({ }) to ({ }) here ({ }) . ({ }) " ({ }) These ({ }) Haar ({ }) wavelet ({ }) features ({ }) , ({ }) " ({ }) perhaps? ({ 14 }) But ({ }) can ({ }) features ({ }) consist ({ }) of ({ }) other ({ }) kinds ({ }) of ({ }) features? ({ }) You ({ }) may ({ }) want ({ }) to ({ }) clarify ({ }) here ({ }) .] ({ }) 
# Sentence pair (1659) source length 18 target length 16 alignment score : 9.10771e-05
The feature value is defined as the difference of sum of the pixels within rectangles . 
NULL ({ }) The ({ 1 }) feature ({ 2 }) value ({ 3 }) is ({ 4 }) defined ({ 5 }) as ({ 6 }) the ({ 7 }) difference ({ 8 }) of ({ 9 }) the ({ }) sum ({ 10 }) of ({ 11 }) the ({ 12 }) pixels ({ 13 }) within ({ 14 }) the ({ }) rectangles ({ 15 }) . ({ 16 }) 
# Sentence pair (1660) source length 12 target length 12 alignment score : 0.00945236
In total , 134 ,736 features were used for training classifiers . 
NULL ({ }) In ({ 1 }) total ({ 2 }) , ({ 3 }) 134 ({ 4 }) ,736 ({ 5 }) features ({ 6 }) were ({ 7 }) used ({ 8 }) for ({ 9 }) training ({ 10 }) classifiers ({ 11 }) . ({ 12 }) 
# Sentence pair (1661) source length 56 target length 53 alignment score : 1.17394e-12
Gabor wavelet features have also often been used in face recognition systems [12] and are defined as : \MATH where \MATH and \MATH define the orientation and scale of the Gabor kernels respectively , \MATH , and the wave vector \MATH , is defined as : \MATH where \MATH , \MATH \MATH . 
NULL ({ }) Gabor ({ 1 }) wavelet ({ 2 }) features ({ 3 }) have ({ 4 }) also ({ 5 }) often ({ 6 }) been ({ 7 }) used ({ 8 }) often ({ }) in ({ 9 }) face ({ 10 }) recognition ({ 11 }) systems ({ 12 }) [12] ({ 13 }) and ({ 14 }) are ({ 15 }) defined ({ 16 }) as ({ 17 }) : ({ 18 }) \MATH ({ 19 }) , ({ }) where ({ 20 }) \MATH ({ 21 }) and ({ 22 }) \MATH ({ 23 }) define ({ 24 }) the ({ 25 }) orientation ({ 26 }) and ({ 27 }) scale ({ 28 }) of ({ 29 }) the ({ 30 }) Gabor ({ 31 }) kernels ({ 32 }) respectively ({ 33 }) , ({ 34 }) \MATH ({ 35 }) , ({ 36 }) and ({ 37 }) the ({ 38 }) wave ({ 39 }) vector ({ 40 }) \MATH ({ 41 }) , ({ 42 }) is ({ 43 }) defined ({ 44 }) as ({ 45 }) : ({ 46 }) \MATH ({ 47 }) where ({ 48 }) \MATH ({ 49 }) , ({ 50 }) \MATH ({ 51 }) and ({ }) \MATH ({ 52 }) . ({ 53 }) 
# Sentence pair (1662) source length 19 target length 19 alignment score : 0.00103533
The Gabor representation of a face image is computed by convolving the face image with the Gabor filters . 
NULL ({ }) The ({ 1 }) Gabor ({ 2 }) representation ({ 3 }) of ({ 4 }) a ({ 5 }) face ({ 6 }) image ({ 7 }) is ({ 8 }) computed ({ 9 }) by ({ 10 }) convolving ({ 11 }) the ({ 12 }) face ({ 13 }) image ({ 14 }) with ({ 15 }) the ({ 16 }) Gabor ({ 17 }) filters ({ 18 }) . ({ 19 }) 
# Sentence pair (1663) source length 30 target length 29 alignment score : 3.95835e-06
Let \MATH be the face image , its convolution with a Gabor filter  ,_( z ) is defined as : \MATH where \MATH denotes the convolution operator . 
NULL ({ }) Let ({ 1 }) \MATH ({ 2 }) be ({ 3 }) the ({ 4 }) face ({ 5 }) image ({ 6 }) ; ({ }) , ({ 7 }) its ({ 8 }) convolution ({ 9 }) with ({ 10 }) a ({ 11 }) Gabor ({ 12 }) filter ({ 13 })  ({ 14 }) ,_( ({ 15 }) z ({ 16 }) ) ({ 17 }) is ({ 18 }) defined ({ 19 }) as ({ 20 }) : ({ 21 }) \MATH ({ 22 }) where ({ 23 }) \MATH ({ 24 }) denotes ({ 25 }) the ({ 26 }) convolution ({ 27 }) operator ({ 28 }) . ({ 29 }) 
# Sentence pair (1664) source length 21 target length 17 alignment score : 2.74295e-07
Similar to [12] , Gabor kernels at five scales \MATH and eight orientations \MATH were used . 
NULL ({ }) Similar ({ 1 }) to ({ 2 }) [12] ({ 3 }) , ({ 4 }) Gabor ({ 5 }) kernels ({ 6 }) at ({ 7 }) five ({ 8 }) scales ({ 9 }) , ({ }) \MATH ({ 10 }) , ({ }) and ({ 11 }) eight ({ 12 }) orientations ({ 13 }) , ({ }) \MATH ({ 14 }) , ({ }) were ({ 15 }) used ({ 16 }) . ({ 17 }) 
# Sentence pair (1665) source length 23 target length 23 alignment score : 0.000423795
At each pixel position , 40 Gabor features are computed by convolving the input image with the real part of Gabor filters . 
NULL ({ }) At ({ 1 }) each ({ 2 }) pixel ({ 3 }) position ({ 4 }) , ({ 5 }) 40 ({ 6 }) Gabor ({ 7 }) features ({ 8 }) are ({ 9 }) computed ({ 10 }) by ({ 11 }) convolving ({ 12 }) the ({ 13 }) input ({ 14 }) image ({ 15 }) with ({ 16 }) the ({ 17 }) real ({ 18 }) part ({ 19 }) of ({ 20 }) Gabor ({ 21 }) filters ({ 22 }) . ({ 23 }) 
# Sentence pair (1666) source length 19 target length 16 alignment score : 3.71658e-07
As a result , \MATH there are \MATH Gabor features for one 24x24 training sample . 
NULL ({ }) As ({ 1 }) a ({ 2 }) result ({ 3 }) , ({ 4 }) one ({ }) \MATH ({ 5 }) training ({ }) sample ({ }) hasthere ({ 6 }) are ({ 7 }) \MATH ({ 8 }) Gabor ({ 9 }) features ({ 10 }) for ({ 11 }) one ({ 12 }) 24x24 ({ 13 }) training ({ 14 }) sample ({ 15 }) . ({ 16 }) 
# Sentence pair (1667) source length 57 target length 53 alignment score : 1.08539e-22
In order to show effectiveness of the proposed feature selection method ( CMI-Multi ) , we compared it with two other feature selection methods that are forward feature selection ( FFS ) [16] and CMI-basedmethod using binary features ( CMIBinary ) [8 , 7] on the data set and feature setsmentioned above . 
NULL ({ 3 }) To ({ 1 }) prove ({ 2 4 }) the ({ }) effectiveness ({ 5 }) of ({ 6 }) the ({ 7 }) proposed ({ 8 }) feature ({ 9 }) selection ({ 10 }) method ({ 11 }) ( ({ 12 }) CMI-Multi ({ 13 }) ) ({ 14 }) , ({ 15 }) we ({ 16 }) compared ({ 17 }) it ({ 18 }) with ({ 19 }) two ({ 20 }) other ({ 21 }) feature ({ 22 }) selection ({ 23 }) methods ({ 24 }) ?that ({ 25 }) are ({ 26 }) forward ({ 27 }) feature ({ 28 }) selection ({ 29 }) ( ({ 30 }) FFS ({ 31 }) ) ({ 32 }) [16] ({ 33 }) and ({ 34 }) a ({ }) CMI-based ({ 35 }) methods ({ }) using ({ 36 }) binary ({ 37 }) features ({ 38 }) ( ({ 39 }) CMI-Binary ({ 40 }) ) ({ 41 }) [8 ({ 42 }) , ({ 43 }) 7] ({ 44 }) ? ({ }) on ({ 45 }) the ({ 46 }) data ({ 47 }) set ({ 48 }) and ({ 49 }) feature ({ 50 }) sets ({ }) mentioned ({ 51 }) described ({ }) above ({ 52 }) . ({ 53 }) 
# Sentence pair (1668) source length 10 target length 10 alignment score : 0.0216296
All classifiers were trained using AdaBoost similar to [1] . 
NULL ({ }) All ({ 1 }) classifiers ({ 2 }) were ({ 3 }) trained ({ 4 }) using ({ 5 }) AdaBoost ({ 6 }) similar ({ 7 }) to ({ 8 }) [1] ({ 9 }) . ({ 10 }) 
# Sentence pair (1669) source length 47 target length 43 alignment score : 2.05919e-13
We chose the forward feature selection proposed by Wu et. al. [16] because it has very impressive results when not only reducing significantly the training time of AdaBoost-based face detection system [1] ( about 100 times ) but also maintaining comparable performance . 
NULL ({ }) We ({ 1 }) chose ({ 2 }) the ({ 3 }) forward ({ 4 }) feature ({ 5 }) selection ({ 6 }) proposed ({ 7 }) by ({ 8 }) Wu ({ 9 }) et. ({ 10 }) al. ({ 11 }) [16] ({ 12 }) because ({ 13 }) it ({ 14 }) has ({ 15 }) very ({ 16 }) impressive ({ 17 }) results ({ 18 }) , ({ }) when ({ 19 }) not ({ 20 }) only ({ 21 }) reducing ({ 22 }) significantly ({ 23 }) the ({ 24 }) training ({ 25 }) time ({ 26 }) of ({ 27 }) the ({ }) AdaBoost-based ({ 28 }) face ({ 29 }) detection ({ 30 }) systems ({ 31 }) [1] ({ 32 }) by ({ }) ( ({ 33 }) about ({ 34 }) 100 ({ 35 }) times ({ 36 }) , ({ }) ) ({ 37 }) but ({ 38 }) also ({ 39 }) maintaining ({ 40 }) comparable ({ 41 }) performance ({ 42 }) . ({ 43 }) 
# Sentence pair (1670) source length 18 target length 18 alignment score : 0.00281305
Figure 2 shows performance of classifiers trained by Haar feature subsets selected by three feature selection methods . 
NULL ({ }) Figure ({ 1 }) 2 ({ 2 }) shows ({ 3 }) performance ({ 4 }) of ({ 5 }) classifiers ({ 6 }) trained ({ 7 }) by ({ 8 }) Haar ({ 9 }) feature ({ 10 }) subsets ({ 11 }) selected ({ 12 }) by ({ 13 }) three ({ 14 }) feature ({ 15 }) selection ({ 16 }) methods ({ 17 }) . ({ 18 }) 
# Sentence pair (1671) source length 28 target length 19 alignment score : 1.01668e-13
It indicates that , the proposed method CMI-Multi outperforms the others while FFS and CMI-Binary have comparable performance . 
NULL ({ }) The ({ }) figureIt ({ 1 }) indicates ({ 2 }) that ({ 3 }) , ({ 4 }) the ({ 5 }) proposed ({ 6 }) method ({ 7 }) , ({ }) CMI-Multi ({ 8 }) , ({ }) outperforms ({ 9 }) the ({ 10 }) others ({ 11 }) while ({ 12 }) the ({ }) performances ({ }) of ({ }) FFS ({ 13 }) and ({ 14 }) CMI-Binary ({ 15 }) have ({ 16 }) were ({ }) comparable ({ 17 }) performanceto ({ 18 }) one ({ }) another ({ }) . ({ 19 }) 
# Sentence pair (1672) source length 21 target length 13 alignment score : 8.76363e-13
The similar result is also shown when tested on Gabor wavelet features . 
NULL ({ }) The ({ 1 }) A ({ }) similar ({ 2 }) result ({ 3 }) is ({ 4 }) was ({ }) also ({ 5 }) shown ({ 6 }) when ({ 7 }) the ({ }) three ({ }) feature ({ }) selection ({ }) methods ({ }) were ({ }) tested ({ 8 }) on ({ 9 }) Gabor ({ 10 }) wavelet ({ 11 }) features ({ 12 }) . ({ 13 }) 
# Sentence pair (1673) source length 25 target length 22 alignment score : 4.87245e-09
In this case , CMI-based feature selection methods obviously outperform FFS and CMI-Multi is confirmed to be more efficient than CMI-Binary . 
NULL ({ }) In ({ 1 }) this ({ 2 }) case ({ 3 }) , ({ 4 }) CMI-based ({ 5 }) feature ({ 6 }) selection ({ 7 }) methods ({ 8 }) obviously ({ 9 }) clearly ({ 10 }) outperformed ({ }) FFS ({ 11 }) , ({ }) and ({ 12 }) CMI-Multi ({ 13 }) is ({ 14 }) was ({ }) confirmed ({ 15 }) to ({ 16 }) be ({ 17 }) more ({ 18 }) efficient ({ 19 }) than ({ 20 }) CMI-Binary ({ 21 }) . ({ 22 }) 
# Sentence pair (1674) source length 26 target length 25 alignment score : 4.36561e-06
Because our proposed method uses same principle as FFS which only trains weak classifiers once , it is extremely fast compared with AdaBoost [1] . 
NULL ({ }) Because ({ 1 }) our ({ 2 }) proposed ({ 3 }) method ({ 4 }) uses ({ 5 }) same ({ 6 }) principle ({ 7 }) as ({ 8 }) FFS ({ 9 }) , ({ }) which ({ 10 }) only ({ 11 }) trains ({ 12 }) weak ({ 13 }) classifiers ({ 14 }) once ({ 15 }) , ({ 16 }) it ({ 17 }) is ({ 18 }) extremely ({ 19 }) fast ({ 20 }) compared ({ 21 }) with ({ 22 }) AdaBoost ({ 23 }) [1] ({ 24 }) . ({ 25 }) 
# Sentence pair (1675) source length 18 target length 18 alignment score : 0.0020384
We built two cascade of AdaBoost classifiers that use CMI-Multi and AdaBoost [1] as feature selection methods . 
NULL ({ }) We ({ 1 }) built ({ 2 }) two ({ 3 }) cascades ({ 4 }) of ({ 5 }) AdaBoost ({ 6 }) classifiers ({ 7 }) that ({ 8 }) use ({ 9 }) CMI-Multi ({ 10 }) and ({ 11 }) AdaBoost ({ 12 }) [1] ({ 13 }) as ({ 14 }) feature ({ 15 }) selection ({ 16 }) methods ({ 17 }) . ({ 18 }) 
# Sentence pair (1676) source length 14 target length 14 alignment score : 0.0106908
Testing on the standard benchmark MIT+CMU test set , they have comparable performance . 
NULL ({ }) Testing ({ 1 }) on ({ 2 }) the ({ 3 }) standard ({ 4 }) benchmark ({ 5 }) MIT+CMU ({ 6 }) test ({ 7 }) set ({ 8 }) , ({ 9 }) they ({ 10 }) hadve ({ 11 }) comparable ({ 12 }) performance ({ 13 }) . ({ 14 }) 
# Sentence pair (1677) source length 14 target length 12 alignment score : 9.32093e-05
However , CMI-Multi is trained faster than AdaBoost approximately 70 times . 
NULL ({ }) However ({ 1 }) , ({ 2 }) CMI-Multi ({ 3 }) wasis ({ 4 }) trained ({ 5 }) faster ({ 6 }) than ({ 7 }) was ({ }) AdaBoost ({ 8 }) by ({ }) approximately ({ 9 }) 70 ({ 10 }) times ({ 11 }) . ({ 12 }) 
# Sentence pair (1678) source length 18 target length 18 alignment score : 0.00112922
We have presented a fast feature selection method using conditional mutual information to handle huge feature sets . 
NULL ({ }) We ({ 1 }) have ({ 2 }) presented ({ 3 }) a ({ 4 }) fast ({ 5 }) feature ({ 6 }) selection ({ 7 }) method ({ 8 }) using ({ 9 }) conditional ({ 10 }) mutual ({ 11 }) information ({ 12 }) to ({ 13 }) handle ({ 14 }) huge ({ 15 }) feature ({ 16 }) sets ({ 17 }) . ({ 18 }) 
# Sentence pair (1679) source length 15 target length 14 alignment score : 0.00140775
The estimation of mutual information is simplified by using MDLP based discretization method . 
NULL ({ }) The ({ 1 }) estimation ({ 2 }) of ({ 3 }) mutual ({ 4 }) information ({ 5 }) is ({ 6 }) simplified ({ 7 }) by ({ 8 }) using ({ 9 }) an ({ }) MDLP- ({ 10 }) based ({ 11 }) discretization ({ 12 }) method ({ 13 }) . ({ 14 }) 
# Sentence pair (1680) source length 26 target length 23 alignment score : 1.94781e-09
Integrated into AdaBoost-based object detection systems , it can not only reduce the training time significantly but also achieve high classification performance . 
NULL ({ }) Integrated ({ 1 }) into ({ 2 }) AdaBoost-based ({ 3 }) object ({ 4 }) detection ({ 5 }) systems ({ 6 }) , ({ 7 }) our ({ }) proposed ({ }) methodit ({ 8 }) can ({ 9 }) not ({ 10 }) only ({ 11 }) reduces ({ 12 }) the ({ 13 }) training ({ 14 }) time ({ 15 }) significantly ({ 16 }) , ({ }) but ({ 17 }) also ({ 18 }) achieves ({ 19 }) high ({ 20 }) classification ({ 21 }) performance ({ 22 }) . ({ 23 }) 
# Sentence pair (1681) source length 51 target length 22 alignment score : 1.62618e-35
Experiments on two popular feature sets such as Haar wavelets and Gabor wavelets have demonstrated the effectiveness of the proposed method . 
NULL ({ }) Experiments ({ 1 }) on ({ 2 }) two ({ 3 }) popular ({ 4 }) feature ({ 5 }) sets ({ 6 }) have ({ }) demonstrated ({ 15 }) the ({ 16 }) effectiveness ({ 17 }) of ({ }) the ({ }) proposed ({ 20 }) method ({ 21 }) . ({ 22 }) //[Please ({ 14 }) note ({ }) : ({ }) I ({ }) am ({ }) not ({ }) sure ({ }) which ({ }) of ({ }) the ({ }) following ({ }) you ({ }) mean ({ }) .--> ({ }) one ({ }) composed ({ }) of ({ 18 }) such ({ 7 }) as ({ 8 }) Haar ({ 9 }) wavelets ({ }) and ({ }) the ({ }) other ({ }) composed ({ }) of ({ }) Gabor ({ }) wavelets ({ }) / ({ }) ? ({ }) Haar ({ }) wavelets ({ 10 }) and ({ 11 }) Gabor ({ 12 }) wavelets ({ 13 }) ?] ({ 19 }) 
# Sentence pair (1682) source length 7 target length 7 alignment score : 0.0864645
A Multi-Stage Approach to Fast Face Detection 
NULL ({ }) A ({ 1 }) Multi-Stage ({ 2 }) Approach ({ 3 }) to ({ 4 }) Fast ({ 5 }) Face ({ 6 }) Detection ({ 7 }) 
# Sentence pair (1683) source length 20 target length 21 alignment score : 8.18016e-16
A multi-stage approach --- which is fast , robust and easy to train --- for a face-detection system is proposed . 
NULL ({ }) A ({ 1 }) multi-stage ({ 2 }) approach ({ 3 }) that ({ 5 }) is ({ 6 }) fast ({ 7 }) , ({ 8 }) robust ({ 9 }) , ({ }) and ({ 10 }) easy ({ 11 }) to ({ 12 }) train ({ 13 }) is ({ 19 }) proposed ({ 20 }) for ({ 15 }) a ({ 16 }) face-detection ({ 4 14 17 }) system ({ 18 }) . ({ 21 }) 
# Sentence pair (1684) source length 34 target length 34 alignment score : 6.3407e-10
Motivated by the work of Viola and Jones [1] , this approach uses a cascade of classifiers to yield a coarse-to-fine strategy to reduce significantly detection time while maintaining a high detection rate . 
NULL ({ }) Motivated ({ 1 }) by ({ 2 }) the ({ 3 }) work ({ 4 }) of ({ 5 }) Viola ({ 6 }) and ({ 7 }) Jones ({ 8 }) [1] ({ 9 }) , ({ 10 }) this ({ 11 }) approach ({ 12 }) uses ({ 13 }) a ({ 14 }) cascade ({ 15 }) of ({ 16 }) classifiers ({ 17 }) to ({ 18 }) yield ({ 19 }) a ({ 20 }) coarse-to-fine ({ 21 }) strategy ({ 22 }) to ({ 23 }) significantly ({ 25 }) reduce ({ 24 }) detection ({ 26 }) time ({ 27 }) while ({ 28 }) maintaining ({ 29 }) a ({ 30 }) high ({ 31 }) detection ({ 32 }) rate ({ 33 }) . ({ 34 }) 
# Sentence pair (1685) source length 15 target length 12 alignment score : 5.07654e-06
However , it is distinguished from previous work by two features . 
NULL ({ }) However ({ 1 }) , ({ 2 }) our ({ }) [system ({ 3 }) / ({ }) approach?] ({ }) is ({ 4 }) distinguished ({ 5 }) from ({ 6 }) previous ({ 7 }) work ({ 8 }) by ({ 9 }) two ({ 10 }) features ({ 11 }) . ({ 12 }) 
# Sentence pair (1686) source length 27 target length 26 alignment score : 1.6528e-06
First , a new stage is added to detect face candidate regions more quickly by using a larger window size and larger moving step size . 
NULL ({ }) First ({ 1 }) , ({ 2 }) a ({ 3 }) new ({ 4 }) stage ({ 5 }) has ({ 6 }) been ({ }) added ({ 7 }) to ({ 8 }) detect ({ 9 }) face ({ 10 }) candidate ({ 11 }) regions ({ 12 }) more ({ 13 }) quickly ({ 14 }) by ({ 15 }) using ({ 16 }) a ({ 17 }) larger ({ 18 }) window ({ 19 }) size ({ 20 }) and ({ 21 }) larger ({ 22 }) moving ({ 23 }) step ({ 24 }) size ({ 25 }) . ({ 26 }) 
# Sentence pair (1687) source length 39 target length 34 alignment score : 2.34226e-13
Second , SVM classifiers are used instead of AdaBoost classifiers in the last stage , and Haar wavelet features selected by the previous stage are reused for the SVM classifier robustly and efficiently . 
NULL ({ }) Second ({ 1 }) , ({ 2 }) support ({ }) vector ({ }) machine ({ }) ( ({ }) SVM ({ 3 }) ) ({ }) classifiers ({ 4 }) are ({ 5 }) used ({ 6 }) instead ({ 7 }) of ({ 8 }) AdaBoost ({ 9 }) classifiers ({ 10 }) in ({ 11 }) the ({ 12 }) last ({ 13 }) stage ({ 14 }) , ({ 15 }) and ({ 16 }) Haar ({ 17 }) wavelet ({ 18 }) features ({ 19 }) selected ({ 20 }) by ({ 21 }) the ({ 22 }) previous ({ 23 }) stage ({ 24 }) are ({ 25 }) reused ({ 26 }) for ({ 27 }) the ({ 28 }) SVM ({ 29 }) classifier ({ 30 }) robustly ({ 31 }) and ({ 32 }) efficiently ({ 33 }) . ({ 34 }) 
# Sentence pair (1688) source length 44 target length 44 alignment score : 2.95115e-09
By combining AdaBoost and SVM classifiers , the final system can achieve both fast and robust detection because most non-face patterns are rejected quickly in earlier layers , while only a small number of promising face patterns is classified robustly in later layers . 
NULL ({ }) By ({ 1 }) combining ({ 2 }) AdaBoost ({ 3 }) and ({ 4 }) SVM ({ 5 }) classifiers ({ 6 }) , ({ 7 }) the ({ 8 }) final ({ 9 }) system ({ 10 }) can ({ 11 }) achieve ({ 12 }) both ({ 13 }) fast ({ 14 }) and ({ 15 }) robust ({ 16 }) detection ({ 17 }) because ({ 18 }) most ({ 19 }) non-face ({ 20 }) patterns ({ 21 }) are ({ 22 }) rejected ({ 23 }) quickly ({ 24 }) in ({ 25 }) earlier ({ 26 }) layers ({ 27 }) , ({ 28 }) while ({ 29 }) only ({ 30 }) a ({ 31 }) small ({ 32 }) number ({ 33 }) of ({ 34 }) promising ({ 35 }) face ({ 36 }) patterns ({ 37 }) are ({ 38 }) classified ({ 39 }) robustly ({ 40 }) in ({ 41 }) later ({ 42 }) layers ({ 43 }) . ({ 44 }) 
# Sentence pair (1689) source length 20 target length 19 alignment score : 2.02561e-05
The proposed multi-stage-based system is shown to run faster than the original AdaBoost-based system while maintaining comparable accuracy . 
NULL ({ }) The ({ 1 }) proposed ({ 2 }) multi-stage-based ({ 3 }) system ({ 4 }) has ({ 5 }) been ({ }) shown ({ 6 }) to ({ 7 }) run ({ 8 }) faster ({ 9 }) than ({ 10 }) the ({ 11 }) original ({ 12 }) AdaBoost-based ({ 13 }) system ({ 14 }) while ({ 15 }) maintaining ({ 16 }) comparable ({ 17 }) accuracy ({ 18 }) . ({ 19 }) 
# Sentence pair (1690) source length 34 target length 34 alignment score : 7.11411e-06
Face detection is one of the most active research areas in computer vision because of its many interesting applications in fields such as security , surveillance , multimedia retrieval , and human-computer interaction . 
NULL ({ }) Face ({ 1 }) detection ({ 2 }) is ({ 3 }) one ({ 4 }) of ({ 5 }) the ({ 6 }) most ({ 7 }) active ({ 8 }) research ({ 9 }) areas ({ 10 }) in ({ 11 }) computer ({ 12 }) vision ({ 13 }) because ({ 14 }) of ({ 15 }) its ({ 16 }) many ({ 17 }) interesting ({ 18 }) applications ({ 19 }) in ({ 20 }) fields ({ 21 }) such ({ 22 }) as ({ 23 }) security ({ 24 }) , ({ 25 }) surveillance ({ 26 }) , ({ 27 }) multimedia ({ 28 }) retrieval ({ 29 }) , ({ 30 }) and ({ 31 }) human-computer ({ 32 }) interaction ({ 33 }) . ({ 34 }) 
# Sentence pair (1691) source length 20 target length 22 alignment score : 1.18611e-09
For example , face detection is combined with other modules to identify who a person in a video sequence is [2] . 
NULL ({ 20 }) For ({ 1 }) example ({ 2 }) , ({ 3 }) face ({ 4 }) detection ({ 5 }) is ({ 6 }) combined ({ 7 }) with ({ 8 }) other ({ 9 }) modules ({ 10 }) to ({ 11 }) identify ({ 12 13 }) a ({ 14 }) person ({ 15 }) in ({ 16 }) a ({ 17 }) video ({ 18 }) sequence ({ 19 }) [2] ({ 21 }) . ({ 22 }) 
# Sentence pair (1692) source length 25 target length 25 alignment score : 6.76408e-05
Face locations , the results of a face detection system , can be used for applications such as face recognition and video indexing [3] . 
NULL ({ }) Face ({ 1 }) locations ({ 2 }) , ({ 3 }) the ({ 4 }) results ({ 5 }) of ({ 6 }) a ({ 7 }) face ({ 8 }) detection ({ 9 }) system ({ 10 }) , ({ 11 }) can ({ 12 }) be ({ 13 }) used ({ 14 }) for ({ 15 }) applications ({ 16 }) such ({ 17 }) as ({ 18 }) face ({ 19 }) recognition ({ 20 }) and ({ 21 }) video ({ 22 }) indexing ({ 23 }) [3] ({ 24 }) . ({ 25 }) 
# Sentence pair (1693) source length 59 target length 58 alignment score : 2.00407e-12
Although it has been studied for more than 30 years , developing a fast and robust face detection system that can handle the variations found in different faces in real applications , such as facial expressions , pose changes , illumination changes , complex backgrounds , and low resolutions , is still a challenging research target [4] . 
NULL ({ }) Although ({ 1 }) this ({ }) area ({ 2 }) has ({ 3 }) been ({ 4 }) studied ({ 5 }) for ({ 6 }) more ({ 7 }) than ({ 8 }) 30 ({ 9 }) years ({ 10 }) , ({ 11 }) developing ({ 12 }) a ({ 13 }) fast ({ 14 }) and ({ 15 }) robust ({ 16 }) face ({ 17 }) detection ({ 18 }) system ({ 19 }) that ({ 20 }) can ({ 21 }) handle ({ 22 }) the ({ 23 }) variations ({ 24 }) found ({ 25 }) in ({ 26 }) different ({ 27 }) faces ({ 28 }) in ({ 29 }) real ({ 30 }) applications ({ 31 }) , ({ 32 }) such ({ 33 }) as ({ 34 }) facial ({ 35 }) expressions ({ 36 }) , ({ 37 }) pose ({ 38 }) changes ({ 39 }) , ({ 40 }) illumination ({ 41 }) changes ({ 42 }) , ({ 43 }) complex ({ 44 }) backgrounds ({ 45 }) , ({ 46 }) and ({ 47 }) low ({ 48 }) resolutions ({ 49 }) , ({ 50 }) is ({ 51 }) still ({ 52 }) a ({ 53 }) challenging ({ 54 }) research ({ 55 }) target ({ 56 }) [4] ({ 57 }) . ({ 58 }) 
# Sentence pair (1694) source length 46 target length 39 alignment score : 8.22898e-19
Recently , with advances in machine learning research , Neural Network [5] ,[6] , Support Vector Machines ( SVM ) [7] ,[8] ,[9] and AdaBoost [1] ,[10] ,[11] ,[12] ,[13] are typical choices for building robust face detectors . 
NULL ({ }) Recently ({ 1 }) , ({ 2 }) with ({ 3 }) advances ({ 4 }) in ({ 5 }) machine ({ 6 }) learning ({ 7 }) research ({ 8 }) , ({ 9 }) neural ({ 10 }) networks ({ 11 }) [5] ({ 12 }) , ({ }) [6] ({ 13 }) , ({ 14 }) support ({ 15 }) vector ({ 16 }) machines ({ 17 }) ( ({ 18 }) SVM ({ 19 }) ) ({ 20 }) [7] ({ 21 }) , ({ }) [8] ({ 22 }) , ({ }) [9] ({ 23 }) and ({ 24 }) AdaBoost ({ 25 }) [1] ({ 26 }) , ({ }) [10] ({ 27 }) , ({ }) [11] ({ 28 }) , ({ }) [12] ({ 29 }) , ({ }) [13] ({ 30 }) are ({ 31 }) typical ({ 32 }) choices ({ 33 }) for ({ 34 }) building ({ 35 }) robust ({ 36 }) face ({ 37 }) detectors ({ 38 }) . ({ 39 }) 
# Sentence pair (1695) source length 14 target length 14 alignment score : 0.00741941
Current research is focusing on feature extractions and appropriate structures for combining classifiers . 
NULL ({ }) Current ({ 1 }) research ({ 2 }) is ({ 3 }) focusing ({ 4 }) on ({ 5 }) feature ({ 6 }) extractions ({ 7 }) and ({ 8 }) appropriate ({ 9 }) structures ({ 10 }) for ({ 11 }) combining ({ 12 }) classifiers ({ 13 }) . ({ 14 }) 
# Sentence pair (1696) source length 36 target length 28 alignment score : 1.34162e-12
Generally , to classify an input pattern of intensities as a face or non-face , features must be extracted and normalized before passing to a classifier [14] . 
NULL ({ }) Generally ({ 1 }) , ({ 2 }) to ({ 3 }) classify ({ 4 }) an ({ 5 }) input ({ 6 }) pattern ({ 7 }) of ({ 8 }) intensities ({ 9 }) as ({ 10 }) a ({ 11 }) face ({ 12 }) or ({ 13 }) non-face ({ 14 }) , ({ 15 }) features ({ 16 }) must ({ 17 }) be ({ 18 }) extracted ({ 19 }) and ({ 20 }) normalized ({ 21 }) before ({ 22 }) passing ({ 23 }) [the ({ 24 }) image ({ }) / ({ }) the ({ }) pattern ({ }) / ({ }) the ({ }) results?] ({ 25 }) to ({ }) a ({ }) classifier ({ 26 }) [14] ({ 27 }) . ({ 28 }) 
# Sentence pair (1697) source length 50 target length 47 alignment score : 2.00634e-28
There are many kinds of features that have been used ranging from simple features such as intensity values [7] ,[5] and eigenspace [15] to complex features such as wavelets [16] ,[1] ,[12] , edge orientation histograms [17] ,[18] and Bayesian discriminating features ( BDF ) [19] . 
NULL ({ 2 7 }) Many ({ 1 3 }) kinds ({ 4 }) of ({ 5 }) features ({ 6 }) have ({ 8 }) been ({ 9 }) used ({ 10 }) , ({ }) ranging ({ 11 }) from ({ 12 }) simple ({ 13 }) ones ({ 14 }) such ({ 15 }) as ({ 16 }) intensity ({ 17 }) values ({ 18 }) [7] ({ 19 }) , ({ }) [5] ({ 20 }) and ({ 21 }) eigenspace ({ 22 }) [15] ({ 23 }) to ({ 24 }) complex ({ 25 }) ones ({ 26 }) such ({ 27 }) as ({ 28 }) wavelets ({ 29 }) [16] ({ 30 }) , ({ }) [1] ({ 31 }) , ({ }) [12] ({ 32 }) , ({ 33 }) edge ({ 34 }) orientation ({ 35 }) histograms ({ 36 }) [17] ({ 37 }) , ({ }) [18] ({ 38 }) , ({ }) and ({ 39 }) Bayesian ({ 40 }) discriminating ({ 41 }) features ({ 42 }) ( ({ 43 }) BDF ({ 44 }) ) ({ 45 }) [19] ({ 46 }) . ({ 47 }) 
# Sentence pair (1698) source length 17 target length 17 alignment score : 3.18667e-07
Discriminative and informative features usually increase detection rate and reduce complexity of the training procedure [17] . 
NULL ({ 13 }) Discriminative ({ 1 }) and ({ 2 }) informative ({ 3 }) features ({ 4 }) usually ({ 5 }) increase ({ 6 }) detection ({ 7 }) rates ({ 8 }) and ({ 9 }) reduce ({ 10 }) the ({ }) complexity ({ 11 }) of ({ 12 }) training ({ 14 }) procedures ({ 15 }) [17] ({ 16 }) . ({ 17 }) 
# Sentence pair (1699) source length 48 target length 48 alignment score : 8.99297e-10
In a typical face detector which is scale-free and location-free , the number of analyzed patterns is usually very large ( 160 ,000 patterns for a 320x240 pixel image ) because the face classifier has to scan over the input image at every location and every scale . 
NULL ({ }) In ({ 1 }) a ({ 2 }) typical ({ 3 }) face ({ 4 }) detector ({ 5 }) that ({ 6 }) is ({ 7 }) scale- ({ 8 }) and ({ 9 }) location-free ({ 10 }) , ({ 11 }) the ({ 12 }) number ({ 13 }) of ({ 14 }) analyzed ({ 15 }) patterns ({ 16 }) is ({ 17 }) usually ({ 18 }) very ({ 19 }) large ({ 20 }) ( ({ 21 }) 160 ({ 22 }) ,000 ({ 23 }) patterns ({ 24 }) for ({ 25 }) a ({ 26 }) 320x240 ({ 27 }) pixel ({ 28 }) image ({ 29 }) ) ({ 30 }) because ({ 31 }) the ({ 32 }) face ({ 33 }) classifier ({ 34 }) has ({ 35 }) to ({ 36 }) scan ({ 37 }) over ({ 38 }) the ({ 39 }) input ({ 40 }) image ({ 41 }) at ({ 42 }) every ({ 43 }) location ({ 44 }) and ({ 45 }) every ({ 46 }) scale ({ 47 }) . ({ 48 }) 
# Sentence pair (1700) source length 12 target length 12 alignment score : 0.00303904
However , the huge majority of the analyzed patterns are non-face . 
NULL ({ }) However ({ 1 }) , ({ 2 }) the ({ 3 }) vast ({ 4 }) majority ({ 5 }) of ({ 6 }) the ({ 7 }) analyzed ({ 8 }) patterns ({ 9 }) are ({ 10 }) non-face ({ 11 }) . ({ 12 }) 
# Sentence pair (1701) source length 20 target length 20 alignment score : 0.000143104
Statistics from [9] have shown that the ratio of non-face to face patterns is about 50 ,000 to 1 . 
NULL ({ }) Statistics ({ 1 }) from ({ 2 }) [9] ({ 3 }) have ({ 4 }) shown ({ 5 }) that ({ 6 }) the ({ 7 }) ratio ({ 8 }) of ({ 9 }) non-face ({ 10 }) to ({ 11 }) face ({ 12 }) patterns ({ 13 }) is ({ 14 }) about ({ 15 }) 50 ({ 16 }) ,000 ({ 17 }) to ({ 18 }) 1 ({ 19 }) . ({ 20 }) 
# Sentence pair (1702) source length 36 target length 34 alignment score : 5.98435e-19
Face detectors based on single classifiers such as SVM [7] ,[8] ,[9] and Neural Network [6] ,[5] are usually slow because they process non-face regions and face regions in the input image equally . 
NULL ({ }) Face ({ 1 }) detectors ({ 2 }) based ({ 3 }) on ({ 4 }) single ({ 5 }) classifiers ({ 6 }) such ({ 7 }) as ({ 8 }) SVM ({ 9 }) [7] ({ 10 }) , ({ }) [8] ({ 11 }) , ({ }) [9] ({ 12 }) and ({ 13 }) neural ({ 14 }) networks ({ 15 }) [6] ({ 16 }) , ({ }) [5] ({ 17 }) are ({ 18 }) usually ({ 19 }) slow ({ 20 }) because ({ 21 }) they ({ 22 }) equally ({ 33 }) process ({ 23 }) non-face ({ 24 25 }) and ({ 26 }) face ({ 27 }) regions ({ 28 }) in ({ 29 }) the ({ 30 }) input ({ 31 }) image ({ 32 }) . ({ 34 }) 
# Sentence pair (1703) source length 33 target length 27 alignment score : 4.51248e-13
To deal with the problem of processing a large number of patterns , a combination of simple-to-complex classifiers is proposed [8] ,[1] ,[9] ,[20] ,[21] ,[11] . 
NULL ({ }) To ({ 1 }) deal ({ 2 }) with ({ 3 }) the ({ 4 }) problem ({ 5 }) of ({ 6 }) processing ({ 7 }) a ({ 8 }) large ({ 9 }) number ({ 10 }) of ({ 11 }) patterns ({ 12 }) , ({ 13 }) a ({ 14 }) combination ({ 15 }) of ({ 16 }) simple-to-complex ({ 17 }) classifiers ({ 18 }) has ({ 19 }) been ({ }) proposed ({ 20 }) [8] ({ 21 }) , ({ }) [1] ({ 22 }) , ({ }) [9] ({ 23 }) , ({ }) [20] ({ 24 }) , ({ }) [21] ({ 25 }) , ({ }) [11] ({ 26 }) . ({ 27 }) 
# Sentence pair (1704) source length 45 target length 39 alignment score : 1.67864e-13
In particular , fast and simple classifiers are used as filters at the earliest stages to quickly reject a large number of non-face patterns and a slower yet more accurate classifier is then used for classifying face-like patterns . 
NULL ({ }) In ({ 1 }) particular ({ 2 }) , ({ 3 }) fast ({ 4 }) and ({ 5 }) simple ({ 6 }) classifiers ({ 7 }) are ({ 8 }) [recommended ({ 9 }) to ({ }) be?] ({ }) used ({ }) as ({ 10 }) filters ({ 11 }) at ({ 12 }) the ({ 13 }) earliest ({ 14 }) stages ({ 15 }) to ({ 16 }) quickly ({ 17 }) reject ({ 18 }) a ({ 19 }) large ({ 20 }) number ({ 21 }) of ({ 22 }) non-face ({ 23 }) patterns ({ 24 }) and ({ 25 }) a ({ 26 }) slower ({ 27 }) yet ({ 28 }) more ({ 29 }) accurate ({ 30 }) classifier ({ 31 }) is ({ 32 }) then ({ 33 }) recommended ({ }) to ({ }) be ({ }) used ({ 34 }) for ({ 35 }) classifying ({ 36 }) face-like ({ 37 }) patterns ({ 38 }) . ({ 39 }) 
# Sentence pair (1705) source length 26 target length 19 alignment score : 2.12571e-12
By this way , the complexity of classifiers is adapted corresponding to the difficulty in the input patterns . 
NULL ({ }) In ({ 1 }) this ({ 2 }) way ({ 3 }) , ({ 4 }) the ({ 5 }) complexity ({ 6 }) of ({ 7 }) classifiers ({ 8 }) can ({ }) be ({ }) adapted ({ 10 }) corresponding ({ 11 }) to ({ 12 }) the ({ 13 }) difficulty ({ 14 }) in ({ 15 }) the ({ 16 }) input ({ 17 }) patterns ({ 18 }) . ({ 19 }) / ({ }) / ({ }) [is ({ }) / ({ }) can ({ }) be?] ({ 9 }) 
# Sentence pair (1706) source length 66 target length 67 alignment score : 7.44171e-23
In [8] , non linear SVM classifiers using pixel-based features are arranged into a sequence with increasing number of support vectors , or in [9] , linear SVM classifiers trained at different resolutions are used for rejection and a reduced set of principle component analysis ( PCA )-based features are used with the non linear SVM at the classification stage in order to reduce computation time . 
NULL ({ }) In ({ 1 }) [8] ({ 2 }) , ({ 3 }) nonlinear ({ 4 5 }) SVM ({ 6 }) classifiers ({ 7 }) using ({ 8 }) pixel-based ({ 9 }) features ({ 10 }) were ({ 11 }) arranged ({ 12 }) into ({ 13 }) a ({ 14 }) sequence ({ 15 }) by ({ 16 }) increasing ({ 17 }) the ({ }) number ({ 18 }) of ({ 19 }) support ({ 20 }) vectors ({ 21 }) , ({ 22 }) while ({ 23 }) in ({ 24 }) [9] ({ 25 }) , ({ 26 }) linear ({ 27 }) SVM ({ 28 }) classifiers ({ 29 }) trained ({ 30 }) at ({ 31 }) different ({ 32 }) resolutions ({ 33 }) were ({ 34 }) used ({ 35 }) for ({ 36 }) rejection ({ 37 }) and ({ 38 }) a ({ 39 }) reduced ({ 40 }) set ({ 41 }) of ({ 42 }) principle ({ 43 }) component ({ 44 }) analysis ({ 45 }) ( ({ 46 }) PCA ({ 47 }) )-based ({ 48 }) features ({ 49 }) were ({ 50 }) used ({ 51 }) with ({ 52 }) the ({ 53 }) nonlinear ({ 54 55 }) SVM ({ 56 }) at ({ 57 }) the ({ 58 }) classification ({ 59 }) stage ({ 60 }) in ({ 61 }) order ({ 62 }) to ({ 63 }) reduce ({ 64 }) computation ({ 65 }) time ({ 66 }) . ({ 67 }) 
# Sentence pair (1707) source length 16 target length 17 alignment score : 1.25928e-06
In [1] , AdaBoost based classifiers are arranged in a degeneration decision tree or a cascade . 
NULL ({ }) In ({ 1 }) [1] ({ 2 }) , ({ 3 }) AdaBoost-based ({ 4 5 }) classifiers ({ 6 }) were ({ 7 }) arranged ({ 8 }) in ({ 9 }) a ({ 10 }) degeneration ({ 11 }) decision ({ 12 }) tree ({ 13 }) or ({ 14 }) a ({ 15 }) cascade ({ 16 }) . ({ 17 }) 
# Sentence pair (1708) source length 19 target length 19 alignment score : 0.000261522
Using about 10 features of the first two layers , more than 90\% of non-face patterns are rejected . 
NULL ({ }) Using ({ 1 }) about ({ 2 }) 10 ({ 3 }) features ({ 4 }) of ({ 5 }) the ({ 6 }) first ({ 7 }) two ({ 8 }) layers ({ 9 }) , ({ 10 }) more ({ 11 }) than ({ 12 }) 90\% ({ 13 }) of ({ 14 }) non-face ({ 15 }) patterns ({ 16 }) were ({ 17 }) rejected ({ 18 }) . ({ 19 }) 
# Sentence pair (1709) source length 18 target length 16 alignment score : 2.48351e-05
Recently , boosting chain [20] and nested cascade [11] have also been proposed for improvements . 
NULL ({ }) Recently ({ 1 }) , ({ 2 }) a ({ }) boosting ({ 3 }) chain ({ 4 }) [20] ({ 5 }) and ({ 6 }) a ({ }) nested ({ 7 }) cascade ({ 8 }) [11] ({ 9 }) have ({ 10 }) also ({ 11 }) been ({ 12 }) proposed ({ 13 }) for ({ 14 }) improvements ({ 15 }) . ({ 16 }) 
# Sentence pair (1710) source length 47 target length 21 alignment score : 9.51759e-33
It is believed that the cascade structure of classifiers is the key factor in enhancement of current real-time face detectors . 
NULL ({ }) It ({ 1 }) is ({ 2 }) believed ({ 3 }) that ({ 4 }) the ({ 5 }) cascade ({ 6 }) structure ({ 7 }) of ({ 8 }) classifiers ({ 9 }) is ({ 10 }) the ({ 11 }) key ({ 12 }) factor ({ 13 }) in ({ 14 }) enhancement ({ 15 }) of ({ 16 }) current ({ 17 }) real-time ({ 18 }) face ({ 19 }) detectors ({ 20 }) . ({ 21 }) / ({ }) / ({ }) It ({ }) is ({ }) believed?This ({ }) sounds ({ }) vague?who ({ }) believes ({ }) this? ({ }) " ({ }) May ({ }) researchers ({ }) believe ({ }) , ({ }) " ({ }) for ({ }) example ({ }) , ({ }) would ({ }) be ({ }) clearer ({ }) and ({ }) sound ({ }) more ({ }) believable ({ }) .] ({ }) 
# Sentence pair (1711) source length 21 target length 20 alignment score : 7.45253e-05
This work is motivated by Viola and Jones [1] who proposed a framework for fast and robust face detection . 
NULL ({ }) This ({ 1 }) work ({ 2 }) is ({ 3 }) motivated ({ 4 }) by ({ 5 }) Viola ({ 6 }) and ({ 7 }) Jones ({ 8 }) [1] ({ 9 }) , ({ }) who ({ 10 }) proposed ({ 11 }) a ({ 12 }) framework ({ 13 }) for ({ 14 }) fast ({ 15 }) and ({ 16 }) robust ({ 17 }) face ({ 18 }) detection ({ 19 }) . ({ 20 }) 
# Sentence pair (1712) source length 8 target length 8 alignment score : 0.0018774
Their success mainly comes from three contributions : 
NULL ({ }) Their ({ 1 }) success ({ 2 }) comes ({ 3 }) mainly ({ 4 }) from ({ 5 }) three ({ 6 }) contributions ({ 7 }) : ({ 8 }) 
# Sentence pair (1713) source length 11 target length 18 alignment score : 1.87868e-21
-Firstly , the cascaded structure of simple-to-complex classifiers reduces computation time dramatically ( as mentioned above ) . 
NULL ({ 2 3 14 }) -The ({ 1 }) cascaded ({ 4 }) structure ({ 5 }) of ({ 6 }) simple-to-complex ({ 7 }) classifiers ({ 8 }) reduces ({ 9 }) computation ({ 10 }) time ({ 11 }) dramatically ({ 12 13 15 16 17 }) . ({ 18 }) 
# Sentence pair (1714) source length 25 target length 27 alignment score : 3.31638e-09
-Secondly , AdaBoost is used to select discriminative and significant features from a pool of a very large number of features and then construct the classifier . 
NULL ({ 2 }) -AdaBoost ({ 1 3 }) is ({ 4 }) used ({ 5 }) to ({ 6 }) select ({ 7 }) discriminative ({ 8 }) and ({ 9 }) significant ({ 10 }) features ({ 11 }) from ({ 12 }) a ({ 13 }) pool ({ 14 }) of ({ 15 }) a ({ 16 }) very ({ 17 }) large ({ 18 }) number ({ 19 }) of ({ 20 }) features ({ 21 }) and ({ 22 }) then ({ 23 }) construct ({ 24 }) the ({ 25 }) classifier ({ 26 }) . ({ 27 }) 
# Sentence pair (1715) source length 16 target length 16 alignment score : 0.00399568
The output classifier built from these selected features is very fast and robust in classification . 
NULL ({ }) The ({ 1 }) output ({ 2 }) classifier ({ 3 }) built ({ 4 }) from ({ 5 }) these ({ 6 }) selected ({ 7 }) features ({ 8 }) is ({ 9 }) very ({ 10 }) fast ({ 11 }) and ({ 12 }) robust ({ 13 }) in ({ 14 }) classification ({ 15 }) . ({ 16 }) 
# Sentence pair (1716) source length 17 target length 18 alignment score : 2.0049e-06
Compared to SVM-based classifiers or neural network-based classifiers , AdaBoost based classifiers are hundreds of times faster . 
NULL ({ }) Compared ({ 1 }) to ({ 2 }) SVM-based ({ 3 }) classifiers ({ 4 }) or ({ 5 }) neural ({ 6 }) network-based ({ 7 }) classifiers ({ 8 }) , ({ 9 }) AdaBoost-based ({ 10 11 }) classifiers ({ 12 }) are ({ 13 }) hundreds ({ 14 }) of ({ 15 }) times ({ 16 }) faster ({ 17 }) . ({ 18 }) 
# Sentence pair (1717) source length 25 target length 24 alignment score : 6.82867e-10
-Thirdly , Haar-wavelet features used for all stages are informative [22] and evaluated extremely fast due to the introduction of the integral image . 
NULL ({ 2 }) -Haar ({ 1 }) wavelet ({ 3 }) features ({ 4 }) used ({ 5 }) for ({ 6 }) all ({ 7 }) stages ({ 8 }) are ({ 9 }) informative ({ 10 }) [22] ({ 11 }) and ({ 12 }) can ({ }) be ({ }) evaluated ({ 13 }) extremely ({ 14 }) quickly ({ 15 }) due ({ 16 }) to ({ 17 }) the ({ 18 }) introduction ({ 19 }) of ({ 20 }) the ({ 21 }) integral ({ 22 }) image ({ 23 }) . ({ 24 }) 
# Sentence pair (1718) source length 10 target length 10 alignment score : 0.0210397
However , this framework still has the following problems : 
NULL ({ }) However ({ 1 }) , ({ 2 }) this ({ 3 }) framework ({ 4 }) still ({ 5 }) has ({ 6 }) the ({ 7 }) following ({ 8 }) problems ({ 9 }) : ({ 10 }) 
# Sentence pair (1719) source length 22 target length 22 alignment score : 0.000300193
-First , the cascaded classifiers that use AdaBoost and Haar wavelet features are only efficient in quickly rejecting simple non-face patterns . 
NULL ({ }) -First ({ 1 }) , ({ 2 }) the ({ 3 }) cascaded ({ 4 }) classifiers ({ 5 }) that ({ 6 }) use ({ 7 }) AdaBoost ({ 8 }) and ({ 9 }) Haar ({ 10 }) wavelet ({ 11 }) features ({ 12 }) are ({ 13 }) only ({ 14 }) efficient ({ 15 }) in ({ 16 }) quickly ({ 17 }) rejecting ({ 18 }) simple ({ 19 }) non-face ({ 20 }) patterns ({ 21 }) . ({ 22 }) 
# Sentence pair (1720) source length 20 target length 20 alignment score : 0.000473424
To robustly classify complex patterns , it is necessary to use a larger number of features and layer classifiers . 
NULL ({ }) To ({ 1 }) robustly ({ 2 }) classify ({ 3 }) complex ({ 4 }) patterns ({ 5 }) , ({ 6 }) it ({ 7 }) is ({ 8 }) necessary ({ 9 }) to ({ 10 }) use ({ 11 }) a ({ 12 }) larger ({ 13 }) number ({ 14 }) of ({ 15 }) features ({ 16 }) and ({ 17 }) layer ({ 18 }) classifiers ({ 19 }) . ({ 20 }) 
# Sentence pair (1721) source length 24 target length 23 alignment score : 7.34574e-06
This need is apparent when face and non-face patterns become hard to distinguish , weak classifiers are too weak to boost [22] . 
NULL ({ }) This ({ 1 }) need ({ 2 }) is ({ 3 }) apparent ({ 4 }) because ({ }) when ({ 5 }) face ({ 6 }) and ({ 7 }) non-face ({ 8 }) patterns ({ 9 }) become ({ 10 }) hard ({ 11 }) to ({ 12 }) distinguish ({ 13 }) , ({ 14 }) weak ({ 15 }) classifiers ({ 16 }) are ({ 17 }) too ({ 18 }) weak ({ 19 }) to ({ 20 }) boost ({ 21 }) [22] ({ 22 }) . ({ 23 }) 
# Sentence pair (1722) source length 30 target length 29 alignment score : 1.68589e-07
With the first several layers in our experiment ( cf. Figure 1 ) , using some 800 weak classifiers , more than \MATH of non-face patterns are rejected . 
NULL ({ }) With ({ 1 }) the ({ 2 }) first ({ 3 }) several ({ 4 }) layers ({ 5 }) in ({ 6 }) our ({ 7 }) experiment ({ 8 }) ( ({ 9 }) cf ({ 10 }) . ({ }) Figure ({ 11 }) 1 ({ 12 }) ) ({ 13 }) , ({ 14 }) using ({ 15 }) some ({ 16 }) 800 ({ 17 }) weak ({ 18 }) classifiers ({ 19 }) , ({ 20 }) more ({ 21 }) than ({ 22 }) \MATH ({ 23 }) of ({ 24 }) non-face ({ 25 }) patterns ({ 26 }) were ({ 27 }) rejected ({ 28 }) . ({ 29 }) 
# Sentence pair (1723) source length 35 target length 39 alignment score : 4.31165e-31
However , turning the later layers into robustly classifying a smaller number of remaining patterns , it requires a lot more , e.g. , 5 ,660 , weak classifiers , thus making the training task much more complicated . 
NULL ({ 16 19 24 27 }) However ({ 1 }) , ({ 2 }) enabling ({ 3 }) the ({ 4 }) later ({ 5 }) layers ({ 6 }) to ({ 7 }) robustly ({ 8 }) classify ({ 9 }) a ({ 10 }) smaller ({ 11 }) number ({ 12 }) of ({ 13 }) remaining ({ 14 }) patterns ({ 15 }) requires ({ 17 18 }) many ({ 20 }) more ({ 21 }) weak ({ 28 }) classifiers ({ 29 }) ( ({ 23 }) around ({ 22 }) 5 ({ 25 }) ,660 ({ 26 }) ) ({ }) , ({ 30 }) thus ({ 31 }) making ({ 32 }) the ({ 33 }) training ({ 34 }) task ({ 35 }) much ({ 36 }) more ({ 37 }) complicated ({ 38 }) . ({ 39 }) 
# Sentence pair (1724) source length 8 target length 8 alignment score : 0.0645149
-Second , the training process is complicated . 
NULL ({ }) -Second ({ 1 }) , ({ 2 }) the ({ 3 }) training ({ 4 }) process ({ 5 }) is ({ 6 }) complicated ({ 7 }) . ({ 8 }) 
# Sentence pair (1725) source length 44 target length 47 alignment score : 2.10333e-18
Firstly , it requires a long training time because the training time is proportional to the number of features in the input feature set ( which is normally hundreds of thousands ) and the number of training samples ( which is generally tens of thousands ) . 
NULL ({ 2 7 }) It ({ 1 }) requires ({ 3 4 }) a ({ 5 }) long ({ 6 }) time ({ 8 }) because ({ 9 }) the ({ 10 }) training ({ 11 }) time ({ 12 }) is ({ 13 }) proportional ({ 14 }) to ({ 15 }) the ({ 16 }) number ({ 17 }) of ({ 18 }) features ({ 19 }) in ({ 20 }) the ({ 21 }) input ({ 22 }) feature ({ 23 }) set ({ 24 }) ( ({ 25 }) which ({ 26 }) is ({ 27 }) normally ({ 28 }) hundreds ({ 29 }) of ({ 30 }) thousands ({ 31 }) ) ({ 32 }) and ({ 33 }) the ({ 34 }) number ({ 35 }) of ({ 36 }) training ({ 37 }) samples ({ 38 }) ( ({ 39 }) which ({ 40 }) is ({ 41 }) generally ({ 42 }) tens ({ 43 }) of ({ 44 }) thousands ({ 45 }) ) ({ 46 }) . ({ 47 }) 
# Sentence pair (1726) source length 46 target length 46 alignment score : 3.64747e-08
In our experiment , with 20 ,000 training samples and 134 ,736 features , the average training time for choosing one feature associated with the weak classifier is about 30 minutes on a PC ( Pentium 4 , 2 .8 MHz , 512-MB RAM ) . 
NULL ({ }) In ({ 1 }) our ({ 2 }) experiment ({ 3 }) , ({ 4 }) with ({ 5 }) 20 ({ 6 }) ,000 ({ 7 }) training ({ 8 }) samples ({ 9 }) and ({ 10 }) 134 ({ 11 }) ,736 ({ 12 }) features ({ 13 }) , ({ 14 }) the ({ 15 }) average ({ 16 }) training ({ 17 }) time ({ 18 }) for ({ 19 }) choosing ({ 20 }) one ({ 21 }) feature ({ 22 }) associated ({ 23 }) with ({ 24 }) the ({ 25 }) weak ({ 26 }) classifier ({ 27 }) was ({ 28 }) about ({ 29 }) 30 ({ 30 }) minutes ({ 31 }) on ({ 32 }) a ({ 33 }) PC ({ 34 }) ( ({ 35 }) Pentium ({ 36 }) 4 ({ 37 }) , ({ 38 }) 2 ({ 39 }) .8 ({ 40 }) MHz ({ 41 }) , ({ 42 }) 512-MB ({ 43 }) RAM ({ 44 }) ) ({ 45 }) . ({ 46 }) 
# Sentence pair (1727) source length 22 target length 21 alignment score : 9.45795e-07
Therefore , training a cascade of classifiers with around 6 ,060 features [1] might take in order of several weeks . 
NULL ({ }) Therefore ({ 1 }) , ({ 2 }) training ({ 3 }) a ({ 4 }) cascade ({ 5 }) of ({ 6 }) classifiers ({ 7 }) with ({ 8 }) around ({ 9 }) 6 ({ 10 }) ,060 ({ 11 }) features ({ 12 }) [1] ({ 13 }) might ({ 14 }) take ({ 15 }) on ({ 16 }) the ({ }) order ({ 17 }) of ({ 18 }) several ({ 19 }) weeks ({ 20 }) . ({ 21 }) 
# Sentence pair (1728) source length 33 target length 26 alignment score : 1.2617e-14
Secondly , AdaBoost-based classifiers are constructed by adding features after each round of boosting , so several training parameters must be tuned manually while training . 
NULL ({ }) Another ({ 1 }) thing ({ 2 }) that ({ }) complicates ({ }) the ({ }) training ({ }) process ({ }) is ({ }) that ({ }) AdaBoost-based ({ 3 }) classifiers ({ 4 }) are ({ 5 }) constructed ({ 6 }) by ({ 7 }) adding ({ 8 }) features ({ 9 }) after ({ 10 }) each ({ 11 }) round ({ 12 }) of ({ 13 }) boosting ({ 14 }) , ({ 15 }) so ({ 16 }) several ({ 17 }) training ({ 18 }) parameters ({ 19 }) must ({ 20 }) be ({ 21 }) tuned ({ 22 }) manually ({ 23 }) while ({ 24 }) training ({ 25 }) . ({ 26 }) 
# Sentence pair (1729) source length 48 target length 48 alignment score : 3.11662e-08
In practice , for stopping training a classifier , at least the following three parameters must be determined in advance : minimum detection rate , maximum false positive rate , and maximum number of boosting rounds ( or the number of weak classifiers of each layer ) . 
NULL ({ }) In ({ 1 }) practice ({ 2 }) , ({ 3 }) for ({ 4 }) stopping ({ 5 }) training ({ 6 }) a ({ 7 }) classifier ({ 8 }) , ({ 9 }) at ({ 10 }) least ({ 11 }) the ({ 12 }) following ({ 13 }) three ({ 14 }) parameters ({ 15 }) must ({ 16 }) be ({ 17 }) determined ({ 18 }) in ({ 19 }) advance ({ 20 }) : ({ 21 }) minimum ({ 22 }) detection ({ 23 }) rate ({ 24 }) , ({ 25 }) maximum ({ 26 }) false ({ 27 }) positive ({ 28 }) rate ({ 29 }) , ({ 30 }) and ({ 31 }) maximum ({ 32 }) number ({ 33 }) of ({ 34 }) boosting ({ 35 }) rounds ({ 36 }) ( ({ 37 }) or ({ 38 }) the ({ 39 }) number ({ 40 }) of ({ 41 }) weak ({ 42 }) classifiers ({ 43 }) of ({ 44 }) each ({ 45 }) layer ({ 46 }) ) ({ 47 }) . ({ 48 }) 
# Sentence pair (1730) source length 29 target length 26 alignment score : 3.53856e-25
Because the complexity of the training sets varies through layers in the cascade , it is undetermined how to choose these parameters automatically and optimally . 
NULL ({ 15 }) Because ({ 1 }) the ({ 2 }) complexity ({ 3 }) of ({ 4 }) the ({ 5 }) training ({ 6 }) sets ({ 7 }) varies ({ 8 }) throughout ({ 9 18 }) the ({ }) layers ({ 10 }) in ({ 11 }) the ({ 12 }) cascade ({ 13 }) , ({ 14 }) a ({ 17 }) way ({ 16 }) to ({ 19 }) choose ({ 20 }) these ({ 21 }) parameters ({ 22 }) automatically ({ 23 }) and ({ 24 }) optimally ({ 25 }) has ({ }) not ({ }) been ({ }) determined ({ }) . ({ 26 }) 
# Sentence pair (1731) source length 31 target length 31 alignment score : 1.51239e-05
For example , in the first layers , it is quite easy to train a classifier with a minimum detection rate of \MATH and a maximum false-positive rate of \MATH . 
NULL ({ }) For ({ 1 }) example ({ 2 }) , ({ 3 }) in ({ 4 }) the ({ 5 }) first ({ 6 }) layers ({ 7 }) , ({ 8 }) it ({ 9 }) is ({ 10 }) quite ({ 11 }) easy ({ 12 }) to ({ 13 }) train ({ 14 }) a ({ 15 }) classifier ({ 16 }) with ({ 17 }) a ({ 18 }) minimum ({ 19 }) detection ({ 20 }) rate ({ 21 }) of ({ 22 }) \MATH ({ 23 }) and ({ 24 }) a ({ 25 }) maximum ({ 26 }) false-positive ({ 27 }) rate ({ 28 }) of ({ 29 }) \MATH ({ 30 }) . ({ 31 }) 
# Sentence pair (1732) source length 23 target length 23 alignment score : 0.00017501
However , in later layers , choosing the detection rate of \MATH will give a false positive rate greater than \MATH [22] . 
NULL ({ }) However ({ 1 }) , ({ 2 }) in ({ 3 }) later ({ 4 }) layers ({ 5 }) , ({ 6 }) choosing ({ 7 }) the ({ 8 }) detection ({ 9 }) rate ({ 10 }) of ({ 11 }) \MATH ({ 12 }) will ({ 13 }) give ({ 14 }) a ({ 15 }) false ({ 16 }) positive ({ 17 }) rate ({ 18 }) greater ({ 19 }) than ({ 20 }) \MATH ({ 21 }) [22] ({ 22 }) . ({ 23 }) 
# Sentence pair (1733) source length 12 target length 12 alignment score : 0.0124085
Adding more features directly increases computation time and might cause over-fitting . 
NULL ({ }) Adding ({ 1 }) more ({ 2 }) features ({ 3 }) directly ({ 4 }) increases ({ 5 }) computation ({ 6 }) time ({ 7 }) and ({ 8 }) might ({ 9 }) cause ({ 10 }) over-fitting ({ 11 }) . ({ 12 }) 
# Sentence pair (1734) source length 32 target length 32 alignment score : 1.41435e-06
The authors therefore propose a multi-stage approach to build a face-detection system by adopting the advantages of Viola and Jones' approach and by introducing a method to address the above problems . 
NULL ({ }) The ({ 1 }) authors ({ 2 }) therefore ({ 3 }) propose ({ 4 }) a ({ 5 }) multi-stage ({ 6 }) approach ({ 7 }) to ({ 8 }) build ({ 9 }) a ({ 10 }) face-detection ({ 11 }) system ({ 12 }) by ({ 13 }) adopting ({ 14 }) the ({ 15 }) advantages ({ 16 }) of ({ 17 }) Viola ({ 18 }) and ({ 19 }) Jones' ({ 20 }) approach ({ 21 }) and ({ 22 }) by ({ 23 }) introducing ({ 24 }) a ({ 25 }) method ({ 26 }) to ({ 27 }) address ({ 28 }) the ({ 29 }) above ({ 30 }) problems ({ 31 }) . ({ 32 }) 
# Sentence pair (1735) source length 38 target length 36 alignment score : 7.8645e-10
Specifically , for quick rejection of non-face patterns , we reuse two key ingredients of Viola and Jones' system , that is , the cascaded structure of simple-to-complex classifiers and AdaBoost trained with Haar-wavelet features . 
NULL ({ }) Specifically ({ 1 }) , ({ 2 }) for ({ 3 }) quick ({ 4 }) rejection ({ 5 }) of ({ 6 }) non-face ({ 7 }) patterns ({ 8 }) , ({ 9 }) we ({ 10 }) have ({ }) reused ({ 11 }) two ({ 12 }) key ({ 13 }) ingredients ({ 14 }) of ({ 15 }) Viola ({ 16 }) and ({ 17 }) Jones' ({ 18 }) system ({ 19 }) , ({ 20 }) that ({ 21 }) is ({ 22 }) , ({ 23 }) the ({ 24 }) cascaded ({ 25 }) structure ({ 26 }) of ({ 27 }) simple-to-complex ({ 28 }) classifiers ({ 29 }) and ({ 30 }) AdaBoost ({ 31 }) trained ({ 32 }) with ({ 33 }) Haar ({ }) wavelet ({ 34 }) features ({ 35 }) . ({ 36 }) 
# Sentence pair (1736) source length 18 target length 18 alignment score : 0.0024887
Furthermore , for robust classification and simple training , we propose using SVM classifiers for later layers . 
NULL ({ }) Furthermore ({ 1 }) , ({ 2 }) for ({ 3 }) robust ({ 4 }) classification ({ 5 }) and ({ 6 }) simple ({ 7 }) training ({ 8 }) , ({ 9 }) we ({ 10 }) propose ({ 11 }) using ({ 12 }) SVM ({ 13 }) classifiers ({ 14 }) for ({ 15 }) later ({ 16 }) layers ({ 17 }) . ({ 18 }) 
# Sentence pair (1737) source length 8 target length 9 alignment score : 3.76855e-05
The contribution of this approach is three fold : 
NULL ({ }) The ({ 1 }) contribution ({ 2 }) of ({ 3 }) this ({ 4 }) approach ({ 5 }) is ({ 6 }) threefold ({ 7 8 }) : ({ 9 }) 
# Sentence pair (1738) source length 29 target length 28 alignment score : 1.1965e-06
-First , to detect the face candidate regions , a new stage ( using a larger window size and a larger moving step size ) is added . 
NULL ({ }) -First ({ 1 }) , ({ 2 }) to ({ 3 }) detect ({ 4 }) the ({ 5 }) face ({ 6 }) candidate ({ 7 }) regions ({ 8 }) , ({ 9 }) a ({ 10 }) new ({ 11 }) stage ({ 12 }) ( ({ 13 }) using ({ 14 }) a ({ 15 }) larger ({ 16 }) window ({ 17 }) size ({ 18 }) and ({ 19 }) a ({ 20 }) larger ({ 21 }) moving ({ 22 }) step ({ 23 }) size ({ 24 }) ) ({ 25 }) has ({ 26 }) been ({ }) added ({ 27 }) . ({ 28 }) 
# Sentence pair (1739) source length 23 target length 24 alignment score : 6.03915e-07
We use 36 x 36-pixel window-based classifiers with a moving step size of 12 pixels , to quickly estimate the candidate face regions . 
NULL ({ 16 }) We ({ 1 }) use ({ 2 }) 36 ({ 3 }) x ({ 4 }) 36-pixel ({ 5 }) window-based ({ 6 }) classifiers ({ 7 }) with ({ 8 }) a ({ 9 }) moving ({ 10 }) step ({ 11 }) size ({ 12 }) of ({ 13 }) 12 ({ 14 }) pixels ({ 15 }) to ({ 17 }) quickly ({ 18 }) estimate ({ 19 }) the ({ 20 }) candidate ({ 21 }) face ({ 22 }) regions ({ 23 }) . ({ 24 }) 
# Sentence pair (1740) source length 22 target length 22 alignment score : 4.75209e-05
The idea of using larger windows and moving the step size was adopted in [5] , but it severely degraded performance . 
NULL ({ }) The ({ 1 }) idea ({ 2 }) of ({ 3 }) using ({ 4 }) larger ({ 5 }) windows ({ 6 }) and ({ 7 }) moving ({ 8 }) the ({ 9 }) step ({ 10 }) size ({ 11 }) was ({ 12 }) adopted ({ 13 }) in ({ 14 }) [5] ({ 15 }) , ({ 16 }) but ({ 17 }) it ({ 18 }) severely ({ 19 }) degraded ({ 20 }) performance ({ 21 }) . ({ 22 }) 
# Sentence pair (1741) source length 30 target length 29 alignment score : 2.56313e-07
To improve speed while maintaining high accuracy , our approach takes advantage of the combination of the Haar wavelet features and the AdaBoost learning for fast and robust evaluation 
NULL ({ }) To ({ 1 }) improve ({ 2 }) speed ({ 3 }) while ({ 4 }) maintaining ({ 5 }) high ({ 6 }) accuracy ({ 7 }) , ({ 8 }) our ({ 9 }) approach ({ 10 }) takes ({ 11 }) advantage ({ 12 }) of ({ 13 }) the ({ 14 }) combination ({ 15 }) of ({ 16 }) the ({ 17 }) Haar ({ 18 }) wavelet ({ 19 }) features ({ 20 }) and ({ 21 }) the ({ 22 }) AdaBoost ({ 23 }) learning ({ 24 }) for ({ 25 }) fast ({ 26 }) and ({ 27 }) robust ({ 28 }) evaluation ({ 29 }) . ({ }) 
# Sentence pair (1742) source length 27 target length 28 alignment score : 1.02109e-16
Second , how to efficiently reuse the features selected by AdaBoost in the previous stage , for the SVM classifiers of the last stage , is investigated . 
NULL ({ 16 25 26 }) Second ({ 1 }) , ({ 2 }) we ({ }) have ({ }) investigated ({ 27 }) how ({ 3 }) to ({ 4 }) efficiently ({ 5 }) reuse ({ 6 }) the ({ 7 }) features ({ 8 }) selected ({ 9 }) by ({ 10 }) AdaBoost ({ 11 }) in ({ 12 }) the ({ 13 }) previous ({ 14 }) stage ({ 15 }) for ({ 17 }) the ({ 18 }) SVM ({ 19 }) classifiers ({ 20 }) of ({ 21 }) the ({ 22 }) last ({ 23 }) stage ({ 24 }) . ({ 28 }) 
# Sentence pair (1743) source length 23 target length 23 alignment score : 2.86503e-11
Reusing these features brings to two advantages : ( i ) Haar wavelet features are very fast in evaluating and normalizing [1] . 
NULL ({ 5 }) Reusing ({ 1 }) these ({ 2 }) features ({ 3 }) brings ({ 4 }) two ({ 6 }) advantages ({ 7 }) : ({ 8 }) ( ({ 9 }) i ({ 10 }) ) ({ 11 }) Haar ({ 12 }) wavelet ({ 13 }) features ({ 14 }) are ({ 15 }) very ({ 16 }) fast ({ 17 }) in ({ 18 }) being ({ 19 }) evaluated ({ }) and ({ 20 }) normalized ({ 21 }) [1] ({ 22 }) . ({ 23 }) 
# Sentence pair (1744) source length 17 target length 16 alignment score : 2.54768e-20
Furthermore , it is unnecessary to re-evaluate these features because they have been previously evaluated . 
NULL ({ 3 4 }) Furthermore ({ 1 }) , ({ 2 }) these ({ 8 }) features ({ 9 }) do ({ 5 }) not ({ }) need ({ }) to ({ 6 }) be ({ }) re-evaluated ({ 7 }) because ({ 10 }) they ({ 11 }) have ({ 12 }) already ({ 14 }) been ({ 13 }) evaluated ({ 15 }) . ({ 16 }) 
# Sentence pair (1745) source length 33 target length 32 alignment score : 2.19834e-23
( ii ) By using SVM classifiers with powerful generalization , using too many features in the cascade is avoided , therefore importantly training time is saved and over-fitting is avoided . 
NULL ({ 26 30 }) ( ({ 1 }) ii ({ 2 }) ) ({ 3 }) By ({ 4 }) using ({ 5 }) SVM ({ 6 }) classifiers ({ 7 }) with ({ 8 }) powerful ({ 9 }) generalization ({ 10 }) , ({ 11 }) using ({ 12 }) too ({ 13 }) many ({ 14 }) features ({ 15 }) in ({ 16 }) the ({ 17 }) cascade ({ 18 }) is ({ 19 }) avoided ({ 20 }) , ({ 21 }) with ({ }) the ({ }) important ({ 22 }) results ({ }) of ({ }) saving ({ 23 }) training ({ 24 }) time ({ 25 }) and ({ 28 }) avoiding ({ 27 }) over-fitting ({ 29 31 }) . ({ 32 }) 
# Sentence pair (1746) source length 27 target length 26 alignment score : 3.01625e-06
Third , the training time of AdaBoost classifiers is shortened by using simple sampling techniques to reduce the number of features in the feature set . 
NULL ({ }) Third ({ 1 }) , ({ 2 }) the ({ 3 }) training ({ 4 }) time ({ 5 }) of ({ 6 }) AdaBoost ({ 7 }) classifiers ({ 8 }) has ({ 9 }) been ({ }) shortened ({ 10 }) by ({ 11 }) using ({ 12 }) simple ({ 13 }) sampling ({ 14 }) techniques ({ 15 }) to ({ 16 }) reduce ({ 17 }) the ({ 18 }) number ({ 19 }) of ({ 20 }) features ({ 21 }) in ({ 22 }) the ({ 23 }) feature ({ 24 }) set ({ 25 }) . ({ 26 }) 
# Sentence pair (1747) source length 25 target length 22 alignment score : 2.73041e-27
Experiments will show that for rejection , using a full feature set and a sampled feature set gives the comparable performance . 
NULL ({ 13 19 }) Experiments ({ 1 }) showed ({ 2 3 }) that ({ 4 }) for ({ 5 }) rejection ({ 6 }) , ({ 7 }) the ({ }) performance ({ 21 }) gained ({ 9 }) by ({ }) using ({ 8 }) a ({ 14 }) sampled ({ 15 }) feature ({ 16 }) set ({ 17 }) was ({ 18 }) comparable ({ 20 }) to ({ }) that ({ }) of ({ }) a ({ }) full ({ 10 }) feature ({ 11 }) set ({ 12 }) . ({ 22 }) 
# Sentence pair (1748) source length 24 target length 23 alignment score : 7.81738e-09
Along with using several SVM classifiers instead of many AdaBoost classifiers in later layers , the total training time is reduced significantly . 
NULL ({ }) Along ({ 1 }) with ({ 2 }) using ({ 3 }) several ({ 4 }) SVM ({ 5 }) classifiers ({ 6 }) instead ({ 7 }) of ({ 8 }) many ({ 9 }) AdaBoost ({ 10 }) classifiers ({ 11 }) in ({ 12 }) later ({ 13 }) layers ({ 14 }) , ({ 15 }) the ({ 16 }) total ({ 17 }) training ({ 18 }) time ({ 19 }) has ({ 20 }) been ({ }) significantly ({ 22 }) reduced ({ 21 }) . ({ 23 }) 
# Sentence pair (1749) source length 14 target length 18 alignment score : 2.18269e-20
There have been several studies working on how to handle the drawbacks of Viola and Jones' system . 
NULL ({ 9 }) Several ({ 1 }) studies ({ 5 }) have ({ 2 }) worked ({ 3 4 }) on ({ 7 }) addressing ({ 6 8 10 }) the ({ 11 }) drawbacks ({ 12 }) of ({ 13 }) Viola ({ 14 }) and ({ 15 }) Jones' ({ 16 }) system ({ 17 }) . ({ 18 }) 
# Sentence pair (1750) source length 17 target length 17 alignment score : 0.000814568
Wu et al. [23] used direct feature selection to reduce training time while maintaining comparable performance . 
NULL ({ }) Wu ({ 1 }) et ({ 2 }) al. ({ 3 }) [23] ({ 4 }) used ({ 5 }) direct ({ 6 }) feature ({ 7 }) selection ({ 8 }) to ({ 9 }) reduce ({ 10 }) training ({ 11 }) time ({ 12 }) while ({ 13 }) maintaining ({ 14 }) comparable ({ 15 }) performance ({ 16 }) . ({ 17 }) 
# Sentence pair (1751) source length 18 target length 18 alignment score : 0.00163016
Their idea is to separate the training process into two stages : feature selection and classifier construction . 
NULL ({ }) Their ({ 1 }) idea ({ 2 }) is ({ 3 }) to ({ 4 }) separate ({ 5 }) the ({ 6 }) training ({ 7 }) process ({ 8 }) into ({ 9 }) two ({ 10 }) stages ({ 11 }) : ({ 12 }) feature ({ 13 }) selection ({ 14 }) and ({ 15 }) classifier ({ 16 }) construction ({ 17 }) . ({ 18 }) 
# Sentence pair (1752) source length 23 target length 23 alignment score : 0.000317024
In Viola and Jones' work , features are selected by the discriminative performance of their associated weak classifiers through the boosting process . 
NULL ({ }) In ({ 1 }) Viola ({ 2 }) and ({ 3 }) Jones' ({ 4 }) work ({ 5 }) , ({ 6 }) features ({ 7 }) are ({ 8 }) selected ({ 9 }) by ({ 10 }) the ({ 11 }) discriminative ({ 12 }) performance ({ 13 }) of ({ 14 }) their ({ 15 }) associated ({ 16 }) weak ({ 17 }) classifiers ({ 18 }) through ({ 19 }) the ({ 20 }) boosting ({ 21 }) process ({ 22 }) . ({ 23 }) 
# Sentence pair (1753) source length 20 target length 20 alignment score : 1.72915e-10
It is therefore very time consuming because all weak classifiers must be trained every time one feature is selected . 
NULL ({ 2 }) This ({ 1 }) process ({ 3 }) is ({ }) very ({ 4 }) time ({ 5 }) consuming ({ 6 }) because ({ 7 }) all ({ 8 }) weak ({ 9 }) classifiers ({ 10 }) must ({ 11 }) be ({ 12 }) trained ({ 13 }) every ({ 14 }) time ({ 15 }) one ({ 16 }) feature ({ 17 }) is ({ 18 }) selected ({ 19 }) . ({ 20 }) 
# Sentence pair (1754) source length 37 target length 32 alignment score : 1.13313e-14
With their new proposal , weak classifiers are trained only once and features are selected by the direct feature selection method that directly maximizes the learning objective of the output classifier . 
NULL ({ }) With ({ 1 }) the ({ }) new ({ 3 }) proposal ({ 4 }) of ({ }) Wu ({ 2 }) et ({ }) al. ({ }) , ({ 5 }) weak ({ 6 }) classifiers ({ 7 }) are ({ 8 }) trained ({ 9 }) only ({ 10 }) once ({ 11 }) and ({ 12 }) features ({ 13 }) are ({ 14 }) selected ({ 15 }) by ({ 16 }) the ({ 17 }) direct ({ 18 }) feature ({ 19 }) selection ({ 20 }) method ({ 21 }) , ({ }) which ({ 22 }) directly ({ 23 }) maximizes ({ 24 }) the ({ 25 }) learning ({ 26 }) objective ({ 27 }) of ({ 28 }) the ({ 29 }) output ({ 30 }) classifier ({ 31 }) . ({ 32 }) 
# Sentence pair (1755) source length 15 target length 15 alignment score : 0.00139205
They claim that their method is 100 times faster than Viola and Jones' method . 
NULL ({ }) They ({ 1 }) claim ({ 2 }) that ({ 3 }) their ({ 4 }) method ({ 5 }) is ({ 6 }) 100 ({ 7 }) times ({ 8 }) faster ({ 9 }) than ({ 10 }) Viola ({ 11 }) and ({ 12 }) Jones' ({ 13 }) method ({ 14 }) . ({ 15 }) 
# Sentence pair (1756) source length 14 target length 17 alignment score : 1.37937e-12
Another direction is to optimally build the cascade to improve the overall performance of the cascade . 
NULL ({ 14 15 }) Another ({ 1 }) direction ({ 2 }) is ({ 3 }) to ({ 4 }) optimally ({ 5 }) build ({ 6 }) the ({ 7 }) cascade ({ 8 16 }) to ({ 9 }) improve ({ 10 }) its ({ 11 }) overall ({ 12 }) performance ({ 13 }) . ({ 17 }) 
# Sentence pair (1757) source length 17 target length 17 alignment score : 4.62456e-05
Sun et al. [24] and [25] propose a scheme to optimally tune parameters in layer classifiers . 
NULL ({ }) Sun ({ 1 }) et ({ 2 }) al. ({ 3 }) [24] ({ 4 }) and ({ 5 }) [25] ({ 6 }) proposed ({ 7 }) a ({ 8 }) scheme ({ 9 }) to ({ 10 }) optimally ({ 11 }) tune ({ 12 }) parameters ({ 13 }) in ({ 14 }) layer ({ 15 }) classifiers ({ 16 }) . ({ 17 }) 
# Sentence pair (1758) source length 14 target length 14 alignment score : 0.00571495
However , their approach is somewhat complicated and is not easy to implement . 
NULL ({ }) However ({ 1 }) , ({ 2 }) their ({ 3 }) approach ({ 4 }) is ({ 5 }) somewhat ({ 6 }) complicated ({ 7 }) and ({ 8 }) is ({ 9 }) not ({ 10 }) easy ({ 11 }) to ({ 12 }) implement ({ 13 }) . ({ 14 }) 
# Sentence pair (1759) source length 27 target length 25 alignment score : 6.61973e-10
Xiao et al. [20] and Huang et al. [11] propose the boosting chain structure in which subsequent layers utilize historical information of previous layers . 
NULL ({ }) Xiao ({ 1 }) et ({ 2 }) al. ({ 3 }) [20] ({ 4 }) and ({ 5 }) Huang ({ 6 }) et ({ 7 }) al. ({ 8 }) [11] ({ 9 }) proposed ({ 10 }) a ({ 11 }) boosting ({ 12 }) chain ({ 13 }) structure ({ 14 }) in ({ 15 }) which ({ 16 }) subsequent ({ 17 }) layers ({ 18 }) utilize ({ 19 }) the ({ }) historical ({ 20 }) information ({ 21 }) of ({ 22 }) the ({ }) previous ({ 23 }) layers ({ 24 }) . ({ 25 }) 
# Sentence pair (1760) source length 12 target length 12 alignment score : 0.00857309
This significantly reduces the number of features used in each layer . 
NULL ({ }) This ({ 1 }) significantly ({ 2 }) reduces ({ 3 }) the ({ 4 }) number ({ 5 }) of ({ 6 }) features ({ 7 }) used ({ 8 }) in ({ 9 }) each ({ 10 }) layer ({ 11 }) . ({ 12 }) 
# Sentence pair (1761) source length 22 target length 22 alignment score : 5.14796e-06
Discrete AdaBoost uses a binary weak classifier that is too weak to boost in the case of the hard distinguished dataset . 
NULL ({ }) Discrete ({ 1 }) AdaBoost ({ 2 }) uses ({ 3 }) a ({ 4 }) binary ({ 5 }) weak ({ 6 }) classifier ({ 7 }) that ({ 8 }) is ({ 9 }) too ({ 10 }) weak ({ 11 }) to ({ 12 }) boost ({ 13 }) in ({ 14 }) the ({ 15 }) case ({ 16 }) of ({ 17 }) a ({ 18 }) hard ({ 19 }) distinguished ({ 20 }) dataset ({ 21 }) . ({ 22 }) 
# Sentence pair (1762) source length 31 target length 27 alignment score : 1.73091e-09
Studies based on RealBoost [26] , such as [12] ,[10] ,[27] ,[11] , introduced new kinds of weak classifiers that are stronger than binary weak classifiers . 
NULL ({ }) Studies ({ 1 }) based ({ 2 }) on ({ 3 }) RealBoost ({ 4 }) [26] ({ 5 }) , ({ 6 }) such ({ 7 }) as ({ 8 }) [12] ({ 9 }) , ({ }) [10] ({ 10 }) , ({ }) [27] ({ 11 }) , ({ }) and ({ }) [11] ({ 12 }) , ({ 13 }) introduced ({ 14 }) new ({ 15 }) kinds ({ 16 }) of ({ 17 }) weak ({ 18 }) classifiers ({ 19 }) that ({ 20 }) are ({ 21 }) stronger ({ 22 }) than ({ 23 }) binary ({ 24 }) weak ({ 25 }) classifiers ({ 26 }) . ({ 27 }) 
# Sentence pair (1763) source length 25 target length 26 alignment score : 1.63721e-18
New real-valued weak classifiers can effectively discriminate face and non-face distributions and , in consequence , the total number of features used also reduces dramatically . 
NULL ({ 14 16 }) These ({ 1 }) new ({ }) real-valued ({ 2 }) weak ({ 3 }) classifiers ({ 4 }) can ({ 5 }) effectively ({ 6 }) discriminate ({ 7 }) face ({ 8 }) and ({ 9 }) non-face ({ 10 }) distributions ({ 11 12 }) , ({ 13 }) so ({ 15 }) the ({ 17 }) total ({ 18 }) number ({ 19 }) of ({ 20 }) features ({ 21 }) used ({ 22 }) is ({ }) also ({ 23 }) reduced ({ 24 }) dramatically ({ 25 }) . ({ 26 }) 
# Sentence pair (1764) source length 14 target length 13 alignment score : 0.000135009
Face detection systems such as [27] ,[11] only use around 800 features . 
NULL ({ }) Face ({ 1 }) detection ({ 2 }) systems ({ 3 }) such ({ 4 }) as ({ 5 }) [27] ({ 6 }) and ({ }) [11] ({ 7 }) only ({ 8 }) use ({ 9 }) around ({ 10 }) 800 ({ 11 }) features ({ 12 }) . ({ 13 }) 
# Sentence pair (1765) source length 19 target length 19 alignment score : 0.00100989
However , the main problem with these systems is how to choose the most appropriate number of bins . 
NULL ({ }) However ({ 1 }) , ({ 2 }) the ({ 3 }) main ({ 4 }) problem ({ 5 }) with ({ 6 }) these ({ 7 }) systems ({ 8 }) is ({ 9 }) how ({ 10 }) to ({ 11 }) choose ({ 12 }) the ({ 13 }) most ({ 14 }) appropriate ({ 15 }) number ({ 16 }) of ({ 17 }) bins ({ 18 }) . ({ 19 }) 
# Sentence pair (1766) source length 32 target length 28 alignment score : 3.70338e-11
Small number of bins might not well approximate the real distribution while large number of bins might cause over-fitting , increase computation time and waste storage space . 
NULL ({ }) A ({ 1 }) small ({ }) number ({ 2 }) of ({ 3 }) bins ({ 4 }) might ({ 5 }) not ({ 6 }) accurately ({ 7 }) approximate ({ 8 }) the ({ 9 }) real ({ 10 }) distribution ({ 11 }) , ({ }) while ({ 12 }) a ({ }) large ({ 13 }) number ({ 14 }) of ({ 15 }) bins ({ 16 }) might ({ 17 }) cause ({ 18 }) over-fitting ({ 19 }) , ({ 20 }) increase ({ 21 }) computation ({ 22 }) time ({ 23 }) , ({ }) and ({ 24 }) waste ({ 25 }) storage ({ 26 }) space ({ 27 }) . ({ 28 }) 
# Sentence pair (1767) source length 24 target length 24 alignment score : 1.55897e-13
Actually , our system can benefit from this approach when building the rejection stage and thus also reduce the training time much more . 
NULL ({ }) However ({ 1 }) , ({ 2 }) our ({ 3 }) system ({ 4 }) can ({ 5 }) benefit ({ 6 }) from ({ 7 }) this ({ 8 }) approach ({ 9 }) when ({ 10 }) building ({ 11 }) the ({ 12 }) rejection ({ 13 }) stage ({ 14 }) and ({ 15 }) can ({ 16 }) thus ({ 17 }) reduce ({ 18 }) the ({ 19 }) training ({ 20 }) time ({ 21 }) even ({ 22 }) further ({ 23 }) . ({ 24 }) 
# Sentence pair (1768) source length 22 target length 23 alignment score : 5.30886e-07
The proposed face detection system consists of three stages that classify a 24x24 pixel window as either a face or a non-face . 
NULL ({ }) The ({ 1 }) proposed ({ 2 }) face ({ 3 }) detection ({ 4 }) system ({ 5 }) consists ({ 6 }) of ({ 7 }) three ({ 8 }) stages ({ 9 }) that ({ 10 }) classify ({ 11 }) a ({ 12 }) 24x24-pixel ({ 13 14 }) window ({ 15 }) as ({ 16 }) either ({ 17 }) a ({ 18 }) face ({ 19 }) or ({ 20 }) a ({ 21 }) non-face ({ 22 }) . ({ 23 }) 
# Sentence pair (1769) source length 42 target length 41 alignment score : 5.01018e-11
To detect faces of different sizes and locations , the detector is applied at every location and scale in the input image with a scale factor of 1 .2 , which is similar to the other approaches [5] ,[6] ,[9] . 
NULL ({ 35 }) To ({ 1 }) detect ({ 2 }) faces ({ 3 }) of ({ 4 }) different ({ 5 }) sizes ({ 6 }) and ({ 7 }) locations ({ 8 }) , ({ 9 }) the ({ 10 }) detector ({ 11 }) is ({ 12 }) applied ({ 13 }) at ({ 14 }) every ({ 15 }) location ({ 16 }) and ({ 17 }) scale ({ 18 }) in ({ 19 }) the ({ 20 }) input ({ 21 }) image ({ 22 }) with ({ 23 }) a ({ 24 }) scale ({ 25 }) factor ({ 26 }) of ({ 27 }) 1 ({ 28 }) .2 ({ 29 }) , ({ 30 }) which ({ 31 }) is ({ 32 }) similar ({ 33 }) to ({ 34 }) other ({ 36 }) approaches ({ 37 }) [5] ({ 38 }) , ({ }) [6] ({ 39 }) , ({ }) [9] ({ 40 }) . ({ 41 }) 
# Sentence pair (1770) source length 11 target length 11 alignment score : 0.0205713
An outline of this system is given in Figure 2 . 
NULL ({ }) An ({ 1 }) outline ({ 2 }) of ({ 3 }) this ({ 4 }) system ({ 5 }) is ({ 6 }) given ({ 7 }) in ({ 8 }) Figure ({ 9 }) 2 ({ 10 }) . ({ 11 }) 
# Sentence pair (1771) source length 28 target length 28 alignment score : 2.94598e-05
The first stage is a cascade of classifiers used to estimate face candidate regions by evaluating 36x36 input windows , with a moving step of 12 pixels . 
NULL ({ }) The ({ 1 }) first ({ 2 }) stage ({ 3 }) is ({ 4 }) a ({ 5 }) cascade ({ 6 }) of ({ 7 }) classifiers ({ 8 }) used ({ 9 }) to ({ 10 }) estimate ({ 11 }) face ({ 12 }) candidate ({ 13 }) regions ({ 14 }) by ({ 15 }) evaluating ({ 16 }) 36x36 ({ 17 }) input ({ 18 }) windows ({ 19 }) , ({ 20 }) with ({ 21 }) a ({ 22 }) moving ({ 23 }) step ({ 24 }) of ({ 25 }) 12 ({ 26 }) pixels ({ 27 }) . ({ 28 }) 
# Sentence pair (1772) source length 31 target length 30 alignment score : 2.06814e-06
If a 36x36 window is detected as the existence of a face , 144 ( i.e. 12x12 ) likely face positions are collected and passed to the next stage . 
NULL ({ }) If ({ 1 }) a ({ 2 }) 36x36-pixel ({ 3 }) window ({ 4 }) is ({ 5 }) detected ({ 6 }) as ({ 7 }) the ({ 8 }) existence ({ 9 }) of ({ 10 }) a ({ 11 }) face ({ 12 }) , ({ 13 }) 144 ({ 14 }) ( ({ 15 }) i.e. ({ 16 }) , ({ }) 12x12 ({ 17 }) ) ({ 18 }) likely ({ 19 }) face ({ 20 }) positions ({ 21 }) are ({ 22 }) collected ({ 23 }) and ({ 24 }) passed ({ 25 }) to ({ 26 }) the ({ 27 }) next ({ 28 }) stage ({ 29 }) . ({ 30 }) 
# Sentence pair (1773) source length 22 target length 22 alignment score : 0.000259259
The second stage is a cascade of classifiers used to investigate 24x24 window face candidate locations returned from the previous stage . 
NULL ({ }) The ({ 1 }) second ({ 2 }) stage ({ 3 }) is ({ 4 }) a ({ 5 }) cascade ({ 6 }) of ({ 7 }) classifiers ({ 8 }) used ({ 9 }) to ({ 10 }) investigate ({ 11 }) 24x24 ({ 12 }) window ({ 13 }) face ({ 14 }) candidate ({ 15 }) locations ({ 16 }) returned ({ 17 }) from ({ 18 }) the ({ 19 }) previous ({ 20 }) stage ({ 21 }) . ({ 22 }) 
# Sentence pair (1774) source length 33 target length 33 alignment score : 1.17973e-06
The main purpose of designing these two stages is trying to filter out a large number of non-face patterns as quick as possible before passing complex patterns to the final stage classifier . 
NULL ({ }) The ({ 1 }) main ({ 2 }) purpose ({ 3 }) of ({ 4 }) designing ({ 5 }) these ({ 6 }) two ({ 7 }) stages ({ 8 }) is ({ 9 }) trying ({ 10 }) to ({ 11 }) filter ({ 12 }) out ({ 13 }) a ({ 14 }) large ({ 15 }) number ({ 16 }) of ({ 17 }) non-face ({ 18 }) patterns ({ 19 }) as ({ 20 }) quickly ({ 21 }) as ({ 22 }) possible ({ 23 }) before ({ 24 }) passing ({ 25 }) complex ({ 26 }) patterns ({ 27 }) to ({ 28 }) the ({ 29 }) final ({ 30 }) stage ({ 31 }) classifier ({ 32 }) . ({ 33 }) 
# Sentence pair (1775) source length 28 target length 29 alignment score : 1.91667e-08
This is done by taking advantages of Viola and Jones' approach [1] , in which Haar wavelet features and the cascaded AdaBoost classifiers are extremely fast in computation . 
NULL ({ 27 }) This ({ 1 }) is ({ 2 }) done ({ 3 }) by ({ 4 }) taking ({ 5 }) advantage ({ 6 }) of ({ 7 }) Viola ({ 8 }) and ({ 9 }) Jones' ({ 10 }) approach ({ 11 }) [1] ({ 12 }) , ({ 13 }) in ({ 14 }) which ({ 15 }) Haar ({ 16 }) wavelet ({ 17 }) features ({ 18 }) and ({ 19 }) the ({ 20 }) cascaded ({ 21 }) AdaBoost ({ 22 }) classifiers ({ 23 }) enable ({ 24 }) extremely ({ 25 }) fast ({ 26 }) computation ({ 28 }) . ({ 29 }) 
# Sentence pair (1776) source length 28 target length 28 alignment score : 2.26681e-05
Although the cascade of \MATH AdaBoost classifiers rejects non-face patterns rapidly , it is still influenced by the large number of \MATH patterns that it must process . 
NULL ({ }) Although ({ 1 }) the ({ 2 }) cascade ({ 3 }) of ({ 4 }) \MATH ({ 5 }) AdaBoost ({ 6 }) classifiers ({ 7 }) rejects ({ 8 }) non-face ({ 9 }) patterns ({ 10 }) rapidly ({ 11 }) , ({ 12 }) it ({ 13 }) is ({ 14 }) still ({ 15 }) influenced ({ 16 }) by ({ 17 }) the ({ 18 }) large ({ 19 }) number ({ 20 }) of ({ 21 }) \MATH ({ 22 }) patterns ({ 23 }) that ({ 24 }) it ({ 25 }) must ({ 26 }) process ({ 27 }) . ({ 28 }) 
# Sentence pair (1777) source length 27 target length 26 alignment score : 3.71316e-14
The reason why the fist stage , which is a cascade of \MATH classifiers , is added is to decrease the number of analyzed patterns . 
NULL ({ }) For ({ 1 }) this ({ }) reason ({ 2 3 }) , ({ }) the ({ 4 }) first ({ 5 }) stage ({ 6 }) , ({ 7 }) which ({ 8 }) is ({ 9 }) a ({ 10 }) cascade ({ 11 }) of ({ 12 }) \MATH ({ 13 }) classifiers ({ 14 }) , ({ 15 }) is ({ 16 }) added ({ 17 }) is ({ 18 }) to ({ 19 }) decrease ({ 20 }) the ({ 21 }) number ({ 22 }) of ({ 23 }) analyzed ({ 24 }) patterns ({ 25 }) . ({ 26 }) 
# Sentence pair (1778) source length 19 target length 19 alignment score : 0.000715036
To this end , this stage is trained specially to make the classifiers invariant to small face translations . 
NULL ({ }) To ({ 1 }) this ({ 2 }) end ({ 3 }) , ({ 4 }) this ({ 5 }) stage ({ 6 }) is ({ 7 }) trained ({ 8 }) specially ({ 9 }) to ({ 10 }) make ({ 11 }) the ({ 12 }) classifiers ({ 13 }) invariant ({ 14 }) to ({ 15 }) small ({ 16 }) face ({ 17 }) translations ({ 18 }) . ({ 19 }) 
# Sentence pair (1779) source length 17 target length 17 alignment score : 0.00107728
These classifiers can detect faces that are off-center by up to six pixels in any direction . 
NULL ({ }) These ({ 1 }) classifiers ({ 2 }) can ({ 3 }) detect ({ 4 }) faces ({ 5 }) that ({ 6 }) are ({ 7 }) off-center ({ 8 }) by ({ 9 }) up ({ 10 }) to ({ 11 }) six ({ 12 }) pixels ({ 13 }) in ({ 14 }) any ({ 15 }) direction ({ 16 }) . ({ 17 }) 
# Sentence pair (1780) source length 18 target length 18 alignment score : 0.000868208
An illustration of the difference between 24x24 and \MATH face training samples is depicted in Figure 3 . 
NULL ({ }) An ({ 1 }) illustration ({ 2 }) of ({ 3 }) the ({ 4 }) difference ({ 5 }) between ({ 6 }) 24x24 ({ 7 }) and ({ 8 }) \MATH ({ 9 }) face ({ 10 }) training ({ 11 }) samples ({ 12 }) is ({ 13 }) depicted ({ 14 }) in ({ 15 }) Figure ({ 16 }) 3 ({ 17 }) . ({ 18 }) 
# Sentence pair (1781) source length 33 target length 33 alignment score : 8.23412e-13
The \MATH window is chosen in accordance with the idea from [5] stated that the classifier can be trained to be invariant to translation by up to \MATH of original window size . 
NULL ({ }) The ({ 1 }) \MATH ({ 2 }) window ({ 3 }) is ({ 4 }) chosen ({ 5 }) in ({ 6 }) accordance ({ 7 }) with ({ 8 }) the ({ 9 }) idea ({ 10 }) in ({ 11 }) [5] ({ 12 13 }) that ({ 14 }) the ({ 15 }) classifier ({ 16 }) can ({ 17 }) be ({ 18 }) trained ({ 19 }) to ({ 20 }) be ({ 21 }) invariant ({ 22 }) to ({ 23 }) translation ({ 24 }) by ({ 25 }) up ({ 26 }) to ({ 27 }) \MATH ({ 28 }) of ({ 29 }) the ({ }) original ({ 30 }) window ({ 31 }) size ({ 32 }) . ({ 33 }) 
# Sentence pair (1782) source length 25 target length 24 alignment score : 9.99755e-12
With this flexible classifier , the moving step size can be increased up to 12 pixels that reduce dramatically number of analyzed patterns . 
NULL ({ 17 }) With ({ 1 }) this ({ 2 }) flexible ({ 3 }) classifier ({ 4 }) , ({ 5 }) the ({ 6 }) moving ({ 7 }) step ({ 8 }) size ({ 9 }) can ({ 10 }) be ({ 11 }) increased ({ 12 }) up ({ 13 }) to ({ 14 }) 12 ({ 15 }) pixels ({ 16 }) to ({ }) dramatically ({ 19 }) reduce ({ 18 }) the ({ }) number ({ 20 }) of ({ 21 }) analyzed ({ 22 }) patterns ({ 23 }) . ({ 24 }) 
# Sentence pair (1783) source length 14 target length 13 alignment score : 2.31291e-05
Efficiency of this stage will be discussed further in section 6 .3 . 
NULL ({ }) The ({ }) efficiency ({ 1 }) of ({ 2 }) this ({ 3 }) stage ({ 4 }) will ({ 5 }) be ({ 6 }) discussed ({ 7 }) further ({ 8 }) in ({ 9 }) section ({ 10 }) 6 ({ 11 }) .3 ({ 12 }) . ({ 13 }) 
# Sentence pair (1784) source length 25 target length 25 alignment score : 1.33548e-05
The last stage is a cascade of non-linear SVM classifiers that reuses features that have been selected by AdaBoost in the second stage classifier . 
NULL ({ }) The ({ 1 }) last ({ 2 }) stage ({ 3 }) is ({ 4 }) a ({ 5 }) cascade ({ 6 }) of ({ 7 }) nonlinear ({ 8 }) SVM ({ 9 }) classifiers ({ 10 }) that ({ 11 }) reuses ({ 12 }) features ({ 13 }) that ({ 14 }) have ({ 15 }) been ({ 16 }) selected ({ 17 }) by ({ 18 }) AdaBoost ({ 19 }) in ({ 20 }) the ({ 21 }) second ({ 22 }) stage ({ 23 }) classifier ({ 24 }) . ({ 25 }) 
# Sentence pair (1785) source length 19 target length 19 alignment score : 0.000649498
These feature values are evaluated and scaled to be between 0 and 1 to form a feature vector . 
NULL ({ }) These ({ 1 }) feature ({ 2 }) values ({ 3 }) are ({ 4 }) evaluated ({ 5 }) and ({ 6 }) scaled ({ 7 }) to ({ 8 }) be ({ 9 }) between ({ 10 }) 0 ({ 11 }) and ({ 12 }) 1 ({ 13 }) to ({ 14 }) form ({ 15 }) a ({ 16 }) feature ({ 17 }) vector ({ 18 }) . ({ 19 }) 
# Sentence pair (1786) source length 26 target length 23 alignment score : 5.2357e-19
In our experiments , only 100 features are used and hence it is faster than using any pixel-based SVM classifiers [8] ,[9] . 
NULL ({ 10 }) In ({ 1 }) our ({ 2 }) experiments ({ 3 }) , ({ 4 }) only ({ 5 }) 100 ({ 6 }) features ({ 7 }) were ({ 8 }) used ({ 9 }) , ({ }) making ({ 11 }) classification ({ 12 }) faster ({ 14 }) than ({ 15 }) it ({ }) would ({ 13 }) have ({ }) been ({ }) using ({ 16 }) pixel-based ({ 17 18 }) SVM ({ 19 }) classifiers ({ 20 }) [8] ({ 21 }) , ({ }) [9] ({ 22 }) . ({ 23 }) 
# Sentence pair (1787) source length 16 target length 16 alignment score : 1.51141e-07
The same feature set as proposed in [1] is used ( cf. Figure 4 ) . 
NULL ({ 5 }) The ({ 1 }) same ({ 2 }) feature ({ 3 }) set ({ 4 }) proposed ({ 6 }) in ({ 7 }) [1] ({ 8 }) was ({ 9 }) used ({ 10 }) ( ({ 11 }) cf ({ 12 }) . ({ }) Figure ({ 13 }) 4 ({ 14 }) ) ({ 15 }) . ({ 16 }) 
# Sentence pair (1788) source length 19 target length 19 alignment score : 5.24506e-06
It consists of four kinds of features modeled from adjacent basic rectangles with the same size and shape . 
NULL ({ }) It ({ 1 }) consists ({ 2 }) of ({ 3 }) four ({ 4 }) kinds ({ 5 }) of ({ 6 }) features ({ 7 }) modeled ({ 8 }) from ({ 9 }) adjacent ({ 10 }) basic ({ 11 }) rectangles ({ 12 }) of ({ 13 }) the ({ 14 }) same ({ 15 }) size ({ 16 }) and ({ 17 }) shape ({ 18 }) . ({ 19 }) 
# Sentence pair (1789) source length 17 target length 16 alignment score : 0.0004606
The feature value is defined as the difference of sum of the pixels within rectangles . 
NULL ({ }) The ({ 1 }) feature ({ 2 }) value ({ 3 }) is ({ 4 }) defined ({ 5 }) as ({ 6 }) the ({ 7 }) difference ({ 8 }) of ({ 9 }) the ({ }) sum ({ 10 }) of ({ 11 }) the ({ 12 }) pixels ({ 13 }) within ({ 14 }) rectangles ({ 15 }) . ({ 16 }) 
# Sentence pair (1790) source length 30 target length 26 alignment score : 8.82104e-09
Each feature is parameterized by four parameters : the position within the window \MATH , width \MATH and height \MATH ( cf. Figure 5 ) . 
NULL ({ }) Each ({ 1 }) feature ({ 2 }) is ({ 3 }) parameterized ({ 4 }) by ({ 5 }) four ({ 6 }) parameters ({ 7 }) : ({ 8 }) the ({ 9 }) position ({ 10 }) within ({ 11 }) the ({ 12 }) window ({ 13 }) \MATH ({ 14 }) , ({ 15 }) the ({ }) width ({ 16 }) \MATH ({ 17 }) , ({ }) and ({ 18 }) the ({ }) height ({ 19 }) \MATH ({ 20 }) ( ({ 21 }) cf ({ 22 }) . ({ }) Figure ({ 23 }) 5 ({ 24 }) ) ({ 25 }) . ({ 26 }) 
# Sentence pair (1791) source length 19 target length 17 alignment score : 6.28601e-09
By using integral image definition [1] , these rectangle feature values can be computed extremely quickly . 
NULL ({ }) By ({ 1 }) using ({ 2 }) integral ({ 3 }) image ({ 4 }) definition ({ 5 }) [1] ({ 6 }) , ({ 7 }) the ({ }) feature ({ 10 }) values ({ 11 }) of ({ }) these ({ 8 }) rectangles ({ 9 }) can ({ 12 }) be ({ 13 }) computed ({ 14 }) extremely ({ 15 }) quickly ({ 16 }) . ({ 17 }) 
# Sentence pair (1792) source length 24 target length 24 alignment score : 0.000321597
The integral image at location \MATH is defined as \MATH , where \MATH is the integral image and \MATH is the original image . 
NULL ({ }) The ({ 1 }) integral ({ 2 }) image ({ 3 }) at ({ 4 }) location ({ 5 }) \MATH ({ 6 }) is ({ 7 }) defined ({ 8 }) as ({ 9 }) \MATH ({ 10 }) , ({ 11 }) where ({ 12 }) \MATH ({ 13 }) is ({ 14 }) the ({ 15 }) integral ({ 16 }) image ({ 17 }) and ({ 18 }) \MATH ({ 19 }) is ({ 20 }) the ({ 21 }) original ({ 22 }) image ({ 23 }) . ({ 24 }) 
# Sentence pair (1793) source length 41 target length 41 alignment score : 2.58475e-07
In practice , \MATH can be computed simply by using the following recurrent function :\MATH , and sum of the pixels within a rectangle can be computed from four integral image values of its vertices , for example , \MATH . 
NULL ({ }) In ({ 1 }) practice ({ 2 }) , ({ 3 }) \MATH ({ 4 }) can ({ 5 }) be ({ 6 }) computed ({ 7 }) simply ({ 8 }) by ({ 9 }) using ({ 10 }) the ({ 11 }) following ({ 12 }) recurrent ({ 13 }) function ({ 14 }) :\MATH ({ 15 }) , ({ 16 }) and ({ 17 }) sum ({ 18 }) of ({ 19 }) the ({ 20 }) pixels ({ 21 }) within ({ 22 }) a ({ 23 }) rectangle ({ 24 }) can ({ 25 }) be ({ 26 }) computed ({ 27 }) from ({ 28 }) four ({ 29 }) integral ({ 30 }) image ({ 31 }) values ({ 32 }) of ({ 33 }) its ({ 34 }) vertices ({ 35 }) , ({ 36 }) for ({ 37 }) example ({ 38 }) , ({ 39 }) \MATH ({ 40 }) . ({ 41 }) 
# Sentence pair (1794) source length 16 target length 16 alignment score : 0.000808293
Boosting is used to improve the classification performance of any given simple learning algorithm [28] . 
NULL ({ }) Boosting ({ 1 }) is ({ 2 }) used ({ 3 }) to ({ 4 }) improve ({ 5 }) the ({ 6 }) classification ({ 7 }) performance ({ 8 }) of ({ 9 }) any ({ 10 }) given ({ 11 }) simple ({ 12 }) learning ({ 13 }) algorithm ({ 14 }) [28] ({ 15 }) . ({ 16 }) 
# Sentence pair (1795) source length 34 target length 33 alignment score : 1.29299e-06
Given \MATH weak classifiers \MATH learned through \MATH rounds of boosting , the strong classifier is formed by a linear combination : \MATH where \MATH are coefficients found in the boosting process . 
NULL ({ }) Given ({ 1 }) \MATH ({ 2 }) weak ({ 3 }) classifiers ({ 4 }) \MATH ({ 5 }) learned ({ 6 }) through ({ 7 }) \MATH ({ 8 }) rounds ({ 9 }) of ({ 10 }) boosting ({ 11 }) , ({ 12 }) the ({ 13 }) strong ({ 14 }) classifier ({ 15 }) is ({ 16 }) formed ({ 17 }) by ({ 18 }) a ({ 19 }) linear ({ 20 }) combination ({ 21 }) : ({ 22 }) \MATH ({ 23 }) , ({ }) where ({ 24 }) \MATH ({ 25 }) are ({ 26 }) coefficients ({ 27 }) found ({ 28 }) in ({ 29 }) the ({ 30 }) boosting ({ 31 }) process ({ 32 }) . ({ 33 }) 
# Sentence pair (1796) source length 43 target length 43 alignment score : 4.19883e-11
Each weak classifier \MATH is associated with a feature \MATH and a threshold \MATH such that the number of incorrect classified examples corresponding to this weak classifier is minimized : \MATH , where polarity \MATH indicates the direction of the inequality sign . 
NULL ({ 25 }) Each ({ 1 }) weak ({ 2 }) classifier ({ 3 }) \MATH ({ 4 }) is ({ 5 }) associated ({ 6 }) with ({ 7 }) a ({ 8 }) feature ({ 9 }) \MATH ({ 10 }) and ({ 11 }) a ({ 12 }) threshold ({ 13 }) \MATH ({ 14 }) such ({ 15 }) that ({ 16 }) the ({ 17 }) number ({ 18 }) of ({ 19 }) incorrectly ({ 20 }) classified ({ 21 }) examples ({ 22 }) corresponding ({ 23 }) to ({ 24 }) the ({ }) weak ({ 26 }) classifier ({ 27 }) is ({ 28 }) minimized ({ 29 }) : ({ 30 }) \MATH ({ 31 }) , ({ 32 }) where ({ 33 }) polarity ({ 34 }) \MATH ({ 35 }) indicates ({ 36 }) the ({ 37 }) direction ({ 38 }) of ({ 39 }) the ({ 40 }) inequality ({ 41 }) sign ({ 42 }) . ({ 43 }) 
# Sentence pair (1797) source length 21 target length 21 alignment score : 0.000248683
In each round of boosting , the best weak classifier \MATH that has the lowest error \MATH will be chosen . 
NULL ({ }) In ({ 1 }) each ({ 2 }) round ({ 3 }) of ({ 4 }) boosting ({ 5 }) , ({ 6 }) the ({ 7 }) best ({ 8 }) weak ({ 9 }) classifier ({ 10 }) \MATH ({ 11 }) that ({ 12 }) has ({ 13 }) the ({ 14 }) lowest ({ 15 }) error ({ 16 }) \MATH ({ 17 }) will ({ 18 }) be ({ 19 }) chosen ({ 20 }) . ({ 21 }) 
# Sentence pair (1798) source length 40 target length 42 alignment score : 1.44188e-13
The error of each weak classifier is measured with respect to the set of weights over each example of the training set \MATH , where \MATH and \MATH are the weight and the label of the training example \MATH , respectively . 
NULL ({ 33 40 }) The ({ 1 }) error ({ 2 }) of ({ 3 }) each ({ 4 }) weak ({ 5 }) classifier ({ 6 }) is ({ 7 }) measured ({ 8 }) with ({ 9 }) respect ({ 10 }) to ({ 11 }) the ({ 12 }) set ({ 13 }) of ({ 14 }) weights ({ 15 }) over ({ 16 }) each ({ 17 }) example ({ 18 }) of ({ 19 }) the ({ 20 }) training ({ 21 }) set ({ 22 }) \MATH ({ 23 }) , ({ 24 }) where ({ 25 }) \MATH ({ 26 }) and ({ 27 }) \MATH ({ 28 }) are ({ 29 }) the ({ 30 }) respective ({ 41 }) weight ({ 31 }) and ({ 32 }) label ({ 34 }) of ({ 35 }) the ({ 36 }) training ({ 37 }) example ({ 38 }) \MATH ({ 39 }) . ({ 42 }) 
# Sentence pair (1799) source length 26 target length 26 alignment score : 7.39134e-05
After each round , these weights are updated such that the weak learner will focus much more on the hard examples in the next round . 
NULL ({ }) After ({ 1 }) each ({ 2 }) round ({ 3 }) , ({ 4 }) these ({ 5 }) weights ({ 6 }) are ({ 7 }) updated ({ 8 }) such ({ 9 }) that ({ 10 }) the ({ 11 }) weak ({ 12 }) learner ({ 13 }) will ({ 14 }) focus ({ 15 }) much ({ 16 }) more ({ 17 }) on ({ 18 }) the ({ 19 }) hard ({ 20 }) examples ({ 21 }) in ({ 22 }) the ({ 23 }) next ({ 24 }) round ({ 25 }) . ({ 26 }) 
# Sentence pair (1800) source length 28 target length 28 alignment score : 1.41462e-05
The main idea of building a cascade of classifiers is to reduce the computation time by giving different treatments to different complexities of input windows ( cf . 
NULL ({ }) The ({ 1 }) main ({ 2 }) idea ({ 3 }) of ({ 4 }) building ({ 5 }) a ({ 6 }) cascade ({ 7 }) of ({ 8 }) classifiers ({ 9 }) is ({ 10 }) to ({ 11 }) reduce ({ 12 }) the ({ 13 }) computation ({ 14 }) time ({ 15 }) by ({ 16 }) giving ({ 17 }) different ({ 18 }) treatments ({ 19 }) to ({ 20 }) different ({ 21 }) complexities ({ 22 }) of ({ 23 }) input ({ 24 }) windows ({ 25 }) ( ({ 26 }) cf ({ 27 }) . ({ 28 }) 
# Sentence pair (1801) source length 4 target length 4 alignment score : 0.302061
Figure 7 ) . 
NULL ({ }) Figure ({ 1 }) 7 ({ 2 }) ) ({ 3 }) . ({ 4 }) 
# Sentence pair (1802) source length 17 target length 17 alignment score : 0.00148244
Only input windows that have passed through all layers of the cascade are classified as faces . 
NULL ({ }) Only ({ 1 }) input ({ 2 }) windows ({ 3 }) that ({ 4 }) have ({ 5 }) passed ({ 6 }) through ({ 7 }) all ({ 8 }) layers ({ 9 }) of ({ 10 }) the ({ 11 }) cascade ({ 12 }) are ({ 13 }) classified ({ 14 }) as ({ 15 }) faces ({ 16 }) . ({ 17 }) 
# Sentence pair (1803) source length 37 target length 38 alignment score : 4.75633e-15
Training cascaded classifiers that can achieve both good detection rate and less computation time is quite complex , because a higher detection rate requires more features , but more features are correspondent to more time for evaluation . 
NULL ({ 18 31 }) Training ({ 1 }) cascaded ({ 2 }) classifiers ({ 3 }) that ({ 4 }) can ({ 5 }) achieve ({ 6 }) both ({ 7 }) good ({ 8 }) detection ({ 9 }) rates ({ 10 }) and ({ 11 }) less ({ 12 }) computation ({ 13 }) time ({ 14 }) is ({ 15 }) quite ({ 16 }) complex ({ 17 }) ; ({ 19 }) a ({ 20 }) higher ({ 21 }) detection ({ 22 }) rate ({ 23 }) requires ({ 24 }) more ({ 25 }) features ({ 26 }) , ({ 27 }) but ({ 28 }) more ({ 29 }) features ({ 30 }) correspond ({ 32 }) to ({ 33 }) more ({ 34 }) time ({ 35 }) needed ({ }) for ({ 36 }) evaluation ({ 37 }) . ({ 38 }) 
# Sentence pair (1804) source length 22 target length 22 alignment score : 0.000178042
To simplify this , the detection rate goal and the false positive rate goal for each layer are usually set beforehand . 
NULL ({ }) To ({ 1 }) simplify ({ 2 }) this ({ 3 }) , ({ 4 }) the ({ 5 }) detection ({ 6 }) rate ({ 7 }) goal ({ 8 }) and ({ 9 }) the ({ 10 }) false ({ 11 }) positive ({ 12 }) rate ({ 13 }) goal ({ 14 }) for ({ 15 }) each ({ 16 }) layer ({ 17 }) are ({ 18 }) usually ({ 19 }) set ({ 20 }) beforehand ({ 21 }) . ({ 22 }) 
# Sentence pair (1805) source length 36 target length 36 alignment score : 8.24893e-10
Viola and Jones [1] stated that , if the layer classifier could achieve the predefined target goals after 200 features are used , the training process will stop and a new layer will be added . 
NULL ({ }) Viola ({ 1 }) and ({ 2 }) Jones ({ 3 }) [1] ({ 4 }) stated ({ 5 }) that ({ 6 }) , ({ 7 }) if ({ 8 }) the ({ 9 }) layer ({ 10 }) classifier ({ 11 }) has ({ 12 }) achieved ({ 13 }) the ({ 14 }) predefined ({ 15 }) target ({ 16 }) goals ({ 17 }) after ({ 18 }) 200 ({ 19 }) features ({ 20 }) are ({ 21 }) used ({ 22 }) , ({ 23 }) the ({ 24 }) training ({ 25 }) process ({ 26 }) will ({ 27 }) stop ({ 28 }) and ({ 29 }) a ({ 30 }) new ({ 31 }) layer ({ 32 }) will ({ 33 }) be ({ 34 }) added ({ 35 }) . ({ 36 }) 
# Sentence pair (1806) source length 9 target length 9 alignment score : 0.047443
1 . <section label= " SVM Classifier " > 
NULL ({ }) 1 ({ 1 }) . ({ 2 }) <section ({ 3 }) label= ({ 4 }) " ({ 5 }) SVM ({ 6 }) Classifier ({ 7 }) " ({ 8 }) > ({ 9 }) 
# Sentence pair (1807) source length 16 target length 16 alignment score : 0.00368971
The support vector machine is a statistical learning method based on the structure-risk minimization principle . 
NULL ({ }) The ({ 1 }) support ({ 2 }) vector ({ 3 }) machine ({ 4 }) is ({ 5 }) a ({ 6 }) statistical ({ 7 }) learning ({ 8 }) method ({ 9 }) based ({ 10 }) on ({ 11 }) the ({ 12 }) structure-risk ({ 13 }) minimization ({ 14 }) principle ({ 15 }) . ({ 16 }) 
# Sentence pair (1808) source length 17 target length 15 alignment score : 6.55622e-06
It has been very efficiently proved in many pattern recognition applications [29] ,[8] ,[9] . 
NULL ({ }) It ({ 1 }) has ({ 2 }) been ({ 3 }) very ({ 4 }) efficiently ({ 5 }) proven ({ 6 }) in ({ 7 }) many ({ 8 }) pattern ({ 9 }) recognition ({ 10 }) applications ({ 11 }) [29] ({ 12 }) , ({ }) [8] ({ 13 }) , ({ }) [9] ({ 14 }) . ({ 15 }) 
# Sentence pair (1809) source length 23 target length 23 alignment score : 0.000211999
In the binary classification case , the objective of the SVM is to find the best separating hyperplane with a maximum margin . 
NULL ({ }) In ({ 1 }) the ({ 2 }) binary ({ 3 }) classification ({ 4 }) case ({ 5 }) , ({ 6 }) the ({ 7 }) objective ({ 8 }) of ({ 9 }) the ({ 10 }) SVM ({ 11 }) is ({ 12 }) to ({ 13 }) find ({ 14 }) the ({ 15 }) best ({ 16 }) separating ({ 17 }) hyperplane ({ 18 }) with ({ 19 }) a ({ 20 }) maximum ({ 21 }) margin ({ 22 }) . ({ 23 }) 
# Sentence pair (1810) source length 36 target length 37 alignment score : 3.92515e-11
The form of SVM classifiers is : \MATH where : \MATH is the d-dimensional vector of an observation example , \MATH is a class label , and \MATH is the vector of the \MATH training example . 
NULL ({ 10 }) The ({ 1 }) form ({ 2 }) of ({ 3 }) SVM ({ 4 }) classifiers ({ 5 }) is ({ 6 }) : ({ 7 }) \MATH ({ 8 }) where ({ 9 }) \MATH ({ 11 }) is ({ 12 }) the ({ 13 }) d-dimensional ({ 14 }) vector ({ 15 }) of ({ 16 }) an ({ 17 }) observation ({ 18 }) example ({ 19 }) , ({ 20 }) \MATH ({ 21 }) is ({ 22 }) a ({ 23 }) class ({ 24 }) label ({ 25 }) , ({ 26 }) and ({ 27 }) \MATH ({ 28 }) is ({ 29 }) the ({ 30 }) vector ({ 31 }) of ({ 32 }) the ({ 33 }) \MATH ({ 34 }) training ({ 35 }) example ({ 36 }) . ({ 37 }) 
# Sentence pair (1811) source length 12 target length 12 alignment score : 0.00731613
All the \MATH corresponding to non-zero \MATH are called support vectors . 
NULL ({ }) All ({ 1 }) the ({ 2 }) \MATH ({ 3 }) corresponding ({ 4 }) to ({ 5 }) non-zero ({ 6 }) \MATH ({ 7 }) are ({ 8 }) called ({ 9 }) support ({ 10 }) vectors ({ 11 }) . ({ 12 }) 
# Sentence pair (1812) source length 20 target length 21 alignment score : 3.95006e-07
It is important to choose the appropriate kernel and parameter \MATH in order to to obtain the robust SVM classifier . 
NULL ({ 14 }) It ({ 1 }) is ({ 2 }) important ({ 3 }) to ({ 4 }) choose ({ 5 }) the ({ 6 }) appropriate ({ 7 }) kernel ({ 8 }) and ({ 9 }) parameter ({ 10 }) \MATH ({ 11 }) in ({ 12 }) order ({ 13 }) to ({ 15 }) obtain ({ 16 }) the ({ 17 }) robust ({ 18 }) SVM ({ 19 }) classifier ({ 20 }) . ({ 21 }) 
# Sentence pair (1813) source length 27 target length 26 alignment score : 5.44765e-06
Although many kernels have been introduced by researchers , the following four kernels are commonly used : \MATH where \MATH and \MATH are kernel parameters . 
NULL ({ }) Although ({ 1 }) many ({ 2 }) kernels ({ 3 }) have ({ 4 }) been ({ 5 }) introduced ({ 6 }) by ({ 7 }) researchers ({ 8 }) , ({ 9 }) the ({ 10 }) following ({ 11 }) four ({ 12 }) kernels ({ 13 }) are ({ 14 }) commonly ({ 15 }) used ({ 16 }) : ({ 17 }) \MATH ({ 18 }) where ({ 19 }) \MATH ({ 20 }) , ({ }) and ({ 21 }) \MATH ({ 22 }) are ({ 23 }) kernel ({ 24 }) parameters ({ 25 }) . ({ 26 }) 
# Sentence pair (1814) source length 25 target length 25 alignment score : 3.34184e-09
Compared to AdaBoost classifiers , SVM classifiers run much slower in running because of the large number of support vectors and heavy kernel computation . 
NULL ({ 11 }) Compared ({ 1 }) to ({ 2 }) AdaBoost ({ 3 }) classifiers ({ 4 }) , ({ 5 }) SVM ({ 6 }) classifiers ({ 7 }) run ({ 8 }) much ({ 9 }) more ({ 10 }) slowly ({ 12 }) because ({ 13 }) of ({ 14 }) the ({ 15 }) large ({ 16 }) number ({ 17 }) of ({ 18 }) support ({ 19 }) vectors ({ 20 }) and ({ 21 }) the ({ }) heavy ({ 22 }) kernel ({ 23 }) computation ({ 24 }) . ({ 25 }) 
# Sentence pair (1815) source length 29 target length 29 alignment score : 1.36366e-05
To control the trade-off between the number of support vectors and errors , Scholkopf et al. [30] proposed using a new parameter \MATH instead of the parameter \MATH . 
NULL ({ }) To ({ 1 }) control ({ 2 }) the ({ 3 }) trade-off ({ 4 }) between ({ 5 }) the ({ 6 }) number ({ 7 }) of ({ 8 }) support ({ 9 }) vectors ({ 10 }) and ({ 11 }) errors ({ 12 }) , ({ 13 }) Scholkopf ({ 14 }) et ({ 15 }) al. ({ 16 }) [30] ({ 17 }) proposed ({ 18 }) using ({ 19 }) a ({ 20 }) new ({ 21 }) parameter ({ 22 }) \MATH ({ 23 }) instead ({ 24 }) of ({ 25 }) the ({ 26 }) parameter ({ 27 }) \MATH ({ 28 }) . ({ 29 }) 
# Sentence pair (1816) source length 27 target length 27 alignment score : 3.10392e-05
They proved that the parameter \MATH is an upper bound of the fraction of margin errors and a lower bound of the fraction of support vectors . 
NULL ({ }) They ({ 1 }) proved ({ 2 }) that ({ 3 }) the ({ 4 }) parameter ({ 5 }) \MATH ({ 6 }) is ({ 7 }) an ({ 8 }) upper ({ 9 }) bound ({ 10 }) of ({ 11 }) the ({ 12 }) fraction ({ 13 }) of ({ 14 }) margin ({ 15 }) errors ({ 16 }) and ({ 17 }) a ({ 18 }) lower ({ 19 }) bound ({ 20 }) of ({ 21 }) the ({ 22 }) fraction ({ 23 }) of ({ 24 }) support ({ 25 }) vectors ({ 26 }) . ({ 27 }) 
# Sentence pair (1817) source length 12 target length 12 alignment score : 0.013023
The implementations of \MATH and \MATH are provided by LibSVM [31] . 
NULL ({ }) The ({ 1 }) implementations ({ 2 }) of ({ 3 }) \MATH ({ 4 }) and ({ 5 }) \MATH ({ 6 }) are ({ 7 }) provided ({ 8 }) by ({ 9 }) LibSVM ({ 10 }) [31] ({ 11 }) . ({ 12 }) 
# Sentence pair (1818) source length 20 target length 15 alignment score : 3.25639e-07
For training , we collected 7 ,500 , 24x24-size face patterns from the Internet . 
NULL ({ }) For ({ 1 }) training ({ 2 }) , ({ 3 }) we ({ 4 }) collected ({ 5 }) 7 ({ 6 }) ,500 ({ 7 }) , ({ 8 }) 24x24-size ({ 9 }) face ({ 10 }) patterns ({ 11 }) from ({ 12 }) the ({ 13 }) Internet ({ 14 }) . ({ 15 }) / ({ }) / ({ }) size ({ }) / ({ }) pixel? ({ }) 
# Sentence pair (1819) source length 34 target length 34 alignment score : 2.3404e-06
Non-face patterns were generated at different locations and scales from 8 ,440 images with various subjects , such as rocks , trees , buildings , scenery , and flowers , containing no faces . 
NULL ({ }) Non-face ({ 1 }) patterns ({ 2 }) were ({ 3 }) generated ({ 4 }) at ({ 5 }) different ({ 6 }) locations ({ 7 }) and ({ 8 }) scales ({ 9 }) from ({ 10 }) 8 ({ 11 }) ,440 ({ 12 }) images ({ 13 }) with ({ 14 }) various ({ 15 }) subjects ({ 16 }) , ({ 17 }) such ({ 18 }) as ({ 19 }) rocks ({ 20 }) , ({ 21 }) trees ({ 22 }) , ({ 23 }) buildings ({ 24 }) , ({ 25 }) scenery ({ 26 }) , ({ 27 }) and ({ 28 }) flowers ({ 29 }) , ({ 30 }) containing ({ 31 }) no ({ 32 }) faces ({ 33 }) . ({ 34 }) 
# Sentence pair (1820) source length 14 target length 14 alignment score : 0.0065696
Some examples of the collected 24x24 face patterns are shown in Figure 8 . 
NULL ({ }) Some ({ 1 }) examples ({ 2 }) of ({ 3 }) the ({ 4 }) collected ({ 5 }) 24x24 ({ 6 }) face ({ 7 }) patterns ({ 8 }) are ({ 9 }) shown ({ 10 }) in ({ 11 }) Figure ({ 12 }) 8 ({ 13 }) . ({ 14 }) 
# Sentence pair (1821) source length 23 target length 23 alignment score : 9.2898e-05
Face patterns for training the 36x36 classifiers are generated by selecting 36x36 windows containing the 24x24 face window of the input image . 
NULL ({ }) Face ({ 1 }) patterns ({ 2 }) for ({ 3 }) training ({ 4 }) the ({ 5 }) 36x36 ({ 6 }) classifiers ({ 7 }) were ({ 8 }) generated ({ 9 }) by ({ 10 }) selecting ({ 11 }) 36x36 ({ 12 }) windows ({ 13 }) containing ({ 14 }) the ({ 15 }) 24x24 ({ 16 }) face ({ 17 }) window ({ 18 }) of ({ 19 }) the ({ 20 }) input ({ 21 }) image ({ 22 }) . ({ 23 }) 
# Sentence pair (1822) source length 19 target length 19 alignment score : 0.000743071
Figure 9 shows some examples of 36x36 face patterns that include various kinds of floating positions and backgrounds . 
NULL ({ }) Figure ({ 1 }) 9 ({ 2 }) shows ({ 3 }) some ({ 4 }) examples ({ 5 }) of ({ 6 }) 36x36 ({ 7 }) face ({ 8 }) patterns ({ 9 }) that ({ 10 }) include ({ 11 }) various ({ 12 }) kinds ({ 13 }) of ({ 14 }) floating ({ 15 }) positions ({ 16 }) and ({ 17 }) backgrounds ({ 18 }) . ({ 19 }) 
# Sentence pair (1823) source length 26 target length 26 alignment score : 2.56008e-05
To train the cascade of 24x24 AdaBoost classifiers used in the rejection stage , the same 7 ,500 face patterns are used for all layers . 
NULL ({ }) To ({ 1 }) train ({ 2 }) the ({ 3 }) cascade ({ 4 }) of ({ 5 }) 24x24 ({ 6 }) AdaBoost ({ 7 }) classifiers ({ 8 }) used ({ 9 }) in ({ 10 }) the ({ 11 }) rejection ({ 12 }) stage ({ 13 }) , ({ 14 }) the ({ 15 }) same ({ 16 }) 7 ({ 17 }) ,500 ({ 18 }) face ({ 19 }) patterns ({ 20 }) were ({ 21 }) used ({ 22 }) for ({ 23 }) all ({ 24 }) layers ({ 25 }) . ({ 26 }) 
# Sentence pair (1824) source length 20 target length 20 alignment score : 0.000435996
Non-face patterns of the training and the validating sets of the first layer in the cascade are selected randomly . 
NULL ({ }) Non-face ({ 1 }) patterns ({ 2 }) of ({ 3 }) the ({ 4 }) training ({ 5 }) and ({ 6 }) the ({ 7 }) validating ({ 8 }) sets ({ 9 }) of ({ 10 }) the ({ 11 }) first ({ 12 }) layer ({ 13 }) in ({ 14 }) the ({ 15 }) cascade ({ 16 }) were ({ 17 }) selected ({ 18 }) randomly ({ 19 }) . ({ 20 }) 
# Sentence pair (1825) source length 23 target length 23 alignment score : 0.000236986
Non-face patterns of the subsequent layer classifiers are false positives collected by the partially trained cascade on the set of non-face images . 
NULL ({ }) Non-face ({ 1 }) patterns ({ 2 }) of ({ 3 }) the ({ 4 }) subsequent ({ 5 }) layer ({ 6 }) classifiers ({ 7 }) are ({ 8 }) false ({ 9 }) positives ({ 10 }) collected ({ 11 }) by ({ 12 }) the ({ 13 }) partially ({ 14 }) trained ({ 15 }) cascade ({ 16 }) on ({ 17 }) the ({ 18 }) set ({ 19 }) of ({ 20 }) non-face ({ 21 }) images ({ 22 }) . ({ 23 }) 
# Sentence pair (1826) source length 24 target length 24 alignment score : 4.64854e-05
For each layer classifier , 7 ,500 non-face patterns are used for training and 7 ,500 other non-face patterns are used for validating . 
NULL ({ }) For ({ 1 }) each ({ 2 }) layer ({ 3 }) classifier ({ 4 }) , ({ 5 }) 7 ({ 6 }) ,500 ({ 7 }) non-face ({ 8 }) patterns ({ 9 }) were ({ 10 }) used ({ 11 }) for ({ 12 }) training ({ 13 }) and ({ 14 }) 7 ({ 15 }) ,500 ({ 16 }) other ({ 17 }) non-face ({ 18 }) patterns ({ 19 }) were ({ 20 }) used ({ 21 }) for ({ 22 }) validating ({ 23 }) . ({ 24 }) 
# Sentence pair (1827) source length 28 target length 29 alignment score : 1.79627e-09
To compare the performance of classifiers , we have implemented a fully cascade of classifiers trained by AdaBoost , similar to that used by Viola and Jones [1] . 
NULL ({ }) To ({ 1 }) compare ({ 2 }) the ({ 3 }) performance ({ 4 }) of ({ 5 }) classifiers ({ 6 }) , ({ 7 }) we ({ 8 }) implemented ({ 9 10 }) a ({ 11 }) full ({ 12 }) cascade ({ 13 }) of ({ 14 }) classifiers ({ 15 }) trained ({ 16 }) by ({ 17 }) AdaBoost ({ 18 }) , ({ 19 }) similar ({ 20 }) to ({ 21 }) that ({ 22 }) used ({ 23 }) by ({ 24 }) Viola ({ 25 }) and ({ 26 }) Jones ({ 27 }) [1] ({ 28 }) . ({ 29 }) 
# Sentence pair (1828) source length 11 target length 11 alignment score : 0.020017
The training parameters of each layer were set as follows . 
NULL ({ }) The ({ 1 }) training ({ 2 }) parameters ({ 3 }) of ({ 4 }) each ({ 5 }) layer ({ 6 }) were ({ 7 }) set ({ 8 }) as ({ 9 }) follows ({ 10 }) . ({ 11 }) 
# Sentence pair (1829) source length 33 target length 32 alignment score : 1.24329e-07
The minimum of the detection rate is \MATH , the maximum of the false positive rate is \MATH and the maximum of the number of features in each layer is 200 . 
NULL ({ }) The ({ 1 }) minimum ({ 2 }) of ({ 3 }) the ({ 4 }) detection ({ 5 }) rate ({ 6 }) was ({ 7 }) \MATH ({ 8 }) , ({ 9 }) the ({ 10 }) maximum ({ 11 }) of ({ 12 }) the ({ 13 }) false ({ 14 }) positive ({ 15 }) rate ({ 16 }) was ({ 17 }) \MATH ({ 18 }) , ({ }) and ({ 19 }) the ({ 20 }) maximum ({ 21 }) of ({ 22 }) the ({ 23 }) number ({ 24 }) of ({ 25 }) features ({ 26 }) in ({ 27 }) each ({ 28 }) layer ({ 29 }) was ({ 30 }) 200 ({ 31 }) . ({ 32 }) 
# Sentence pair (1830) source length 17 target length 17 alignment score : 0.00137328
This setting resulted in a face detector that consists of 38 layers with 6 ,360 features . 
NULL ({ }) This ({ 1 }) setting ({ 2 }) resulted ({ 3 }) in ({ 4 }) a ({ 5 }) face ({ 6 }) detector ({ 7 }) that ({ 8 }) consists ({ 9 }) of ({ 10 }) 38 ({ 11 }) layers ({ 12 }) with ({ 13 }) 6 ({ 14 }) ,360 ({ 15 }) features ({ 16 }) . ({ 17 }) 
# Sentence pair (1831) source length 19 target length 19 alignment score : 0.000702263
All experiments were run on a PC ( Pentium 4 , 2 .8 MHz , 512-MB RAM ) . 
NULL ({ }) All ({ 1 }) experiments ({ 2 }) were ({ 3 }) run ({ 4 }) on ({ 5 }) a ({ 6 }) PC ({ 7 }) ( ({ 8 }) Pentium ({ 9 }) 4 ({ 10 }) , ({ 11 }) 2 ({ 12 }) .8 ({ 13 }) MHz ({ 14 }) , ({ 15 }) 512-MB ({ 16 }) RAM ({ 17 }) ) ({ 18 }) . ({ 19 }) 
# Sentence pair (1832) source length 21 target length 21 alignment score : 0.000185029
The training process was terminated when no more false positives were found in the non-face images of the data set . 
NULL ({ }) The ({ 1 }) training ({ 2 }) process ({ 3 }) was ({ 4 }) terminated ({ 5 }) when ({ 6 }) no ({ 7 }) more ({ 8 }) false ({ 9 }) positives ({ 10 }) were ({ 11 }) found ({ 12 }) in ({ 13 }) the ({ 14 }) non-face ({ 15 }) images ({ 16 }) of ({ 17 }) the ({ 18 }) data ({ 19 }) set ({ 20 }) . ({ 21 }) 
# Sentence pair (1833) source length 32 target length 31 alignment score : 2.59972e-07
If \MATH is the number of Haar wavelet features and \MATH is the number of training patterns , the learning time of AdaBoost to train \MATH weak classifiers is roughly[1] . 
NULL ({ }) If ({ 1 }) \MATH ({ 2 }) is ({ 3 }) the ({ 4 }) number ({ 5 }) of ({ 6 }) Haar ({ 7 }) wavelet ({ 8 }) features ({ 9 }) and ({ 10 }) \MATH ({ 11 }) is ({ 12 }) the ({ 13 }) number ({ 14 }) of ({ 15 }) training ({ 16 }) patterns ({ 17 }) , ({ 18 }) the ({ 19 }) learning ({ 20 }) time ({ 21 }) of ({ 22 }) AdaBoost ({ 23 }) to ({ 24 }) train ({ 25 }) \MATH ({ 26 }) weak ({ 27 }) classifiers ({ 28 }) is ({ 29 }) roughly ({ 30 }) [1] ({ }) . ({ 31 }) 
# Sentence pair (1834) source length 40 target length 40 alignment score : 3.44126e-07
Therefore , if the number of training patterns is fixed , the learning time can be shortened when either the number of features in the feature set or the number of weak classifiers in the final cascade is reduced . 
NULL ({ }) Therefore ({ 1 }) , ({ 2 }) if ({ 3 }) the ({ 4 }) number ({ 5 }) of ({ 6 }) training ({ 7 }) patterns ({ 8 }) is ({ 9 }) fixed ({ 10 }) , ({ 11 }) the ({ 12 }) learning ({ 13 }) time ({ 14 }) can ({ 15 }) be ({ 16 }) shortened ({ 17 }) when ({ 18 }) either ({ 19 }) the ({ 20 }) number ({ 21 }) of ({ 22 }) features ({ 23 }) in ({ 24 }) the ({ 25 }) feature ({ 26 }) set ({ 27 }) or ({ 28 }) the ({ 29 }) number ({ 30 }) of ({ 31 }) weak ({ 32 }) classifiers ({ 33 }) in ({ 34 }) the ({ 35 }) final ({ 36 }) cascade ({ 37 }) is ({ 38 }) reduced ({ 39 }) . ({ 40 }) 
# Sentence pair (1835) source length 35 target length 33 alignment score : 4.24804e-08
In our approach , the cascaded classifiers are only used for efficient rejection , so we can reduce both these numbers in order to keep training time for the full system reasonable . 
NULL ({ }) In ({ 1 }) our ({ 2 }) approach ({ 3 }) , ({ 4 }) the ({ 5 }) cascaded ({ 6 }) classifiers ({ 7 }) are ({ 8 }) only ({ 9 }) used ({ 10 }) for ({ 11 }) efficient ({ 12 }) rejection ({ 13 }) , ({ 14 }) so ({ 15 }) we ({ 16 }) can ({ 17 }) reduce ({ 18 }) both ({ 19 }) of ({ }) these ({ 20 }) numbers ({ 21 }) in ({ 22 }) order ({ 23 }) to ({ 24 }) keep ({ 25 }) the ({ }) training ({ 26 }) time ({ 27 }) for ({ 28 }) the ({ 29 }) full ({ 30 }) system ({ 31 }) reasonable ({ 32 }) . ({ 33 }) 
# Sentence pair (1836) source length 59 target length 19 alignment score : 2.59127e-49
As mentioned in section 4 .1 , each feature is parameterized by a tuple of four parameters \MATH . 
NULL ({ }) As ({ 1 }) mentioned ({ 2 }) in ({ 3 }) section ({ 4 }) 4 ({ 5 }) .1 ({ 6 }) , ({ 7 }) each ({ 8 }) feature ({ 9 }) is ({ 10 }) parameterized ({ 11 }) by ({ 12 }) a ({ 13 }) tuple ({ 14 }) of ({ 15 }) four ({ 16 }) parameters ({ 17 }) \MATH ({ 18 }) . ({ 19 }) / ({ }) / ({ }) If ({ }) this ({ }) ( ({ }) and ({ }) other ({ }) places ({ }) ) ({ }) do ({ }) not ({ }) display ({ }) with ({ }) spaces ({ }) after ({ }) the ({ }) commas ({ }) , ({ }) spaces ({ }) must ({ }) be ({ }) insert ({ }) . ({ }) A ({ }) comma ({ }) should ({ }) always ({ }) be ({ }) followed ({ }) by ({ }) a ({ }) space ({ }) . ({ }) I ({ }) recommend ({ }) checking ({ }) this ({ }) carefully ({ }) throughout ({ }) .] ({ }) 
# Sentence pair (1837) source length 16 target length 16 alignment score : 0.000136376
A set of features is then formed by changing these parameters in correspondent steps \MATH . 
NULL ({ }) A ({ 1 }) set ({ 2 }) of ({ 3 }) features ({ 4 }) is ({ 5 }) then ({ 6 }) formed ({ 7 }) by ({ 8 }) changing ({ 9 }) these ({ 10 }) parameters ({ 11 }) in ({ 12 }) corresponding ({ 13 }) steps ({ 14 }) \MATH ({ 15 }) . ({ 16 }) 
# Sentence pair (1838) source length 14 target length 13 alignment score : 5.68491e-11
In the other hand , a feature set is parameterized by \MATH . 
NULL ({ 6 }) A ({ 1 }) feature ({ 7 }) set ({ 8 }) , ({ }) on ({ }) the ({ 2 }) other ({ 3 }) hand ({ 4 }) , ({ 5 }) is ({ 9 }) parameterized ({ 10 }) by ({ 11 }) \MATH ({ 12 }) . ({ 13 }) 
# Sentence pair (1839) source length 32 target length 32 alignment score : 1.12573e-05
One of the simplest ways to sub-sample the feature set is to change parameters \MATH , for example , from a full feature set \MATH to a reduced feature set \MATH . 
NULL ({ }) One ({ 1 }) of ({ 2 }) the ({ 3 }) simplest ({ 4 }) ways ({ 5 }) to ({ 6 }) sub-sample ({ 7 }) the ({ 8 }) feature ({ 9 }) set ({ 10 }) is ({ 11 }) to ({ 12 }) change ({ 13 }) parameters ({ 14 }) \MATH ({ 15 }) , ({ 16 }) for ({ 17 }) example ({ 18 }) , ({ 19 }) from ({ 20 }) a ({ 21 }) full ({ 22 }) feature ({ 23 }) set ({ 24 }) \MATH ({ 25 }) to ({ 26 }) a ({ 27 }) reduced ({ 28 }) feature ({ 29 }) set ({ 30 }) \MATH ({ 31 }) . ({ 32 }) 
# Sentence pair (1840) source length 23 target length 23 alignment score : 2.33825e-09
Because the full feature set is redundant , this sub-sampling is expected not to affect the rejection performance of AdaBoost classifiers significantly . 
NULL ({ }) Because ({ 1 }) the ({ 2 }) full ({ 3 }) feature ({ 4 }) set ({ 5 }) is ({ 6 }) redundant ({ 7 }) , ({ 8 }) this ({ 9 }) sub-sampling ({ 10 }) is ({ 11 }) expected ({ 12 }) not ({ 13 }) to ({ 14 }) significantly ({ 22 }) affect ({ 15 }) the ({ 16 }) rejection ({ 17 }) performance ({ 18 }) of ({ 19 }) AdaBoost ({ 20 }) classifiers ({ 21 }) . ({ 23 }) 
# Sentence pair (1841) source length 46 target length 45 alignment score : 6.89839e-13
We carried out experiments to compare the performance of classifiers trained on these two feature sets : the full feature set \MATH containing 134 ,736 features and the reduced feature set \MATH containing 14 ,807 features ( excluding features with the small size ) . 
NULL ({ 41 }) We ({ 1 }) carried ({ 2 }) out ({ 3 }) experiments ({ 4 }) to ({ 5 }) compare ({ 6 }) the ({ 7 }) performance ({ 8 }) of ({ 9 }) classifiers ({ 10 }) trained ({ 11 }) on ({ 12 }) these ({ 13 }) two ({ 14 }) feature ({ 15 }) sets ({ 16 }) : ({ 17 }) the ({ 18 }) full ({ 19 }) feature ({ 20 }) set ({ 21 }) \MATH ({ 22 }) , ({ }) containing ({ 23 }) 134 ({ 24 }) ,736 ({ 25 }) features ({ 26 }) and ({ 27 }) the ({ 28 }) reduced ({ 29 }) feature ({ 30 }) set ({ 31 }) \MATH ({ 32 }) , ({ }) containing ({ 33 }) 14 ({ 34 }) ,807 ({ 35 }) features ({ 36 }) ( ({ 37 }) excluding ({ 38 }) features ({ 39 }) of ({ 40 }) small ({ 42 }) size ({ 43 }) ) ({ 44 }) . ({ 45 }) 
# Sentence pair (1842) source length 12 target length 12 alignment score : 0.00379062
Two classifiers are trained up to the maximum of 200 features . 
NULL ({ }) Two ({ 1 }) classifiers ({ 2 }) were ({ 3 }) trained ({ 4 }) up ({ 5 }) to ({ 6 }) the ({ 7 }) maximum ({ 8 }) of ({ 9 }) 200 ({ 10 }) features ({ 11 }) . ({ 12 }) 
# Sentence pair (1843) source length 14 target length 14 alignment score : 0.00342621
The classifier 's threshold is changed to meet the detection rate of \MATH . 
NULL ({ }) The ({ 1 }) classifier ({ 2 }) 's ({ 3 }) threshold ({ 4 }) was ({ 5 }) changed ({ 6 }) to ({ 7 }) meet ({ 8 }) the ({ 9 }) detection ({ 10 }) rate ({ 11 }) of ({ 12 }) \MATH ({ 13 }) . ({ 14 }) 
# Sentence pair (1844) source length 14 target length 14 alignment score : 0.00996061
The training set contains 7 ,500 face patterns and 7 ,500 non-face patterns . 
NULL ({ }) The ({ 1 }) training ({ 2 }) set ({ 3 }) contains ({ 4 }) 7 ({ 5 }) ,500 ({ 6 }) face ({ 7 }) patterns ({ 8 }) and ({ 9 }) 7 ({ 10 }) ,500 ({ 11 }) non-face ({ 12 }) patterns ({ 13 }) . ({ 14 }) 
# Sentence pair (1845) source length 21 target length 21 alignment score : 2.62715e-05
Rejection performance is evaluated through the false positive rate on a validation test set which contains 500 ,000 non-face patterns . 
NULL ({ }) Rejection ({ 1 }) performance ({ 2 }) was ({ 3 }) evaluated ({ 4 }) through ({ 5 }) the ({ 6 }) false ({ 7 }) positive ({ 8 }) rate ({ 9 }) on ({ 10 }) a ({ 11 }) validation ({ 12 }) test ({ 13 }) set ({ 14 }) that ({ 15 }) contains ({ 16 }) 500 ({ 17 }) ,000 ({ 18 }) non-face ({ 19 }) patterns ({ 20 }) . ({ 21 }) 
# Sentence pair (1846) source length 13 target length 13 alignment score : 0.00420027
All non-face patterns are selected randomly from the training set mentioned above . 
NULL ({ }) All ({ 1 }) non-face ({ 2 }) patterns ({ 3 }) were ({ 4 }) selected ({ 5 }) randomly ({ 6 }) from ({ 7 }) the ({ 8 }) training ({ 9 }) set ({ 10 }) mentioned ({ 11 }) above ({ 12 }) . ({ 13 }) 
# Sentence pair (1847) source length 35 target length 35 alignment score : 7.32146e-09
The result shown in Figure 10 indicates that the performances of these two classifiers are no different , especially when the number of features is large enough , for example , more than 50 . 
NULL ({ }) The ({ 1 }) results ({ 2 }) shown ({ 3 }) in ({ 4 }) Figure ({ 5 }) 10 ({ 6 }) indicate ({ 7 }) that ({ 8 }) the ({ 9 }) performances ({ 10 }) of ({ 11 }) these ({ 12 }) two ({ 13 }) classifiers ({ 14 }) were ({ 15 }) no ({ 16 }) different ({ 17 }) , ({ 18 }) especially ({ 19 }) when ({ 20 }) the ({ 21 }) number ({ 22 }) of ({ 23 }) features ({ 24 }) was ({ 25 }) large ({ 26 }) enough ({ 27 }) , ({ 28 }) for ({ 29 }) example ({ 30 }) , ({ 31 }) more ({ 32 }) than ({ 33 }) 50 ({ 34 }) . ({ 35 }) 
# Sentence pair (1848) source length 21 target length 22 alignment score : 1.99054e-10
As a result , by using the reduced feature set , the training time can be shortened approximately to one ninth . 
NULL ({ 19 }) As ({ 1 }) a ({ 2 }) result ({ 3 }) , ({ 4 }) by ({ 5 }) using ({ 6 }) the ({ 7 }) reduced ({ 8 }) feature ({ 9 }) set ({ 10 }) , ({ 11 }) the ({ 12 }) training ({ 13 }) time ({ 14 }) can ({ 15 }) be ({ 16 }) shortened ({ 17 }) to ({ }) approximately ({ 18 }) one-ninth ({ 20 21 }) . ({ 22 }) 
# Sentence pair (1849) source length 60 target length 38 alignment score : 2.64061e-40
Our another experiment has shown that , for similar performance , the AdaBoost classifier trained on the reduced feature set that uses larger sampling step sizes requires more features than that trained on the full feature set . 
NULL ({ 31 }) Another ({ }) experiment ({ 3 }) we ({ }) conducted ({ }) showed ({ 5 }) that ({ 6 }) , ({ 7 }) for ({ 8 }) similar ({ 9 }) performance ({ 10 }) , ({ 11 }) an ({ 12 }) AdaBoost ({ 13 }) classifier ({ 14 }) trained ({ 15 }) on ({ 16 }) the ({ 17 }) reduced ({ 18 }) feature ({ 19 }) set ({ 20 }) that ({ 21 }) uses ({ 22 }) larger ({ 23 }) sampling ({ 24 }) step ({ 25 }) sizes ({ 26 }) requires ({ 27 }) more ({ 28 }) features ({ 29 }) than ({ 30 }) one ({ }) trained ({ 32 }) on ({ 33 }) the ({ 34 }) full ({ 35 }) feature ({ 36 }) set ({ 37 }) . ({ 38 }) / ({ }) / ({ }) [Do ({ }) you ({ }) need ({ }) a ({ }) reference ({ }) here ({ }) , ({ }) or ({ }) is ({ }) this ({ }) still ({ }) talking ({ }) about ({ }) the ({ }) experiments ({ }) you ({ }) report ({ 4 }) in ({ }) this ({ }) paper?] ({ 1 2 }) 
# Sentence pair (1850) source length 16 target length 16 alignment score : 0.00202858
Therefore , only the sampling parameter \MATH was used in training the 24x24 AdaBoost classifiers . 
NULL ({ }) Therefore ({ 1 }) , ({ 2 }) only ({ 3 }) the ({ 4 }) sampling ({ 5 }) parameter ({ 6 }) \MATH ({ 7 }) was ({ 8 }) used ({ 9 }) in ({ 10 }) training ({ 11 }) the ({ 12 }) 24x24 ({ 13 }) AdaBoost ({ 14 }) classifiers ({ 15 }) . ({ 16 }) 
# Sentence pair (1851) source length 25 target length 25 alignment score : 0.000104654
In our system , the first stage is a cascade of classifiers that processes 36x36 patterns with a moving step size of 12 pixels . 
NULL ({ }) In ({ 1 }) our ({ 2 }) system ({ 3 }) , ({ 4 }) the ({ 5 }) first ({ 6 }) stage ({ 7 }) is ({ 8 }) a ({ 9 }) cascade ({ 10 }) of ({ 11 }) classifiers ({ 12 }) that ({ 13 }) processes ({ 14 }) 36x36 ({ 15 }) patterns ({ 16 }) with ({ 17 }) a ({ 18 }) moving ({ 19 }) step ({ 20 }) size ({ 21 }) of ({ 22 }) 12 ({ 23 }) pixels ({ 24 }) . ({ 25 }) 
# Sentence pair (1852) source length 37 target length 35 alignment score : 1.5658e-08
By taking advantage of simplification in training classifiers only for rejection demonstrated in section 6 .2 , training this cascade only uses the feature set generated from a 36x36 window with sampling parameters \MATH . 
NULL ({ }) By ({ 1 }) taking ({ 2 }) advantage ({ 3 }) of ({ 4 }) simplification ({ 5 }) in ({ 6 }) training ({ 7 }) classifiers ({ 8 }) only ({ 9 }) for ({ 10 }) rejection ({ 11 }) , ({ }) as ({ }) demonstrated ({ 12 }) in ({ 13 }) section ({ 14 }) 6 ({ 15 }) .2 ({ 16 }) , ({ 17 }) training ({ 18 }) this ({ 19 }) cascade ({ 20 }) only ({ 21 }) uses ({ 22 }) the ({ 23 }) feature ({ 24 }) set ({ 25 }) generated ({ 26 }) from ({ 27 }) a ({ 28 }) 36x36 ({ 29 }) window ({ 30 }) with ({ 31 }) sampling ({ 32 }) parameters ({ 33 }) \MATH ({ 34 }) . ({ 35 }) 
# Sentence pair (1853) source length 10 target length 10 alignment score : 0.0197184
As a result , 12 ,223 features are produced . 
NULL ({ }) As ({ 1 }) a ({ 2 }) result ({ 3 }) , ({ 4 }) 12 ({ 5 }) ,223 ({ 6 }) features ({ 7 }) are ({ 8 }) produced ({ 9 }) . ({ 10 }) 
# Sentence pair (1854) source length 14 target length 14 alignment score : 0.0111608
The training set contains 12 ,000 face patterns and 12 ,000 non-face patterns . 
NULL ({ }) The ({ 1 }) training ({ 2 }) set ({ 3 }) contains ({ 4 }) 12 ({ 5 }) ,000 ({ 6 }) face ({ 7 }) patterns ({ 8 }) and ({ 9 }) 12 ({ 10 }) ,000 ({ 11 }) non-face ({ 12 }) patterns ({ 13 }) . ({ 14 }) 
# Sentence pair (1855) source length 54 target length 53 alignment score : 3.85083e-28
Since a 36x36 face sample contains a lot of background outside the 24x24 face region while the classifier is required to be fast and to keep all possible face regions , training parameters are set as follows : the minimum detection rate of \MATH and maximum of false positive rate of \MATH . 
NULL ({ 37 38 39 }) Since ({ 1 }) a ({ 2 }) 36x36 ({ 3 }) face ({ 4 }) sample ({ 5 }) contains ({ 6 }) a ({ 7 }) large ({ }) proportion ({ 8 }) of ({ 9 }) background ({ 10 }) outside ({ 11 }) the ({ 12 }) 24x24 ({ 13 }) face ({ 14 }) region ({ 15 }) and ({ 16 }) the ({ 17 }) classifier ({ 18 }) is ({ 19 }) required ({ 20 }) to ({ 21 }) be ({ 22 }) fast ({ 23 }) and ({ 24 }) to ({ 25 }) keep ({ 26 }) all ({ 27 }) possible ({ 28 }) face ({ 29 }) regions ({ 30 }) , ({ 31 }) a ({ }) minimum ({ 40 }) detection ({ 41 }) rate ({ 42 }) of ({ 43 }) \MATH ({ 44 }) and ({ 45 }) a ({ }) maximum ({ 46 }) of ({ 47 }) false ({ 48 }) positive ({ 49 }) rate ({ 50 }) of ({ 51 }) \MATH ({ 52 }) were ({ 34 }) set ({ 35 }) as ({ 36 }) the ({ }) training ({ 32 }) parameters ({ 33 }) . ({ 53 }) 
# Sentence pair (1856) source length 32 target length 33 alignment score : 2.02615e-09
In our experiments , after reaching 50 features , the classifier 's performance does not significantly increase anymore , so the maximum number of features for each layer is set to 50 . 
NULL ({ }) In ({ 1 }) our ({ 2 }) experiments ({ 3 }) , ({ 4 }) after ({ 5 }) reaching ({ 6 }) 50 ({ 7 }) features ({ 8 }) , ({ 9 }) the ({ 10 }) classifier ({ 11 }) 's ({ 12 }) performance ({ 13 }) did ({ 14 }) not ({ 15 }) significantly ({ 16 }) increase ({ 17 18 }) , ({ 19 }) so ({ 20 }) the ({ 21 }) maximum ({ 22 }) number ({ 23 }) of ({ 24 }) features ({ 25 }) for ({ 26 }) each ({ 27 }) layer ({ 28 }) is ({ 29 }) set ({ 30 }) to ({ 31 }) 50 ({ 32 }) . ({ 33 }) 
# Sentence pair (1857) source length 31 target length 31 alignment score : 1.6799e-06
To keep a balance between computation speed and robustness , the maximum number of layers is set to three because using more layers would degrade the overall detection rate dramatically . 
NULL ({ }) To ({ 1 }) keep ({ 2 }) a ({ 3 }) balance ({ 4 }) between ({ 5 }) computation ({ 6 }) speed ({ 7 }) and ({ 8 }) robustness ({ 9 }) , ({ 10 }) the ({ 11 }) maximum ({ 12 }) number ({ 13 }) of ({ 14 }) layers ({ 15 }) is ({ 16 }) set ({ 17 }) to ({ 18 }) three ({ 19 }) because ({ 20 }) using ({ 21 }) more ({ 22 }) layers ({ 23 }) would ({ 24 }) degrade ({ 25 }) the ({ 26 }) overall ({ 27 }) detection ({ 28 }) rate ({ 29 }) dramatically ({ 30 }) . ({ 31 }) 
# Sentence pair (1858) source length 17 target length 17 alignment score : 0.00336555
Figure 11( a ) shows several features of the first 36x36 layer classifier selected by AdaBoost . 
NULL ({ }) Figure ({ 1 }) 11( ({ 2 }) a ({ 3 }) ) ({ 4 }) shows ({ 5 }) several ({ 6 }) features ({ 7 }) of ({ 8 }) the ({ 9 }) first ({ 10 }) 36x36 ({ 11 }) layer ({ 12 }) classifier ({ 13 }) selected ({ 14 }) by ({ 15 }) AdaBoost ({ 16 }) . ({ 17 }) 
# Sentence pair (1859) source length 31 target length 20 alignment score : 2.73584e-16
It is somehow similar to features of the first 24x24 layer classifier as shown in Figure 11( b ) . 
NULL ({ }) They ({ 1 }) are ({ }) somehow ({ 3 }) similar ({ 4 }) to ({ 5 }) the ({ }) features ({ 6 }) of ({ 7 }) the ({ 8 }) first ({ 9 }) 24x24 ({ 10 }) layer ({ 11 }) classifier ({ 12 }) as ({ 13 }) shown ({ 14 }) in ({ 15 }) Figure ({ 16 }) 11( ({ 17 }) b ({ 18 }) ) ({ 19 }) . ({ 20 }) / ({ }) / ({ }) [somehow?This ({ 2 }) sounds ({ }) vague ({ }) . ({ }) How ({ }) are ({ }) they ({ }) similar?] ({ }) 
# Sentence pair (1860) source length 18 target length 18 alignment score : 0.00104075
In addition , Figure 12 shows an example of face candidate regions estimated by using this cascade . 
NULL ({ }) In ({ 1 }) addition ({ 2 }) , ({ 3 }) Figure ({ 4 }) 12 ({ 5 }) shows ({ 6 }) an ({ 7 }) example ({ 8 }) of ({ 9 }) face ({ 10 }) candidate ({ 11 }) regions ({ 12 }) estimated ({ 13 }) by ({ 14 }) using ({ 15 }) this ({ 16 }) cascade ({ 17 }) . ({ 18 }) 
# Sentence pair (1861) source length 35 target length 38 alignment score : 2.54115e-25
Two main issues surrounding the reuse of features selected by AdaBoost are : ( i ) which layer whose features will be reused for SVM is the best? and ( ii ) How many features should be used? 
NULL ({ 26 27 }) Two ({ 1 }) main ({ 2 }) issues ({ 3 }) surrounding ({ 4 }) the ({ 5 }) reuse ({ 6 28 }) of ({ 7 }) features ({ 8 }) selected ({ 9 }) by ({ 10 }) AdaBoost ({ 11 }) are ({ 12 }) : ({ 13 }) ( ({ 14 }) i ({ 15 }) ) ({ 16 }) which ({ 17 }) layerfs ({ 18 19 }) features ({ 20 }) should ({ 21 }) be ({ 22 }) reused ({ 23 }) for ({ 24 }) SVM ({ 25 }) and ({ 29 }) ( ({ 30 }) ii ({ 31 }) ) ({ 32 }) how ({ 33 }) many ({ 34 }) features ({ 35 }) should ({ 36 }) be ({ 37 }) used ({ 38 }) . ({ }) 
# Sentence pair (1862) source length 33 target length 33 alignment score : 1.27252e-07
For comparison of the performance of SVM classifiers , 2 ,450 face patterns and 7 ,500 non-face patterns which are separated from the training set ( section 6 .1 ) were used . 
NULL ({ }) For ({ 1 }) comparison ({ 2 }) of ({ 3 }) the ({ 4 }) performance ({ 5 }) of ({ 6 }) SVM ({ 7 }) classifiers ({ 8 }) , ({ 9 }) 2 ({ 10 }) ,450 ({ 11 }) face ({ 12 }) patterns ({ 13 }) and ({ 14 }) 7 ({ 15 }) ,500 ({ 16 }) non-face ({ 17 }) patterns ({ 18 }) that ({ 19 }) were ({ 20 }) separated ({ 21 }) from ({ 22 }) the ({ 23 }) training ({ 24 }) set ({ 25 }) ( ({ 26 }) section ({ 27 }) 6 ({ 28 }) .1 ({ 29 }) ) ({ 30 }) were ({ 31 }) used ({ 32 }) . ({ 33 }) 
# Sentence pair (1863) source length 15 target length 15 alignment score : 0.00391142
The SVM classifiers were trained with a RBF kernel whose parameter \MATH is \MATH . 
NULL ({ }) The ({ 1 }) SVM ({ 2 }) classifiers ({ 3 }) were ({ 4 }) trained ({ 5 }) with ({ 6 }) a ({ 7 }) RBF ({ 8 }) kernel ({ 9 }) whose ({ 10 }) parameter ({ 11 }) \MATH ({ 12 }) is ({ 13 }) \MATH ({ 14 }) . ({ 15 }) 
# Sentence pair (1864) source length 8 target length 8 alignment score : 0.0378617
The parameter \MATH is set to \MATH . 
NULL ({ }) The ({ 1 }) parameter ({ 2 }) \MATH ({ 3 }) was ({ 4 }) set ({ 5 }) to ({ 6 }) \MATH ({ 7 }) . ({ 8 }) 
# Sentence pair (1865) source length 10 target length 9 alignment score : 0.00420894
These parameters were found by using cross-validation test . 
NULL ({ }) These ({ 1 }) parameters ({ 2 }) were ({ 3 }) found ({ 4 }) by ({ 5 }) using ({ 6 }) a ({ }) cross-validation ({ 7 }) test ({ 8 }) . ({ 9 }) 
# Sentence pair (1866) source length 30 target length 30 alignment score : 1.40377e-05
Figure 13 compares the performance of classifiers trained on 200-feature sets selected by different layers in the cascade ( layers 14 , 17 , 20 , and 25 ) . 
NULL ({ }) Figure ({ 1 }) 13 ({ 2 }) compares ({ 3 }) the ({ 4 }) performance ({ 5 }) of ({ 6 }) classifiers ({ 7 }) trained ({ 8 }) on ({ 9 }) 200-feature ({ 10 }) sets ({ 11 }) selected ({ 12 }) by ({ 13 }) different ({ 14 }) layers ({ 15 }) in ({ 16 }) the ({ 17 }) cascade ({ 18 }) ( ({ 19 }) layers ({ 20 }) 14 ({ 21 }) , ({ 22 }) 17 ({ 23 }) , ({ 24 }) 20 ({ 25 }) , ({ 26 }) and ({ 27 }) 25 ({ 28 }) ) ({ 29 }) . ({ 30 }) 
# Sentence pair (1867) source length 27 target length 27 alignment score : 4.63945e-05
These comparable performances suggest that the second stage ( using AdaBoost ) can be switched to the final stage ( using SVM ) at any time . 
NULL ({ }) These ({ 1 }) comparable ({ 2 }) performances ({ 3 }) suggest ({ 4 }) that ({ 5 }) the ({ 6 }) second ({ 7 }) stage ({ 8 }) ( ({ 9 }) using ({ 10 }) AdaBoost ({ 11 }) ) ({ 12 }) can ({ 13 }) be ({ 14 }) switched ({ 15 }) to ({ 16 }) the ({ 17 }) final ({ 18 }) stage ({ 19 }) ( ({ 20 }) using ({ 21 }) SVM ({ 22 }) ) ({ 23 }) at ({ 24 }) any ({ 25 }) time ({ 26 }) . ({ 27 }) 
# Sentence pair (1868) source length 16 target length 15 alignment score : 2.41955e-07
As a result , total training time of the system can be easily controlled . 
NULL ({ }) As ({ 1 }) a ({ 2 }) result ({ 3 }) , ({ 4 }) the ({ }) total ({ 5 }) training ({ 6 }) time ({ 7 }) of ({ 8 }) the ({ 9 }) system ({ 10 }) can ({ 11 }) easily ({ 13 }) be ({ 12 }) controlled ({ 14 }) . ({ 15 }) 
# Sentence pair (1869) source length 34 target length 30 alignment score : 1.05222e-24
To determine how many features is robust enough , we used the 200-feature set selected in layer 17 to generate different subsets of features with different number of features . 
NULL ({ 12 }) To ({ 1 }) determine ({ 2 }) the ({ }) number ({ }) of ({ }) features ({ 5 }) is ({ 6 }) that ({ }) would ({ }) be ({ }) sufficiently ({ 8 }) robust ({ 7 }) , ({ 9 }) we ({ 10 }) used ({ 11 }) the ({ }) 200-feature ({ 3 4 13 }) set ({ 14 }) selected ({ 15 }) in ({ 16 }) layer ({ 17 }) 17 ({ 18 }) to ({ 19 }) generate ({ 20 }) different ({ 21 }) subsets ({ 22 }) of ({ 23 }) features ({ 24 }) with ({ 25 }) different ({ 26 }) numbers ({ 27 }) of ({ 28 }) features ({ 29 }) . ({ 30 }) 
# Sentence pair (1870) source length 19 target length 18 alignment score : 2.94676e-06
Features in each set were selected in the order that they were added in the training process . 
NULL ({ }) Features ({ 1 }) in ({ 2 }) each ({ 3 }) set ({ 4 }) were ({ 5 }) selected ({ 6 }) in ({ 7 }) the ({ 8 }) order ({ 9 }) in ({ }) which ({ 10 }) they ({ 11 }) were ({ 12 }) added ({ 13 }) in ({ 14 }) the ({ 15 }) training ({ 16 }) process ({ 17 }) . ({ 18 }) 
# Sentence pair (1871) source length 20 target length 19 alignment score : 0.000355183
For example , a 25-feature set consists of first 25 features selected by AdaBoost when training layer 17 . 
NULL ({ }) For ({ 1 }) example ({ 2 }) , ({ 3 }) a ({ 4 }) 25-feature ({ 5 }) set ({ 6 }) consists ({ 7 }) of ({ 8 }) the ({ }) first ({ 9 }) 25 ({ 10 }) features ({ 11 }) selected ({ 12 }) by ({ 13 }) AdaBoost ({ 14 }) when ({ 15 }) training ({ 16 }) layer ({ 17 }) 17 ({ 18 }) . ({ 19 }) 
# Sentence pair (1872) source length 26 target length 21 alignment score : 9.4684e-09
The results shown in Figure 14 indicate that with more than 100 features , the performance of classifiers is comparable . 
NULL ({ }) The ({ 1 }) results ({ 2 }) shown ({ 3 }) in ({ 4 }) Figure ({ 5 }) 14 ({ 6 }) indicate ({ 7 }) that ({ 8 }) with ({ 9 }) more ({ 10 }) than ({ 11 }) 100 ({ 12 }) features ({ 13 }) , ({ 14 }) the ({ 15 }) performance ({ 16 }) of ({ 17 }) the ({ }) classifiers ({ 18 }) was ({ 19 }) comparable ({ 20 }) . ({ 21 }) / ({ }) / ({ }) [to ({ }) what?] ({ }) 
# Sentence pair (1873) source length 33 target length 32 alignment score : 2.31664e-07
Basically , the speed of a SVM classifier is proportional to the number of features used , so the greater number of features used , the slower the classifier will be . 
NULL ({ }) Basically ({ 1 }) , ({ 2 }) the ({ 3 }) speed ({ 4 }) of ({ 5 }) a ({ 6 }) SVM ({ 7 }) classifier ({ 8 }) is ({ 9 }) proportional ({ 10 }) to ({ 11 }) the ({ 12 }) number ({ 13 }) of ({ 14 }) features ({ 15 }) used ({ 16 }) , ({ 17 }) so ({ 18 }) the ({ 19 }) greater ({ 20 }) the ({ }) number ({ 21 }) of ({ 22 }) features ({ 23 }) used ({ 24 }) , ({ 25 }) the ({ 26 }) slower ({ 27 }) the ({ 28 }) classifier ({ 29 }) will ({ 30 }) be ({ 31 }) . ({ 32 }) 
# Sentence pair (1874) source length 15 target length 16 alignment score : 1.40537e-07
Figure 15 shows the processing speed of SVM classifiers that uses different subsets of features . 
NULL ({ 10 }) Figure ({ 1 }) 15 ({ 2 }) shows ({ 3 }) the ({ 4 }) processing ({ 5 }) speed ({ 6 }) of ({ 7 }) SVM ({ 8 }) classifiers ({ 9 }) using ({ 11 }) different ({ 12 }) subsets ({ 13 }) of ({ 14 }) features ({ 15 }) . ({ 16 }) 
# Sentence pair (1875) source length 21 target length 18 alignment score : 8.3981e-10
The SVM classifier using 25 features run fastest while the SVM classifier using 200 features run slowest . 
NULL ({ }) The ({ 1 }) SVM ({ 2 }) classifier ({ 3 }) using ({ 4 }) 25 ({ 5 }) features ({ 6 }) ran ({ 7 }) the ({ }) fastest ({ 8 }) , ({ }) while ({ 9 }) the ({ 10 }) SVM ({ 11 }) classifier ({ 12 }) using ({ 13 }) 200 ({ 14 }) features ({ 15 }) was ({ }) the ({ }) slowest ({ 16 17 }) . ({ 18 }) 
# Sentence pair (1876) source length 41 target length 33 alignment score : 3.03508e-17
The speeds of SVM classifiers using 100 , 125 and 175 features are not importantly different because their difference in terms of number of features and number of support vectors is inconsiderable . 
NULL ({ }) The ({ 1 }) speeds ({ 2 }) of ({ 3 }) SVM ({ 4 }) classifiers ({ 5 }) using ({ 6 }) 100 ({ 7 }) , ({ 8 }) 125 ({ 9 }) , ({ }) and ({ 10 }) 175 ({ 11 }) features ({ 12 }) were ({ 13 }) not ({ 14 }) importantly ({ 15 }) different ({ 16 }) because ({ 17 }) their ({ 18 }) difference ({ 19 }) in ({ 20 }) terms ({ 21 }) of ({ 22 }) number ({ 23 }) of ({ 24 }) features ({ 25 }) and ({ 26 }) number ({ 27 }) of ({ 28 }) support ({ 29 }) vectors ({ 30 }) were ({ }) not ({ }) large ({ }) enough ({ }) to ({ }) have ({ }) a ({ }) significant ({ 31 }) impact ({ 32 }) . ({ 33 }) 
# Sentence pair (1877) source length 14 target length 16 alignment score : 1.50481e-07
Therefore , 100 features might be the best trade-off between the speed and the performance . 
NULL ({ 11 14 }) Therefore ({ 1 }) , ({ 2 }) 100 ({ 3 }) features ({ 4 }) might ({ 5 }) be ({ 6 }) the ({ 7 }) best ({ 8 }) trade-off ({ 9 }) between ({ 10 }) speed ({ 12 }) and ({ 13 }) performance ({ 15 }) . ({ 16 }) 
# Sentence pair (1878) source length 21 target length 20 alignment score : 7.38213e-05
We carried out an experiment to show efficiency of a single SVM classifier over a cascade of AdaBoost classifiers . 
NULL ({ }) We ({ 1 }) carried ({ 2 }) out ({ 3 }) an ({ 4 }) experiment ({ 5 }) to ({ 6 }) show ({ 7 }) the ({ }) efficiency ({ 8 }) of ({ 9 }) a ({ 10 }) single ({ 11 }) SVM ({ 12 }) classifier ({ 13 }) over ({ 14 }) a ({ 15 }) cascade ({ 16 }) of ({ 17 }) AdaBoost ({ 18 }) classifiers ({ 19 }) . ({ 20 }) 
# Sentence pair (1879) source length 33 target length 33 alignment score : 9.755e-06
In this experiment , 40 ,000 false positives were gathered by running a cascade of 17 AdaBoost classifiers ( CAB17 ) on the set of non-face images mentioned in section 6 .1 . 
NULL ({ }) In ({ 1 }) this ({ 2 }) experiment ({ 3 }) , ({ 4 }) 40 ({ 5 }) ,000 ({ 6 }) false ({ 7 }) positives ({ 8 }) were ({ 9 }) gathered ({ 10 }) by ({ 11 }) running ({ 12 }) a ({ 13 }) cascade ({ 14 }) of ({ 15 }) 17 ({ 16 }) AdaBoost ({ 17 }) classifiers ({ 18 }) ( ({ 19 }) CAB17 ({ 20 }) ) ({ 21 }) on ({ 22 }) the ({ 23 }) set ({ 24 }) of ({ 25 }) non-face ({ 26 }) images ({ 27 }) mentioned ({ 28 }) in ({ 29 }) section ({ 30 }) 6 ({ 31 }) .1 ({ 32 }) . ({ 33 }) 
# Sentence pair (1880) source length 34 target length 34 alignment score : 2.79639e-06
These false positives then were used as hard non-face patterns to train and test the performance of two classifiers : a single RBF SVM classifier and a cascade of other 18 AdaBoost classifiers . 
NULL ({ }) These ({ 1 }) false ({ 2 }) positives ({ 3 }) then ({ 4 }) were ({ 5 }) used ({ 6 }) as ({ 7 }) hard ({ 8 }) non-face ({ 9 }) patterns ({ 10 }) to ({ 11 }) train ({ 12 }) and ({ 13 }) test ({ 14 }) the ({ 15 }) performance ({ 16 }) of ({ 17 }) two ({ 18 }) classifiers ({ 19 }) : ({ 20 }) a ({ 21 }) single ({ 22 }) RBF ({ 23 }) SVM ({ 24 }) classifier ({ 25 }) and ({ 26 }) a ({ 27 }) cascade ({ 28 }) of ({ 29 }) other ({ 30 }) 18 ({ 31 }) AdaBoost ({ 32 }) classifiers ({ 33 }) . ({ 34 }) 
# Sentence pair (1881) source length 24 target length 24 alignment score : 0.00017873
Of 40 ,000 non-face patterns , 7 ,500 non-face patterns were used along with 7 ,500 face patterns to train these two classifiers . 
NULL ({ }) Of ({ 1 }) 40 ({ 2 }) ,000 ({ 3 }) non-face ({ 4 }) patterns ({ 5 }) , ({ 6 }) 7 ({ 7 }) ,500 ({ 8 }) non-face ({ 9 }) patterns ({ 10 }) were ({ 11 }) used ({ 12 }) along ({ 13 }) with ({ 14 }) 7 ({ 15 }) ,500 ({ 16 }) face ({ 17 }) patterns ({ 18 }) to ({ 19 }) train ({ 20 }) these ({ 21 }) two ({ 22 }) classifiers ({ 23 }) . ({ 24 }) 
# Sentence pair (1882) source length 22 target length 19 alignment score : 8.41144e-08
The remaining 34 ,000 non-face patterns and other 2 ,450 face patterns were used to compare the accuracy . 
NULL ({ }) The ({ 1 }) remaining ({ 2 }) 34 ({ 3 }) ,000 ({ 4 }) non-face ({ 5 }) patterns ({ 6 }) and ({ 7 }) other ({ 8 }) 2 ({ 9 }) ,450 ({ 10 }) face ({ 11 }) patterns ({ 12 }) were ({ 13 }) used ({ 14 }) to ({ 15 }) compare ({ 16 }) the ({ 17 }) accuracy ({ 18 }) of ({ }) the ({ }) classifiers ({ }) . ({ 19 }) 
# Sentence pair (1883) source length 17 target length 17 alignment score : 0.00213324
The cascade of AdaBoost classifiers were trained with the parameters set as in section 6 .1 . 
NULL ({ }) The ({ 1 }) cascade ({ 2 }) of ({ 3 }) AdaBoost ({ 4 }) classifiers ({ 5 }) were ({ 6 }) trained ({ 7 }) with ({ 8 }) the ({ 9 }) parameters ({ 10 }) set ({ 11 }) as ({ 12 }) in ({ 13 }) section ({ 14 }) 6 ({ 15 }) .1 ({ 16 }) . ({ 17 }) 
# Sentence pair (1884) source length 31 target length 31 alignment score : 1.33048e-07
The RBF SVM classifier reused 100 features selected by the last layer of CAB17 as the feature vector and was trained by a RBF kernel whose parameter \MATH is \MATH . 
NULL ({ }) The ({ 1 }) RBF ({ 2 }) SVM ({ 3 }) classifier ({ 4 }) reused ({ 5 }) 100 ({ 6 }) features ({ 7 }) selected ({ 8 }) by ({ 9 }) the ({ 10 }) last ({ 11 }) layer ({ 12 }) of ({ 13 }) CAB17 ({ 14 }) as ({ 15 }) the ({ 16 }) feature ({ 17 }) vector ({ 18 }) and ({ 19 }) was ({ 20 }) trained ({ 21 }) by ({ 22 }) an ({ 23 }) RBF ({ 24 }) kernel ({ 25 }) whose ({ 26 }) parameter ({ 27 }) \MATH ({ 28 }) is ({ 29 }) \MATH ({ 30 }) . ({ 31 }) 
# Sentence pair (1885) source length 8 target length 8 alignment score : 0.0378617
The parameter \MATH is set to \MATH . 
NULL ({ }) The ({ 1 }) parameter ({ 2 }) \MATH ({ 3 }) was ({ 4 }) set ({ 5 }) to ({ 6 }) \MATH ({ 7 }) . ({ 8 }) 
# Sentence pair (1886) source length 10 target length 9 alignment score : 0.00266614
These parameters are found by using cross-validation test . 
NULL ({ }) These ({ 1 }) parameters ({ 2 }) were ({ 3 }) found ({ 4 }) by ({ 5 }) using ({ 6 }) a ({ }) cross-validation ({ 7 }) test ({ 8 }) . ({ 9 }) 
# Sentence pair (1887) source length 100 target length 42 alignment score : 8.15437e-67
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters . 
NULL ({ }) The ({ 1 }) result ({ 2 }) shown ({ 3 }) in ({ 4 }) Figure ({ 5 }) 16 ({ 6 }) demonstrates ({ 7 }) that ({ 8 }) with ({ 9 }) hard ({ 10 }) classified ({ 11 }) patterns ({ 12 }) that ({ 13 }) later ({ 14 }) layers ({ 15 }) of ({ 16 }) the ({ 17 }) cascade ({ 18 }) will ({ 19 }) process ({ 20 }) , ({ 21 }) the ({ 22 }) single ({ 23 }) SVM ({ 24 }) classifier ({ 25 }) can ({ 26 }) achieve ({ 27 }) higher ({ 28 }) accuracy ({ 29 }) than ({ 30 }) the ({ 31 }) cascade ({ 32 }) of ({ 33 }) AdaBoost ({ 34 }) classifiers ({ 35 }) trained ({ 36 }) by ({ 37 }) roughly ({ 38 }) predefined ({ 39 }) training ({ 40 }) parameters ({ 41 }) . ({ }) / ({ }) / ({ }) ?NOTE ({ }) : ({ }) I ({ }) believe ({ }) that ({ }) I ({ }) hyphenated ({ }) this ({ }) term ({ }) in ({ }) your ({ }) previous ({ }) document ({ }) , ({ }) but ({ }) after ({ }) seeing ({ }) it ({ }) used ({ }) here ({ }) , ({ }) I ({ }) would ({ }) say ({ }) that ({ }) it ({ }) does ({ }) not ({ }) need ({ }) to ({ }) be ({ }) hyphenated. ({ 42 }) My ({ }) apologies ({ }) for ({ }) any ({ }) confusion ({ }) . ({ }) A ({ }) better ({ }) way ({ }) to ({ }) express ({ }) this ({ }) , ({ }) however ({ }) , ({ }) might ({ }) be ({ }) " ({ }) patterns ({ }) that ({ }) have ({ }) been ({ }) classified ({ }) as ({ }) 
# Sentence pair (1888) source length 34 target length 34 alignment score : 2.11953e-08
Furthermore , the training time of a single SVM ( which takes several hours ) is much smaller than that of a cascade of AdaBoost classifiers ( which might take everal weeks ) . 
NULL ({ }) Furthermore ({ 1 }) , ({ 2 }) the ({ 3 }) training ({ 4 }) time ({ 5 }) of ({ 6 }) a ({ 7 }) single ({ 8 }) SVM ({ 9 }) ( ({ 10 }) which ({ 11 }) takes ({ 12 }) several ({ 13 }) hours ({ 14 }) ) ({ 15 }) is ({ 16 }) much ({ 17 }) shorter ({ 18 }) than ({ 19 }) that ({ 20 }) of ({ 21 }) a ({ 22 }) cascade ({ 23 }) of ({ 24 }) AdaBoost ({ 25 }) classifiers ({ 26 }) ( ({ 27 }) which ({ 28 }) might ({ 29 }) take ({ 30 }) several ({ 31 }) weeks ({ 32 }) ) ({ 33 }) . ({ 34 }) 
# Sentence pair (1889) source length 8 target length 8 alignment score : 0.0758322
The final system consists of three stages . 
NULL ({ }) The ({ 1 }) final ({ 2 }) system ({ 3 }) consists ({ 4 }) of ({ 5 }) three ({ 6 }) stages ({ 7 }) . ({ 8 }) 
# Sentence pair (1890) source length 22 target length 24 alignment score : 1.60295e-17
In the first stage , the cascaded 36x36 classifiers consist of three layers , making a total number of features used of 120 . 
NULL ({ 19 22 }) In ({ 1 }) the ({ 2 }) first ({ 3 }) stage ({ 4 }) , ({ 5 }) the ({ 6 }) cascaded ({ 7 }) 36x36 ({ 8 }) classifiers ({ 9 }) consist ({ 10 }) of ({ 11 }) three ({ 12 }) layers ({ 13 }) , ({ 14 }) making ({ 15 }) for ({ }) a ({ 16 }) total ({ 17 }) of ({ }) 120 ({ 18 21 23 }) features ({ 20 }) . ({ 24 }) 
# Sentence pair (1891) source length 12 target length 12 alignment score : 0.0207068
The second stage consists of 17 layers with 2 ,160 features . 
NULL ({ }) The ({ 1 }) second ({ 2 }) stage ({ 3 }) consists ({ 4 }) of ({ 5 }) 17 ({ 6 }) layers ({ 7 }) with ({ 8 }) 2 ({ 9 }) ,160 ({ 10 }) features ({ 11 }) . ({ 12 }) 
# Sentence pair (1892) source length 70 target length 36 alignment score : 5.46531e-54
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and , thus , can save significant training time ( which is approximate 27 times in total ) . 
NULL ({ 21 }) Compared ({ 1 }) to ({ 2 }) the ({ 3 }) system ({ 4 }) with ({ 5 }) 6 ({ 6 }) ,061 ({ 7 }) features ({ 8 }) used ({ 9 }) in ({ 10 }) [1] ({ 11 }) , ({ 12 }) our ({ 13 }) system ({ 14 }) uses ({ 15 }) fewer ({ 16 }) features ({ 17 }) and ({ 18 }) can ({ 22 }) thus ({ 20 }) save ({ 23 }) significant ({ 24 }) training ({ }) time ({ 26 }) ; ({ }) the ({ }) training ({ 25 }) time ({ }) needed ({ }) using ({ }) the ({ }) new ({ }) system ({ }) is ({ }) approximately ({ 30 }) 27 ({ 31 }) times ({ 32 }) shorter ({ }) / ({ }) approximately ({ }) 27 ({ }) rounds ({ }) of ({ }) training ({ }) are ({ }) needed ({ }) in ({ 33 }) the ({ }) new ({ }) system ({ }) . ({ }) / ({ }) / ({ }) <--I ({ }) think ({ }) that ({ }) the ({ }) first ({ }) choice ({ }) here ({ }) is ({ 29 }) your ({ 27 }) intended ({ 28 }) meaning ({ }) , ({ 19 }) but ({ }) please ({ 34 }) check ({ }) carefully ({ 35 }) . ({ 36 }) 
# Sentence pair (1893) source length 27 target length 27 alignment score : 3.63144e-06
The final stage is a cascade of three SVM classifiers that take 100 features of the last layer in the second stage as the feature vector . 
NULL ({ }) The ({ 1 }) final ({ 2 }) stage ({ 3 }) is ({ 4 }) a ({ 5 }) cascade ({ 6 }) of ({ 7 }) three ({ 8 }) SVM ({ 9 }) classifiers ({ 10 }) that ({ 11 }) take ({ 12 }) 100 ({ 13 }) features ({ 14 }) of ({ 15 }) the ({ 16 }) last ({ 17 }) layer ({ 18 }) in ({ 19 }) the ({ 20 }) second ({ 21 }) stage ({ 22 }) as ({ 23 }) the ({ 24 }) feature ({ 25 }) vectors ({ 26 }) . ({ 27 }) 
# Sentence pair (1894) source length 17 target length 17 alignment score : 0.00163923
Each SVM classifier was trained by using 7 ,500 face patterns and 7 ,500 non-face patterns . 
NULL ({ }) Each ({ 1 }) SVM ({ 2 }) classifier ({ 3 }) was ({ 4 }) trained ({ 5 }) by ({ 6 }) using ({ 7 }) 7 ({ 8 }) ,500 ({ 9 }) face ({ 10 }) patterns ({ 11 }) and ({ 12 }) 7 ({ 13 }) ,500 ({ 14 }) non-face ({ 15 }) patterns ({ 16 }) . ({ 17 }) 
# Sentence pair (1895) source length 15 target length 15 alignment score : 0.00342272
The same 7 ,500 face patterns were used in training all these SVM classifiers . 
NULL ({ }) The ({ 1 }) same ({ 2 }) 7 ({ 3 }) ,500 ({ 4 }) face ({ 5 }) patterns ({ 6 }) were ({ 7 }) used ({ 8 }) in ({ 9 }) training ({ 10 }) all ({ 11 }) these ({ 12 }) SVM ({ 13 }) classifiers ({ 14 }) . ({ 15 }) 
# Sentence pair (1896) source length 35 target length 35 alignment score : 3.3953e-06
By running the cascade of AdaBoost classifiers of the second stage on the set of non-face images , 40 ,000 false positives were collected and used as non-face patterns to train the SVM classifiers . 
NULL ({ }) By ({ 1 }) running ({ 2 }) the ({ 3 }) cascade ({ 4 }) of ({ 5 }) AdaBoost ({ 6 }) classifiers ({ 7 }) of ({ 8 }) the ({ 9 }) second ({ 10 }) stage ({ 11 }) on ({ 12 }) the ({ 13 }) set ({ 14 }) of ({ 15 }) non-face ({ 16 }) images ({ 17 }) , ({ 18 }) 40 ({ 19 }) ,000 ({ 20 }) false ({ 21 }) positives ({ 22 }) were ({ 23 }) collected ({ 24 }) and ({ 25 }) used ({ 26 }) as ({ 27 }) non-face ({ 28 }) patterns ({ 29 }) to ({ 30 }) train ({ 31 }) the ({ 32 }) SVM ({ 33 }) classifiers ({ 34 }) . ({ 35 }) 
# Sentence pair (1897) source length 22 target length 21 alignment score : 4.76753e-05
7 ,500 non-face patterns used to train the first SVM classifier were selected randomly from the 40 ,000 non-face patterns . 
NULL ({ }) The ({ }) 7 ({ 1 }) ,500 ({ 2 }) non-face ({ 3 }) patterns ({ 4 }) used ({ 5 }) to ({ 6 }) train ({ 7 }) the ({ 8 }) first ({ 9 }) SVM ({ 10 }) classifier ({ 11 }) were ({ 12 }) selected ({ 13 }) randomly ({ 14 }) from ({ 15 }) the ({ 16 }) 40 ({ 17 }) ,000 ({ 18 }) non-face ({ 19 }) patterns ({ 20 }) . ({ 21 }) 
# Sentence pair (1898) source length 24 target length 24 alignment score : 0.000248919
Non-face patterns in the subsequent SVM classifiers were false positives collected by the partially cascaded SVM classifiers on these 40 ,000 non-face patterns . 
NULL ({ }) Non-face ({ 1 }) patterns ({ 2 }) in ({ 3 }) the ({ 4 }) subsequent ({ 5 }) SVM ({ 6 }) classifiers ({ 7 }) were ({ 8 }) false ({ 9 }) positives ({ 10 }) collected ({ 11 }) by ({ 12 }) the ({ 13 }) partially ({ 14 }) cascaded ({ 15 }) SVM ({ 16 }) classifiers ({ 17 }) on ({ 18 }) these ({ 19 }) 40 ({ 20 }) ,000 ({ 21 }) non-face ({ 22 }) patterns ({ 23 }) . ({ 24 }) 
# Sentence pair (1899) source length 19 target length 19 alignment score : 0.000500353
To control the number of support vectors , the parameter \MATH was used instead of the parameter \MATH . 
NULL ({ }) To ({ 1 }) control ({ 2 }) the ({ 3 }) number ({ 4 }) of ({ 5 }) support ({ 6 }) vectors ({ 7 }) , ({ 8 }) the ({ 9 }) parameter ({ 10 }) \MATH ({ 11 }) was ({ 12 }) used ({ 13 }) instead ({ 14 }) of ({ 15 }) the ({ 16 }) parameter ({ 17 }) \MATH ({ 18 }) . ({ 19 }) 
# Sentence pair (1900) source length 13 target length 13 alignment score : 0.00805134
All SVM classifiers were trained by using the RBF kernel with \MATH . 
NULL ({ }) All ({ 1 }) SVM ({ 2 }) classifiers ({ 3 }) were ({ 4 }) trained ({ 5 }) by ({ 6 }) using ({ 7 }) the ({ 8 }) RBF ({ 9 }) kernel ({ 10 }) with ({ 11 }) \MATH ({ 12 }) . ({ 13 }) 
# Sentence pair (1901) source length 50 target length 15 alignment score : 2.48592e-36
All these parameters were found by using cross-validation test tool provided by LibSVM [31]} . 
NULL ({ }) All ({ 1 }) these ({ 2 }) parameters ({ 3 }) were ({ 4 }) found ({ 5 }) by ({ 6 }) using ({ 7 }) a ({ }) cross-validation ({ 8 }) test ({ 9 }) tool ({ 10 }) provided ({ 11 }) by ({ 12 }) LibSVM ({ 13 }) [31] ({ }) . ({ }) / ({ }) / ({ }) ?NOTE ({ 14 }) : ({ }) I ({ }) believe ({ }) that ({ }) I ({ }) hyphenated ({ }) this ({ }) term ({ }) in ({ }) your ({ }) previous ({ }) document ({ }) , ({ }) but ({ }) after ({ }) seeing ({ }) it ({ }) used ({ }) here ({ }) , ({ }) I ({ }) would ({ }) say ({ }) that ({ }) it ({ }) does ({ }) not ({ }) need ({ }) to ({ }) be ({ }) hyphenated ({ 15 }) 
# Sentence pair (1902) source length 23 target length 25 alignment score : 2.40814e-09
This training procedure resulted three SVM classifiers whose the numbers of support vectors are 4 ,725 , 5 ,043 , and 4 ,847 respectively . 
NULL ({ 9 }) This ({ 1 }) training ({ 2 }) procedure ({ 3 }) yielded ({ 4 }) three ({ 5 }) SVM ({ 6 }) classifiers ({ 7 }) whose ({ 8 }) numbers ({ 10 }) of ({ 11 }) support ({ 12 }) vectors ({ 13 }) are ({ 14 }) 4 ({ 15 }) ,725 ({ 16 }) , ({ 17 }) 5 ({ 18 }) ,043 ({ 19 }) , ({ 20 }) and ({ 21 }) 4 ({ 22 }) ,847 ({ 23 24 }) . ({ 25 }) 
# Sentence pair (1903) source length 18 target length 18 alignment score : 0.000103804
The average evaluating speed of a SVM classifier is approximate 610 WPS ( windows per second ) . 
NULL ({ }) The ({ 1 }) average ({ 2 }) evaluating ({ 3 }) speed ({ 4 }) of ({ 5 }) a ({ 6 }) SVM ({ 7 }) classifier ({ 8 }) is ({ 9 }) approximately ({ 10 }) 610 ({ 11 }) WPS ({ 12 }) ( ({ 13 }) windows ({ 14 }) per ({ 15 }) second ({ 16 }) ) ({ 17 }) . ({ 18 }) 
# Sentence pair (1904) source length 35 target length 33 alignment score : 1.15473e-07
We tested our system on the MIT+CMU frontal-face standard test set [5] which consists of 124 images with 480 frontal faces ( excluding images containing hand-drawn , cartoon and small faces ) . 
NULL ({ }) We ({ 1 }) tested ({ 2 }) our ({ 3 }) system ({ 4 }) on ({ 5 }) the ({ 6 }) MIT+CMU ({ 7 }) frontal-face ({ 8 }) standard ({ 9 }) test ({ 10 }) set ({ 11 }) [5] ({ 12 }) , ({ }) which ({ 13 }) consists ({ 14 }) of ({ 15 }) 124 ({ 16 }) images ({ 17 }) with ({ 18 }) 480 ({ 19 }) frontal ({ 20 }) faces ({ 21 }) ( ({ 22 }) excluding ({ 23 }) images ({ 24 }) containing ({ 25 }) hand-drawn ({ 26 }) , ({ 27 }) cartoon ({ 28 }) , ({ }) and ({ 29 }) small ({ 30 }) faces ({ 31 }) ) ({ 32 }) . ({ 33 }) 
# Sentence pair (1905) source length 16 target length 16 alignment score : 0.00446325
The configuration and rejection performance of the classifiers are listed in Table 1 and 2 . 
NULL ({ }) The ({ 1 }) configuration ({ 2 }) and ({ 3 }) rejection ({ 4 }) performance ({ 5 }) of ({ 6 }) the ({ 7 }) classifiers ({ 8 }) are ({ 9 }) listed ({ 10 }) in ({ 11 }) Tables ({ 12 }) 1 ({ 13 }) and ({ 14 }) 2 ({ 15 }) . ({ 16 }) 
# Sentence pair (1906) source length 56 target length 28 alignment score : 1.18823e-35
The first row presents the number of features of each layer , and the second row shows the fraction of the remaining patterns after each layer processing . 
NULL ({ 12 }) The ({ 1 }) first ({ 2 }) row ({ 3 }) presents ({ 4 }) the ({ 5 }) number ({ 6 }) of ({ 7 }) features ({ 8 }) of ({ 9 }) each ({ 10 }) layer ({ 11 }) and ({ 13 }) the ({ 14 }) second ({ 15 }) row ({ 16 }) shows ({ 17 }) the ({ 18 }) fraction ({ 19 }) of ({ 20 }) the ({ 21 }) remaining ({ 22 }) patterns ({ 23 }) after ({ 24 }) each ({ 25 }) layer ({ 26 }) were ({ }) processed ({ }) . ({ }) / ({ }) / ({ }) [fraction ({ }) / ({ }) percentage?<--Here ({ 27 }) and ({ }) after ({ }) , ({ }) you ({ }) use ({ }) " ({ }) percentage ({ }) " ({ }) in ({ }) the ({ }) graph ({ }) , ({ }) so ({ }) you ({ }) may ({ }) want ({ }) to ({ }) keep ({ }) the ({ }) same ({ }) term ({ }) here ({ }) .] ({ 28 }) 
# Sentence pair (1907) source length 18 target length 13 alignment score : 2.67281e-07
The last row indicates the fraction of time that each layer consumes . 
NULL ({ }) The ({ 1 }) last ({ 2 }) row ({ 3 }) indicates ({ 4 }) the ({ 5 }) fraction ({ 6 }) of ({ 7 }) time ({ 8 }) that ({ 9 }) each ({ 10 }) layer ({ 11 }) consumed ({ 12 }) . ({ }) / ({ }) / ({ }) [fraction ({ }) / ({ }) percentage?] ({ 13 }) 
# Sentence pair (1908) source length 15 target length 15 alignment score : 1.05049e-05
All these statistics are extracted from running the classifiers on the MIT+CMU test set . 
NULL ({ }) All ({ 1 }) these ({ 2 }) statistics ({ 3 }) were ({ 4 }) extracted ({ 5 }) by ({ 6 }) running ({ 7 }) the ({ 8 }) classifiers ({ 9 }) on ({ 10 }) the ({ 11 }) MIT+CMU ({ 12 }) test ({ 13 }) set ({ 14 }) . ({ 15 }) 
# Sentence pair (1909) source length 36 target length 36 alignment score : 5.24991e-07
The fraction of the remaining patterns on these two tables indicates that most of the non-face patterns , i.e. , \MATH , are rejected by the first stage , the cascade of 36x36 AdaBoost classifiers . 
NULL ({ }) The ({ 1 }) fraction ({ 2 }) of ({ 3 }) the ({ 4 }) remaining ({ 5 }) patterns ({ 6 }) on ({ 7 }) these ({ 8 }) two ({ 9 }) tables ({ 10 }) indicates ({ 11 }) that ({ 12 }) most ({ 13 }) of ({ 14 }) the ({ 15 }) non-face ({ 16 }) patterns ({ 17 }) , ({ 18 }) i.e. ({ 19 }) , ({ 20 }) \MATH ({ 21 }) , ({ 22 }) were ({ 23 }) rejected ({ 24 }) by ({ 25 }) the ({ 26 }) first ({ 27 }) stage ({ 28 }) , ({ 29 }) the ({ 30 }) cascade ({ 31 }) of ({ 32 }) 36x36 ({ 33 }) AdaBoost ({ 34 }) classifiers ({ 35 }) . ({ 36 }) 
# Sentence pair (1910) source length 40 target length 39 alignment score : 4.95685e-10
If the first 24x24 layer classifier is added to the cascade of 36x36 classifiers , this combination rejects 85 .91\% of analyzed patterns compared to \MATH of using only the first layer of the single cascade 24x24 classifiers . 
NULL ({ }) When ({ 1 }) the ({ 2 }) first ({ 3 }) 24x24 ({ 4 }) layer ({ 5 }) classifier ({ 6 }) was ({ 7 }) added ({ 8 }) to ({ 9 }) the ({ 10 }) cascade ({ 11 }) of ({ 12 }) 36x36 ({ 13 }) classifiers ({ 14 }) , ({ 15 }) this ({ 16 }) combination ({ 17 }) rejected ({ 18 }) 85 ({ 19 }) .91\% ({ 20 }) of ({ 21 }) analyzed ({ 22 }) patterns ({ 23 }) compared ({ 24 }) to ({ 25 }) \MATH ({ 26 }) of ({ 27 }) using ({ 28 }) only ({ 29 }) the ({ 30 }) first ({ 31 }) layer ({ 32 }) of ({ 33 }) the ({ 34 }) single ({ 35 }) cascade ({ 36 }) of ({ }) 24x24 ({ 37 }) classifiers ({ 38 }) . ({ 39 }) 
# Sentence pair (1911) source length 32 target length 23 alignment score : 8.60175e-13
Furthermore , the rejection of this very large number of patterns is done extremely quickly , only using \MATH of processing time . 
NULL ({ }) Furthermore ({ 1 }) , ({ 2 }) the ({ 3 }) rejection ({ 4 }) of ({ 5 }) this ({ 6 }) very ({ 7 }) large ({ 8 }) number ({ 9 }) of ({ 10 }) patterns ({ 11 }) was ({ 12 }) done ({ 13 }) extremely ({ 14 }) quickly ({ 15 }) , ({ 16 }) only ({ 17 }) using ({ 18 }) \MATH ({ 19 }) of ({ 20 }) the ({ }) total ({ }) processing ({ 21 }) time ({ 22 }) . ({ 23 }) / ({ }) / ({ }) [the ({ }) total ({ }) / ({ }) the ({ }) standard?] ({ }) 
# Sentence pair (1912) source length 23 target length 23 alignment score : 7.90345e-05
It also shows that most of the processing time used by the AdaBoost+SVM system , \MATH , is used for SVM classifiers . 
NULL ({ }) It ({ 1 }) also ({ 2 }) shows ({ 3 }) that ({ 4 }) most ({ 5 }) of ({ 6 }) the ({ 7 }) processing ({ 8 }) time ({ 9 }) used ({ 10 }) by ({ 11 }) the ({ 12 }) AdaBoost+SVM ({ 13 }) system ({ 14 }) , ({ 15 }) \MATH ({ 16 }) , ({ 17 }) was ({ 18 }) used ({ 19 }) for ({ 20 }) SVM ({ 21 }) classifiers ({ 22 }) . ({ 23 }) 
# Sentence pair (1913) source length 18 target length 16 alignment score : 4.91473e-07
Detection rate and speed of classifiers with ten false positives are listed in Table 3 . 
NULL ({ }) The ({ }) detection ({ 1 }) rate ({ 2 }) and ({ 3 }) speed ({ 4 }) of ({ 5 }) the ({ }) classifiers ({ 6 }) with ({ 7 }) ten ({ 8 }) false ({ 9 }) positives ({ 10 }) are ({ 11 }) listed ({ 12 }) in ({ 13 }) Table ({ 14 }) 3 ({ 15 }) . ({ 16 }) 
# Sentence pair (1914) source length 23 target length 23 alignment score : 3.39131e-08
It is clear that our multi-stage system runs faster than the single cascade of 24x24 AdaBoost classifiers while detection rates are comparable . 
NULL ({ }) It ({ 1 }) is ({ 2 }) clear ({ 3 }) that ({ 4 }) our ({ 5 }) multi-stage ({ 6 }) system ({ 7 }) ran ({ 8 }) faster ({ 9 }) than ({ 10 }) the ({ 11 }) single ({ 12 }) cascade ({ 13 }) of ({ 14 }) 24x24 ({ 15 }) AdaBoost ({ 16 }) classifiers ({ 17 }) while ({ 18 }) achieving ({ 21 }) comparable ({ 22 }) detection ({ 19 }) rates ({ 20 }) . ({ 23 }) 
# Sentence pair (1915) source length 8 target length 11 alignment score : 5.97649e-17
This performance is possible because of the three following reasons : 
NULL ({ 6 7 }) This ({ 1 }) performance ({ 2 }) was ({ 3 }) possible ({ 4 }) for ({ }) three ({ 8 }) reasons ({ 5 9 10 }) . ({ 11 }) 
# Sentence pair (1916) source length 31 target length 31 alignment score : 7.12223e-12
First , the cascade of 36x36 AdaBoost classifiers rejects a lot of non-face patterns extremely fast while slow SVM classifiers only process a very small number of the remaining patterns . 
NULL ({ 10 }) First ({ 1 }) , ({ 2 }) the ({ 3 }) cascade ({ 4 }) of ({ 5 }) 36x36 ({ 6 }) AdaBoost ({ 7 }) classifiers ({ 8 }) rejected ({ 9 }) many ({ 11 }) of ({ 12 }) non-face ({ 13 }) patterns ({ 14 }) extremely ({ 15 }) quickly ({ 16 }) , ({ }) while ({ 17 }) slow ({ 18 }) SVM ({ 19 }) classifiers ({ 20 }) only ({ 21 }) processed ({ 22 }) a ({ 23 }) very ({ 24 }) small ({ 25 }) number ({ 26 }) of ({ 27 }) the ({ 28 }) remaining ({ 29 }) patterns ({ 30 }) . ({ 31 }) 
# Sentence pair (1917) source length 33 target length 35 alignment score : 1.24016e-23
Second , many images in the MIT+CMU test set contain large portion of background which was mentioned in [9] which said the ratio of non-face to face patterns is about 50 ,000 to 1 . 
NULL ({ 18 20 22 }) Second ({ 1 }) , ({ 2 }) many ({ 3 }) images ({ 4 }) in ({ 5 }) the ({ 6 }) MIT+CMU ({ 7 }) test ({ 8 }) set ({ 9 }) contain ({ 10 }) large ({ 11 }) portion ({ 12 }) of ({ 13 }) background ({ 14 }) , ({ }) which ({ 15 }) [9] ({ 16 19 21 }) mentioned ({ 17 }) has ({ 29 }) a ({ }) ratio ({ 23 }) of ({ 24 }) non-face ({ 25 }) to ({ 26 }) face ({ 27 }) patterns ({ 28 }) of ({ }) about ({ 30 }) 50 ({ 31 }) ,000 ({ 32 }) to ({ 33 }) 1 ({ 34 }) . ({ 35 }) 
# Sentence pair (1918) source length 28 target length 27 alignment score : 4.8556e-06
Experimental results showed that the AdaBoost+SVM system runs faster than that of the original AdaBoost on \MATH of total number of images in this test set . 
NULL ({ }) Experimental ({ 1 }) results ({ 2 }) showed ({ 3 }) that ({ 4 }) the ({ 5 }) AdaBoost+SVM ({ 6 }) system ({ 7 }) ran ({ 8 }) faster ({ 9 }) than ({ 10 }) that ({ 11 }) of ({ 12 }) the ({ 13 }) original ({ 14 }) AdaBoost ({ 15 }) on ({ 16 }) \MATH ({ 17 }) of ({ 18 }) the ({ }) total ({ 19 }) number ({ 20 }) of ({ 21 }) images ({ 22 }) in ({ 23 }) this ({ 24 }) test ({ 25 }) set ({ 26 }) . ({ 27 }) 
# Sentence pair (1919) source length 39 target length 40 alignment score : 1.28357e-15
Third , at a small number of false positives , some true face candidate regions rejected by 36x36 classifiers do not affect so much in final performance because it might also be rejected by 24x24 classifiers in later layers . 
NULL ({ 25 }) Third ({ 1 }) , ({ 2 }) at ({ 3 }) a ({ 4 }) small ({ 5 }) number ({ 6 }) of ({ 7 }) false ({ 8 }) positives ({ 9 }) , ({ 10 }) some ({ 11 }) true ({ 12 }) face ({ 13 }) candidate ({ 14 }) regions ({ 15 }) rejected ({ 16 }) by ({ 17 }) 36x36 ({ 18 }) classifiers ({ 19 }) did ({ 20 }) not ({ 21 }) severely ({ 22 }) affect ({ 23 24 }) the ({ }) final ({ 26 }) performance ({ 27 }) because ({ 28 }) they ({ 29 }) might ({ 30 }) also ({ 31 }) be ({ 32 }) rejected ({ 33 }) by ({ 34 }) 24x24 ({ 35 }) classifiers ({ 36 }) in ({ 37 }) later ({ 38 }) layers ({ 39 }) . ({ 40 }) 
# Sentence pair (1920) source length 9 target length 9 alignment score : 0.0427349
Some detection results are given in Figure 17 . 
NULL ({ }) Some ({ 1 }) detection ({ 2 }) results ({ 3 }) are ({ 4 }) given ({ 5 }) in ({ 6 }) Figure ({ 7 }) 17 ({ 8 }) . ({ 9 }) 
# Sentence pair (1921) source length 20 target length 20 alignment score : 0.000566122
We have developed a method to build a fast and robust face detection system based on a multi-stage approach . 
NULL ({ }) We ({ 1 }) have ({ 2 }) developed ({ 3 }) a ({ 4 }) method ({ 5 }) to ({ 6 }) build ({ 7 }) a ({ 8 }) fast ({ 9 }) and ({ 10 }) robust ({ 11 }) face ({ 12 }) detection ({ 13 }) system ({ 14 }) based ({ 15 }) on ({ 16 }) a ({ 17 }) multi-stage ({ 18 }) approach ({ 19 }) . ({ 20 }) 
# Sentence pair (1922) source length 40 target length 37 alignment score : 1.18206e-14
The cascaded structure of AdaBoost-based classifiers in two first stages allows to best adapt to various complexities of input patterns ,while non linear SVM classifiers at the final stage are robust enough to achieve good results . 
NULL ({ }) The ({ 1 }) cascaded ({ 2 }) structure ({ 3 }) of ({ 4 }) AdaBoost-based ({ 5 }) classifiers ({ 6 }) in ({ 7 }) the ({ }) two ({ 8 }) first ({ 9 }) stages ({ 10 }) allows ({ 11 }) the ({ }) system ({ }) to ({ 12 }) best ({ 13 }) adapt ({ 14 }) to ({ 15 }) various ({ 16 }) complexities ({ 17 }) of ({ 18 }) input ({ 19 }) patterns ({ 20 }) , ({ }) while ({ 21 }) nonlinear ({ 22 23 }) SVM ({ 24 }) classifiers ({ 25 }) at ({ 26 }) the ({ 27 }) final ({ 28 }) stage ({ 29 }) are ({ 30 }) robust ({ 31 }) enough ({ 32 }) to ({ 33 }) achieve ({ 34 }) good ({ 35 }) results ({ 36 }) . ({ 37 }) 
# Sentence pair (1923) source length 52 target length 45 alignment score : 1.81355e-15
Extensive experiments demonstrated that a significant computation time is devoted to potential face regions because almost all non-face patterns are rejected quickly by the two first stages , and only a very small number of face-like patterns is processed by the slow SVM classifiers . 
NULL ({ }) Extensive ({ 1 }) experiments ({ 2 }) demonstrated ({ 3 }) that ({ 4 }) a ({ 5 }) significant ({ 6 }) computation ({ 7 }) time ({ 8 }) is ({ 9 }) devoted ({ 10 }) to ({ 11 }) potential ({ 12 }) face ({ 13 }) regions ({ 14 }) because ({ 15 }) almost ({ 16 }) all ({ 17 }) non-face ({ 18 }) patterns ({ 19 }) are ({ 20 }) rejected ({ 21 }) quickly ({ 22 }) by ({ 23 }) the ({ 24 }) two ({ 25 }) first ({ 26 }) stages ({ 27 }) , ({ 28 }) and ({ 29 }) only ({ 30 }) a ({ 31 }) very ({ 32 }) small ({ 33 }) number ({ 34 }) of ({ 35 }) face-like ({ 36 }) patterns ({ 37 }) are ({ 38 }) processed ({ 39 }) by ({ 40 }) the ({ 41 }) slow ({ 42 }) SVM ({ 43 }) classifiers ({ 44 }) . ({ 45 }) / ({ }) / ({ }) [are ({ }) / ({ }) need ({ }) to ({ }) be?] ({ }) 
# Sentence pair (1924) source length 24 target length 24 alignment score : 2.32116e-10
Discriminant Haar wavelet features selected from AdaBoost are used for all stage classifier to take advantages from their efficient representation and fast evaluation . 
NULL ({ }) Discriminant ({ 1 }) Haar ({ 2 }) wavelet ({ 3 }) features ({ 4 }) selected ({ 5 }) from ({ 6 }) AdaBoost ({ 7 }) are ({ 8 }) used ({ 9 }) for ({ 10 }) all ({ 11 }) stage ({ 12 }) classifiers ({ 13 }) to ({ 14 }) take ({ 15 }) advantage ({ 16 }) of ({ 17 }) their ({ 18 }) efficient ({ 19 }) representation ({ 20 }) and ({ 21 }) fast ({ 22 }) evaluation ({ 23 }) . ({ 24 }) 
# Sentence pair (1925) source length 10 target length 10 alignment score : 0.0227418
Unsupervised Face Re-Ranking By Mining the Web and Video Archives 
NULL ({ }) Unsupervised ({ 1 }) Face ({ 2 }) Re-Ranking ({ 3 }) By ({ 4 }) Mining ({ 5 }) the ({ 6 }) Web ({ 7 }) and ({ 8 }) Video ({ 9 }) Archives ({ 10 }) 
# Sentence pair (1926) source length 23 target length 24 alignment score : 1.04672e-16
to improve the retrieval performance of image search engines that use textual information for indexing , it is necessary to utilize visual information . 
NULL ({ 16 }) It ({ 17 }) is ({ 18 }) necessary ({ 19 }) to ({ 20 }) utilize ({ 21 }) visual ({ 22 }) information ({ 23 }) to ({ 1 }) improve ({ 2 }) the ({ 3 }) efficiency ({ 4 }) of ({ }) retrieval ({ 5 }) in ({ 6 }) image-search ({ 7 8 }) engines ({ 9 }) that ({ 10 }) use ({ 11 }) textual ({ 12 }) information ({ 13 }) for ({ 14 }) indexing ({ 15 }) . ({ 24 }) 
# Sentence pair (1927) source length 17 target length 17 alignment score : 2.70275e-08
One popular approach is to learn visual consistency among the images returned by these search engines . 
NULL ({ 10 }) One ({ 1 }) popular ({ 2 }) approach ({ 3 }) has ({ 4 }) been ({ }) to ({ 5 }) learn ({ 6 }) visual ({ 7 }) consistency ({ 8 }) between ({ 9 }) images ({ 11 }) returned ({ 12 }) by ({ 13 }) these ({ 14 }) search ({ 15 }) engines ({ 16 }) . ({ 17 }) 
# Sentence pair (1928) source length 21 target length 27 alignment score : 4.64456e-23
Most of the state of the art methods for learning the visual consistency usually learn one specific classifier for each query for re-ranking the returned images . 
NULL ({ 2 3 5 6 11 }) Most ({ 1 }) state-of-the-art ({ 4 7 }) methods ({ 8 }) of ({ 9 }) learning ({ 10 }) visual ({ 12 }) consistency ({ 13 }) usually ({ 14 }) learn ({ 15 }) one ({ 16 }) specific ({ 17 }) classifier ({ 18 }) for ({ 19 }) each ({ 20 }) query ({ 21 }) to ({ 22 }) re-rank ({ 23 }) the ({ 24 }) returned ({ 25 }) images ({ 26 }) . ({ 27 }) 
# Sentence pair (1929) source length 26 target length 24 alignment score : 1.39086e-10
The drawback of these methods is it requires computational cost and processing time that are unsuitable for handling a large number of queries . 
NULL ({ }) The ({ 1 }) main ({ }) drawback ({ 2 }) with ({ 3 }) these ({ 4 }) methods ({ 5 }) is ({ 6 }) that ({ }) they ({ 7 }) require ({ 8 }) computational ({ 9 }) cost ({ 10 }) and ({ 11 }) processing ({ 12 }) time ({ 13 }) that ({ 14 }) are ({ 15 }) unsuitable ({ 16 }) for ({ 17 }) handling ({ 18 }) a ({ 19 }) large ({ 20 }) number ({ 21 }) of ({ 22 }) queries ({ 23 }) . ({ 24 }) 
# Sentence pair (1930) source length 19 target length 19 alignment score : 7.47878e-08
We propose a method in which one generic classifier is learned and then is used for all queries . 
NULL ({ 14 }) We ({ 1 }) propose ({ 2 }) a ({ 3 }) method ({ 4 }) in ({ 5 }) which ({ 6 }) one ({ 7 }) generic ({ 8 }) classifier ({ 9 }) is ({ 10 }) learned ({ 11 }) and ({ 12 }) is ({ }) then ({ 13 }) used ({ 15 }) for ({ 16 }) all ({ 17 }) queries ({ 18 }) . ({ 19 }) 
# Sentence pair (1931) source length 33 target length 33 alignment score : 2.1087e-08
Different from query-specific based methods that learn classifiers for recognition concepts encoded in each query , the generic classifier of our method learns relevancy between images and the query for re-ranking purpose . 
NULL ({ }) Different ({ 1 }) from ({ 2 }) query-specific ({ 3 }) based ({ 4 }) methods ({ 5 }) that ({ 6 }) learn ({ 7 }) classifiers ({ 8 }) for ({ 9 }) recognition ({ 10 }) concepts ({ 11 }) encoded ({ 12 }) in ({ 13 }) each ({ 14 }) query ({ 15 }) , ({ 16 }) the ({ 17 }) generic ({ 18 }) classifier ({ 19 }) in ({ 20 }) our ({ 21 }) method ({ 22 }) learns ({ 23 }) relevance ({ 24 }) between ({ 25 }) images ({ 26 }) and ({ 27 }) the ({ 28 }) query ({ 29 }) for ({ 30 }) re-ranking ({ 31 }) purposes ({ 32 }) . ({ 33 }) 
# Sentence pair (1932) source length 30 target length 30 alignment score : 5.99066e-13
The key contribution of this paper is to introduce a query-dependent feature to represent this relevancy and an unsupervised method to collect training samples for learning the generic classifier . 
NULL ({ }) The ({ 1 }) key ({ 2 }) contribution ({ 3 }) of ({ 4 }) this ({ 5 }) research ({ 6 }) is ({ 7 }) to ({ 8 }) introduce ({ 9 }) a ({ 10 }) query-dependent ({ 11 }) feature ({ 12 }) to ({ 13 }) represent ({ 14 }) this ({ 15 }) relevance ({ 16 }) and ({ 17 }) an ({ 18 }) unsupervised ({ 19 }) method ({ 20 }) of ({ 21 }) collecting ({ 22 }) training ({ 23 }) samples ({ 24 }) to ({ 25 }) learn ({ 26 }) the ({ 27 }) generic ({ 28 }) classifier ({ 29 }) . ({ 30 }) 
# Sentence pair (1933) source length 18 target length 17 alignment score : 3.33309e-08
The generic classifier is built automatically and independent with existing ranking algorithms of input search engines . 
NULL ({ }) The ({ 1 }) generic ({ 2 }) classifier ({ 3 }) is ({ 4 }) built ({ 5 }) automatically ({ 6 }) and ({ 7 }) is ({ }) independent ({ 8 }) of ({ 9 }) existing ({ 10 }) ranking ({ 11 }) algorithms ({ 12 }) for ({ 13 }) input ({ 14 }) search ({ 15 }) engines ({ 16 }) . ({ 17 }) 
# Sentence pair (1934) source length 15 target length 14 alignment score : 1.06039e-08
experimental results show that the proposed method achieves good performance in various datasets . 
NULL ({ }) The ({ }) experimental ({ 1 }) results ({ 2 }) demonstrated ({ 3 }) that ({ 4 }) the ({ 5 }) proposed ({ 6 }) method ({ 7 }) performed ({ 8 }) very ({ 9 }) well ({ 10 }) in ({ 11 }) various ({ 12 }) datasets ({ 13 }) . ({ 14 }) 
# Sentence pair (1935) source length 9 target length 9 alignment score : 0.00133183
Image search is essential for many search engines . 
NULL ({ }) Image ({ 1 }) searches ({ 2 }) are ({ 3 }) essential ({ 4 }) for ({ 5 }) many ({ 6 }) search ({ 7 }) engines ({ 8 }) . ({ 9 }) 
# Sentence pair (1936) source length 17 target length 19 alignment score : 7.62056e-19
Most of existing image search engines usually use text information for judging relevancy , resulting low precision performance . 
NULL ({ 2 18 }) Most ({ 1 }) existing ({ 3 }) image-search ({ 4 5 }) engines ({ 6 }) usually ({ 7 }) use ({ 8 }) text ({ 9 }) information ({ 10 }) to ({ 11 }) determine ({ 12 }) relevance ({ 13 }) , ({ 14 }) resulting ({ 15 }) in ({ }) poor ({ 16 }) precision ({ 17 }) . ({ 19 }) 
# Sentence pair (1937) source length 20 target length 18 alignment score : 2.81538e-13
To improve the retrieval performance , it is necessary to use visual information of images for re-ranking . 
NULL ({ }) To ({ 1 }) improve ({ 2 }) the ({ 3 }) accuracy ({ 4 }) of ({ }) retrieval ({ 5 }) , ({ 6 }) it ({ 7 }) is ({ 8 }) necessary ({ 9 }) to ({ 10 }) use ({ 11 }) visual ({ 12 }) information ({ 13 }) from ({ 14 }) images ({ 15 }) to ({ 16 }) re-rank ({ 17 }) them ({ }) . ({ 18 }) 
# Sentence pair (1938) source length 12 target length 12 alignment score : 1.74749e-06
However , content-based image understanding is a challenging and unsolved problem . 
NULL ({ }) However ({ 1 }) , ({ 2 }) understanding ({ 3 }) content-based ({ 4 }) images ({ 5 }) remains ({ 6 }) a ({ 7 }) challenging ({ 8 }) and ({ 9 }) unsolved ({ 10 }) problem ({ 11 }) . ({ 12 }) 
# Sentence pair (1939) source length 15 target length 15 alignment score : 8.67676e-11
In addition , using visual information requires huge computational cost compared with using text . 
NULL ({ }) In ({ 1 }) addition ({ 2 }) , ({ 3 }) using ({ 4 }) visual ({ 5 }) information ({ 6 }) requires ({ 7 }) much ({ 8 }) greater ({ 11 }) computational ({ 9 }) cost ({ 10 }) than ({ 12 }) using ({ 13 }) text ({ 14 }) . ({ 15 }) 
# Sentence pair (1940) source length 42 target length 39 alignment score : 1.08362e-20
One popular approach \CITE combining both text and visual information is to use text information to quickly retrieve a set of candidates and then do post-processing (i . e . re-rank) on this set to improve the precision . 
NULL ({ 37 }) One ({ 1 }) popular ({ 2 }) approach ({ 3 }) \CITE ({ 4 }) combining ({ 5 }) both ({ 6 }) text ({ 7 }) and ({ 8 }) visual ({ 9 }) information ({ 10 }) has ({ 11 }) been ({ }) to ({ 12 }) use ({ 13 }) text ({ 14 }) information ({ 15 }) to ({ 16 }) quickly ({ 17 }) retrieve ({ 18 }) a ({ 19 }) set ({ 20 }) of ({ 21 }) candidates ({ 22 }) and ({ 23 }) then ({ 24 }) do ({ 25 }) post-processing ({ 26 }) ( ({ }) i ({ }) . ({ 28 }) e ({ 27 29 31 }) . ({ 30 }) , ({ }) re-ranking ({ }) ) ({ }) on ({ 32 }) this ({ 33 }) set ({ 34 }) to ({ 35 }) improve ({ 36 }) precision ({ 38 }) . ({ 39 }) 
# Sentence pair (1941) source length 30 target length 29 alignment score : 1.19027e-12
There are two ways for post-processing : The first way \CITE is to build a ranker or a classifier specific to the given query using the returned images . 
NULL ({ 10 }) There ({ 1 }) are ({ 2 }) two ({ 3 }) ways ({ 4 }) of ({ }) doing ({ 5 }) post-processing ({ 6 }) : ({ 7 }) The ({ 8 }) first ({ 9 }) \CITE ({ 11 }) has ({ 12 }) been ({ }) to ({ 13 }) build ({ 14 }) a ({ 15 }) ranker ({ 16 }) or ({ 17 }) a ({ 18 }) classifier ({ 19 }) specific ({ 20 }) to ({ 21 }) the ({ 22 }) given ({ 23 }) query ({ 24 }) using ({ 25 }) the ({ 26 }) returned ({ 27 }) images ({ 28 }) . ({ 29 }) 
# Sentence pair (1942) source length 10 target length 10 alignment score : 0.0161162
Building such classifiers requires large computational cost and time . 
NULL ({ }) Building ({ 1 }) such ({ 2 }) classifiers ({ 3 }) involves ({ 4 }) large ({ 5 }) computational ({ 6 }) cost ({ 7 }) and ({ 8 }) time ({ 9 }) . ({ 10 }) 
# Sentence pair (1943) source length 19 target length 18 alignment score : 9.84787e-07
As a result , this way is not scalable for applications processing very large number of queries . 
NULL ({ }) As ({ 1 }) a ({ 2 }) result ({ 3 }) , ({ 4 }) this ({ 5 }) way ({ 6 }) is ({ 7 }) not ({ 8 }) scalable ({ 9 }) for ({ 10 }) applications ({ 11 }) that ({ }) process ({ 12 }) very ({ 13 }) large ({ 14 }) numbers ({ 15 }) of ({ 16 }) queries ({ 17 }) . ({ 18 }) 
# Sentence pair (1944) source length 21 target length 20 alignment score : 2.6834e-05
The second way \CITE is to build a generic classifier once and then use it for all new queries . 
NULL ({ }) The ({ 1 }) second ({ 2 }) way ({ 3 }) \CITE ({ 4 }) has ({ 5 }) been ({ }) to ({ 6 }) build ({ 7 }) a ({ 8 }) generic ({ 9 }) classifier ({ 10 }) once ({ 11 }) and ({ 12 }) then ({ 13 }) use ({ 14 }) it ({ 15 }) for ({ 16 }) all ({ 17 }) new ({ 18 }) queries ({ 19 }) . ({ 20 }) 
# Sentence pair (1945) source length 16 target length 18 alignment score : 3.79906e-10
This way is more scalable and can be used for practical applications such as meta search engines . 
NULL ({ 2 }) This ({ 1 }) is ({ 3 }) more ({ 4 }) scalable ({ 5 }) and ({ 6 }) can ({ 7 }) be ({ 8 }) used ({ 9 }) for ({ 10 }) practical ({ 11 }) applications ({ 12 }) such ({ 13 }) as ({ 14 }) meta-search ({ 15 16 }) engines ({ 17 }) . ({ 18 }) 
# Sentence pair (1946) source length 26 target length 25 alignment score : 4.04408e-10
We follow the latter way for the problem of face retrieval in which the system enables users to search persons's appearance by their names . 
NULL ({ }) We ({ 1 }) pursued ({ 2 }) the ({ 3 }) latter ({ 4 }) way ({ 5 }) to ({ }) solve ({ 6 }) the ({ 7 }) problem ({ 8 }) with ({ 9 }) face ({ 10 }) retrieval ({ 11 }) in ({ 12 }) which ({ 13 }) the ({ 14 }) system ({ 15 }) enables ({ 16 }) users ({ 17 }) to ({ 18 }) search ({ 19 }) people's ({ 20 }) appearances ({ 21 }) by ({ 22 }) their ({ 23 }) names ({ 24 }) . ({ 25 }) 
# Sentence pair (1947) source length 29 target length 28 alignment score : 8.30416e-08
Our system re-ranks the faces returned by text-based search engines by a generic classifier that is trained in advance using visual information before returning to the user . 
NULL ({ }) Our ({ 1 }) system ({ 2 }) re-ranks ({ 3 }) the ({ 4 }) faces ({ 5 }) returned ({ 6 }) by ({ 7 }) text-based ({ 8 }) search ({ 9 }) engines ({ 10 }) with ({ 11 }) a ({ 12 }) generic ({ 13 }) classifier ({ 14 }) that ({ 15 }) is ({ 16 }) trained ({ 17 }) in ({ 18 }) advance ({ 19 }) using ({ 20 }) visual ({ 21 }) information ({ 22 }) before ({ 23 }) returning ({ 24 }) them ({ }) to ({ 25 }) the ({ 26 }) user ({ 27 }) . ({ 28 }) 
# Sentence pair (1948) source length 29 target length 26 alignment score : 2.8818e-14
Building such generic classifiers requires solving two problems : finding good query-relative representation of faces and collecting a large labeled dataset for training the classifier . 
NULL ({ }) Building ({ 1 }) such ({ 2 }) generic ({ 3 }) classifiers ({ 4 }) requires ({ 5 6 }) two ({ 7 }) problems ({ 8 }) to ({ }) be ({ }) solved ({ }) : ({ 9 }) finding ({ 10 }) a ({ }) good ({ 11 }) query-relative ({ 12 }) representation ({ 13 }) of ({ 14 }) faces ({ 15 }) and ({ 16 }) collecting ({ 17 }) a ({ 18 }) large ({ 19 }) labeled ({ 20 }) dataset ({ 21 }) to ({ 22 }) train ({ 23 }) the ({ 24 }) classifier ({ 25 }) . ({ 26 }) 
# Sentence pair (1949) source length 9 target length 10 alignment score : 3.01431e-12
By addressing these problems , Our contribution is two-fold : 
NULL ({ 5 }) Our ({ 1 6 }) contribution ({ 7 }) by ({ }) addressing ({ 2 }) these ({ 3 }) problems ({ 4 }) is ({ 8 }) two-fold ({ 9 }) : ({ 10 }) 
# Sentence pair (1950) source length 15 target length 15 alignment score : 0.000117071
-We propose a general framework for re-ranking faces returned by existing text-based search engine . 
NULL ({ }) -We ({ 1 }) propose ({ 2 }) a ({ 3 }) general ({ 4 }) framework ({ 5 }) for ({ 6 }) re-ranking ({ 7 }) faces ({ 8 }) returned ({ 9 }) by ({ 10 }) existing ({ 11 }) text-based ({ 12 }) search ({ 13 }) engines ({ 14 }) . ({ 15 }) 
# Sentence pair (1951) source length 23 target length 24 alignment score : 1.69228e-12
In this framework , We learn a relevance classifier that classifies whether an input face is relevant to the associated query or not . 
NULL ({ 4 }) We ({ 5 }) learn ({ 6 }) a ({ 7 }) relevance ({ 8 }) classifier ({ 9 }) that ({ 10 }) classifies ({ 11 }) whether ({ 12 }) an ({ 13 }) input ({ 14 }) face ({ 15 }) is ({ 16 }) relevant ({ 17 }) to ({ 18 }) the ({ 19 }) associated ({ 20 }) query ({ 21 }) or ({ 22 }) not ({ 23 }) in ({ 1 }) this ({ 2 }) framework ({ 3 }) . ({ 24 }) 
# Sentence pair (1952) source length 14 target length 14 alignment score : 0.0054214
The output scores returned by this classifier are used to re-rank the faces . 
NULL ({ }) The ({ 1 }) output ({ 2 }) scores ({ 3 }) returned ({ 4 }) by ({ 5 }) this ({ 6 }) classifier ({ 7 }) are ({ 8 }) used ({ 9 }) to ({ 10 }) re-rank ({ 11 }) the ({ 12 }) faces ({ 13 }) . ({ 14 }) 
# Sentence pair (1953) source length 15 target length 14 alignment score : 0.000230455
The more relevant a face to the query , the higher score is . 
NULL ({ }) The ({ 1 }) more ({ 2 }) relevant ({ 3 }) a ({ 4 }) face ({ 5 }) is ({ }) to ({ 6 }) the ({ 7 }) query ({ 8 }) , ({ 9 }) the ({ 10 }) higher ({ 11 }) score ({ 12 }) is ({ 13 }) . ({ 14 }) 
# Sentence pair (1954) source length 21 target length 23 alignment score : 5.979e-11
This approach is different from existing approaches such as \CITE that learn a classifier to recognize the identity of the returned faces . 
NULL ({ 8 9 }) This ({ 1 }) approach ({ 2 }) is ({ 3 }) different ({ 4 }) from ({ 5 }) existing ({ 6 }) ones ({ 7 }) \CITE ({ 10 }) that ({ 11 }) learn ({ 12 }) a ({ 13 }) classifier ({ 14 }) to ({ 15 }) recognize ({ 16 }) the ({ 17 }) identity ({ 18 }) of ({ 19 }) the ({ 20 }) returned ({ 21 }) faces ({ 22 }) . ({ 23 }) 
# Sentence pair (1955) source length 19 target length 19 alignment score : 0.000810582
For example , it recognizes a face as the appearance of 'personX' or not the appearance of 'personX' . 
NULL ({ }) For ({ 1 }) example ({ 2 }) , ({ 3 }) it ({ 4 }) recognizes ({ 5 }) a ({ 6 }) face ({ 7 }) as ({ 8 }) the ({ 9 }) appearance ({ 10 }) of ({ 11 }) 'personX' ({ 12 }) or ({ 13 }) not ({ 14 }) the ({ 15 }) appearance ({ 16 }) of ({ 17 }) 'personX' ({ 18 }) . ({ 19 }) 
# Sentence pair (1956) source length 19 target length 19 alignment score : 0.000387475
Instead , the relevance classifier is learned to classify a face being relevant or irrelevant to the query . 
NULL ({ }) Instead ({ 1 }) , ({ 2 }) the ({ 3 }) relevance ({ 4 }) classifier ({ 5 }) is ({ 6 }) learned ({ 7 }) to ({ 8 }) classify ({ 9 }) a ({ 10 }) face ({ 11 }) being ({ 12 }) relevant ({ 13 }) or ({ 14 }) irrelevant ({ 15 }) to ({ 16 }) the ({ 17 }) query ({ 18 }) . ({ 19 }) 
# Sentence pair (1957) source length 25 target length 23 alignment score : 1.82266e-18
this classifier is independent with the identity of faces , so it can be shared for multiple queries (cf . Figure \REF) . 
NULL ({ 11 }) As ({ }) this ({ 1 }) classifier ({ 2 }) is ({ 3 }) independent ({ 4 }) of ({ 5 }) the ({ 6 }) identity ({ 7 }) of ({ 8 }) faces ({ 9 }) , ({ 10 }) it ({ 12 }) can ({ 13 }) be ({ 14 }) shared ({ 15 }) for ({ 16 }) multiple ({ 17 }) queries ({ 18 }) ( ({ }) cf ({ 19 }) . ({ 20 }) Figure ({ 21 }) \REF ({ 22 }) ) ({ }) . ({ 23 }) 
# Sentence pair (1958) source length 19 target length 18 alignment score : 0.00017852
We propose a novel representation for each face that models relevance between that face and the query . 
NULL ({ }) We ({ 1 }) propose ({ 2 }) a ({ 3 }) novel ({ 4 }) representation ({ 5 }) for ({ 6 }) each ({ 7 }) face ({ 8 }) that ({ 9 }) models ({ 10 }) the ({ }) relevance ({ 11 }) between ({ 12 }) that ({ 13 }) face ({ 14 }) and ({ 15 }) the ({ 16 }) query ({ 17 }) . ({ 18 }) 
# Sentence pair (1959) source length 23 target length 22 alignment score : 7.01535e-05
Once this query-dependent feature for each face is extracted , one relevance classifier can be shared by faces of various queries . 
NULL ({ }) Once ({ 1 }) this ({ 2 }) query-dependent ({ 3 }) feature ({ 4 }) for ({ 5 }) each ({ 6 }) face ({ 7 }) is ({ 8 }) extracted ({ 9 }) , ({ 10 }) one ({ 11 }) relevance ({ 12 }) classifier ({ 13 }) can ({ 14 }) be ({ 15 }) shared ({ 16 }) by ({ 17 }) the ({ }) faces ({ 18 }) of ({ 19 }) various ({ 20 }) queries ({ 21 }) . ({ 22 }) 
# Sentence pair (1960) source length 25 target length 24 alignment score : 2.45357e-12
experimental results show that the relevance classifier that is independent with underlying ranking algorithm of existing search engines can significantly boost the performance . 
NULL ({ 22 }) The ({ }) experimental ({ 1 }) results ({ 2 }) demonstrated ({ 3 }) that ({ 4 }) the ({ 5 }) relevance ({ 6 }) classifier ({ 7 }) that ({ 8 }) is ({ 9 }) independent ({ 10 }) of ({ 11 }) the ({ }) underlying ({ 12 }) ranking ({ 13 }) algorithms ({ 14 }) of ({ 15 }) existing ({ 16 }) search ({ 17 }) engines ({ 18 }) could ({ 19 }) significantly ({ 20 }) boost ({ 21 }) performance ({ 23 }) . ({ 24 }) 
# Sentence pair (1961) source length 19 target length 19 alignment score : 2.02363e-08
-We propose a simple yet efficient mining technique for automatically collecting labeled data for training the generic classifier . 
NULL ({ }) -We ({ 1 }) propose ({ 2 }) a ({ 3 }) simple ({ 4 }) yet ({ 5 }) efficient ({ 6 }) mining ({ 7 }) technique ({ 8 }) of ({ 9 }) automatically ({ 10 }) collecting ({ 11 }) labeled ({ 12 }) data ({ 13 }) to ({ 14 }) train ({ 15 }) the ({ 16 }) generic ({ 17 }) classifier ({ 18 }) . ({ 19 }) 
# Sentence pair (1962) source length 27 target length 29 alignment score : 3.52377e-17
Specifically , We detect and group faces of persons appearing in video programs in face tracks in which each face track contains of the faces of one person . 
NULL ({ 2 23 }) We ({ 3 }) specifically ({ 1 }) detected ({ 4 }) and ({ 5 }) grouped ({ 6 }) faces ({ 7 }) of ({ 8 }) people ({ 9 }) appearing ({ 10 }) in ({ 11 }) video ({ 12 }) programs ({ 13 }) in ({ 14 }) face ({ 15 }) tracks ({ 16 }) in ({ 17 }) which ({ 18 }) each ({ 19 }) face ({ 20 }) track ({ 21 }) contained ({ 22 }) the ({ 24 }) faces ({ 25 }) of ({ 26 }) one ({ 27 }) person ({ 28 }) . ({ 29 }) 
# Sentence pair (1963) source length 33 target length 33 alignment score : 4.85777e-20
To distinguish face tracks of different persons , we assume that if multiple faces are detected at different locations in one frame , they are of different persons (cf . Figure \REF) . 
NULL ({ 30 }) To ({ 1 }) distinguish ({ 2 }) the ({ }) face ({ 3 }) tracks ({ 4 }) of ({ 5 }) different ({ 6 }) people ({ 7 }) , ({ 8 }) we ({ 9 }) assumed ({ 10 }) that ({ 11 }) if ({ 12 }) multiple ({ 13 }) faces ({ 14 }) were ({ 15 }) detected ({ 16 }) at ({ 17 }) different ({ 18 }) locations ({ 19 }) in ({ 20 }) one ({ 21 }) frame ({ 22 }) , ({ 23 }) they ({ 24 }) would ({ 25 }) be ({ }) of ({ 26 }) different ({ 27 }) people ({ 28 }) ( ({ }) cf ({ 29 31 32 }) . ({ 33 }) 
# Sentence pair (1964) source length 29 target length 30 alignment score : 2.11842e-11
Using this assumption , we collect the face tracks whose faces are detected in the same frames to guarantee that each face track is associated to one unique person . 
NULL ({ 7 }) Using ({ 1 }) this ({ 2 }) assumption ({ 3 }) , ({ 4 }) we ({ 5 }) collected ({ 6 }) face ({ 8 }) tracks ({ 9 }) whose ({ 10 }) faces ({ 11 }) were ({ 12 }) detected ({ 13 }) in ({ 14 }) the ({ 15 }) same ({ 16 }) frames ({ 17 }) to ({ 18 }) guarantee ({ 19 }) that ({ 20 }) each ({ 21 }) face ({ 22 }) track ({ 23 }) was ({ 24 }) associated ({ 25 }) with ({ 26 }) one ({ 27 }) unique ({ 28 }) person ({ 29 }) . ({ 30 }) 
# Sentence pair (1965) source length 18 target length 19 alignment score : 3.89673e-18
To enlarge the number of such face tracks , We use video programs of multiple genres and channels . 
NULL ({ 9 }) We ({ 10 }) used ({ 11 }) video ({ 12 }) programs ({ 13 }) from ({ 14 }) multiple ({ 15 }) genres ({ 16 }) and ({ 17 }) channels ({ 18 }) to ({ 1 }) increase ({ 2 }) the ({ 3 }) number ({ 4 }) of ({ 5 }) such ({ 6 }) face ({ 7 }) tracks ({ 8 }) . ({ 19 }) 
# Sentence pair (1966) source length 21 target length 22 alignment score : 3.16486e-15
From these faces , We can artificially generate face sets similar to the sets returned by search engines given person names . 
NULL ({ 1 4 }) We ({ 5 }) could ({ 6 }) artificially ({ 7 }) generate ({ 8 }) face ({ 9 }) sets ({ 10 }) from ({ }) these ({ 2 }) faces ({ 3 }) similar ({ 11 }) to ({ 12 }) the ({ 13 }) sets ({ 14 }) returned ({ 15 }) by ({ 16 }) search ({ 17 }) engines ({ 18 }) given ({ 19 }) people's ({ 20 }) names ({ 21 }) . ({ 22 }) 
# Sentence pair (1967) source length 32 target length 32 alignment score : 5.55714e-11
Since we know the relevance of these faces to the artificial sets , the labels of each face can be easily generated and no human intervention is needed for this process . 
NULL ({ }) Since ({ 1 }) we ({ 2 }) knew ({ 3 }) the ({ 4 }) relevance ({ 5 }) of ({ 6 }) these ({ 7 }) faces ({ 8 }) to ({ 9 }) the ({ 10 }) artificial ({ 11 }) sets ({ 12 }) , ({ 13 }) the ({ 14 }) labels ({ 15 }) for ({ 16 }) each ({ 17 }) face ({ 18 }) could ({ 19 }) be ({ 20 }) easily ({ 21 }) generated ({ 22 }) and ({ 23 }) no ({ 24 }) human ({ 25 }) intervention ({ 26 }) was ({ 27 }) needed ({ 28 }) in ({ 29 }) this ({ 30 }) process ({ 31 }) . ({ 32 }) 
# Sentence pair (1968) source length 25 target length 28 alignment score : 3.86548e-22
Note that the label of faces in our approach is not identity of that face . It is the relevance between the face and the associated query . 
NULL ({ 13 16 18 }) Note ({ 1 }) that ({ 2 }) the ({ 3 }) labels ({ 4 }) of ({ 5 }) faces ({ 6 }) in ({ 7 }) our ({ 8 }) approach ({ 9 }) did ({ 10 }) not ({ 11 }) identity ({ 12 }) those ({ 14 }) faces ({ 15 }) but ({ 17 }) the ({ 19 }) relevance ({ 20 }) between ({ 21 }) the ({ 22 }) faces ({ 23 }) and ({ 24 }) the ({ 25 }) associated ({ 26 }) query ({ 27 }) . ({ 28 }) 
# Sentence pair (1969) source length 28 target length 29 alignment score : 8.51826e-15
Collecting training sets from such external sources as video archives is easy and efficient because : firstly , a large number of videos can be easy to obtain . 
NULL ({ 27 }) Collecting ({ 1 }) training ({ 2 }) sets ({ 3 }) from ({ 4 }) such ({ 5 }) external ({ 6 }) sources ({ 7 }) as ({ 8 }) video ({ 9 }) archives ({ 10 }) is ({ 11 }) easy ({ 12 }) and ({ 13 }) efficient ({ 14 }) because ({ 15 }) , ({ 16 }) first ({ 17 }) , ({ 18 }) a ({ 19 }) large ({ 20 }) number ({ 21 }) of ({ 22 }) videos ({ 23 }) can ({ 24 }) be ({ 25 }) easily ({ 26 }) obtained ({ 28 }) . ({ 29 }) 
# Sentence pair (1970) source length 16 target length 16 alignment score : 2.12725e-06
For example , people can record broadcast videos of different channels in a certain period . 
NULL ({ }) For ({ 1 }) example ({ 2 }) , ({ 3 }) people ({ 4 }) can ({ 5 }) record ({ 6 }) broadcast ({ 7 }) videos ({ 8 }) from ({ 9 }) different ({ 10 }) channels ({ 11 }) within ({ 12 }) a ({ 13 }) certain ({ 14 }) period ({ 15 }) . ({ 16 }) 
# Sentence pair (1971) source length 19 target length 19 alignment score : 6.91028e-13
Secondly , a huge number of faces can be obtained by applying the face detector in every frame . 
NULL ({ 16 }) Second ({ 1 }) , ({ 2 }) a ({ 3 }) huge ({ 4 }) number ({ 5 }) of ({ 6 }) faces ({ 7 }) can ({ 8 }) be ({ 9 }) obtained ({ 10 }) by ({ 11 }) applying ({ 12 }) a ({ 13 }) face ({ 14 }) detector ({ 15 }) to ({ }) all ({ 17 }) frames ({ 18 }) . ({ 19 }) 
# Sentence pair (1972) source length 26 target length 23 alignment score : 3.44048e-13
In addition , using temporal information , faces of one person appearing in consecutive frames can be automatically grouped with high accuracy . 
NULL ({ 7 }) In ({ 1 }) addition ({ 2 }) , ({ 3 }) the ({ }) faces ({ 8 }) of ({ 9 }) one ({ 10 }) person ({ 11 }) appearing ({ 12 }) in ({ 13 }) consecutive ({ 14 }) frames ({ 15 }) can ({ 16 }) be ({ 17 }) automatically ({ 18 }) grouped ({ 19 }) with ({ 20 }) a ({ }) high ({ 21 }) degree ({ }) of ({ }) accuracy ({ 22 }) using ({ 4 }) temporal ({ 5 }) information ({ 6 }) . ({ 23 }) 
# Sentence pair (1973) source length 29 target length 28 alignment score : 1.21367e-23
given a query described by text , for example , 'airplane' or 'George Bush' , finding relevant images with high precision is essential for image search engines . 
NULL ({ 2 8 15 }) It ({ }) is ({ 22 }) essential ({ 23 }) for ({ 24 }) image-search ({ 25 26 }) engines ({ 27 }) to ({ }) find ({ 16 }) relevant ({ 17 }) images ({ 18 }) with ({ 19 }) a ({ }) high ({ 20 }) degree ({ }) of ({ }) precision ({ 21 }) given ({ 1 }) queries ({ 3 }) described ({ 4 }) by ({ 5 }) text ({ 6 }) , ({ 7 }) e.g. ({ 9 }) , ({ 10 }) 'airplane' ({ 11 }) or ({ 12 }) 'George ({ 13 }) Bush' ({ 14 }) . ({ 28 }) 
# Sentence pair (1974) source length 28 target length 30 alignment score : 8.55297e-10
Existing image search engines usually use textual information associated with the images such as filename , image caption , and surrounding text for ranking that leads to poor precision . 
NULL ({ 11 }) Existing ({ 1 }) image-search ({ 2 3 }) engines ({ 4 }) usually ({ 5 }) use ({ 6 }) textual ({ 7 }) information ({ 8 }) associated ({ 9 }) with ({ 10 }) images ({ 12 }) such ({ 13 }) as ({ 14 }) filenames ({ 15 }) , ({ 16 }) image ({ 17 }) captions ({ 18 }) , ({ 19 }) and ({ 20 }) surrounding ({ 21 }) text ({ 22 }) for ({ 23 }) ranking ({ 24 }) that ({ 25 }) leads ({ 26 }) to ({ 27 }) poor ({ 28 }) precision ({ 29 }) . ({ 30 }) 
# Sentence pair (1975) source length 14 target length 15 alignment score : 0.000405119
To improve the precision , visual information is used to re-rank the returned images . 
NULL ({ 3 }) To ({ 1 }) improve ({ 2 }) precision ({ 4 }) , ({ 5 }) visual ({ 6 }) information ({ 7 }) is ({ 8 }) used ({ 9 }) to ({ 10 }) re-rank ({ 11 }) the ({ 12 }) returned ({ 13 }) images ({ 14 }) . ({ 15 }) 
# Sentence pair (1976) source length 28 target length 28 alignment score : 1.46805e-07
The idea is to rely on the visual consistency among these images to learn visual classifiers that measure the relevancy between an image and the input query . 
NULL ({ }) The ({ 1 }) idea ({ 2 }) is ({ 3 }) to ({ 4 }) rely ({ 5 }) on ({ 6 }) the ({ 7 }) visual ({ 8 }) consistency ({ 9 }) between ({ 10 }) these ({ 11 }) images ({ 12 }) to ({ 13 }) learn ({ 14 }) visual ({ 15 }) classifiers ({ 16 }) that ({ 17 }) measure ({ 18 }) the ({ 19 }) relevance ({ 20 }) between ({ 21 }) an ({ 22 }) image ({ 23 }) and ({ 24 }) the ({ 25 }) input ({ 26 }) query ({ 27 }) . ({ 28 }) 
# Sentence pair (1977) source length 20 target length 21 alignment score : 2.01297e-14
There are different approaches described in \CITE for re-ranking images containing general objects and faces returned from text-based search engines . 
NULL ({ 6 }) There ({ 1 }) have ({ 2 }) been ({ }) different ({ 3 }) approaches ({ 4 5 }) \CITE ({ 7 }) to ({ 8 }) re-ranking ({ 9 }) images ({ 10 }) containing ({ 11 }) general ({ 12 }) objects ({ 13 }) and ({ 14 }) faces ({ 15 }) returned ({ 16 }) from ({ 17 }) text-based ({ 18 }) search ({ 19 }) engines ({ 20 }) . ({ 21 }) 
# Sentence pair (1978) source length 29 target length 28 alignment score : 1.28917e-17
Work such as \CITE extend topics models using probabilistic Late Semantic Analysis , Latent Dirichlet Allocation , or Hierarchical Dirichlet Process to learn generative model based classifiers . 
NULL ({ 2 3 }) Work ({ 1 }) \CITE ({ 4 }) has ({ }) extended ({ 5 }) to ({ }) topics ({ 6 }) on ({ }) models ({ 7 }) using ({ 8 }) probabilistic ({ 9 }) Late ({ 10 }) Semantic ({ 11 }) Analysis ({ 12 }) , ({ 13 }) Latent ({ 14 }) Dirichlet ({ 15 }) Allocation ({ 16 }) , ({ 17 }) or ({ 18 }) the ({ }) Hierarchical ({ 19 }) Dirichlet ({ 20 }) Process ({ 21 }) to ({ 22 }) learn ({ 23 }) generative ({ 24 25 }) model-based ({ 26 }) classifiers ({ 27 }) . ({ 28 }) 
# Sentence pair (1979) source length 11 target length 11 alignment score : 1.89737e-05
These models can handle noisy image data in some degree . 
NULL ({ 8 }) These ({ 1 }) models ({ 2 }) can ({ 3 }) handle ({ 4 }) noisy ({ 5 }) image ({ 6 }) data ({ 7 }) to ({ }) some ({ 9 }) degree ({ 10 }) . ({ 11 }) 
# Sentence pair (1980) source length 21 target length 19 alignment score : 1.37907e-06
However , they have many parameters needed to be tuned such as number of topics and feature configurations . 
NULL ({ }) However ({ 1 }) , ({ 2 }) they ({ 3 }) have ({ 4 }) many ({ 5 }) parameters ({ 6 }) that ({ }) need ({ 7 }) to ({ 8 }) be ({ 9 }) tuned ({ 10 }) such ({ 11 }) as ({ 12 }) the ({ }) number ({ 13 }) of ({ 14 }) topics ({ 15 }) and ({ 16 }) feature ({ 17 }) configurations ({ 18 }) . ({ 19 }) 
# Sentence pair (1981) source length 26 target length 23 alignment score : 4.07066e-19
In addition , how to select the best topic associated with the input query for identifying target label is still challenging \CITE . 
NULL ({ 15 }) In ({ 1 }) addition ({ 2 }) , ({ 3 }) how ({ 4 }) the ({ 7 }) best ({ 8 }) topic ({ 9 }) is ({ }) selected ({ }) associated ({ 10 }) with ({ 11 }) the ({ 12 }) input ({ 13 }) query ({ 14 }) to ({ 5 }) identify ({ 6 16 }) the ({ }) target ({ 17 }) label ({ 18 }) is ({ 19 }) still ({ 20 }) a ({ }) difficult ({ }) issue ({ 21 }) \CITE ({ 22 }) . ({ 23 }) 
# Sentence pair (1982) source length 17 target length 19 alignment score : 4.99168e-13
In \CITE , Textual information is used to build a text ranker to re-rank the returned images \CITE . 
NULL ({ 3 }) Textual ({ 1 2 }) information ({ 5 }) has ({ 6 }) been ({ 4 }) used ({ 7 }) to ({ 8 }) build ({ 9 }) a ({ 10 }) text ({ 11 }) ranker ({ 12 }) to ({ 13 }) re-rank ({ 14 }) the ({ 15 }) returned ({ 16 }) images ({ 17 }) \CITE ({ 18 }) . ({ 19 }) 
# Sentence pair (1983) source length 24 target length 22 alignment score : 1.10178e-08
The top images in this ranked list are used as positive samples to train visual classifiers using SVM (Support vector machines) . 
NULL ({ }) The ({ 1 }) top ({ 2 }) images ({ 3 }) in ({ 4 }) this ({ 5 }) ranked ({ 6 }) list ({ 7 }) were ({ 8 }) used ({ 9 }) as ({ 10 }) positive ({ 11 }) samples ({ 12 }) to ({ 13 }) train ({ 14 }) visual ({ 15 }) classifiers ({ 16 }) using ({ 17 }) SVM ({ 18 }) ( ({ }) Support ({ 19 }) vector ({ 20 }) machines ({ 21 }) ) ({ }) . ({ 22 }) 
# Sentence pair (1984) source length 13 target length 13 alignment score : 1.46361e-10
This method makes the training data cleaner that leads to performance improvement . 
NULL ({ 8 }) This ({ 1 }) method ({ 2 }) made ({ 3 }) the ({ 4 }) training ({ 5 }) data ({ 6 }) cleaner ({ 7 }) and ({ }) led ({ 9 }) to ({ 10 }) improved ({ 12 }) performance ({ 11 }) . ({ 13 }) 
# Sentence pair (1985) source length 18 target length 21 alignment score : 1.65634e-15
In \CITE , A multiple instance learning framework is used to learn category models from images associated with keywords \CITE . 
NULL ({ 3 }) A ({ 1 4 }) multiple-instance ({ 2 5 6 }) learning ({ 7 }) framework ({ 8 }) has ({ 9 }) been ({ }) used ({ 10 }) to ({ 11 }) learn ({ 12 }) category ({ 13 }) models ({ 14 }) from ({ 15 }) images ({ 16 }) associated ({ 17 }) with ({ 18 }) keywords ({ 19 }) \CITE ({ 20 }) . ({ 21 }) 
# Sentence pair (1986) source length 10 target length 9 alignment score : 0.00389867
The returned images are treated as positive bag . 
NULL ({ }) The ({ 1 }) returned ({ 2 }) images ({ 3 }) were ({ 4 }) treated ({ 5 }) as ({ 6 }) a ({ }) positive ({ 7 }) bag ({ 8 }) . ({ 9 }) 
# Sentence pair (1987) source length 12 target length 12 alignment score : 0.00219108
Negative bags are collected from image sets corresponding to unrelated keywords . 
NULL ({ }) Negative ({ 1 }) bags ({ 2 }) were ({ 3 }) collected ({ 4 }) from ({ 5 }) image ({ 6 }) sets ({ 7 }) corresponding ({ 8 }) to ({ 9 }) unrelated ({ 10 }) keywords ({ 11 }) . ({ 12 }) 
# Sentence pair (1988) source length 10 target length 10 alignment score : 0.00904662
The learned model is used to re-rank the images . 
NULL ({ }) The ({ 1 }) learned ({ 2 }) model ({ 3 }) was ({ 4 }) used ({ 5 }) to ({ 6 }) re-rank ({ 7 }) the ({ 8 }) images ({ 9 }) . ({ 10 }) 
# Sentence pair (1989) source length 8 target length 12 alignment score : 2.28433e-15
The work mentioned above are for re-ranking images containing general objects . 
NULL ({ 5 6 }) These ({ 1 }) researchers ({ 2 }) re-ranked ({ 3 4 7 }) images ({ 8 }) containing ({ 9 }) general ({ 10 }) objects ({ 11 }) . ({ 12 }) 
# Sentence pair (1990) source length 26 target length 29 alignment score : 1.8086e-33
For re-ranking faces , work described in \CITE use Gaussian mixture models to build face recognizers and apply these recognizers back to the input faces for re-ranking \CITE . 
NULL ({ 4 7 }) Gaussian ({ 1 10 }) mixture ({ 11 }) models ({ 12 }) have ({ }) been ({ }) used ({ 6 }) for ({ }) re-ranking ({ 2 }) faces ({ 3 }) to ({ 13 }) build ({ 14 }) face ({ 15 }) recognizers ({ 16 }) and ({ 17 }) apply ({ 18 }) these ({ 19 }) recognizers ({ 5 9 20 }) back ({ 21 }) to ({ 22 }) the ({ 23 }) input ({ 24 }) faces ({ 25 }) for ({ 26 }) re-ranking ({ 27 }) \CITE ({ 8 28 }) . ({ 29 }) 
# Sentence pair (1991) source length 19 target length 23 alignment score : 3.77005e-23
In \CITE , Discriminative approach based models such as SVM and linear discriminant analysis are used instead of Gaussian mixture models \CITE . 
NULL ({ 2 3 }) Discriminative-approach-based ({ 1 6 }) models ({ 7 }) such ({ 8 }) as ({ 9 }) SVM ({ 10 }) and ({ 11 }) linear ({ 12 }) discriminant ({ 13 }) analysis ({ 14 }) have ({ 15 }) been ({ }) used ({ 16 }) instead ({ 17 }) of ({ 18 }) Gaussian ({ 4 19 }) mixture ({ 5 20 }) models ({ 21 }) \CITE ({ 22 }) . ({ 23 }) 
# Sentence pair (1992) source length 17 target length 21 alignment score : 2.9481e-16
In \CITE , A densest graph based method is used for finding the face group relevant to the query \CITE . 
NULL ({ 3 }) A ({ 1 4 }) densest-graph-based ({ 2 5 6 7 }) method ({ 8 }) has ({ 9 }) been ({ }) used ({ 10 }) for ({ 11 }) finding ({ 12 }) the ({ 13 }) face ({ 14 }) group ({ 15 }) relevant ({ 16 }) to ({ 17 }) the ({ 18 }) query ({ 19 }) \CITE ({ 20 }) . ({ 21 }) 
# Sentence pair (1993) source length 12 target length 14 alignment score : 3.75104e-14
As for these approaches , One specific classifier is built for each query . 
NULL ({ 5 }) One ({ 1 6 }) specific ({ 7 }) classifier ({ 8 }) is ({ 9 }) built ({ 10 }) for ({ 11 }) each ({ 12 }) query ({ 13 }) in ({ 2 }) these ({ 3 }) approaches ({ 4 }) . ({ 14 }) 
# Sentence pair (1994) source length 23 target length 22 alignment score : 3.67001e-11
Therefore , to handle a large number of queries , many classifiers must be built which are not suitable in practice . 
NULL ({ }) Therefore ({ 1 }) , ({ 10 }) many ({ 11 }) classifiers ({ 12 }) must ({ 13 }) be ({ 14 }) built ({ 15 }) , ({ }) which ({ 16 }) are ({ 17 }) not ({ 18 }) suitable ({ 19 }) in ({ 20 }) practice ({ 21 }) , ({ 2 }) to ({ 3 }) handle ({ 4 }) a ({ 5 }) large ({ 6 }) number ({ 7 }) of ({ 8 }) queries ({ 9 }) . ({ 22 }) 
# Sentence pair (1995) source length 17 target length 19 alignment score : 1.71775e-11
In \CITE{Krapac10CVPR} , Only one generic classifier is built in advance \CITE and then used for all queries . 
NULL ({ 3 }) Only ({ 1 2 4 }) one ({ 5 }) generic ({ 6 }) classifier ({ 7 }) has ({ 8 }) been ({ }) built ({ 9 }) in ({ 10 }) advance ({ 11 }) \CITE ({ 12 }) and ({ 13 }) then ({ 14 }) used ({ 15 }) for ({ 16 }) all ({ 17 }) queries ({ 18 }) . ({ 19 }) 
# Sentence pair (1996) source length 17 target length 17 alignment score : 1.24512e-05
This generic classifier is a relevance classifier that learns relevancy between an image and the query . 
NULL ({ }) This ({ 1 }) generic ({ 2 }) classifier ({ 3 }) was ({ 4 }) a ({ 5 }) relevance ({ 6 }) classifier ({ 7 }) that ({ 8 }) learned ({ 9 }) relevance ({ 10 }) between ({ 11 }) an ({ 12 }) image ({ 13 }) and ({ 14 }) the ({ 15 }) query ({ 16 }) . ({ 17 }) 
# Sentence pair (1997) source length 26 target length 29 alignment score : 4.84357e-16
As for specific classifiers , Each image is classified as 'class-A' or 'non-class-A' , where 'class-A' is the category associated with the query , for example , 'airplane' . 
NULL ({ 5 25 }) Each ({ 1 6 }) image ({ 7 }) for ({ 2 }) specific ({ 3 }) classifiers ({ 4 }) is ({ 8 }) classified ({ 9 }) as ({ 10 }) 'class-A' ({ 11 }) or ({ 12 }) 'non-class-A' ({ 13 }) , ({ 14 }) where ({ 15 }) 'class-A' ({ 16 }) is ({ 17 }) the ({ 18 }) category ({ 19 }) associated ({ 20 }) with ({ 21 }) the ({ 22 }) query ({ 23 }) , ({ 24 }) e.g. ({ 26 }) , ({ 27 }) 'airplane' ({ 28 }) . ({ 29 }) 
# Sentence pair (1998) source length 18 target length 18 alignment score : 0.0018844
In other words , each specific classifier is associated with one class label implied by the query . 
NULL ({ }) In ({ 1 }) other ({ 2 }) words ({ 3 }) , ({ 4 }) each ({ 5 }) specific ({ 6 }) classifier ({ 7 }) is ({ 8 }) associated ({ 9 }) with ({ 10 }) one ({ 11 }) class ({ 12 }) label ({ 13 }) implied ({ 14 }) by ({ 15 }) the ({ 16 }) query ({ 17 }) . ({ 18 }) 
# Sentence pair (1999) source length 16 target length 16 alignment score : 1.17539e-11
In generic classifier , Each image is classified as relevant or irrelevant to the query . 
NULL ({ 4 }) Each ({ 1 5 }) image ({ 6 }) in ({ }) a ({ }) generic ({ 2 }) classifier ({ 3 }) is ({ 7 }) classified ({ 8 }) as ({ 9 }) relevant ({ 10 }) or ({ 11 }) irrelevant ({ 12 }) to ({ 13 }) the ({ 14 }) query ({ 15 }) . ({ 16 }) 
# Sentence pair (2000) source length 16 target length 16 alignment score : 9.68853e-06
Therefore , it is independent to class labels and can be used for any query . 
NULL ({ }) Therefore ({ 1 }) , ({ 2 }) it ({ 3 }) is ({ 4 }) independent ({ 5 }) of ({ 6 }) class ({ 7 }) labels ({ 8 }) and ({ 9 }) can ({ 10 }) be ({ 11 }) used ({ 12 }) for ({ 13 }) any ({ 14 }) query ({ 15 }) . ({ 16 }) 
# Sentence pair (2001) source length 18 target length 18 alignment score : 9.97176e-07
This method works well for objects such as car , flag , but fails to handle faces . 
NULL ({ 10 }) This ({ 1 }) method ({ 2 }) works ({ 3 }) well ({ 4 }) for ({ 5 }) objects ({ 6 }) such ({ 7 }) as ({ 8 }) cars ({ 9 }) and ({ }) flags ({ 11 }) , ({ 12 }) but ({ 13 }) fails ({ 14 }) to ({ 15 }) handle ({ 16 }) faces ({ 17 }) . ({ 18 }) 
# Sentence pair (2002) source length 9 target length 11 alignment score : 3.99277e-06
Our method is inspired by the generic classifier based approach . 
NULL ({ }) Our ({ 1 }) method ({ 2 }) was ({ 3 }) inspired ({ 4 }) by ({ 5 }) the ({ 6 }) generic-classifier-based ({ 7 8 9 }) approach ({ 10 }) . ({ 11 }) 
# Sentence pair (2003) source length 36 target length 36 alignment score : 1.79631e-13
We extend it by two means : first , query-dependent features specific for faces are proposed , and second , the training data for learning the generic classifier is collected automatically by mining video archives . 
NULL ({ }) We ({ 1 }) extended ({ 2 }) it ({ 3 }) in ({ 4 }) two ({ 5 }) ways ({ 6 }) : ({ 7 }) first ({ 8 }) , ({ 9 }) query-dependent ({ 10 }) features ({ 11 }) specific ({ 12 }) to ({ 13 }) faces ({ 14 }) are ({ 15 }) proposed ({ 16 }) , ({ 17 }) and ({ 18 }) second ({ 19 }) , ({ 20 }) the ({ 21 }) training ({ 22 }) data ({ 23 }) for ({ 24 }) learning ({ 25 }) the ({ 26 }) generic ({ 27 }) classifier ({ 28 }) are ({ 29 }) collected ({ 30 }) automatically ({ 31 }) by ({ 32 }) mining ({ 33 }) video ({ 34 }) archives ({ 35 }) . ({ 36 }) 
# Sentence pair (2004) source length 32 target length 34 alignment score : 3.70985e-13
Given a set of faces returned by any search engine for a queried person ( e .g . 'George Bush' ) , our task is to re-rank these faces to improve the precision . 
NULL ({ 18 32 }) Given ({ 1 }) a ({ 2 }) set ({ 3 }) of ({ 4 }) faces ({ 5 }) returned ({ 6 }) by ({ 7 }) any ({ 8 }) search ({ 9 }) engine ({ 10 }) for ({ 11 }) a ({ 12 }) queried ({ 13 }) person ({ 14 }) ( ({ 15 }) e.g. ({ 16 17 }) , ({ }) 'George ({ 19 }) Bush' ({ 20 }) ) ({ 21 }) , ({ 22 }) our ({ 23 }) task ({ 24 }) is ({ 25 }) to ({ 26 }) re-rank ({ 27 }) these ({ 28 }) faces ({ 29 }) to ({ 30 }) improve ({ 31 }) precision ({ 33 }) . ({ 34 }) 
# Sentence pair (2005) source length 33 target length 33 alignment score : 3.72415e-08
To this end , we extract query-dependent feature for each face and then use the generic classifier trained in advance to predict scores representing the relevance between that face and the query . 
NULL ({ }) To ({ 1 }) this ({ 2 }) end ({ 3 }) , ({ 4 }) we ({ 5 }) extract ({ 6 }) query-dependent ({ 7 }) features ({ 8 }) for ({ 9 }) each ({ 10 }) face ({ 11 }) and ({ 12 }) then ({ 13 }) use ({ 14 }) the ({ 15 }) generic ({ 16 }) classifier ({ 17 }) trained ({ 18 }) in ({ 19 }) advance ({ 20 }) to ({ 21 }) predict ({ 22 }) scores ({ 23 }) representing ({ 24 }) the ({ 25 }) relevance ({ 26 }) between ({ 27 }) that ({ 28 }) face ({ 29 }) and ({ 30 }) the ({ 31 }) query ({ 32 }) . ({ 33 }) 
# Sentence pair (2006) source length 9 target length 9 alignment score : 0.0305825
These scores are sorted and used for re-ranking . 
NULL ({ }) These ({ 1 }) scores ({ 2 }) are ({ 3 }) sorted ({ 4 }) and ({ 5 }) used ({ 6 }) for ({ 7 }) re-ranking ({ 8 }) . ({ 9 }) 
# Sentence pair (2007) source length 16 target length 16 alignment score : 4.68801e-05
The ranked list is then return to users as shown in Figure \REF( b ) . 
NULL ({ }) The ({ 1 }) ranked ({ 2 }) list ({ 3 }) is ({ 4 }) then ({ 5 }) returned ({ 6 }) to ({ 7 }) users ({ 8 }) as ({ 9 }) shown ({ 10 }) in ({ 11 }) Figure ({ 12 }) \REF( ({ 13 }) b ({ 14 }) ) ({ 15 }) . ({ 16 }) 
# Sentence pair (2008) source length 26 target length 28 alignment score : 3.3279e-14
This approach is different from existing approaches such as \CITE as shown in Figure \REF( a ) in which one specific classifier is built for each query . 
NULL ({ 8 9 11 }) This ({ 1 }) approach ({ 2 }) is ({ 3 }) different ({ 4 }) from ({ 5 }) the ({ }) existing ({ 6 }) approaches ({ 7 }) \CITE ({ 10 }) shown ({ 12 }) in ({ 13 }) Figure ({ 14 }) \REF( ({ 15 }) a ({ 16 }) ) ({ 17 }) in ({ 18 }) which ({ 19 }) one ({ 20 }) specific ({ 21 }) classifier ({ 22 }) is ({ 23 }) built ({ 24 }) for ({ 25 }) each ({ 26 }) query ({ 27 }) . ({ 28 }) 
# Sentence pair (2009) source length 41 target length 40 alignment score : 1.91999e-11
To build the specific classifier for re-ranking faces returned by the query of 'personX' , each face is represented by the query-independent feature such as pixel intensity around facial features such as eyes , nose , and mouth \CITE . 
NULL ({ }) To ({ 1 }) build ({ 2 }) a ({ 3 }) specific ({ 4 }) classifier ({ 5 }) for ({ 6 }) re-ranking ({ 7 }) faces ({ 8 }) returned ({ 9 }) by ({ 10 }) the ({ 11 }) query ({ 12 }) of ({ 13 }) 'personX' ({ 14 }) , ({ 15 }) each ({ 16 }) face ({ 17 }) is ({ 18 }) represented ({ 19 }) by ({ 20 }) a ({ 21 }) query-independent ({ 22 }) feature ({ 23 }) such ({ 24 }) as ({ 25 }) pixel ({ 26 }) intensity ({ 27 }) around ({ 28 }) facial ({ 29 }) features ({ 30 }) such ({ 31 }) as ({ 32 }) the ({ }) eyes ({ 33 }) , ({ 34 }) nose ({ 35 }) , ({ 36 }) and ({ 37 }) mouth ({ 38 }) \CITE ({ 39 }) . ({ 40 }) 
# Sentence pair (2010) source length 19 target length 19 alignment score : 0.00075184
The label for each face is 'personX' or 'non-personX' meaning that it is relevant or irrelevant to 'personX' . 
NULL ({ }) The ({ 1 }) label ({ 2 }) for ({ 3 }) each ({ 4 }) face ({ 5 }) is ({ 6 }) 'personX' ({ 7 }) or ({ 8 }) 'non-personX' ({ 9 }) meaning ({ 10 }) that ({ 11 }) it ({ 12 }) is ({ 13 }) relevant ({ 14 }) or ({ 15 }) irrelevant ({ 16 }) to ({ 17 }) 'personX' ({ 18 }) . ({ 19 }) 
# Sentence pair (2011) source length 22 target length 23 alignment score : 1.15147e-17
Meanwhile , to build the generic classifier which is independent with any \textit{'personX'} , each face is represented by the query-dependent feature . 
NULL ({ 2 }) Further ({ 1 }) , ({ 14 }) each ({ 15 }) face ({ 16 }) is ({ 17 }) represented ({ 18 }) by ({ 19 }) the ({ 20 }) query-dependent ({ 21 }) feature ({ 22 }) to ({ 3 }) build ({ 4 }) a ({ 5 }) generic ({ 6 }) classifier ({ 7 }) that ({ 8 }) is ({ 9 }) independent ({ 10 }) of ({ 11 }) any ({ 12 }) 'personX' ({ 13 }) . ({ 23 }) 
# Sentence pair (2012) source length 13 target length 13 alignment score : 0.00920377
The label for each face is relevant or irrelevant to the query . 
NULL ({ }) The ({ 1 }) label ({ 2 }) for ({ 3 }) each ({ 4 }) face ({ 5 }) is ({ 6 }) relevant ({ 7 }) or ({ 8 }) irrelevant ({ 9 }) to ({ 10 }) the ({ 11 }) query ({ 12 }) . ({ 13 }) 
# Sentence pair (2013) source length 10 target length 10 alignment score : 0.00647248
The query-dependent feature is used to encode this relevancy . 
NULL ({ }) The ({ 1 }) query-dependent ({ 2 }) feature ({ 3 }) is ({ 4 }) used ({ 5 }) to ({ 6 }) encode ({ 7 }) this ({ 8 }) relevance ({ 9 }) . ({ 10 }) 
# Sentence pair (2014) source length 10 target length 13 alignment score : 1.24724e-14
In \CITE , the Query-dependent features using textual information are proposed \CITE . 
NULL ({ 2 3 4 }) Query-dependent ({ 1 5 }) features ({ 6 }) using ({ 7 }) textual ({ 8 }) information ({ 9 }) has ({ }) been ({ 10 }) proposed ({ 11 }) \CITE ({ 12 }) . ({ 13 }) 
# Sentence pair (2015) source length 35 target length 36 alignment score : 1.09189e-11
Each feature is treated as binary indicating the presence or absence of the query terms in textual data associated with the input image , for example , filename , image title , and nearby text . 
NULL ({ 13 25 }) Each ({ 1 }) feature ({ 2 }) was ({ 3 }) treated ({ 4 }) as ({ 5 }) binary ({ 6 }) indicating ({ 7 }) the ({ 8 }) presence ({ 9 }) or ({ 10 }) absence ({ 11 }) of ({ 12 }) query ({ 14 }) terms ({ 15 }) in ({ 16 }) the ({ }) textual ({ 17 }) data ({ 18 }) associated ({ 19 }) with ({ 20 }) the ({ 21 }) input ({ 22 }) image ({ 23 }) , ({ 24 }) e.g. ({ 26 }) , ({ 27 }) filenames ({ 28 }) , ({ 29 }) image ({ 30 }) titles ({ 31 }) , ({ 32 }) and ({ 33 }) nearby ({ 34 }) text ({ 35 }) . ({ 36 }) 
# Sentence pair (2016) source length 30 target length 32 alignment score : 2.57357e-15
Extending this query-dependent feature for using visual information is not trivial since we can not compute the presence and absence of the query term such as 'George Bush' in each face . 
NULL ({ 22 }) Extending ({ 1 }) this ({ 2 }) query-dependent ({ 3 }) feature ({ 4 }) to ({ 5 }) use ({ 6 }) visual ({ 7 }) information ({ 8 }) is ({ 9 }) not ({ 10 }) trivial ({ 11 }) since ({ 12 }) we ({ 13 }) cannot ({ 14 15 }) compute ({ 16 }) the ({ 17 }) presence ({ 18 }) or ({ 19 }) absence ({ 20 }) of ({ 21 }) query ({ 23 }) terms ({ 24 }) such ({ 25 }) as ({ 26 }) 'George ({ 27 }) Bush' ({ 28 }) in ({ 29 }) each ({ 30 }) face ({ 31 }) . ({ 32 }) 
# Sentence pair (2017) source length 13 target length 15 alignment score : 8.56741e-13
In \CITE , Each image \CITE is represented as a set of visual words . 
NULL ({ 2 3 }) Each ({ 1 4 }) image ({ 5 }) in ({ }) \CITE ({ 6 }) is ({ 7 }) represented ({ 8 }) as ({ 9 }) a ({ 10 }) set ({ 11 }) of ({ 12 }) visual ({ 13 }) words ({ 14 }) . ({ 15 }) 
# Sentence pair (2018) source length 21 target length 22 alignment score : 1.48947e-06
The top- \MATH visual words that are strongly associated with the set of the returned images for the query are selected . 
NULL ({ 14 }) The ({ 1 }) top- ({ 2 }) \MATH ({ 3 }) visual ({ 4 }) words ({ 5 }) that ({ 6 }) are ({ 7 }) strongly ({ 8 }) associated ({ 9 }) with ({ 10 }) the ({ 11 }) set ({ 12 }) of ({ 13 }) returned ({ 15 }) images ({ 16 }) for ({ 17 }) the ({ 18 }) query ({ 19 }) are ({ 20 }) selected ({ 21 }) . ({ 22 }) 
# Sentence pair (2019) source length 22 target length 22 alignment score : 0.000395689
The binary features for each image are computed by evaluating the presence and absence of these visual words in that image . 
NULL ({ }) The ({ 1 }) binary ({ 2 }) features ({ 3 }) for ({ 4 }) each ({ 5 }) image ({ 6 }) are ({ 7 }) computed ({ 8 }) by ({ 9 }) evaluating ({ 10 }) the ({ 11 }) presence ({ 12 }) and ({ 13 }) absence ({ 14 }) of ({ 15 }) these ({ 16 }) visual ({ 17 }) words ({ 18 }) in ({ 19 }) that ({ 20 }) image ({ 21 }) . ({ 22 }) 
# Sentence pair (2020) source length 30 target length 28 alignment score : 3.40476e-14
Since this method is suitable for general objects rather than faces , we proposed another method described below for extracting query-dependent features to train the generic classifier . 
NULL ({ 19 }) Since ({ 1 }) this ({ 2 }) method ({ 3 }) is ({ 4 }) suitable ({ 5 }) for ({ 6 }) general ({ 7 }) objects ({ 8 }) rather ({ 9 }) than ({ 10 }) faces ({ 11 }) , ({ 12 }) we ({ 13 }) propose ({ 14 }) another ({ 15 }) method ({ 16 }) of ({ }) extracting ({ 20 }) query-dependent ({ 21 }) features ({ 22 }) to ({ 23 }) train ({ 24 }) the ({ 25 }) generic ({ 26 }) classifier ({ 27 }) that ({ }) is ({ }) described ({ 17 }) below ({ 18 }) . ({ 28 }) 
# Sentence pair (2021) source length 32 target length 32 alignment score : 1.55152e-23
To be able to model the relevance between a face and the given query , We assume that there is visual consistency among faces returned by search engines for that query . 
NULL ({ 12 15 20 }) We ({ 1 }) assumed ({ 17 }) that ({ 18 }) there ({ 19 }) would ({ }) be ({ 2 }) visual ({ 21 }) consistency ({ 22 }) between ({ 23 }) faces ({ 24 }) returned ({ 25 }) by ({ 26 }) search ({ 27 }) engines ({ 28 }) for ({ 29 }) a ({ }) query ({ 14 }) to ({ 16 }) be ({ }) able ({ 3 }) to ({ 4 }) model ({ 5 }) the ({ 6 }) relevance ({ 7 }) between ({ 8 }) a ({ 9 }) face ({ 10 }) and ({ 11 }) that ({ 30 }) given ({ 13 }) query ({ 31 }) . ({ 32 }) 
# Sentence pair (2022) source length 20 target length 19 alignment score : 5.48151e-07
In the other word , we assume faces that are relevant to the query form the largest cluster . 
NULL ({ }) In ({ 1 }) the ({ 2 }) other ({ 3 }) words ({ 4 }) , ({ 5 }) we ({ 6 }) assumed ({ 7 }) faces ({ 8 }) that ({ 9 }) were ({ 10 }) relevant ({ 11 }) to ({ 12 }) the ({ 13 }) query ({ 14 }) would ({ }) form ({ 15 }) the ({ 16 }) largest ({ 17 }) cluster ({ 18 }) . ({ 19 }) 
# Sentence pair (2023) source length 34 target length 34 alignment score : 2.41169e-07
Note that finding such cluster is still difficult since the number of clusters is not known in advance and the accuracy of clustering algorithms always depends on the discriminative power of feature representation . 
NULL ({ }) Note ({ 1 }) that ({ 2 }) finding ({ 3 }) such ({ 4 }) clusters ({ 5 }) is ({ 6 }) still ({ 7 }) difficult ({ 8 }) since ({ 9 }) the ({ 10 }) number ({ 11 }) of ({ 12 }) clusters ({ 13 }) is ({ 14 }) not ({ 15 }) known ({ 16 }) in ({ 17 }) advance ({ 18 }) and ({ 19 }) the ({ 20 }) accuracy ({ 21 }) of ({ 22 }) clustering ({ 23 }) algorithms ({ 24 }) always ({ 25 }) depends ({ 26 }) on ({ 27 }) the ({ 28 }) discriminative ({ 29 }) power ({ 30 }) of ({ 31 }) feature ({ 32 }) representation ({ 33 }) . ({ 34 }) 
# Sentence pair (2024) source length 15 target length 15 alignment score : 9.30314e-05
This assumption is widely accepted in most of the work of this field \CITE . 
NULL ({ }) This ({ 1 }) assumption ({ 2 }) is ({ 3 }) widely ({ 4 }) accepted ({ 5 }) in ({ 6 }) most ({ 7 }) of ({ 8 }) the ({ 9 }) work ({ 10 }) in ({ 11 }) this ({ 12 }) field ({ 13 }) \CITE ({ 14 }) . ({ 15 }) 
# Sentence pair (2025) source length 30 target length 29 alignment score : 2.22393e-12
We consider the problem of finding relevant and irrelevant faces in the input set as the problem of outlier detection \CITE that is popular in data mining community . 
NULL ({ }) We ({ 1 }) consider ({ 2 }) the ({ 3 }) problem ({ 4 }) of ({ 5 }) finding ({ 6 }) relevant ({ 7 }) and ({ 8 }) irrelevant ({ 9 }) faces ({ 10 }) in ({ 11 }) the ({ 12 }) input ({ 13 }) set ({ 14 }) to ({ }) be ({ 15 }) the ({ 16 }) problem ({ 17 }) of ({ 18 }) outlier ({ 19 }) detection ({ 20 }) \CITE ({ 21 }) that ({ 22 }) is ({ 23 }) popular ({ 24 }) in ({ 25 }) the ({ }) data-mining ({ 26 27 }) community ({ 28 }) . ({ 29 }) 
# Sentence pair (2026) source length 26 target length 26 alignment score : 1.83422e-12
We first describe several distance based outlier detection methods that use the distance to the \MATH -nearest neighbors to determine observations as outliers or non-outliers . 
NULL ({ }) We ({ 1 }) first ({ 2 }) describe ({ 3 }) several ({ 4 }) distance-based ({ 5 6 }) methods ({ 9 }) of ({ }) outlier ({ 7 }) detection ({ 8 }) that ({ 10 }) use ({ 11 }) the ({ 12 }) distance ({ 13 }) to ({ 14 }) the ({ 15 }) \MATH ({ 16 }) -nearest ({ 17 }) neighbors ({ 18 }) to ({ 19 }) determine ({ 20 }) observations ({ 21 }) as ({ 22 }) outliers ({ 23 }) or ({ 24 }) non-outliers ({ 25 }) . ({ 26 }) 
# Sentence pair (2027) source length 11 target length 11 alignment score : 3.25096e-06
Then the adaptation is proposed to form the query-dependent feature . 
NULL ({ 2 }) Then ({ 1 }) , ({ }) adaptation ({ 3 }) is ({ 4 }) proposed ({ 5 }) to ({ 6 }) form ({ 7 }) a ({ 8 }) query-dependent ({ 9 }) feature ({ 10 }) . ({ 11 }) 
# Sentence pair (2028) source length 40 target length 41 alignment score : 9.78787e-16
Given a threshold \MATH , for each point \MATH , we examine number of points \MATH so that \MATH , where \MATH is the distance ( e .g . Euclidean distance ) between \MATH and \MATH in the feature space . 
NULL ({ 2 29 }) Given ({ 1 }) threshold ({ 3 }) \MATH ({ 4 }) , ({ 5 }) for ({ 6 }) each ({ 7 }) point ({ 8 }) \MATH ({ 9 }) , ({ 10 }) we ({ 11 }) examine ({ 12 }) the ({ }) number ({ 13 }) of ({ 14 }) points ({ 15 }) \MATH ({ 16 }) so ({ 17 }) that ({ 18 }) \MATH ({ 19 }) , ({ 20 }) where ({ 21 }) \MATH ({ 22 }) is ({ 23 }) the ({ 24 }) distance ({ 25 }) ( ({ 26 }) e.g. ({ 27 28 }) , ({ }) Euclidean ({ 30 }) distance ({ 31 }) ) ({ 32 }) between ({ 33 }) \MATH ({ 34 }) and ({ 35 }) \MATH ({ 36 }) in ({ 37 }) the ({ 38 }) feature ({ 39 }) space ({ 40 }) . ({ 41 }) 
# Sentence pair (2029) source length 31 target length 32 alignment score : 2.4348e-10
This number of points \MATH is called the neighborhood score of \MATH and is defined as follows : \MATH where \MATH is the total number of points of the input dataset . 
NULL ({ 17 }) This ({ 1 }) number ({ 2 }) of ({ 3 }) points ({ 4 }) \MATH ({ 5 }) is ({ 6 }) called ({ 7 }) the ({ 8 }) neighborhood ({ 9 }) score ({ 10 }) of ({ 11 }) \MATH ({ 12 }) and ({ 13 }) is ({ 14 }) defined ({ 15 }) as ({ 16 }) : ({ 18 }) \MATH ({ 19 }) where ({ 20 }) \MATH ({ 21 }) is ({ 22 }) the ({ 23 }) total ({ 24 }) number ({ 25 }) of ({ 26 }) points ({ 27 }) in ({ 28 }) the ({ 29 }) input ({ 30 }) dataset ({ 31 }) . ({ 32 }) 
# Sentence pair (2030) source length 30 target length 30 alignment score : 2.57855e-08
A low value of \MATH indicates \MATH is a candidate of outliers , while a high value of \MATH indicates \MATH is a member of one strong association cluster . 
NULL ({ }) A ({ 1 }) low ({ 2 }) value ({ 3 }) for ({ 4 }) \MATH ({ 5 }) indicates ({ 6 }) \MATH ({ 7 }) is ({ 8 }) a ({ 9 }) candidate ({ 10 }) of ({ 11 }) outliers ({ 12 }) , ({ 13 }) while ({ 14 }) a ({ 15 }) high ({ 16 }) value ({ 17 }) for ({ 18 }) \MATH ({ 19 }) indicates ({ 20 }) \MATH ({ 21 }) is ({ 22 }) a ({ 23 }) member ({ 24 }) of ({ 25 }) one ({ 26 }) strong ({ 27 }) association ({ 28 }) cluster ({ 29 }) . ({ 30 }) 
# Sentence pair (2031) source length 21 target length 20 alignment score : 1.76616e-06
In practice , it is difficult to know \MATH because it depends on underlying distribution of the input dataset . 
NULL ({ }) In ({ 1 }) practice ({ 2 }) , ({ 3 }) it ({ 4 }) is ({ 5 }) difficult ({ 6 }) to ({ 7 }) know ({ 8 }) \MATH ({ 9 }) because ({ 10 }) this ({ 11 }) depends ({ 12 }) on ({ 13 }) the ({ }) underlying ({ 14 }) distribution ({ 15 }) of ({ 16 }) the ({ 17 }) input ({ 18 }) dataset ({ 19 }) . ({ 20 }) 
# Sentence pair (2032) source length 37 target length 38 alignment score : 2.80336e-10
For each point \MATH , find its \MATH -nearest neighbors \MATH , the distance score of \MATH is the sum of the distances between \MATH and its \MATH -nearest neighbors \MATH and is defined as follows : \MATH 
NULL ({ 36 }) For ({ 1 }) each ({ 2 }) point ({ 3 }) \MATH ({ 4 }) , ({ 5 }) find ({ 6 }) its ({ 7 }) \MATH ({ 8 }) -nearest ({ 9 }) neighbors ({ 10 }) \MATH ({ 11 }) ; ({ 12 }) the ({ 13 }) distance ({ 14 }) score ({ 15 }) of ({ 16 }) \MATH ({ 17 }) is ({ 18 }) the ({ 19 }) sum ({ 20 }) of ({ 21 }) the ({ 22 }) distances ({ 23 }) between ({ 24 }) \MATH ({ 25 }) and ({ 26 }) its ({ 27 }) \MATH ({ 28 }) -nearest ({ 29 }) neighbors ({ 30 }) \MATH ({ 31 }) and ({ 32 }) is ({ 33 }) defined ({ 34 }) as ({ 35 }) : ({ 37 }) \MATH ({ 38 }) 
# Sentence pair (2033) source length 29 target length 28 alignment score : 1.80443e-10
Points with larger values for \MATH have more sparse neighborhoods and are likely outliers than points belonging to dense clusters which usually have lower values of \MATH . 
NULL ({ }) Points ({ 1 }) with ({ 2 }) larger ({ 3 }) values ({ 4 }) for ({ 5 }) \MATH ({ 6 }) have ({ 7 }) sparser ({ 8 }) neighborhoods ({ 9 10 }) and ({ 11 }) are ({ 12 }) more ({ }) likely ({ 13 }) outliers ({ 14 }) than ({ 15 }) points ({ 16 }) belonging ({ 17 }) to ({ 18 }) dense ({ 19 }) clusters ({ 20 }) , ({ }) which ({ 21 }) usually ({ 22 }) have ({ 23 }) lower ({ 24 }) values ({ 25 }) for ({ 26 }) \MATH ({ 27 }) . ({ 28 }) 
# Sentence pair (2034) source length 20 target length 19 alignment score : 0.000151041
Similar to nearest neighbor score , it is difficult to determine the appropriate \MATH value for each dataset . 
NULL ({ }) Similar ({ 1 }) to ({ 2 }) the ({ }) nearest ({ 3 }) neighbor ({ 4 }) score ({ 5 }) , ({ 6 }) it ({ 7 }) is ({ 8 }) difficult ({ 9 }) to ({ 10 }) determine ({ 11 }) the ({ 12 }) appropriate ({ 13 }) \MATH ({ 14 }) value ({ 15 }) for ({ 16 }) each ({ 17 }) dataset ({ 18 }) . ({ 19 }) 
# Sentence pair (2035) source length 21 target length 19 alignment score : 1.33386e-06
We consider the generic classifier as an outlier classifier that classifies an input sample as outlier or non-outlier . 
NULL ({ }) We ({ 1 }) consider ({ 2 }) the ({ 3 }) generic ({ 4 }) classifier ({ 5 }) as ({ 6 }) an ({ 7 }) outlier ({ 8 }) classifier ({ 9 }) that ({ 10 }) classifies ({ 11 }) an ({ 12 }) input ({ 13 }) sample ({ 14 }) as ({ 15 }) an ({ }) outlier ({ 16 }) or ({ 17 }) a ({ }) non-outlier ({ 18 }) . ({ 19 }) 
# Sentence pair (2036) source length 29 target length 30 alignment score : 1.42984e-25
In our framework , Each face is an sample , and non-outliers / outliers mean faces relevant / irrelevant to the query ( i .e . target person ) . 
NULL ({ 4 26 }) Each ({ 5 }) face ({ 6 }) in ({ 1 }) our ({ 2 }) framework ({ 3 }) is ({ 7 }) a ({ 8 }) sample ({ 9 }) , ({ 10 }) and ({ 11 }) non-outliers ({ 12 }) / ({ 13 }) outliers ({ 14 }) mean ({ 15 }) faces ({ 16 }) are ({ }) relevant ({ 17 }) / ({ 18 }) irrelevant ({ 19 }) to ({ 20 }) the ({ 21 }) query ({ 22 }) ( ({ 23 }) i.e. ({ 24 }) , ({ 25 }) target ({ 27 }) person ({ 28 }) ) ({ 29 }) . ({ 30 }) 
# Sentence pair (2037) source length 34 target length 33 alignment score : 8.63681e-13
As described above , \MATH and \MATH of outliers and non-outliers might have distributions shown in Figure \REF , these scores can be used as feature values to discriminate non-outliers and outliers . 
NULL ({ }) As ({ 1 }) described ({ 2 }) above ({ 3 }) , ({ 4 }) the ({ }) \MATH ({ 5 }) and ({ 6 }) \MATH ({ 7 }) of ({ 8 }) outliers ({ 9 }) and ({ 10 }) non-outliers ({ 11 }) might ({ 12 }) have ({ 13 }) the ({ }) distributions ({ 14 15 }) in ({ 16 }) Figure ({ 17 }) \REF ({ 18 }) ; ({ 19 }) these ({ 20 }) scores ({ 21 }) can ({ 22 }) be ({ 23 }) used ({ 24 }) as ({ 25 }) feature ({ 26 }) values ({ 27 }) to ({ 28 }) discriminate ({ 29 }) non-outliers ({ 30 }) from ({ 31 }) outliers ({ 32 }) . ({ 33 }) 
# Sentence pair (2038) source length 29 target length 28 alignment score : 1.18242e-05
From this observation , the feature vector is formed by varying parameters such as \MATH and \MATH in formula of \MATH and \MATH as follows : \MATH . 
NULL ({ }) From ({ 1 }) this ({ 2 }) observation ({ 3 }) , ({ 4 }) the ({ 5 }) feature ({ 6 }) vector ({ 7 }) is ({ 8 }) formed ({ 9 }) by ({ 10 }) varying ({ 11 }) parameters ({ 12 }) such ({ 13 }) as ({ 14 }) \MATH ({ 15 }) and ({ 16 }) \MATH ({ 17 }) in ({ 18 }) the ({ }) formula ({ 19 }) of ({ 20 }) \MATH ({ 21 }) and ({ 22 }) \MATH ({ 23 }) as ({ 24 }) follows ({ 25 }) : ({ 26 }) \MATH ({ 27 }) . ({ 28 }) 
# Sentence pair (2039) source length 21 target length 24 alignment score : 7.08311e-16
In order to train the relevance classifier using supervised learning methods such as SVM , it requires a sufficient number of training samples . 
NULL ({ 2 15 }) It ({ 1 }) requires ({ 16 17 }) a ({ 18 }) sufficient ({ 19 }) number ({ 20 }) of ({ 21 }) training ({ 22 }) samples ({ 23 }) to ({ 3 }) train ({ 4 }) the ({ 5 }) relevance ({ 6 }) classifier ({ 7 }) using ({ 8 }) supervised ({ 9 }) learning ({ 10 }) methods ({ 11 }) such ({ 12 }) as ({ 13 }) SVM ({ 14 }) . ({ 24 }) 
# Sentence pair (2040) source length 21 target length 22 alignment score : 4.36127e-16
To collect training samples , The simplest way \CITE is we pick many names , and pass them to search engines . 
NULL ({ 5 11 }) The ({ 6 }) simplest ({ 7 }) way ({ 8 }) \CITE ({ 9 }) of ({ 1 }) collecting ({ 2 }) training ({ 3 }) samples ({ 4 }) is ({ 10 }) to ({ }) pick ({ 12 }) many ({ 13 }) names ({ 14 }) , ({ 15 }) and ({ 16 }) pass ({ 17 }) them ({ 18 }) to ({ 19 }) search ({ 20 }) engines ({ 21 }) . ({ 22 }) 
# Sentence pair (2041) source length 24 target length 22 alignment score : 8.41038e-07
After collecting the returned faces , we manually label each face whether it is relevant to the input query or not . 
NULL ({ }) After ({ 1 }) collecting ({ 2 }) the ({ 3 }) returned ({ 4 }) faces ({ 5 }) , ({ 6 }) we ({ 7 }) manually ({ 8 }) label ({ 9 }) each ({ 10 }) face ({ 11 }) as ({ }) to ({ }) whether ({ 12 }) it ({ 13 }) is ({ 14 }) relevant ({ 15 }) to ({ 16 }) the ({ 17 }) input ({ 18 }) query ({ 19 }) or ({ 20 }) not ({ 21 }) . ({ 22 }) 
# Sentence pair (2042) source length 11 target length 11 alignment score : 2.79829e-07
It is a tedious task and requires human labor cost . 
NULL ({ }) This ({ 1 }) is ({ 2 }) a ({ 3 }) tedious ({ 4 }) task ({ 5 }) and ({ 6 }) involves ({ 7 }) a ({ }) human-labor ({ 8 9 }) cost ({ 10 }) . ({ 11 }) 
# Sentence pair (2043) source length 15 target length 15 alignment score : 9.92062e-06
We propose another approach to automatically collect training samples for training the relevant classifier . 
NULL ({ }) We ({ 1 }) propose ({ 2 }) another ({ 3 }) approach ({ 4 }) to ({ 5 }) automatically ({ 6 }) collecting ({ 7 }) training ({ 8 }) samples ({ 9 }) to ({ 10 }) train ({ 11 }) the ({ 12 }) relevant ({ 13 }) classifier ({ 14 }) . ({ 15 }) 
# Sentence pair (2044) source length 7 target length 7 alignment score : 0.000106436
This approach consists of two steps : 
NULL ({ }) This ({ 1 }) approach ({ 2 }) consists ({ 3 }) of ({ 4 }) two ({ 5 }) steps ({ 6 }) . ({ 7 }) 
# Sentence pair (2045) source length 39 target length 39 alignment score : 1.734e-11
First , by mining video archives , we automatically collect a set of faces of \MATH different persons \MATH , where \MATH is the set of faces of person \MATH , and \MATH is the number of persons; and 
NULL ({ }) First ({ 1 }) , ({ 2 }) by ({ 3 }) mining ({ 4 }) video ({ 5 }) archives ({ 6 }) , ({ 7 }) we ({ 8 }) automatically ({ 9 }) collect ({ 10 }) a ({ 11 }) set ({ 12 }) of ({ 13 }) faces ({ 14 }) of ({ 15 }) \MATH ({ 16 }) different ({ 17 }) people ({ 18 }) \MATH ({ 19 }) , ({ 20 }) where ({ 21 }) \MATH ({ 22 }) is ({ 23 }) the ({ 24 }) set ({ 25 }) of ({ 26 }) faces ({ 27 }) of ({ 28 }) person ({ 29 }) \MATH ({ 30 }) , ({ 31 }) and ({ 32 }) \MATH ({ 33 }) is ({ 34 }) the ({ 35 }) number ({ 36 }) of ({ 37 }) people ({ 38 }) . ({ 39 }) 
# Sentence pair (2046) source length 31 target length 31 alignment score : 1.36767e-05
Second , we generate a set of subsets \MATH , where \MATH is the set of faces that is picked from \MATH , and \MATH is the number of subsets . 
NULL ({ }) Second ({ 1 }) , ({ 2 }) we ({ 3 }) generate ({ 4 }) a ({ 5 }) set ({ 6 }) of ({ 7 }) subsets ({ 8 }) \MATH ({ 9 }) , ({ 10 }) where ({ 11 }) \MATH ({ 12 }) is ({ 13 }) the ({ 14 }) set ({ 15 }) of ({ 16 }) faces ({ 17 }) that ({ 18 }) is ({ 19 }) picked ({ 20 }) from ({ 21 }) \MATH ({ 22 }) , ({ 23 }) and ({ 24 }) \MATH ({ 25 }) is ({ 26 }) the ({ 27 }) number ({ 28 }) of ({ 29 }) subsets ({ 30 }) . ({ 31 }) 
# Sentence pair (2047) source length 12 target length 11 alignment score : 0.00276102
The restriction is the assumption of visual consistency is satisfied . 
NULL ({ }) The ({ 1 }) restriction ({ 2 }) is ({ 3 }) that ({ }) the ({ 4 }) assumption ({ 5 }) of ({ 6 }) visual ({ 7 }) consistency ({ 8 }) is ({ 9 }) satisfied ({ 10 }) . ({ 11 }) 
# Sentence pair (2048) source length 38 target length 36 alignment score : 3.55409e-11
In other words , as shown in Figure \REF , \MATH might have several face clusters and the largest cluster is equivalent to the faces relevant to the query if returning by a search engine . 
NULL ({ }) In ({ 1 }) other ({ 2 }) words ({ 3 }) , ({ 4 }) as ({ 5 }) seen ({ 6 }) in ({ 7 }) Figure ({ 8 }) \REF ({ 9 }) , ({ 10 }) \MATH ({ 11 }) might ({ 12 }) have ({ 13 }) several ({ 14 }) face ({ 15 }) clusters ({ 16 }) and ({ 17 }) the ({ 18 }) largest ({ 19 }) cluster ({ 20 }) is ({ 21 }) equivalent ({ 22 }) to ({ 23 }) the ({ 24 }) faces ({ 25 }) relevant ({ 26 }) to ({ 27 }) the ({ 28 }) query ({ 29 }) if ({ 30 }) they ({ }) are ({ }) returned ({ 31 }) by ({ 32 }) a ({ 33 }) search ({ 34 }) engine ({ 35 }) . ({ 36 }) 
# Sentence pair (2049) source length 24 target length 20 alignment score : 3.53016e-08
As a result , this method can stimulate face sets returned by search engines using many names mentioned above . 
NULL ({ }) As ({ 1 }) a ({ 2 }) result ({ 3 }) , ({ 4 }) this ({ 5 }) method ({ 6 }) can ({ 7 }) be ({ }) used ({ }) to ({ }) stimulate ({ 8 }) face ({ 9 }) sets ({ 10 }) returned ({ 11 }) by ({ 12 }) search ({ 13 }) engines ({ 14 }) using ({ 15 }) many ({ 16 }) names ({ 17 }) as ({ }) mentioned ({ 18 }) above ({ 19 }) . ({ 20 }) 
# Sentence pair (2050) source length 16 target length 16 alignment score : 0.00401967
To obtain \MATH , we use a simple technique for faces extracted from video archives . 
NULL ({ }) To ({ 1 }) obtain ({ 2 }) \MATH ({ 3 }) , ({ 4 }) we ({ 5 }) use ({ 6 }) a ({ 7 }) simple ({ 8 }) technique ({ 9 }) for ({ 10 }) faces ({ 11 }) extracted ({ 12 }) from ({ 13 }) video ({ 14 }) archives ({ 15 }) . ({ 16 }) 
# Sentence pair (2051) source length 18 target length 19 alignment score : 8.89971e-09
Specifically , We use the following heuristics to pick a set of different persons appearing in video archives : 
NULL ({ 2 }) We ({ 3 }) specifically ({ 1 }) use ({ 4 }) the ({ 5 }) following ({ 6 }) heuristics ({ 7 }) to ({ 8 }) pick ({ 9 }) a ({ 10 }) set ({ 11 }) of ({ 12 }) different ({ 13 }) people ({ 14 }) appearing ({ 15 }) in ({ 16 }) video ({ 17 }) archives ({ 18 }) : ({ 19 }) 
# Sentence pair (2052) source length 24 target length 22 alignment score : 1.41897e-08
-If there are more than one face appearing in different locations in one frame , they likely belong to different persons . 
NULL ({ }) -If ({ 1 }) there ({ 2 }) is ({ 3 }) more ({ 4 }) than ({ 5 }) one ({ 6 }) face ({ 7 }) appearing ({ 8 }) in ({ 9 }) different ({ 10 }) locations ({ 11 }) in ({ 12 }) one ({ 13 }) frame ({ 14 }) , ({ 15 }) they ({ 16 }) are ({ }) likely ({ 17 }) to ({ }) belong ({ 18 }) to ({ 19 }) different ({ 20 }) people ({ 21 }) . ({ 22 }) 
# Sentence pair (2053) source length 10 target length 9 alignment score : 2.38965e-05
Figure \REF shows an example of this case . 
NULL ({ }) Figure ({ 1 }) \REF ({ 2 }) shows ({ 3 }) an ({ 4 }) example ({ 5 }) where ({ 6 }) this ({ 7 }) has ({ }) occurred ({ 8 }) . ({ 9 }) 
# Sentence pair (2054) source length 30 target length 30 alignment score : 1.41239e-14
-If two persons appear in video programs broadcast by different broadcast stations ( e .g . , CNN , MSNBC , and CCTV ) , they are likely different . 
NULL ({ 16 }) -If ({ 1 }) two ({ 2 }) people ({ 3 }) appear ({ 4 }) in ({ 5 }) video ({ 6 }) programs ({ 7 }) broadcast ({ 8 }) by ({ 9 }) different ({ 10 }) broadcast ({ 11 }) stations ({ 12 }) ( ({ 13 }) e.g. ({ 14 15 }) , ({ 17 }) CNN ({ 18 }) , ({ 19 }) MSNBC ({ 20 }) , ({ 21 }) and ({ 22 }) CCTV ({ 23 }) ) ({ 24 }) , ({ 25 }) they ({ 26 }) are ({ 27 }) likely ({ 28 }) to ({ }) be ({ }) different ({ 29 }) . ({ 30 }) 
# Sentence pair (2055) source length 26 target length 25 alignment score : 1.5272e-13
If we have large video archives , using these heuristics we can collect a sufficient number of training samples for learning the relevance classifier . 
NULL ({ }) If ({ 1 }) we ({ 2 }) have ({ 3 }) large ({ 4 }) video ({ 5 }) archives ({ 6 }) , ({ 7 }) we ({ 11 }) can ({ 12 }) collect ({ 13 }) a ({ 14 }) sufficient ({ 15 }) number ({ 16 }) of ({ 17 }) training ({ 18 }) samples ({ 19 }) to ({ 20 }) learn ({ 21 }) the ({ 22 }) relevance ({ 23 }) classifier ({ 24 }) by ({ }) using ({ 8 }) these ({ 9 }) heuristics ({ 10 }) . ({ 25 }) 
# Sentence pair (2056) source length 25 target length 26 alignment score : 6.31231e-11
We form a face set Generating \MATH by picking a subset of faces of Generating \MATH and adding randomly faces from other sets Generating \MATH . 
NULL ({ 3 }) We ({ 1 }) form ({ 2 }) face ({ 4 }) set ({ 5 }) Generating ({ 6 }) \MATH ({ 7 }) by ({ 8 }) picking ({ 9 }) a ({ 10 }) subset ({ 11 }) of ({ 12 }) faces ({ 13 }) of ({ 14 }) Generating ({ 15 }) \MATH ({ 16 }) and ({ 17 }) randomly ({ 19 }) adding ({ 18 }) faces ({ 20 }) from ({ 21 }) other ({ 22 }) sets ({ 23 }) Generating ({ 24 }) \MATH ({ 25 }) . ({ 26 }) 
# Sentence pair (2057) source length 32 target length 32 alignment score : 7.2433e-10
To keep the assumption of visual consistency satisfied , the number of faces selected in each set Generating \MATH must be smaller than the number of faces in set Generating \MATH . 
NULL ({ }) To ({ 1 }) keep ({ 2 }) satisfying ({ 3 }) the ({ }) assumption ({ 4 }) of ({ 5 }) visual ({ 6 }) consistency ({ 7 8 }) , ({ 9 }) the ({ 10 }) number ({ 11 }) of ({ 12 }) faces ({ 13 }) selected ({ 14 }) in ({ 15 }) each ({ 16 }) set ({ 17 }) Generating ({ 18 }) \MATH ({ 19 }) must ({ 20 }) be ({ 21 }) smaller ({ 22 }) than ({ 23 }) the ({ 24 }) number ({ 25 }) of ({ 26 }) faces ({ 27 }) in ({ 28 }) set ({ 29 }) Generating ({ 30 }) \MATH ({ 31 }) . ({ 32 }) 
# Sentence pair (2058) source length 31 target length 31 alignment score : 2.48714e-05
We then label faces in set Generating \MATH as relevant to the query associated with Generating \MATH , and the other faces of Generating \MATH as irrelevant to the query . 
NULL ({ }) We ({ 1 }) then ({ 2 }) label ({ 3 }) faces ({ 4 }) in ({ 5 }) set ({ 6 }) Generating ({ 7 }) \MATH ({ 8 }) as ({ 9 }) relevant ({ 10 }) to ({ 11 }) the ({ 12 }) query ({ 13 }) associated ({ 14 }) with ({ 15 }) Generating ({ 16 }) \MATH ({ 17 }) , ({ 18 }) and ({ 19 }) the ({ 20 }) other ({ 21 }) faces ({ 22 }) of ({ 23 }) Generating ({ 24 }) \MATH ({ 25 }) as ({ 26 }) irrelevant ({ 27 }) to ({ 28 }) the ({ 29 }) query ({ 30 }) . ({ 31 }) 
# Sentence pair (2059) source length 20 target length 19 alignment score : 0.000134801
Once the training samples are collected , we use SVM with linear kernel to learn the relevance classifier . 
NULL ({ }) Once ({ 1 }) the ({ 2 }) training ({ 3 }) samples ({ 4 }) are ({ 5 }) collected ({ 6 }) , ({ 7 }) we ({ 8 }) use ({ 9 }) SVM ({ 10 }) with ({ 11 }) a ({ }) linear ({ 12 }) kernel ({ 13 }) to ({ 14 }) learn ({ 15 }) the ({ 16 }) relevance ({ 17 }) classifier ({ 18 }) . ({ 19 }) 
# Sentence pair (2060) source length 15 target length 14 alignment score : 8.3593e-05
TRECVID dataset : We collected all video programs of TRECVID 2006 dataset \CITE . 
NULL ({ }) TRECVID ({ 1 }) dataset ({ 2 }) : ({ 3 }) We ({ 4 }) collected ({ 5 }) all ({ 6 }) video ({ 7 }) programs ({ 8 }) from ({ 9 }) the ({ }) TRECVID ({ 10 }) 2006 ({ 11 }) dataset ({ 12 }) \CITE ({ 13 }) . ({ 14 }) 
# Sentence pair (2061) source length 20 target length 19 alignment score : 5.16747e-07
There are 527 video programs broadcast on 7 channels in 3 languages including English , Chinese and Arabic . 
NULL ({ }) There ({ 1 }) were ({ 2 }) 527 ({ 3 }) video ({ 4 }) programs ({ 5 }) broadcast ({ 6 }) on ({ 7 }) seven ({ 8 }) channels ({ 9 }) in ({ 10 }) three ({ 11 }) languages ({ 12 }) including ({ 13 }) English ({ 14 }) , ({ 15 }) Chinese ({ 16 }) , ({ }) and ({ 17 }) Arabic ({ 18 }) . ({ 19 }) 
# Sentence pair (2062) source length 31 target length 29 alignment score : 9.55029e-08
We extracted faces from these video programs and grouped faces belonging to one person in each shot in one face track using a similar method described in \CITE . 
NULL ({ }) We ({ 1 }) extracted ({ 2 }) faces ({ 3 }) from ({ 4 }) these ({ 5 }) video ({ 6 }) programs ({ 7 }) and ({ 8 }) grouped ({ 9 }) faces ({ 10 }) belonging ({ 11 }) to ({ 12 }) one ({ 13 }) person ({ 14 }) in ({ 15 }) each ({ 16 }) shot ({ 17 }) in ({ 18 }) one ({ 19 }) face ({ 20 }) track ({ 21 }) using ({ 22 }) a ({ 23 }) similar ({ 24 }) method ({ 25 }) to ({ }) that ({ }) described ({ 26 }) in ({ 27 }) \CITE ({ 28 }) . ({ 29 }) 
# Sentence pair (2063) source length 34 target length 34 alignment score : 4.91602e-17
For each channel , We scanned all face tracks extracted from the videos broadcast by this channel , and picked face tracks extracted from keyframes that several faces were detected at different locations . 
NULL ({ 4 }) We ({ 5 }) scanned ({ 6 }) all ({ 7 }) face ({ 8 }) tracks ({ 9 }) for ({ 1 }) each ({ 2 }) channel ({ 3 }) extracted ({ 10 }) from ({ 11 }) the ({ 12 }) videos ({ 13 }) broadcast ({ 14 }) by ({ 15 }) this ({ 16 }) channel ({ 17 }) , ({ 18 }) and ({ 19 }) picked ({ 20 }) face ({ 21 }) tracks ({ 22 }) extracted ({ 23 }) from ({ 24 }) key ({ 25 }) frames ({ }) where ({ 26 }) several ({ 27 }) faces ({ 28 }) were ({ 29 }) detected ({ 30 }) at ({ 31 }) different ({ 32 }) locations ({ 33 }) . ({ 34 }) 
# Sentence pair (2064) source length 22 target length 22 alignment score : 1.75621e-15
To guarantee selected face tracks representing different persons , for one channel , only face tracks of one shot was picked . 
NULL ({ 13 }) To ({ 1 }) guarantee ({ 2 }) selected ({ 3 }) face ({ 4 }) tracks ({ 5 }) representing ({ 6 }) different ({ 7 }) people ({ 8 }) , ({ 9 }) only ({ 14 }) the ({ }) face ({ 15 }) tracks ({ 16 }) from ({ 17 }) one ({ 18 }) shot ({ 19 }) were ({ 20 }) picked ({ 21 }) for ({ 10 }) one ({ 11 }) channel ({ 12 }) . ({ 22 }) 
# Sentence pair (2065) source length 24 target length 24 alignment score : 3.13621e-08
As a result , there are 5 ,126 faces of 19 face tracks picked from the 7 channels corresponding to 19 different persons . 
NULL ({ }) As ({ 1 }) a ({ 2 }) result ({ 3 }) , ({ 4 }) there ({ 5 }) were ({ 6 }) 5 ({ 7 }) ,126 ({ 8 }) faces ({ 9 }) of ({ 10 }) 19 ({ 11 }) face ({ 12 }) tracks ({ 13 }) selected ({ 14 }) from ({ 15 }) the ({ 16 }) seven ({ 17 }) channels ({ 18 }) corresponding ({ 19 }) to ({ 20 }) 19 ({ 21 }) different ({ 22 }) people ({ 23 }) . ({ 24 }) 
# Sentence pair (2066) source length 13 target length 14 alignment score : 2.3674e-06
Note that , the system does not know the identity of these faces . 
NULL ({ 3 }) Note ({ 1 }) that ({ 2 }) the ({ 4 }) system ({ 5 }) did ({ 6 }) not ({ 7 }) know ({ 8 }) the ({ 9 }) identity ({ 10 }) of ({ 11 }) these ({ 12 }) faces ({ 13 }) . ({ 14 }) 
# Sentence pair (2067) source length 11 target length 11 alignment score : 6.62217e-05
It only knows any two face tracks represent different persons . 
NULL ({ }) It ({ 1 }) only ({ 2 }) knew ({ 3 }) any ({ 4 }) two ({ 5 }) face ({ 6 }) tracks ({ 7 }) represented ({ 8 }) different ({ 9 }) people ({ 10 }) . ({ 11 }) 
# Sentence pair (2068) source length 14 target length 14 alignment score : 6.09763e-05
The number of faces of these face tracks is shown in Figure \REF . 
NULL ({ }) The ({ 1 }) number ({ 2 }) of ({ 3 }) faces ({ 4 }) in ({ 5 }) these ({ 6 }) face ({ 7 }) tracks ({ 8 }) is ({ 9 }) shown ({ 10 }) in ({ 11 }) Figure ({ 12 }) \REF ({ 13 }) . ({ 14 }) 
# Sentence pair (2069) source length 23 target length 23 alignment score : 1.82658e-17
Using these face tracks , We generated 133 labeled sets described in Section \REF and used them for training the relevance classifier . 
NULL ({ 5 }) We ({ 6 }) generated ({ 7 }) the ({ }) 133 ({ 1 8 }) labeled ({ 9 }) sets ({ 10 }) described ({ 11 }) in ({ 12 }) Section ({ 13 }) \REF ({ 14 }) using ({ }) these ({ 2 }) face ({ 3 }) tracks ({ 4 }) and ({ 15 }) used ({ 16 }) them ({ 17 }) to ({ 18 }) train ({ 19 }) the ({ 20 }) relevance ({ 21 }) classifier ({ 22 }) . ({ 23 }) 
# Sentence pair (2070) source length 29 target length 29 alignment score : 1.36457e-05
Yahoo News Images : This dataset consists of approximately half a million news photos and captions from Yahoo News collected over a period of roughly two years \CITE . 
NULL ({ }) Yahoo ({ 1 }) News ({ 2 }) Images ({ 3 }) : ({ 4 }) This ({ 5 }) dataset ({ 6 }) consists ({ 7 }) of ({ 8 }) approximately ({ 9 }) half ({ 10 }) a ({ 11 }) million ({ 12 }) news ({ 13 }) photos ({ 14 }) and ({ 15 }) captions ({ 16 }) from ({ 17 }) Yahoo ({ 18 }) News ({ 19 }) collected ({ 20 }) over ({ 21 }) a ({ 22 }) period ({ 23 }) of ({ 24 }) roughly ({ 25 }) two ({ 26 }) years ({ 27 }) \CITE ({ 28 }) . ({ 29 }) 
# Sentence pair (2071) source length 29 target length 27 alignment score : 3.73448e-07
Using person names as queries , we applied simple string search to the captions this dataset to return a list of faces for each queried name . 
NULL ({ }) Using ({ 1 }) peoplefs ({ 2 }) names ({ 3 }) as ({ 4 }) queries ({ 5 }) , ({ 6 }) we ({ 7 }) applied ({ 8 }) a ({ }) simple ({ 9 }) string ({ 10 }) search ({ 11 }) to ({ 12 }) the ({ 13 }) captions ({ 14 }) in ({ }) this ({ 15 }) dataset ({ 16 }) to ({ 17 }) return ({ 18 }) a ({ 19 }) list ({ 20 }) of ({ 21 }) faces ({ 22 }) for ({ 23 }) each ({ 24 }) queried ({ 25 }) name ({ 26 }) . ({ 27 }) 
# Sentence pair (2072) source length 11 target length 11 alignment score : 0.0286575
We used 23 names of celebrities such as George W . 
NULL ({ }) We ({ 1 }) used ({ 2 }) 23 ({ 3 }) names ({ 4 }) of ({ 5 }) celebrities ({ 6 }) such ({ 7 }) as ({ 8 }) George ({ 9 }) W ({ 10 }) . ({ 11 }) 
# Sentence pair (2073) source length 15 target length 15 alignment score : 0.00810716
Bush , Vladimir Putin , Ziang Jemin , Tony Blair , and Abdullah Gul . 
NULL ({ }) Bush ({ 1 }) , ({ 2 }) Vladimir ({ 3 }) Putin ({ 4 }) , ({ 5 }) Ziang ({ 6 }) Jemin ({ 7 }) , ({ 8 }) Tony ({ 9 }) Blair ({ 10 }) , ({ 11 }) and ({ 12 }) Abdullah ({ 13 }) Gul ({ 14 }) . ({ 15 }) 
# Sentence pair (2074) source length 10 target length 11 alignment score : 4.61645e-11
These names are widely used in experiments such as \CITE . 
NULL ({ 8 9 }) These ({ 1 }) names ({ 2 }) have ({ 3 }) widely ({ 4 }) been ({ }) used ({ 5 }) in ({ 6 }) experiments ({ 7 }) \CITE ({ 10 }) . ({ 11 }) 
# Sentence pair (2075) source length 16 target length 16 alignment score : 2.2588e-07
In total , 9 ,136 faces were retrieved in which 3 ,909 faces were relevant . 
NULL ({ 3 }) A ({ 1 }) total ({ 2 }) of ({ }) 9 ({ 4 }) ,136 ({ 5 }) faces ({ 6 }) were ({ 7 }) retrieved ({ 8 }) in ({ 9 }) which ({ 10 }) 3 ({ 11 }) ,909 ({ 12 }) faces ({ 13 }) were ({ 14 }) relevant ({ 15 }) . ({ 16 }) 
# Sentence pair (2076) source length 7 target length 8 alignment score : 1.96799e-08
On average , The accuracy was \MATH . 
NULL ({ 3 }) The ({ 4 }) accuracy ({ 5 }) was ({ 6 }) \MATH ({ 7 }) on ({ 1 }) average ({ 2 }) . ({ 8 }) 
# Sentence pair (2077) source length 28 target length 25 alignment score : 9.82063e-10
Google Images : We used the same set of person names used in Yahoo News Images dataset and put to Google Image Search Engine . 
NULL ({ }) Google ({ 1 }) Images ({ 2 }) : ({ 3 }) We ({ 4 }) used ({ 5 }) the ({ 6 }) same ({ 7 }) set ({ 8 }) of ({ 9 }) peoplefs ({ 10 }) names ({ 11 }) used ({ 12 }) in ({ 13 }) the ({ }) Yahoo ({ 14 }) News ({ 15 }) Images ({ 16 }) dataset ({ 17 }) and ({ 18 }) input ({ 19 }) them ({ }) into ({ 20 }) the ({ }) Google ({ 21 }) Image ({ 22 }) Search ({ 23 }) Engine ({ 24 }) . ({ 25 }) 
# Sentence pair (2078) source length 16 target length 17 alignment score : 2.18044e-10
For each query , We crawled a maximum of 500 images from URLs returned by Google . 
NULL ({ 4 }) We ({ 5 }) crawled ({ 6 }) a ({ 7 }) maximum ({ 8 }) of ({ 9 }) 500 ({ 10 }) images ({ 11 }) from ({ 12 }) URLs ({ 13 }) returned ({ 14 }) by ({ 15 }) Google ({ 16 }) for ({ 1 }) each ({ 2 }) query ({ 3 }) . ({ 17 }) 
# Sentence pair (2079) source length 16 target length 16 alignment score : 2.12083e-07
In total , 9 ,516 faces were extracted in which 5 ,816 faces were relevant . 
NULL ({ 3 }) A ({ 1 }) total ({ 2 }) of ({ }) 9 ({ 4 }) ,516 ({ 5 }) faces ({ 6 }) were ({ 7 }) extracted ({ 8 }) in ({ 9 }) which ({ 10 }) 5 ({ 11 }) ,816 ({ 12 }) faces ({ 13 }) were ({ 14 }) relevant ({ 15 }) . ({ 16 }) 
# Sentence pair (2080) source length 7 target length 8 alignment score : 1.96799e-08
On average , The accuracy was \MATH . 
NULL ({ 3 }) The ({ 4 }) accuracy ({ 5 }) was ({ 6 }) \MATH ({ 7 }) on ({ 1 }) average ({ 2 }) . ({ 8 }) 
# Sentence pair (2081) source length 11 target length 11 alignment score : 0.013243
The TRECVID dataset was used for training the generic classifier . 
NULL ({ }) The ({ 1 }) TRECVID ({ 2 }) dataset ({ 3 }) was ({ 4 }) used ({ 5 }) for ({ 6 }) training ({ 7 }) the ({ 8 }) generic ({ 9 }) classifier ({ 10 }) . ({ 11 }) 
# Sentence pair (2082) source length 21 target length 20 alignment score : 3.72485e-07
The datasets , Yahoo News Images and Google Images as shown in Figure \REF , were used for testing . 
NULL ({ 3 }) The ({ 1 }) datasets ({ 2 }) for ({ }) Yahoo ({ 4 }) News ({ 5 }) Images ({ 6 }) and ({ 7 }) Google ({ 8 }) Images ({ 9 }) , ({ }) as ({ 10 }) shown ({ 11 }) in ({ 12 }) Figure ({ 13 }) \REF ({ 14 }) , ({ 15 }) were ({ 16 }) used ({ 17 }) for ({ 18 }) testing ({ 19 }) . ({ 20 }) 
# Sentence pair (2083) source length 17 target length 17 alignment score : 0.00245619
We used the Viola-Jones face detector \CITE to detect frontal faces in images and video frames . 
NULL ({ }) We ({ 1 }) used ({ 2 }) the ({ 3 }) Viola-Jones ({ 4 }) face ({ 5 }) detector ({ 6 }) \CITE ({ 7 }) to ({ 8 }) detect ({ 9 }) frontal ({ 10 }) faces ({ 11 }) in ({ 12 }) images ({ 13 }) and ({ 14 }) video ({ 15 }) frames ({ 16 }) . ({ 17 }) 
# Sentence pair (2084) source length 23 target length 22 alignment score : 7.86857e-15
To group faces belonging to one person in one video shot , We simply used a similar technique described in \CITE . 
NULL ({ 12 }) We ({ 1 }) simply ({ 14 }) used ({ 15 }) a ({ 16 }) similar ({ 17 }) technique ({ 18 }) to ({ 13 }) that ({ }) described ({ 19 }) in ({ 20 }) \CITE ({ 21 }) to ({ }) group ({ 2 }) faces ({ 3 }) belonging ({ 4 }) to ({ 5 }) one ({ 6 }) person ({ 7 }) in ({ 8 }) one ({ 9 }) video ({ 10 }) shot ({ 11 }) . ({ 22 }) 
# Sentence pair (2085) source length 40 target length 41 alignment score : 1.77788e-13
Using the prior knowledge that faces of the same person in consecutive frames do not change much in locations and appearance , the technique used tracked points to robustly associate these faces into face tracks with the precision of \MATH . 
NULL ({ 2 }) Using ({ 1 }) prior ({ 3 }) knowledge ({ 4 }) that ({ 5 }) faces ({ 6 }) of ({ 7 }) the ({ 8 }) same ({ 9 }) person ({ 10 }) in ({ 11 }) consecutive ({ 12 }) frames ({ 13 }) do ({ 14 }) not ({ 15 }) change ({ 16 }) much ({ 17 }) in ({ 18 }) locations ({ 19 }) and ({ 20 }) appearance ({ 21 }) , ({ 22 }) the ({ 23 }) technique ({ 24 }) used ({ 25 }) tracked ({ 26 }) points ({ 27 }) to ({ 28 }) robustly ({ 29 }) associate ({ 30 }) these ({ 31 }) faces ({ 32 }) in ({ 33 }) face ({ 34 }) tracks ({ 35 }) with ({ 36 }) a ({ 37 }) precision ({ 38 }) of ({ 39 }) \MATH ({ 40 }) . ({ 41 }) 
# Sentence pair (2086) source length 18 target length 18 alignment score : 0.000173907
Once faces were extracted , we used the code provided by the authors \CITE to extract features . 
NULL ({ }) Once ({ 1 }) faces ({ 2 }) were ({ 3 }) extracted ({ 4 }) , ({ 5 }) we ({ 6 }) used ({ 7 }) the ({ 8 }) code ({ 9 }) provided ({ 10 }) by ({ 11 }) the ({ 12 }) authors ({ 13 }) \CITE ({ 14 }) to ({ 15 }) extract ({ 16 }) features ({ 17 }) . ({ 18 }) 
# Sentence pair (2087) source length 16 target length 16 alignment score : 0.000832873
Each face is then represented as a point in a very high dimensional feature space . 
NULL ({ }) Each ({ 1 }) face ({ 2 }) was ({ 3 }) then ({ 4 }) represented ({ 5 }) as ({ 6 }) a ({ 7 }) point ({ 8 }) in ({ 9 }) a ({ 10 }) very ({ 11 }) high ({ 12 }) dimensional ({ 13 }) feature ({ 14 }) space ({ 15 }) . ({ 16 }) 
# Sentence pair (2088) source length 23 target length 26 alignment score : 1.33054e-26
Specifically , for each face , 9 facial feature points were detected , and 4 more facial feature points were inferred from these 9 points . 
NULL ({ 2 6 }) Nine ({ 1 }) facial-feature ({ 18 }) points ({ 19 }) were ({ 20 }) specifically ({ 17 }) detected ({ 12 }) for ({ 3 }) each ({ 4 }) face ({ 5 }) , ({ 13 }) and ({ 14 }) four ({ 15 }) more ({ 16 }) facial ({ 8 }) feature ({ 9 }) points ({ 10 }) were ({ 11 }) inferred ({ 21 }) from ({ 22 }) these ({ 23 }) nine ({ 7 24 }) points ({ 25 }) . ({ 26 }) 
# Sentence pair (2089) source length 14 target length 14 alignment score : 5.79775e-13
In total , There were 13 feature points from which features are extracted . 
NULL ({ 3 }) There ({ 1 4 }) were ({ 5 }) a ({ }) total ({ 2 }) of ({ }) 13 ({ 6 }) feature ({ 7 }) points ({ 8 }) from ({ 9 }) which ({ 10 }) features ({ 11 }) were ({ 12 }) extracted ({ 13 }) . ({ 14 }) 
# Sentence pair (2090) source length 16 target length 15 alignment score : 4.88076e-06
The features are intensity values lying within the circle with radius of 15 pixels . 
NULL ({ }) The ({ 1 }) features ({ 2 }) were ({ 3 }) intensity ({ 4 }) values ({ 5 }) lying ({ 6 }) within ({ 7 }) a ({ 8 }) circle ({ 9 }) with ({ 10 }) a ({ }) radius ({ 11 }) of ({ 12 }) 15 ({ 13 }) pixels ({ 14 }) . ({ 15 }) 
# Sentence pair (2091) source length 10 target length 10 alignment score : 0.00611676
The output feature has 13x149 = 1 ,937 dimensions . 
NULL ({ }) The ({ 1 }) output ({ 2 }) feature ({ 3 }) had ({ 4 }) 13x149 ({ 5 }) = ({ 6 }) 1 ({ 7 }) ,937 ({ 8 }) dimensions ({ 9 }) . ({ 10 }) 
# Sentence pair (2092) source length 6 target length 8 alignment score : 6.39017e-08
Figure \REF shows illustration of this feature . 
NULL ({ 5 }) Figure ({ 1 }) \REF ({ 2 }) illustrates ({ 3 4 }) this ({ 6 }) feature ({ 7 }) . ({ 8 }) 
# Sentence pair (2093) source length 26 target length 25 alignment score : 6.86948e-08
We evaluated the retrieval performance with measures that are commonly used in information retrieval , such as precision , recall , and average precision . 
NULL ({ }) We ({ 1 }) evaluated ({ 2 }) the ({ 3 }) efficiency ({ 4 }) of ({ }) retrieval ({ 5 }) with ({ 6 }) measures ({ 7 }) that ({ 8 }) are ({ 9 }) commonly ({ 10 }) used ({ 11 }) in ({ 12 }) information ({ 13 }) retrieval ({ 14 }) , ({ 15 }) such ({ 16 }) as ({ 17 }) precision ({ 18 }) , ({ 19 }) recall ({ 20 }) , ({ 21 }) and ({ 22 }) average ({ 23 }) precision ({ 24 }) . ({ 25 }) 
# Sentence pair (2094) source length 41 target length 42 alignment score : 3.73071e-10
Given a queried person and letting \MATH be the total number of faces returned , \MATH the number of relevant faces , and \MATH the total number of relevant faces , recall and precision can be calculated as follows : \MATH . 
NULL ({ 39 }) Given ({ 1 }) a ({ 2 }) queried ({ 3 }) person ({ 4 }) and ({ 5 }) letting ({ 6 }) \MATH ({ 7 }) be ({ 8 }) the ({ 9 }) total ({ 10 }) number ({ 11 }) of ({ 12 }) faces ({ 13 }) returned ({ 14 }) , ({ 15 }) \MATH ({ 16 }) the ({ 17 }) number ({ 18 }) of ({ 19 }) relevant ({ 20 }) faces ({ 21 }) , ({ 22 }) and ({ 23 }) \MATH ({ 24 }) the ({ 25 }) total ({ 26 }) number ({ 27 }) of ({ 28 }) relevant ({ 29 }) faces ({ 30 }) , ({ 31 }) recall ({ 32 }) and ({ 33 }) precision ({ 34 }) can ({ 35 }) be ({ 36 }) calculated ({ 37 }) as ({ 38 }) : ({ 40 }) \MATH ({ 41 }) . ({ 42 }) 
# Sentence pair (2095) source length 18 target length 15 alignment score : 4.1526e-06
Precision and recall only evaluate the quality of an unordered set of retrieved faces . 
NULL ({ }) Precision ({ 1 }) and ({ 2 }) recall ({ 3 }) were ({ }) only ({ 4 }) used ({ }) to ({ }) evaluate ({ 5 }) the ({ 6 }) quality ({ 7 }) of ({ 8 }) an ({ 9 }) unordered ({ 10 }) set ({ 11 }) of ({ 12 }) retrieved ({ 13 }) faces ({ 14 }) . ({ 15 }) 
# Sentence pair (2096) source length 20 target length 22 alignment score : 1.06463e-12
To evaluate ranked lists in which both recall and precision are taken into account , the average precision is usually used . 
NULL ({ 15 16 }) Average ({ 1 17 }) precision ({ 18 }) is ({ 19 }) usually ({ 20 }) used ({ 21 }) to ({ }) evaluate ({ 2 }) ranked ({ 3 }) lists ({ 4 }) in ({ 5 }) which ({ 6 }) both ({ 7 }) recall ({ 8 }) and ({ 9 }) precision ({ 10 }) are ({ 11 }) taken ({ 12 }) into ({ 13 }) account ({ 14 }) . ({ 22 }) 
# Sentence pair (2097) source length 35 target length 36 alignment score : 1.01343e-07
The average precision is computed by taking the average of the interpolated precision measured at the 11 recall levels of 0 .0 , 0 .1 , 0 .2 , . . . , 1 .0 . 
NULL ({ 16 }) The ({ 1 }) average ({ 2 }) precision ({ 3 }) is ({ 4 }) computed ({ 5 }) by ({ 6 }) taking ({ 7 }) the ({ 8 }) average ({ 9 }) of ({ 10 }) the ({ 11 }) interpolated ({ 12 }) precision ({ 13 }) measured ({ 14 }) at ({ 15 }) 11 ({ 17 }) recall ({ 18 }) levels ({ 19 }) of ({ 20 }) 0 ({ 21 }) .0 ({ 22 }) , ({ 23 }) 0 ({ 24 }) .1 ({ 25 }) , ({ 26 }) 0 ({ 27 }) .2 ({ 28 }) , ({ 29 }) . ({ 30 }) . ({ 31 }) . ({ 32 }) , ({ 33 }) 1 ({ 34 }) .0 ({ 35 }) . ({ 36 }) 
# Sentence pair (2098) source length 27 target length 23 alignment score : 2.17517e-07
The interpolated precision \MATH at a certain recall level \MATH is defined as the highest precision found for any recall level \MATH : 
NULL ({ }) The ({ 1 }) interpolated ({ 2 }) precision ({ 3 }) , ({ }) \MATH ({ 4 }) , ({ }) at ({ 5 }) a ({ 6 }) certain ({ 7 }) recall ({ 8 }) level ({ 9 }) , ({ }) \MATH ({ 10 }) , ({ }) is ({ 11 }) defined ({ 12 }) as ({ 13 }) the ({ 14 }) highest ({ 15 }) precision ({ 16 }) found ({ 17 }) for ({ 18 }) any ({ 19 }) recall ({ 20 }) level ({ 21 }) \MATH ({ 22 }) : ({ 23 }) 
# Sentence pair (2099) source length 28 target length 28 alignment score : 2.75879e-12
In addition , to evaluate the performance of multiple queries , we used mean average precision , which is the mean of average precisions computed from queries . 
NULL ({ 3 }) In ({ 1 }) addition ({ 2 }) , ({ 11 }) we ({ 12 }) used ({ 13 }) the ({ }) mean ({ 14 }) average ({ 15 }) precision ({ 16 }) to ({ 4 }) evaluate ({ 5 }) the ({ 6 }) performance ({ 7 }) of ({ 8 }) multiple ({ 9 }) queries ({ 10 }) , ({ 17 }) which ({ 18 }) is ({ 19 }) the ({ 20 }) mean ({ 21 }) of ({ 22 }) average ({ 23 }) precisions ({ 24 }) computed ({ 25 }) from ({ 26 }) queries ({ 27 }) . ({ 28 }) 
# Sentence pair (2100) source length 25 target length 18 alignment score : 3.64854e-21
In this experiment , We compare the MAP performance of the following systems testing on YahooNews Images : 
NULL ({ 4 7 }) We ({ 1 }) compared ({ 6 }) the ({ }) performance ({ 9 }) of ({ 10 }) the ({ 11 }) Maximum ({ 12 }) A-Posteriori ({ 8 }) ( ({ }) MAP ({ 5 }) ) ({ }) algorithm ({ }) in ({ }) seven ({ }) systems ({ 13 }) in ({ }) this ({ 2 }) experiment ({ 3 }) by ({ }) testing ({ 14 }) it ({ }) on ({ 15 }) YahooNews ({ 16 }) Images ({ 17 }) : ({ 18 }) 
# Sentence pair (2101) source length 21 target length 21 alignment score : 0.000249083
-DistScore-TrainGoogleImages : The training set is the set of annotated faces returned by Google Images Search for 23 person names . 
NULL ({ }) -DistScore-TrainGoogleImages ({ 1 }) : ({ 2 }) The ({ 3 }) training ({ 4 }) set ({ 5 }) was ({ 6 }) the ({ 7 }) set ({ 8 }) of ({ 9 }) annotated ({ 10 }) faces ({ 11 }) returned ({ 12 }) by ({ 13 }) Google ({ 14 }) Images ({ 15 }) Search ({ 16 }) for ({ 17 }) 23 ({ 18 }) peoplefs ({ 19 }) names ({ 20 }) . ({ 21 }) 
# Sentence pair (2102) source length 8 target length 8 alignment score : 0.03009
The feature vector is computed using \MATH . 
NULL ({ }) The ({ 1 }) feature ({ 2 }) vector ({ 3 }) was ({ 4 }) computed ({ 5 }) using ({ 6 }) \MATH ({ 7 }) . ({ 8 }) 
# Sentence pair (2103) source length 11 target length 11 alignment score : 0.0128141
-NNScore-TrainGoogleImages : The training set is the same as DistScore-TrainGoogleImages . 
NULL ({ }) -NNScore-TrainGoogleImages ({ 1 }) : ({ 2 }) The ({ 3 }) training ({ 4 }) set ({ 5 }) was ({ 6 }) the ({ 7 }) same ({ 8 }) as ({ 9 }) DistScore-TrainGoogleImages ({ 10 }) . ({ 11 }) 
# Sentence pair (2104) source length 8 target length 8 alignment score : 0.03009
The feature vector is computed using \MATH . 
NULL ({ }) The ({ 1 }) feature ({ 2 }) vector ({ 3 }) was ({ 4 }) computed ({ 5 }) using ({ 6 }) \MATH ({ 7 }) . ({ 8 }) 
# Sentence pair (2105) source length 9 target length 9 alignment score : 0.0175004
DistScore-TrainTRECVID : The feature vector is computed using . 
NULL ({ }) DistScore-TrainTRECVID ({ 1 }) : ({ 2 }) The ({ 3 }) feature ({ 4 }) vector ({ 5 }) was ({ 6 }) computed ({ 7 }) using ({ 8 }) . ({ 9 }) 
# Sentence pair (2106) source length 19 target length 19 alignment score : 1.00329e-05
The training set is the set of annotated faces artificially generated by our method described in Section \REF . 
NULL ({ }) The ({ 1 }) training ({ 2 }) set ({ 3 }) was ({ 4 }) the ({ 5 }) set ({ 6 }) of ({ 7 }) annotated ({ 8 }) faces ({ 9 }) artificially ({ 10 }) generated ({ 11 }) with ({ 12 }) our ({ 13 }) method ({ 14 }) described ({ 15 }) in ({ 16 }) Section ({ 17 }) \REF ({ 18 }) . ({ 19 }) 
# Sentence pair (2107) source length 11 target length 11 alignment score : 0.0112413
-NNScore-TrainTRECVID : The training set is the same as DistScore-TrainTRECVID . 
NULL ({ }) -NNScore-TrainTRECVID ({ 1 }) : ({ 2 }) The ({ 3 }) training ({ 4 }) set ({ 5 }) was ({ 6 }) the ({ 7 }) same ({ 8 }) as ({ 9 }) DistScore-TrainTRECVID ({ 10 }) . ({ 11 }) 
# Sentence pair (2108) source length 8 target length 8 alignment score : 0.03009
The feature vector is computed using \MATH . 
NULL ({ }) The ({ 1 }) feature ({ 2 }) vector ({ 3 }) was ({ 4 }) computed ({ 5 }) using ({ 6 }) \MATH ({ 7 }) . ({ 8 }) 
# Sentence pair (2109) source length 11 target length 11 alignment score : 0.00650561
-Krapac[11]-TrainGoogleImages : The training set is the same as DistScore-TrainGoogleImages . 
NULL ({ }) -Krapac[11]-TrainGoogleImages ({ 1 }) : ({ 2 }) The ({ 3 }) training ({ 4 }) set ({ 5 }) was ({ 6 }) the ({ 7 }) same ({ 8 }) as ({ 9 }) DistScore-TrainGoogleImages ({ 10 }) . ({ 11 }) 
# Sentence pair (2110) source length 16 target length 16 alignment score : 1.80549e-09
We re-implemented the method proposed by Krapac et al . \CITE for extracting query-dependent feature . 
NULL ({ 10 }) We ({ 1 }) re-implemented ({ 2 }) the ({ 3 }) method ({ 4 }) proposed ({ 5 }) by ({ 6 }) Krapac ({ 7 }) et ({ 8 }) al. ({ 9 }) \CITE ({ 11 }) of ({ 12 }) extracting ({ 13 }) the ({ }) query-dependent ({ 14 }) feature ({ 15 }) . ({ 16 }) 
# Sentence pair (2111) source length 19 target length 20 alignment score : 3.95862e-09
Since this method was proposed to handle images , not for faces , we modified it for handling faces . 
NULL ({ 11 }) Since ({ 1 }) this ({ 2 }) method ({ 3 }) was ({ 4 }) proposed ({ 5 }) to ({ 6 }) handle ({ 7 }) images ({ 8 }) , ({ 9 }) not ({ 10 }) faces ({ 12 }) , ({ 13 }) we ({ 14 }) modified ({ 15 }) it ({ 16 }) to ({ 17 }) handle ({ 18 }) faces ({ 19 }) . ({ 20 }) 
# Sentence pair (2112) source length 12 target length 13 alignment score : 4.03861e-08
Specifically , Each face is represented as a bag of visual words . 
NULL ({ 2 }) Each ({ 3 }) face ({ 4 }) was ({ 5 }) specifically ({ 1 }) represented ({ 6 }) as ({ 7 }) a ({ 8 }) bag ({ 9 }) of ({ 10 }) visual ({ 11 }) words ({ 12 }) . ({ 13 }) 
# Sentence pair (2113) source length 19 target length 20 alignment score : 1.109e-05
We used 13 facial feature points detected in each face and their descriptors using pixel intensity as visual words . 
NULL ({ }) We ({ 1 }) used ({ 2 }) 13 ({ 3 }) facial-feature ({ 4 5 }) points ({ 6 }) detected ({ 7 }) in ({ 8 }) each ({ 9 }) face ({ 10 }) and ({ 11 }) their ({ 12 }) descriptors ({ 13 }) using ({ 14 }) pixel ({ 15 }) intensity ({ 16 }) as ({ 17 }) visual ({ 18 }) words ({ 19 }) . ({ 20 }) 
# Sentence pair (2114) source length 21 target length 21 alignment score : 0.000269652
The codebook is formed by clustering all visual words extracted from all faces of the training set into 200 clusters . 
NULL ({ }) The ({ 1 }) codebook ({ 2 }) was ({ 3 }) formed ({ 4 }) by ({ 5 }) clustering ({ 6 }) all ({ 7 }) visual ({ 8 }) words ({ 9 }) extracted ({ 10 }) from ({ 11 }) all ({ 12 }) faces ({ 13 }) of ({ 14 }) the ({ 15 }) training ({ 16 }) set ({ 17 }) into ({ 18 }) 200 ({ 19 }) clusters ({ 20 }) . ({ 21 }) 
# Sentence pair (2115) source length 25 target length 24 alignment score : 8.96137e-06
top-$k$ visual words strongly related to the returned faces of each query and the binary feature vector are computed as described in \CITE . 
NULL ({ }) The ({ }) top-$k$ ({ 1 }) visual ({ 2 }) words ({ 3 }) strongly ({ 4 }) related ({ 5 }) to ({ 6 }) the ({ 7 }) returned ({ 8 }) faces ({ 9 }) of ({ 10 }) each ({ 11 }) query ({ 12 }) and ({ 13 }) the ({ 14 }) binary ({ 15 }) feature ({ 16 }) vector ({ 17 }) were ({ 18 }) computed ({ 19 }) as ({ 20 }) described ({ 21 }) in ({ 22 }) \CITE ({ 23 }) . ({ 24 }) 
# Sentence pair (2116) source length 37 target length 36 alignment score : 1.18041e-15
-Mensink[15]-GaussianModels : This method proposed by Mensink et al . \CITE models the returned faces by using two Gaussians , one for the faces relevant to the target person and one for the remaining faces . 
NULL ({ 10 }) -Mensink[15]-GaussianModels ({ 1 }) : ({ 2 }) This ({ 3 }) method ({ 4 }) proposed ({ 5 }) by ({ 6 }) Mensink ({ 7 }) et ({ 8 }) al. ({ 9 }) \CITE ({ 11 }) modeled ({ 12 }) the ({ 13 }) returned ({ 14 }) faces ({ 15 }) by ({ 16 }) using ({ 17 }) two ({ 18 }) Gaussians ({ 19 }) , ({ 20 }) the ({ }) first ({ 21 }) for ({ 22 }) the ({ 23 }) faces ({ 24 }) relevant ({ 25 }) to ({ 26 }) the ({ 27 }) target ({ 28 }) person ({ 29 }) and ({ 30 }) the ({ }) second ({ 31 }) for ({ 32 }) the ({ 33 }) remaining ({ 34 }) faces ({ 35 }) . ({ 36 }) 
# Sentence pair (2117) source length 23 target length 24 alignment score : 7.36732e-10
-Mensink[15]-Friends : This method proposed by Mensink et al . \CITE uses linear discriminant analysis to train a specific classifier for each query . 
NULL ({ 10 }) -Mensink[15]-Friends ({ 1 }) : ({ 2 }) This ({ 3 }) method ({ 4 }) proposed ({ 5 }) by ({ 6 }) Mensink ({ 7 }) et ({ 8 }) al. ({ 9 }) \CITE ({ 11 }) used ({ 12 }) linear ({ 13 }) discriminant ({ 14 }) analysis ({ 15 }) to ({ 16 }) train ({ 17 }) a ({ 18 }) specific ({ 19 }) classifier ({ 20 }) for ({ 21 }) each ({ 22 }) query ({ 23 }) . ({ 24 }) 
# Sentence pair (2118) source length 24 target length 24 alignment score : 1.57278e-06
This method uses detected person names in captions associated with faces for query expansion to model faces of the target person 's friends . 
NULL ({ }) This ({ 1 }) method ({ 2 }) used ({ 3 }) detected ({ 4 }) peoplefs ({ 5 }) names ({ 6 }) in ({ 7 }) captions ({ 8 }) associated ({ 9 }) with ({ 10 }) faces ({ 11 }) for ({ 12 }) query ({ 13 }) expansion ({ 14 }) to ({ 15 }) model ({ 16 }) faces ({ 17 }) of ({ 18 }) the ({ 19 }) target ({ 20 }) person ({ 21 }) 's ({ 22 }) friends ({ 23 }) . ({ 24 }) 
# Sentence pair (2119) source length 17 target length 23 alignment score : 3.16154e-16
The Methods such as Mensink[15]-GaussianModels and Mensink[15]-Friends are the state of the art methods that learn a specific classifier for each query . 
NULL ({ 9 11 12 }) Methods ({ 1 2 }) such ({ 3 }) as ({ 4 }) Mensink[15]-GaussianModels ({ 5 }) and ({ 6 }) Mensink[15]-Friends ({ 7 }) are ({ 8 }) state-of-the-art ({ 10 13 14 }) that ({ 15 }) learn ({ 16 }) a ({ 17 }) specific ({ 18 }) classifier ({ 19 }) for ({ 20 }) each ({ 21 }) query ({ 22 }) . ({ 23 }) 
# Sentence pair (2120) source length 22 target length 25 alignment score : 1.27562e-10
The method Krapac[11]-TrainGoogleImages is similar to our method in which one generic classifier is trained in advance and then is used for new queries . 
NULL ({ 20 }) Krapac[11]-TrainGoogleImages ({ 1 2 3 }) is ({ 4 }) similar ({ 5 }) to ({ 6 }) our ({ 7 }) method ({ 8 }) in ({ 9 }) which ({ 10 }) one ({ 11 }) generic ({ 12 }) classifier ({ 13 }) is ({ 14 }) trained ({ 15 }) in ({ 16 }) advance ({ 17 }) and ({ 18 }) then ({ 19 }) used ({ 21 }) for ({ 22 }) new ({ 23 }) queries ({ 24 }) . ({ 25 }) 
# Sentence pair (2121) source length 18 target length 16 alignment score : 2.17209e-12
Figure \REF shows the performance comparison of these systems when testing on YahooNews Images dataset . 
NULL ({ 6 }) Figure ({ 1 }) \REF ({ 2 }) compares ({ 3 }) the ({ 4 }) performance ({ 5 }) of ({ 7 }) these ({ 8 }) systems ({ 9 }) when ({ 10 }) they ({ }) were ({ }) tested ({ 11 }) on ({ 12 }) the ({ }) YahooNews ({ 13 }) Images ({ 14 }) dataset ({ 15 }) . ({ 16 }) 
# Sentence pair (2122) source length 25 target length 28 alignment score : 9.71954e-17
As for systems such as DistScore-TrainGoogleImages , NNScore-TrainGoogleImages , DistScore-TrainTRECVID , and NNScore-TrainTRECVID , the curves show the correlation between the performance and the number of features . 
NULL ({ 14 15 21 }) The ({ 1 }) curves ({ 16 }) plot ({ 17 }) the ({ 18 }) correlation ({ 19 }) between ({ 20 }) performance ({ 22 }) and ({ 23 }) the ({ 24 }) number ({ 25 }) of ({ 26 }) features ({ 27 }) for ({ 2 }) systems ({ 3 }) such ({ 4 }) as ({ 5 }) DistScore-TrainGoogleImages ({ 6 }) , ({ 7 }) NNScore-TrainGoogleImages ({ 8 }) , ({ 9 }) DistScore-TrainTRECVID ({ 10 }) , ({ 11 }) and ({ 12 }) NNScore-TrainTRECVID ({ 13 }) . ({ 28 }) 
# Sentence pair (2123) source length 7 target length 9 alignment score : 2.47656e-09
-DistScore is significantly better than that of NNScore . 
NULL ({ 6 7 }) -DistScore ({ 1 }) performed ({ 2 }) significantly ({ 3 }) better ({ 4 }) than ({ 5 }) NNScore ({ 8 }) . ({ 9 }) 
# Sentence pair (2124) source length 16 target length 16 alignment score : 4.3656e-05
-The performance of DistScore and NNScore are not affected by selecting the number of features . 
NULL ({ }) -The ({ 1 }) performance ({ 2 }) of ({ 3 }) DistScore ({ 4 }) and ({ 5 }) NNScore ({ 6 }) was ({ 7 }) not ({ 8 }) affected ({ 9 }) by ({ 10 }) selecting ({ 11 }) the ({ 12 }) number ({ 13 }) of ({ 14 }) features ({ 15 }) . ({ 16 }) 
# Sentence pair (2125) source length 15 target length 15 alignment score : 5.13566e-07
Therefore , we can use small number of features for reducing the computational cost . 
NULL ({ }) Therefore ({ 1 }) , ({ 2 }) we ({ 3 }) could ({ 4 }) use ({ 5 }) small ({ 6 }) numbers ({ 7 }) of ({ 8 }) features ({ 9 }) to ({ 10 }) reduce ({ 11 }) the ({ 12 }) computational ({ 13 }) cost ({ 14 }) . ({ 15 }) 
# Sentence pair (2126) source length 28 target length 30 alignment score : 1.95707e-13
-The performance of the system using the training data generated artificially by our method is comparable with that of the system using the training data returned by search engines . 
NULL ({ 7 23 }) -The ({ 1 }) performance ({ 2 }) of ({ 3 }) the ({ 4 }) system ({ 5 }) using ({ 6 }) training ({ 8 }) data ({ 9 }) generated ({ 10 }) artificially ({ 11 }) with ({ 12 }) our ({ 13 }) method ({ 14 }) was ({ 15 }) comparable ({ 16 }) to ({ 17 }) that ({ 18 }) of ({ 19 }) the ({ 20 }) system ({ 21 }) using ({ 22 }) training ({ 24 }) data ({ 25 }) returned ({ 26 }) by ({ 27 }) search ({ 28 }) engines ({ 29 }) . ({ 30 }) 
# Sentence pair (2127) source length 20 target length 20 alignment score : 9.86342e-24
-Our proposed method DistScore-TrainTRECVID has comparable performance to the state of the art method in specific classifier-based approach Mensink[15]-Friends . 
NULL ({ 2 11 12 }) -The ({ 1 }) method ({ 3 }) of ({ }) DistScore-TrainTRECVID ({ 4 }) we ({ }) propose ({ 6 }) performed ({ 5 }) comparably ({ 7 }) to ({ 8 }) the ({ 9 }) state-of-the-art ({ 10 13 }) method ({ 14 }) in ({ 15 }) the ({ }) specific ({ 16 }) classifier-based ({ 17 }) approach ({ 18 }) of ({ }) Mensink[15]-Friends ({ 19 }) . ({ 20 }) 
# Sentence pair (2128) source length 15 target length 10 alignment score : 1.47759e-09
It outperforms the method using only visual information Mensink[15]-GaussianModels . 
NULL ({ }) It ({ 1 }) outperformed ({ 2 }) the ({ 3 }) method ({ 4 }) where ({ 5 }) only ({ 6 }) visual ({ 7 }) information ({ 8 }) was ({ }) used ({ }) , ({ }) i.e. ({ }) , ({ }) Mensink[15]-GaussianModels ({ 9 }) . ({ 10 }) 
# Sentence pair (2129) source length 20 target length 18 alignment score : 4.83921e-12
-Our proposed method DistScore-TrainTRECVID outperforms the method proposed by Krapac et al . customized for handling faces . 
NULL ({ }) -Our ({ 1 }) proposed ({ 2 }) method ({ 3 }) DistScore-TrainTRECVID ({ 4 }) outperformed ({ 5 }) the ({ 6 }) method ({ 7 }) proposed ({ 8 }) by ({ 9 }) Krapac ({ 10 }) et ({ 11 }) al. ({ 12 }) , ({ }) which ({ 13 }) was ({ }) customized ({ 14 }) to ({ 15 }) handle ({ 16 }) faces ({ 17 }) . ({ 18 }) 
# Sentence pair (2130) source length 26 target length 23 alignment score : 1.91868e-12
As shown in Figure \REF , DistScore-TrainTRECVID outperforms original ranking of Google Images Search Engine if using from 20 to 50 features . 
NULL ({ }) As ({ 1 }) seen ({ 2 }) in ({ 3 }) Figure ({ 4 }) \REF ({ 5 }) , ({ 6 }) DistScore-TrainTRECVID ({ 7 }) outperformed ({ 8 }) the ({ }) original ({ 9 }) ranking ({ 10 }) of ({ 11 }) the ({ }) Google ({ 12 }) Images ({ 13 }) Search ({ 14 }) Engine ({ 15 17 }) if ({ 16 }) from ({ 18 }) 20 ({ 19 }) to ({ 20 }) 50 ({ 21 }) features ({ 22 }) were ({ }) used ({ }) . ({ 23 }) 
# Sentence pair (2131) source length 42 target length 39 alignment score : 8.36423e-19
The result of DistScore-TrainTRECVID on YahooNews Images set and Google Images set indicates that the relevance classifier of our proposed method is able to generalize well on different queries and independent with underlying ranking algorithms of search engines . 
NULL ({ }) The ({ 1 }) results ({ 2 }) for ({ 3 }) DistScore-TrainTRECVID ({ 4 }) on ({ 5 }) the ({ }) YahooNews ({ 6 }) Images ({ 7 }) set ({ 8 }) and ({ 9 }) Google ({ 10 }) Images ({ 11 }) set ({ 12 }) indicate ({ 13 }) that ({ 14 }) the ({ 15 }) relevance ({ 16 }) classifier ({ 17 }) with ({ 18 }) our ({ 19 }) proposed ({ 20 }) method ({ 21 }) was ({ 22 }) able ({ 23 }) to ({ 24 }) generalize ({ 25 }) well ({ 26 }) on ({ 27 }) different ({ 28 }) queries ({ 29 }) and ({ 30 }) was ({ }) independent ({ 31 }) of ({ 32 }) underlying ({ 33 }) ranking ({ 34 }) algorithms ({ 35 }) used ({ }) in ({ 36 }) search ({ 37 }) engines ({ 38 }) . ({ 39 }) 
# Sentence pair (2132) source length 32 target length 30 alignment score : 3.8148e-12
Figure \REF shows an example of re-ranking result of top-30 faces for the query John Paul that is one of the most difficult cases of the YahooNews Images set . 
NULL ({ }) Figure ({ 1 }) \REF ({ 2 }) shows ({ 3 }) an ({ 4 }) example ({ 5 }) of ({ 6 }) re-ranking ({ 7 }) results ({ 8 }) for ({ 9 }) the ({ }) top-30 ({ 10 }) faces ({ 11 }) for ({ 12 }) the ({ 13 }) query ({ 14 }) John ({ 15 }) Paul ({ 16 }) , ({ }) which ({ 17 }) is ({ 18 }) one ({ 19 }) of ({ 20 }) the ({ 21 }) most ({ 22 }) difficult ({ 23 }) cases ({ 24 }) in ({ 25 }) the ({ 26 }) YahooNews ({ 27 }) Images ({ 28 }) set ({ 29 }) . ({ 30 }) 
# Sentence pair (2133) source length 14 target length 17 alignment score : 2.35463e-12
The result clearly shows that our proposed method outperforms the other state of the art methods . 
NULL ({ 13 14 }) The ({ 1 }) results ({ 2 }) clearly ({ 3 }) demonstrate ({ 4 }) that ({ 5 }) our ({ 6 }) proposed ({ 7 }) method ({ 8 }) outperformed ({ 9 }) the ({ 10 }) other ({ 11 }) state-of-the-art ({ 12 15 }) methods ({ 16 }) . ({ 17 }) 
# Sentence pair (2134) source length 36 target length 35 alignment score : 2.87501e-10
Our query-dependent feature is based on nearest neighbors of the images in the returned image set that usually have complexity of \MATH , where \MATH is the total number of images in the set . 
NULL ({ 10 }) Our ({ 1 }) query-dependent ({ 2 }) feature ({ 3 }) was ({ 4 }) based ({ 5 }) on ({ 6 }) the ({ }) nearest ({ 7 }) neighbors ({ 8 }) of ({ 9 }) images ({ 11 }) in ({ 12 }) the ({ 13 }) returned ({ 14 }) image ({ 15 }) set ({ 16 }) that ({ 17 }) usually ({ 18 }) have ({ 19 }) a ({ }) complexity ({ 20 }) of ({ 21 }) \MATH ({ 22 }) , ({ 23 }) where ({ 24 }) \MATH ({ 25 }) is ({ 26 }) the ({ 27 }) total ({ 28 }) number ({ 29 }) of ({ 30 }) images ({ 31 }) in ({ 32 }) the ({ 33 }) set ({ 34 }) . ({ 35 }) 
# Sentence pair (2135) source length 40 target length 32 alignment score : 5.9782e-17
However , recent studies on indexing techniques such as \MATH -d tree , locality sensitive hashing ( LSH ) , and SASH \CITE can speed up the nearest neighbor search significantly . 
NULL ({ }) However ({ 1 }) , ({ 2 }) recent ({ 3 }) studies ({ 4 }) on ({ 5 }) indexing ({ 6 }) techniques ({ 7 }) such ({ 8 }) as ({ 9 }) \MATH ({ 10 }) -d ({ 11 }) tree ({ 12 }) , ({ 13 }) locality ({ 14 }) sensitive ({ 15 }) hashing ({ 16 }) ( ({ 17 }) LSH ({ 18 }) ) ({ 19 }) , ({ 20 }) and ({ 21 }) a ({ }) Self ({ 22 }) Adaptive ({ 23 }) Set ({ 24 }) of ({ }) Histograms ({ 27 }) ( ({ }) SASH ({ 31 }) ) ({ }) \CITE ({ }) could ({ }) significantly ({ }) speed ({ 25 }) up ({ 26 }) the ({ }) nearest ({ 28 }) neighbor ({ 29 }) search ({ 30 }) . ({ 32 }) 
# Sentence pair (2136) source length 18 target length 22 alignment score : 3.00738e-19
For example , as described in \CITE , the complexity of fast lookup of $k$ approximate nearest neighbors is \MATH \CITE . 
NULL ({ 3 4 6 7 }) For ({ 1 }) example ({ 2 }) , ({ 8 }) the ({ 9 }) complexity ({ 10 }) of ({ 11 }) the ({ }) fast ({ 12 }) lookup ({ 13 }) of ({ 14 }) $k$ ({ 15 }) approximate ({ 5 16 }) nearest ({ 17 }) neighbors ({ 18 }) is ({ 19 }) \MATH ({ 20 }) \CITE ({ 21 }) . ({ 22 }) 
# Sentence pair (2137) source length 19 target length 17 alignment score : 1.73218e-09
Studying other techniques to speedup the query-feature extraction process is our next step in future work . 
NULL ({ }) Studying ({ 1 }) other ({ 2 }) techniques ({ 3 }) to ({ 4 }) speed ({ 5 }) up ({ 6 }) the ({ }) process ({ 9 }) of ({ }) query-feature ({ 7 }) extraction ({ 8 }) is ({ 10 }) our ({ 11 }) next ({ 12 }) step ({ 13 }) in ({ 14 }) future ({ 15 }) work ({ 16 }) . ({ 17 }) 
# Sentence pair (2138) source length 1 target length 1 alignment score : 0.873979
b</subsection> 
NULL ({ }) 376 ({ 1 }) 
# Sentence pair (2139) source length 16 target length 16 alignment score : 1.52314e-05
We have presented a novel method for re-ranking face images returned by existing search engines . 
NULL ({ }) We ({ 1 }) have ({ 2 }) presented ({ 3 }) a ({ 4 }) novel ({ 5 }) method ({ 6 }) of ({ 7 }) re-ranking ({ 8 }) face ({ 9 }) images ({ 10 }) returned ({ 11 }) by ({ 12 }) existing ({ 13 }) search ({ 14 }) engines ({ 15 }) . ({ 16 }) 
# Sentence pair (2140) source length 25 target length 25 alignment score : 1.31236e-10
Instead of training a specific classifier for each new query , we train only one generic classifier and use it for ranking new queries . 
NULL ({ }) Instead ({ 1 }) of ({ 2 }) training ({ 3 }) a ({ 4 }) specific ({ 5 }) classifier ({ 6 }) for ({ 7 }) each ({ 8 }) new ({ 9 }) query ({ 10 }) , ({ 11 }) we ({ 12 }) only ({ 14 }) trained ({ 13 }) one ({ 15 }) generic ({ 16 }) classifier ({ 17 }) and ({ 18 }) used ({ 19 }) it ({ 20 }) for ({ 21 }) ranking ({ 22 }) new ({ 23 }) queries ({ 24 }) . ({ 25 }) 
# Sentence pair (2141) source length 9 target length 10 alignment score : 1.62313e-05
This helps to make the ranking application more scalable . 
NULL ({ 3 }) This ({ 1 }) helped ({ 2 }) make ({ 4 }) the ({ 5 }) ranking ({ 6 }) application ({ 7 }) more ({ 8 }) scalable ({ 9 }) . ({ 10 }) 
# Sentence pair (2142) source length 23 target length 24 alignment score : 7.34147e-14
To train the generic classifier , We propose a simple unsupervised method to obtain a large number of labeled faces from video archives . 
NULL ({ 6 }) We ({ 7 }) propose ({ 8 }) a ({ 9 }) simple ({ 10 }) unsupervised ({ 11 }) method ({ 12 }) to ({ 1 }) train ({ 2 }) the ({ 3 }) generic ({ 4 }) classifier ({ 5 }) to ({ 13 }) obtain ({ 14 }) a ({ 15 }) large ({ 16 }) number ({ 17 }) of ({ 18 }) labeled ({ 19 }) faces ({ 20 }) from ({ 21 }) video ({ 22 }) archives ({ 23 }) . ({ 24 }) 
# Sentence pair (2143) source length 18 target length 18 alignment score : 0.000413918
It uses temporal information to group faces belonging to one person in one shot into one track . 
NULL ({ }) It ({ 1 }) uses ({ 2 }) temporal ({ 3 }) information ({ 4 }) to ({ 5 }) group ({ 6 }) faces ({ 7 }) belonging ({ 8 }) to ({ 9 }) one ({ 10 }) person ({ 11 }) in ({ 12 }) one ({ 13 }) shot ({ 14 }) into ({ 15 }) one ({ 16 }) track ({ 17 }) . ({ 18 }) 
# Sentence pair (2144) source length 22 target length 22 alignment score : 1.11418e-05
Several heuristics are employed to guarantee that a subset of face tracks has the correct labels used in the training process . 
NULL ({ }) Several ({ 1 }) heuristics ({ 2 }) are ({ 3 }) employed ({ 4 }) to ({ 5 }) guarantee ({ 6 }) that ({ 7 }) a ({ 8 }) subset ({ 9 }) of ({ 10 }) face ({ 11 }) tracks ({ 12 }) has ({ 13 }) the ({ 14 }) correct ({ 15 }) labels ({ 16 }) used ({ 17 }) in ({ 18 }) the ({ 19 }) training ({ 20 }) process ({ 21 }) . ({ 22 }) 
# Sentence pair (2145) source length 32 target length 30 alignment score : 4.42991e-20
Experiments shown that although our method is unsupervised and independent with underlying algorithms of existing search engines but successfully learns visual consistency among returned faces to boosts retrieval performance . 
NULL ({ }) Experiments ({ 1 }) revealed ({ 2 }) that ({ 3 }) although ({ 4 }) our ({ 5 }) method ({ 6 }) is ({ 7 }) unsupervised ({ 8 }) and ({ 9 }) independent ({ 10 }) of ({ 11 }) underlying ({ 12 }) algorithms ({ 13 }) in ({ 14 }) existing ({ 15 }) search ({ 16 }) engines ({ 17 }) , ({ }) it ({ 18 }) successfully ({ 19 }) learned ({ 20 }) visual ({ 21 }) consistency ({ 22 }) between ({ 23 }) returned ({ 24 }) faces ({ 25 }) to ({ 26 }) boost ({ 27 }) efficiency ({ 28 }) of ({ }) retrieval ({ 29 }) . ({ 30 }) 
# Sentence pair (2146) source length 7 target length 7 alignment score : 0.060447
Enhancing mathematical search with names of formulas 
NULL ({ }) Enhancing ({ 1 }) mathematical ({ 2 }) searches ({ 3 }) with ({ 4 }) names ({ 5 }) of ({ 6 }) formulas ({ 7 }) 
# Sentence pair (2147) source length 14 target length 17 alignment score : 3.00203e-13
We present a method to enhance the performance of a mathematical search system in this paper . 
NULL ({ 14 }) We ({ 1 }) present ({ 2 }) a ({ 3 }) method ({ 4 }) to ({ 5 }) enhance ({ 6 15 16 }) the ({ 7 }) performance ({ 8 }) of ({ 9 }) a ({ 10 }) mathematical ({ 11 }) search ({ 12 }) system ({ 13 }) . ({ 17 }) 
# Sentence pair (2148) source length 32 target length 33 alignment score : 9.03296e-14
Targeting to mathematical formulas that appear in natural language documents , we collect the names of formulas from the surrounding text , and incorpo-rate the correspondence to the search system 's database . 
NULL ({ 2 22 }) By ({ }) targeting ({ 1 }) mathematical ({ 3 }) formulas ({ 4 }) that ({ 5 }) appear ({ 6 }) in ({ 7 }) natural ({ 8 }) language ({ 9 }) documents ({ 10 }) , ({ 11 }) we ({ 12 }) collect ({ 13 }) the ({ 14 }) names ({ 15 }) of ({ 16 }) formulas ({ 17 }) from ({ 18 }) the ({ 19 }) surrounding ({ 20 }) text ({ 21 }) and ({ 23 }) incorporate ({ 24 }) the ({ 25 }) correspondence ({ 26 }) into ({ 27 }) the ({ 28 }) search ({ 29 }) system ({ 30 }) 's ({ 31 }) database ({ 32 }) . ({ 33 }) 
# Sentence pair (2149) source length 20 target length 21 alignment score : 1.63927e-13
E ectiveness of the proposed approach is shown through experiments using Wikipedia mathematical articles and Wolfram Functions Site data sets . 
NULL ({ 5 }) The ({ 1 }) effectiveness ({ 2 }) of ({ 3 }) the ({ 4 }) approach ({ 6 }) is ({ 7 }) demonstrated ({ 8 }) through ({ 9 }) experiments ({ 10 }) using ({ 11 }) Wikipedia ({ 12 }) mathematical ({ 13 }) articles ({ 14 }) and ({ 15 }) Wolfram ({ 16 }) Functions ({ 17 }) Site ({ 18 }) data ({ 19 }) sets ({ 20 }) . ({ 21 }) 
# Sentence pair (2150) source length 27 target length 43 alignment score : 6.04033e-70
In the current digital environment , the mathematical content being published on the Web is increasing day by day . While more and more mathematical contents being available on the Web , retrieving mathematical contents becomes an important issue for many users . 
NULL ({ 2 7 20 29 30 32 }) The ({ }) mathematical ({ 8 }) content ({ 9 26 }) being ({ 10 27 }) published ({ 1 11 28 }) on ({ 12 }) the ({ 13 }) Web ({ 3 14 31 }) is ({ 15 }) increasing ({ 16 }) day ({ 4 17 19 }) by ({ 18 }) day ({ 5 21 22 }) , ({ 6 }) and ({ 23 }) retrieving ({ 24 33 }) mathematical ({ 25 34 }) content ({ 35 }) has ({ }) become ({ 36 }) an ({ 37 }) important ({ 38 }) issue ({ 39 }) for ({ 40 }) many ({ 41 }) users ({ 42 }) . ({ 43 }) 
# Sentence pair (2151) source length 25 target length 27 alignment score : 4.39303e-19
Teach-ers , students , researchers do need to gain access to mathematical resources for teaching , studying , or obtaining updated information for research and development . 
NULL ({ }) Teachers ({ 1 }) , ({ 2 }) students ({ 3 }) , ({ 4 }) and ({ }) researchers ({ 5 6 }) need ({ 7 }) better ({ 8 }) access ({ 9 10 }) to ({ 11 }) mathematical ({ 12 }) resources ({ 13 }) for ({ 14 }) teaching ({ 15 }) , ({ 16 }) studying ({ 17 }) , ({ 18 }) and ({ }) obtaining ({ 19 20 21 }) information ({ 22 }) for ({ 23 }) research ({ 24 }) and ({ 25 }) development ({ 26 }) . ({ 27 }) 
# Sentence pair (2152) source length 17 target length 18 alignment score : 1.60785e-11
Therefore , users need specialized search systems to nd the formula that is relevant to their requirements . 
NULL ({ 10 }) Moreover ({ 1 }) , ({ 2 }) users ({ 3 }) need ({ 4 }) specialized ({ 5 }) search ({ 6 }) systems ({ 7 }) to ({ 8 }) find ({ 9 }) formulas ({ 11 }) that ({ 12 }) are ({ 13 }) relevant ({ 14 }) to ({ 15 }) their ({ 16 }) needs ({ 17 }) . ({ 18 }) 
# Sentence pair (2153) source length 33 target length 37 alignment score : 1.26543e-29
Internet search engines are able to detect some particular keywords in mathematical formula but they mostly fail to recognize mathematical symbols and constructs such as integral sym-bols , square root symbols , fractions , or matrices . 
NULL ({ 4 6 28 }) Internet ({ 1 }) search ({ 2 }) engines ({ 3 }) can ({ 5 }) detect ({ 7 8 }) particular ({ 9 }) keywords ({ 10 }) in ({ 11 }) mathematical ({ 12 }) formulas ({ 13 }) but ({ 14 }) they ({ 15 }) mostly ({ 16 }) fail ({ 17 }) at ({ 18 }) recognizing ({ 19 }) mathematical ({ 20 }) symbols ({ 21 }) and ({ 22 }) constructs ({ 23 }) such ({ 24 }) as ({ 25 }) integral ({ 26 }) and ({ }) square ({ 27 29 }) root ({ 30 }) symbols ({ 31 }) , ({ 32 }) fractions ({ 33 }) , ({ 34 }) and ({ }) matrices ({ 35 36 }) . ({ 37 }) 
# Sentence pair (2154) source length 11 target length 11 alignment score : 2.37026e-08
There exist some mathematical-dedicated search engines available on the Internet . 
NULL ({ }) There ({ 1 }) are ({ 2 }) some ({ 3 }) mathematically ({ 4 }) oriented ({ 7 }) search ({ 5 }) engines ({ 6 }) on ({ 8 }) the ({ 9 }) Internet ({ 10 }) . ({ 11 }) 
# Sentence pair (2155) source length 21 target length 21 alignment score : 0.000193199
Although such engines provide more accurate and relevant results , they usually do not provide enough information for the user . 
NULL ({ }) Although ({ 1 }) such ({ 2 }) engines ({ 3 }) provide ({ 4 }) more ({ 5 }) accurate ({ 6 }) and ({ 7 }) relevant ({ 8 }) results ({ 9 }) , ({ 10 }) they ({ 11 }) usually ({ 12 }) do ({ 13 }) not ({ 14 }) provide ({ 15 }) enough ({ 16 }) information ({ 17 }) for ({ 18 }) the ({ 19 }) user ({ 20 }) . ({ 21 }) 
# Sentence pair (2156) source length 35 target length 32 alignment score : 7.60004e-25
Furthermore , these systems do not take into account the semantics of mathematical formulas revealed by surrounding natural language text , like the name of the formula and its variables' descrip-tion . 
NULL ({ 23 25 28 }) Furthermore ({ 1 }) , ({ 2 }) these ({ 3 }) systems ({ 4 }) do ({ 5 }) not ({ 6 }) take ({ 7 }) into ({ 8 }) account ({ 9 }) the ({ 10 }) semantics ({ 11 }) of ({ 12 }) mathematical ({ 13 }) formulas ({ 14 }) as ({ }) revealed ({ 15 }) by ({ 16 }) the ({ }) surrounding ({ 17 }) natural ({ 18 }) language ({ 19 }) text ({ 20 }) , ({ 21 }) e.g. ({ }) , ({ }) the ({ }) formulafs ({ 22 }) name ({ 24 }) or ({ }) the ({ 26 }) description ({ 27 }) of ({ }) its ({ 29 }) variables ({ 30 31 }) . ({ 32 }) 
# Sentence pair (2157) source length 20 target length 20 alignment score : 1.25075e-05
The Digital Library of Mathematical functions ( DLMF ) project is a mathematical database available on the Web [8] . 
NULL ({ }) The ({ 1 }) Digital ({ 2 }) Library ({ 3 }) of ({ 4 }) Mathematical ({ 5 }) Functions ({ 6 }) ( ({ 7 }) DLMF ({ 8 }) ) ({ 9 }) project ({ 10 }) is ({ 11 }) a ({ 12 }) mathematical ({ 13 }) database ({ 14 }) available ({ 15 }) on ({ 16 }) the ({ 17 }) Web ({ 18 }) [8] ({ 19 }) . ({ 20 }) 
# Sentence pair (2158) source length 17 target length 17 alignment score : 0.00212286
This site provides a major resource of mathematical reference data for special formulas and their applications . 
NULL ({ }) This ({ 1 }) site ({ 2 }) provides ({ 3 }) a ({ 4 }) major ({ 5 }) resource ({ 6 }) of ({ 7 }) mathematical ({ 8 }) reference ({ 9 }) data ({ 10 }) for ({ 11 }) special ({ 12 }) formulas ({ 13 }) and ({ 14 }) their ({ 15 }) applications ({ 16 }) . ({ 17 }) 
# Sentence pair (2159) source length 12 target length 9 alignment score : 1.29933e-14
But full mathematical search is still not available . 
NULL ({ }) But ({ 1 6 }) even ({ }) this ({ }) site ({ }) does ({ 5 }) not ({ 7 }) provide ({ 8 }) a ({ }) full ({ 2 }) mathematical ({ 3 }) search ({ 4 }) . ({ 9 }) 
# Sentence pair (2160) source length 13 target length 13 alignment score : 0.00593012
Other systems that support mathematical search are MathFind [4] , MathWebSearch [3] . 
NULL ({ }) Other ({ 1 }) systems ({ 2 }) that ({ 3 }) support ({ 4 }) mathematical ({ 5 }) searches ({ 6 }) are ({ 7 }) MathFind ({ 8 }) [4] ({ 9 }) , ({ 10 }) MathWebSearch ({ 11 }) [3] ({ 12 }) . ({ 13 }) 
# Sentence pair (2161) source length 16 target length 16 alignment score : 2.0612e-05
These systems , however , provide neither similarity structures nor semantic meanings of the formulas . 
NULL ({ }) These ({ 1 }) systems ({ 2 }) , ({ 3 }) however ({ 4 }) , ({ 5 }) provide ({ 6 }) neither ({ 7 }) similarity ({ 8 }) structures ({ 9 }) nor ({ 10 }) semantic ({ 11 }) meanings ({ 12 }) of ({ 13 }) their ({ 14 }) formulas ({ 15 }) . ({ 16 }) 
# Sentence pair (2162) source length 21 target length 19 alignment score : 1.27878e-13
The Wolfram Functions Site [7] contains large mathe-matical formulas and also provides a semantics search for mathematical formulas . 
NULL ({ }) The ({ 1 }) Wolfram ({ 2 }) Functions ({ 3 }) Site ({ 4 }) [7] ({ 5 }) contains ({ 6 }) a ({ }) large ({ 7 }) number ({ 8 }) of ({ }) mathematical ({ 17 }) formulas ({ 9 }) and ({ 10 }) also ({ 11 }) provides ({ 12 }) a ({ 13 }) semantic ({ 14 }) search ({ 15 }) for ({ 16 }) them ({ 18 }) . ({ 19 }) 
# Sentence pair (2163) source length 52 target length 49 alignment score : 1.97372e-42
This site and some recent works done by Adeel et al. [2] and Yokoi and Aizawa [1] propose similarity search methods based on MathML but these works do not make use of the semantics of the formulas' surrounding text , which is considered to be important information sources . 
NULL ({ 40 44 }) This ({ 1 }) site ({ 2 }) and ({ 3 }) some ({ 4 }) recent ({ 5 }) work ({ 6 }) done ({ 7 }) by ({ 8 }) Adeel ({ 9 }) et ({ 10 }) al. ({ 11 }) [2] ({ 12 }) and ({ 13 }) Yokoi ({ 14 }) and ({ 15 }) Aizawa ({ 16 26 27 }) [1] ({ 17 }) employ ({ 18 }) similarity ({ 19 }) search ({ 20 }) methods ({ 21 }) based ({ 22 }) on ({ 23 }) MathML ({ 24 }) but ({ 25 }) they ({ }) do ({ 28 }) not ({ 29 }) make ({ 30 }) use ({ 31 }) of ({ 32 }) the ({ 33 }) semantics ({ 34 }) of ({ 35 }) the ({ 36 }) formulas' ({ 37 }) surrounding ({ 38 }) text ({ 39 }) . ({ }) //[ ({ 41 }) ? ({ }) ? ({ }) propose ({ }) is ({ 42 }) unclear ({ }) in ({ }) the ({ }) sense ({ }) of ({ }) a ({ }) website ({ 43 46 48 }) .] ({ 45 47 49 }) 
# Sentence pair (2164) source length 25 target length 24 alignment score : 2.56322e-06
The work presented in this paper focuses on retrieving mathematical formulas on the Web using mathematical expressions and the surrounding natural language text . 
NULL ({ }) The ({ 1 }) work ({ 2 }) presented ({ 3 }) in ({ 4 }) this ({ 5 }) paper ({ 6 }) focuses ({ 7 }) on ({ 8 }) retrieving ({ 9 }) mathematical ({ 10 }) formulas ({ 11 }) on ({ 12 }) the ({ 13 }) Web ({ 14 }) by ({ }) using ({ 15 }) mathematical ({ 16 }) expressions ({ 17 }) and ({ 18 }) the ({ 19 }) surrounding ({ 20 }) natural ({ 21 }) language ({ 22 }) text ({ 23 }) . ({ 24 }) 
# Sentence pair (2165) source length 24 target length 27 alignment score : 4.89648e-19
We describe here in detail our work toward creating a mathematical database that contains for-mulas , their names , their variables' descriptions and other related information . 
NULL ({ 4 }) We ({ 1 }) describe ({ 2 }) our ({ 6 }) work ({ 7 }) toward ({ 3 5 8 }) creating ({ 9 }) a ({ 10 }) mathematical ({ 11 }) database ({ 12 }) that ({ 13 }) contains ({ 14 }) formulas ({ 15 }) , ({ 16 }) their ({ 17 }) names ({ 18 }) , ({ 19 }) variable ({ 20 }) descriptions ({ 21 22 }) , ({ }) and ({ 23 }) other ({ 24 }) related ({ 25 }) information ({ 26 }) . ({ 27 }) 
# Sentence pair (2166) source length 15 target length 16 alignment score : 8.05114e-08
We also implement a mathematical search system that use this information as its base knowledge . 
NULL ({ }) We ({ 1 }) implemented ({ 2 3 }) a ({ 4 }) mathematical ({ 5 }) search ({ 6 }) system ({ 7 }) that ({ 8 }) uses ({ 9 }) this ({ 10 }) information ({ 11 }) as ({ 12 }) its ({ 13 }) base ({ 14 }) knowledge ({ 15 }) . ({ 16 }) 
# Sentence pair (2167) source length 30 target length 31 alignment score : 1.37299e-11
This information is very helpful when performing mathematical search by reducing the need for formula input and solving the notational variation problem where mathematically equivalent formulas follow di erent notations . 
NULL ({ }) This ({ 1 }) information ({ 2 }) is ({ 3 }) very ({ 4 }) helpful ({ 5 }) when ({ 6 }) performing ({ 7 }) mathematical ({ 8 }) search ({ 9 }) by ({ 10 }) reducing ({ 11 }) the ({ 12 }) need ({ 13 }) for ({ 14 }) formula ({ 15 }) input ({ 16 }) and ({ 17 }) solving ({ 18 }) the ({ 19 }) notational ({ 20 }) variation ({ 21 }) problem ({ 22 }) where ({ 23 }) mathematically ({ 24 }) equivalent ({ 25 }) formulas ({ 26 }) follow ({ 27 }) different ({ 28 }) notations ({ 29 30 }) . ({ 31 }) 
# Sentence pair (2168) source length 24 target length 23 alignment score : 1.84035e-10
Relations between formulas and their name could also be used to correct errors in mathematical OCR systems , such as Infty [5] . 
NULL ({ }) The ({ 6 }) relationship ({ 1 }) between ({ 2 }) formulas ({ 3 }) and ({ 4 }) their ({ 5 }) names ({ 7 }) can ({ }) also ({ 8 }) be ({ 9 }) used ({ 10 }) to ({ 11 }) correct ({ 12 }) errors ({ 13 }) in ({ 14 }) mathematical ({ 15 }) OCR ({ 16 }) systems ({ 17 }) , ({ 18 }) such ({ 19 }) as ({ 20 }) Infty ({ 21 }) [5] ({ 22 }) . ({ 23 }) 
# Sentence pair (2169) source length 16 target length 20 alignment score : 1.45943e-13
It also provides opportunities to make mathematical better understandable and usable for di erent groups of people with disabilities . 
NULL ({ 12 }) It ({ 1 }) also ({ 2 }) provides ({ 3 }) opportunities ({ 4 }) to ({ 5 }) make ({ 6 }) mathematics ({ 7 }) better ({ 8 }) understandable ({ 9 }) and ({ 10 }) usable ({ 11 13 14 15 }) for ({ 16 }) people ({ 17 }) with ({ 18 }) disabilities ({ 19 }) . ({ 20 }) 
# Sentence pair (2170) source length 21 target length 23 alignment score : 4.79526e-15
The remainder of this paper is organized as follow : In section 2 , we present an overview of the proposed framework . 
NULL ({ 14 20 }) The ({ 1 }) remainder ({ 2 }) of ({ 3 }) this ({ 4 }) paper ({ 5 }) is ({ 6 }) organized ({ 7 }) as ({ 8 }) follows ({ 9 }) : ({ 10 }) we ({ 15 }) present ({ 16 }) an ({ 17 }) overview ({ 18 }) of ({ 19 }) our ({ 21 }) framework ({ 22 }) in ({ 11 }) section ({ 12 }) 2 ({ 13 }) . ({ 23 }) 
# Sentence pair (2171) source length 12 target length 12 alignment score : 0.0109967
We then describe the results of our experiments in section 3 . 
NULL ({ }) We ({ 1 }) then ({ 2 }) describe ({ 3 }) the ({ 4 }) results ({ 5 }) of ({ 6 }) our ({ 7 }) experiments ({ 8 }) in ({ 9 }) section ({ 10 }) 3 ({ 11 }) . ({ 12 }) 
# Sentence pair (2172) source length 12 target length 12 alignment score : 3.95035e-06
Section 4 concludes the paper and gives avenues for future works . 
NULL ({ }) Section ({ 1 }) 4 ({ 2 }) concludes ({ 3 }) the ({ 4 }) paper ({ 5 }) and ({ 6 }) gives ({ 7 }) avenues ({ 8 }) of ({ 9 }) future ({ 10 }) study ({ 11 }) . ({ 12 }) 
# Sentence pair (2173) source length 22 target length 27 alignment score : 2.50411e-29
Mathematical formulas on the Web has many di erent formats , some of them are LaTeX , and the Mathematical Markup Language ( MathML ) [6] . 
NULL ({ 13 14 15 17 19 }) Mathematical ({ 1 }) formulas ({ 2 }) on ({ 3 }) the ({ 4 }) Web ({ 5 }) have ({ 6 }) many ({ 7 }) different ({ 8 }) formats ({ 9 10 }) , ({ 11 }) e.g. ({ 12 }) , ({ }) LaTeX ({ 16 }) and ({ 18 }) Mathematical ({ 20 }) Markup ({ 21 }) Language ({ 22 }) ( ({ 23 }) MathML ({ 24 }) ) ({ 25 }) [6] ({ 26 }) . ({ 27 }) 
# Sentence pair (2174) source length 7 target length 7 alignment score : 8.62868e-05
This makes the search more dif-cult . 
NULL ({ }) This ({ 1 }) diversity ({ 2 }) makes ({ 3 }) searches ({ 4 }) more ({ 5 }) difficult ({ 6 }) . ({ 7 }) 
# Sentence pair (2175) source length 14 target length 14 alignment score : 5.71805e-05
In this paper , we use the presentation MathML format for mathematical formulas . 
NULL ({ }) In ({ 1 }) this ({ 2 }) paper ({ 3 }) , ({ 4 }) we ({ 5 }) shall ({ 8 }) use ({ 6 }) the ({ 7 }) MathML ({ 9 }) format ({ 10 }) for ({ 11 }) mathematical ({ 12 }) formulas ({ 13 }) . ({ 14 }) 
# Sentence pair (2176) source length 17 target length 17 alignment score : 3.84833e-07
Formulas with other formats can be easily converted to MathML format using existing freely available tools . 
NULL ({ }) Formulas ({ 1 }) with ({ 2 }) other ({ 3 }) formats ({ 4 }) can ({ 5 }) be ({ 6 }) easily ({ 7 }) converted ({ 8 }) to ({ 9 }) MathML ({ 10 }) format ({ 11 }) by ({ }) using ({ 12 }) freely ({ 13 14 }) available ({ 15 }) tools ({ 16 }) . ({ 17 }) 
# Sentence pair (2177) source length 16 target length 15 alignment score : 3.21285e-06
For our works , we use LaTeXML Converter which is freely available at \URL . 
NULL ({ }) For ({ 1 }) our ({ 2 }) work ({ 3 }) , ({ 4 }) we ({ 5 }) used ({ 6 }) LaTeXML ({ 7 }) Converter ({ 8 }) , ({ }) which ({ 9 }) is ({ 10 }) freely ({ 11 }) available ({ 12 }) at ({ 13 }) \URL ({ 14 }) . ({ 15 }) 
# Sentence pair (2178) source length 14 target length 14 alignment score : 0.00618567
We automatically collected our mathematical formulas from Wikipedia and the Wolfram Functions Site . 
NULL ({ }) We ({ 1 }) automatically ({ 2 }) collected ({ 3 }) our ({ 4 }) mathematical ({ 5 }) formulas ({ 6 }) from ({ 7 }) Wikipedia ({ 8 }) and ({ 9 }) the ({ 10 }) Wolfram ({ 11 }) Functions ({ 12 }) Site ({ 13 }) . ({ 14 }) 
# Sentence pair (2179) source length 25 target length 23 alignment score : 5.56318e-08
Figure 1 shows a page on mathematical section on Wikipedia and the information we retrieved on this site besides the mathematical formulas . 
NULL ({ }) Figure ({ 1 }) 1 ({ 2 }) shows ({ 3 }) a ({ 4 }) page ({ 5 }) from ({ 6 }) a ({ }) mathematical ({ 7 }) section ({ 8 }) on ({ 9 }) Wikipedia ({ 10 }) and ({ 11 }) the ({ 12 }) information ({ 13 }) we ({ 14 }) retrieved ({ 15 }) on ({ 16 }) this ({ 17 }) site ({ 18 }) , ({ }) besides ({ 19 }) the ({ 20 }) mathematical ({ 21 }) formulas ({ 22 }) . ({ 23 }) 
# Sentence pair (2180) source length 14 target length 21 alignment score : 1.52365e-30
At this point , we use some heuristics to provide an adequate solution for matching mathematical formulas with their names . 
NULL ({ 4 14 }) We ({ }) used ({ 6 }) heuristics ({ 7 8 }) to ({ 9 }) ensure ({ 1 3 10 12 }) adequate ({ 2 5 11 13 }) matching ({ 15 }) of ({ }) mathematical ({ 16 }) formulas ({ 17 }) with ({ 18 }) their ({ 19 }) names ({ 20 }) . ({ 21 }) 
# Sentence pair (2181) source length 21 target length 21 alignment score : 2.77017e-06
These heuristics are based on the type settings and distances between the name strings and formulas in the same page . 
NULL ({ }) These ({ 1 }) heuristics ({ 2 }) are ({ 3 }) based ({ 4 }) on ({ 5 }) the ({ 6 }) type ({ 7 }) settings ({ 8 }) and ({ 9 }) distances ({ 10 }) between ({ 11 }) the ({ 12 }) name ({ 13 }) strings ({ 14 }) and ({ 15 }) formulas ({ 16 }) on ({ 17 }) the ({ 18 }) same ({ 19 }) page ({ 20 }) . ({ 21 }) 
# Sentence pair (2182) source length 14 target length 15 alignment score : 7.17917e-07
After collecting the mathematical formulas from these resources , we extract keywords for indexing . 
NULL ({ 3 }) After ({ 1 }) collecting ({ 2 }) mathematical ({ 4 }) formulas ({ 5 }) from ({ 6 }) these ({ 7 }) resources ({ 8 }) , ({ 9 }) we ({ 10 }) extracted ({ 11 }) keywords ({ 12 }) for ({ 13 }) indexing ({ 14 }) . ({ 15 }) 
# Sentence pair (2183) source length 15 target length 15 alignment score : 0.000787378
The keywords include formulas' names , operators , variables' names , and so on . 
NULL ({ }) The ({ 1 }) keywords ({ 2 }) included ({ 3 }) formulas' ({ 4 }) names ({ 5 }) , ({ 6 }) operators ({ 7 }) , ({ 8 }) variables' ({ 9 }) names ({ 10 }) , ({ 11 }) and ({ 12 }) so ({ 13 }) on ({ 14 }) . ({ 15 }) 
# Sentence pair (2184) source length 14 target length 16 alignment score : 1.6505e-08
Our system allows two ways of searching : text content search and formula content search . 
NULL ({ }) Our ({ 1 }) system ({ 2 }) allows ({ 3 }) two ({ 4 }) ways ({ 5 }) of ({ 6 }) searching ({ 7 }) : ({ 8 }) text ({ 9 }) content ({ 10 11 }) and ({ 12 }) formula ({ 13 }) content ({ 14 15 }) . ({ 16 }) 
# Sentence pair (2185) source length 27 target length 30 alignment score : 4.58581e-32
In the rst case , users can use the extracted keywords for search , for example : " sin " , " Pythagorean " or " trigonometric functions " . 
NULL ({ 2 9 12 15 }) In ({ 1 }) a ({ }) text ({ }) content ({ 4 }) search ({ }) , ({ 5 }) users ({ 6 }) search ({ 13 }) with ({ }) extracted ({ 10 }) keywords ({ 11 }) , ({ 14 }) e.g. ({ 16 }) , ({ 17 }) " ({ 18 }) sin ({ 19 }) " ({ 20 }) , ({ 21 }) " ({ 22 }) Pythagorean ({ 23 }) " ({ 24 }) or ({ 25 }) " ({ 26 }) trigonometric ({ 3 7 8 27 }) functions ({ 28 }) " ({ 29 }) . ({ 30 }) 
# Sentence pair (2186) source length 17 target length 18 alignment score : 1.62496e-17
In the second case , users can input the mathematical formulas directly , for example : \MATH . 
NULL ({ }) In ({ 1 }) a ({ 2 }) formula ({ 3 }) content ({ 4 }) search ({ 7 }) , ({ 5 }) users ({ 6 }) directly ({ 12 }) input ({ 8 }) the ({ 9 }) formulas ({ 10 11 }) , ({ 13 }) for ({ 14 }) example ({ 15 }) : ({ 16 }) \MATH ({ 17 }) . ({ 18 }) 
# Sentence pair (2187) source length 9 target length 9 alignment score : 0.0293583
The system then looks for relevant formula names . 
NULL ({ }) The ({ 1 }) system ({ 2 }) then ({ 3 }) looks ({ 4 }) for ({ 5 }) relevant ({ 6 }) formula ({ 7 }) names ({ 8 }) . ({ 9 }) 
# Sentence pair (2188) source length 13 target length 13 alignment score : 1.79886e-05
If found , it will return other information related with that formula . 
NULL ({ }) If ({ 1 }) found ({ 2 }) , ({ 3 }) it ({ 4 }) will ({ 5 }) return ({ 6 }) other ({ 7 }) information ({ 8 }) related ({ 9 }) to ({ 10 }) that ({ 11 }) formula ({ 12 }) . ({ 13 }) 
# Sentence pair (2189) source length 26 target length 22 alignment score : 6.03235e-13
Else , it just looks for mathematical formulas which are similar to the input ( including formulas with similar structure ) . 
NULL ({ }) If ({ }) nothing ({ 1 }) matching ({ }) is ({ }) found ({ }) , ({ 2 }) it ({ 3 }) looks ({ 4 5 }) for ({ 6 }) mathematical ({ 7 }) formulas ({ 8 }) which ({ 9 }) are ({ 10 }) similar ({ 11 }) to ({ 12 }) the ({ 13 }) input ({ 14 }) ( ({ 15 }) including ({ 16 }) formulas ({ 17 }) with ({ 18 }) a ({ }) similar ({ 19 }) structure ({ 20 }) ) ({ 21 }) . ({ 22 }) 
# Sentence pair (2190) source length 21 target length 21 alignment score : 0.000128459
Evaluate a mathematical search system is not an easy task because we do not have any standard for this task . 
NULL ({ }) Evaluating ({ 1 }) a ({ 2 }) mathematical ({ 3 }) search ({ 4 }) system ({ 5 }) is ({ 6 }) not ({ 7 }) an ({ 8 }) easy ({ 9 }) task ({ 10 }) because ({ 11 }) we ({ 12 }) do ({ 13 }) not ({ 14 }) have ({ 15 }) any ({ 16 }) standard ({ 17 }) for ({ 18 }) this ({ 19 }) task ({ 20 }) . ({ 21 }) 
# Sentence pair (2191) source length 9 target length 9 alignment score : 0.0319264
The similarity between mathematical formulas is very subjective . 
NULL ({ }) The ({ 1 }) similarity ({ 2 }) between ({ 3 }) mathematical ({ 4 }) formulas ({ 5 }) is ({ 6 }) very ({ 7 }) subjective ({ 8 }) . ({ 9 }) 
# Sentence pair (2192) source length 25 target length 16 alignment score : 6.29103e-21
In our work , we manually consider formulas with the same semantic meaning are relevant . 
NULL ({ 2 4 }) We ({ 1 }) consider ({ 7 }) that ({ }) formulas ({ 8 }) with ({ 9 }) the ({ 10 }) same ({ 11 }) semantic ({ 12 }) meaning ({ 13 }) are ({ 14 }) relevant ({ 15 }) . ({ 16 }) //[The ({ 3 }) original ({ }) is ({ }) unclear ({ }) the ({ }) rewrite ({ 5 }) seems ({ 6 }) to ({ }) be ({ }) what ({ }) you ({ }) mean ({ }) .] ({ }) 
# Sentence pair (2193) source length 19 target length 20 alignment score : 3.78822e-06
For example , while searching for sin( a ) , we also consider the results containing arcsin or cosin . 
NULL ({ 14 }) For ({ 1 }) example ({ 2 }) , ({ 3 }) while ({ 4 }) searching ({ 5 }) for ({ 6 }) sin( ({ 7 }) a ({ 8 }) ) ({ 9 }) , ({ 10 }) we ({ 11 }) also ({ 12 }) consider ({ 13 }) results ({ 15 }) containing ({ 16 }) arcsin ({ 17 }) or ({ 18 }) cosin ({ 19 }) . ({ 20 }) 
# Sentence pair (2194) source length 27 target length 27 alignment score : 2.99294e-05
Our experiments were conducted on a collection of about 16 ,000 mathematical docu-ments on Wikipedia and about 155 ,000 mathematical formulas on the Wolfram Functions Site . 
NULL ({ }) Our ({ 1 }) experiments ({ 2 }) were ({ 3 }) conducted ({ 4 }) on ({ 5 }) a ({ 6 }) collection ({ 7 }) of ({ 8 }) about ({ 9 }) 16 ({ 10 }) ,000 ({ 11 }) mathematical ({ 12 }) docu-ments ({ 13 }) on ({ 14 }) Wikipedia ({ 15 }) and ({ 16 }) about ({ 17 }) 155 ({ 18 }) ,000 ({ 19 }) mathematical ({ 20 }) formulas ({ 21 }) on ({ 22 }) the ({ 23 }) Wolfram ({ 24 }) Functions ({ 25 }) Site ({ 26 }) . ({ 27 }) 
# Sentence pair (2195) source length 27 target length 30 alignment score : 5.63755e-19
In order to show the e ect of linking the formula with its name , we also set up an experimental search system without using the formula 's names . 
NULL ({ 3 5 }) To ({ 1 }) show ({ 2 4 }) the ({ }) effect ({ 7 }) of ({ 8 }) linking ({ 6 9 }) the ({ 10 }) formula ({ 11 }) with ({ 12 }) its ({ 13 }) name ({ 14 }) , ({ 15 }) we ({ 16 }) also ({ 17 }) set ({ 18 }) up ({ 19 }) an ({ 20 }) experimental ({ 21 }) search ({ 22 }) system ({ 23 }) without ({ 24 }) using ({ 25 }) the ({ 26 }) formula ({ 27 }) 's ({ 28 }) names ({ 29 }) . ({ 30 }) 
# Sentence pair (2196) source length 19 target length 14 alignment score : 2.0169e-14
Table 1 shows top 5 of the searching results for the query \MATH . 
NULL ({ 6 7 }) Table ({ 1 }) 1 ({ 2 }) shows ({ 3 }) the ({ }) top ({ 4 }) 5 ({ 5 }) search ({ 8 }) results ({ 9 }) for ({ 10 }) the ({ 11 }) query ({ 12 }) " ({ }) sin( ({ 13 }) a ({ }) + ({ }) b ({ }) ) ({ }) " ({ }) . ({ 14 }) 
# Sentence pair (2197) source length 25 target length 28 alignment score : 5.26982e-14
As can be seen from the table , when the system associates the formulas with their names , it can provide more useful information to the user . 
NULL ({ 5 6 }) As ({ 1 }) can ({ 2 }) be ({ 3 }) seen ({ 4 7 }) , ({ 8 }) when ({ 9 }) the ({ 10 }) system ({ 11 }) associates ({ 12 }) the ({ 13 }) formulas ({ 14 }) with ({ 15 }) their ({ 16 }) names ({ 17 }) , ({ 18 }) it ({ 19 }) can ({ 20 }) provide ({ 21 }) more ({ 22 }) useful ({ 23 }) information ({ 24 }) to ({ 25 }) the ({ 26 }) user ({ 27 }) . ({ 28 }) 
# Sentence pair (2198) source length 14 target length 14 alignment score : 0.00447646
The system also allows the user to input the formula 's name directly . 
NULL ({ }) The ({ 1 }) system ({ 2 }) also ({ 3 }) allows ({ 4 }) the ({ 5 }) user ({ 6 }) to ({ 7 }) input ({ 8 }) the ({ 9 }) formula ({ 10 }) 's ({ 11 }) name ({ 12 }) directly ({ 13 }) . ({ 14 }) 
# Sentence pair (2199) source length 14 target length 13 alignment score : 2.42698e-06
Table 2 shows top 10 results with the query " Pythagorean " . 
NULL ({ }) Table ({ 1 }) 2 ({ 2 }) shows ({ 3 }) the ({ }) top ({ 4 }) 10 ({ 5 }) results ({ 6 }) for ({ 7 }) the ({ 8 }) query ({ 9 }) " ({ 10 }) Pythagorean ({ 11 }) " ({ 12 }) . ({ 13 }) 
# Sentence pair (2200) source length 31 target length 31 alignment score : 5.06863e-06
Note that at this time , when the user submits a query that does not match any function 's name in our database , the system can not return anything . 
NULL ({ }) Note ({ 1 }) that ({ 2 }) at ({ 3 }) this ({ 4 }) time ({ 5 }) , ({ 6 }) when ({ 7 }) the ({ 8 }) user ({ 9 }) submits ({ 10 }) a ({ 11 }) query ({ 12 }) that ({ 13 }) does ({ 14 }) not ({ 15 }) match ({ 16 }) any ({ 17 }) function ({ 18 }) 's ({ 19 }) name ({ 20 }) in ({ 21 }) our ({ 22 }) database ({ 23 }) , ({ 24 }) the ({ 25 }) system ({ 26 }) can ({ 27 }) not ({ 28 }) return ({ 29 }) anything ({ 30 }) . ({ 31 }) 
# Sentence pair (2201) source length 29 target length 33 alignment score : 1.95469e-20
In this paper , we presented a new framework for mathematical search where links between formulas and their names are automatically detected from the target documents and then utilized in the search . 
NULL ({ 4 5 }) We ({ 1 }) presented ({ 2 3 6 }) a ({ 7 }) new ({ 8 }) framework ({ 9 }) for ({ 10 }) mathematical ({ 11 }) searches ({ 12 }) where ({ 13 }) links ({ 14 }) between ({ 15 }) formulas ({ 16 }) and ({ 17 }) their ({ 18 }) names ({ 19 }) are ({ 20 }) automatically ({ 21 }) detected ({ 22 }) in ({ 23 }) the ({ 24 }) target ({ 25 }) documents ({ 26 }) and ({ 27 }) then ({ 28 }) utilized ({ 29 }) in ({ 30 }) the ({ 31 }) search ({ 32 }) . ({ 33 }) 
# Sentence pair (2202) source length 23 target length 24 alignment score : 1.47501e-11
Due to unavailability of the standard corpora to evaluate mathemat-ical search systems , our evaluation at this moment still remained subjective and limited . 
NULL ({ }) Due ({ 1 }) to ({ 2 }) unavailability ({ 3 }) of ({ 4 }) a ({ 5 }) standard ({ 6 }) corpora ({ 7 }) to ({ 8 }) evaluate ({ 9 }) mathematical ({ 10 }) search ({ 11 }) systems ({ 12 }) , ({ 13 }) our ({ 14 }) evaluation ({ 15 }) at ({ 16 }) this ({ 17 }) moment ({ 18 }) remains ({ 19 }) subjective ({ 20 21 }) and ({ 22 }) limited ({ 23 }) . ({ 24 }) 
# Sentence pair (2203) source length 18 target length 20 alignment score : 2.14399e-12
We believe that our approach , by incorporating information other than the mathematical formulas themselves , showed promising results . 
NULL ({ 6 16 }) We ({ 1 }) believe ({ 2 }) that ({ 3 }) our ({ 4 }) approach ({ 5 }) of ({ }) incorporating ({ 7 8 }) information ({ 9 }) other ({ 10 }) than ({ 11 }) the ({ 12 }) mathematical ({ 13 }) formulas ({ 14 }) themselves ({ 15 }) showed ({ 17 }) promising ({ 18 }) results ({ 19 }) . ({ 20 }) 
# Sentence pair (2204) source length 14 target length 17 alignment score : 2.67036e-16
The experimental results have shown how helpful this information provides to the users of mathematical search . 
NULL ({ 12 14 }) The ({ 1 }) experimental ({ 2 }) results ({ 3 }) showed ({ 4 5 }) how ({ 6 }) helpful ({ 7 }) this ({ 8 }) information ({ 9 }) is ({ 10 }) to ({ 11 }) mathematical ({ 15 }) search ({ 16 }) users ({ 13 }) . ({ 17 }) 
# Sentence pair (2205) source length 18 target length 18 alignment score : 3.60132e-08
However , this is only a rst step , some important issues are left for future study . 
NULL ({ }) However ({ 1 }) , ({ 2 }) this ({ 3 }) is ({ 4 }) only ({ 5 }) a ({ 6 }) first ({ 7 }) step ({ 8 }) ; ({ 9 }) many ({ 10 }) important ({ 11 }) issues ({ 12 }) are ({ 13 }) left ({ 14 }) for ({ 15 }) future ({ 16 }) study ({ 17 }) . ({ 18 }) 
# Sentence pair (2206) source length 37 target length 33 alignment score : 3.37142e-11
Using formula 's name is one way of taking into account the semantic meaning of the formula , we are considering other information such as formula 's description and variable 's description . 
NULL ({ }) Using ({ 1 }) a ({ }) formula ({ 2 }) 's ({ 3 }) name ({ 4 }) is ({ 5 }) only ({ }) one ({ 6 }) way ({ 7 }) of ({ 8 }) taking ({ 9 }) into ({ 10 }) account ({ 11 }) the ({ 12 }) semantic ({ 13 }) meaning ({ 14 }) of ({ 15 }) the ({ 16 }) formula ({ 17 }) ; ({ 18 }) we ({ 19 }) are ({ 20 }) considering ({ 21 }) other ({ 22 }) information ({ 23 }) such ({ 24 }) as ({ 25 }) the ({ }) formula ({ 26 }) 's ({ 27 }) description ({ 28 }) and ({ 29 }) its ({ }) variable ({ 30 }) 's ({ 31 }) description ({ 32 }) . ({ 33 }) 
# Sentence pair (2207) source length 18 target length 18 alignment score : 0.000643927
Currently , our system uses only the links between formulas and their names in the same article . 
NULL ({ }) Currently ({ 1 }) , ({ 2 }) our ({ 3 }) system ({ 4 }) uses ({ 5 }) only ({ 6 }) the ({ 7 }) links ({ 8 }) between ({ 9 }) formulas ({ 10 }) and ({ 11 }) their ({ 12 }) names ({ 13 }) in ({ 14 }) the ({ 15 }) same ({ 16 }) article ({ 17 }) . ({ 18 }) 
# Sentence pair (2208) source length 13 target length 12 alignment score : 0.000382446
Therefore , linking formulas across articles should be taken into account . 
NULL ({ }) Therefore ({ 1 }) , ({ 2 }) linking ({ 3 }) formulas ({ 4 }) across ({ 5 }) articles ({ 6 }) should ({ 7 }) also ({ }) be ({ 8 }) taken ({ 9 }) into ({ 10 }) account ({ 11 }) . ({ 12 }) 
# Sentence pair (2209) source length 11 target length 11 alignment score : 0.0141769
Automatic approach to understanding mathematical expressions using MathML Parallel Markup corpora 
NULL ({ }) Automatic ({ 1 }) approach ({ 2 }) to ({ 3 }) understanding ({ 4 }) mathematical ({ 5 }) expressions ({ 6 }) using ({ 7 }) MathML ({ 8 }) Parallel ({ 9 }) Markup ({ 10 }) corpora ({ 11 }) 
# Sentence pair (2210) source length 58 target length 34 alignment score : 8.27625e-40
This paper explores the use of MathML Pallel Markup Corpora for mathematical expression understanding , the task of which is formulated as a translation from Presentation to Content MathML Markups in our approach . 
NULL ({ }) This ({ 1 }) paper ({ 2 }) explores ({ 3 }) the ({ 4 }) use ({ 5 }) of ({ 6 }) MathML ({ 7 }) Pallel ({ 8 }) Markup ({ 9 }) Corpora ({ 10 }) for ({ 11 }) automatic ({ }) understanding ({ 14 }) of ({ }) mathematical ({ 12 }) expressions ({ 13 }) , ({ 15 }) the ({ 16 }) task ({ 17 }) of ({ 18 }) which ({ 19 }) is ({ 20 }) formulated ({ 21 }) as ({ 22 }) a ({ 23 }) translation ({ 24 }) from ({ 25 }) Presentation ({ 26 }) to ({ 27 }) Content ({ 28 }) MathML ({ 29 }) Markups ({ 30 }) . ({ }) // ({ 31 }) <the ({ 32 }) use ({ }) of ({ }) capitals ({ }) implies ({ }) that ({ }) these ({ }) are ({ }) software ({ }) applications ({ }) like ({ }) PowerPoint ({ 33 }) or ({ }) Word ({ }) . ({ }) I ({ }) assume ({ }) this ({ }) is ({ }) the ({ }) right ({ }) idea ({ }) .> ({ }) . ({ 34 }) 
# Sentence pair (2211) source length 29 target length 29 alignment score : 2.77552e-10
In contrast to existing researches that mainly relied on manually encoded transformation rules , we adopt a Statistical-Machine-Translation-based method to automatically extract translation rules from parallel markup corpora . 
NULL ({ }) In ({ 1 }) contrast ({ 2 }) to ({ 3 }) previous ({ 4 }) research ({ 5 }) that ({ 6 }) mainly ({ 7 }) relied ({ 8 }) on ({ 9 }) manually ({ 10 }) encoded ({ 11 }) transformation ({ 12 }) rules ({ 13 }) , ({ 14 }) we ({ 15 }) use ({ 16 }) a ({ 17 }) statistical-machine-translation-based ({ 18 }) method ({ 19 }) to ({ 20 }) automatically ({ 21 }) extract ({ 22 }) translation ({ 23 }) rules ({ 24 }) from ({ 25 }) parallel ({ 26 }) markup ({ 27 }) corpora ({ 28 }) . ({ 29 }) 
# Sentence pair (2212) source length 36 target length 35 alignment score : 8.41022e-08
Our study shows that the structural features embedded in the MathML tree can be effectively exploited in the sub-tree alignment and the translation rules extracted from the alignment give boost to the translation system . 
NULL ({ }) Our ({ 1 }) study ({ 2 }) shows ({ 3 }) that ({ 4 }) the ({ 5 }) structural ({ 6 }) features ({ 7 }) embedded ({ 8 }) in ({ 9 }) the ({ 10 }) MathML ({ 11 }) tree ({ 12 }) can ({ 13 }) be ({ 14 }) effectively ({ 15 }) exploited ({ 16 }) in ({ 17 }) the ({ 18 }) sub-tree ({ 19 }) alignment ({ 20 }) and ({ 21 }) the ({ 22 }) translation ({ 23 }) rules ({ 24 }) extracted ({ 25 }) from ({ 26 }) the ({ 27 }) alignment ({ 28 }) give ({ 29 }) a ({ }) boost ({ 30 }) to ({ 31 }) the ({ 32 }) translation ({ 33 }) system ({ 34 }) . ({ 35 }) 
# Sentence pair (2213) source length 48 target length 20 alignment score : 1.17983e-41
Experimental results on the Wolfram Function Site show that our approach achieves an improvement against the prior rule-based system . 
NULL ({ 16 }) Experimental ({ 1 }) results ({ 2 }) on ({ 3 }) the ({ 4 }) Wolfram ({ 5 }) Function ({ 6 }) Site ({ 7 }) show ({ 8 }) that ({ }) our ({ 10 }) approach ({ 11 }) is ({ }) an ({ 13 }) improvement ({ 14 }) over ({ 15 }) prior ({ 17 }) rule-based ({ 18 }) systems ({ 19 }) . ({ 20 }) // ({ }) <Note ({ 12 }) : ({ }) It ({ }) seems ({ }) that ({ 9 }) where ({ }) were ({ }) two ({ }) prior ({ }) systems ({ }) that ({ }) were ({ }) compared ({ }) . ({ }) If ({ }) not ({ }) , ({ }) you ({ }) can ({ }) go ({ }) back ({ }) to ({ }) using ({ }) a ({ }) prior ({ }) system ({ }) .> ({ }) . ({ }) 
# Sentence pair (2214) source length 41 target length 41 alignment score : 2.04965e-14
One of the most significant current discussions in the digitization of mathematical and scientific content and its applications is the semantic enrichment of mathematical documents , that is adding or associating semantic tags - usually concepts - to mathematical expressions . 
NULL ({ 8 }) One ({ 1 }) of ({ 2 }) the ({ 3 }) most ({ 4 }) significant ({ 5 }) discussions ({ 6 }) regarding ({ 7 }) the ({ 9 }) digitization ({ 10 }) of ({ 11 }) mathematical ({ 12 }) and ({ 13 }) scientific ({ 14 }) content ({ 15 }) and ({ 16 }) its ({ 17 }) applications ({ 18 }) is ({ 19 }) about ({ 20 }) semantic ({ 21 }) enrichment ({ 22 }) of ({ 23 }) mathematical ({ 24 }) documents ({ 25 }) , ({ 26 }) that ({ 27 }) is ({ 28 }) , ({ }) adding ({ 29 }) or ({ 30 }) associating ({ 31 }) semantic ({ 32 }) tags ({ 33 }) - ({ 34 }) usually ({ 35 }) concepts ({ 36 }) - ({ 37 }) with ({ 38 }) mathematical ({ 39 }) expressions ({ 40 }) . ({ 41 }) 
# Sentence pair (2215) source length 27 target length 27 alignment score : 5.71793e-05
By encoding the underlying mathematical meaning of an expression explicitly , it is possible to interchange information more precisely between systems that semantically process mathematical objects . 
NULL ({ }) By ({ 1 }) encoding ({ 2 }) the ({ 3 }) underlying ({ 4 }) mathematical ({ 5 }) meaning ({ 6 }) of ({ 7 }) an ({ 8 }) expression ({ 9 }) explicitly ({ 10 }) , ({ 11 }) it ({ 12 }) is ({ 13 }) possible ({ 14 }) to ({ 15 }) interchange ({ 16 }) information ({ 17 }) more ({ 18 }) precisely ({ 19 }) between ({ 20 }) systems ({ 21 }) that ({ 22 }) semantically ({ 23 }) process ({ 24 }) mathematical ({ 25 }) objects ({ 26 }) . ({ 27 }) 
# Sentence pair (2216) source length 35 target length 30 alignment score : 2.03846e-14
The direct application of this is enabling semantic searches for mathematical expressions by understanding the intent of the searcher and the contextual meaning of mathematical terms improve search accuracy . 
NULL ({ }) The ({ 1 }) direct ({ 2 }) application ({ 3 }) of ({ 4 }) this ({ 5 }) idea ({ 6 }) enables ({ 7 }) semantic ({ 8 }) searches ({ 9 }) for ({ 10 }) mathematical ({ 11 }) expressions ({ 12 }) whereby ({ 13 }) the ({ }) system ({ }) 's ({ }) eunderstanding ({ 14 }) ' ({ }) of ({ }) the ({ 15 }) intent ({ 16 }) of ({ 17 }) the ({ 18 }) searcher ({ 19 }) and ({ 20 }) the ({ 21 }) contextual ({ 22 }) meaning ({ 23 }) of ({ 24 }) mathematical ({ 25 }) terms ({ 26 }) improves ({ 27 }) search ({ 28 }) accuracy ({ 29 }) . ({ 30 }) 
# Sentence pair (2217) source length 15 target length 15 alignment score : 0.00044571
It also benefits computer algebra systems , automatic reasoning system and multi-lingual translation systems . 
NULL ({ }) It ({ 1 }) also ({ 2 }) benefits ({ 3 }) computer ({ 4 }) algebra ({ 5 }) systems ({ 6 }) , ({ 7 }) automatic ({ 8 }) reasoning ({ 9 }) systems ({ 10 }) and ({ 11 }) multi-lingual ({ 12 }) translation ({ 13 }) systems ({ 14 }) . ({ 15 }) 
# Sentence pair (2218) source length 20 target length 21 alignment score : 2.73533e-06
However , as is the case with natural language , the semantic enrichment of mathematical expressions is a non-trivial task . 
NULL ({ 11 }) However ({ 1 }) , ({ 2 }) as ({ 3 }) is ({ 4 }) the ({ 5 }) case ({ 6 }) with ({ 7 }) natural ({ 8 }) language ({ 9 }) , ({ 10 }) semantic ({ 12 }) enrichment ({ 13 }) of ({ 14 }) mathematical ({ 15 }) expressions ({ 16 }) is ({ 17 }) a ({ 18 }) non-trivial ({ 19 }) task ({ 20 }) . ({ 21 }) 
# Sentence pair (2219) source length 28 target length 28 alignment score : 1.26563e-05
- First , mathematical notation , though more rigorous than natural language , is nonetheless at times ambiguous , context-dependent , and varies from community to community . 
NULL ({ }) - ({ 1 }) First ({ 2 }) , ({ 3 }) mathematical ({ 4 }) notation ({ 5 }) , ({ 6 }) though ({ 7 }) more ({ 8 }) rigorous ({ 9 }) than ({ 10 }) natural ({ 11 }) language ({ 12 }) , ({ 13 }) is ({ 14 }) nonetheless ({ 15 }) at ({ 16 }) times ({ 17 }) ambiguous ({ 18 }) , ({ 19 }) context-dependent ({ 20 }) , ({ 21 }) and ({ 22 }) varies ({ 23 }) from ({ 24 }) community ({ 25 }) to ({ 26 }) community ({ 27 }) . ({ 28 }) 
# Sentence pair (2220) source length 22 target length 22 alignment score : 5.47444e-05
- Second , the underlying mathematical meaning of an expression need to follow a semantic markup in a semantically rigorous way . 
NULL ({ }) - ({ 1 }) Second ({ 2 }) , ({ 3 }) the ({ 4 }) underlying ({ 5 }) mathematical ({ 6 }) meaning ({ 7 }) of ({ 8 }) an ({ 9 }) expression ({ 10 }) needs ({ 11 }) to ({ 12 }) follow ({ 13 }) a ({ 14 }) semantic ({ 15 }) markup ({ 16 }) in ({ 17 }) a ({ 18 }) semantically ({ 19 }) rigorous ({ 20 }) way ({ 21 }) . ({ 22 }) 
# Sentence pair (2221) source length 22 target length 21 alignment score : 8.58044e-06
Because of this , failing to follow the constraint , the computer might not be able to process that expression . 
NULL ({ }) Because ({ 1 }) of ({ 2 }) this ({ 3 }) , ({ 4 }) in ({ }) failing ({ 5 }) to ({ 6 }) follow ({ 7 }) the ({ 8 }) constraint ({ 9 }) , ({ 10 }) the ({ 11 }) computer ({ 12 }) might ({ 13 }) not ({ 14 }) be ({ 15 }) able ({ 16 }) to ({ 17 }) process ({ 18 }) that ({ 19 }) expression ({ 20 }) . ({ 21 }) 
# Sentence pair (2222) source length 32 target length 40 alignment score : 2.46187e-27
- The third problem is that new notations tend to be introduced and used as and when needed so a mechanism is required for referring to mathematical concepts outside of the base collection , allowing them to be represented . 
NULL ({ 15 16 34 36 37 38 }) - ({ 1 }) The ({ 2 }) third ({ 3 }) problem ({ 4 }) is ({ 5 }) that ({ 6 }) new ({ 7 }) notations ({ 8 }) tend ({ 9 }) to ({ 10 }) be ({ 11 }) introduced ({ 12 }) and ({ 13 }) used ({ 14 }) when ({ 17 }) needed ({ 18 }) so ({ 19 }) a ({ 20 }) mechanism ({ 21 }) is ({ 22 }) required ({ 23 }) for ({ 24 }) referring ({ 25 }) to ({ 26 }) mathematical ({ 27 }) concepts ({ 28 }) outside ({ 29 }) of ({ 30 }) the ({ 31 }) base ({ 32 }) collection ({ 33 35 39 }) . ({ 40 }) 
# Sentence pair (2223) source length 26 target length 24 alignment score : 1.89124e-11
The aim of this paper is to introduce a method for automatic mathematics semantic enrichment that capable of analyze and disambiguate mathematical terms . 
NULL ({ }) The ({ 1 }) aim ({ 2 }) of ({ 3 }) this ({ 4 }) paper ({ 5 }) is ({ 6 }) to ({ 7 }) describe ({ 8 }) a ({ 9 }) method ({ 10 }) of ({ }) automatic ({ 12 }) semantic ({ 14 }) enrichment ({ 15 }) for ({ 11 }) mathematics ({ 13 }) that ({ 16 }) is ({ }) capable ({ 17 }) of ({ 18 }) analyzing ({ 19 }) and ({ 20 }) disambiguating ({ 21 }) mathematical ({ 22 }) terms ({ 23 }) . ({ 24 }) 
# Sentence pair (2224) source length 25 target length 25 alignment score : 6.37889e-05
In our research , MathML \CITE Presentation Markup is used to display mathematical expressions and MathML Content Markup is used to convey mathematical meaning . 
NULL ({ }) In ({ 1 }) our ({ 2 }) research ({ 3 }) , ({ 4 }) MathML ({ 5 }) \CITE ({ 6 }) Presentation ({ 7 }) Markup ({ 8 }) is ({ 9 }) used ({ 10 }) to ({ 11 }) display ({ 12 }) mathematical ({ 13 }) expressions ({ 14 }) and ({ 15 }) MathML ({ 16 }) Content ({ 17 }) Markup ({ 18 }) is ({ 19 }) used ({ 20 }) to ({ 21 }) convey ({ 22 }) mathematical ({ 23 }) meaning ({ 24 }) . ({ 25 }) 
# Sentence pair (2225) source length 17 target length 15 alignment score : 3.31153e-05
The semantic enrichment task then becomes generating Content MathML outputs from Presentation MathML expressions . 
NULL ({ }) The ({ 1 }) semantic ({ 2 }) enrichment ({ 3 }) task ({ 4 }) then ({ 5 }) becomes ({ 6 }) one ({ }) of ({ }) generating ({ 7 }) Content ({ 8 }) MathML ({ 9 }) outputs ({ 10 }) from ({ 11 }) Presentation ({ 12 }) MathML ({ 13 }) expressions ({ 14 }) . ({ 15 }) 
# Sentence pair (2226) source length 13 target length 13 alignment score : 0.00508319
There are three reasons why we choose MathML markup in our research . 
NULL ({ }) There ({ 1 }) are ({ 2 }) three ({ 3 }) reasons ({ 4 }) why ({ 5 }) we ({ 6 }) chose ({ 7 }) MathML ({ 8 }) markup ({ 9 }) in ({ 10 }) our ({ 11 }) research ({ 12 }) . ({ 13 }) 
# Sentence pair (2227) source length 36 target length 36 alignment score : 2.09408e-07
- First , since its first release in 1997 , MathML has grown to become a general format that enables mathematics to be served , received , and processed in a wide variety of applications . 
NULL ({ }) - ({ 1 }) First ({ 2 }) , ({ 3 }) since ({ 4 }) its ({ 5 }) first ({ 6 }) release ({ 7 }) in ({ 8 }) 1997 ({ 9 }) , ({ 10 }) MathML ({ 11 }) has ({ 12 }) grown ({ 13 }) to ({ 14 }) become ({ 15 }) a ({ 16 }) general ({ 17 }) format ({ 18 }) that ({ 19 }) enables ({ 20 }) mathematics ({ 21 }) to ({ 22 }) be ({ 23 }) served ({ 24 }) , ({ 25 }) received ({ 26 }) , ({ 27 }) and ({ 28 }) processed ({ 29 }) in ({ 30 }) a ({ 31 }) wide ({ 32 }) variety ({ 33 }) of ({ 34 }) applications ({ 35 }) . ({ 36 }) 
# Sentence pair (2228) source length 16 target length 16 alignment score : 0.000204585
- Second , MathML can be used to encode both mathematical notation and mathematical content . 
NULL ({ }) - ({ 1 }) Second ({ 2 }) , ({ 3 }) MathML ({ 4 }) can ({ 5 }) be ({ 6 }) used ({ 7 }) to ({ 8 }) encode ({ 9 }) both ({ 10 }) mathematical ({ 11 }) notations ({ 12 }) and ({ 13 }) mathematical ({ 14 }) content ({ 15 }) . ({ 16 }) 
# Sentence pair (2229) source length 20 target length 19 alignment score : 8.9498e-05
- Last , large collections of formulas are available in MathML and we can easily assess these collections . 
NULL ({ }) - ({ 1 }) Last ({ 2 }) , ({ 3 }) large ({ 4 }) collections ({ 5 }) of ({ 6 }) formulas ({ 7 }) are ({ 8 }) available ({ 9 }) in ({ 10 }) MathML ({ 11 }) , ({ }) and ({ 12 }) we ({ 13 }) can ({ 14 }) easily ({ 15 }) assess ({ 16 }) these ({ 17 }) collections ({ 18 }) . ({ 19 }) 
# Sentence pair (2230) source length 27 target length 27 alignment score : 1.25256e-06
- In the scope of this paper , we only make use the information within a mathematical expression for disambiguation when translating it to content markup . 
NULL ({ }) - ({ 1 }) In ({ 2 }) the ({ 3 }) scope ({ 4 }) of ({ 5 }) this ({ 6 }) paper ({ 7 }) , ({ 8 }) we ({ 9 }) only ({ 10 }) make ({ 11 }) use ({ 12 }) the ({ 13 }) information ({ 14 }) within ({ 15 }) a ({ 16 }) mathematical ({ 17 }) expression ({ 18 }) for ({ 19 }) disambiguation ({ 20 }) when ({ 21 }) translating ({ 22 }) it ({ 23 }) into ({ 24 }) content ({ 25 }) markup ({ 26 }) . ({ 27 }) 
# Sentence pair (2231) source length 17 target length 17 alignment score : 0.00182536
The prior solution to this problem is SnuggleTeX \CITE , which was proposed by David McKain . 
NULL ({ }) The ({ 1 }) prior ({ 2 }) solution ({ 3 }) to ({ 4 }) this ({ 5 }) problem ({ 6 }) is ({ 7 }) SnuggleTeX ({ 8 }) \CITE ({ 9 }) , ({ 10 }) which ({ 11 }) was ({ 12 }) proposed ({ 13 }) by ({ 14 }) David ({ 15 }) McKain ({ 16 }) . ({ 17 }) 
# Sentence pair (2232) source length 10 target length 10 alignment score : 0.00118501
The system used rule-based methods for disambiguation and translation . 
NULL ({ }) The ({ 1 }) system ({ 2 }) uses ({ 3 }) rule-based ({ 4 }) methods ({ 5 }) for ({ 6 }) disambiguation ({ 7 }) and ({ 8 }) translation ({ 9 }) . ({ 10 }) 
# Sentence pair (2233) source length 7 target length 7 alignment score : 0.0657822
This solution has two main limitations : 
NULL ({ }) This ({ 1 }) solution ({ 2 }) has ({ 3 }) two ({ 4 }) main ({ 5 }) limitations ({ 6 }) : ({ 7 }) 
# Sentence pair (2234) source length 19 target length 19 alignment score : 2.3252e-07
- Since it is a hand written rule-based system , SnuggleTeX requires mathematical knowledge and human effort to develop 
NULL ({ }) - ({ 1 }) Since ({ 2 }) it ({ 3 }) is ({ 4 }) a ({ 5 }) hand-written ({ 6 7 }) rule-based ({ 8 }) system ({ 9 }) , ({ 10 }) SnuggleTeX ({ 11 }) requires ({ 12 }) mathematical ({ 13 }) knowledge ({ 14 }) and ({ 15 }) human ({ 16 }) effort ({ 17 }) to ({ 18 }) develop ({ 19 }) . ({ }) 
# Sentence pair (2235) source length 24 target length 26 alignment score : 1.25171e-10
- Due to the diversity of mathematical expressions , SnuggleTeX is still to be considered experimental and has difficulty processing complicated mathematical symbols and expressions . 
NULL ({ 13 14 }) - ({ 1 }) Due ({ 2 }) to ({ 3 }) the ({ 4 }) diversity ({ 5 }) of ({ 6 }) mathematical ({ 7 }) expressions ({ 8 }) , ({ 9 }) SnuggleTeX ({ 10 }) is ({ 11 }) still ({ 12 }) considered ({ 15 }) experimental ({ 16 }) and ({ 17 }) has ({ 18 }) difficulty ({ 19 }) processing ({ 20 }) complicated ({ 21 }) mathematical ({ 22 }) symbols ({ 23 }) and ({ 24 }) expressions ({ 25 }) . ({ 26 }) 
# Sentence pair (2236) source length 41 target length 22 alignment score : 1.93641e-27
In this paper , we propose an approach that automatically learn the semantics inference from a presentation from parallel markup data . 
NULL ({ }) In ({ 1 }) this ({ 2 }) paper ({ 3 }) , ({ 4 }) we ({ 5 }) propose ({ 6 }) an ({ 7 }) approach ({ 8 }) that ({ 9 }) automatically ({ 10 }) learns ({ 11 }) semantic ({ 13 }) inferences ({ 14 }) in ({ }) a ({ 16 }) presentation ({ 17 }) from ({ 18 }) parallel ({ 19 }) markup ({ 20 }) data ({ 21 }) . ({ 22 }) // ({ }) <The ({ }) original ({ }) has ({ }) too ({ }) many ({ }) from ({ }) to ({ }) be ({ }) logically ({ 15 }) clear ({ }) . ({ }) The ({ }) rewrite ({ }) is ({ }) a ({ }) guess ({ 12 }) . ({ }) > ({ }) . ({ }) 
# Sentence pair (2237) source length 9 target length 12 alignment score : 4.29401e-15
The idea of this approach is based on statistical machine translation . 
NULL ({ 3 4 }) This ({ 1 }) approach ({ 2 5 }) is ({ 6 }) based ({ 7 }) on ({ 8 }) statistical ({ 9 }) machine ({ 10 }) translation ({ 11 }) . ({ 12 }) 
# Sentence pair (2238) source length 38 target length 39 alignment score : 1.4057e-12
The underlying mathematical meaning of an expression is inferred according to the probability distribution $ p( c | p ) $ that a semantic expression $ c $ is the translation of a presentation expression $ p $ . 
NULL ({ 11 }) The ({ 1 }) underlying ({ 2 }) mathematical ({ 3 }) meaning ({ 4 }) of ({ 5 }) an ({ 6 }) expression ({ 7 }) is ({ 8 }) inferred ({ 9 }) from ({ 10 }) the ({ 12 }) probability ({ 13 }) distribution ({ 14 }) $ ({ 15 }) p( ({ 16 }) c ({ 17 }) | ({ 18 }) p ({ 19 }) ) ({ 20 }) $ ({ 21 }) that ({ 22 }) a ({ 23 }) semantic ({ 24 }) expression ({ 25 }) $ ({ 26 }) c ({ 27 }) $ ({ 28 }) is ({ 29 }) the ({ 30 }) translation ({ 31 }) of ({ 32 }) a ({ 33 }) presentation ({ 34 }) expression ({ 35 }) $ ({ 36 }) p ({ 37 }) $ ({ 38 }) . ({ 39 }) 
# Sentence pair (2239) source length 23 target length 26 alignment score : 7.33499e-24
The probability distribution will be automatically learned from data that have both Presentation and Content MathML markup , that is the parallel markup MathML data . 
NULL ({ 5 10 11 21 }) The ({ 1 }) probability ({ 2 }) distribution ({ 3 }) is ({ 4 }) automatically ({ 6 }) learned ({ 7 }) from ({ 8 }) both ({ 12 }) Presentation ({ 13 }) and ({ 14 }) Content ({ 15 }) MathML ({ 16 }) markup ({ 17 }) data ({ 9 }) , ({ }) that ({ 19 }) is ({ 20 }) , ({ 18 }) parallel ({ 22 }) markup ({ 23 }) MathML ({ 24 }) data ({ 25 }) . ({ 26 }) 
# Sentence pair (2240) source length 15 target length 15 alignment score : 0.0012746
The data used in this study was collected from the Wolfram Function Site \CITE . 
NULL ({ }) The ({ 1 }) data ({ 2 }) used ({ 3 }) in ({ 4 }) this ({ 5 }) study ({ 6 }) was ({ 7 }) collected ({ 8 }) from ({ 9 }) the ({ 10 }) Wolfram ({ 11 }) Function ({ 12 }) Site ({ 13 }) \CITE ({ 14 }) . ({ 15 }) 
# Sentence pair (2241) source length 29 target length 29 alignment score : 6.50563e-09
We also prepare another parallel markup MathML data by annotating mathematical expressions on 20 papers from The Archives of the Association for Computational Linguistics \CITE ( ACL-ARC ) . 
NULL ({ }) We ({ 1 }) also ({ 2 }) prepared ({ 3 }) other ({ 4 }) parallel ({ 5 }) markup ({ 6 }) MathML ({ 7 }) data ({ 8 }) by ({ 9 }) annotating ({ 10 }) mathematical ({ 11 }) expressions ({ 12 }) in ({ 13 }) 20 ({ 14 }) papers ({ 15 }) from ({ 16 }) The ({ 17 }) Archives ({ 18 }) of ({ 19 }) the ({ 20 }) Association ({ 21 }) for ({ 22 }) Computational ({ 23 }) Linguistics ({ 24 }) \CITE ({ 25 }) ( ({ 26 }) ACL-ARC ({ 27 }) ) ({ 28 }) . ({ 29 }) 
# Sentence pair (2242) source length 9 target length 8 alignment score : 6.37555e-07
We have two main contributions in this paper 
NULL ({ }) There ({ 1 }) are ({ 2 }) two ({ 3 }) main ({ 4 }) contributions ({ 5 }) in ({ 6 }) this ({ 7 }) paper ({ 8 }) : ({ }) 
# Sentence pair (2243) source length 18 target length 17 alignment score : 2.60429e-08
- First , successfully apply the machine translation techniques to the problem of mathematic semantic enrichment . 
NULL ({ 6 }) - ({ 1 }) First ({ 2 }) , ({ 3 }) we ({ }) successfully ({ 4 }) applied ({ 5 }) machine ({ 7 }) translation ({ 8 }) techniques ({ 9 }) to ({ 10 }) solving ({ 11 }) the ({ }) problem ({ 12 }) of ({ 13 }) mathematic ({ 14 }) semantic ({ 15 }) enrichment ({ 16 }) . ({ 17 }) 
# Sentence pair (2244) source length 27 target length 28 alignment score : 2.4305e-09
Experimental results show that our system significantly outperforms the current rule-based system and it can handle a lot of practical cases in the mathematics semantic enrichment problem . 
NULL ({ }) Experimental ({ 1 }) results ({ 2 }) show ({ 3 }) that ({ 4 }) our ({ 5 }) system ({ 6 }) significantly ({ 7 }) outperforms ({ 8 }) the ({ 9 }) current ({ 10 }) rule-based ({ 11 }) system ({ 12 }) and ({ 13 }) it ({ 14 }) can ({ 15 }) handle ({ 16 }) a ({ 17 }) lot ({ 18 }) of ({ 19 }) practical ({ 20 }) cases ({ 21 }) in ({ 22 }) the ({ 23 }) semantic ({ 24 25 }) enrichment ({ 26 }) problem ({ 27 }) . ({ 28 }) 
# Sentence pair (2245) source length 27 target length 31 alignment score : 6.93721e-34
Since both quantity and quality of mathematical expressions are continuing to grow and expand through time , we believe that our system will cover most of real life mathematical expressions . 
NULL ({ 17 26 }) The ({ 1 }) quantity ({ 2 3 }) and ({ 4 }) quality ({ 5 }) of ({ 6 }) mathematical ({ 7 }) expressions ({ 8 }) are ({ 9 }) continuing ({ 10 }) to ({ 11 }) grow ({ 12 16 }) , ({ }) and ({ 13 }) we ({ 18 }) believe ({ 14 15 19 }) that ({ 20 }) our ({ 21 }) system ({ 22 }) will ({ 23 }) be ({ }) able ({ }) to ({ }) cover ({ 24 27 28 }) most ({ 25 }) mathematical ({ 29 }) expressions ({ 30 }) . ({ 31 }) 
# Sentence pair (2246) source length 41 target length 42 alignment score : 1.19107e-35
- Second , mathematics knowledge such as symbol 's meanings or structural relations is automatically learned while training , therefor it is not required mathematics experts nor human effort and it is also easier to update the system given more data . 
NULL ({ 22 37 }) - ({ 1 }) Second ({ 2 }) , ({ 3 }) mathematics ({ 4 }) knowledge ({ 5 }) such ({ 6 }) as ({ 7 }) a ({ }) symbol ({ 8 }) 's ({ 9 }) meanings ({ 10 }) or ({ 11 }) structural ({ 12 }) relations ({ 13 }) is ({ 14 }) automatically ({ 15 }) learned ({ 16 }) while ({ 17 }) training ({ 18 }) ; ({ 19 }) therefore ({ 20 }) , ({ }) the ({ }) system ({ 38 }) requires ({ 21 }) no ({ }) human ({ 28 }) effort ({ 29 }) or ({ 23 }) expertise ({ 24 25 26 27 }) , ({ }) and ({ 30 }) it ({ 31 }) is ({ 32 }) easier ({ 33 34 }) to ({ 35 }) update ({ 36 39 }) with ({ }) more ({ 40 }) data ({ 41 }) . ({ 42 }) 
# Sentence pair (2247) source length 19 target length 18 alignment score : 9.51412e-06
Since new notations keep growing , it is important to update the system as quick as possible . 
NULL ({ }) Since ({ 1 }) new ({ 2 }) notations ({ 3 }) keep ({ 4 }) cropping ({ 5 }) up ({ }) , ({ 6 }) it ({ 7 }) is ({ 8 }) important ({ 9 }) to ({ 10 }) update ({ 11 }) the ({ 12 }) system ({ 13 }) as ({ 14 }) quickly ({ 15 }) as ({ 16 }) possible ({ 17 }) . ({ 18 }) 
# Sentence pair (2248) source length 26 target length 31 alignment score : 3.60557e-23
In our experiments , we performed a 10-folds cross validation on mathematical expressions from 6 categories of the Wolfram Functions Site to evaluate the effectiveness of our proposed learning method . 
NULL ({ 2 3 4 5 28 }) We ({ 1 }) performed ({ 6 }) a ({ 7 }) ten-fold ({ 8 }) cross ({ 9 }) validation ({ 10 }) on ({ 11 }) mathematical ({ 12 }) expressions ({ 13 }) from ({ 14 }) six ({ 15 }) categories ({ 16 }) of ({ 17 }) the ({ 18 }) Wolfram ({ 19 }) Functions ({ 20 }) Site ({ 21 }) to ({ 22 }) evaluate ({ 23 }) the ({ 24 }) effectiveness ({ 25 }) of ({ 26 }) our ({ 27 }) learning ({ 29 }) method ({ 30 }) . ({ 31 }) 
# Sentence pair (2249) source length 33 target length 31 alignment score : 1.30617e-18
We set up another experiment to confirm the correlation between system performance and training set size and saw that increasing the size of training data actually boost the system performance . 
NULL ({ }) We ({ 1 }) performed ({ 2 3 }) another ({ 4 }) experiment ({ 5 }) to ({ 6 }) assess ({ 7 }) the ({ 8 }) correlation ({ 9 }) between ({ 10 }) the ({ }) system ({ 11 }) 's ({ }) performance ({ 12 }) and ({ 13 }) training ({ 14 }) set ({ 15 }) size ({ 16 }) and ({ 17 }) found ({ 18 }) that ({ 19 }) increasing ({ 20 }) the ({ 21 }) size ({ 22 }) of ({ 23 }) the ({ }) training ({ 24 }) data ({ 25 }) boosted ({ 26 27 }) the ({ 28 }) system ({ 29 }) 's ({ }) performance ({ 30 }) . ({ 31 }) 
# Sentence pair (2250) source length 20 target length 19 alignment score : 5.78281e-11
We also performed extensive side-by-side comparison with prior work \CITE over a data set from ACL-ARC scientific papers . 
NULL ({ }) We ({ 1 }) also ({ 2 }) performed ({ 3 }) an ({ 4 }) extensive ({ 5 }) comparison ({ 6 }) with ({ 7 }) prior ({ 8 }) work ({ 9 }) \CITE ({ 10 }) using ({ 11 }) a ({ 12 }) data ({ 13 }) set ({ 14 }) collected ({ }) from ({ 15 }) ACL-ARC ({ 16 }) scientific ({ 17 }) papers ({ 18 }) . ({ 19 }) 
# Sentence pair (2251) source length 29 target length 29 alignment score : 8.90567e-19
Our experimental results show that the proposed approach works well on the mathematics semantic enrichment problem and it excels the previous work by providing significantly less error rate . 
NULL ({ 6 }) Our ({ 1 }) experimental ({ 2 }) results ({ 3 }) show ({ 4 }) that ({ 5 }) our ({ 7 }) approach ({ 8 }) works ({ 9 }) well ({ 10 }) in ({ }) dealing ({ 11 }) with ({ }) the ({ 12 }) mathematics ({ 13 }) semantic ({ 14 }) enrichment ({ 15 }) problem ({ 16 }) and ({ 17 }) it ({ 18 }) outperforms ({ 19 }) the ({ 20 }) previous ({ 21 }) work ({ 22 }) by ({ 23 }) making ({ 24 }) significantly ({ 25 }) fewer ({ 26 27 }) errors ({ 28 }) . ({ 29 }) 
# Sentence pair (2252) source length 32 target length 42 alignment score : 2.39813e-38
The remainder of this paper is organized as follows : In Section 2 , we give a brief overview of the background and related work for semantic enrichment of mathematical expressions , while in Section 3 we present our proposed method . 
NULL ({ 32 34 37 38 }) The ({ 1 }) remainder ({ 2 }) of ({ 3 }) this ({ 4 }) paper ({ 5 }) is ({ 6 }) organized ({ 7 }) as ({ 8 }) follows ({ 9 }) : ({ 10 }) In ({ 11 }) Section ({ 12 }) 2 ({ 13 }) , ({ 14 }) we ({ 15 }) give ({ 16 }) a ({ 17 }) brief ({ 18 33 36 39 41 }) overview ({ 19 35 40 }) of ({ 20 }) the ({ 21 }) background ({ 22 }) and ({ 23 }) related ({ 24 }) work ({ 25 }) on ({ 26 }) semantic ({ 27 }) enrichment ({ 28 }) of ({ 29 }) mathematical ({ 30 }) expressions ({ 31 }) . ({ 42 }) 
# Sentence pair (2253) source length 18 target length 12 alignment score : 1.03256e-11
We then describe the experimental setup and results in Section 4 . 
NULL ({ }) We ({ 1 }) present ({ 2 }) our ({ }) method ({ }) in ({ }) Section ({ }) 3 ({ }) and ({ }) describe ({ 3 }) the ({ 4 }) experimental ({ 5 }) setup ({ 6 }) and ({ 7 }) results ({ 8 }) in ({ 9 }) Section ({ 10 }) 4 ({ 11 }) . ({ 12 }) 
# Sentence pair (2254) source length 12 target length 12 alignment score : 0.00687205
Section 5 concludes the paper and gives avenues for future work . 
NULL ({ }) Section ({ 1 }) 5 ({ 2 }) concludes ({ 3 }) the ({ 4 }) paper ({ 5 }) and ({ 6 }) gives ({ 7 }) avenues ({ 8 }) for ({ 9 }) future ({ 10 }) work ({ 11 }) . ({ 12 }) 
# Sentence pair (2255) source length 19 target length 19 alignment score : 0.000683463
Since mathematical formulas contain both mathematical symbols and structures , a special markup is required for their representation . 
NULL ({ }) Since ({ 1 }) mathematical ({ 2 }) formulas ({ 3 }) contain ({ 4 }) both ({ 5 }) mathematical ({ 6 }) symbols ({ 7 }) and ({ 8 }) structures ({ 9 }) , ({ 10 }) a ({ 11 }) special ({ 12 }) markup ({ 13 }) is ({ 14 }) required ({ 15 }) for ({ 16 }) their ({ 17 }) representation ({ 18 }) . ({ 19 }) 
# Sentence pair (2256) source length 15 target length 15 alignment score : 0.00232571
Until recently , images have been used to represent mathematical formulas on the web . 
NULL ({ }) Until ({ 1 }) recently ({ 2 }) , ({ 3 }) images ({ 4 }) have ({ 5 }) been ({ 6 }) used ({ 7 }) to ({ 8 }) represent ({ 9 }) mathematical ({ 10 }) formulas ({ 11 }) on ({ 12 }) the ({ 13 }) web ({ 14 }) . ({ 15 }) 
# Sentence pair (2257) source length 23 target length 23 alignment score : 3.91374e-05
This type of display does not need any markup language to decode the formulas , but it is hard to process them . 
NULL ({ }) This ({ 1 }) type ({ 2 }) of ({ 3 }) display ({ 4 }) does ({ 5 }) not ({ 6 }) need ({ 7 }) any ({ 8 }) markup ({ 9 }) language ({ 10 }) to ({ 11 }) decode ({ 12 }) the ({ 13 }) formulas ({ 14 }) , ({ 15 }) but ({ 16 }) it ({ 17 }) is ({ 18 }) hard ({ 19 }) to ({ 20 }) process ({ 21 }) them ({ 22 }) . ({ 23 }) 
# Sentence pair (2258) source length 25 target length 25 alignment score : 8.01392e-15
A way of dealing with mathematical formulas in this format is to convert them to another text-based format , as seen in InftyReader \CITE . 
NULL ({ }) A ({ 1 }) way ({ 2 }) of ({ 3 }) dealing ({ 4 }) with ({ 5 }) mathematical ({ 6 }) formulas ({ 7 }) in ({ 8 }) this ({ 9 }) format ({ 10 }) is ({ 11 }) to ({ 12 }) convert ({ 13 }) them ({ 14 }) into ({ 15 }) another ({ 16 }) text-based ({ 17 }) format ({ 18 }) , ({ }) for ({ }) example ({ }) , ({ 19 }) InftyReader ({ 20 21 22 23 }) \CITE ({ 24 }) . ({ 25 }) 
# Sentence pair (2259) source length 12 target length 13 alignment score : 8.341e-12
For scientific documents , \TeX{} has been used to encode mathematical formulas . 
NULL ({ 4 }) \TeX{} ({ 1 5 }) has ({ 6 }) been ({ 7 }) used ({ 8 }) to ({ 9 }) encode ({ 10 }) mathematical ({ 11 }) formulas ({ 12 }) in ({ }) scientific ({ 2 }) documents ({ 3 }) . ({ 13 }) 
# Sentence pair (2260) source length 19 target length 19 alignment score : 5.64079e-06
The formula is printed in a way a person would write by hand , or typeset the equation . 
NULL ({ }) A ({ 1 }) formula ({ 2 }) is ({ 3 }) printed ({ 4 }) in ({ 5 }) a ({ 6 }) way ({ 7 }) a ({ 8 }) person ({ 9 }) would ({ 10 }) write ({ 11 }) by ({ 12 }) hand ({ 13 }) , ({ 14 }) or ({ 15 }) typeset ({ 16 }) the ({ 17 }) equation ({ 18 }) . ({ 19 }) 
# Sentence pair (2261) source length 22 target length 22 alignment score : 5.82565e-11
In some web pages , such as the Wikipedia site , a formula is displayed in both image and \TeX{} formats . 
NULL ({ 12 }) In ({ 1 }) some ({ 2 }) web ({ 3 }) pages ({ 4 }) , ({ 5 }) such ({ 6 }) as ({ 7 }) on ({ }) the ({ 8 }) Wikipedia ({ 9 }) site ({ 10 }) , ({ 11 }) formulas ({ 13 }) are ({ 14 }) displayed ({ 15 }) in ({ 16 }) both ({ 17 }) image ({ 18 }) and ({ 19 }) \TeX{} ({ 20 }) formats ({ 21 }) . ({ 22 }) 
# Sentence pair (2262) source length 27 target length 27 alignment score : 2.1328e-05
The best known open markup format for representing mathematical formulas for the web is MathML \CITE , which was recommended by the W3C math working group . 
NULL ({ }) The ({ 1 }) best ({ 2 }) known ({ 3 }) open ({ 4 }) markup ({ 5 }) format ({ 6 }) for ({ 7 }) representing ({ 8 }) mathematical ({ 9 }) formulas ({ 10 }) for ({ 11 }) the ({ 12 }) web ({ 13 }) is ({ 14 }) MathML ({ 15 }) \CITE ({ 16 }) , ({ 17 }) which ({ 18 }) was ({ 19 }) recommended ({ 20 }) by ({ 21 }) the ({ 22 }) W3C ({ 23 }) math ({ 24 }) working ({ 25 }) group ({ 26 }) . ({ 27 }) 
# Sentence pair (2263) source length 10 target length 10 alignment score : 0.0161907
It provides a standard way of representing mathematical expressions . 
NULL ({ }) It ({ 1 }) provides ({ 2 }) a ({ 3 }) standard ({ 4 }) way ({ 5 }) of ({ 6 }) representing ({ 7 }) mathematical ({ 8 }) expressions ({ 9 }) . ({ 10 }) 
# Sentence pair (2264) source length 18 target length 18 alignment score : 0.000363383
It is an XML application for describing mathematical notations and encoding mathematical content within a text format . 
NULL ({ }) It ({ 1 }) is ({ 2 }) an ({ 3 }) XML ({ 4 }) application ({ 5 }) for ({ 6 }) describing ({ 7 }) mathematical ({ 8 }) notations ({ 9 }) and ({ 10 }) encoding ({ 11 }) mathematical ({ 12 }) content ({ 13 }) within ({ 14 }) a ({ 15 }) text ({ 16 }) format ({ 17 }) . ({ 18 }) 
# Sentence pair (2265) source length 36 target length 38 alignment score : 2.07281e-17
MathML has two types of encoding , content-based encoding which is called Content MathML , dealing with the meaning of formulas , and presentation-based encoding which is called Presentation MathML , dealing with the display of formulas . 
NULL ({ 10 11 27 }) MathML ({ 1 }) has ({ 2 }) two ({ 3 }) types ({ 4 }) of ({ 5 }) encoding ({ 6 }) , ({ 7 }) content-based ({ 8 }) encoding ({ 9 }) , ({ }) called ({ 12 }) Content ({ 13 }) MathML ({ 14 }) , ({ 15 }) dealing ({ 16 }) with ({ 17 }) the ({ 18 }) meaning ({ 19 }) of ({ 20 }) formulas ({ 21 }) , ({ 22 }) and ({ 23 }) presentation-based ({ 24 26 }) encoding ({ 25 }) , ({ }) called ({ 28 }) Presentation ({ 29 }) MathML ({ 30 }) , ({ 31 }) dealing ({ 32 }) with ({ 33 }) the ({ 34 }) display ({ 35 }) of ({ 36 }) formulas ({ 37 }) . ({ 38 }) 
# Sentence pair (2266) source length 26 target length 27 alignment score : 4.10725e-16
The illustration tree display of Presentation and Content Markup of the expression $ C_{-\frac{17}{2}}= \tilde {\infty} $ are depicted in Figure \REF and Figure \REF respectively . 
NULL ({ 26 }) The ({ 1 }) illustration ({ 2 }) trees ({ 3 4 }) of ({ 5 }) the ({ }) Presentation ({ 6 }) and ({ 7 }) Content ({ 8 }) Markup ({ 9 }) of ({ 10 }) the ({ 11 }) expression ({ 12 }) $ ({ 13 }) C_{-\frac{17}{2}}= ({ 14 }) \tilde ({ 15 }) {\infty} ({ 16 }) $ ({ 17 }) are ({ 18 }) depicted ({ 19 }) in ({ 20 }) Figure ({ 21 }) \REF ({ 22 }) and ({ 23 }) Figure ({ 24 }) \REF ({ 25 }) . ({ 27 }) 
# Sentence pair (2267) source length 14 target length 14 alignment score : 0.00568799
Besides MathML , there are other markups such as eqn \CITE , OpenOffice . 
NULL ({ }) Besides ({ 1 }) MathML ({ 2 }) , ({ 3 }) there ({ 4 }) are ({ 5 }) other ({ 6 }) markups ({ 7 }) such ({ 8 }) as ({ 9 }) eqn ({ 10 }) \CITE ({ 11 }) , ({ 12 }) OpenOffice ({ 13 }) . ({ 14 }) 
# Sentence pair (2268) source length 25 target length 23 alignment score : 5.97339e-08
org Math \CITE , ASCIIMathML \CITE and OpenMath \CITE , but these markup can be converted to MathML using freely available tools . 
NULL ({ }) org ({ 1 }) Math ({ 2 }) \CITE ({ 3 }) , ({ 4 }) ASCIIMathML ({ 5 }) \CITE ({ 6 }) , ({ }) and ({ 7 }) OpenMath ({ 8 }) \CITE ({ 9 }) , ({ 10 }) but ({ 11 }) these ({ 12 }) markups ({ 13 }) can ({ 14 }) be ({ 15 }) converted ({ 16 }) into ({ 17 }) MathML ({ 18 }) by ({ }) using ({ 19 }) freely ({ 20 }) available ({ 21 }) tools ({ 22 }) . ({ 23 }) 
# Sentence pair (2269) source length 11 target length 10 alignment score : 0.00503215
There are not many studies on semantic enrichment problem . 
NULL ({ }) There ({ 1 }) are ({ 2 }) not ({ 3 }) many ({ 4 }) studies ({ 5 }) on ({ 6 }) the ({ }) semantic ({ 7 }) enrichment ({ 8 }) problem ({ 9 }) . ({ 10 }) 
# Sentence pair (2270) source length 18 target length 18 alignment score : 1.14351e-14
In this section , we list some works that related to exploit the meaning of mathematical expressions . 
NULL ({ 9 11 }) In ({ 1 }) this ({ 2 }) section ({ 3 }) , ({ 4 }) we ({ 5 }) list ({ 6 }) some ({ 7 }) of ({ }) the ({ }) work ({ 8 }) on ({ 10 }) exploiting ({ 12 }) the ({ 13 }) meanings ({ 14 }) of ({ 15 }) mathematical ({ 16 }) expressions ({ 17 }) . ({ 18 }) 
# Sentence pair (2271) source length 20 target length 21 alignment score : 2.80397e-17
For understanding mathematical expressions , Grigole et al. \CITE proposed an approach based on the surrounding text of mathematical expressions . 
NULL ({ 5 18 }) Grigole ({ 1 6 }) et ({ 7 }) al. ({ 8 }) \CITE ({ 9 }) proposed ({ 10 }) an ({ 11 }) approach ({ 12 }) to ({ }) understanding ({ 2 }) mathematical ({ 3 }) expressions ({ 4 }) based ({ 13 }) on ({ 14 }) the ({ 15 }) text ({ 17 }) surrounding ({ 16 }) the ({ }) mathematical ({ 19 }) expressions ({ 20 }) . ({ 21 }) 
# Sentence pair (2272) source length 23 target length 25 alignment score : 5.55586e-09
The main idea of this approach is to use the surrounding text for disambiguation which is based on word sense disambiguation and lexical similarity . 
NULL ({ 15 16 }) The ({ 1 }) main ({ 2 }) idea ({ 3 }) of ({ 4 }) this ({ 5 }) approach ({ 6 }) is ({ 7 }) to ({ 8 }) use ({ 9 }) the ({ 10 }) surrounding ({ 11 }) text ({ 12 }) for ({ 13 }) disambiguation ({ 14 }) based ({ 17 }) on ({ 18 }) word ({ 19 }) sense ({ 20 }) disambiguation ({ 21 }) and ({ 22 }) lexical ({ 23 }) similarity ({ 24 }) . ({ 25 }) 
# Sentence pair (2273) source length 21 target length 21 alignment score : 0.000188006
First , a local context C ( 5 nouns preceding a target mathematical expression ) is found in each sentence . 
NULL ({ }) First ({ 1 }) , ({ 2 }) a ({ 3 }) local ({ 4 }) context ({ 5 }) C ({ 6 }) ( ({ 7 }) five ({ 8 }) nouns ({ 9 }) preceding ({ 10 }) a ({ 11 }) target ({ 12 }) mathematical ({ 13 }) expression ({ 14 }) ) ({ 15 }) is ({ 16 }) found ({ 17 }) in ({ 18 }) each ({ 19 }) sentence ({ 20 }) . ({ 21 }) 
# Sentence pair (2274) source length 29 target length 29 alignment score : 2.34911e-05
For each noun , the system identifies a Term Cluster ( derived from the OpenMath Content Dictionary ) with the highest semantic similarity according to a similarity metric . 
NULL ({ }) For ({ 1 }) each ({ 2 }) noun ({ 3 }) , ({ 4 }) the ({ 5 }) system ({ 6 }) identifies ({ 7 }) a ({ 8 }) Term ({ 9 }) Cluster ({ 10 }) ( ({ 11 }) derived ({ 12 }) from ({ 13 }) the ({ 14 }) OpenMath ({ 15 }) Content ({ 16 }) Dictionary ({ 17 }) ) ({ 18 }) with ({ 19 }) the ({ 20 }) highest ({ 21 }) semantic ({ 22 }) similarity ({ 23 }) according ({ 24 }) to ({ 25 }) a ({ 26 }) similarity ({ 27 }) metric ({ 28 }) . ({ 29 }) 
# Sentence pair (2275) source length 20 target length 20 alignment score : 7.19246e-07
The similarity scores obtained were weighted , summed up , and normalized by the length of the considered context . 
NULL ({ }) The ({ 1 }) similarity ({ 2 }) scores ({ 3 }) obtained ({ 4 }) are ({ 5 }) weighted ({ 6 }) , ({ 7 }) summed ({ 8 }) up ({ 9 }) , ({ 10 }) and ({ 11 }) normalized ({ 12 }) by ({ 13 }) the ({ 14 }) length ({ 15 }) of ({ 16 }) the ({ 17 }) considered ({ 18 }) context ({ 19 }) . ({ 20 }) 
# Sentence pair (2276) source length 14 target length 13 alignment score : 5.14476e-12
The assigned interpretation is the Term Cluster with the highest similarity score . 
NULL ({ 5 }) The ({ 1 }) Term ({ 6 }) Cluster ({ 7 }) with ({ 8 }) the ({ 9 }) highest ({ 10 }) similarity ({ 11 }) score ({ 3 }) is ({ 4 }) assigned ({ 2 }) as ({ }) the ({ }) interpretation ({ 12 }) . ({ 13 }) 
# Sentence pair (2277) source length 24 target length 21 alignment score : 3.31609e-09
The approach was evaluated on 451 manually annotated mathematical expressions and the best result was 68.26 $ F_{0.5} $ score . 
NULL ({ }) The ({ 1 }) approach ({ 2 }) was ({ 3 }) evaluated ({ 4 }) on ({ 5 }) 451 ({ 6 }) manually ({ 7 }) annotated ({ 8 }) mathematical ({ 9 }) expressions ({ 10 }) , ({ }) and ({ 11 }) the ({ 12 }) best ({ 13 }) result ({ 14 }) was ({ 15 }) an ({ }) F_{0.5} ({ 18 }) $ ({ 19 }) score ({ 20 }) of ({ }) 68.26 ({ 16 }) $ ({ 17 }) . ({ 21 }) 
# Sentence pair (2278) source length 32 target length 32 alignment score : 2.45602e-13
To deal with the meanings of mathematical formulas , Nghiem et al. \CITE proposed an approach for extracting the names or descriptions of the formulas using natural language text surrounding them . 
NULL ({ 19 24 }) To ({ 1 }) deal ({ 2 }) with ({ 3 }) the ({ 4 }) meanings ({ 5 }) of ({ 6 }) mathematical ({ 7 }) formulas ({ 8 }) , ({ 9 }) Nghiem ({ 10 }) et ({ 11 }) al. ({ 12 }) \CITE ({ 13 }) proposed ({ 14 }) an ({ 15 }) approach ({ 16 }) for ({ 17 }) extracting ({ 18 }) names ({ 20 }) or ({ 21 }) descriptions ({ 22 }) of ({ 23 }) formulas ({ 25 }) by ({ }) using ({ 26 }) the ({ }) natural ({ 27 }) language ({ 28 }) text ({ 29 }) surrounding ({ 30 }) them ({ 31 }) . ({ 32 }) 
# Sentence pair (2279) source length 15 target length 15 alignment score : 0.00176493
The most accurate extraction result using data from Wikipedia was $ 68.33 $ percent . 
NULL ({ }) The ({ 1 }) most ({ 2 }) accurate ({ 3 }) extraction ({ 4 }) result ({ 5 }) using ({ 6 }) data ({ 7 }) from ({ 8 }) Wikipedia ({ 9 }) was ({ 10 }) $ ({ 11 }) 68.33 ({ 12 }) $ ({ 13 }) percent ({ 14 }) . ({ 15 }) 
# Sentence pair (2280) source length 15 target length 15 alignment score : 0.00365327
There are two other projects that deal with the semantic meaning of mathematical expressions . 
NULL ({ }) There ({ 1 }) are ({ 2 }) two ({ 3 }) other ({ 4 }) projects ({ 5 }) that ({ 6 }) deal ({ 7 }) with ({ 8 }) the ({ 9 }) semantic ({ 10 }) meaning ({ 11 }) of ({ 12 }) mathematical ({ 13 }) expressions ({ 14 }) . ({ 15 }) 
# Sentence pair (2281) source length 27 target length 27 alignment score : 2.08276e-06
The first is the SnuggleTeX project \CITE , which provides a free and open-source Java library for converting fragments of LaTeX to XML including Content MathML . 
NULL ({ }) The ({ 1 }) first ({ 2 }) is ({ 3 }) the ({ 4 }) SnuggleTeX ({ 5 }) project ({ 6 }) \CITE ({ 7 }) , ({ 8 }) which ({ 9 }) provides ({ 10 }) a ({ 11 }) free ({ 12 }) and ({ 13 }) open-source ({ 14 }) Java ({ 15 }) library ({ 16 }) for ({ 17 }) converting ({ 18 }) fragments ({ 19 }) of ({ 20 }) LaTeX ({ 21 }) into ({ 22 }) XML ({ 23 }) including ({ 24 }) Content ({ 25 }) MathML ({ 26 }) . ({ 27 }) 
# Sentence pair (2282) source length 7 target length 7 alignment score : 0.110206
The other project is Lamapun \CITE . 
NULL ({ }) The ({ 1 }) other ({ 2 }) project ({ 3 }) is ({ 4 }) Lamapun ({ 5 }) \CITE ({ 6 }) . ({ 7 }) 
# Sentence pair (2283) source length 16 target length 15 alignment score : 0.00127809
This project investigates semantic enrichment , structural semantics and ambiguity resolution in mathematical corpora . 
NULL ({ }) This ({ 1 }) project ({ 2 }) investigates ({ 3 }) semantic ({ 4 }) enrichment ({ 5 }) , ({ 6 }) structural ({ 7 }) semantics ({ 8 }) , ({ }) and ({ 9 }) ambiguity ({ 10 }) resolution ({ 11 }) in ({ 12 }) mathematical ({ 13 }) corpora ({ 14 }) . ({ 15 }) 
# Sentence pair (2284) source length 10 target length 11 alignment score : 1.18814e-09
Unfortunately , there are no evaluation report on these systems . 
NULL ({ }) Unfortunately ({ 1 }) , ({ 2 }) there ({ 3 }) are ({ 4 }) no ({ 5 }) evaluations ({ 6 7 }) of ({ 8 }) these ({ 9 }) systems ({ 10 }) . ({ 11 }) 
# Sentence pair (2285) source length 21 target length 22 alignment score : 1.9671e-10
To translate mathematical expressions from the Presentation MathML to Content MathML format , a list of rules for translation is required . 
NULL ({ 18 }) To ({ 1 }) translate ({ 2 }) mathematical ({ 3 }) expressions ({ 4 }) from ({ 5 }) the ({ 6 }) Presentation ({ 7 }) MathML ({ 8 }) into ({ 9 }) Content ({ 10 }) MathML ({ 11 }) format ({ 12 }) , ({ 13 }) a ({ 14 }) list ({ 15 }) of ({ 16 }) translation ({ 19 }) rules ({ 17 }) is ({ 20 }) required ({ 21 }) . ({ 22 }) 
# Sentence pair (2286) source length 11 target length 11 alignment score : 0.0222293
Building these translation rules by hand is a large undertaking . 
NULL ({ }) Building ({ 1 }) these ({ 2 }) translation ({ 3 }) rules ({ 4 }) by ({ 5 }) hand ({ 6 }) is ({ 7 }) a ({ 8 }) large ({ 9 }) undertaking ({ 10 }) . ({ 11 }) 
# Sentence pair (2287) source length 25 target length 28 alignment score : 4.4996e-25
Our task is inherently domain specific therefore we propose an approach which is based on statistical machine learning methods that automatically extract these rules from a dataset . 
NULL ({ 12 13 20 }) Our ({ 1 }) task ({ 2 }) is ({ 3 }) inherently ({ 4 }) domain-specific ({ 5 }) ; ({ 6 }) therefore ({ 7 }) , ({ }) we ({ 8 }) devised ({ 9 }) an ({ 10 }) approach ({ 11 }) based ({ 14 }) on ({ 15 }) statistical ({ 16 }) machine ({ 17 }) learning ({ 18 }) for ({ 19 }) automatically ({ 21 }) extracting ({ 22 23 }) rules ({ 24 }) from ({ 25 }) a ({ 26 }) dataset ({ 27 }) . ({ 28 }) 
# Sentence pair (2288) source length 17 target length 18 alignment score : 1.22554e-10
Nowadays , statistical machine translation ( SMT ) is by far the most widely-studied machine translation method . 
NULL ({ 2 }) Statistical ({ 1 3 }) machine ({ 4 }) translation ({ 5 }) ( ({ 6 }) SMT ({ 7 }) ) ({ 8 }) is ({ 9 }) by ({ 10 }) far ({ 11 }) the ({ 12 }) most ({ 13 }) widely ({ }) studied ({ 14 }) machine ({ 15 }) translation ({ 16 }) method ({ 17 }) . ({ 18 }) 
# Sentence pair (2289) source length 41 target length 41 alignment score : 3.32537e-12
SMT uses a very large data set of good translations , that is , a corpus of texts which have already been translated into other language , and then uses those texts to automatically infer a statistical model of translation . 
NULL ({ }) SMT ({ 1 }) uses ({ 2 }) a ({ 3 }) very ({ 4 }) large ({ 5 }) data ({ 6 }) set ({ 7 }) of ({ 8 }) good ({ 9 }) translations ({ 10 }) , ({ 11 }) that ({ 12 }) is ({ 13 }) , ({ 14 }) a ({ 15 }) corpus ({ 16 }) of ({ 17 }) texts ({ 18 }) which ({ 19 }) have ({ 20 }) already ({ 21 }) been ({ 22 }) translated ({ 23 }) into ({ 24 }) another ({ 25 }) language ({ 26 }) , ({ 27 }) and ({ 28 }) it ({ 29 }) uses ({ 30 }) those ({ 31 }) texts ({ 32 }) to ({ 33 }) automatically ({ 34 }) infer ({ 35 }) a ({ 36 }) statistical ({ 37 }) model ({ 38 }) of ({ 39 }) translation ({ 40 }) . ({ 41 }) 
# Sentence pair (2290) source length 16 target length 14 alignment score : 6.08503e-05
The statistical model is then applied to new texts to make a translation . 
NULL ({ }) The ({ 1 }) statistical ({ 2 }) model ({ 3 }) is ({ 4 }) then ({ 5 }) applied ({ 6 }) to ({ 7 }) new ({ 8 }) texts ({ 9 }) to ({ 10 }) make ({ 11 }) a ({ 12 }) translation ({ 13 }) of ({ }) them ({ }) . ({ 14 }) 
# Sentence pair (2291) source length 29 target length 29 alignment score : 2.2081e-16
Tree-based or syntax-based SMT can be used for tree-to-tree translation but it has two drawbacks when apply to the problem of translating from Presentation to Content MathML expression . 
NULL ({ 23 }) Tree-based ({ 1 }) or ({ 2 }) syntax-based ({ 3 }) SMT ({ 4 }) can ({ 5 }) be ({ 6 }) used ({ 7 }) for ({ 8 }) tree-to-tree ({ 9 }) translation ({ 10 }) but ({ 11 }) it ({ 12 }) has ({ 13 }) two ({ 14 }) drawbacks ({ 15 }) when ({ 16 }) it ({ }) is ({ }) applied ({ 17 }) to ({ 18 }) the ({ 19 }) problem ({ 20 }) of ({ 21 }) translating ({ 22 }) Presentation ({ 24 }) into ({ 25 }) Content ({ 26 }) MathML ({ 27 28 }) . ({ 29 }) 
# Sentence pair (2292) source length 18 target length 19 alignment score : 7.59975e-08
- The first drawback is tree-based SMT focus on generating the surface texts rather than the tree structures . 
NULL ({ 11 16 }) - ({ 1 }) The ({ 2 }) first ({ 3 }) drawback ({ 4 }) is ({ 5 }) that ({ }) tree-based ({ 6 }) SMT ({ 7 }) focuses ({ 8 }) on ({ 9 }) generating ({ 10 }) surface ({ 12 }) texts ({ 13 }) rather ({ 14 }) than ({ 15 }) tree ({ 17 }) structures ({ 18 }) . ({ 19 }) 
# Sentence pair (2293) source length 14 target length 14 alignment score : 4.00021e-07
While mathematical expressions have strict structures , it fails to fulfill this requirement . 
NULL ({ }) Mathematical ({ 1 2 }) expressions ({ 3 }) have ({ 4 }) strict ({ 5 }) structures ({ 6 }) , ({ 7 }) and ({ }) it ({ 8 }) fails ({ 9 }) to ({ 10 }) fulfill ({ 11 }) this ({ 12 }) requirement ({ 13 }) . ({ 14 }) 
# Sentence pair (2294) source length 29 target length 29 alignment score : 1.65727e-05
- The second drawback is there are many long mathematical expressions in real-world data and translating long and complex sentences has been a critical problem in machine translation . 
NULL ({ }) - ({ 1 }) The ({ 2 }) second ({ 3 }) drawback ({ 4 }) is ({ 5 }) there ({ 6 }) are ({ 7 }) many ({ 8 }) long ({ 9 }) mathematical ({ 10 }) expressions ({ 11 }) in ({ 12 }) real-world ({ 13 }) data ({ 14 }) and ({ 15 }) translating ({ 16 }) long ({ 17 }) and ({ 18 }) complex ({ 19 }) sentences ({ 20 }) has ({ 21 }) been ({ 22 }) a ({ 23 }) critical ({ 24 }) problem ({ 25 }) in ({ 26 }) machine ({ 27 }) translation ({ 28 }) . ({ 29 }) 
# Sentence pair (2295) source length 18 target length 19 alignment score : 3.27324e-09
To overcome these limitations , we introduced two separated sets of rule : fragment rules and translation rules . 
NULL ({ 11 }) To ({ 1 }) overcome ({ 2 }) these ({ 3 }) limitations ({ 4 }) , ({ 5 }) we ({ 6 }) made ({ 7 }) two ({ 8 }) separate ({ 9 }) rule ({ 12 }) sets ({ 10 }) : ({ 13 }) fragment ({ 14 }) rules ({ 15 }) and ({ 16 }) translation ({ 17 }) rules ({ 18 }) . ({ 19 }) 
# Sentence pair (2296) source length 9 target length 9 alignment score : 0.000152905
The detail is described in the next section . 
NULL ({ }) The ({ 1 }) details ({ 2 }) are ({ 3 }) described ({ 4 }) in ({ 5 }) the ({ 6 }) next ({ 7 }) section ({ 8 }) . ({ 9 }) 
# Sentence pair (2297) source length 11 target length 11 alignment score : 0.0233918
The framework of the system is shown in Figure \REF . 
NULL ({ }) The ({ 1 }) framework ({ 2 }) of ({ 3 }) the ({ 4 }) system ({ 5 }) is ({ 6 }) shown ({ 7 }) in ({ 8 }) Figure ({ 9 }) \REF ({ 10 }) . ({ 11 }) 
# Sentence pair (2298) source length 7 target length 7 alignment score : 0.0782999
The system has three main modules . 
NULL ({ }) The ({ 1 }) system ({ 2 }) has ({ 3 }) three ({ 4 }) main ({ 5 }) modules ({ 6 }) . ({ 7 }) 
# Sentence pair (2299) source length 20 target length 18 alignment score : 3.93117e-07
- Preprocessing : processes MathML expressions to remove error expressions or format tags with no semantic meaning . 
NULL ({ }) - ({ 1 }) Preprocessing ({ 2 }) : ({ 3 }) This ({ }) module ({ 7 }) processes ({ 4 }) MathML ({ 5 }) expressions ({ 6 }) by ({ }) removing ({ 8 }) error ({ 9 }) expressions ({ 10 }) or ({ 11 }) format ({ 12 }) tags ({ 13 }) with ({ 14 }) no ({ 15 }) semantic ({ 16 }) meaning ({ 17 }) . ({ 18 }) 
# Sentence pair (2300) source length 39 target length 19 alignment score : 5.02188e-33
- Extracting Rules : given a dataset contains MathML parallel markup expressions , extract the rules for translation . 
NULL ({ 15 }) - ({ 1 }) Rule ({ 2 }) Extraction ({ 3 }) : ({ 4 }) This ({ }) module ({ }) is ({ }) given ({ 5 }) a ({ 6 }) dataset ({ 7 }) containing ({ 8 }) MathML ({ 9 }) parallel ({ 10 }) markup ({ 11 }) expressions ({ 12 }) , ({ 13 }) and ({ }) it ({ }) extracts ({ 17 }) translation ({ 18 }) rules ({ 16 }) from ({ }) it ({ }) . ({ }) // ({ }) <The ({ }) original ({ }) is ({ }) ungrammatical ({ 14 }) and ({ }) unclear ({ }) . ({ }) The ({ }) rewrite ({ }) is ({ }) a ({ }) guess ({ }) .> ({ }) . ({ 19 }) 
# Sentence pair (2301) source length 34 target length 31 alignment score : 9.53879e-16
- Generating Content MathML : given a mathematical expressions in Presentation MathML markup , and a set of rules , generate Content MathML expressions to enrich the Presentation MathML expressions . 
NULL ({ 14 }) - ({ 1 }) Content ({ 3 }) MathML ({ 4 }) Generation ({ 2 }) : ({ 5 }) This ({ }) module ({ 7 }) is ({ }) given ({ 6 }) mathematical ({ 8 }) expressions ({ 9 }) in ({ 10 }) Presentation ({ 11 }) MathML ({ 12 }) markup ({ 13 }) and ({ 15 }) a ({ 16 }) set ({ 17 }) of ({ 18 }) rules ({ 19 }) , ({ 20 }) and ({ }) it ({ }) generates ({ 21 }) Content ({ 22 }) MathML ({ 23 }) expressions ({ 24 }) to ({ 25 }) enrich ({ 26 }) the ({ 27 }) Presentation ({ 28 }) MathML ({ 29 }) expressions ({ 30 }) . ({ 31 }) 
# Sentence pair (2302) source length 18 target length 18 alignment score : 0.00140539
The presentation elements of Presentation MathML are divided into two classes : token elements and layout schemata . 
NULL ({ }) The ({ 1 }) presentation ({ 2 }) elements ({ 3 }) of ({ 4 }) Presentation ({ 5 }) MathML ({ 6 }) are ({ 7 }) divided ({ 8 }) into ({ 9 }) two ({ 10 }) classes ({ 11 }) : ({ 12 }) token ({ 13 }) elements ({ 14 }) and ({ 15 }) layout ({ 16 }) schemata ({ 17 }) . ({ 18 }) 
# Sentence pair (2303) source length 65 target length 14 alignment score : 6.83767e-56
Token elements represent identifier 's names , function 's names , numbers , etc. 
NULL ({ }) Token ({ 1 }) elements ({ 2 }) represent ({ 3 }) the ({ }) identifier ({ 4 }) 's ({ 5 }) names ({ 6 }) , ({ 7 }) function ({ 8 }) 's ({ 9 }) names ({ 10 }) , ({ 11 }) numbers ({ 12 }) , ({ 13 }) etc. ({ 14 }) // ({ }) <the ({ }) identifier ({ }) 's ({ }) names ({ }) means ({ }) there ({ }) is ({ }) one ({ }) identifier ({ }) with ({ }) possibly ({ }) many ({ }) names ({ }) . ({ }) If ({ }) this ({ }) is ({ }) what ({ }) you ({ }) want ({ }) to ({ }) say ({ }) , ({ }) it ({ }) is ({ }) okay ({ }) . ({ }) If ({ }) not ({ }) , ({ }) maybe ({ }) you ({ }) mean ({ }) simply ({ }) " ({ }) identifier ({ }) names ({ }) " ({ }) . ({ }) ><Likewise ({ }) , ({ }) maybe ({ }) you ({ }) mean ({ }) " ({ }) function ({ }) names ({ }) " ({ }) .> ({ }) 
# Sentence pair (2304) source length 8 target length 8 alignment score : 0.0802229
Layout schemata build expressions out of parts . 
NULL ({ }) Layout ({ 1 }) schemata ({ 2 }) build ({ 3 }) expressions ({ 4 }) out ({ 5 }) of ({ 6 }) parts ({ 7 }) . ({ 8 }) 
# Sentence pair (2305) source length 36 target length 37 alignment score : 2.79274e-14
By investigating the data from the Wolfram Function Site , we noticed that there are elements that have no specific meaning , they are used for displaying purpose only and most of them are layout schemata . 
NULL ({ 3 }) After ({ 1 }) investigating ({ 2 }) data ({ 4 }) on ({ 5 }) the ({ 6 }) Wolfram ({ 7 }) Function ({ 8 }) Site ({ 9 }) , ({ 10 }) we ({ 11 }) noticed ({ 12 }) that ({ 13 }) there ({ 14 }) are ({ 15 }) elements ({ 16 }) that ({ 17 }) have ({ 18 }) no ({ 19 }) specific ({ 20 }) meaning ({ 21 }) ; ({ 22 }) they ({ 23 }) are ({ 24 }) used ({ 25 }) for ({ 26 }) display ({ 27 }) purposes ({ 28 }) only ({ 29 }) and ({ 30 }) most ({ 31 }) of ({ 32 }) them ({ 33 }) are ({ 34 }) layout ({ 35 }) schemata ({ 36 }) . ({ 37 }) 
# Sentence pair (2306) source length 24 target length 24 alignment score : 5.5187e-05
For example , the $ <mtext> </mtext> $ or $ <mspace / > $ tags are used to insert some space between expressions . 
NULL ({ }) For ({ 1 }) example ({ 2 }) , ({ 3 }) the ({ 4 }) $ ({ 5 }) <mtext> ({ 6 }) </mtext> ({ 7 }) $ ({ 8 }) or ({ 9 }) $ ({ 10 }) <mspace ({ 11 }) / ({ 12 }) > ({ 13 }) $ ({ 14 }) tags ({ 15 }) are ({ 16 }) used ({ 17 }) to ({ 18 }) insert ({ 19 }) some ({ 20 }) space ({ 21 }) between ({ 22 }) expressions ({ 23 }) . ({ 24 }) 
# Sentence pair (2307) source length 44 target length 30 alignment score : 1.52946e-29
Another example are the pairs of parentheses , it is used to indicate that the expressions in the parentheses go together , while its structure already encoded that information . 
NULL ({ 4 }) Another ({ 1 }) example ({ 2 }) is ({ 3 }) pairs ({ 5 }) of ({ 6 }) parentheses ({ 7 }) ; ({ 8 }) these ({ }) are ({ }) used ({ 11 }) to ({ 12 }) indicate ({ 13 }) that ({ 14 }) the ({ 15 }) expressions ({ 16 }) in ({ 17 }) the ({ 18 }) parentheses ({ 19 }) go ({ 20 }) together ({ 21 }) , ({ 22 }) despite ({ 23 }) that ({ }) their ({ 24 }) structure ({ 25 }) already ({ 26 }) encodes ({ 27 }) that ({ 28 }) information ({ 29 }) . ({ 30 }) // ({ }) <The ({ }) original ({ }) is ({ }) unclear ({ }) . ({ }) The ({ }) rewrite ({ 9 }) is ({ 10 }) a ({ }) guess ({ }) . ({ }) > ({ }) . ({ }) 
# Sentence pair (2308) source length 7 target length 14 alignment score : 2.29059e-25
As a result , in this preprocessing step , these elements are removed . 
NULL ({ 2 9 12 }) This ({ 1 }) preprocessing ({ 7 }) step ({ 8 }) removes ({ 3 4 5 }) these ({ 10 }) elements ({ 6 11 13 }) . ({ 14 }) 
# Sentence pair (2309) source length 17 target length 21 alignment score : 1.24761e-18
In this step , we also removed mathematical expressions with error markups such as expressions that have no Content markup . 
NULL ({ 2 4 5 }) We ({ 1 }) also ({ 6 }) remove ({ 3 7 }) mathematical ({ 8 }) expressions ({ 9 }) with ({ 10 }) error ({ 11 }) markups ({ 12 }) such ({ 13 }) as ({ 14 }) expressions ({ 15 }) that ({ 16 }) have ({ 17 }) no ({ 18 }) Content ({ 19 }) markup ({ 20 }) . ({ 21 }) 
# Sentence pair (2310) source length 14 target length 14 alignment score : 7.63176e-08
For simplification , expressions with more than 200 content nodes also be removed . 
NULL ({ 12 }) For ({ 1 }) simplification ({ 2 }) , ({ 3 }) expressions ({ 4 }) with ({ 5 }) more ({ 6 }) than ({ 7 }) 200 ({ 8 }) content ({ 9 }) nodes ({ 10 }) are ({ }) also ({ 11 }) removed ({ 13 }) . ({ 14 }) 
# Sentence pair (2311) source length 19 target length 20 alignment score : 7.77325e-06
In the training phase , we use GIZA++ \CITE for alignment between Presentation MathML terms and Content MathML terms . 
NULL ({ }) In ({ 1 }) the ({ 2 }) training ({ 3 }) phase ({ 4 }) , ({ 5 }) we ({ 6 }) use ({ 7 }) GIZA++ ({ 8 }) \CITE ({ 9 }) for ({ 10 }) aligning ({ 11 12 }) Presentation ({ 13 }) MathML ({ 14 }) terms ({ 15 }) and ({ 16 }) Content ({ 17 }) MathML ({ 18 }) terms ({ 19 }) . ({ 20 }) 
# Sentence pair (2312) source length 20 target length 21 alignment score : 8.03072e-08
Based on the aligned data , we use some heuristics to extract rules which we called " fragment rules " . 
NULL ({ }) Based ({ 1 }) on ({ 2 }) the ({ 3 }) aligned ({ 4 }) data ({ 5 }) , ({ 6 }) we ({ 7 }) use ({ 8 }) heuristics ({ 9 10 }) to ({ 11 }) extract ({ 12 }) rules ({ 13 }) that ({ 14 }) we ({ 15 }) call ({ 16 }) " ({ 17 }) fragment ({ 18 }) rules ({ 19 }) " ({ 20 }) . ({ 21 }) 
# Sentence pair (2313) source length 19 target length 17 alignment score : 0.000119333
Fragment rules are rules that define the translation from Presentation MathML sub-trees to Content MathML sub-trees . 
NULL ({ }) Fragment ({ 1 }) rules ({ 2 }) are ({ 3 }) rules ({ 4 }) that ({ 5 }) define ({ 6 }) the ({ 7 }) translation ({ 8 }) from ({ 9 }) the ({ }) Presentation ({ 10 }) MathML ({ 11 }) sub-trees ({ 12 }) to ({ 13 }) the ({ }) Content ({ 14 }) MathML ({ 15 }) sub-trees ({ 16 }) . ({ 17 }) 
# Sentence pair (2314) source length 26 target length 24 alignment score : 5.65083e-09
These rules are applied to break the large Presentation MathML tree into smaller sub-trees while maintaining the structure of output Content MathML trees . 
NULL ({ }) These ({ 1 }) rules ({ 2 }) are ({ 3 }) used ({ 4 }) to ({ 5 }) break ({ 6 }) up ({ 7 }) a ({ }) large ({ 8 }) Presentation ({ 9 }) MathML ({ 10 }) tree ({ 11 }) into ({ 12 }) smaller ({ 13 }) sub-trees ({ 14 }) while ({ 15 }) maintaining ({ 16 }) the ({ 17 }) structure ({ 18 }) of ({ 19 }) the ({ }) output ({ 20 }) Content ({ 21 }) MathML ({ 22 }) trees ({ 23 }) . ({ 24 }) 
# Sentence pair (2315) source length 21 target length 19 alignment score : 4.58768e-07
These rules are extracted based on the fact that translate small tree is easier than translate large one . 
NULL ({ }) These ({ 1 }) rules ({ 2 }) are ({ 3 }) extracted ({ 4 }) based ({ 5 }) on ({ 6 }) the ({ 7 }) fact ({ 8 }) that ({ 9 }) translating ({ 10 }) a ({ }) small ({ 11 }) tree ({ 12 }) is ({ 13 }) easier ({ 14 }) than ({ 15 }) translating ({ 16 }) a ({ }) large ({ 17 }) one ({ 18 }) . ({ 19 }) 
# Sentence pair (2316) source length 28 target length 24 alignment score : 8.49489e-15
Each rule in fragment rule set is associated with its probability , that is the frequent that rule happened in the training data . 
NULL ({ }) Each ({ 1 }) rule ({ 2 }) in ({ 3 }) the ({ }) fragment ({ 4 }) rule ({ 5 }) set ({ 6 }) is ({ 7 }) associated ({ 8 }) with ({ 9 }) a ({ 10 }) probability ({ 11 }) , ({ 12 }) that ({ 13 }) is ({ 14 }) , ({ }) the ({ 15 }) frequency ({ 16 }) at ({ }) which ({ 17 }) a ({ }) rule ({ 18 }) occurs ({ 19 }) in ({ 20 }) the ({ 21 }) training ({ 22 }) data ({ 23 }) . ({ 24 }) 
# Sentence pair (2317) source length 24 target length 27 alignment score : 8.68589e-28
If the sub-trees can not be broken any longer , we extract another rules , which we called " translation rules " , at that point . 
NULL ({ 23 25 }) Once ({ 1 }) the ({ 2 }) sub-trees ({ 3 }) cannot ({ 4 5 }) be ({ 6 }) broken ({ 7 24 }) down ({ 8 26 }) further ({ 9 }) , ({ 10 }) we ({ 11 }) start ({ }) to ({ }) extract ({ 12 }) other ({ 13 }) rules ({ 14 }) , ({ 15 }) which ({ 16 }) we ({ 17 }) call ({ 18 }) " ({ 19 }) translation ({ 20 }) rules ({ 21 }) " ({ 22 }) . ({ 27 }) 
# Sentence pair (2318) source length 13 target length 15 alignment score : 1.81709e-07
We then enhances the translation rule set with the translation terms extracted by GIZA++ . 
NULL ({ 9 }) We ({ 1 }) enhance ({ 2 3 }) the ({ 4 }) translation ({ 5 }) rule ({ 6 }) set ({ 7 }) with ({ 8 }) translation ({ 10 }) terms ({ 11 }) extracted ({ 12 }) by ({ 13 }) GIZA++ ({ 14 }) . ({ 15 }) 
# Sentence pair (2319) source length 13 target length 16 alignment score : 2.03829e-10
The pseudo code of the algorithm for extracting fragment rules is described in Algorithm \REF . 
NULL ({ 4 5 }) The ({ 1 }) pseudo ({ 2 }) code ({ 3 6 }) for ({ 7 }) extracting ({ 8 }) fragment ({ 9 }) rules ({ 10 }) is ({ 11 }) described ({ 12 }) in ({ 13 }) Algorithm ({ 14 }) \REF ({ 15 }) . ({ 16 }) 
# Sentence pair (2320) source length 22 target length 20 alignment score : 4.73899e-06
In the previous steps , we got two sets of rules , fragment rule set and translation rule set . 
NULL ({ }) In ({ 1 }) the ({ 2 }) previous ({ 3 }) steps ({ 4 }) , ({ 5 }) we ({ 6 }) get ({ 7 }) two ({ 8 }) sets ({ 9 }) of ({ 10 }) rules ({ 11 }) , ({ 12 }) a ({ }) fragment ({ 13 }) rule ({ 14 }) set ({ 15 }) and ({ 16 }) a ({ }) translation ({ 17 }) rule ({ 18 }) set ({ 19 }) . ({ 20 }) 
# Sentence pair (2321) source length 8 target length 8 alignment score : 0.0528958
We then use these rules for translation . 
NULL ({ }) We ({ 1 }) then ({ 2 }) use ({ 3 }) these ({ 4 }) rules ({ 5 }) for ({ 6 }) translation ({ 7 }) . ({ 8 }) 
# Sentence pair (2322) source length 19 target length 20 alignment score : 6.36219e-10
Given a mathematical expressions in Presentation MathML markup , the system will generate Content MathML markup of that expression . 
NULL ({ 2 }) Given ({ 1 }) mathematical ({ 3 }) expressions ({ 4 }) in ({ 5 }) Presentation ({ 6 }) MathML ({ 7 }) markup ({ 8 }) , ({ 9 }) the ({ 10 }) system ({ 11 }) will ({ 12 }) generate ({ 13 }) Content ({ 14 }) MathML ({ 15 }) markup ({ 16 }) for ({ 17 }) each ({ 18 }) expression ({ 19 }) . ({ 20 }) 
# Sentence pair (2323) source length 12 target length 13 alignment score : 1.6976e-05
- First , the expression is preprocess to remove non semantic elements . 
NULL ({ }) - ({ 1 }) First ({ 2 }) , ({ 3 }) the ({ 4 }) expression ({ 5 }) is ({ 6 }) preprocessed ({ 7 }) to ({ 8 }) remove ({ 9 }) non-semantic ({ 10 11 }) elements ({ 12 }) . ({ 13 }) 
# Sentence pair (2324) source length 19 target length 20 alignment score : 1.60635e-07
- Second , the fragment rule is applied to the expression until it could not be divided any further . 
NULL ({ }) - ({ 1 }) Second ({ 2 }) , ({ 3 }) the ({ 4 }) fragment ({ 5 }) rule ({ 6 }) is ({ 7 }) applied ({ 8 }) to ({ 9 }) the ({ 10 }) expression ({ 11 }) until ({ 12 }) it ({ 13 }) cannot ({ 14 15 }) be ({ 16 }) divided ({ 17 }) any ({ 18 }) further ({ 19 }) . ({ 20 }) 
# Sentence pair (2325) source length 25 target length 24 alignment score : 2.91237e-11
- Third , the small sub-expressions in Presentation MathML markup will be translated into sub-expressions in Content MathML markup using translation rule set . 
NULL ({ }) - ({ 1 }) Third ({ 2 }) , ({ 3 }) the ({ 4 }) small ({ 5 }) sub-expressions ({ 6 }) in ({ 7 }) Presentation ({ 8 }) MathML ({ 9 }) markup ({ 10 }) are ({ 11 }) translated ({ 12 13 }) into ({ 14 }) sub-expressions ({ 15 }) in ({ 16 }) Content ({ 17 }) MathML ({ 18 }) markup ({ 19 }) by ({ }) using ({ 20 }) the ({ }) translation ({ 21 }) rule ({ 22 }) set ({ 23 }) . ({ 24 }) 
# Sentence pair (2326) source length 17 target length 17 alignment score : 0.00196862
If no translation rule is found for a sub-expression , that expression is marked as untranslated . 
NULL ({ }) If ({ 1 }) no ({ 2 }) translation ({ 3 }) rule ({ 4 }) is ({ 5 }) found ({ 6 }) for ({ 7 }) a ({ 8 }) sub-expression ({ 9 }) , ({ 10 }) that ({ 11 }) expression ({ 12 }) is ({ 13 }) marked ({ 14 }) as ({ 15 }) untranslated ({ 16 }) . ({ 17 }) 
# Sentence pair (2327) source length 18 target length 18 alignment score : 3.52196e-05
- Last , sub-expressions in Content MathML markup is grouped to form the complete Content MathML expression . 
NULL ({ }) - ({ 1 }) Last ({ 2 }) , ({ 3 }) sub-expressions ({ 4 }) in ({ 5 }) Content ({ 6 }) MathML ({ 7 }) markup ({ 8 }) are ({ 9 }) grouped ({ 10 }) to ({ 11 }) form ({ 12 }) the ({ 13 }) complete ({ 14 }) Content ({ 15 }) MathML ({ 16 }) expression ({ 17 }) . ({ 18 }) 
# Sentence pair (2328) source length 14 target length 14 alignment score : 0.00637525
Before the last step , we add a heuristic translation to translate numbers . 
NULL ({ }) Before ({ 1 }) the ({ 2 }) last ({ 3 }) step ({ 4 }) , ({ 5 }) we ({ 6 }) add ({ 7 }) a ({ 8 }) heuristic ({ 9 }) translation ({ 10 }) to ({ 11 }) translate ({ 12 }) numbers ({ 13 }) . ({ 14 }) 
# Sentence pair (2329) source length 22 target length 21 alignment score : 1.76716e-26
The reason for this is that there is infinite number and we could never present every number in the rule . 
NULL ({ 18 19 }) The ({ 1 }) reason ({ 2 }) for ({ 3 }) this ({ 4 }) is ({ 5 }) that ({ 6 }) there ({ 7 }) is ({ 8 }) an ({ }) infinite ({ 9 16 }) number ({ 10 }) of ({ }) rules ({ 17 }) . ({ 21 }) // ({ 14 }) <The ({ 11 }) rewrite ({ 12 }) is ({ }) a ({ }) guess ({ }) .> ({ 13 15 20 }) . ({ }) 
# Sentence pair (2330) source length 9 target length 9 alignment score : 0.0511503
The translation algorithm is described in Algorithm \REF . 
NULL ({ }) The ({ 1 }) translation ({ 2 }) algorithm ({ 3 }) is ({ 4 }) described ({ 5 }) in ({ 6 }) Algorithm ({ 7 }) \REF ({ 8 }) . ({ 9 }) 
# Sentence pair (2331) source length 13 target length 14 alignment score : 0.000112469
The experiments were carried out using the datasets from the Wolfram Function site . 
NULL ({ 7 }) The ({ 1 }) experiments ({ 2 }) were ({ 3 }) carried ({ 4 }) out ({ 5 }) using ({ 6 }) datasets ({ 8 }) from ({ 9 }) the ({ 10 }) Wolfram ({ 11 }) Function ({ 12 }) site ({ 13 }) . ({ 14 }) 
# Sentence pair (2332) source length 16 target length 16 alignment score : 0.00105436
This site was created as a resource for educational , mathematical , and scientific communities . 
NULL ({ }) This ({ 1 }) site ({ 2 }) was ({ 3 }) created ({ 4 }) as ({ 5 }) a ({ 6 }) resource ({ 7 }) for ({ 8 }) educational ({ 9 }) , ({ 10 }) mathematical ({ 11 }) , ({ 12 }) and ({ 13 }) scientific ({ 14 }) communities ({ 15 }) . ({ 16 }) 
# Sentence pair (2333) source length 14 target length 14 alignment score : 0.00622993
It contains the world 's most encyclopedic collection of information about mathematical functions . 
NULL ({ }) It ({ 1 }) contains ({ 2 }) the ({ 3 }) world ({ 4 }) 's ({ 5 }) most ({ 6 }) encyclopedic ({ 7 }) collection ({ 8 }) of ({ 9 }) information ({ 10 }) about ({ 11 }) mathematical ({ 12 }) functions ({ 13 }) . ({ 14 }) 
# Sentence pair (2334) source length 16 target length 16 alignment score : 0.00426154
All formulas on this site are available in both Presentation MathML and Content MathML format . 
NULL ({ }) All ({ 1 }) formulas ({ 2 }) on ({ 3 }) this ({ 4 }) site ({ 5 }) are ({ 6 }) available ({ 7 }) in ({ 8 }) both ({ 9 }) Presentation ({ 10 }) MathML ({ 11 }) and ({ 12 }) Content ({ 13 }) MathML ({ 14 }) format ({ 15 }) . ({ 16 }) 
# Sentence pair (2335) source length 15 target length 15 alignment score : 1.9765e-07
These datasets we used contain 205 , 653 mathematical expressions belong to 6 categories . 
NULL ({ }) The ({ 1 }) datasets ({ 2 }) we ({ 3 }) used ({ 4 }) contain ({ 5 }) 205 ({ 6 }) , ({ 7 }) 653 ({ 8 }) mathematical ({ 9 }) expressions ({ 10 }) belonging ({ 11 }) to ({ 12 }) six ({ 13 }) categories ({ 14 }) . ({ 15 }) 
# Sentence pair (2336) source length 12 target length 12 alignment score : 0.0102399
All of these expressions have both MathML Presentation and Content Markup . 
NULL ({ }) All ({ 1 }) of ({ 2 }) these ({ 3 }) expressions ({ 4 }) have ({ 5 }) both ({ 6 }) MathML ({ 7 }) Presentation ({ 8 }) and ({ 9 }) Content ({ 10 }) Markups ({ 11 }) . ({ 12 }) 
# Sentence pair (2337) source length 22 target length 22 alignment score : 1.98929e-06
Training and testing were performed using 10-fold cross-validation ; for each category , the original corpus is partitioned into 10 subsets . 
NULL ({ }) Training ({ 1 }) and ({ 2 }) testing ({ 3 }) were ({ 4 }) performed ({ 5 }) using ({ 6 }) ten-fold ({ 7 }) cross-validation ({ 8 }) ; ({ 9 }) for ({ 10 }) each ({ 11 }) category ({ 12 }) , ({ 13 }) the ({ 14 }) original ({ 15 }) corpus ({ 16 }) was ({ 17 }) partitioned ({ 18 }) into ({ 19 }) ten ({ 20 }) subsets ({ 21 }) . ({ 22 }) 
# Sentence pair (2338) source length 29 target length 29 alignment score : 2.24889e-06
Of the 10 subsets , a single subset is retained as the validation data for testing the model , and the remaining subsets are used as training data . 
NULL ({ }) Of ({ 1 }) the ({ 2 }) ten ({ 3 }) subsets ({ 4 }) , ({ 5 }) a ({ 6 }) single ({ 7 }) subset ({ 8 }) was ({ 9 }) retained ({ 10 }) as ({ 11 }) the ({ 12 }) validation ({ 13 }) data ({ 14 }) for ({ 15 }) testing ({ 16 }) the ({ 17 }) model ({ 18 }) , ({ 19 }) and ({ 20 }) the ({ 21 }) remaining ({ 22 }) subsets ({ 23 }) were ({ 24 }) used ({ 25 }) as ({ 26 }) training ({ 27 }) data ({ 28 }) . ({ 29 }) 
# Sentence pair (2339) source length 22 target length 23 alignment score : 7.24221e-08
The cross-validation process is then repeated 10 times , with each of the 10 subsets used exactly once as the validation data . 
NULL ({ }) The ({ 1 }) cross-validation ({ 2 }) process ({ 3 }) was ({ 4 }) repeated ({ 5 6 }) ten ({ 7 }) times ({ 8 }) , ({ 9 }) with ({ 10 }) each ({ 11 }) of ({ 12 }) the ({ 13 }) ten ({ 14 }) subsets ({ 15 }) used ({ 16 }) exactly ({ 17 }) once ({ 18 }) as ({ 19 }) the ({ 20 }) validation ({ 21 }) data ({ 22 }) . ({ 23 }) 
# Sentence pair (2340) source length 15 target length 15 alignment score : 0.000629695
The 10 results from the folds then are averaged to produce a single estimation . 
NULL ({ }) The ({ 1 }) ten ({ 2 }) results ({ 3 }) from ({ 4 }) the ({ 5 }) folds ({ 6 }) then ({ 7 }) were ({ 8 }) averaged ({ 9 }) to ({ 10 }) produce ({ 11 }) a ({ 12 }) single ({ 13 }) estimation ({ 14 }) . ({ 15 }) 
# Sentence pair (2341) source length 23 target length 23 alignment score : 1.85447e-06
To prove the effectiveness of our models to real data , we conducted another experiment on the mathematical expressions in scientific papers . 
NULL ({ }) To ({ 1 }) prove ({ 2 }) the ({ 3 }) effectiveness ({ 4 }) of ({ 5 }) our ({ 6 }) models ({ 7 }) with ({ 8 }) real ({ 9 }) data ({ 10 }) , ({ 11 }) we ({ 12 }) conducted ({ 13 }) another ({ 14 }) experiment ({ 15 }) on ({ 16 }) the ({ 17 }) mathematical ({ 18 }) expressions ({ 19 }) in ({ 20 }) scientific ({ 21 }) papers ({ 22 }) . ({ 23 }) 
# Sentence pair (2342) source length 53 target length 28 alignment score : 1.09633e-37
Currently we have 20 papers from ACL archive , all of the math expressions in these papers are annotated manually with both Presentation Markup and Content Markup . 
NULL ({ }) Currently ({ 1 }) , ({ }) we ({ 2 }) have ({ 3 }) 20 ({ 4 }) papers ({ 5 }) from ({ 6 }) the ({ }) ACL ({ 7 }) archive ({ 8 }) , ({ 9 }) and ({ }) we ({ }) manually ({ 20 }) annotated ({ 19 }) all ({ 10 }) of ({ 11 }) the ({ 12 }) math ({ 13 }) expressions ({ 14 }) in ({ 15 }) these ({ 16 }) papers ({ 17 }) with ({ 21 }) both ({ 22 }) Presentation ({ 23 }) Markup ({ 24 }) and ({ 25 }) Content ({ 26 }) Markup ({ 27 }) . ({ 28 }) // ({ }) The ({ }) original ({ }) is ({ }) somewhat ({ }) vague ({ 18 }) . ({ }) The ({ }) rewrite ({ }) is ({ }) a ({ }) guess ({ }) . ({ }) Use ({ }) it ({ }) if ({ }) it ({ }) is ({ }) correct ({ }) . ({ }) > ({ }) . ({ }) 
# Sentence pair (2343) source length 6 target length 6 alignment score : 0.0997981
We called this data ACL-ARC . 
NULL ({ }) We ({ 1 }) called ({ 2 }) this ({ 3 }) data ({ 4 }) ACL-ARC ({ 5 }) . ({ 6 }) 
# Sentence pair (2344) source length 25 target length 25 alignment score : 3.09434e-07
In the first experiment , the data is not compatible with SnuggleTeX since SnuggleTeX use ASCII MathML while the Wolfram Functions site does not . 
NULL ({ }) In ({ 1 }) the ({ 2 }) first ({ 3 }) experiment ({ 4 }) , ({ 5 }) the ({ 6 }) data ({ 7 }) was ({ 8 }) not ({ 9 }) compatible ({ 10 }) with ({ 11 }) SnuggleTeX ({ 12 }) since ({ 13 }) SnuggleTeX ({ 14 }) uses ({ 15 }) ASCII ({ 16 }) MathML ({ 17 }) but ({ 18 }) the ({ 19 }) Wolfram ({ 20 }) Functions ({ 21 }) site ({ 22 }) does ({ 23 }) not ({ 24 }) . ({ 25 }) 
# Sentence pair (2345) source length 15 target length 18 alignment score : 7.77854e-13
In the second experiment with ACL-ARC data , we compared our model side by side with SnuggleTeX . 
NULL ({ 14 }) In ({ 1 }) the ({ 2 }) second ({ 3 }) experiment ({ 4 }) with ({ 5 }) ACL-ARC ({ 6 13 15 }) data ({ 7 }) , ({ 8 }) we ({ 9 }) compared ({ 10 }) our ({ 11 }) model ({ 12 }) with ({ 16 }) SnuggleTeX ({ 17 }) . ({ 18 }) 
# Sentence pair (2346) source length 8 target length 8 alignment score : 0.00811927
Table \REF contains the various data statistics . 
NULL ({ }) Table ({ 1 }) \REF ({ 2 }) lists ({ 3 }) the ({ 4 }) various ({ 5 }) data ({ 6 }) statistics ({ 7 }) . ({ 8 }) 
# Sentence pair (2347) source length 40 target length 40 alignment score : 7.85717e-11
Given a Presentation MathML expression $ e $ , we assume that tree $ A $ is the correct Content MathML tree of expression $ e $ and tree $ B $ is the output using the automatic translation . 
NULL ({ }) Given ({ 1 }) a ({ 2 }) Presentation ({ 3 }) MathML ({ 4 }) expression ({ 5 }) $ ({ 6 }) e ({ 7 }) $ ({ 8 }) , ({ 9 }) we ({ 10 }) assume ({ 11 }) that ({ 12 }) tree ({ 13 }) $ ({ 14 }) A ({ 15 }) $ ({ 16 }) is ({ 17 }) the ({ 18 }) correct ({ 19 }) Content ({ 20 }) MathML ({ 21 }) tree ({ 22 }) of ({ 23 }) expression ({ 24 }) $ ({ 25 }) e ({ 26 }) $ ({ 27 }) and ({ 28 }) tree ({ 29 }) $ ({ 30 }) B ({ 31 }) $ ({ 32 }) is ({ 33 }) the ({ 34 }) output ({ 35 }) of ({ 36 }) the ({ 37 }) automatic ({ 38 }) translation ({ 39 }) . ({ 40 }) 
# Sentence pair (2348) source length 22 target length 22 alignment score : 0.000244499
The basic idea to evaluate the correctness of tree $ B $ is directly comparing it with tree $ A $ . 
NULL ({ }) The ({ 1 }) basic ({ 2 }) idea ({ 3 }) to ({ 4 }) evaluate ({ 5 }) the ({ 6 }) correctness ({ 7 }) of ({ 8 }) tree ({ 9 }) $ ({ 10 }) B ({ 11 }) $ ({ 12 }) is ({ 13 }) directly ({ 14 }) comparing ({ 15 }) it ({ 16 }) with ({ 17 }) tree ({ 18 }) $ ({ 19 }) A ({ 20 }) $ ({ 21 }) . ({ 22 }) 
# Sentence pair (2349) source length 25 target length 25 alignment score : 4.47549e-08
In the experiments , we extend the conventional definition of " Translation Error Rate " and use a metric which is the combined version of 
NULL ({ }) In ({ 1 }) the ({ 2 }) experiments ({ 3 }) , ({ 4 }) we ({ 5 }) extended ({ 6 }) the ({ 7 }) conventional ({ 8 }) definition ({ 9 }) of ({ 10 }) " ({ 11 }) Translation ({ 12 }) Error ({ 13 }) Rate ({ 14 }) " ({ 15 }) and ({ 16 }) used ({ 17 }) a ({ 18 }) metric ({ 19 }) which ({ 20 }) is ({ 21 }) a ({ 22 }) combined ({ 23 }) version ({ 24 }) of ({ 25 }) 
# Sentence pair (2350) source length 24 target length 23 alignment score : 5.6885e-05
- Tree Edit Distance \CITE : the tree edit distance is the minimal cost to transform A into B using edit operations . 
NULL ({ }) - ({ 1 }) the ({ }) Tree ({ 2 }) Edit ({ 3 }) Distance ({ 4 }) \CITE ({ 5 }) : ({ 6 }) the ({ 7 }) tree ({ 8 }) edit ({ 9 }) distance ({ 10 }) is ({ 11 }) the ({ 12 }) minimal ({ 13 }) cost ({ 14 }) to ({ 15 }) transform ({ 16 }) A ({ 17 }) into ({ 18 }) B ({ 19 }) using ({ 20 }) edit ({ 21 }) operations ({ 22 }) . ({ 23 }) 
# Sentence pair (2351) source length 21 target length 21 alignment score : 0.000357194
There are three types of edit operations : substituting a node , inserting a node , and deleting a node . 
NULL ({ }) There ({ 1 }) are ({ 2 }) three ({ 3 }) types ({ 4 }) of ({ 5 }) edit ({ 6 }) operation ({ 7 }) : ({ 8 }) substituting ({ 9 }) a ({ 10 }) node ({ 11 }) , ({ 12 }) inserting ({ 13 }) a ({ 14 }) node ({ 15 }) , ({ 16 }) and ({ 17 }) deleting ({ 18 }) a ({ 19 }) node ({ 20 }) . ({ 21 }) 
# Sentence pair (2352) source length 36 target length 34 alignment score : 6.04553e-08
- Translation Error Rate \CITE : translation error rate is an error metric for machine translation that measures the number of edits required to change a system output into one of the references . 
NULL ({ }) - ({ 1 }) the ({ }) Translation ({ 2 }) Error ({ 3 }) Rate ({ 4 }) \CITE ({ 5 }) : ({ 6 }) the ({ }) translation ({ 7 }) error ({ 8 }) rate ({ 9 }) is ({ 10 }) an ({ 11 }) error ({ 12 }) metric ({ 13 }) for ({ 14 }) machine ({ 15 }) translation ({ 16 }) that ({ 17 }) measures ({ 18 }) the ({ 19 }) number ({ 20 }) of ({ 21 }) edits ({ 22 }) required ({ 23 }) to ({ 24 }) change ({ 25 }) a ({ 26 }) system ({ 27 }) output ({ 28 }) into ({ 29 }) one ({ 30 }) of ({ 31 }) the ({ 32 }) references ({ 33 }) . ({ 34 }) 
# Sentence pair (2353) source length 14 target length 13 alignment score : 0.00010323
We call the new metric Tree Edit Distance Rate ( TEDR ) . 
NULL ({ }) We ({ 1 }) called ({ 2 }) the ({ 3 }) new ({ 4 }) metric ({ 5 }) the ({ }) Tree ({ 6 }) Edit ({ 7 }) Distance ({ 8 }) Rate ({ 9 }) ( ({ 10 }) TEDR ({ 11 }) ) ({ 12 }) . ({ 13 }) 
# Sentence pair (2354) source length 60 target length 39 alignment score : 7.70885e-27
TEDR is defined as the rate between ( 1 ) the minimal cost to transform a tree A into another tree B using edit operations and ( 2 ) the maximum number of nodes of A and B . 
NULL ({ }) TEDR ({ 1 }) is ({ 2 }) defined ({ 3 }) as ({ 4 }) the ({ 5 }) rate ({ 6 }) between ({ 7 }) ( ({ 8 }) 1 ({ 9 }) ) ({ 10 }) the ({ 11 }) minimal ({ 12 }) cost ({ 13 }) to ({ 14 }) transform ({ 15 }) a ({ 16 }) tree ({ 17 }) A ({ 18 }) into ({ 19 }) another ({ 20 }) tree ({ 21 }) B ({ 22 }) using ({ 23 }) edit ({ 24 }) operations ({ 25 }) and ({ 26 }) ( ({ 27 }) 2 ({ 28 }) ) ({ 29 }) the ({ 30 }) maximum ({ 31 }) number ({ 32 }) of ({ 33 }) nodes ({ 34 }) of ({ 35 }) A ({ 36 }) and ({ 37 }) B ({ 38 }) . ({ 39 }) // ({ }) <The ({ }) " ({ }) rate ({ }) between ({ }) " ({ }) is ({ }) unclear ({ }) to ({ }) me ({ }) . ({ }) Do ({ }) you ({ }) mean ({ }) , ({ }) " ({ }) the ({ }) ratio ({ }) of ({ }) " ({ }) > ({ }) 
# Sentence pair (2355) source length 9 target length 9 alignment score : 0.037513
It can be computed using Eq . \REF . 
NULL ({ }) It ({ 1 }) can ({ 2 }) be ({ 3 }) computed ({ 4 }) using ({ 5 }) Eq ({ 6 }) . ({ 7 }) \REF ({ 8 }) . ({ 9 }) 
# Sentence pair (2356) source length 24 target length 23 alignment score : 1.79759e-05
For example , the output tree using translation system for the expression $ C_{-\frac{17}{2}}= \tilde {\infty} $ is depict in Figure \REF . 
NULL ({ }) For ({ 1 }) example ({ 2 }) , ({ 3 }) the ({ 4 }) output ({ 5 }) tree ({ 6 }) using ({ 7 }) the ({ }) translation ({ 8 }) system ({ 9 }) for ({ 10 }) the ({ 11 }) expression ({ 12 }) $ ({ 13 }) C_{-\frac{17}{2}}= ({ 14 }) \tilde ({ 15 }) {\infty} ({ 16 }) $ ({ 17 }) is ({ 18 }) depicted ({ 19 }) in ({ 20 }) Figure ({ 21 }) \REF ({ 22 }) . ({ 23 }) 
# Sentence pair (2357) source length 50 target length 49 alignment score : 3.16504e-20
Compare to the reference tree in Figure \REF , we need to substituting X node , inserting Y node , and deleting Z node , so that $ TED( A , B ) = x $ . While the maximum number of node of two trees is y . 
NULL ({ 37 }) Compared ({ 1 }) with ({ 2 }) the ({ 3 }) reference ({ 4 }) tree ({ 5 }) in ({ 6 }) Figure ({ 7 }) \REF ({ 8 }) , ({ 9 }) we ({ 10 }) need ({ 11 }) to ({ 12 }) substitute ({ 13 }) X ({ 14 }) nodes ({ 15 }) , ({ 16 }) insert ({ 17 }) Y ({ 18 }) nodes ({ 19 }) , ({ 20 }) and ({ 21 }) delete ({ 22 }) Z ({ 23 }) nodes ({ 24 }) , ({ 25 }) so ({ 26 }) that ({ 27 }) $ ({ 28 }) TED( ({ 29 }) A ({ 30 }) , ({ 31 }) B ({ 32 }) ) ({ 33 }) = ({ 34 }) x ({ 35 }) $ ({ 36 }) , ({ }) while ({ 38 }) the ({ 39 }) maximum ({ 40 }) number ({ 41 }) of ({ 42 }) nodes ({ 43 }) of ({ 44 }) the ({ }) two ({ 45 }) trees ({ 46 }) is ({ 47 }) y ({ 48 }) . ({ 49 }) 
# Sentence pair (2358) source length 14 target length 14 alignment score : 0.0086685
Therefore , $ TEDR( A \rightarrow B ) = \frac{x}{y} = z $ . 
NULL ({ }) Therefore ({ 1 }) , ({ 2 }) $ ({ 3 }) TEDR( ({ 4 }) A ({ 5 }) \rightarrow ({ 6 }) B ({ 7 }) ) ({ 8 }) = ({ 9 }) \frac{x}{y} ({ 10 }) = ({ 11 }) z ({ 12 }) $ ({ 13 }) . ({ 14 }) 
# Sentence pair (2359) source length 26 target length 31 alignment score : 6.16501e-38
For the data in Wolfram Function site , it appeared that SnuggleTeX is not applicable to this data since SnuggleTeX use ASCII MathML while the Wolfram Functions site does not . 
NULL ({ 8 }) It ({ 9 }) appeared ({ 10 }) that ({ 11 }) SnuggleTeX ({ 12 }) was ({ 13 }) not ({ 14 }) applicable ({ 1 7 15 }) to ({ 16 }) the ({ 2 }) data ({ 3 }) from ({ 4 }) the ({ }) Wolfram ({ 5 26 }) Function ({ 6 17 27 }) site ({ 18 }) since ({ 19 }) it ({ 20 }) uses ({ 21 }) ASCII ({ 22 }) MathML ({ 23 }) but ({ 24 }) the ({ 25 }) site ({ 28 }) does ({ 29 }) not ({ 30 }) . ({ 31 }) 
# Sentence pair (2360) source length 12 target length 12 alignment score : 1.50912e-08
Therefore we could not do the side-by-side comparison on this data . 
NULL ({ 6 }) Therefore ({ 1 }) , ({ }) we ({ 2 }) could ({ 3 }) not ({ 4 }) do ({ 5 }) a ({ 7 }) comparison ({ 8 }) on ({ 9 }) this ({ 10 }) data ({ 11 }) . ({ 12 }) 
# Sentence pair (2361) source length 23 target length 22 alignment score : 1.28204e-09
Our experimental results show that our approach can archive reasonable results , that is 20 percent TEDR with large training data . 
NULL ({ }) Our ({ 1 }) experimental ({ 2 }) results ({ 3 }) show ({ 4 }) that ({ 5 }) our ({ 6 }) approach ({ 7 }) gives ({ 8 }) reasonable ({ 9 10 }) results ({ 11 }) , ({ 12 }) that ({ 13 }) is ({ 14 }) , ({ }) a ({ }) 20 ({ 15 }) percent ({ 16 }) TEDR ({ 17 }) with ({ 18 }) large ({ 19 }) training ({ 20 }) data ({ 21 }) . ({ 22 }) 
# Sentence pair (2362) source length 21 target length 21 alignment score : 1.7084e-12
For small data which has less than 3000 training samples , the results vary from 50 to 75 percent TEDR . 
NULL ({ 4 }) For ({ 1 }) small ({ 2 }) data ({ 3 }) ( ({ 5 }) less ({ 6 }) than ({ 7 }) 3000 ({ 8 }) training ({ 9 }) samples ({ 10 }) ) ({ }) , ({ 11 }) the ({ 12 }) results ({ 13 }) vary ({ 14 }) from ({ 15 }) 50 ({ 16 }) to ({ 17 }) 75 ({ 18 }) percent ({ 19 }) TEDR ({ 20 }) . ({ 21 }) 
# Sentence pair (2363) source length 23 target length 26 alignment score : 7.4511e-21
For ACL-ARC data , the experimental results from our side-by-side comparison show that our system significantly outperforms SnuggleTeX in terms of Tree Edit Distance Rate . 
NULL ({ 8 9 11 }) For ({ 1 }) ACL-ARC ({ 2 }) data ({ 3 }) , ({ 4 }) the ({ 5 }) experimental ({ 6 }) results ({ 7 }) show ({ 12 }) that ({ 13 }) our ({ 14 }) system ({ 15 }) significantly ({ 16 }) outperforms ({ 17 }) SnuggleTeX ({ 18 }) in ({ 19 }) terms ({ 20 }) of ({ 21 }) the ({ }) Tree ({ 22 }) Edit ({ 23 }) Distance ({ 10 24 }) Rate ({ 25 }) . ({ 26 }) 
# Sentence pair (2364) source length 13 target length 13 alignment score : 8.9935e-17
Our system archived 24 percent TEDR less than the output using SnuggleTeX . 
NULL ({ 9 }) Our ({ 1 }) system ({ 2 }) had ({ 3 }) a ({ }) 24 ({ 4 }) percent ({ 5 8 }) lower ({ 7 }) TEDR ({ 6 }) in ({ }) comparison ({ 10 }) with ({ 11 }) SnuggleTeX ({ 12 }) . ({ 13 }) 
# Sentence pair (2365) source length 27 target length 26 alignment score : 8.51684e-10
To find out the correlation between TEDR score and training set size , we set up an experiment using mathematical expressions in Elementary Functions category . 
NULL ({ }) To ({ 1 }) investigate ({ 2 3 }) the ({ 4 }) correlation ({ 5 }) between ({ 6 }) the ({ }) TEDR ({ 7 }) score ({ 8 }) and ({ 9 }) training ({ 10 }) set ({ 11 }) size ({ 12 }) , ({ 13 }) we ({ 14 }) set ({ 15 }) up ({ 16 }) an ({ 17 }) experiment ({ 18 }) using ({ 19 }) mathematical ({ 20 }) expressions ({ 21 }) in ({ 22 }) the ({ }) Elementary ({ 23 }) Functions ({ 24 }) category ({ 25 }) . ({ 26 }) 
# Sentence pair (2366) source length 19 target length 18 alignment score : 6.05666e-11
We started with one fifth of the data , and then increase data one fifth each run . 
NULL ({ 9 }) We ({ 1 }) started ({ 2 }) with ({ 3 }) one ({ 4 }) fifth ({ 5 }) of ({ 6 }) the ({ 7 }) data ({ 8 }) and ({ 10 }) increased ({ 11 12 }) the ({ }) data ({ 13 }) by ({ }) one ({ 14 }) fifth ({ 15 }) in ({ }) each ({ 16 }) run ({ 17 }) . ({ 18 }) 
# Sentence pair (2367) source length 22 target length 22 alignment score : 6.99987e-05
Our experimental results conform with the theoretical analysis that the more training data we have , the better the results are . 
NULL ({ }) Our ({ 1 }) experimental ({ 2 }) results ({ 3 }) conformed ({ 4 }) with ({ 5 }) the ({ 6 }) theoretical ({ 7 }) analysis ({ 8 }) that ({ 9 }) the ({ 10 }) more ({ 11 }) training ({ 12 }) data ({ 13 }) we ({ 14 }) have ({ 15 }) , ({ 16 }) the ({ 17 }) better ({ 18 }) the ({ 19 }) results ({ 20 }) are ({ 21 }) . ({ 22 }) 
# Sentence pair (2368) source length 29 target length 30 alignment score : 4.59442e-10
Table \REF and Table \REF show the TEDR of our proposed method on the Wolfram Functions Site data and in comparison with SnuggleTeX on ACL ARC data , respectively . 
NULL ({ 11 }) Table ({ 1 }) \REF ({ 2 }) and ({ 3 }) Table ({ 4 }) \REF ({ 5 }) show ({ 6 }) the ({ 7 }) TEDR ({ 8 }) of ({ 9 }) our ({ 10 }) method ({ 12 }) on ({ 13 }) the ({ 14 }) Wolfram ({ 15 }) Functions ({ 16 }) Site ({ 17 }) data ({ 18 }) and ({ 19 }) in ({ 20 }) comparison ({ 21 }) with ({ 22 }) SnuggleTeX ({ 23 }) on ({ 24 }) ACL ({ 25 }) ARC ({ 26 }) data ({ 27 }) , ({ 28 }) respectively ({ 29 }) . ({ 30 }) 
# Sentence pair (2369) source length 16 target length 16 alignment score : 0.00608346
Table \REF and Figure \REF shows the correlation between TEDR score and training set size . 
NULL ({ }) Table ({ 1 }) \REF ({ 2 }) and ({ 3 }) Figure ({ 4 }) \REF ({ 5 }) shows ({ 6 }) the ({ 7 }) correlation ({ 8 }) between ({ 9 }) TEDR ({ 10 }) score ({ 11 }) and ({ 12 }) training ({ 13 }) set ({ 14 }) size ({ 15 }) . ({ 16 }) 
# Sentence pair (2370) source length 11 target length 16 alignment score : 1.05898e-15
In this paper , we discussed the problem of the semantic enrichment of mathematical expressions . 
NULL ({ 4 10 }) We ({ 1 }) discussed ({ 2 3 5 6 }) the ({ 7 }) problem ({ 8 }) of ({ 9 }) semantic ({ 11 }) enrichment ({ 12 }) of ({ 13 }) mathematical ({ 14 }) expressions ({ 15 }) . ({ 16 }) 
# Sentence pair (2371) source length 32 target length 34 alignment score : 7.39443e-19
Our experimental results show that our approach based on the statistical machine translation method for translating a Presentation MathML expression to a Content MathML expression has the significant improvement over a prior system . 
NULL ({ 22 31 }) Our ({ 1 }) experimental ({ 2 }) results ({ 3 }) show ({ 4 }) that ({ 5 }) our ({ 6 }) approach ({ 7 }) based ({ 8 }) on ({ 9 }) the ({ 10 }) statistical ({ 11 }) machine ({ 12 }) translation ({ 13 }) method ({ 14 }) for ({ 15 }) translating ({ 16 }) a ({ 17 }) Presentation ({ 18 }) MathML ({ 19 }) expressions ({ 20 }) to ({ 21 }) Content ({ 23 }) MathML ({ 24 }) expressions ({ 25 }) is ({ 26 }) a ({ 27 }) significant ({ 28 }) improvement ({ 29 }) over ({ 30 }) prior ({ 32 }) systems ({ 33 }) . ({ 34 }) 
# Sentence pair (2372) source length 10 target length 10 alignment score : 0.0299975
As we mentioned before , mathematical notations are context-dependent . 
NULL ({ }) As ({ 1 }) we ({ 2 }) mentioned ({ 3 }) before ({ 4 }) , ({ 5 }) mathematical ({ 6 }) notations ({ 7 }) are ({ 8 }) context-dependent ({ 9 }) . ({ 10 }) 
# Sentence pair (2373) source length 27 target length 27 alignment score : 1.68763e-05
That means we need to consider not only surrounding expressions but also the document that contains the notations in order to generate the correct semantic output . 
NULL ({ }) That ({ 1 }) means ({ 2 }) we ({ 3 }) need ({ 4 }) to ({ 5 }) consider ({ 6 }) not ({ 7 }) only ({ 8 }) surrounding ({ 9 }) expressions ({ 10 }) but ({ 11 }) also ({ 12 }) the ({ 13 }) document ({ 14 }) that ({ 15 }) contains ({ 16 }) the ({ 17 }) notations ({ 18 }) in ({ 19 }) order ({ 20 }) to ({ 21 }) generate ({ 22 }) the ({ 23 }) correct ({ 24 }) semantic ({ 25 }) output ({ 26 }) . ({ 27 }) 
# Sentence pair (2374) source length 17 target length 15 alignment score : 3.78618e-07
In the scope of this paper , we only consider the first context information . 
NULL ({ }) In ({ 1 }) the ({ 2 }) scope ({ 3 }) of ({ 4 }) this ({ 5 }) paper ({ 6 }) , ({ 7 }) we ({ 8 }) only ({ 9 }) considered ({ 10 }) the ({ 11 }) first ({ 12 }) sort ({ }) of ({ }) context ({ 13 }) information ({ 14 }) . ({ 15 }) 
# Sentence pair (2375) source length 26 target length 25 alignment score : 1.58413e-06
Since this is a first attempt to translate Presentation to Content MathML using a machine learning method , there is room for further improvement . 
NULL ({ }) Since ({ 1 }) this ({ 2 }) is ({ 3 }) a ({ 4 }) first ({ 5 }) attempt ({ 6 }) to ({ 7 }) translate ({ 8 }) from ({ }) Presentation ({ 9 }) to ({ 10 }) Content ({ 11 }) MathML ({ 12 }) using ({ 13 }) a ({ 14 }) machine ({ 15 }) learning ({ 16 }) method ({ 17 }) , ({ 18 }) there ({ 19 }) is ({ 20 }) room ({ 21 }) for ({ 22 }) further ({ 23 }) improvement ({ 24 }) . ({ 25 }) 
# Sentence pair (2376) source length 3 target length 3 alignment score : 0.402341
Possible improvements are 
NULL ({ }) Possible ({ 1 }) improvements ({ 2 }) are ({ 3 }) 
# Sentence pair (2377) source length 13 target length 13 alignment score : 0.00412263
- Increasing the training data so the system can cover more mathematical notations 
NULL ({ }) - ({ 1 }) Increasing ({ 2 }) the ({ 3 }) training ({ 4 }) data ({ 5 }) so ({ 6 }) the ({ 7 }) system ({ 8 }) can ({ 9 }) cover ({ 10 }) more ({ 11 }) mathematical ({ 12 }) notations ({ 13 }) 
# Sentence pair (2378) source length 22 target length 21 alignment score : 3.7068e-05
- Expanding the work by incorporating the surrounding information of mathematical expressions , for example definitions or other mathematical expressions . 
NULL ({ }) - ({ 1 }) Expanding ({ 2 }) the ({ 3 }) work ({ 4 }) by ({ 5 }) incorporating ({ 6 }) the ({ 7 }) surrounding ({ 8 }) information ({ 9 }) of ({ 10 }) mathematical ({ 11 }) expressions ({ 12 }) , ({ 13 }) for ({ 14 }) example ({ 15 }) , ({ }) definitions ({ 16 }) or ({ 17 }) other ({ 18 }) mathematical ({ 19 }) expressions ({ 20 }) . ({ 21 }) 
# Sentence pair (2379) source length 16 target length 19 alignment score : 5.95381e-16
By combining the automatic extraction of fragment rules and translation rules , our approach has shown promising results . 
NULL ({ 3 12 13 }) Our ({ 1 }) approach ({ 14 }) combining ({ 2 }) automatic ({ 4 }) extraction ({ 5 }) of ({ 6 }) fragment ({ 7 }) rules ({ 8 }) and ({ 9 }) translation ({ 10 }) rules ({ 11 }) has ({ 15 }) shown ({ 16 }) promising ({ 17 }) results ({ 18 }) . ({ 19 }) 
# Sentence pair (2380) source length 16 target length 16 alignment score : 4.63001e-16
The experimental results confirm that this approach is helpful to the understanding of mathematical expressions . 
NULL ({ 7 }) The ({ 1 }) experimental ({ 2 }) results ({ 3 }) confirm ({ 4 }) that ({ 5 }) it ({ 6 }) would ({ 8 }) be ({ }) helpful ({ 9 }) for ({ 10 }) automatic ({ 11 }) understanding ({ 12 }) of ({ 13 }) mathematical ({ 14 }) expressions ({ 15 }) . ({ 16 }) 
# Sentence pair (2381) source length 17 target length 17 alignment score : 0.000439723
However , this is only a first step ; many important issues remain for future studies . 
NULL ({ }) However ({ 1 }) , ({ 2 }) this ({ 3 }) is ({ 4 }) only ({ 5 }) a ({ 6 }) first ({ 7 }) step ({ 8 }) ; ({ 9 }) many ({ 10 }) important ({ 11 }) issues ({ 12 }) remain ({ 13 }) for ({ 14 }) future ({ 15 }) studies ({ 16 }) . ({ 17 }) 
# Sentence pair (2382) source length 13 target length 13 alignment score : 1.9651e-08
Currently , our system deals only with a sub-part of mathematical notations . 
NULL ({ }) Currently ({ 1 }) , ({ 2 }) our ({ 3 }) system ({ 4 }) deals ({ 5 6 }) with ({ 7 }) a ({ 8 }) limited ({ }) range ({ 9 }) of ({ 10 }) mathematical ({ 11 }) notations ({ 12 }) . ({ 13 }) 
# Sentence pair (2383) source length 15 target length 16 alignment score : 1.96021e-10
In future work , we should also consider expanding it to cover all mathematical notations . 
NULL ({ }) In ({ 1 }) the ({ }) future ({ 2 3 }) , ({ 4 }) we ({ 5 }) should ({ 6 }) consider ({ 7 8 }) expanding ({ 9 }) it ({ 10 }) to ({ 11 }) cover ({ 12 }) all ({ 13 }) mathematical ({ 14 }) notations ({ 15 }) . ({ 16 }) 
# Sentence pair (2384) source length 8 target length 8 alignment score : 0.0429559
Improving protein coreference resolution by simple semantic classification 
NULL ({ }) Improving ({ 1 }) protein ({ 2 }) coreference ({ 3 }) resolution ({ 4 }) by ({ 5 }) simple ({ 6 }) semantic ({ 7 }) classification ({ 8 }) 
# Sentence pair (2385) source length 20 target length 21 alignment score : 1.87138e-21
Recent research shows a major part of difficult cases in event extraction for the biomedical domain are related to coreference . 
NULL ({ 10 }) Current ({ 1 }) research ({ 2 }) has ({ 3 }) shown ({ 4 }) that ({ }) major ({ 5 }) difficulties ({ 6 }) in ({ 7 }) event ({ 8 11 }) extraction ({ 12 }) cases ({ 9 }) for ({ 13 }) the ({ 14 }) biomedical ({ 15 }) domain ({ 16 }) are ({ 17 }) related ({ 18 }) to ({ 19 }) coreference ({ 20 }) . ({ 21 }) 
# Sentence pair (2386) source length 14 target length 16 alignment score : 3.20353e-09
Therefore , coreference resolution is believed to be useful for the improvement of event extraction . 
NULL ({ 11 13 }) Therefore ({ 1 }) , ({ 2 }) coreference ({ 3 }) resolution ({ 4 }) is ({ 5 }) believed ({ 6 }) to ({ 7 }) be ({ 8 }) useful ({ 9 }) for ({ 10 }) improving ({ 12 }) event ({ 14 }) extraction ({ 15 }) . ({ 16 }) 
# Sentence pair (2387) source length 28 target length 30 alignment score : 5.84394e-13
To address the problem of coreference resolution in molecular biology literature , the Protein Coreference ( COREF ) task was arranged in the BioNLP-ST 2011 as a supporting task . 
NULL ({ 3 5 }) To ({ 1 }) address ({ 2 4 }) coreference ({ 6 }) resolution ({ 7 }) in ({ 8 }) molecular ({ 9 }) biology ({ 10 }) literature ({ 11 }) , ({ 12 }) the ({ 13 }) Protein ({ 14 }) Coreference ({ 15 }) ( ({ 16 }) COREF ({ 17 }) ) ({ 18 }) task ({ 19 }) was ({ 20 }) arranged ({ 21 }) in ({ 22 }) the ({ 23 }) BioNLP-ST ({ 24 }) 2011 ({ 25 }) , ({ }) as ({ 26 }) a ({ 27 }) supporting ({ 28 }) task ({ 29 }) . ({ 30 }) 
# Sentence pair (2388) source length 34 target length 39 alignment score : 1.07973e-25
However , the shared task results showed that transferring coreference resolution methods developed for other domains to the biological domain was not straight forward , which is supposed to be caused by the domain differences in coreference phenomena . 
NULL ({ 26 27 }) However ({ 1 }) , ({ 2 }) the ({ 3 }) shared ({ 4 }) task ({ 5 }) results ({ 6 }) indicated ({ 7 }) that ({ 8 }) transferring ({ 9 }) coreference ({ 10 }) resolution ({ 11 }) methods ({ 12 }) developed ({ 13 }) for ({ 14 }) other ({ 15 }) domains ({ 16 }) to ({ 17 }) the ({ 18 }) biological ({ 19 }) domain ({ 20 }) was ({ 21 }) not ({ 22 }) straightforward ({ 23 24 }) , ({ 25 }) due ({ 28 }) to ({ 29 }) the ({ 33 }) domain ({ 34 }) differences ({ 35 }) in ({ 36 }) the ({ }) coreference ({ 37 }) phenomena ({ 30 31 32 38 }) . ({ 39 }) 
# Sentence pair (2389) source length 24 target length 24 alignment score : 1.20985e-13
We studied the contribution of domain-specific information , i .e information indicating the protein type , in a rule-based protein coreference resolution system . 
NULL ({ }) We ({ 1 }) studied ({ 2 }) the ({ 3 }) contribution ({ 4 }) of ({ 5 }) domain-specific ({ 6 }) information ({ 7 }) , ({ 8 }) including ({ 9 10 }) information ({ 11 }) that ({ }) indicates ({ 12 }) the ({ 13 }) protein ({ 14 }) type ({ 15 }) , ({ 16 }) in ({ 17 }) a ({ 18 }) rule-based ({ 19 }) protein ({ 20 }) coreference ({ 21 }) resolution ({ 22 }) system ({ 23 }) . ({ 24 }) 
# Sentence pair (2390) source length 26 target length 24 alignment score : 1.01387e-08
In particular , the domain-specific information is encoded into semantic classification modules whose output is used in different components of the coreference resolution . 
NULL ({ }) In ({ 1 }) particular ({ 2 }) , ({ 3 }) the ({ 4 }) domain-specific ({ 5 }) information ({ 6 }) is ({ 7 }) encoded ({ 8 }) into ({ 9 }) semantic ({ 10 }) classification ({ 11 }) modules ({ 12 }) for ({ }) which ({ 13 }) the ({ }) output ({ 14 }) is ({ 15 }) used ({ 16 }) in ({ 17 }) different ({ 18 }) components ({ 19 }) of ({ 20 }) the ({ 21 }) coreference ({ 22 }) resolution ({ 23 }) . ({ 24 }) 
# Sentence pair (2391) source length 32 target length 32 alignment score : 1.51976e-10
We compared our system with the top four systems in the BioNLP-ST 2011 , and surprisingly we found that the minimal configuration has outperformed the best system in the BioNLP-ST 2011 . 
NULL ({ }) We ({ 1 }) compared ({ 2 }) our ({ 3 }) system ({ 4 }) with ({ 5 }) the ({ 6 }) top ({ 7 }) four ({ 8 }) systems ({ 9 }) in ({ 10 }) the ({ 11 }) BioNLP-ST ({ 12 }) 2011 ({ 13 }) ; ({ 14 }) surprisingly ({ 15 16 }) , ({ }) we ({ 17 }) found ({ 18 }) that ({ 19 }) the ({ 20 }) minimal ({ 21 }) configuration ({ 22 }) had ({ 23 }) outperformed ({ 24 }) the ({ 25 }) best ({ 26 }) system ({ 27 }) in ({ 28 }) the ({ 29 }) BioNLP-ST ({ 30 }) 2011 ({ 31 }) . ({ 32 }) 
# Sentence pair (2392) source length 40 target length 39 alignment score : 3.72026e-17
Analysis of the experimental results showed that semantic classification using protein information has contributed to an increase in performance ( 2.3 % on the test data , and 4 .0% on the development data , in F-score ) . 
NULL ({ }) Analysis ({ 1 }) of ({ 2 }) the ({ 3 }) experimental ({ 4 }) results ({ 5 }) revealed ({ 6 }) that ({ 7 }) semantic ({ 8 }) classification ({ 9 }) , ({ }) using ({ 10 }) protein ({ 11 }) information ({ 12 }) , ({ }) had ({ 13 }) contributed ({ 14 }) to ({ 15 }) an ({ 16 }) increase ({ 17 }) in ({ 18 }) performance ({ 19 }) by ({ 20 }) 2.3 ({ 21 }) % ({ 22 }) on ({ 23 }) the ({ 24 }) test ({ 25 }) data ({ 26 }) , ({ 27 }) and ({ 28 }) 4 ({ 29 }) .0% ({ 30 }) on ({ 31 }) the ({ 32 }) development ({ 33 }) data ({ 34 }) , ({ 35 }) in ({ 36 }) F-score ({ 37 38 }) . ({ 39 }) 
# Sentence pair (2393) source length 14 target length 14 alignment score : 0.00459456
The use of domain-specific information in semantic classification is important for coreference resolution . 
NULL ({ }) The ({ 1 }) use ({ 2 }) of ({ 3 }) domain-specific ({ 4 }) information ({ 5 }) in ({ 6 }) semantic ({ 7 }) classification ({ 8 }) is ({ 9 }) important ({ 10 }) for ({ 11 }) coreference ({ 12 }) resolution ({ 13 }) . ({ 14 }) 
# Sentence pair (2394) source length 28 target length 28 alignment score : 1.93334e-17
Since such information is difficult to be transferred across different domains , we need to continue seeking for methods to exploit and use it in coreference resolution . 
NULL ({ 2 18 }) Since ({ 1 }) it ({ }) is ({ 4 }) difficult ({ 5 }) to ({ 6 }) transfer ({ 7 }) domain-specific ({ 8 }) information ({ 3 }) across ({ 9 }) different ({ 10 }) domains ({ 11 }) , ({ 12 }) we ({ 13 }) need ({ 14 }) to ({ 15 }) continue ({ 16 }) to ({ }) seek ({ 17 }) methods ({ 19 }) to ({ 20 }) exploit ({ 21 }) and ({ 22 }) use ({ 23 }) it ({ 24 }) in ({ 25 }) coreference ({ 26 }) resolution ({ 27 }) . ({ 28 }) 
# Sentence pair (2395) source length 52 target length 50 alignment score : 2.16617e-18
While named entity recognition ( NER ) and relation or event extraction are regarded as standard tasks of biomedical information extraction ( IE ) , coreference resolution [ 2 , 16 , 30 ] is more and more recognized as an important component of IE for a higher performance . 
NULL ({ }) While ({ 1 }) named ({ 2 }) entity ({ 3 }) recognition ({ 4 }) ( ({ 5 }) NER ({ 6 }) ) ({ 7 }) and ({ 8 }) relation ({ 9 }) / ({ 10 }) event ({ 11 }) extraction ({ 12 }) are ({ 13 }) regarded ({ 14 }) as ({ 15 }) standard ({ 16 }) tasks ({ 17 }) for ({ 18 }) biomedical ({ 19 }) information ({ 20 }) extraction ({ 21 }) ( ({ 22 }) IE ({ 23 }) ) ({ 24 }) , ({ 25 }) coreference ({ 26 }) resolution ({ 27 }) [ ({ 28 }) 2 ({ 29 }) , ({ 30 }) 16 ({ 31 }) , ({ 32 }) 30 ({ 33 }) ] ({ 34 }) is ({ 35 }) being ({ }) recognized ({ 39 }) more ({ 36 }) and ({ 37 }) more ({ 38 }) as ({ 40 }) an ({ 41 }) important ({ 42 }) component ({ 43 }) of ({ 44 }) IE ({ 45 }) to ({ }) achieve ({ 46 }) a ({ 47 }) higher ({ 48 }) performance ({ 49 }) . ({ 50 }) 
# Sentence pair (2396) source length 47 target length 48 alignment score : 5.17295e-24
Without coreference resolution , the performance of IE is often substantially limited due to an abundance of coreference relations in natural language text , i.e. , information pieces written in text with involvement of a coreference relation are hard to be captured [ 9 , 14 ] . 
NULL ({ 5 7 9 }) Without ({ 1 }) coreference ({ 2 }) resolution ({ 3 }) , ({ 4 }) oftentimes ({ 25 }) , ({ 26 }) the ({ }) IE ({ 8 }) performance ({ 6 }) issubstantially ({ 10 11 }) limited ({ 12 }) , ({ }) due ({ 13 }) to ({ 14 }) the ({ 15 }) abundance ({ 16 }) of ({ 17 }) coreference ({ 18 }) relations ({ 19 }) in ({ 20 }) natural ({ 21 }) language ({ 22 }) text ({ 23 }) ; ({ 24 }) information ({ 27 }) pieces ({ 28 }) written ({ 29 }) in ({ 30 }) text ({ 31 }) with ({ 32 }) the ({ }) involvement ({ 33 }) of ({ 34 }) a ({ 35 }) coreference ({ 36 }) relation ({ 37 }) are ({ 38 }) hard ({ 39 }) to ({ 40 }) be ({ 41 }) captured ({ 42 }) [ ({ 43 }) 9 ({ 44 }) , ({ 45 }) 14 ({ 46 }) ] ({ 47 }) . ({ 48 }) 
# Sentence pair (2397) source length 32 target length 27 alignment score : 2.8324e-11
There have been several attempts for coreference resolution , particularly for newswire texts [ 7 , 8 , 22 , 23 , 28 , 30 ] . 
NULL ({ }) There ({ 1 }) have ({ 2 }) been ({ 3 }) several ({ 4 }) attempts ({ 5 }) for ({ 6 }) coreference ({ 7 }) resolution ({ 8 }) ; ({ 9 }) in ({ }) particular ({ 10 }) , ({ }) they ({ }) have ({ }) been ({ }) for ({ 11 }) newswire ({ 12 }) texts ({ 13 }) [ ({ 14 }) 7 ({ 15 }) , ({ 16 }) 8 ({ 17 }) , ({ 18 }) 22 ({ 19 }) , ({ 20 }) 23 ({ 21 }) , ({ 22 }) 28 ({ 23 }) , ({ 24 }) 30 ({ 25 }) ] ({ 26 }) . ({ 27 }) 
# Sentence pair (2398) source length 42 target length 34 alignment score : 1.62089e-15
It is also one of the lessons from BioNLP Shared Task ( BioNLP-ST , hereafter ) 2009 that coreference relations in biomedical text substantially hinder the progress of fine-grained IE [ 10 ] . 
NULL ({ }) Coreference ({ 1 }) resolution ({ }) is ({ 2 }) also ({ 3 }) one ({ 4 }) of ({ 5 }) the ({ 6 }) lessons ({ 7 }) from ({ 8 }) the ({ }) BioNLP ({ 9 }) Shared ({ 10 }) Task ({ 11 }) ( ({ 12 }) BioNLP-ST ({ 13 }) , ({ 14 }) hereafter ({ 15 }) ) ({ 16 }) 2009 ({ }) , ({ }) in ({ }) which ({ }) it ({ }) was ({ }) communicated ({ 17 }) that ({ 18 }) coreference ({ 19 }) relations ({ 20 }) in ({ 21 }) biomedical ({ 22 }) text ({ 23 }) substantially ({ 24 }) hinder ({ 25 }) the ({ 26 }) progress ({ 27 }) of ({ 28 }) fine-grained ({ 29 }) IE ({ 30 }) [ ({ 31 }) 10 ({ 32 }) ] ({ 33 }) . ({ 34 }) 
# Sentence pair (2399) source length 29 target length 29 alignment score : 9.86028e-06
To address the problem of coreference resolution in molecular biology literature , the Protein Coreference ( COREF ) task was arranged in BioNLP-ST 2011 as a supporting task . 
NULL ({ }) To ({ 1 }) address ({ 2 }) the ({ 3 }) problem ({ 4 }) of ({ 5 }) coreference ({ 6 }) resolution ({ 7 }) in ({ 8 }) molecular ({ 9 }) biology ({ 10 }) literature ({ 11 }) , ({ 12 }) the ({ 13 }) Protein ({ 14 }) Coreference ({ 15 }) ( ({ 16 }) COREF ({ 17 }) ) ({ 18 }) task ({ 19 }) was ({ 20 }) arranged ({ 21 }) in ({ 22 }) BioNLP-ST ({ 23 }) 2011 ({ 24 }) as ({ 25 }) a ({ 26 }) supporting ({ 27 }) task ({ 28 }) . ({ 29 }) 
# Sentence pair (2400) source length 14 target length 14 alignment score : 1.29307e-15
This task definition focuses on a specific type of entities , i.e. Protein . 
NULL ({ 11 }) This ({ 1 }) task ({ 2 }) definition ({ 3 }) focuses ({ 4 }) on ({ 5 }) protein ({ }) , ({ }) as ({ }) a ({ 6 }) specific ({ 7 }) type ({ 8 }) of ({ 9 }) entity ({ 10 12 13 }) . ({ 14 }) 
# Sentence pair (2401) source length 23 target length 23 alignment score : 0.000357261
Figure 1 shows an example text segmented into four sentences , S2 - S5 , where coreferential expressions are shown in brackets . 
NULL ({ }) Figure ({ 1 }) 1 ({ 2 }) shows ({ 3 }) an ({ 4 }) example ({ 5 }) text ({ 6 }) segmented ({ 7 }) into ({ 8 }) four ({ 9 }) sentences ({ 10 }) , ({ 11 }) S2 ({ 12 }) - ({ 13 }) S5 ({ 14 }) , ({ 15 }) where ({ 16 }) coreferential ({ 17 }) expressions ({ 18 }) are ({ 19 }) shown ({ 20 }) in ({ 21 }) brackets ({ 22 }) . ({ 23 }) 
# Sentence pair (2402) source length 50 target length 52 alignment score : 7.75315e-30
In the figure , protein names are highlighted in bold face , P4 - P10 , and targeted anaphoric expressions of the shared task , e.g. pronouns and definite noun phrases , are T29 , and T32 , of which the antecedents are indicated by arrows if found in the text . 
NULL ({ 25 32 35 36 }) In ({ 1 }) the ({ 2 }) figure ({ 3 }) , ({ 4 }) protein ({ 5 }) names ({ 6 }) P4 ({ 13 }) - ({ 14 }) P10 ({ 15 }) are ({ 7 }) highlighted ({ 8 }) in ({ 9 }) boldface ({ 10 11 }) ; ({ 12 }) the ({ }) targeted ({ 18 }) anaphoric ({ 19 }) expressions ({ 20 }) of ({ 21 }) the ({ 22 }) shared ({ 23 }) task ({ 24 }) ( ({ 26 }) pronouns ({ 27 }) and ({ 28 }) definite ({ 29 }) noun ({ 30 }) phrases ({ 31 }) ) ({ }) are ({ 33 }) T29 ({ 34 }) , ({ 16 }) and ({ 17 }) T32 ({ 37 }) , ({ 38 }) for ({ 39 }) which ({ 40 }) the ({ 41 }) antecedents ({ 42 }) are ({ 43 }) indicated ({ 44 }) by ({ 45 }) arrows ({ 46 }) , ({ }) if ({ 47 }) found ({ 48 }) in ({ 49 }) the ({ 50 }) text ({ 51 }) . ({ 52 }) 
# Sentence pair (2403) source length 27 target length 27 alignment score : 3.76432e-05
In the example , the definite-noun-phrase expression , this transcription factor ( T32 ) , is considered coreferential with the protein mention p65 ( P10 ) . 
NULL ({ }) In ({ 1 }) the ({ 2 }) example ({ 3 }) , ({ 4 }) the ({ 5 }) definite-noun-phrase ({ 6 }) expression ({ 7 }) , ({ 8 }) this ({ 9 }) transcription ({ 10 }) factor ({ 11 }) ( ({ 12 }) T32 ({ 13 }) ) ({ 14 }) , ({ 15 }) is ({ 16 }) considered ({ 17 }) coreferential ({ 18 }) with ({ 19 }) the ({ 20 }) protein ({ 21 }) mention ({ 22 }) p65 ({ 23 }) ( ({ 24 }) P10 ({ 25 }) ) ({ 26 }) . ({ 27 }) 
# Sentence pair (2404) source length 44 target length 42 alignment score : 3.38934e-10
Without knowing this coreference relation , it becomes hard to capture the information written in the phrase , nuclear exclusion of this transcription factor , which is localization of p65 ( out of nucleus ) according to the framework of BioNLP-ST . 
NULL ({ }) Without ({ 1 }) knowing ({ 2 }) this ({ 3 }) coreference ({ 4 }) relation ({ 5 }) , ({ 6 }) it ({ 7 }) becomes ({ 8 }) difficult ({ 9 }) to ({ 10 }) capture ({ 11 }) the ({ 12 }) information ({ 13 }) written ({ 14 }) in ({ 15 }) the ({ 16 }) phrase ({ 17 }) , ({ 18 }) nuclear ({ 19 }) exclusion ({ 20 }) of ({ 21 }) this ({ 22 }) transcription ({ 23 }) factor ({ 24 }) , ({ 25 }) which ({ 26 }) is ({ 27 }) a ({ }) localization ({ 28 }) of ({ 29 }) p65 ({ 30 }) ( ({ 31 }) out ({ 32 }) of ({ 33 }) nucleus ({ 34 }) ) ({ 35 }) , ({ }) according ({ 36 }) to ({ 37 }) the ({ 38 }) framework ({ 39 }) of ({ 40 }) BioNLP-ST ({ 41 }) . ({ 42 }) 
# Sentence pair (2405) source length 15 target length 15 alignment score : 0.00407151
The terminologies used in this paper are similar to those in [ 25 ] . 
NULL ({ }) The ({ 1 }) terminologies ({ 2 }) used ({ 3 }) in ({ 4 }) this ({ 5 }) paper ({ 6 }) are ({ 7 }) similar ({ 8 }) to ({ 9 }) those ({ 10 }) in ({ 11 }) [ ({ 12 }) 25 ({ 13 }) ] ({ 14 }) . ({ 15 }) 
# Sentence pair (2406) source length 28 target length 28 alignment score : 4.75503e-09
A new term is introduced in the BioNLP-ST is antecedent protein , which indicates the protein mention contained in the antecedent expression , e.g. p65 in T28 . 
NULL ({ 4 }) A ({ 1 }) new ({ 2 }) term ({ 3 }) introduced ({ 5 }) in ({ 6 }) the ({ 7 }) BioNLP-ST ({ 8 }) is ({ 9 }) antecedent ({ 10 }) protein ({ 11 }) , ({ 12 }) which ({ 13 }) indicates ({ 14 }) the ({ 15 }) protein ({ 16 }) mention ({ 17 }) contained ({ 18 }) in ({ 19 }) the ({ 20 }) antecedent ({ 21 }) expression ({ 22 }) , ({ 23 }) e.g. ({ 24 }) , ({ }) p65 ({ 25 }) in ({ 26 }) T28 ({ 27 }) . ({ 28 }) 
# Sentence pair (2407) source length 50 target length 47 alignment score : 7.39173e-16
There are other coreferential expressions which are ignored in the context of this COREF task such as this complex and the NF-kappa B transcription factor complex ( Figure 1 ) , since we only focus on the antecedent expressions that contain and point to protein mentions . 
NULL ({ 33 }) There ({ 1 }) are ({ 2 }) other ({ 3 }) coreferential ({ 4 }) expressions ({ 5 }) , ({ }) which ({ 6 }) are ({ 7 }) ignored ({ 8 }) in ({ 9 }) the ({ 10 }) context ({ 11 }) of ({ 12 }) this ({ 13 }) COREF ({ 14 }) task ({ 15 }) , ({ }) such ({ 16 }) as ({ 17 }) : ({ }) this ({ 18 }) complex ({ 19 }) and ({ 20 }) the ({ 21 }) NF-kappa ({ 22 }) B ({ 23 }) transcription ({ 24 }) factor ({ 25 }) complex ({ 26 }) ( ({ 27 }) Figure ({ 28 }) 1 ({ 29 }) ) ({ 30 }) , ({ 31 }) since ({ 32 }) our ({ 34 }) focus ({ 35 }) is ({ }) on ({ 36 }) the ({ 37 }) antecedent ({ 38 }) expressions ({ 39 }) that ({ 40 }) contain ({ 41 }) and ({ 42 }) point ({ 43 }) to ({ 44 }) protein ({ 45 }) mentions ({ 46 }) . ({ 47 }) 
# Sentence pair (2408) source length 35 target length 32 alignment score : 1.88727e-08
The best system in the COREF shared task according to the primary evaluation found 22 .2% of anaphoric protein references at the precision of 73 .3% ( 34 .1% Fscore ) . 
NULL ({ }) The ({ 1 }) best ({ 2 }) system ({ 3 }) in ({ 4 }) the ({ 5 }) COREF ({ 6 }) shared ({ 7 }) task ({ 8 }) , ({ }) according ({ 9 }) to ({ 10 }) the ({ 11 }) primary ({ 12 }) evaluation ({ 13 }) , ({ }) found ({ 14 }) 22 ({ 15 }) .2% ({ 16 }) of ({ 17 }) the ({ }) anaphoric ({ 18 }) protein ({ 19 }) references ({ 20 }) at ({ 21 }) the ({ 22 }) precision ({ 23 }) of ({ 24 }) 73 ({ 25 }) .3% ({ 26 }) ( ({ 27 }) 34 ({ 28 }) .1% ({ 29 }) F-score ({ 30 }) ) ({ 31 }) . ({ 32 }) 
# Sentence pair (2409) source length 34 target length 35 alignment score : 2.06896e-19
This is an encouraging result , since the authors make use of an external coreference resolution tool originally built for the news domain , without much domain adaptation on the main coreference resolution algorithm . 
NULL ({ 2 4 }) The ({ 1 }) results ({ }) are ({ 3 }) promising ({ 5 }) , ({ 6 }) since ({ 7 }) the ({ 8 }) authors ({ 9 }) make ({ 10 }) use ({ 11 }) of ({ 12 }) an ({ 13 }) external ({ 14 }) coreference ({ 15 }) resolution ({ 16 }) tool ({ 17 }) originally ({ 18 }) built ({ 19 }) for ({ 20 }) the ({ 21 }) news ({ 22 }) domain ({ 23 }) , ({ 24 }) without ({ 25 }) much ({ 26 }) domain ({ 27 }) adaptation ({ 28 }) on ({ 29 }) the ({ 30 }) main ({ 31 }) coreference ({ 32 }) resolution ({ 33 }) algorithm ({ 34 }) . ({ 35 }) 
# Sentence pair (2410) source length 20 target length 21 alignment score : 2.41718e-06
Modifications are mostly made to the markable detection component and post processing for the output coreference links [ 11 ] . 
NULL ({ }) Modifications ({ 1 }) are ({ 2 }) mostly ({ 3 }) made ({ 4 }) to ({ 5 }) the ({ 6 }) markable ({ 7 }) detection ({ 8 }) component ({ 9 }) and ({ 10 }) post-processing ({ 11 12 }) for ({ 13 }) the ({ 14 }) output ({ 15 }) coreference ({ 16 }) links ({ 17 }) [ ({ 18 }) 11 ({ 19 }) ] ({ 20 }) . ({ 21 }) 
# Sentence pair (2411) source length 42 target length 44 alignment score : 7.56364e-27
However , the external coreference tool achieves much lower results on biological texts than that on news texts , from 66 .38% down to 49 .65% in MUC-score [ 11 , 27 ] , which is supposed to be caused by domain differences . 
NULL ({ 15 }) However ({ 1 }) , ({ 2 }) the ({ 3 }) external ({ 4 }) coreference ({ 5 }) tool ({ 6 }) " ({ }) s ({ 8 }) performance ({ }) drops ({ 10 }) for ({ 11 }) biological ({ 12 }) texts ({ 13 }) than ({ 14 }) for ({ 16 }) news ({ 17 }) texts ({ 18 }) , ({ 19 }) from ({ 20 }) 66 ({ 21 }) .38% ({ 22 23 }) to ({ 24 }) 49 ({ 7 9 25 }) .65% ({ 26 }) in ({ 27 }) MUC-score ({ 28 }) [ ({ 29 }) 11 ({ 30 }) , ({ 31 }) 27 ({ 32 }) ] ({ 33 }) , ({ 34 }) which ({ 35 }) is ({ 36 }) supposed ({ 37 }) to ({ 38 }) be ({ 39 }) caused ({ 40 }) by ({ 41 }) domain ({ 42 }) differences ({ 43 }) . ({ 44 }) 
# Sentence pair (2412) source length 32 target length 32 alignment score : 4.60177e-09
A detailed analysis on the _nal submissions of the COREF task participants was reported in the organizer 's papers [ 15 , 31 ] , which is summarized in table 2 . 
NULL ({ }) A ({ 1 }) detailed ({ 2 }) analysis ({ 3 }) on ({ 4 }) the ({ 5 }) _nal ({ 6 }) submission ({ 7 }) of ({ 8 }) the ({ 9 }) COREF ({ 10 }) task ({ 11 }) participants ({ 12 }) was ({ 13 }) reported ({ 14 }) in ({ 15 }) the ({ 16 }) organizer ({ 17 }) 's ({ 18 }) papers ({ 19 }) [ ({ 20 }) 15 ({ 21 }) , ({ 22 }) 31 ({ 23 }) ] ({ 24 }) , ({ 25 }) and ({ 26 }) is ({ 27 }) summarized ({ 28 }) in ({ 29 }) table ({ 30 }) 2 ({ 31 }) . ({ 32 }) 
# Sentence pair (2413) source length 57 target length 57 alignment score : 7.73433e-10
In this analysis , the submitted predictions on the test data set of the COREF shared task are analyzed according to four types of anaphoric expressions : DNP for definite noun phrases , RELAT for relative pronouns , PRON for other pronouns including personal , possessive , and demonstrative pronouns , and OTHER for catch-all type . 
NULL ({ }) In ({ 1 }) this ({ 2 }) analysis ({ 3 }) , ({ 4 }) the ({ 5 }) submitted ({ 6 }) predictions ({ 7 }) on ({ 8 }) the ({ 9 }) test ({ 10 }) data ({ 11 }) set ({ 12 }) of ({ 13 }) the ({ 14 }) COREF ({ 15 }) shared ({ 16 }) task ({ 17 }) are ({ 18 }) analyzed ({ 19 }) according ({ 20 }) to ({ 21 }) four ({ 22 }) types ({ 23 }) of ({ 24 }) anaphoric ({ 25 }) expressions ({ 26 }) : ({ 27 }) DNP ({ 28 }) for ({ 29 }) definite ({ 30 }) noun ({ 31 }) phrases ({ 32 }) , ({ 33 }) RELAT ({ 34 }) for ({ 35 }) relative ({ 36 }) pronouns ({ 37 }) , ({ 38 }) PRON ({ 39 }) for ({ 40 }) other ({ 41 }) pronouns ({ 42 }) including ({ 43 }) personal ({ 44 }) , ({ 45 }) possessive ({ 46 }) , ({ 47 }) and ({ 48 }) demonstrative ({ 49 }) pronouns ({ 50 }) , ({ 51 }) and ({ 52 }) OTHER ({ 53 }) for ({ 54 }) catch-all ({ 55 }) type ({ 56 }) . ({ 57 }) 
# Sentence pair (2414) source length 9 target length 8 alignment score : 1.85768e-07
Below are examples of the coreference types . 
NULL ({ }) Examples ({ 1 }) of ({ 4 }) the ({ 5 }) coreference ({ 6 }) types ({ 7 }) are ({ 2 }) outlined ({ 3 }) below ({ 8 }) : ({ }) 
# Sentence pair (2415) source length 34 target length 32 alignment score : 3.15877e-10
- " . . . ,the phosphorylation status of [ TRAF2 ] had significant effects on the ability of [ the protein ] to bind to CD40 , " ( DNP ) 
NULL ({ }) - ({ 1 }) " ({ 2 }) [ ({ }) . ({ 3 }) . ({ 4 }) . ({ 5 }) ] ({ }) the ({ }) phosphorylation ({ 6 7 }) status ({ 8 }) of ({ 9 }) [ ({ 10 }) TRAF2 ({ 11 }) ] ({ 12 }) had ({ 13 }) significant ({ 14 }) effects ({ 15 }) on ({ 16 }) the ({ 17 }) ability ({ 18 }) of ({ 19 }) [ ({ 20 }) the ({ 21 }) protein ({ 22 }) ] ({ 23 }) to ({ 24 }) bind ({ 25 }) to ({ 26 }) CD40 ({ 27 }) , ({ 28 }) " ({ 29 }) ( ({ 30 }) DNP ({ 31 }) ) ({ 32 }) 
# Sentence pair (2416) source length 29 target length 30 alignment score : 1.29796e-12
- " Subnuclear fractionation reveals that there are [ two ATF1 isoforms ] [ which ] appear to differ with respect to DNA binding activity , " ( RELAT ) 
NULL ({ }) - ({ 1 }) " ({ 2 }) Subnuclear ({ 3 }) fractionation ({ 4 }) reveals ({ 5 }) that ({ 6 }) there ({ 7 }) are ({ 8 }) [ ({ 9 }) two ({ 10 }) ATF1 ({ 11 }) isoforms ({ 12 14 }) , ({ }) which ({ 15 }) ] ({ 13 16 }) appear ({ 17 }) to ({ 18 }) differ ({ 19 }) with ({ 20 }) respect ({ 21 }) to ({ 22 }) DNA ({ 23 }) binding ({ 24 }) activity ({ 25 }) , ({ 26 }) " ({ 27 }) ( ({ 28 }) RELAT ({ 29 }) ) ({ 30 }) 
# Sentence pair (2417) source length 25 target length 25 alignment score : 7.64656e-05
- " This ability of [ CIITA ] to facilitate promoter occupation is undissociable from [ its ] transactivation potential , " ( PRON ) 
NULL ({ }) - ({ 1 }) " ({ 2 }) This ({ 3 }) ability ({ 4 }) of ({ 5 }) [ ({ 6 }) CIITA ({ 7 }) ] ({ 8 }) to ({ 9 }) facilitate ({ 10 }) promoter ({ 11 }) occupation ({ 12 }) is ({ 13 }) undissociable ({ 14 }) from ({ 15 }) [ ({ 16 }) its ({ 17 }) ] ({ 18 }) transactivation ({ 19 }) potential ({ 20 }) , ({ 21 }) " ({ 22 }) ( ({ 23 }) PRON ({ 24 }) ) ({ 25 }) 
# Sentence pair (2418) source length 64 target length 57 alignment score : 3.78241e-37
The analysis results in also showed that the best resolution results for definite noun phrases ( the DNP type ) , and several pronouns of the PRON type are 27 .5% F-score and 10 .1 F-score respectively , which are far less than that for relative pronoun ( the RELAT type ) 66 .2 % F-score . 
NULL ({ 4 40 }) An ({ 1 }) analysis ({ 2 }) of ({ }) the ({ }) results ({ 3 }) indicated ({ 5 6 }) that ({ 7 }) the ({ 8 }) best ({ 9 }) resolution ({ 10 }) results ({ 11 }) for ({ 12 }) definite ({ 13 }) noun ({ 14 }) phrases ({ 15 }) ( ({ 16 }) the ({ 17 }) DNP ({ 18 }) type ({ 19 }) ) ({ 20 }) , ({ 21 }) and ({ 22 }) several ({ 23 }) pronouns ({ 24 }) of ({ 25 }) the ({ 26 }) PRON ({ 27 }) type ({ 28 }) was ({ 29 }) 27 ({ 30 }) .5% ({ 31 }) F-score ({ 32 }) and ({ 33 }) 10 ({ 34 }) .1 ({ 35 }) F-score ({ 36 }) , ({ }) respectively ({ 37 }) ; ({ }) the ({ }) scores ({ }) were ({ }) much ({ }) lower ({ 42 }) than ({ 43 }) the ({ }) F-score ({ 44 }) for ({ 45 }) relative ({ 46 }) pronouns ({ 47 }) ( ({ 48 }) the ({ 49 }) RELAT ({ 50 }) type ({ 51 }) ) ({ 52 }) , ({ 38 }) which ({ 39 }) yielded ({ 41 }) a ({ }) 66 ({ 53 }) .2 ({ 54 }) % ({ 55 }) F-score ({ 56 }) . ({ 57 }) 
# Sentence pair (2419) source length 22 target length 22 alignment score : 6.90281e-15
Thus , it can be inferred that definite noun phrases and pronouns are more difficult to be resolved than relative pronouns . 
NULL ({ }) Thus ({ 1 }) , ({ 2 }) it ({ 3 }) can ({ 4 }) be ({ 5 }) inferred ({ 6 18 }) that ({ 7 }) it ({ 17 }) is ({ }) more ({ 14 }) difficult ({ 15 }) to ({ 16 }) resolve ({ 13 }) definite ({ 8 }) noun ({ 9 }) phrases ({ 10 }) and ({ 11 }) pronouns ({ 12 }) than ({ 19 }) relative ({ 20 }) pronouns ({ 21 }) . ({ 22 }) 
# Sentence pair (2420) source length 21 target length 22 alignment score : 6.61825e-09
The top four official results of the COREF shared task are shown again in the top four rows of Table 2 . 
NULL ({ }) The ({ 1 }) top ({ 2 }) four ({ 3 }) official ({ 4 }) results ({ 5 }) of ({ 6 }) the ({ 7 }) COREF ({ 8 }) shared ({ 9 }) task ({ 10 }) are ({ 11 }) presented ({ 12 13 }) in ({ 14 }) the ({ 15 }) top ({ 16 }) four ({ 17 }) rows ({ 18 }) of ({ 19 }) Table ({ 20 }) 2 ({ 21 }) . ({ 22 }) 
# Sentence pair (2421) source length 50 target length 44 alignment score : 2.6642e-22
In this paper , we compare the contributions of different features in coreference resolution , two simple types of domain-portable information : discourse preference and number-agreement , and domain-specific information which can be considered as more difficult to be transferred across different domains . 
NULL ({ 28 }) In ({ 1 }) this ({ 2 }) paper ({ 3 }) , ({ 4 }) we ({ 5 }) compare ({ 6 }) the ({ 7 }) contributions ({ 8 }) of ({ 9 }) different ({ 10 }) features ({ 11 }) in ({ 12 }) coreference ({ 13 }) resolution ({ 14 }) ; ({ 15 }) two ({ 16 }) simple ({ 17 }) types ({ 18 }) of ({ 19 }) domain-portable ({ 20 }) information ({ 21 }) : ({ 22 }) discourse ({ 23 }) preference ({ 24 }) and ({ 25 }) number-agreement ({ 26 }) , ({ 27 }) is ({ }) compared ({ }) , ({ }) as ({ 35 }) well ({ 32 }) as ({ }) domain-specific ({ 29 }) information ({ 30 }) , ({ }) which ({ 31 }) is ({ }) considered ({ 34 }) to ({ }) be ({ 33 }) more ({ 36 }) difficult ({ 37 }) to ({ 38 }) be ({ 39 }) transferred ({ 40 }) across ({ 41 }) different ({ 42 }) domains ({ 43 }) . ({ 44 }) 
# Sentence pair (2422) source length 26 target length 25 alignment score : 1.17793e-05
We implemented a protein coreference system that makes use of syntactic information from parser output , and protein-indicated information encoded in rule-based semantic classification . 
NULL ({ }) We ({ 1 }) implemented ({ 2 }) a ({ 3 }) protein ({ 4 }) coreference ({ 5 }) system ({ 6 }) that ({ 7 }) makes ({ 8 }) use ({ 9 }) of ({ 10 }) syntactic ({ 11 }) information ({ 12 }) from ({ 13 }) the ({ }) parser ({ 14 }) output ({ 15 }) , ({ 16 }) and ({ 17 }) protein-indicated ({ 18 }) information ({ 19 }) encoded ({ 20 }) in ({ 21 }) rule-based ({ 22 }) semantic ({ 23 }) classification ({ 24 }) . ({ 25 }) 
# Sentence pair (2423) source length 35 target length 36 alignment score : 1.12977e-13
Experimental results showed that domain specific semantic information is important for coreference resolution , and that simple semantic classification using semantic features helped our system to outperform the best reported result in the shared task . 
NULL ({ }) Experimental ({ 1 }) results ({ 2 }) showed ({ 3 }) that ({ 4 }) domain-specific ({ 5 6 }) semantic ({ 7 }) information ({ 8 }) is ({ 9 }) important ({ 10 }) for ({ 11 }) coreference ({ 12 }) resolution ({ 13 }) , ({ 14 }) and ({ 15 }) that ({ 16 }) simple ({ 17 }) semantic ({ 18 }) classification ({ 19 }) using ({ 20 }) semantic ({ 21 }) features ({ 22 }) helped ({ 23 }) our ({ 24 }) system ({ 25 }) to ({ 26 }) outperform ({ 27 }) the ({ 28 }) best-reported ({ 29 }) system ({ 30 }) results ({ 31 }) in ({ 32 }) the ({ 33 }) shared ({ 34 }) task ({ 35 }) . ({ 36 }) 
# Sentence pair (2424) source length 25 target length 27 alignment score : 2.21878e-13
As we needed to get an insight into the problem , we took a rule-based approach , analyzing the training data of BioNLP-ST 2011 Coref task . 
NULL ({ 2 }) In ({ 1 }) order ({ 3 }) to ({ 4 }) acquire ({ 5 }) insight ({ 6 7 }) into ({ 8 }) the ({ 9 }) problem ({ 10 }) , ({ 11 }) we ({ 12 }) took ({ 13 }) a ({ 14 }) rule-based ({ 15 }) approach ({ 16 }) , ({ 17 }) analyzing ({ 18 }) the ({ 19 }) training ({ 20 }) data ({ 21 }) of ({ 22 }) BioNLP-ST ({ 23 }) 2011 ({ 24 }) Coref ({ 25 }) task ({ 26 }) . ({ 27 }) 
# Sentence pair (2425) source length 28 target length 29 alignment score : 1.02934e-11
The performance of the system evaluated on the official test data set of the COREF task shows a significant improvement over the official winning system of the task . 
NULL ({ 12 }) The ({ 1 }) performance ({ 2 }) of ({ 3 }) the ({ 4 }) system ({ 5 }) evaluated ({ 6 }) on ({ 7 }) the ({ 8 }) official ({ 9 }) test ({ 10 }) dataset ({ 11 }) of ({ 13 }) the ({ 14 }) COREF ({ 15 }) task ({ 16 }) shows ({ 17 }) a ({ 18 }) significant ({ 19 }) improvement ({ 20 }) over ({ 21 }) the ({ 22 }) official ({ 23 }) winning ({ 24 }) system ({ 25 }) of ({ 26 }) the ({ 27 }) task ({ 28 }) . ({ 29 }) 
# Sentence pair (2426) source length 13 target length 13 alignment score : 0.00256376
This section presents the overview and the performance evaluation of our system . 
NULL ({ }) This ({ 1 }) section ({ 2 }) presents ({ 3 }) the ({ 4 }) overview ({ 5 }) and ({ 6 }) the ({ 7 }) performance ({ 8 }) evaluation ({ 9 }) of ({ 10 }) our ({ 11 }) system ({ 12 }) . ({ 13 }) 
# Sentence pair (2427) source length 32 target length 32 alignment score : 2.94359e-06
Figure 2 shows the overall design of the system , which includes five main components : preprocessing , markable detection , anaphor selection , antecedent candidate selection , and antecedent prediction . 
NULL ({ }) Figure ({ 1 }) 2 ({ 2 }) shows ({ 3 }) the ({ 4 }) overall ({ 5 }) design ({ 6 }) of ({ 7 }) the ({ 8 }) system ({ 9 }) , ({ 10 }) which ({ 11 }) includes ({ 12 }) five ({ 13 }) main ({ 14 }) components ({ 15 }) : ({ 16 }) preprocessing ({ 17 }) , ({ 18 }) markable ({ 19 }) detection ({ 20 }) , ({ 21 }) anaphor ({ 22 }) selection ({ 23 }) , ({ 24 }) antecedent ({ 25 }) candidate ({ 26 }) selection ({ 27 }) , ({ 28 }) and ({ 29 }) antecedent ({ 30 }) prediction ({ 31 }) . ({ 32 }) 
# Sentence pair (2428) source length 9 target length 10 alignment score : 6.17911e-06
Processing of each component is briefly described as below . 
NULL ({ }) Processing ({ 1 }) of ({ 2 }) each ({ 3 }) component ({ 4 }) is ({ 5 }) briefly ({ 6 }) described ({ 7 }) below ({ 8 9 }) . ({ 10 }) 
# Sentence pair (2429) source length 12 target length 12 alignment score : 0.00936588
More details of implementation can be found in the method section . 
NULL ({ }) More ({ 1 }) details ({ 2 }) of ({ 3 }) implementation ({ 4 }) can ({ 5 }) be ({ 6 }) found ({ 7 }) in ({ 8 }) the ({ 9 }) method ({ 10 }) section ({ 11 }) . ({ 12 }) 
# Sentence pair (2430) source length 21 target length 21 alignment score : 0.000349511
Step 0 - Preprocessing : The input text is preprocessed using NLP tools for sentence segmentation , and syntactic parsing . 
NULL ({ }) Step ({ 1 }) 0 ({ 2 }) - ({ 3 }) Preprocessing ({ 4 }) : ({ 5 }) The ({ 6 }) input ({ 7 }) text ({ 8 }) is ({ 9 }) preprocessed ({ 10 }) using ({ 11 }) NLP ({ 12 }) tools ({ 13 }) for ({ 14 }) sentence ({ 15 }) segmentation ({ 16 }) , ({ 17 }) and ({ 18 }) syntactic ({ 19 }) parsing ({ 20 }) . ({ 21 }) 
# Sentence pair (2431) source length 21 target length 17 alignment score : 1.44018e-14
We used Genia Sentence Splitter and Enju Parser [ 15 ] for the purposes , respectively . 
NULL ({ 13 }) We ({ 1 }) used ({ 2 }) the ({ }) Genia ({ 3 }) Sentence ({ 4 }) Splitter ({ 5 }) and ({ 6 }) Enju ({ 7 }) Parser ({ 8 }) [ ({ 9 }) 15 ({ 10 }) ] ({ 11 }) for ({ 12 }) sentence ({ 14 }) segmentation ({ }) and ({ }) syntactic ({ }) parsing ({ }) , ({ 15 }) respectively ({ 16 }) . ({ 17 }) 
# Sentence pair (2432) source length 52 target length 44 alignment score : 3.12876e-17
( Enju parser comes with a default tokenizer and part-of-speech tagger for biological text . ) Row 1 in the example Table 1 shows three sentences outputted from Genia Sentence Splitter , and noun phrases outputted from Enju Parser for the sentence S3 . 
NULL ({ }) ( ({ 1 }) Enju ({ 2 }) parser ({ 3 }) comes ({ 4 }) with ({ 5 }) a ({ 6 }) default ({ 7 }) tokenizer ({ 8 }) and ({ 9 }) part-of-speech ({ 10 }) tagger ({ 11 }) for ({ 12 }) biological ({ 13 }) text ({ 14 }) . ({ 15 }) ) ({ 16 }) Row ({ 17 }) 1 ({ 18 }) in ({ 19 }) the ({ 20 }) example ({ 21 }) of ({ }) Table ({ 22 }) 1 ({ 23 }) shows ({ 24 }) three ({ 25 }) sentences ({ 26 }) as ({ }) the ({ }) output ({ 27 }) from ({ 28 }) the ({ }) Genia ({ 29 }) Sentence ({ 30 }) Splitter ({ 31 }) , ({ 32 }) and ({ 33 }) noun ({ 34 }) phrases ({ 35 }) as ({ }) the ({ }) output ({ 36 }) from ({ 37 }) the ({ }) Enju ({ 38 }) Parser ({ 39 }) for ({ 40 }) the ({ 41 }) sentence ({ 42 }) , ({ }) S3 ({ 43 }) . ({ 44 }) 
# Sentence pair (2433) source length 18 target length 19 alignment score : 1.29377e-07
Due to the limit of space , only a part of the phrases are shown in the table . 
NULL ({ 5 }) Due ({ 1 }) to ({ 2 }) the ({ 3 }) limited ({ 4 }) space ({ 6 }) , ({ 7 }) only ({ 8 }) a ({ 9 }) part ({ 10 }) of ({ 11 }) the ({ 12 }) phrases ({ 13 }) are ({ 14 }) shown ({ 15 }) in ({ 16 }) the ({ 17 }) table ({ 18 }) . ({ 19 }) 
# Sentence pair (2434) source length 14 target length 14 alignment score : 0.000325406
The full parse tree of this sentence is separately shown in Figure 3 . 
NULL ({ }) The ({ 1 }) full ({ 2 }) parse ({ 3 }) tree ({ 4 }) for ({ 5 }) this ({ 6 }) sentence ({ 7 }) is ({ 8 }) separately ({ 9 }) shown ({ 10 }) in ({ 11 }) Figure ({ 12 }) 3 ({ 13 }) . ({ 14 }) 
# Sentence pair (2435) source length 28 target length 26 alignment score : 2.55711e-11
Step 1 - Markable detection : collects text chunks that are candidate coreferential expressions , which are also called markables following the jargon of MUC-7 . 
NULL ({ }) Step ({ 1 }) 1 ({ 2 }) - ({ 3 }) Markable ({ 4 }) detection ({ 5 }) : ({ 6 }) Text ({ 7 }) chunks ({ 8 9 }) that ({ 10 }) are ({ 11 }) candidate ({ 12 }) coreferential ({ 13 }) expressions ({ 14 }) , ({ 15 }) which ({ 16 }) are ({ 17 }) also ({ 18 }) called ({ 19 }) markables ({ 20 }) following ({ 21 }) the ({ 22 }) jargon ({ 23 }) of ({ 24 }) MUC-7 ({ 25 }) , ({ }) are ({ }) collected ({ }) . ({ 26 }) 
# Sentence pair (2436) source length 35 target length 30 alignment score : 9.4768e-16
For the set of markables , noun phrases , which do not include subordinate clause , are collected as analyzed by a syntactic parser , Enju in our case . 
NULL ({ 25 }) For ({ 1 }) the ({ 2 }) set ({ 3 }) of ({ 4 }) markables ({ 5 }) , ({ 6 }) noun ({ 7 }) phrases ({ 8 }) , ({ 9 }) which ({ 10 }) do ({ 11 }) not ({ 12 }) include ({ 13 }) a ({ }) subordinate ({ 14 }) clause ({ 15 }) , ({ 16 }) are ({ 17 }) collected ({ 18 }) as ({ 19 }) they ({ }) are ({ }) analyzed ({ 20 }) by ({ 21 }) a ({ 22 }) syntactic ({ 23 }) parser ({ 24 }) ( ({ }) in ({ 27 }) our ({ 28 }) case ({ 29 }) , ({ }) Enju ({ 26 }) ) ({ }) . ({ 30 }) 
# Sentence pair (2437) source length 7 target length 7 alignment score : 0.0887149
Pronouns are also collected as markables . 
NULL ({ }) Pronouns ({ 1 }) are ({ 2 }) also ({ 3 }) collected ({ 4 }) as ({ 5 }) markables ({ 6 }) . ({ 7 }) 
# Sentence pair (2438) source length 29 target length 28 alignment score : 5.68376e-07
Then , for chunks that share the same head word , which is normally the main noun of a noun phrase , only the longest is taken . 
NULL ({ }) Then ({ 1 }) , ({ 2 }) for ({ 3 }) chunks ({ 4 }) that ({ 5 }) share ({ 6 }) the ({ 7 }) same ({ 8 }) head ({ 9 }) word ({ 10 }) , ({ 11 }) which ({ 12 }) is ({ 13 }) normally ({ 14 }) the ({ 15 }) main ({ 16 }) noun ({ 17 }) of ({ 18 }) a ({ 19 }) noun ({ 20 }) phrase ({ 21 }) , ({ 22 }) only ({ 23 }) the ({ 24 }) longest ({ 25 }) chunk ({ }) is ({ 26 }) taken ({ 27 }) . ({ 28 }) 
# Sentence pair (2439) source length 26 target length 26 alignment score : 2.95247e-10
Since the Enju parser output such head-word information for every noun phrase , we make use of this information for our processing without any modification . 
NULL ({ }) Since ({ 1 }) the ({ 2 }) Enju ({ 3 }) parser ({ 4 }) outputs ({ 5 }) head-word ({ 6 7 }) information ({ 8 }) for ({ 9 }) every ({ 10 }) noun ({ 11 }) phrase ({ 12 }) , ({ 13 }) we ({ 14 }) make ({ 15 }) use ({ 16 }) of ({ 17 }) this ({ 18 }) information ({ 19 }) for ({ 20 }) our ({ 21 }) processing ({ 22 }) , ({ }) without ({ 23 }) any ({ 24 }) modification ({ 25 }) . ({ 26 }) 
# Sentence pair (2440) source length 17 target length 17 alignment score : 0.00264852
The third row of Table 1 shows the result of markable detection for the sample text . 
NULL ({ }) The ({ 1 }) third ({ 2 }) row ({ 3 }) of ({ 4 }) Table ({ 5 }) 1 ({ 6 }) shows ({ 7 }) the ({ 8 }) result ({ 9 }) of ({ 10 }) markable ({ 11 }) detection ({ 12 }) for ({ 13 }) the ({ 14 }) sample ({ 15 }) text ({ 16 }) . ({ 17 }) 
# Sentence pair (2441) source length 64 target length 60 alignment score : 4.53721e-20
In the sentence S3 , three noun phrases recognized by the NX and NP tags of Enju output , role , role for c-Myc in apoptosis , and this role for c-Myc in apoptosis ( Step 0 results ) share the same head word role , thus only the longest one this role for c-Myc in apoptosis is selected . 
NULL ({ }) In ({ 1 }) the ({ 2 }) sentence ({ 3 }) S3 ({ 4 }) , ({ 5 }) three ({ 6 }) noun ({ 7 }) phrases ({ 8 }) recognized ({ 9 }) by ({ 10 }) the ({ 11 }) NX ({ 12 }) and ({ 13 }) NP ({ 14 }) tags ({ 15 }) of ({ 16 }) the ({ }) Enju ({ 17 }) output ({ 18 }) , ({ 19 }) role ({ 20 }) , ({ 21 }) role ({ 22 }) for ({ 23 }) c-Myc ({ 24 }) in ({ 25 }) apoptosis ({ 26 }) , ({ 27 }) and ({ 28 }) this ({ 29 }) role ({ 30 }) for ({ 31 }) c-Myc ({ 32 }) in ({ 33 }) apoptosis ({ 34 }) ( ({ 35 }) Step ({ 36 }) 0 ({ 37 }) results ({ 38 }) ) ({ 39 }) share ({ 40 }) the ({ 41 }) same ({ 42 }) head-word ({ 43 44 }) role ({ 45 }) ; ({ 46 }) thus ({ 47 }) , ({ }) only ({ 48 }) the ({ 49 }) longest ({ 50 }) noun ({ 51 }) phrase ({ }) , ({ }) this ({ 52 }) role ({ 53 }) for ({ 54 }) c-Myc ({ 55 }) in ({ 56 }) apoptosis ({ 57 }) , ({ }) is ({ 58 }) selected ({ 59 }) . ({ 60 }) 
# Sentence pair (2442) source length 10 target length 10 alignment score : 0.018665
However , between studies and studies using . . . 
NULL ({ }) However ({ 1 }) , ({ 2 }) between ({ 3 }) studies ({ 4 }) and ({ 5 }) studies ({ 6 }) using ({ 7 }) . ({ 8 }) . ({ 9 }) . ({ 10 }) 
# Sentence pair (2443) source length 16 target length 16 alignment score : 0.00331258
apoptosis , the former chunk is selected , since the latter contains a subordinate clause . 
NULL ({ }) apoptosis ({ 1 }) , ({ 2 }) the ({ 3 }) former ({ 4 }) chunk ({ 5 }) is ({ 6 }) selected ({ 7 }) , ({ 8 }) since ({ 9 }) the ({ 10 }) latter ({ 11 }) contains ({ 12 }) a ({ 13 }) subordinate ({ 14 }) clause ({ 15 }) . ({ 16 }) 
# Sentence pair (2444) source length 39 target length 38 alignment score : 1.1762e-18
Step 2 - Anaphor selection : determines candidate anaphoric expressions , which are basically pronouns and definite noun phrases ( a minority of anaphors are indefinite noun phrases or entity names , which act as appositions . ) 
NULL ({ 38 }) Step ({ 1 }) 2 ({ 2 }) - ({ 3 }) Anaphor ({ 4 }) selection ({ 5 }) : ({ 6 }) Candidate ({ 7 8 }) anaphoric ({ 9 }) expressions ({ 10 }) , ({ 11 }) which ({ 12 }) are ({ 13 }) basically ({ 14 }) pronouns ({ 15 }) and ({ 16 }) definite ({ 17 }) noun ({ 18 }) phrases ({ 19 }) , ({ }) are ({ }) determined ({ 20 }) . ({ }) A ({ 21 }) minority ({ 22 }) of ({ 23 }) anaphors ({ 24 }) are ({ 25 }) indefinite ({ 26 }) noun ({ 27 }) phrases ({ 28 }) or ({ 29 }) entity ({ 30 }) names ({ 31 }) , ({ 32 }) which ({ 33 }) act ({ 34 }) as ({ 35 }) appositions ({ 36 }) . ({ 37 }) 
# Sentence pair (2445) source length 17 target length 17 alignment score : 0.00302223
The system first considers all pronouns and definite noun phrases in the markable set as anaphors . 
NULL ({ }) The ({ 1 }) system ({ 2 }) first ({ 3 }) considers ({ 4 }) all ({ 5 }) pronouns ({ 6 }) and ({ 7 }) definite ({ 8 }) noun ({ 9 }) phrases ({ 10 }) in ({ 11 }) the ({ 12 }) markable ({ 13 }) set ({ 14 }) as ({ 15 }) anaphors ({ 16 }) . ({ 17 }) 
# Sentence pair (2446) source length 18 target length 18 alignment score : 0.00102801
Then , several filters are applied to remove anaphors that are not relevant to the task definition . 
NULL ({ }) Then ({ 1 }) , ({ 2 }) several ({ 3 }) filters ({ 4 }) are ({ 5 }) applied ({ 6 }) to ({ 7 }) remove ({ 8 }) anaphors ({ 9 }) that ({ 10 }) are ({ 11 }) not ({ 12 }) relevant ({ 13 }) to ({ 14 }) the ({ 15 }) task ({ 16 }) definition ({ 17 }) . ({ 18 }) 
# Sentence pair (2447) source length 11 target length 12 alignment score : 1.26252e-06
We implemented two types of filters : syntactic and semantic filters . 
NULL ({ }) We ({ 1 }) implemented ({ 2 }) two ({ 3 }) types ({ 4 }) of ({ 5 }) filters ({ 6 11 }) : ({ 7 }) syntactic ({ 8 }) and ({ 9 }) semantic ({ 10 }) . ({ 12 }) 
# Sentence pair (2448) source length 28 target length 27 alignment score : 2.16482e-09
Syntactic filters are used to filter out pleonastic its , or pronouns such as he , she , which are not expected to refer to proteins . 
NULL ({ }) Syntactic ({ 1 }) filters ({ 2 }) are ({ 3 }) used ({ 4 }) to ({ 5 }) filter ({ 6 }) out ({ 7 }) pleonastic ({ 8 }) its ({ 9 }) , ({ 10 }) or ({ 11 }) pronouns ({ 12 }) , ({ }) like ({ 13 }) : ({ 14 }) he ({ 15 }) , ({ 16 }) she ({ 17 }) , ({ 18 }) which ({ 19 }) are ({ 20 }) not ({ 21 }) expected ({ 22 }) to ({ 23 }) refer ({ 24 }) to ({ 25 }) proteins ({ 26 }) . ({ 27 }) 
# Sentence pair (2449) source length 24 target length 26 alignment score : 1.24179e-13
Moreover , because the focus of our task is protein references , semantic filters can be used to filter out non-protein anaphors at this stage . 
NULL ({ 4 6 }) Moreover ({ 1 }) , ({ 2 }) because ({ 3 }) our ({ 7 }) task ({ 8 }) focuses ({ 5 }) on ({ 9 }) protein ({ 10 }) references ({ 11 }) , ({ 12 }) semantic ({ 13 }) filters ({ 14 }) can ({ 15 }) be ({ 16 }) used ({ 17 }) to ({ 18 }) filter ({ 19 }) out ({ 20 }) non-protein ({ 21 }) anaphors ({ 22 }) at ({ 23 }) this ({ 24 }) stage ({ 25 }) . ({ 26 }) 
# Sentence pair (2450) source length 35 target length 35 alignment score : 1.15727e-14
In practice , for definite noun phrase type of anaphors , this is done using a list of possible head words of protein references , and for pronouns , their context words are used . 
NULL ({ 25 }) In ({ 1 }) practice ({ 2 }) , ({ 3 }) for ({ 4 }) definite ({ 5 }) noun ({ 6 }) phrase ({ 7 }) type ({ 8 }) of ({ 9 }) anaphors ({ 10 }) , ({ 11 }) this ({ 12 }) is ({ 13 }) accomplished ({ 14 }) , ({ }) by ({ }) using ({ 15 }) a ({ 16 }) list ({ 17 }) of ({ 18 }) possible ({ 19 }) head-words ({ 20 21 }) of ({ 22 }) protein ({ 23 }) references ({ 24 }) ; ({ 26 }) for ({ 27 }) pronouns ({ 28 }) , ({ 29 }) their ({ 30 }) context ({ 31 }) words ({ 32 }) are ({ 33 }) used ({ 34 }) . ({ 35 }) 
# Sentence pair (2451) source length 13 target length 13 alignment score : 6.83858e-05
More details of the methods can be found in the following section . 
NULL ({ }) More ({ 1 }) details ({ 2 }) of ({ 3 }) these ({ 4 }) methods ({ 5 }) can ({ 6 }) be ({ 7 }) found ({ 8 }) in ({ 9 }) the ({ 10 }) following ({ 11 }) section ({ 12 }) . ({ 13 }) 
# Sentence pair (2452) source length 22 target length 22 alignment score : 0.00030259
Step 3 - Antecedent candidate selection : For each anaphor , this component collects the antecedent candidates from the preceding expressions . 
NULL ({ }) Step ({ 1 }) 3 ({ 2 }) - ({ 3 }) Antecedent ({ 4 }) candidate ({ 5 }) selection ({ 6 }) : ({ 7 }) For ({ 8 }) each ({ 9 }) anaphor ({ 10 }) , ({ 11 }) this ({ 12 }) component ({ 13 }) collects ({ 14 }) the ({ 15 }) antecedent ({ 16 }) candidates ({ 17 }) from ({ 18 }) the ({ 19 }) preceding ({ 20 }) expressions ({ 21 }) . ({ 22 }) 
# Sentence pair (2453) source length 19 target length 18 alignment score : 0.00011183
One of the candidates will become the response antecedent as a result of the antecedent prediction step . 
NULL ({ }) One ({ 1 }) of ({ 2 }) the ({ 3 }) candidates ({ 4 }) will ({ 5 }) become ({ 6 }) the ({ 7 }) response ({ 8 }) antecedent ({ 9 }) , ({ }) as ({ 10 }) a ({ 11 }) result ({ 12 }) of ({ 13 }) the ({ 14 }) antecedent ({ 15 }) prediction ({ 16 }) step ({ 17 }) . ({ 18 }) 
# Sentence pair (2454) source length 29 target length 28 alignment score : 2.02596e-08
In theory , all expressions in the set of markables can become antecedent candidates , however too much candidates makes it difficult to achieve correct antecedent prediction . 
NULL ({ }) In ({ 1 }) theory ({ 2 }) , ({ 3 }) all ({ 4 }) expressions ({ 5 }) in ({ 6 }) the ({ 7 }) set ({ 8 }) of ({ 9 }) markables ({ 10 }) can ({ 11 }) become ({ 12 }) antecedent ({ 13 }) candidates ({ 14 }) ; ({ 15 }) however ({ 16 }) , ({ }) too ({ 17 }) many ({ 18 }) candidates ({ 19 }) makes ({ 20 }) it ({ 21 }) difficult ({ 22 }) to ({ 23 }) achieve ({ 24 }) correct ({ 25 }) antecedent ({ 26 }) prediction ({ 27 }) . ({ 28 }) 
# Sentence pair (2455) source length 18 target length 18 alignment score : 0.000387581
Moreover , we also filter out candidates that violate syntactic or semantic constraints raised by the anaphor . 
NULL ({ }) Moreover ({ 1 }) , ({ 2 }) we ({ 3 }) also ({ 4 }) filter ({ 5 }) out ({ 6 }) candidates ({ 7 }) that ({ 8 }) violate ({ 9 }) syntactic ({ 10 }) or ({ 11 }) semantic ({ 12 }) constraints ({ 13 }) raised ({ 14 }) by ({ 15 }) the ({ 16 }) anaphor ({ 17 }) . ({ 18 }) 
# Sentence pair (2456) source length 22 target length 21 alignment score : 1.86111e-05
In our system , this is done by using a window size in sentences , together with several syntactic filters . 
NULL ({ }) In ({ 1 }) our ({ 2 }) system ({ 3 }) , ({ 4 }) this ({ 5 }) is ({ 6 }) done ({ 7 }) by ({ 8 }) using ({ 9 }) a ({ 10 }) particular ({ }) window ({ 11 }) size ({ 12 }) in ({ 13 }) sentences ({ 14 }) , ({ 15 }) together ({ 16 }) with ({ 17 }) several ({ 18 }) syntactic ({ 19 }) filters ({ 20 }) . ({ 21 }) 
# Sentence pair (2457) source length 17 target length 17 alignment score : 0.003263
One of the syntactic filters is based on syntactic relations among phrases outputted from the parser . 
NULL ({ }) One ({ 1 }) of ({ 2 }) the ({ 3 }) syntactic ({ 4 }) filters ({ 5 }) is ({ 6 }) based ({ 7 }) on ({ 8 }) syntactic ({ 9 }) relations ({ 10 }) among ({ 11 }) phrases ({ 12 }) outputted ({ 13 }) from ({ 14 }) the ({ 15 }) parser ({ 16 }) . ({ 17 }) 
# Sentence pair (2458) source length 32 target length 31 alignment score : 7.13661e-07
The idea behind this is that some types of syntactic relations imply the impossibility of coreference relations between its argument noun phrases and the inclusive expressions of these noun phrases . 
NULL ({ }) The ({ 1 }) idea ({ 2 }) behind ({ 3 }) this ({ 4 }) filter ({ }) is ({ 5 }) that ({ 6 }) some ({ 7 }) types ({ 8 }) of ({ 9 }) syntactic ({ 10 }) relations ({ 11 }) imply ({ 12 }) the ({ 13 }) impossibility ({ 14 }) of ({ 15 }) coreference ({ 16 }) relations ({ 17 }) between ({ 18 }) its ({ 19 }) argument ({ 20 }) noun ({ 21 }) phrases ({ 22 }) and ({ 23 }) the ({ 24 }) inclusive ({ 25 }) expressions ({ 26 }) of ({ 27 }) these ({ 28 }) noun ({ 29 }) phrases ({ 30 }) . ({ 31 }) 
# Sentence pair (2459) source length 35 target length 35 alignment score : 5.78721e-10
For example , the two expressions dominant negative form and its in our example in Table 1 , can not be coreferential with each other , since they are connected via the preposition of . 
NULL ({ }) For ({ 1 }) example ({ 2 }) , ({ 3 }) the ({ 4 }) two ({ 5 }) expressions ({ 6 }) : ({ }) dominant ({ 7 }) negative ({ 8 }) form ({ 9 }) and ({ 10 }) its ({ 11 }) in ({ 12 }) our ({ 13 }) example ({ 14 }) in ({ 15 }) Table ({ 16 }) 1 ({ 17 }) , ({ 18 }) cannot ({ 19 20 }) be ({ 21 }) coreferential ({ 22 }) with ({ 23 }) each ({ 24 }) other ({ 25 }) , ({ 26 }) since ({ 27 }) they ({ 28 }) are ({ 29 }) connected ({ 30 }) via ({ 31 }) the ({ 32 }) preposition ({ 33 }) of ({ 34 }) . ({ 35 }) 
# Sentence pair (2460) source length 17 target length 17 alignment score : 1.37015e-05
Another syntactic filter removes pronouns which are not in the same pronoun family as the anaphor . 
NULL ({ }) Another ({ 1 }) syntactic ({ 2 }) filter ({ 3 }) removes ({ 4 }) pronouns ({ 5 }) that ({ 6 }) are ({ 7 }) not ({ 8 }) in ({ 9 }) the ({ 10 }) same ({ 11 }) pronoun ({ 12 }) family ({ 13 }) as ({ 14 }) the ({ 15 }) anaphor ({ 16 }) . ({ 17 }) 
# Sentence pair (2461) source length 13 target length 13 alignment score : 0.00479081
This results in the disappearance of this in candidate antecedents of its . 
NULL ({ }) This ({ 1 }) results ({ 2 }) in ({ 3 }) the ({ 4 }) disappearance ({ 5 }) of ({ 6 }) this ({ 7 }) in ({ 8 }) candidate ({ 9 }) antecedents ({ 10 }) of ({ 11 }) its ({ 12 }) . ({ 13 }) 
# Sentence pair (2462) source length 15 target length 15 alignment score : 0.00211515
Pronouns in the same family as its are its , it , and itself . 
NULL ({ }) Pronouns ({ 1 }) in ({ 2 }) the ({ 3 }) same ({ 4 }) family ({ 5 }) as ({ 6 }) its ({ 7 }) are ({ 8 }) its ({ 9 }) , ({ 10 }) it ({ 11 }) , ({ 12 }) and ({ 13 }) itself ({ 14 }) . ({ 15 }) 
# Sentence pair (2463) source length 25 target length 23 alignment score : 1.53408e-18
Step 4 - Antecedent predicion : selects the best candidate in the antecedent candidate set , and forms a response coreference link . 
NULL ({ 8 }) Step ({ 1 }) 4 ({ 2 }) - ({ 3 }) Antecedent ({ 4 }) prediction ({ 5 }) : ({ 6 }) The ({ 7 }) best ({ 9 }) candidate ({ 10 }) in ({ 11 }) the ({ 12 }) antecedent ({ 13 }) candidate ({ 14 }) set ({ 15 }) is ({ }) selected ({ }) , ({ 16 }) and ({ 17 }) a ({ 19 }) response ({ 20 }) coreference ({ 21 }) link ({ 22 }) is ({ }) formed ({ 18 }) . ({ 23 }) 
# Sentence pair (2464) source length 12 target length 12 alignment score : 0.00795655
Antecedent candidates are compared with one another using a comparison procedure . 
NULL ({ }) Antecedent ({ 1 }) candidates ({ 2 }) are ({ 3 }) compared ({ 4 }) with ({ 5 }) one ({ 6 }) another ({ 7 }) using ({ 8 }) a ({ 9 }) comparison ({ 10 }) procedure ({ 11 }) . ({ 12 }) 
# Sentence pair (2465) source length 18 target length 18 alignment score : 0.00145766
This procedure implements a decision rule list containing four rules , encoding the following selection preference conditions : 
NULL ({ }) This ({ 1 }) procedure ({ 2 }) implements ({ 3 }) a ({ 4 }) decision ({ 5 }) rule ({ 6 }) list ({ 7 }) containing ({ 8 }) four ({ 9 }) rules ({ 10 }) , ({ 11 }) encoding ({ 12 }) the ({ 13 }) following ({ 14 }) selection ({ 15 }) preference ({ 16 }) conditions ({ 17 }) : ({ 18 }) 
# Sentence pair (2466) source length 25 target length 21 alignment score : 2.93202e-10
-Rule 1 ( Number agreement - NUM-AGREE ) : The candidate which is not number conflict with anaphor is selected . 
NULL ({ }) -Rule ({ 1 }) 1 ({ 2 }) ( ({ 3 }) Number ({ 4 }) agreement ({ 5 }) - ({ 6 }) NUM-AGREE ({ 7 }) ) ({ 8 }) : ({ 9 }) The ({ 10 }) candidate ({ 11 }) , ({ }) which ({ 12 }) does ({ 13 }) not ({ 14 }) conflict ({ 16 }) in ({ }) number ({ 15 }) with ({ 17 }) the ({ }) anaphor ({ 18 }) , ({ }) is ({ 19 }) selected ({ 20 }) . ({ 21 }) 
# Sentence pair (2467) source length 24 target length 22 alignment score : 2.1787e-05
-Rule 2 ( Semantic constraint - SEM-CONS ) : If anaphor is a protein reference , then protein candidate is selected . 
NULL ({ }) -Rule ({ 1 }) 2 ({ 2 }) ( ({ 3 }) Semantic ({ 4 }) constraint ({ 5 }) - ({ 6 }) SEM-CONS ({ 7 }) ) ({ 8 }) : ({ 9 }) If ({ 10 }) the ({ }) anaphor ({ 11 }) is ({ 12 }) a ({ 13 }) protein ({ 14 }) reference ({ 15 }) , ({ 16 }) then ({ 17 }) a ({ }) protein ({ 18 }) candidate ({ 19 }) is ({ 20 }) selected ({ 21 }) . ({ 22 }) 
# Sentence pair (2468) source length 21 target length 21 alignment score : 0.000770035
-Rule 3 ( Discourse preference - DISC-PREF ) : According to the anaphor type , the farther candidate is selected . 
NULL ({ }) -Rule ({ 1 }) 3 ({ 2 }) ( ({ 3 }) Discourse ({ 4 }) preference ({ 5 }) - ({ 6 }) DISC-PREF ({ 7 }) ) ({ 8 }) : ({ 9 }) According ({ 10 }) to ({ 11 }) the ({ 12 }) anaphor ({ 13 }) type ({ 14 }) , ({ 15 }) the ({ 16 }) farther ({ 17 }) candidate ({ 18 }) is ({ 19 }) selected ({ 20 }) . ({ 21 }) 
# Sentence pair (2469) source length 16 target length 16 alignment score : 0.00468454
-Default rule ( Default discourse preference - DEFAULT ) : The closer candidate is selected . 
NULL ({ }) -Default ({ 1 }) rule ({ 2 }) ( ({ 3 }) Default ({ 4 }) discourse ({ 5 }) preference ({ 6 }) - ({ 7 }) DEFAULT ({ 8 }) ) ({ 9 }) : ({ 10 }) The ({ 11 }) closer ({ 12 }) candidate ({ 13 }) is ({ 14 }) selected ({ 15 }) . ({ 16 }) 
# Sentence pair (2470) source length 34 target length 33 alignment score : 4.48438e-08
The rules are implemented using different features of expressions such as syntactic types of expression , head noun , semantic types , etc. , in a similar way to [ 22 ] . 
NULL ({ }) The ({ 1 }) rules ({ 2 }) are ({ 3 }) implemented ({ 4 }) using ({ 5 }) different ({ 6 }) features ({ 7 }) of ({ 8 }) expressions ({ 9 }) , ({ }) such ({ 10 }) as ({ 11 }) syntactic ({ 12 }) types ({ 13 }) of ({ 14 }) expressions ({ 15 }) , ({ 16 }) head ({ 17 }) noun ({ 18 }) , ({ 19 }) semantic ({ 20 }) types ({ 21 }) , ({ 22 }) etc. ({ 23 }) , ({ 24 }) in ({ 25 }) a ({ 26 }) similar ({ 27 }) way ({ 28 }) to ({ 29 }) [ ({ 30 }) 22 ({ 31 }) ] ({ 32 }) . ({ 33 }) 
# Sentence pair (2471) source length 21 target length 21 alignment score : 0.00010371
Each rule in the decision list compares two candidates , and returns the preferrable candidate in concern with the anaphor . 
NULL ({ }) Each ({ 1 }) rule ({ 2 }) in ({ 3 }) the ({ 4 }) decision ({ 5 }) list ({ 6 }) compares ({ 7 }) two ({ 8 }) candidates ({ 9 }) , ({ 10 }) and ({ 11 }) returns ({ 12 }) the ({ 13 }) preferable ({ 14 }) candidate ({ 15 }) in ({ 16 }) concern ({ 17 }) with ({ 18 }) the ({ 19 }) anaphor ({ 20 }) . ({ 21 }) 
# Sentence pair (2472) source length 13 target length 13 alignment score : 0.00542857
If equility happens , the next rule in the list is applied . 
NULL ({ }) If ({ 1 }) equility ({ 2 }) happens ({ 3 }) , ({ 4 }) the ({ 5 }) next ({ 6 }) rule ({ 7 }) in ({ 8 }) the ({ 9 }) list ({ 10 }) is ({ 11 }) applied ({ 12 }) . ({ 13 }) 
# Sentence pair (2473) source length 31 target length 31 alignment score : 1.6073e-06
The default and also last rule in the decision rule list is special in the sense that depending on the anaphor , it prefers the closer or the farther candidate . 
NULL ({ }) The ({ 1 }) default ({ 2 }) and ({ 3 }) also ({ 4 }) last ({ 5 }) rule ({ 6 }) in ({ 7 }) the ({ 8 }) decision ({ 9 }) rule ({ 10 }) list ({ 11 }) is ({ 12 }) special ({ 13 }) in ({ 14 }) the ({ 15 }) sense ({ 16 }) that ({ 17 }) depending ({ 18 }) on ({ 19 }) the ({ 20 }) anaphor ({ 21 }) , ({ 22 }) it ({ 23 }) prefers ({ 24 }) the ({ 25 }) closer ({ 26 }) or ({ 27 }) the ({ 28 }) farther ({ 29 }) candidate ({ 30 }) . ({ 31 }) 
# Sentence pair (2474) source length 16 target length 15 alignment score : 6.74419e-09
Thanks to this rule , the decision list never results in the equility result . 
NULL ({ }) Because ({ 1 }) of ({ 2 }) this ({ 3 }) particular ({ }) rule ({ 4 }) , ({ 5 }) the ({ 6 }) decision ({ 7 }) list ({ 8 }) never ({ 9 }) results ({ 10 }) in ({ 11 }) the ({ 12 }) equility ({ 13 }) result ({ 14 }) . ({ 15 }) 
# Sentence pair (2475) source length 19 target length 18 alignment score : 5.54579e-06
By this way , candidates can be sorted , and the best candidate is selected as antecedent . 
NULL ({ }) In ({ 1 }) this ({ 2 }) way ({ 3 }) , ({ 4 }) candidates ({ 5 }) can ({ 6 }) be ({ 7 }) sorted ({ 8 }) , ({ 9 }) and ({ 10 }) the ({ 11 }) best ({ 12 }) candidate ({ 13 }) is ({ 14 }) selected ({ 15 }) as ({ 16 }) the ({ }) antecedent ({ 17 }) . ({ 18 }) 
# Sentence pair (2476) source length 15 target length 14 alignment score : 0.000275881
Figure 4 illustrates how the decision list works when comparing two candidates and . 
NULL ({ }) Figure ({ 1 }) 4 ({ 2 }) illustrates ({ 3 }) how ({ 4 }) the ({ 5 }) decision ({ 6 }) list ({ 7 }) works ({ 8 }) when ({ 9 }) comparing ({ 10 }) two ({ 11 }) candidates ({ 12 }) : ({ }) and ({ 13 }) . ({ 14 }) 
# Sentence pair (2477) source length 20 target length 20 alignment score : 0.000138379
More details about the implementation of the main components of our system shown in Figure 2 are presented below . 
NULL ({ }) More ({ 1 }) details ({ 2 }) concerning ({ 3 }) the ({ 4 }) implementation ({ 5 }) of ({ 6 }) the ({ 7 }) main ({ 8 }) components ({ 9 }) of ({ 10 }) our ({ 11 }) system ({ 12 }) shown ({ 13 }) in ({ 14 }) Figure ({ 15 }) 2 ({ 16 }) are ({ 17 }) presented ({ 18 }) below ({ 19 }) . ({ 20 }) 
# Sentence pair (2478) source length 46 target length 41 alignment score : 1.69087e-15
In this step , we want to filter out those pronouns and definite noun phrases that are not target of this task , comprised of two types : non-anaphoric expressions , and anaphoric expressions which do not point to proteins . 
NULL ({ }) In ({ 1 }) this ({ 2 }) step ({ 3 }) , ({ 4 }) we ({ 5 }) want ({ 6 }) to ({ 7 }) filter ({ 8 }) out ({ 9 }) those ({ 10 }) pronouns ({ 11 }) and ({ 12 }) definite ({ 13 }) noun ({ 14 }) phrases ({ 15 }) that ({ 16 }) are ({ 17 }) not ({ 18 }) a ({ }) target ({ 19 }) of ({ 20 }) this ({ 21 }) task ({ 22 }) . ({ }) The ({ }) expressions ({ 23 }) are ({ }) comprised ({ 24 }) of ({ 25 }) two ({ 26 }) types ({ 27 }) : ({ 28 }) non-anaphoric ({ 29 }) expressions ({ 30 }) , ({ 31 }) and ({ 32 }) anaphoric ({ 33 }) expressions ({ 34 }) , ({ }) which ({ 35 }) do ({ 36 }) not ({ 37 }) point ({ 38 }) to ({ 39 }) proteins ({ 40 }) . ({ 41 }) 
# Sentence pair (2479) source length 14 target length 13 alignment score : 0.00092787
The term anaphoric is used with the common sense in NLP community . 
NULL ({ }) The ({ 1 }) term ({ 2 }) anaphoric ({ 3 }) is ({ 4 }) used ({ 5 }) with ({ 6 }) the ({ 7 }) common ({ 8 }) sense ({ 9 }) in ({ 10 }) the ({ }) NLP ({ 11 }) community ({ 12 }) . ({ 13 }) 
# Sentence pair (2480) source length 15 target length 13 alignment score : 3.96707e-05
Anaphoric expression means an expression that has a noun phrase as antecedent . 
NULL ({ }) Anaphoric ({ 1 }) expression ({ 2 }) refers ({ 3 }) to ({ }) an ({ 4 }) expression ({ 5 }) that ({ 6 }) has ({ 7 }) a ({ 8 }) noun ({ 9 }) phrase ({ 10 }) as ({ 11 }) an ({ }) antecedent ({ 12 }) . ({ 13 }) 
# Sentence pair (2481) source length 26 target length 26 alignment score : 6.58421e-10
This means expressions with a sentence or phrase antecedents , or nominal but successive antecedents , are not our target and should be filtered out . 
NULL ({ }) Thus ({ 1 }) , ({ 2 }) expressions ({ 3 }) with ({ 4 }) a ({ 5 }) sentence ({ 6 }) or ({ 7 }) phrase ({ 8 }) antecedents ({ 9 }) , ({ 10 }) or ({ 11 }) nominal ({ 12 }) but ({ 13 }) successive ({ 14 }) antecedents ({ 15 }) , ({ 16 }) are ({ 17 }) not ({ 18 }) our ({ 19 }) target ({ 20 }) and ({ 21 }) should ({ 22 }) be ({ 23 }) filtered ({ 24 }) out ({ 25 }) . ({ 26 }) 
# Sentence pair (2482) source length 19 target length 24 alignment score : 1.38851e-14
Non-anaphoric expressions includes first and second person pronouns such as I , we , you , . . . , and pleonastic it . 
NULL ({ 16 }) Non-anaphoric ({ 1 }) expressions ({ 2 }) include ({ 3 }) first ({ 4 }) and ({ 5 }) second-person ({ 6 7 }) pronouns ({ 8 }) such ({ 9 }) as ({ 10 }) I ({ 11 }) , ({ 12 }) we ({ 13 }) , ({ 14 }) you ({ 15 }) , ({ 20 }) and ({ 21 }) pleonastic ({ 22 }) it ({ 23 }) . ({ 17 18 19 24 }) 
# Sentence pair (2483) source length 22 target length 24 alignment score : 6.3433e-13
First and second person pronouns are easily to be recognized by the part-of-speech tags , thus we use part-of-speech information for the filtering . 
NULL ({ 8 9 }) First ({ 1 }) and ({ 2 }) second-person ({ 3 4 }) pronouns ({ 5 }) are ({ 6 }) easily ({ 7 }) recognized ({ 10 }) by ({ 11 }) the ({ 12 }) part-of-speech ({ 13 }) tags ({ 14 }) ; ({ 15 }) thus ({ 16 }) , ({ }) we ({ 17 }) use ({ 18 }) part-of-speech ({ 19 }) information ({ 20 }) for ({ 21 }) the ({ 22 }) filtering ({ 23 }) . ({ 24 }) 
# Sentence pair (2484) source length 21 target length 20 alignment score : 4.14354e-05
For pleonastic it , we make use of the following four patterns , which are similar to [ 13 ] 
NULL ({ }) For ({ 1 }) pleonastic ({ 2 }) it ({ 3 }) , ({ 4 }) we ({ 5 }) make ({ 6 }) use ({ 7 }) of ({ 8 }) the ({ 9 }) following ({ 10 }) four ({ 11 }) patterns ({ 12 }) , ({ 13 }) which ({ 14 }) are ({ 15 }) similar ({ 16 }) to ({ 17 }) [ ({ 18 }) 13 ({ 19 }) ] ({ 20 }) : ({ }) 
# Sentence pair (2485) source length 7 target length 7 alignment score : 0.0711926
It be [ Adj|Adv| verb ]* that 
NULL ({ }) It ({ 1 }) be ({ 2 }) [ ({ 3 }) Adj|Adv| ({ 4 }) verb ({ 5 }) ]* ({ 6 }) that ({ 7 }) 
# Sentence pair (2486) source length 9 target length 9 alignment score : 0.0350081
It be Adj [ for NP ] to VP 
NULL ({ }) It ({ 1 }) be ({ 2 }) Adj ({ 3 }) [ ({ 4 }) for ({ 5 }) NP ({ 6 }) ] ({ 7 }) to ({ 8 }) VP ({ 9 }) 
# Sentence pair (2487) source length 7 target length 7 alignment score : 0.088912
It [ seems|appears|means|follows ] [ that ]* 
NULL ({ }) It ({ 1 }) [ ({ 2 }) seems|appears|means|follows ({ 3 }) ] ({ 4 }) [ ({ 5 }) that ({ 6 }) ]* ({ 7 }) 
# Sentence pair (2488) source length 16 target length 16 alignment score : 0.0033248
NP [ makes|finds|take ] it [ Adj ]* [ for NP ]* [ to VP|Ving ] 
NULL ({ }) NP ({ 1 }) [ ({ 2 }) makes|finds|take ({ 3 }) ] ({ 4 }) it ({ 5 }) [ ({ 6 }) Adj ({ 7 }) ]* ({ 8 }) [ ({ 9 }) for ({ 10 }) NP ({ 11 }) ]* ({ 12 }) [ ({ 13 }) to ({ 14 }) VP|Ving ({ 15 }) ] ({ 16 }) 
# Sentence pair (2489) source length 30 target length 30 alignment score : 5.77452e-07
To recognize and filter anaphoric expressions which do not point to proteins , the system is based on the protein semantic classification results determined by the method presented below . 
NULL ({ }) To ({ 1 }) recognize ({ 2 }) and ({ 3 }) filter ({ 4 }) anaphoric ({ 5 }) expressions ({ 6 }) that ({ 7 }) do ({ 8 }) not ({ 9 }) point ({ 10 }) to ({ 11 }) proteins ({ 12 }) , ({ 13 }) the ({ 14 }) system ({ 15 }) is ({ 16 }) based ({ 17 }) on ({ 18 }) the ({ 19 }) protein ({ 20 }) semantic ({ 21 }) classification ({ 22 }) results ({ 23 }) determined ({ 24 }) by ({ 25 }) the ({ 26 }) method ({ 27 }) presented ({ 28 }) below ({ 29 }) . ({ 30 }) 
# Sentence pair (2490) source length 28 target length 28 alignment score : 3.20011e-05
For each anaphoric markable , the system collects a list of antecedent candidates , and select the most probable candidate to be the antecedent of the anaphor . 
NULL ({ }) For ({ 1 }) each ({ 2 }) anaphoric ({ 3 }) markable ({ 4 }) , ({ 5 }) the ({ 6 }) system ({ 7 }) collects ({ 8 }) a ({ 9 }) list ({ 10 }) of ({ 11 }) antecedent ({ 12 }) candidates ({ 13 }) , ({ 14 }) and ({ 15 }) select ({ 16 }) the ({ 17 }) most ({ 18 }) probable ({ 19 }) candidate ({ 20 }) to ({ 21 }) be ({ 22 }) the ({ 23 }) antecedent ({ 24 }) of ({ 25 }) the ({ 26 }) anaphor ({ 27 }) . ({ 28 }) 
# Sentence pair (2491) source length 24 target length 18 alignment score : 2.29636e-11
Basically all expressions detected in the initial expression set are antecedent candidate , except for anaphoric pronouns . 
NULL ({ }) Basically ({ 1 }) , ({ }) all ({ 2 }) of ({ }) the ({ }) expressions ({ 3 }) detected ({ 4 }) in ({ 5 }) the ({ 6 }) initial ({ 7 }) expression ({ 8 }) set ({ 9 }) are ({ 10 }) an ({ }) antecedent ({ 11 }) candidate ({ 12 }) , ({ 13 }) with ({ }) the ({ }) exception ({ 14 }) of ({ 15 }) anaphoric ({ 16 }) pronouns ({ 17 }) . ({ 18 }) 
# Sentence pair (2492) source length 22 target length 22 alignment score : 0.000174462
However , if the list contains too many candidates , then it may be more difficult for the later antecedent-selection algorithm . 
NULL ({ }) However ({ 1 }) , ({ 2 }) if ({ 3 }) the ({ 4 }) list ({ 5 }) contains ({ 6 }) too ({ 7 }) many ({ 8 }) candidates ({ 9 }) , ({ 10 }) then ({ 11 }) it ({ 12 }) may ({ 13 }) be ({ 14 }) more ({ 15 }) difficult ({ 16 }) for ({ 17 }) the ({ 18 }) later ({ 19 }) antecedent-selection ({ 20 }) algorithm ({ 21 }) . ({ 22 }) 
# Sentence pair (2493) source length 19 target length 18 alignment score : 0.000202257
Therefore , candidates that are not probable to be antecedent of the anaphor should be filtered out . 
NULL ({ }) Therefore ({ 1 }) , ({ 2 }) candidates ({ 3 }) that ({ 4 }) are ({ 5 }) not ({ 6 }) probable ({ 7 }) to ({ 8 }) be ({ 9 }) an ({ }) antecedent ({ 10 }) of ({ 11 }) the ({ 12 }) anaphor ({ 13 }) should ({ 14 }) be ({ 15 }) filtered ({ 16 }) out ({ 17 }) . ({ 18 }) 
# Sentence pair (2494) source length 9 target length 9 alignment score : 0.030049
There are several filters that can be used : 
NULL ({ }) There ({ 1 }) are ({ 2 }) several ({ 3 }) filters ({ 4 }) that ({ 5 }) can ({ 6 }) be ({ 7 }) used ({ 8 }) : ({ 9 }) 
# Sentence pair (2495) source length 12 target length 12 alignment score : 2.97096e-08
Window size sets a border to include or exclude antecedent candidates . 
NULL ({ 4 }) Window ({ 1 }) size ({ 2 }) Borders ({ 3 }) are ({ }) set ({ 5 }) to ({ 6 }) include ({ 7 }) or ({ 8 }) exclude ({ 9 }) antecedent ({ 10 }) candidates ({ 11 }) . ({ 12 }) 
# Sentence pair (2496) source length 24 target length 24 alignment score : 4.13586e-13
This is a common method for antecedent candidate filtering having been used in the previous work [ 3 , 5 , 26 ] . 
NULL ({ }) This ({ 1 }) is ({ 2 }) a ({ 3 }) common ({ 4 }) method ({ 5 }) for ({ 6 }) antecedent ({ 7 }) candidate ({ 8 }) filtering ({ 9 }) , ({ }) as ({ }) seen ({ 12 }) in ({ 13 }) the ({ 14 }) previous ({ 15 }) work ({ 16 }) [ ({ 17 }) 3 ({ 18 }) , ({ 19 }) 5 ({ 20 }) , ({ 21 }) 26 ({ 10 11 22 }) ] ({ 23 }) . ({ 24 }) 
# Sentence pair (2497) source length 34 target length 32 alignment score : 2.03426e-08
Since our task focuses on anaphoric coreference , antecedent expressions normally appear not too far ( in sentence distance ) from the anaphors , using window sizes is a proper technique . 
NULL ({ }) Since ({ 1 }) our ({ 2 }) task ({ 3 }) focuses ({ 4 }) on ({ 5 }) anaphoric ({ 6 }) coreference ({ 7 }) , ({ 8 }) antecedent ({ 9 }) expressions ({ 10 }) normally ({ 11 }) appear ({ 12 }) not ({ 13 }) too ({ 14 }) far ({ 15 }) ( ({ 16 }) in ({ 17 }) sentence ({ 18 }) distance ({ 19 }) ) ({ 20 }) from ({ 21 }) the ({ 22 }) anaphors ({ 23 }) . ({ }) Thus ({ }) , ({ 24 }) using ({ 25 }) window ({ 26 }) sizes ({ 27 }) is ({ 28 }) a ({ 29 }) proper ({ 30 }) technique ({ 31 }) . ({ 32 }) 
# Sentence pair (2498) source length 36 target length 36 alignment score : 3.26299e-32
Syntactic dependency relations The fact that arguments of some dependency relations such as poss-arg12 and prep-arg12 do not corefer with each other enables us to use them to correctly eliminate the number of antecedent candidates . 
NULL ({ 6 27 }) Syntactic ({ 1 }) dependency ({ 2 }) relations ({ 3 }) Since ({ 4 }) arguments ({ 5 7 }) of ({ 8 }) some ({ 9 }) dependency ({ 10 }) relations ({ 11 }) ( ({ }) such ({ 12 }) as ({ 13 }) poss-arg12 ({ 14 23 24 }) and ({ 15 }) prep-arg12 ({ 16 }) ) ({ }) do ({ 17 }) not ({ 18 }) corefer ({ 19 }) with ({ 20 }) each ({ 21 }) other ({ 22 }) , ({ }) they ({ }) can ({ 25 }) be ({ }) used ({ 26 }) to ({ 28 }) correctly ({ 29 }) eliminate ({ 30 }) the ({ 31 }) number ({ 32 }) of ({ 33 }) antecedent ({ 34 }) candidates ({ 35 }) . ({ 36 }) 
# Sentence pair (2499) source length 27 target length 24 alignment score : 2.97424e-08
For instance , two such truncated forms definitely cannot be antecedent of the protein in this context two such truncated forms of the protein 
NULL ({ }) For ({ 1 }) instance ({ 2 }) , ({ 3 }) two ({ 4 }) such ({ 5 }) truncated ({ 6 }) forms ({ 7 }) definitely ({ 8 }) cannot ({ 9 }) be ({ 10 }) an ({ }) antecedent ({ 11 }) of ({ 12 }) the ({ 13 }) protein ({ 14 }) in ({ 15 }) this ({ 16 }) context ({ 17 }) : ({ }) two ({ 18 }) such ({ 19 }) truncated ({ 20 }) forms ({ 21 }) of ({ 22 }) the ({ 23 }) protein ({ 24 }) . ({ }) 
# Sentence pair (2500) source length 36 target length 36 alignment score : 4.54149e-10
After filtering non-relevant antecedent candidates for an anaphor in the above step , depending on the anaphor type , the remained candidates are ranked by fixed rules , or by using a pairwise comparison procedure : 
NULL ({ }) After ({ 1 }) filtering ({ 2 }) non-relevant ({ 3 }) antecedent ({ 4 }) candidates ({ 5 }) for ({ 6 }) an ({ 7 }) anaphor ({ 8 }) in ({ 9 }) the ({ 10 }) step ({ 12 }) above ({ 11 }) , ({ 13 }) depending ({ 14 }) on ({ 15 }) the ({ 16 }) anaphor ({ 17 }) type ({ 18 }) , ({ 19 }) the ({ 20 }) remaining ({ 21 }) candidates ({ 22 }) are ({ 23 }) ranked ({ 24 }) by ({ 25 }) fixed ({ 26 }) rules ({ 27 }) , ({ 28 }) or ({ 29 }) by ({ 30 }) using ({ 31 }) a ({ 32 }) pairwise ({ 33 }) comparison ({ 34 }) procedure ({ 35 }) : ({ 36 }) 
# Sentence pair (2501) source length 38 target length 38 alignment score : 4.90115e-07
The relative pronoun can be said to be the easiest type of coreference resolution , because its antecedent expression is very close to the anaphor , and in many cases , it is right before the anaphor . 
NULL ({ }) The ({ 1 }) relative ({ 2 }) pronoun ({ 3 }) can ({ 4 }) be ({ 5 }) said ({ 6 }) to ({ 7 }) be ({ 8 }) the ({ 9 }) easiest ({ 10 }) type ({ 11 }) of ({ 12 }) coreference ({ 13 }) resolution ({ 14 }) , ({ 15 }) because ({ 16 }) its ({ 17 }) antecedent ({ 18 }) expression ({ 19 }) is ({ 20 }) very ({ 21 }) close ({ 22 }) to ({ 23 }) the ({ 24 }) anaphor ({ 25 }) , ({ 26 }) and ({ 27 }) in ({ 28 }) many ({ 29 }) cases ({ 30 }) , ({ 31 }) it ({ 32 }) is ({ 33 }) right ({ 34 }) before ({ 35 }) the ({ 36 }) anaphor ({ 37 }) . ({ 38 }) 
# Sentence pair (2502) source length 23 target length 23 alignment score : 1.41979e-09
For this type of anaphors , any syntactic parser can be used to find the relations between relative pronouns and their arguments . 
NULL ({ }) For ({ 1 }) these ({ 2 }) types ({ 3 }) of ({ 4 }) anaphors ({ 5 }) , ({ 6 }) any ({ 7 }) syntactic ({ 8 }) parser ({ 9 }) can ({ 10 }) be ({ 11 }) used ({ 12 }) to ({ 13 }) find ({ 14 }) the ({ 15 }) relation ({ 16 }) between ({ 17 }) relative ({ 18 }) pronouns ({ 19 }) and ({ 20 }) their ({ 21 }) arguments ({ 22 }) . ({ 23 }) 
# Sentence pair (2503) source length 6 target length 8 alignment score : 2.00341e-15
This is exactly what our system does . 
NULL ({ 2 }) Our ({ }) system ({ 6 }) accomplishes ({ 1 3 4 7 }) this ({ }) task ({ 5 }) . ({ 8 }) 
# Sentence pair (2504) source length 13 target length 13 alignment score : 0.00541527
It simply produces coreference links between the relative pronouns and their arguments . 
NULL ({ }) It ({ 1 }) simply ({ 2 }) produces ({ 3 }) coreference ({ 4 }) links ({ 5 }) between ({ 6 }) the ({ 7 }) relative ({ 8 }) pronouns ({ 9 }) and ({ 10 }) their ({ 11 }) arguments ({ 12 }) . ({ 13 }) 
# Sentence pair (2505) source length 70 target length 63 alignment score : 2.34241e-25
However , a disadvantage of this method is when the parser makes mistake on finding the correct arguments , coreference also fails , as in the example " . . .of transcription factor NF-kappa B also encodes a p70 I kappa B protein , I kappa B gamma , which is identical to the C-terminal 607 amino acids of . . . " 
NULL ({ 5 23 }) However ({ 1 }) , ({ 2 }) a ({ 3 }) disadvantage ({ 4 }) to ({ }) using ({ }) this ({ 6 }) method ({ 7 }) is ({ 8 }) that ({ }) when ({ 9 }) the ({ 10 }) parser ({ 11 }) makes ({ 12 }) a ({ }) mistake ({ 13 }) on ({ 14 }) finding ({ 15 }) the ({ 16 }) correct ({ 17 }) arguments ({ 18 }) , ({ 19 }) the ({ }) coreference ({ 20 }) also ({ 21 }) fails ({ 22 }) . ({ }) This ({ }) is ({ }) exemplified ({ 24 }) in ({ 25 }) the ({ 26 }) following ({ 27 }) : ({ }) " ({ 28 }) . ({ 29 }) . ({ 30 }) .of ({ 31 }) transcription ({ 32 }) factor ({ 33 }) NF-kappa ({ 34 }) B ({ 35 }) also ({ 36 }) encodes ({ 37 }) a ({ 38 }) p70 ({ 39 }) I ({ 40 }) kappa ({ 41 }) B ({ 42 }) protein ({ 43 }) , ({ 44 }) I ({ 45 }) kappa ({ 46 }) B ({ 47 }) gamma ({ 48 }) , ({ 49 }) which ({ 50 }) is ({ 51 }) identical ({ 52 }) to ({ 53 }) the ({ 54 }) C-terminal ({ 55 }) 607 ({ 56 }) amino ({ 57 }) acids ({ 58 }) of ({ 59 }) . ({ 60 }) . ({ 61 }) . ({ 62 }) " ({ 63 }) 
# Sentence pair (2506) source length 18 target length 18 alignment score : 0.00147825
This procedure compares two candidate expressions at a time with respect to preferences raised by the anaphor . 
NULL ({ }) This ({ 1 }) procedure ({ 2 }) compares ({ 3 }) two ({ 4 }) candidate ({ 5 }) expressions ({ 6 }) at ({ 7 }) a ({ 8 }) time ({ 9 }) with ({ 10 }) respect ({ 11 }) to ({ 12 }) preferences ({ 13 }) raised ({ 14 }) by ({ 15 }) the ({ 16 }) anaphor ({ 17 }) . ({ 18 }) 
# Sentence pair (2507) source length 13 target length 13 alignment score : 0.012673
The best antecedent expression is selected to form a response coreference link . 
NULL ({ }) The ({ 1 }) best ({ 2 }) antecedent ({ 3 }) expression ({ 4 }) is ({ 5 }) selected ({ 6 }) to ({ 7 }) form ({ 8 }) a ({ 9 }) response ({ 10 }) coreference ({ 11 }) link ({ 12 }) . ({ 13 }) 
# Sentence pair (2508) source length 21 target length 21 alignment score : 0.000305467
In particular , a list of rules is used to compare two candidates of an anaphor in a deterministic manner . 
NULL ({ }) In ({ 1 }) particular ({ 2 }) , ({ 3 }) a ({ 4 }) list ({ 5 }) of ({ 6 }) rules ({ 7 }) is ({ 8 }) used ({ 9 }) to ({ 10 }) compare ({ 11 }) two ({ 12 }) candidates ({ 13 }) of ({ 14 }) an ({ 15 }) anaphor ({ 16 }) in ({ 17 }) a ({ 18 }) deterministic ({ 19 }) manner ({ 20 }) . ({ 21 }) 
# Sentence pair (2509) source length 18 target length 18 alignment score : 0.00186649
For each rule , both of the candidates are checked against the condition hold by that rule . 
NULL ({ }) For ({ 1 }) each ({ 2 }) rule ({ 3 }) , ({ 4 }) both ({ 5 }) of ({ 6 }) the ({ 7 }) candidates ({ 8 }) are ({ 9 }) checked ({ 10 }) against ({ 11 }) the ({ 12 }) condition ({ 13 }) hold ({ 14 }) by ({ 15 }) that ({ 16 }) rule ({ 17 }) . ({ 18 }) 
# Sentence pair (2510) source length 26 target length 26 alignment score : 2.63503e-07
If one candidate satisfies and the other does not , the procedure ends with the result that the former will be preferable to the latter . 
NULL ({ }) If ({ 1 }) one ({ 2 }) candidate ({ 3 }) satisfies ({ 4 }) and ({ 5 }) the ({ 6 }) other ({ 7 }) does ({ 8 }) not ({ 9 }) , ({ 10 }) the ({ 11 }) procedure ({ 12 }) ends ({ 13 }) with ({ 14 }) the ({ 15 }) result ({ 16 }) that ({ 17 }) the ({ 18 }) former ({ 19 }) will ({ 20 }) be ({ 21 }) preferable ({ 22 }) over ({ 23 }) the ({ 24 }) latter ({ 25 }) . ({ 26 }) 
# Sentence pair (2511) source length 21 target length 21 alignment score : 0.000453119
If both satisfy or both do not satisfy , the procedure proceeds to the next rule in the same manner . 
NULL ({ }) If ({ 1 }) both ({ 2 }) satisfy ({ 3 }) or ({ 4 }) both ({ 5 }) do ({ 6 }) not ({ 7 }) satisfy ({ 8 }) , ({ 9 }) the ({ 10 }) procedure ({ 11 }) proceeds ({ 12 }) to ({ 13 }) the ({ 14 }) next ({ 15 }) rule ({ 16 }) in ({ 17 }) the ({ 18 }) same ({ 19 }) manner ({ 20 }) . ({ 21 }) 
# Sentence pair (2512) source length 26 target length 25 alignment score : 2.04036e-11
The rules are applied in a succession order one after another until the inequality occurs , or end of the rule list is reached . 
NULL ({ 19 }) The ({ 1 }) rules ({ 2 }) are ({ 3 }) applied ({ 4 }) in ({ 5 }) a ({ 6 }) successive ({ 7 }) order ({ 8 }) , ({ }) one ({ 9 }) after ({ 10 }) another ({ 11 }) , ({ }) until ({ 12 }) the ({ 13 }) inequality ({ 14 }) occurs ({ 15 }) , ({ 16 }) or ({ 17 }) until ({ 18 }) the ({ 20 }) end-of-the-rule ({ 21 }) list ({ 22 }) is ({ 23 }) reached ({ 24 }) . ({ 25 }) 
# Sentence pair (2513) source length 17 target length 12 alignment score : 3.28259e-08
The default rule of the procedure prefers the closer antecedent candidate . 
NULL ({ }) The ({ 1 }) default ({ 2 }) rule ({ 3 }) of ({ 4 }) the ({ 5 }) procedure ({ 6 }) , ({ }) is ({ }) in ({ }) the ({ }) preference ({ 7 }) of ({ }) the ({ 8 }) closer ({ 9 }) antecedent ({ 10 }) candidate ({ 11 }) . ({ 12 }) 
# Sentence pair (2514) source length 17 target length 20 alignment score : 6.09161e-14
By definition , two coreferential expressions refer to the same thing , which implies a semantic-constraint on coreference relationship . 
NULL ({ 8 9 }) By ({ 1 }) definition ({ 2 }) , ({ 3 }) two ({ 4 }) coreferential ({ 5 }) expressions ({ 6 }) are ({ }) identical ({ 7 10 11 }) , ({ 12 }) which ({ 13 }) implies ({ 14 }) a ({ 15 }) semantic-constraint ({ 16 }) on ({ 17 }) coreference ({ 18 }) relationship ({ 19 }) . ({ 20 }) 
# Sentence pair (2515) source length 12 target length 12 alignment score : 0.0128989
In other words , semantic types of coreferents must be compatible . 
NULL ({ }) In ({ 1 }) other ({ 2 }) words ({ 3 }) , ({ 4 }) semantic ({ 5 }) types ({ 6 }) of ({ 7 }) coreferents ({ 8 }) must ({ 9 }) be ({ 10 }) compatible ({ 11 }) . ({ 12 }) 
# Sentence pair (2516) source length 43 target length 44 alignment score : 2.01692e-14
In practice , this compatibility is checked based on a given taxonomy of semantic classes in the following manner : two semantic classes are considered compatible or agreed with each other , when they have synonym relation , e.g. , or hypernym-hyponym relation . 
NULL ({ 38 }) In ({ 1 }) practice ({ 2 }) , ({ 3 }) this ({ 4 }) compatibility ({ 5 }) is ({ 6 }) checked ({ 7 }) based ({ 8 }) on ({ 9 }) a ({ 10 }) given ({ 11 }) taxonomy ({ 12 }) of ({ 13 }) semantic ({ 14 }) classes ({ 15 }) in ({ 16 }) the ({ 17 }) following ({ 18 }) manner ({ 19 }) : ({ 20 }) two ({ 21 }) semantic ({ 22 }) classes ({ 23 }) are ({ 24 }) considered ({ 25 }) compatible ({ 26 }) or ({ 27 }) agreed ({ 28 }) with ({ 29 }) each ({ 30 }) other ({ 31 }) , ({ 32 }) when ({ 33 }) they ({ 34 }) have ({ 35 }) a ({ }) synonym ({ 36 }) relation ({ 37 }) , ({ 40 }) or ({ 41 }) hypernym-hyponym ({ 39 42 }) relation ({ 43 }) . ({ 44 }) 
# Sentence pair (2517) source length 30 target length 30 alignment score : 8.14346e-19
In this work , we only focus on the Protein type , ignoring other possible semantic types , so we do not take the structure of taxonomy into account . 
NULL ({ 20 24 }) In ({ 1 }) this ({ 2 }) work ({ 3 }) , ({ 4 }) we ({ 5 }) only ({ 6 }) focus ({ 7 }) on ({ 8 }) the ({ 9 }) Protein ({ 10 }) type ({ 11 }) , ({ 12 }) ignoring ({ 13 }) other ({ 14 }) possible ({ 15 }) semantic ({ 16 }) types ({ 17 }) , ({ 18 }) so ({ 19 }) the ({ }) structure ({ 25 }) of ({ 26 }) the ({ }) taxonomy ({ 21 27 }) is ({ }) not ({ 22 }) taken ({ 23 }) into ({ 28 }) account ({ 29 }) . ({ 30 }) 
# Sentence pair (2518) source length 22 target length 21 alignment score : 1.14936e-06
Thus , the likelihood that two expressions are semantically compatible is definitely beneficial for antecedent prediction , besides syntactic information . 
NULL ({ }) Therefore ({ 1 }) , ({ 2 }) the ({ 3 }) likelihood ({ 4 }) that ({ 5 }) two ({ 6 }) expressions ({ 7 }) are ({ 8 }) semantically ({ 9 }) compatible ({ 10 }) , ({ }) is ({ 11 }) definitely ({ 12 }) beneficial ({ 13 }) for ({ 14 }) antecedent ({ 15 }) prediction ({ 16 }) , ({ 17 }) besides ({ 18 }) syntactic ({ 19 }) information ({ 20 }) . ({ 21 }) 
# Sentence pair (2519) source length 33 target length 32 alignment score : 1.37764e-12
Focusing on specific entity types , i.e. Protein type , helps us to find a proper method for determining the likelihood , and how to encode the likelihood in coreference resolution . 
NULL ({ }) Focusing ({ 1 }) on ({ 2 }) specific ({ 3 }) entity ({ 4 }) types ({ 5 }) , ({ 6 }) i.e. ({ 7 }) , ({ }) Protein ({ 8 }) type ({ 9 }) , ({ 10 }) enables ({ 11 }) us ({ 12 }) to ({ 13 }) find ({ 14 }) a ({ 15 }) proper ({ 16 }) method ({ 17 }) for ({ 18 }) determining ({ 19 }) the ({ 20 }) likelihood ({ 21 }) , ({ 22 }) and ({ 23 }) method ({ 24 }) for ({ 25 }) encoding ({ 26 }) the ({ 27 }) likelihood ({ 28 }) in ({ 29 }) coreference ({ 30 }) resolution ({ 31 }) . ({ 32 }) 
# Sentence pair (2520) source length 28 target length 27 alignment score : 1.77979e-07
Since gold protein annotations are given , we can use them in combination with syntactic information to judge whether an expression is protein-referential expession or not . 
NULL ({ }) Since ({ 1 }) gold ({ 2 }) protein ({ 3 }) annotations ({ 4 }) are ({ 5 }) given ({ 6 }) , ({ 7 }) we ({ 8 }) can ({ 9 }) use ({ 10 }) them ({ 11 }) in ({ 12 }) combination ({ 13 }) with ({ 14 }) syntactic ({ 15 }) information ({ 16 }) to ({ 17 }) judge ({ 18 }) whether ({ 19 }) an ({ 20 }) expression ({ 21 }) is ({ 22 }) a ({ }) protein-referential ({ 23 }) expression ({ 24 }) or ({ 25 }) not ({ 26 }) . ({ 27 }) 
# Sentence pair (2521) source length 35 target length 38 alignment score : 6.22856e-21
In details , if an expression is a noun phrase with a single head word , and it contains a protein mention that completely overlaps with the head word , then the expression is classied as Protein . 
NULL ({ 3 }) If ({ }) an ({ 5 }) expression ({ 6 }) is ({ 7 }) a ({ 8 }) noun ({ 9 }) phrase ({ 10 }) with ({ 11 }) a ({ 12 }) single ({ 13 }) head ({ 14 }) word ({ 15 }) , ({ 16 }) and ({ 17 }) it ({ 18 }) contains ({ 19 }) a ({ 20 }) protein ({ 21 }) mention ({ 22 }) that ({ 23 }) completely ({ 2 24 }) overlaps ({ 1 4 25 }) with ({ 26 }) the ({ 27 }) head ({ 28 }) word ({ 29 }) , ({ 30 }) then ({ 31 }) the ({ 32 }) expression ({ 33 }) is ({ 34 }) classified ({ 35 }) as ({ 36 }) Protein ({ 37 }) . ({ 38 }) 
# Sentence pair (2522) source length 29 target length 28 alignment score : 6.96666e-12
Another case is when the head noun is either protein or gene , and has a protein mention as its premodifier , such as the Tax protein . 
NULL ({ 3 }) In ({ }) another ({ 1 }) case ({ 2 }) , ({ }) when ({ 4 }) the ({ 5 }) head ({ 6 }) noun ({ 7 }) is ({ 8 }) either ({ 9 }) protein ({ 10 }) or ({ 11 }) gene ({ 12 }) , ({ 13 }) and ({ 14 }) has ({ 15 }) a ({ 16 }) protein ({ 17 }) mention ({ 18 }) as ({ 19 }) its ({ 20 }) premodifier ({ 21 }) , ({ 22 }) such ({ 23 }) as ({ 24 }) the ({ 25 }) Tax ({ 26 }) protein ({ 27 }) . ({ 28 }) 
# Sentence pair (2523) source length 28 target length 26 alignment score : 1.01372e-06
For a coordinated noun phrase , if one of its constituents is classified as Protein , then that noun phrase is also classified as Protein . 
NULL ({ }) For ({ 1 }) a ({ 2 }) coordinated ({ 3 }) noun ({ 4 }) phrase ({ 5 }) , ({ 6 }) if ({ 7 }) one ({ 8 }) of ({ 9 }) its ({ 10 }) constituents ({ 11 }) is ({ 12 }) classified ({ 13 }) as ({ 14 }) a ({ }) Protein ({ 15 }) , ({ 16 }) then ({ 17 }) that ({ 18 }) noun ({ 19 }) phrase ({ 20 }) is ({ 21 }) also ({ 22 }) classified ({ 23 }) as ({ 24 }) a ({ }) Protein ({ 25 }) . ({ 26 }) 
# Sentence pair (2524) source length 22 target length 21 alignment score : 3.10847e-05
Pronouns , in particular , possessive pronouns occupy the majority of anaphoric pronouns in biological texts ( Table 5 ) . 
NULL ({ }) Pronouns ({ 1 }) , ({ 2 }) in ({ 3 }) particular ({ 4 }) , ({ 5 }) possessive ({ 6 }) pronouns ({ 7 }) , ({ }) occupy ({ 8 }) the ({ 9 }) majority ({ 10 }) of ({ 11 }) anaphoric ({ 12 }) pronouns ({ 13 }) in ({ 14 }) biological ({ 15 }) texts ({ 16 }) ( ({ 17 }) Table ({ 18 }) 5 ({ 19 }) ) ({ 20 }) . ({ 21 }) 
# Sentence pair (2525) source length 29 target length 29 alignment score : 4.53814e-10
However , they do not contain in themselves much useful information for the resolution , thus we need to exploit more information from its context [ 17 ] . 
NULL ({ 7 }) However ({ 1 }) , ({ 2 }) they ({ 3 }) do ({ 4 }) not ({ 5 }) contain ({ 6 }) very ({ 8 }) much ({ 9 }) useful ({ 10 }) information ({ 11 }) for ({ 12 }) the ({ 13 }) resolution ({ 14 }) ; ({ 15 }) thus ({ 16 }) , ({ }) we ({ 17 }) need ({ 18 }) to ({ 19 }) exploit ({ 20 }) more ({ 21 }) information ({ 22 }) from ({ 23 }) its ({ 24 }) context ({ 25 }) [ ({ 26 }) 17 ({ 27 }) ] ({ 28 }) . ({ 29 }) 
# Sentence pair (2526) source length 21 target length 20 alignment score : 2.54627e-05
The analysis of BioNLP-ST 2011 also showed that we need different strategy to resolve such pronouns [ 18 ] . 
NULL ({ }) The ({ 1 }) analysis ({ 2 }) of ({ 3 }) BioNLP-ST ({ 4 }) 2011 ({ 5 }) also ({ 6 }) showed ({ 7 }) that ({ 8 }) we ({ 9 }) need ({ 10 }) a ({ }) different ({ 11 }) strategy ({ 12 }) to ({ 13 }) resolve ({ 14 }) such ({ 15 }) pronouns ({ 16 }) [ ({ 17 }) 18 ({ 18 }) ] ({ 19 }) . ({ 20 }) 
# Sentence pair (2527) source length 14 target length 14 alignment score : 0.00533834
Fortunately , the key to this problem lies in the context of pronouns . 
NULL ({ }) Fortunately ({ 1 }) , ({ 2 }) the ({ 3 }) key ({ 4 }) to ({ 5 }) this ({ 6 }) problem ({ 7 }) lies ({ 8 }) in ({ 9 }) the ({ 10 }) context ({ 11 }) of ({ 12 }) pronouns ({ 13 }) . ({ 14 }) 
# Sentence pair (2528) source length 21 target length 20 alignment score : 0.000107977
We implemented a simple function to classify the semantic type of a possessive pronoun based on its context word . 
NULL ({ }) We ({ 1 }) implemented ({ 2 }) a ({ 3 }) simple ({ 4 }) function ({ 5 }) to ({ 6 }) classify ({ 7 }) the ({ 8 }) semantic ({ 9 }) type ({ 10 }) of ({ 11 }) a ({ 12 }) possessive ({ 13 }) pronoun ({ 14 }) , ({ }) based ({ 15 }) on ({ 16 }) its ({ 17 }) context ({ 18 }) word ({ 19 }) . ({ 20 }) 
# Sentence pair (2529) source length 39 target length 36 alignment score : 1.45005e-11
In particular , we check the noun phrase whose determiner is its or their ; if the noun phrase contains a protein key word then the inclusive pronoun is classified into the Protein semantic type . 
NULL ({ }) In ({ 1 }) particular ({ 2 }) , ({ 3 }) we ({ 4 }) check ({ 5 }) the ({ 6 }) noun ({ 7 }) phrase ({ 8 }) in ({ }) which ({ 9 }) the ({ }) determiner ({ 10 }) is ({ 11 }) its ({ 12 }) or ({ 13 }) their ({ 14 }) ; ({ 15 }) if ({ 16 }) the ({ 17 }) noun ({ 18 }) phrase ({ 19 }) contains ({ 20 }) a ({ 21 }) protein ({ 22 }) key ({ 23 }) word ({ 24 }) , ({ }) then ({ 25 }) the ({ 26 }) inclusive ({ 27 }) pronoun ({ 28 }) is ({ 29 }) classified ({ 30 }) into ({ 31 }) the ({ 32 }) Protein ({ 33 }) semantic ({ 34 }) type ({ 35 }) . ({ 36 }) 
# Sentence pair (2530) source length 36 target length 35 alignment score : 2.96273e-08
protein key words can be a verb , a noun or an adjective that coocurred with protein mentions and can be used as a clue to distinguish the protein type from other semantic types . 
NULL ({ }) Protein ({ 1 }) key ({ 2 }) words ({ 3 }) can ({ 4 }) be ({ 5 }) a ({ 6 }) verb ({ 7 }) , ({ 8 }) a ({ 9 }) noun ({ 10 }) or ({ 11 }) an ({ 12 }) adjective ({ 13 }) that ({ 14 }) co-occurred ({ 15 }) with ({ 16 }) protein ({ 17 }) mentions ({ 18 }) , ({ }) and ({ 19 }) can ({ 20 }) be ({ 21 }) used ({ 22 }) as ({ 23 }) a ({ 24 }) clue ({ 25 }) to ({ 26 }) distinguish ({ 27 }) the ({ 28 }) protein ({ 29 }) type ({ 30 }) from ({ 31 }) other ({ 32 }) semantic ({ 33 }) types ({ 34 }) . ({ 35 }) 
# Sentence pair (2531) source length 35 target length 34 alignment score : 9.54232e-11
For example , the word binding in the following noun phrases its heterodimeric binding partner , or its binding site is a good clue to infer that it must be a protein reference . 
NULL ({ }) For ({ 1 }) example ({ 2 }) , ({ 3 }) the ({ 4 }) word ({ 5 }) binding ({ 6 }) in ({ 7 }) the ({ 8 }) following ({ 9 }) noun ({ 10 }) phrases ({ 11 }) : ({ }) its ({ 12 }) heterodimeric ({ 13 }) binding ({ 14 }) partner ({ 15 }) , ({ 16 }) or ({ 17 }) its ({ 18 }) binding ({ 19 }) site ({ 20 }) , ({ }) is ({ 21 }) a ({ 22 }) clue ({ 23 24 }) to ({ 25 }) infer ({ 26 }) that ({ 27 }) it ({ 28 }) must ({ 29 }) be ({ 30 }) a ({ 31 }) protein ({ 32 }) reference ({ 33 }) . ({ 34 }) 
# Sentence pair (2532) source length 24 target length 24 alignment score : 5.74545e-09
For our preliminary experiment , we collect these key words manually by checking the noun phrases containing its and their in training data . 
NULL ({ }) For ({ 1 }) our ({ 2 }) preliminary ({ 3 }) experiment ({ 4 }) , ({ 5 }) we ({ 6 }) collect ({ 7 }) these ({ 8 }) keywords ({ 9 10 }) manually ({ 11 }) by ({ 12 }) checking ({ 13 }) the ({ 14 }) noun ({ 15 }) phrases ({ 16 }) containing ({ 17 }) its ({ 18 }) and ({ 19 }) their ({ 20 }) in ({ 21 }) the ({ }) training ({ 22 }) data ({ 23 }) . ({ 24 }) 
# Sentence pair (2533) source length 35 target length 36 alignment score : 3.87251e-10
Our final protein key word set includes 12 words : binding , expression , interaction , regulation , phosphatase activity , localization , gene , sequence , region , phosphorylation , transactivation , and transcription . 
NULL ({ }) Our ({ 1 }) final ({ 2 }) protein ({ 3 }) keyword ({ 4 5 }) set ({ 6 }) includes ({ 7 }) 12 ({ 8 }) words ({ 9 }) : ({ 10 }) binding ({ 11 }) , ({ 12 }) expression ({ 13 }) , ({ 14 }) interaction ({ 15 }) , ({ 16 }) regulation ({ 17 }) , ({ 18 }) phosphatase ({ 19 }) activity ({ 20 }) , ({ 21 }) localization ({ 22 }) , ({ 23 }) gene ({ 24 }) , ({ 25 }) sequence ({ 26 }) , ({ 27 }) region ({ 28 }) , ({ 29 }) phosphorylation ({ 30 }) , ({ 31 }) transactivation ({ 32 }) , ({ 33 }) and ({ 34 }) transcription ({ 35 }) . ({ 36 }) 
# Sentence pair (2534) source length 22 target length 22 alignment score : 0.000235603
In future , the protein key words can be collected automatically using the term corpus , or other resources of proteins . 
NULL ({ }) In ({ 1 }) future ({ 2 }) , ({ 3 }) the ({ 4 }) protein ({ 5 }) key ({ 6 }) words ({ 7 }) can ({ 8 }) be ({ 9 }) collected ({ 10 }) automatically ({ 11 }) using ({ 12 }) the ({ 13 }) term ({ 14 }) corpus ({ 15 }) , ({ 16 }) or ({ 17 }) other ({ 18 }) resources ({ 19 }) of ({ 20 }) proteins ({ 21 }) . ({ 22 }) 
# Sentence pair (2535) source length 16 target length 14 alignment score : 5.82946e-07
Coreferential definite noun phrases in text are used in broader meaning of coreference . 
NULL ({ }) Coreferential ({ 1 }) definite ({ 2 }) noun ({ 3 }) phrases ({ 4 }) in ({ 5 }) text ({ 6 }) are ({ 7 }) used ({ 8 }) to ({ }) include ({ 9 }) a ({ }) broader ({ 10 }) definition ({ 11 }) of ({ 12 }) coreference ({ 13 }) . ({ 14 }) 
# Sentence pair (2536) source length 51 target length 44 alignment score : 1.48222e-16
In other words , their antecedents do not necessarily exist in the textual context ; in particular in biomedical scientific papers , many definite noun phrases do not have antecedents since the referred concepts can be anything understood by experts in the domain . 
NULL ({ }) In ({ 1 }) other ({ 2 }) words ({ 3 }) , ({ 4 }) their ({ 5 }) antecedents ({ 6 }) do ({ 7 }) not ({ 8 }) necessarily ({ 9 }) exist ({ 10 }) in ({ 11 }) the ({ 12 }) textual ({ 13 }) context ({ 14 }) ; ({ 15 }) in ({ 16 }) particular ({ 17 }) , ({ }) in ({ 18 }) biomedical ({ 19 }) scientific ({ 20 }) papers ({ 21 }) , ({ 22 }) many ({ 23 }) definite ({ 24 }) noun ({ 25 }) phrases ({ 26 }) do ({ 27 }) not ({ 28 }) have ({ 29 }) antecedents ({ 30 }) , ({ }) since ({ 31 }) the ({ 32 }) referenced ({ 33 }) concepts ({ 34 }) can ({ 35 }) include ({ 36 }) any ({ }) concept ({ 37 }) that ({ }) is ({ }) understood ({ 38 }) by ({ }) subject ({ }) matter ({ 39 }) experts ({ 40 }) in ({ 41 }) the ({ 42 }) domain ({ 43 }) . ({ 44 }) 
# Sentence pair (2537) source length 14 target length 14 alignment score : 3.82813e-07
Distinguishing such non-anaphoric definite noun phrases from anaphoric ones is an uneasy task . 
NULL ({ }) Distinguishing ({ 1 }) such ({ 2 }) non-anaphoric ({ 3 }) definite ({ 4 }) noun ({ 5 }) phrases ({ 6 }) from ({ 7 }) anaphoric ({ 8 }) ones ({ 9 }) is ({ 10 }) a ({ 11 }) difficult ({ 12 }) task ({ 13 }) . ({ 14 }) 
# Sentence pair (2538) source length 31 target length 27 alignment score : 9.15881e-13
Knowing their semantic type helps to filter out irrelevant candidate antecedents , increasing chance to pick up the right antecedent or the precision of antecedent prediction . 
NULL ({ }) Knowing ({ 1 }) their ({ 2 }) semantic ({ 3 }) type ({ 4 }) helps ({ 5 }) to ({ 6 }) filter ({ 7 }) out ({ 8 }) irrelevant ({ 9 }) candidate ({ 10 }) antecedents ({ 11 }) , ({ }) thereby ({ 12 }) increasing ({ 13 }) the ({ }) chance ({ 14 }) of ({ 15 }) picking ({ 16 }) up ({ 17 }) the ({ 18 }) right ({ 19 }) antecedent ({ 20 }) , ({ }) and ({ }) increasing ({ 21 }) the ({ 22 }) precision ({ 23 }) of ({ 24 }) antecedent ({ 25 }) prediction ({ 26 }) . ({ 27 }) 
# Sentence pair (2539) source length 30 target length 29 alignment score : 5.88388e-06
In our implementation , decision to keep an anaphoric expression for further processing steps for an anaphoric definite noun phrase is based on a protein head word list . 
NULL ({ }) In ({ 1 }) our ({ 2 }) implementation ({ 3 }) , ({ 4 }) the ({ }) decision ({ 5 }) to ({ 6 }) keep ({ 7 }) an ({ 8 }) anaphoric ({ 9 }) expression ({ 10 }) for ({ 11 }) further ({ 12 }) processing ({ 13 }) steps ({ 14 }) for ({ 15 }) an ({ 16 }) anaphoric ({ 17 }) definite ({ 18 }) noun ({ 19 }) phrase ({ 20 }) is ({ 21 }) based ({ 22 }) on ({ 23 }) a ({ 24 }) protein ({ 25 }) head ({ 26 }) word ({ 27 }) list ({ 28 }) . ({ 29 }) 
# Sentence pair (2540) source length 50 target length 49 alignment score : 1.5711e-09
We tested two different head word lists : one is built automatically from the gold anaphoric nominals in gold data , the other word list contains top seven common head words : protein , gene , factor , molecule , element , family , inhibitor , and receptor . 
NULL ({ }) We ({ 1 }) tested ({ 2 }) two ({ 3 }) different ({ 4 }) head ({ 5 }) word ({ 6 }) lists ({ 7 }) : ({ 8 }) one ({ 9 }) is ({ 10 }) built ({ 11 }) automatically ({ 12 }) from ({ 13 }) the ({ 14 }) gold ({ 15 }) anaphoric ({ 16 }) nominals ({ 17 }) in ({ 18 }) gold ({ 19 }) data ({ 20 }) ; ({ 21 }) the ({ 22 }) other ({ 23 }) word ({ 24 }) list ({ 25 }) contains ({ 26 }) the ({ }) top ({ 27 }) seven ({ 28 }) common ({ 29 }) head ({ 30 }) words ({ 31 }) : ({ 32 }) protein ({ 33 }) , ({ 34 }) gene ({ 35 }) , ({ 36 }) factor ({ 37 }) , ({ 38 }) molecule ({ 39 }) , ({ 40 }) element ({ 41 }) , ({ 42 }) family ({ 43 }) , ({ 44 }) inhibitor ({ 45 }) , ({ 46 }) and ({ 47 }) receptor ({ 48 }) . ({ 49 }) 
# Sentence pair (2541) source length 13 target length 13 alignment score : 0.00996913
Semantic type information can be used in coreference resolution in several ways . 
NULL ({ }) Semantic ({ 1 }) type ({ 2 }) information ({ 3 }) can ({ 4 }) be ({ 5 }) used ({ 6 }) in ({ 7 }) coreference ({ 8 }) resolution ({ 9 }) in ({ 10 }) several ({ 11 }) ways ({ 12 }) . ({ 13 }) 
# Sentence pair (2542) source length 18 target length 18 alignment score : 0.0014452
First , in anaphor selection , semantic information can be used to filter out non-protein anaphoric expressions . 
NULL ({ }) First ({ 1 }) , ({ 2 }) in ({ 3 }) anaphor ({ 4 }) selection ({ 5 }) , ({ 6 }) semantic ({ 7 }) information ({ 8 }) can ({ 9 }) be ({ 10 }) used ({ 11 }) to ({ 12 }) filter ({ 13 }) out ({ 14 }) non-protein ({ 15 }) anaphoric ({ 16 }) expressions ({ 17 }) . ({ 18 }) 
# Sentence pair (2543) source length 20 target length 20 alignment score : 0.000755105
Second , in antecedent candidate filtering , semantic agreement between the antecedent candidates and the anaphoric expression is checked . 
NULL ({ }) Second ({ 1 }) , ({ 2 }) in ({ 3 }) antecedent ({ 4 }) candidate ({ 5 }) filtering ({ 6 }) , ({ 7 }) semantic ({ 8 }) agreement ({ 9 }) between ({ 10 }) the ({ 11 }) antecedent ({ 12 }) candidates ({ 13 }) and ({ 14 }) the ({ 15 }) anaphoric ({ 16 }) expression ({ 17 }) is ({ 18 }) checked ({ 19 }) . ({ 20 }) 
# Sentence pair (2544) source length 16 target length 15 alignment score : 1.60431e-06
Those candidates which are not agree with the anaphor in semantics are filtered out . 
NULL ({ }) Those ({ 1 }) candidates ({ 2 }) that ({ 3 }) are ({ 4 }) not ({ 5 }) in ({ }) agreement ({ 6 }) with ({ 7 }) the ({ 8 }) anaphor ({ 9 }) in ({ 10 }) semantics ({ 11 }) are ({ 12 }) filtered ({ 13 }) out ({ 14 }) . ({ 15 }) 
# Sentence pair (2545) source length 28 target length 25 alignment score : 5.29042e-07
For example , if anaphor is classified as protein referent , then non-protein antecedent candidates are removed from the candidate set of the anaphor . 
NULL ({ }) For ({ 1 }) example ({ 2 }) , ({ 3 }) if ({ 4 }) an ({ }) anaphor ({ 5 }) is ({ 6 }) classified ({ 7 }) as ({ 8 }) a ({ }) protein ({ 9 }) referent ({ 10 }) , ({ 11 }) then ({ 12 }) the ({ }) non-protein ({ 13 }) antecedent ({ 14 }) candidates ({ 15 }) are ({ 16 }) removed ({ 17 }) from ({ 18 }) the ({ 19 }) candidate ({ 20 }) set ({ 21 }) of ({ 22 }) the ({ 23 }) anaphor ({ 24 }) . ({ 25 }) 
# Sentence pair (2546) source length 27 target length 27 alignment score : 1.10213e-06
Finally , in antecedent prediction : semantic agreement again can be used as a constraint when comparing two antecedent candidates to select the more probable candidate . 
NULL ({ }) Finally ({ 1 }) , ({ 2 }) in ({ 3 }) antecedent ({ 4 }) prediction ({ 5 }) : ({ 6 }) semantic ({ 7 }) agreement ({ 8 }) can ({ 10 }) again ({ 9 }) be ({ 11 }) used ({ 12 }) as ({ 13 }) a ({ 14 }) constraint ({ 15 }) when ({ 16 }) comparing ({ 17 }) two ({ 18 }) antecedent ({ 19 }) candidates ({ 20 }) to ({ 21 }) select ({ 22 }) the ({ 23 }) more ({ 24 }) probable ({ 25 }) candidate ({ 26 }) . ({ 27 }) 
# Sentence pair (2547) source length 28 target length 26 alignment score : 1.46086e-09
Our minimal system configuration includes all the processing and filters from step 0 to step 3 as explained in the above section ( RB-MIN ) . 
NULL ({ }) Our ({ 1 }) minimal ({ 2 }) system ({ 3 }) configuration ({ 4 }) includes ({ 5 }) all ({ 6 }) of ({ }) the ({ 7 }) processing ({ 8 }) and ({ 9 }) filters ({ 10 }) from ({ 11 }) step ({ 12 }) 0 ({ 13 }) to ({ 14 }) step ({ 15 }) 3 ({ 16 }) , ({ }) as ({ 17 }) explained ({ 18 }) in ({ 19 }) the ({ 20 }) section ({ 22 }) above ({ 21 }) ( ({ 23 }) RB-MIN ({ 24 }) ) ({ 25 }) . ({ 26 }) 
# Sentence pair (2548) source length 40 target length 39 alignment score : 3.00038e-08
For antecedent candidate selection , the window size used in step 4 is set to 2 , which means antecedent candidates are collected in the two nearest sentences from the anaphor , and the sentence embedding the anaphor . 
NULL ({ }) For ({ 1 }) antecedent ({ 2 }) candidate ({ 3 }) selection ({ 4 }) , ({ 5 }) the ({ 6 }) window ({ 7 }) size ({ 8 }) used ({ 9 }) in ({ 10 }) step ({ 11 }) 4 ({ 12 }) is ({ 13 }) set ({ 14 }) to ({ 15 }) 2 ({ 16 }) , ({ 17 }) which ({ 18 }) means ({ 19 }) that ({ }) antecedent ({ 20 }) candidates ({ 21 }) are ({ 22 }) collected ({ 23 }) in ({ 24 }) the ({ 25 }) two ({ 26 }) nearest ({ 27 }) sentences ({ 28 }) from ({ 29 }) the ({ 30 }) anaphor ({ 31 }) , ({ 32 }) and ({ 33 }) the ({ 34 }) sentence ({ 35 }) embedding ({ 36 }) the ({ 37 }) anaphor ({ 38 }) . ({ 39 }) 
# Sentence pair (2549) source length 27 target length 28 alignment score : 2.9732e-09
As the statistics measured on the training set of the corpus shows that 97 .0% percent of protein coreference links have antecedents appearing in within 2 sentences . 
NULL ({ 2 }) The ({ 1 }) statistics ({ 3 }) measured ({ 4 }) on ({ 5 }) the ({ 6 }) training ({ 7 }) set ({ 8 }) of ({ 9 }) the ({ 10 }) corpus ({ 11 }) shows ({ 12 }) that ({ 13 }) 97 ({ 14 }) .0% ({ 15 }) percent ({ 16 }) of ({ 17 }) protein ({ 18 }) coreference ({ 19 }) links ({ 20 }) have ({ 21 }) antecedents ({ 22 }) appearing ({ 23 }) in ({ 24 }) within ({ 25 }) 2 ({ 26 }) sentences ({ 27 }) . ({ 28 }) 
# Sentence pair (2550) source length 16 target length 16 alignment score : 0.00352669
With this window size , the average number of candidates per anaphor is 6 .1 . 
NULL ({ }) With ({ 1 }) this ({ 2 }) window ({ 3 }) size ({ 4 }) , ({ 5 }) the ({ 6 }) average ({ 7 }) number ({ 8 }) of ({ 9 }) candidates ({ 10 }) per ({ 11 }) anaphor ({ 12 }) is ({ 13 }) 6 ({ 14 }) .1 ({ 15 }) . ({ 16 }) 
# Sentence pair (2551) source length 11 target length 11 alignment score : 0.0104504
Also , experiments with wider window sizes did not help . 
NULL ({ }) Also ({ 1 }) , ({ 2 }) experiments ({ 3 }) with ({ 4 }) wider ({ 5 }) window ({ 6 }) sizes ({ 7 }) did ({ 8 }) not ({ 9 }) help ({ 10 }) . ({ 11 }) 
# Sentence pair (2552) source length 36 target length 35 alignment score : 1.4447e-07
The word list used to filter out anaphoric definite noun phrases in step 2 contains the following words : protein , gene , factor , molecule , element ,family , inhibitor , and receptor . 
NULL ({ }) The ({ 1 }) word ({ 2 }) list ({ 3 }) used ({ 4 }) to ({ 5 }) filter ({ 6 }) out ({ 7 }) anaphoric ({ 8 }) definite ({ 9 }) noun ({ 10 }) phrases ({ 11 }) in ({ 12 }) step ({ 13 }) 2 ({ 14 }) contains ({ 15 }) the ({ 16 }) following ({ 17 }) words ({ 18 }) : ({ 19 }) protein ({ 20 }) , ({ 21 }) gene ({ 22 }) , ({ 23 }) factor ({ 24 }) , ({ 25 }) molecule ({ 26 }) , ({ 27 }) element ({ 28 }) , ({ }) family ({ 29 }) , ({ 30 }) inhibitor ({ 31 }) , ({ 32 }) and ({ 33 }) receptor ({ 34 }) . ({ 35 }) 
# Sentence pair (2553) source length 16 target length 16 alignment score : 0.00045907
These words are selected from the top appearring head words extracted from the training data . 
NULL ({ }) These ({ 1 }) words ({ 2 }) are ({ 3 }) selected ({ 4 }) from ({ 5 }) the ({ 6 }) top ({ 7 }) appearing ({ 8 }) head ({ 9 }) words ({ 10 }) extracted ({ 11 }) from ({ 12 }) the ({ 13 }) training ({ 14 }) data ({ 15 }) . ({ 16 }) 
# Sentence pair (2554) source length 23 target length 23 alignment score : 7.27089e-11
Besides , premodifiers of definite noun phrases are also limited to numbers and popular premodifiers of proteins such as nuclear , transcription . 
NULL ({ 2 }) Premodifiers ({ 1 3 }) of ({ 4 }) definite ({ 5 }) noun ({ 6 }) phrases ({ 7 }) are ({ 8 }) also ({ 9 }) limited ({ 10 }) to ({ 11 }) numbers ({ 12 }) and ({ 13 }) popular ({ 14 }) premodifiers ({ 15 }) of ({ 16 }) proteins ({ 17 }) , ({ }) such ({ 18 }) as ({ 19 }) nuclear ({ 20 }) , ({ 21 }) and ({ }) transcription ({ 22 }) . ({ 23 }) 
# Sentence pair (2555) source length 19 target length 19 alignment score : 0.00105269
Using this head word list and premodifiers , the system covers 83 .5 percent of the coreference links . 
NULL ({ }) Using ({ 1 }) this ({ 2 }) head ({ 3 }) word ({ 4 }) list ({ 5 }) and ({ 6 }) premodifiers ({ 7 }) , ({ 8 }) the ({ 9 }) system ({ 10 }) covers ({ 11 }) 83 ({ 12 }) .5 ({ 13 }) percent ({ 14 }) of ({ 15 }) the ({ 16 }) coreference ({ 17 }) links ({ 18 }) . ({ 19 }) 
# Sentence pair (2556) source length 32 target length 31 alignment score : 1.29401e-06
To keep the minimal configuration simple , step 4 - antecedent selection of the baseline only uses the default comparison rule , which assures the closest antecedent candidate is selected . 
NULL ({ }) To ({ 1 }) keep ({ 2 }) the ({ 3 }) minimal ({ 4 }) configuration ({ 5 }) simple ({ 6 }) , ({ 7 }) step ({ 8 }) 4 ({ 9 }) - ({ 10 }) antecedent ({ 11 }) selection ({ 12 }) of ({ 13 }) the ({ 14 }) baseline ({ 15 }) only ({ 16 }) uses ({ 17 }) the ({ 18 }) default ({ 19 }) comparison ({ 20 }) rule ({ 21 }) , ({ 22 }) which ({ 23 }) assures ({ 24 }) that ({ }) the ({ 25 }) closest ({ 26 }) antecedent ({ 27 }) candidate ({ 28 }) is ({ 29 }) selected ({ 30 }) . ({ 31 }) 
# Sentence pair (2557) source length 41 target length 41 alignment score : 4.48485e-07
Table 2 compares our system with the top four official results of the COREF shared task in BioNLP-ST 2011 [ 18 ] : UU [ 11 ] , UZ [ 29 ] , CU , and UT [ 4 ] . 
NULL ({ }) Table ({ 1 }) 2 ({ 2 }) compares ({ 3 }) our ({ 4 }) system ({ 5 }) with ({ 6 }) the ({ 7 }) top ({ 8 }) four ({ 9 }) official ({ 10 }) results ({ 11 }) of ({ 12 }) the ({ 13 }) COREF ({ 14 }) shared ({ 15 }) task ({ 16 }) in ({ 17 }) BioNLP-ST ({ 18 }) 2011 ({ 19 }) [ ({ 20 }) 18 ({ 21 }) ] ({ 22 }) : ({ 23 }) UU ({ 24 }) [ ({ 25 }) 11 ({ 26 }) ] ({ 27 }) , ({ 28 }) UZ ({ 29 }) [ ({ 30 }) 29 ({ 31 }) ] ({ 32 }) , ({ 33 }) CU ({ 34 }) , ({ 35 }) and ({ 36 }) UT ({ 37 }) [ ({ 38 }) 4 ({ 39 }) ] ({ 40 }) . ({ 41 }) 
# Sentence pair (2558) source length 26 target length 26 alignment score : 6.79675e-05
The scoring scheme used throughout this paper is the protein coreference evaluation , the primary evaluation method of the COREF shared task [ 18 ] . 
NULL ({ }) The ({ 1 }) scoring ({ 2 }) scheme ({ 3 }) used ({ 4 }) throughout ({ 5 }) this ({ 6 }) paper ({ 7 }) is ({ 8 }) the ({ 9 }) protein ({ 10 }) coreference ({ 11 }) evaluation ({ 12 }) , ({ 13 }) the ({ 14 }) primary ({ 15 }) evaluation ({ 16 }) method ({ 17 }) of ({ 18 }) the ({ 19 }) COREF ({ 20 }) shared ({ 21 }) task ({ 22 }) [ ({ 23 }) 18 ({ 24 }) ] ({ 25 }) . ({ 26 }) 
# Sentence pair (2559) source length 31 target length 28 alignment score : 9.28648e-08
This primary evaluation method , which was particularly designed for the shared task , is based on protein coreference links automatically generated from manually annotated coreference links . 
NULL ({ }) This ({ 1 }) primary ({ 2 }) evaluation ({ 3 }) method ({ 4 }) , ({ 5 }) which ({ 6 }) was ({ 7 }) particularly ({ 8 }) designed ({ 9 }) for ({ 10 }) the ({ 11 }) shared ({ 12 }) task ({ 13 }) , ({ 14 }) is ({ 15 }) based ({ 16 }) on ({ 17 }) protein ({ 18 }) coreference ({ 19 }) links ({ 20 }) that ({ }) have ({ }) been ({ }) automatically ({ 21 }) generated ({ 22 }) from ({ 23 }) manually ({ 24 }) annotated ({ 25 }) coreference ({ 26 }) links ({ 27 }) . ({ 28 }) 
# Sentence pair (2560) source length 43 target length 43 alignment score : 1.06618e-07
The last column ALL shows the overall results , while its preceding three columns PRON , DNP , and RELAT shows the protein resolution results by three major subtypes of anaphors : pronouns , definite noun phrase and relative pronouns , respectively . 
NULL ({ }) The ({ 1 }) last ({ 2 }) column ({ 3 }) ALL ({ 4 }) shows ({ 5 }) the ({ 6 }) overall ({ 7 }) results ({ 8 }) , ({ 9 }) while ({ 10 }) its ({ 11 }) preceding ({ 12 }) three ({ 13 }) columns ({ 14 }) PRON ({ 15 }) , ({ 16 }) DNP ({ 17 }) , ({ 18 }) and ({ 19 }) RELAT ({ 20 }) shows ({ 21 }) the ({ 22 }) protein ({ 23 }) resolution ({ 24 }) results ({ 25 }) by ({ 26 }) three ({ 27 }) major ({ 28 }) subtypes ({ 29 }) of ({ 30 }) anaphors ({ 31 }) : ({ 32 }) pronouns ({ 33 }) , ({ 34 }) definite ({ 35 }) noun ({ 36 }) phrase ({ 37 }) and ({ 38 }) relative ({ 39 }) pronouns ({ 40 }) , ({ 41 }) respectively ({ 42 }) . ({ 43 }) 
# Sentence pair (2561) source length 31 target length 25 alignment score : 1.85135e-14
Note that RB-MIN with minimal configuration already outperforms the best result by the UU team , with up to 7 .1% higher in Fscore . 
NULL ({ }) Note ({ 1 }) that ({ 2 }) the ({ }) results ({ }) from ({ }) RB-MIN ({ 3 }) with ({ 4 }) minimal ({ 5 }) configuration ({ 6 }) , ({ }) already ({ 7 }) surpasses ({ 8 }) the ({ 9 }) best ({ 10 }) results ({ 11 }) obtained ({ }) by ({ 12 }) the ({ 13 }) UU ({ 14 }) team ({ 15 }) , ({ 16 }) with ({ 17 }) up ({ 18 }) to ({ 19 }) 7 ({ 20 }) .1% ({ 21 }) higher ({ 22 }) performance ({ }) in ({ 23 }) F-score ({ 24 }) . ({ 25 }) 
# Sentence pair (2562) source length 33 target length 35 alignment score : 2.56382e-11
Since RB-MIN uses similar preprocessing tools as UU [ 11 ] , but less information in antecedent prediction , this gap in performance is supposed to be caused by the different markable detection methods . 
NULL ({ 26 27 }) Since ({ 1 }) RB-MIN ({ 2 }) uses ({ 3 }) similar ({ 4 }) preprocessing ({ 5 }) tools ({ 6 }) as ({ 7 }) UU ({ 8 }) [ ({ 9 }) 11 ({ 10 }) ] ({ 11 }) , ({ 12 }) but ({ 13 }) less ({ 14 }) information ({ 15 }) in ({ 16 }) antecedent ({ 17 }) prediction ({ 18 }) , ({ 19 }) this ({ 20 }) gap ({ 21 }) in ({ 22 }) performance ({ 23 }) is ({ 24 }) likely ({ 25 }) caused ({ 28 }) by ({ 29 }) the ({ 30 }) different ({ 31 }) markable ({ 32 }) detection ({ 33 }) methods ({ 34 }) . ({ 35 }) 
# Sentence pair (2563) source length 20 target length 20 alignment score : 0.000576128
UU pointed in their paper that markable detection is one of the challenges of this task [ 11 ] . 
NULL ({ }) UU ({ 1 }) pointed ({ 2 }) in ({ 3 }) their ({ 4 }) paper ({ 5 }) that ({ 6 }) markable ({ 7 }) detection ({ 8 }) is ({ 9 }) one ({ 10 }) of ({ 11 }) the ({ 12 }) challenges ({ 13 }) of ({ 14 }) this ({ 15 }) task ({ 16 }) [ ({ 17 }) 11 ({ 18 }) ] ({ 19 }) . ({ 20 }) 
# Sentence pair (2564) source length 36 target length 36 alignment score : 3.80566e-06
In their system , UU used a machine learning approach , and tested two distinguished models for markable detection : one solved both anaphors and antecedents together , the other treated anaphors and antecedents separately . 
NULL ({ }) In ({ 1 }) their ({ 2 }) system ({ 3 }) , ({ 4 }) UU ({ 5 }) used ({ 6 }) a ({ 7 }) machine ({ 8 }) learning ({ 9 }) approach ({ 10 }) , ({ 11 }) and ({ 12 }) tested ({ 13 }) two ({ 14 }) distinguished ({ 15 }) models ({ 16 }) for ({ 17 }) markable ({ 18 }) detection ({ 19 }) : ({ 20 }) one ({ 21 }) solved ({ 22 }) both ({ 23 }) anaphors ({ 24 }) and ({ 25 }) antecedents ({ 26 }) together ({ 27 }) , ({ 28 }) the ({ 29 }) other ({ 30 }) treated ({ 31 }) anaphors ({ 32 }) and ({ 33 }) antecedents ({ 34 }) separately ({ 35 }) . ({ 36 }) 
# Sentence pair (2565) source length 23 target length 23 alignment score : 0.000205519
Meanwhile , our method is basically based on the boundary of noun phrases and pronouns , as is outputted from the parser . 
NULL ({ }) Meanwhile ({ 1 }) , ({ 2 }) our ({ 3 }) method ({ 4 }) is ({ 5 }) basically ({ 6 }) based ({ 7 }) on ({ 8 }) the ({ 9 }) boundary ({ 10 }) of ({ 11 }) noun ({ 12 }) phrases ({ 13 }) and ({ 14 }) pronouns ({ 15 }) , ({ 16 }) as ({ 17 }) is ({ 18 }) outputted ({ 19 }) from ({ 20 }) the ({ 21 }) parser ({ 22 }) . ({ 23 }) 
# Sentence pair (2566) source length 25 target length 25 alignment score : 4.93629e-05
The patterns used to extract the proper noun phrases and pronouns , are manually designed concerning the markable boundaries annotated in the training data . 
NULL ({ }) The ({ 1 }) patterns ({ 2 }) used ({ 3 }) to ({ 4 }) extract ({ 5 }) the ({ 6 }) proper ({ 7 }) noun ({ 8 }) phrases ({ 9 }) and ({ 10 }) pronouns ({ 11 }) , ({ 12 }) are ({ 13 }) manually ({ 14 }) designed ({ 15 }) concerning ({ 16 }) the ({ 17 }) markable ({ 18 }) boundaries ({ 19 }) annotated ({ 20 }) in ({ 21 }) the ({ 22 }) training ({ 23 }) data ({ 24 }) . ({ 25 }) 
# Sentence pair (2567) source length 34 target length 29 alignment score : 5.65141e-26
Breaking down the system performance by types of anaphors gives us an insight into what have been solved by our methods , and what needs more improvement effort . 
NULL ({ }) Breaking ({ 1 }) down ({ 2 }) the ({ 3 }) system ({ 4 }) performance ({ 5 }) by ({ 6 }) the ({ }) different ({ }) types ({ 7 }) of ({ 8 }) anaphors ({ 9 }) provides ({ 10 }) us ({ 11 }) with ({ }) insight ({ 12 13 }) into ({ 14 }) what ({ 15 }) has ({ 16 }) been ({ 17 }) accomplished ({ 26 }) / ({ }) solved ({ 18 }) by ({ 19 }) our ({ 20 }) methods ({ 21 }) , ({ 22 }) and ({ 23 }) also ({ 25 }) provides ({ }) us ({ 24 }) with ({ }) improvement ({ 27 }) opportunities ({ 28 }) . ({ 29 }) 
# Sentence pair (2568) source length 26 target length 26 alignment score : 8.61117e-05
Concerning the RELAT type of coreference , we can see that RB-MIN and RB-FULL both achieve comparable results with the best team in BioNLP-ST 2011 . 
NULL ({ }) Concerning ({ 1 }) the ({ 2 }) RELAT ({ 3 }) type ({ 4 }) of ({ 5 }) coreference ({ 6 }) , ({ 7 }) we ({ 8 }) can ({ 9 }) see ({ 10 }) that ({ 11 }) RB-MIN ({ 12 }) and ({ 13 }) RB-FULL ({ 14 }) both ({ 15 }) achieve ({ 16 }) comparable ({ 17 }) results ({ 18 }) with ({ 19 }) the ({ 20 }) best ({ 21 }) team ({ 22 }) in ({ 23 }) BioNLP-ST ({ 24 }) 2011 ({ 25 }) . ({ 26 }) 
# Sentence pair (2569) source length 64 target length 63 alignment score : 3.48315e-13
However , it should be noted that our antecedent prediction for the RELAT type is based completely on the output of Enju parser for the RELAT type , so in order to improve this type of coreference , we have to find ways to overcome the parse errors on noun phrase boundary detection and relative clause attachment ( See section Discussions ) . 
NULL ({ }) However ({ 1 }) , ({ 2 }) it ({ 3 }) should ({ 4 }) be ({ 5 }) noted ({ 6 }) that ({ 7 }) our ({ 8 }) antecedent ({ 9 }) prediction ({ 10 }) for ({ 11 }) the ({ 12 }) RELAT ({ 13 }) type ({ 14 }) is ({ 15 }) based ({ 16 }) solely ({ 17 }) on ({ 18 }) the ({ 19 }) output ({ 20 }) of ({ 21 }) the ({ }) Enju ({ 22 }) parser ({ 23 }) for ({ 24 }) the ({ 25 }) RELAT ({ 26 }) type ({ 27 }) , ({ 28 }) so ({ 29 }) in ({ 30 }) order ({ 31 }) to ({ 32 }) improve ({ 33 }) this ({ 34 }) type ({ 35 }) of ({ 36 }) coreference ({ 37 }) , ({ 38 }) we ({ 39 }) have ({ 40 }) to ({ 41 }) find ({ 42 }) ways ({ 43 }) to ({ 44 }) overcome ({ 45 }) the ({ 46 }) parse ({ 47 }) errors ({ 48 }) on ({ 49 }) noun ({ 50 }) phrase ({ 51 }) boundary ({ 52 }) detection ({ 53 }) and ({ 54 }) relative ({ 55 }) clause ({ 56 }) attachment ({ 57 }) ( ({ 58 }) See ({ 59 }) Discussions ({ 61 }) section ({ 60 }) ) ({ 62 }) . ({ 63 }) 
# Sentence pair (2570) source length 29 target length 29 alignment score : 3.44145e-05
The increase in system performance on the PRON and DNP types by RB-FULL demonstrate the effectiveness of discourse and semantic information in the performance of protein coreference resolution . 
NULL ({ }) The ({ 1 }) increase ({ 2 }) in ({ 3 }) system ({ 4 }) performance ({ 5 }) on ({ 6 }) the ({ 7 }) PRON ({ 8 }) and ({ 9 }) DNP ({ 10 }) types ({ 11 }) by ({ 12 }) RB-FULL ({ 13 }) demonstrate ({ 14 }) the ({ 15 }) effectiveness ({ 16 }) of ({ 17 }) discourse ({ 18 }) and ({ 19 }) semantic ({ 20 }) information ({ 21 }) in ({ 22 }) the ({ 23 }) performance ({ 24 }) of ({ 25 }) protein ({ 26 }) coreference ({ 27 }) resolution ({ 28 }) . ({ 29 }) 
# Sentence pair (2571) source length 31 target length 31 alignment score : 9.05169e-06
Comparing RB-MIN , RB-FULL and RB-MIN+1 , 3 , we found that rule 3 , which stands for discourse preference , works well for the PRON type ( 2 ) . 
NULL ({ }) Comparing ({ 1 }) RB-MIN ({ 2 }) , ({ 3 }) RB-FULL ({ 4 }) and ({ 5 }) RB-MIN+1 ({ 6 }) , ({ 7 }) 3 ({ 8 }) , ({ 9 }) we ({ 10 }) found ({ 11 }) that ({ 12 }) rule ({ 13 }) 3 ({ 14 }) , ({ 15 }) which ({ 16 }) stands ({ 17 }) for ({ 18 }) discourse ({ 19 }) preference ({ 20 }) , ({ 21 }) works ({ 22 }) well ({ 23 }) for ({ 24 }) the ({ 25 }) PRON ({ 26 }) type ({ 27 }) ( ({ 28 }) 2 ({ 29 }) ) ({ 30 }) . ({ 31 }) 
# Sentence pair (2572) source length 19 target length 19 alignment score : 0.000516611
On the other hand , the major contribution to the improvement of DNP resolution is from rule 2 . 
NULL ({ }) On ({ 1 }) the ({ 2 }) other ({ 3 }) hand ({ 4 }) , ({ 5 }) the ({ 6 }) major ({ 7 }) contribution ({ 8 }) to ({ 9 }) the ({ 10 }) improvement ({ 11 }) of ({ 12 }) DNP ({ 13 }) resolution ({ 14 }) is ({ 15 }) from ({ 16 }) rule ({ 17 }) 2 ({ 18 }) . ({ 19 }) 
# Sentence pair (2573) source length 17 target length 17 alignment score : 0.000536771
This rule successfully utilizes the domain-specific information , which shows that coreference resolution requires domain-specific information . 
NULL ({ }) This ({ 1 }) rule ({ 2 }) successfully ({ 3 }) utilizes ({ 4 }) the ({ 5 }) domain-specific ({ 6 }) information ({ 7 }) , ({ 8 }) which ({ 9 }) shows ({ 10 }) that ({ 11 }) coreference ({ 12 }) resolution ({ 13 }) requires ({ 14 }) domain-specific ({ 15 }) information ({ 16 }) . ({ 17 }) 
# Sentence pair (2574) source length 19 target length 19 alignment score : 0.000232806
To further explore the elements contributed to this significant improvement , we analyzed our system in more details . 
NULL ({ }) To ({ 1 }) further ({ 2 }) explore ({ 3 }) the ({ 4 }) elements ({ 5 }) contributed ({ 6 }) to ({ 7 }) this ({ 8 }) significant ({ 9 }) improvement ({ 10 }) , ({ 11 }) we ({ 12 }) analyzed ({ 13 }) our ({ 14 }) system ({ 15 }) in ({ 16 }) more ({ 17 }) detail ({ 18 }) . ({ 19 }) 
# Sentence pair (2575) source length 13 target length 9 alignment score : 7.96335e-07
The analysis results are given in section Discussions . 
NULL ({ }) The ({ 1 }) analyses ({ 2 }) of ({ }) the ({ }) results ({ 3 }) are ({ 4 }) provided ({ 5 }) in ({ 6 }) the ({ }) section ({ }) entitled ({ 7 }) Discussions ({ 8 }) . ({ 9 }) 
# Sentence pair (2576) source length 2 target length 2 alignment score : 0.489632
" > 
NULL ({ }) " ({ 1 }) > ({ 2 }) 
# Sentence pair (2577) source length 10 target length 10 alignment score : 0.027606
Table 3 compares various configurations of the rule-based system . 
NULL ({ }) Table ({ 1 }) 3 ({ 2 }) compares ({ 3 }) various ({ 4 }) configurations ({ 5 }) of ({ 6 }) the ({ 7 }) rule-based ({ 8 }) system ({ 9 }) . ({ 10 }) 
# Sentence pair (2578) source length 10 target length 10 alignment score : 0.0222772
The first , RB-MIN , is the minimal system . 
NULL ({ }) The ({ 1 }) first ({ 2 }) , ({ 3 }) RB-MIN ({ 4 }) , ({ 5 }) is ({ 6 }) the ({ 7 }) minimal ({ 8 }) system ({ 9 }) . ({ 10 }) 
# Sentence pair (2579) source length 18 target length 17 alignment score : 0.000376943
The following three show contribution of the three rules , NUM-AGREE , SEM-CONS , and DISC-PREF . 
NULL ({ }) The ({ 1 }) following ({ 2 }) three ({ 3 }) show ({ 4 }) the ({ }) contribution ({ 5 }) of ({ 6 }) the ({ 7 }) three ({ 8 }) rules ({ 9 }) , ({ 10 }) NUM-AGREE ({ 11 }) , ({ 12 }) SEM-CONS ({ 13 }) , ({ 14 }) and ({ 15 }) DISC-PREF ({ 16 }) . ({ 17 }) 
# Sentence pair (2580) source length 6 target length 6 alignment score : 0.120563
RB-FULL is the full system . 
NULL ({ }) RB-FULL ({ 1 }) is ({ 2 }) the ({ 3 }) full ({ 4 }) system ({ 5 }) . ({ 6 }) 
# Sentence pair (2581) source length 15 target length 15 alignment score : 0.00340758
To emphasize the contribution of the semantic rules , it also shows RB-FULL-sem system . 
NULL ({ }) To ({ 1 }) emphasize ({ 2 }) the ({ 3 }) contribution ({ 4 }) of ({ 5 }) the ({ 6 }) semantic ({ 7 }) rules ({ 8 }) , ({ 9 }) it ({ 10 }) also ({ 11 }) shows ({ 12 }) RB-FULL-sem ({ 13 }) system ({ 14 }) . ({ 15 }) 
# Sentence pair (2582) source length 65 target length 66 alignment score : 1.45773e-30
The combination of rule 1 , 2 and 3 resulted in 62 .4% fscore ( RB-MIN+1 , 2 , 3 ) ( Table 3 ) In this configuration , rule 2 contribute to the increasement of 4 points Fscore on the development set , and 2 .3 points Fscore on the test set , when comparing RB-MIN+1 , 3 and RB-MIN+1 , 2 , 3 . 
NULL ({ 34 36 }) The ({ 1 }) combination ({ 2 }) of ({ 3 }) rule ({ 4 }) 1 ({ 5 }) , ({ 6 }) 2 ({ 7 }) and ({ 8 }) 3 ({ 9 }) resulted ({ 10 }) in ({ 11 }) a ({ }) 62 ({ 12 }) .4% ({ 13 }) F-score ({ 14 }) ( ({ 15 }) RB-MIN+1 ({ 16 }) , ({ 17 }) 2 ({ 18 }) , ({ 19 }) 3 ({ 20 }) ) ({ 21 }) ( ({ 22 }) Table ({ 23 }) 3 ({ 24 }) ) ({ 25 }) In ({ 26 }) this ({ 27 }) configuration ({ 28 }) , ({ 29 }) rule ({ 30 }) 2 ({ 31 }) contributes ({ 32 }) to ({ 33 }) a ({ }) 4-point ({ 35 38 }) F-score ({ 37 39 }) increase ({ 40 }) in ({ }) the ({ 41 }) development ({ 42 }) set ({ 43 }) , ({ 44 }) and ({ 45 }) 2 ({ 46 }) .3-point ({ 47 48 }) F-score ({ 49 }) increase ({ }) on ({ 50 }) the ({ 51 }) test ({ 52 }) set ({ 53 }) , ({ 54 }) when ({ 55 }) comparing ({ 56 }) RB-MIN+1 ({ 57 }) , ({ 58 }) 3 ({ 59 }) and ({ 60 }) RB-MIN+1 ({ 61 }) , ({ 62 }) 2 ({ 63 }) , ({ 64 }) 3 ({ 65 }) . ({ 66 }) 
# Sentence pair (2583) source length 18 target length 18 alignment score : 3.12655e-11
However , the result of RB-MIN is more than still 7 points higher than the state-of-the-art performance . 
NULL ({ 15 }) However ({ 1 }) , ({ 2 }) the ({ 3 }) result ({ 4 }) of ({ 5 }) RB-MIN ({ 6 }) is ({ 7 }) still ({ 10 }) more ({ 8 }) than ({ 9 }) 7 ({ 11 }) points ({ 12 }) higher ({ 13 }) than ({ 14 }) in ({ }) state-of-the-art ({ 16 }) performance ({ 17 }) . ({ 18 }) 
# Sentence pair (2584) source length 33 target length 30 alignment score : 4.49446e-09
This gain is due to the fact that the rule ensures the semantic type of antecedents is the same as their anaphors , enabling the correct detection of antecedents . 
NULL ({ }) This ({ 1 }) gain ({ 2 }) is ({ 3 }) due ({ 4 }) to ({ 5 }) the ({ 6 }) fact ({ 7 }) that ({ 8 }) the ({ 9 }) rule ({ 10 }) ensures ({ 11 }) that ({ }) the ({ 12 }) semantic ({ 13 }) type ({ 14 }) of ({ 15 }) antecedents ({ 16 }) is ({ 17 }) the ({ 18 }) same ({ 19 }) as ({ 20 }) for ({ }) their ({ 21 }) anaphors ({ 22 }) , ({ 23 }) thus ({ }) enabling ({ 24 }) the ({ 25 }) correct ({ 26 }) detection ({ 27 }) of ({ 28 }) antecedents ({ 29 }) . ({ 30 }) 
# Sentence pair (2585) source length 24 target length 22 alignment score : 4.65411e-06
In other words , if anaphor is classified as a protein reference , then antecedent must also be a protein reference . 
NULL ({ }) In ({ 1 }) other ({ 2 }) words ({ 3 }) , ({ 4 }) if ({ 5 }) an ({ }) anaphor ({ 6 }) is ({ 7 }) classified ({ 8 }) as ({ 9 }) a ({ 10 }) protein ({ 11 }) reference ({ 12 }) , ({ 13 }) then ({ 14 }) the ({ }) antecedent ({ 15 }) must ({ 16 }) also ({ 17 }) be ({ 18 }) a ({ 19 }) protein ({ 20 }) reference ({ 21 }) . ({ 22 }) 
# Sentence pair (2586) source length 10 target length 10 alignment score : 0.0173489
The following examples illustrate the way rule 2 works . 
NULL ({ }) The ({ 1 }) following ({ 2 }) examples ({ 3 }) illustrate ({ 4 }) the ({ 5 }) way ({ 6 }) rule ({ 7 }) 2 ({ 8 }) works ({ 9 }) . ({ 10 }) 
# Sentence pair (2587) source length 40 target length 38 alignment score : 4.64884e-12
( Coreference examples in this paper are represented as below : gold anaphoric and antecedent expressions are bracketed , antecedents before anaphors ; gold protein mentions are underlined ; and incorrect response antecedents are in italics . ) 
NULL ({ }) ( ({ 1 }) Coreference ({ 2 }) examples ({ 3 }) in ({ 4 }) this ({ 5 }) paper ({ 6 }) are ({ 7 }) represented ({ 8 }) in ({ }) the ({ }) following ({ 9 }) manner ({ 10 }) : ({ 11 }) gold ({ 12 }) anaphoric ({ 13 }) and ({ 14 }) antecedent ({ 15 }) expressions ({ 16 }) are ({ 17 }) bracketed ({ 18 }) , ({ 19 }) antecedents ({ 20 }) before ({ 21 }) anaphors ({ 22 }) ; ({ 23 }) gold ({ 24 }) protein ({ 25 }) mentions ({ 26 }) are ({ 27 }) underlined ({ 28 }) ; ({ 29 }) and ({ 30 }) incorrect ({ 31 }) response ({ 32 }) antecedents ({ 33 }) are ({ 34 }) in ({ 35 }) italics ({ 36 }) . ({ 37 }) ) ({ 38 }) 
# Sentence pair (2588) source length 51 target length 51 alignment score : 3.64061e-09
- " Therefore , [ IRF-1 ] may be an important contributor to IL-12 signaling , and we speculate that the defective IL-12 responses seen in IRF-1- / - mice might be attributable , in part , to the absence of [ this transcription factor ] . " ( PMID-10358173 ) 
NULL ({ }) - ({ 1 }) " ({ 2 }) Therefore ({ 3 }) , ({ 4 }) [ ({ 5 }) IRF-1 ({ 6 }) ] ({ 7 }) may ({ 8 }) be ({ 9 }) an ({ 10 }) important ({ 11 }) contributor ({ 12 }) to ({ 13 }) IL-12 ({ 14 }) signaling ({ 15 }) , ({ 16 }) and ({ 17 }) we ({ 18 }) speculate ({ 19 }) that ({ 20 }) the ({ 21 }) defective ({ 22 }) IL-12 ({ 23 }) responses ({ 24 }) seen ({ 25 }) in ({ 26 }) IRF-1- ({ 27 }) / ({ 28 }) - ({ 29 }) mice ({ 30 }) might ({ 31 }) be ({ 32 }) attributable ({ 33 }) , ({ 34 }) in ({ 35 }) part ({ 36 }) , ({ 37 }) to ({ 38 }) the ({ 39 }) absence ({ 40 }) of ({ 41 }) [ ({ 42 }) this ({ 43 }) transcription ({ 44 }) factor ({ 45 }) ] ({ 46 }) . ({ 47 }) " ({ 48 }) ( ({ 49 }) PMID-10358173 ({ 50 }) ) ({ 51 }) 
# Sentence pair (2589) source length 34 target length 34 alignment score : 1.97407e-06
In this example , without rule 2 , the faulty response antecedent of this transcription factor is part because it is the closet antecedent candidate agreeing with the anaphor on the singular number . 
NULL ({ }) In ({ 1 }) this ({ 2 }) example ({ 3 }) , ({ 4 }) without ({ 5 }) rule ({ 6 }) 2 ({ 7 }) , ({ 8 }) the ({ 9 }) faulty ({ 10 }) response ({ 11 }) antecedent ({ 12 }) of ({ 13 }) this ({ 14 }) transcription ({ 15 }) factor ({ 16 }) is ({ 17 }) part ({ 18 }) because ({ 19 }) it ({ 20 }) is ({ 21 }) the ({ 22 }) closet ({ 23 }) antecedent ({ 24 }) candidate ({ 25 }) agreeing ({ 26 }) with ({ 27 }) the ({ 28 }) anaphor ({ 29 }) on ({ 30 }) the ({ 31 }) singular ({ 32 }) number ({ 33 }) . ({ 34 }) 
# Sentence pair (2590) source length 24 target length 23 alignment score : 4.21912e-05
Meanwhile since this transcription factor is recognized as a protein reference , its closest protein antecedent IRF-1 was successfully detected by RB-FULL . 
NULL ({ }) Meanwhile ({ 1 }) , ({ }) since ({ 2 }) this ({ 3 }) transcription ({ 4 }) factor ({ 5 }) is ({ 6 }) recognized ({ 7 }) as ({ 8 }) a ({ 9 }) protein ({ 10 }) reference ({ 11 }) , ({ 12 }) its ({ 13 }) closest ({ 14 }) protein ({ 15 }) antecedent ({ 16 }) IRF-1 ({ 17 }) was ({ 18 }) successfully ({ 19 }) detected ({ 20 }) by ({ 21 }) RB-FULL ({ 22 }) . ({ 23 }) 
# Sentence pair (2591) source length 4 target length 4 alignment score : 2.02987e-05
Another interesting example is 
NULL ({ }) Another ({ 1 2 }) example ({ 3 }) is ({ 4 }) : ({ }) 
# Sentence pair (2592) source length 38 target length 38 alignment score : 8.05141e-07
- " This role for [ c-Myc ] in apoptosis is now confirmed in studies using a dominant negative form of [ its ] heterodimeric binding partner , Max , which . . . " ( PMID-7964516 ) 
NULL ({ }) - ({ 1 }) " ({ 2 }) This ({ 3 }) role ({ 4 }) for ({ 5 }) [ ({ 6 }) c-Myc ({ 7 }) ] ({ 8 }) in ({ 9 }) apoptosis ({ 10 }) is ({ 11 }) now ({ 12 }) confirmed ({ 13 }) in ({ 14 }) studies ({ 15 }) using ({ 16 }) a ({ 17 }) dominant ({ 18 }) negative ({ 19 }) form ({ 20 }) of ({ 21 }) [ ({ 22 }) its ({ 23 }) ] ({ 24 }) heterodimeric ({ 25 }) binding ({ 26 }) partner ({ 27 }) , ({ 28 }) Max ({ 29 }) , ({ 30 }) which ({ 31 }) . ({ 32 }) . ({ 33 }) . ({ 34 }) " ({ 35 }) ( ({ 36 }) PMID-7964516 ({ 37 }) ) ({ 38 }) 
# Sentence pair (2593) source length 34 target length 34 alignment score : 4.5997e-06
Concerning the anaphoric pronoun its in this example , there are several antecedent candidates : this role , c-Myc , apoptosis , studies , a dominant negative form of its heterodimeric binding partner . 
NULL ({ }) Concerning ({ 1 }) the ({ 2 }) anaphoric ({ 3 }) pronoun ({ 4 }) its ({ 5 }) in ({ 6 }) this ({ 7 }) example ({ 8 }) , ({ 9 }) there ({ 10 }) are ({ 11 }) several ({ 12 }) antecedent ({ 13 }) candidates ({ 14 }) : ({ 15 }) this ({ 16 }) role ({ 17 }) , ({ 18 }) c-Myc ({ 19 }) , ({ 20 }) apoptosis ({ 21 }) , ({ 22 }) studies ({ 23 }) , ({ 24 }) a ({ 25 }) dominant ({ 26 }) negative ({ 27 }) form ({ 28 }) of ({ 29 }) its ({ 30 }) heterodimeric ({ 31 }) binding ({ 32 }) partner ({ 33 }) . ({ 34 }) 
# Sentence pair (2594) source length 43 target length 42 alignment score : 4.32668e-09
Although studies and a dominant negative form of its heterodimeric binding partner have been crossed out because of disagreement in numbers , and violation of abandoned syntactic constraints correspondingly , the system would return the incorrect antecedent apoptosis instead of c-Myc . 
NULL ({ }) Although ({ 1 }) studies ({ 2 }) and ({ 3 }) a ({ 4 }) dominant ({ 5 }) negative ({ 6 }) form ({ 7 }) of ({ 8 }) its ({ 9 }) heterodimeric ({ 10 }) binding ({ 11 }) partner ({ 12 }) have ({ 13 }) been ({ 14 }) crossed ({ 15 }) out ({ 16 }) because ({ 17 }) of ({ 18 }) disagreement ({ 19 }) in ({ 20 }) numbers ({ 21 }) , ({ 22 }) and ({ 23 }) violation ({ 24 }) of ({ 25 }) abandoned ({ 26 }) syntactic ({ 27 }) constraints ({ 28 }) , ({ }) correspondingly ({ 29 }) , ({ 30 }) the ({ 31 }) system ({ 32 }) would ({ 33 }) return ({ 34 }) the ({ 35 }) incorrect ({ 36 }) antecedent ({ 37 }) apoptosis ({ 38 }) instead ({ 39 }) of ({ 40 }) c-Myc ({ 41 }) . ({ 42 }) 
# Sentence pair (2595) source length 37 target length 37 alignment score : 5.81133e-07
Fortunately , the containing noun phrase of the anaphor its has the modifier word binding , which is a clue for classifying its as a protein reference ( See Semantic type classification for pronominal anaphors ) . 
NULL ({ }) Fortunately ({ 1 }) , ({ 2 }) the ({ 3 }) containing ({ 4 }) noun ({ 5 }) phrase ({ 6 }) of ({ 7 }) the ({ 8 }) anaphor ({ 9 }) its ({ 10 }) has ({ 11 }) the ({ 12 }) modifier ({ 13 }) word ({ 14 }) binding ({ 15 }) , ({ 16 }) which ({ 17 }) is ({ 18 }) a ({ 19 }) clue ({ 20 }) for ({ 21 }) classifying ({ 22 }) its ({ 23 }) as ({ 24 }) a ({ 25 }) protein ({ 26 }) reference ({ 27 }) ( ({ 28 }) See ({ 29 }) Semantic ({ 30 }) type ({ 31 }) classification ({ 32 }) for ({ 33 }) pronominal ({ 34 }) anaphors ({ 35 }) ) ({ 36 }) . ({ 37 }) 
# Sentence pair (2596) source length 12 target length 11 alignment score : 0.00222376
Rule 2 utilizes semantic classification result to make correct selection . 
NULL ({ }) Rule ({ 1 }) 2 ({ 2 }) utilizes ({ 3 }) semantic ({ 4 }) classification ({ 5 }) result ({ 6 }) to ({ 7 }) make ({ 8 }) the ({ }) correct ({ 9 }) selection ({ 10 }) . ({ 11 }) 
# Sentence pair (2597) source length 19 target length 19 alignment score : 3.25444e-07
In our system , domain-specific semantic information is ultilized at two places : anaphor selection and antecedent prediction . 
NULL ({ }) In ({ 1 }) our ({ 2 }) system ({ 3 }) , ({ 4 }) domain-specific ({ 5 }) semantic ({ 6 }) information ({ 7 }) is ({ 8 }) utilized ({ 9 }) in ({ 10 }) two ({ 11 }) places ({ 12 }) : ({ 13 }) anaphor ({ 14 }) selection ({ 15 }) and ({ 16 }) antecedent ({ 17 }) prediction ({ 18 }) . ({ 19 }) 
# Sentence pair (2598) source length 16 target length 15 alignment score : 2.70204e-07
The effect of semantic information in antecedent prediction has been analyzed in above section . 
NULL ({ }) The ({ 1 }) effect ({ 2 }) of ({ 3 }) semantic ({ 4 }) information ({ 5 }) in ({ 6 }) antecedent ({ 7 }) prediction ({ 8 }) has ({ 9 }) been ({ 10 }) analyzed ({ 11 }) in ({ 12 }) the ({ }) sections ({ 14 }) above ({ 13 }) . ({ 15 }) 
# Sentence pair (2599) source length 20 target length 20 alignment score : 0.000805556
In this subsection , we are going to explore the contribution of semantic information in the anaphor selection step . 
NULL ({ }) In ({ 1 }) this ({ 2 }) subsection ({ 3 }) , ({ 4 }) we ({ 5 }) are ({ 6 }) going ({ 7 }) to ({ 8 }) explore ({ 9 }) the ({ 10 }) contribution ({ 11 }) of ({ 12 }) semantic ({ 13 }) information ({ 14 }) in ({ 15 }) the ({ 16 }) anaphor ({ 17 }) selection ({ 18 }) step ({ 19 }) . ({ 20 }) 
# Sentence pair (2600) source length 36 target length 36 alignment score : 1.43749e-09
To classify anaphors into protein or non-protein reference , our system employs a head-word based classfier for definite noun phrases , DEFNP-ANA-SEM , and a context-based classifier for pronouns , PRO-ANA-SEM ( Section Methods ) . 
NULL ({ }) To ({ 1 }) classify ({ 2 }) anaphors ({ 3 }) into ({ 4 }) protein ({ 5 }) or ({ 6 }) non-protein ({ 7 }) reference ({ 8 }) , ({ 9 }) our ({ 10 }) system ({ 11 }) employs ({ 12 }) a ({ 13 }) head-word ({ 14 }) based ({ 15 }) classifier ({ 16 }) for ({ 17 }) definite ({ 18 }) noun ({ 19 }) phrases ({ 20 }) , ({ 21 }) DEFNP-ANA-SEM ({ 22 }) , ({ 23 }) and ({ 24 }) a ({ 25 }) context-based ({ 26 }) classifier ({ 27 }) for ({ 28 }) pronouns ({ 29 }) , ({ 30 }) PRO-ANA-SEM ({ 31 }) ( ({ 32 }) Section ({ 33 }) Methods ({ 34 }) ) ({ 35 }) . ({ 36 }) 
# Sentence pair (2601) source length 33 target length 35 alignment score : 1.34012e-15
Without limiting the number of anaphors by using semantic information-based filtering , the precision significantly drops , causing a big decrease in Fscore ( Table 4 , RB-FULL w / o DEFNP-ANA-SEM ) . . 
NULL ({ 35 }) Without ({ 1 }) limiting ({ 2 }) the ({ 3 }) number ({ 4 }) of ({ 5 }) anaphors ({ 6 }) by ({ 7 }) using ({ 8 }) semantic ({ 9 }) information-based ({ 10 }) filtering ({ 11 }) , ({ 12 }) the ({ 13 }) precision ({ 14 }) significantly ({ 15 }) drops ({ 16 }) , ({ 17 }) causing ({ 18 }) a ({ 19 }) big ({ 20 }) decrease ({ 21 }) in ({ 22 }) the ({ }) F-score ({ 23 }) ( ({ 24 }) Table ({ 25 }) 4 ({ 26 }) , ({ 27 }) RB-FULL ({ 28 }) without ({ 29 }) DEFNP-ANA-SEM ({ 30 31 32 }) ) ({ 33 }) . ({ 34 }) 
# Sentence pair (2602) source length 23 target length 18 alignment score : 4.61167e-11
This is because the semantic filter is the only way to filter out definite noun phrase anaphors . 
NULL ({ }) This ({ 1 }) decrease ({ 3 }) is ({ 2 }) due ({ }) to ({ }) the ({ }) fact ({ }) that ({ }) the ({ 4 }) semantic ({ 5 }) filter ({ 6 }) is ({ 7 }) the ({ 8 }) only ({ 9 }) way ({ 10 }) to ({ 11 }) filter ({ 12 }) out ({ 13 }) definite ({ 14 }) noun ({ 15 }) phrase ({ 16 }) anaphors ({ 17 }) . ({ 18 }) 
# Sentence pair (2603) source length 22 target length 22 alignment score : 0.000270492
Without the filter , all definite expressions , which include a huge amount of non-anaphoric expressions , are considered as anaphors . 
NULL ({ }) Without ({ 1 }) the ({ 2 }) filter ({ 3 }) , ({ 4 }) all ({ 5 }) definite ({ 6 }) expressions ({ 7 }) , ({ 8 }) which ({ 9 }) include ({ 10 }) a ({ 11 }) huge ({ 12 }) amount ({ 13 }) of ({ 14 }) non-anaphoric ({ 15 }) expressions ({ 16 }) , ({ 17 }) are ({ 18 }) considered ({ 19 }) as ({ 20 }) anaphors ({ 21 }) . ({ 22 }) 
# Sentence pair (2604) source length 28 target length 28 alignment score : 3.77559e-05
Besides the anaphoric use , definite noun phrases are also used to refer to entities or concepts in the common domain knowledge shared between readers and writers . 
NULL ({ }) Besides ({ 1 }) the ({ 2 }) anaphoric ({ 3 }) use ({ 4 }) , ({ 5 }) definite ({ 6 }) noun ({ 7 }) phrases ({ 8 }) are ({ 9 }) also ({ 10 }) used ({ 11 }) to ({ 12 }) refer ({ 13 }) to ({ 14 }) entities ({ 15 }) or ({ 16 }) concepts ({ 17 }) in ({ 18 }) the ({ 19 }) common ({ 20 }) domain ({ 21 }) knowledge ({ 22 }) shared ({ 23 }) between ({ 24 }) readers ({ 25 }) and ({ 26 }) writers ({ 27 }) . ({ 28 }) 
# Sentence pair (2605) source length 37 target length 37 alignment score : 4.15965e-07
Statistics in [ 21 ] show that only around 30% of definite noun phrases are anaphoric , and the other uses according to their classification include associative , unfamiliar / larger situation , idiom and doubt . 
NULL ({ }) Statistics ({ 1 }) in ({ 2 }) [ ({ 3 }) 21 ({ 4 }) ] ({ 5 }) show ({ 6 }) that ({ 7 }) only ({ 8 }) around ({ 9 }) 30% ({ 10 }) of ({ 11 }) definite ({ 12 }) noun ({ 13 }) phrases ({ 14 }) are ({ 15 }) anaphoric ({ 16 }) , ({ 17 }) and ({ 18 }) the ({ 19 }) other ({ 20 }) uses ({ 21 }) according ({ 22 }) to ({ 23 }) their ({ 24 }) classification ({ 25 }) include ({ 26 }) associative ({ 27 }) , ({ 28 }) unfamiliar ({ 29 }) / ({ 30 }) larger ({ 31 }) situation ({ 32 }) , ({ 33 }) idiom ({ 34 }) and ({ 35 }) doubt ({ 36 }) . ({ 37 }) 
# Sentence pair (2606) source length 13 target length 13 alignment score : 0.00659716
Distinguishing such non-anaphoric definite noun phrases from anaphoric ones is extremely difficult . 
NULL ({ }) Distinguishing ({ 1 }) such ({ 2 }) non-anaphoric ({ 3 }) definite ({ 4 }) noun ({ 5 }) phrases ({ 6 }) from ({ 7 }) anaphoric ({ 8 }) ones ({ 9 }) is ({ 10 }) extremely ({ 11 }) difficult ({ 12 }) . ({ 13 }) 
# Sentence pair (2607) source length 40 target length 41 alignment score : 3.53287e-15
In our system , contextual information of possessive pronouns is utilized through the protein key words ( Section Methods ) , and this contributed to 1 .8% gain in f-score ( Table 4 , RB-FULL w / o PRO-ANA-SEM ) . 
NULL ({ }) In ({ 1 }) our ({ 2 }) system ({ 3 }) , ({ 4 }) contextual ({ 5 }) information ({ 6 }) of ({ 7 }) possessive ({ 8 }) pronouns ({ 9 }) is ({ 10 }) utilized ({ 11 }) through ({ 12 }) the ({ 13 }) protein ({ 14 }) key ({ 15 }) words ({ 16 }) ( ({ 17 }) Section ({ 18 }) Methods ({ 19 }) ) ({ 20 }) , ({ 21 }) and ({ 22 }) this ({ 23 }) contributed ({ 24 }) to ({ 25 }) a ({ }) 1 ({ 26 }) .8% ({ 27 }) gain ({ 28 }) in ({ 29 }) F-score ({ 30 }) ( ({ 31 }) Table ({ 32 }) 4 ({ 33 }) , ({ 34 }) RB-FULL ({ 35 }) without ({ 36 }) PRO-ANA-SEM ({ 37 38 39 }) ) ({ 40 }) . ({ 41 }) 
# Sentence pair (2608) source length 22 target length 22 alignment score : 3.24562e-14
This is an encouraging sign to seek for a systematic method to exploit and include such contextual information in coreference resolution . 
NULL ({ 6 }) This ({ 1 }) gain ({ 3 }) is ({ 2 }) a ({ }) good ({ 5 }) indication ({ 7 }) for ({ 8 }) seeking ({ 4 }) a ({ 9 }) systematic ({ 10 }) method ({ 11 }) to ({ 12 }) develop ({ 13 }) and ({ 14 }) include ({ 15 }) such ({ 16 }) contextual ({ 17 }) information ({ 18 }) in ({ 19 }) coreference ({ 20 }) resolution ({ 21 }) . ({ 22 }) 
# Sentence pair (2609) source length 16 target length 16 alignment score : 2.29086e-14
Below are the examples showing the effectiveness of semantic information from the context of pronouns . 
NULL ({ 2 3 }) Examples ({ 1 4 }) showing ({ 5 }) the ({ 6 }) effectiveness ({ 7 }) of ({ 8 }) semantic ({ 9 }) information ({ 10 }) from ({ 11 }) the ({ 12 }) context ({ 13 }) of ({ 14 }) pronouns ({ 15 }) is ({ }) provided ({ }) below ({ 16 }) : ({ }) 
# Sentence pair (2610) source length 38 target length 38 alignment score : 8.20899e-07
- " This role for [ c-Myc ] in apoptosis is now confirmed in studies using a dominant negative form of [ its ] heterodimeric binding partner , Max , which . . . " ( MID-7964516 ) 
NULL ({ }) - ({ 1 }) " ({ 2 }) This ({ 3 }) role ({ 4 }) for ({ 5 }) [ ({ 6 }) c-Myc ({ 7 }) ] ({ 8 }) in ({ 9 }) apoptosis ({ 10 }) is ({ 11 }) now ({ 12 }) confirmed ({ 13 }) in ({ 14 }) studies ({ 15 }) using ({ 16 }) a ({ 17 }) dominant ({ 18 }) negative ({ 19 }) form ({ 20 }) of ({ 21 }) [ ({ 22 }) its ({ 23 }) ] ({ 24 }) heterodimeric ({ 25 }) binding ({ 26 }) partner ({ 27 }) , ({ 28 }) Max ({ 29 }) , ({ 30 }) which ({ 31 }) . ({ 32 }) . ({ 33 }) . ({ 34 }) " ({ 35 }) ( ({ 36 }) MID-7964516 ({ 37 }) ) ({ 38 }) 
# Sentence pair (2611) source length 25 target length 25 alignment score : 7.31086e-05
- " This ability of [ CIITA ] to facilitate promoter occupation is undissociable from [ its ] transactivation potential . " ( PMID-10221658 ) 
NULL ({ }) - ({ 1 }) " ({ 2 }) This ({ 3 }) ability ({ 4 }) of ({ 5 }) [ ({ 6 }) CIITA ({ 7 }) ] ({ 8 }) to ({ 9 }) facilitate ({ 10 }) promoter ({ 11 }) occupation ({ 12 }) is ({ 13 }) undissociable ({ 14 }) from ({ 15 }) [ ({ 16 }) its ({ 17 }) ] ({ 18 }) transactivation ({ 19 }) potential ({ 20 }) . ({ 21 }) " ({ 22 }) ( ({ 23 }) PMID-10221658 ({ 24 }) ) ({ 25 }) 
# Sentence pair (2612) source length 34 target length 34 alignment score : 7.88723e-06
- " In transient transfectin experiments , [ BCL6 ] can repress transcription from promoters linked to [ its ] DNA target sequence and this activity is . . . " ( PMID-8692924 ) 
NULL ({ }) - ({ 1 }) " ({ 2 }) In ({ 3 }) transient ({ 4 }) transfectin ({ 5 }) experiments ({ 6 }) , ({ 7 }) [ ({ 8 }) BCL6 ({ 9 }) ] ({ 10 }) can ({ 11 }) repress ({ 12 }) transcription ({ 13 }) from ({ 14 }) promoters ({ 15 }) linked ({ 16 }) to ({ 17 }) [ ({ 18 }) its ({ 19 }) ] ({ 20 }) DNA ({ 21 }) target ({ 22 }) sequence ({ 23 }) and ({ 24 }) this ({ 25 }) activity ({ 26 }) is ({ 27 }) . ({ 28 }) . ({ 29 }) . ({ 30 }) " ({ 31 }) ( ({ 32 }) PMID-8692924 ({ 33 }) ) ({ 34 }) 
# Sentence pair (2613) source length 59 target length 59 alignment score : 4.85599e-10
- " [ Human immunodeficiency virus type 1 ( HIV-1 ) Tat ] , an early regulatory protein that is critical for viral gene expression and replication , transactivates the HIV-1 long terminal repeat ( LTR ) via [ its ] binding to the transactivation response element ( TAR ) and , . . . " ( PMID-9261367 ) 
NULL ({ }) - ({ 1 }) " ({ 2 }) [ ({ 3 }) Human ({ 4 }) immunodeficiency ({ 5 }) virus ({ 6 }) type ({ 7 }) 1 ({ 8 }) ( ({ 9 }) HIV-1 ({ 10 }) ) ({ 11 }) Tat ({ 12 }) ] ({ 13 }) , ({ 14 }) an ({ 15 }) early ({ 16 }) regulatory ({ 17 }) protein ({ 18 }) that ({ 19 }) is ({ 20 }) critical ({ 21 }) for ({ 22 }) viral ({ 23 }) gene ({ 24 }) expression ({ 25 }) and ({ 26 }) replication ({ 27 }) , ({ 28 }) transactivates ({ 29 }) the ({ 30 }) HIV-1 ({ 31 }) long ({ 32 }) terminal ({ 33 }) repeat ({ 34 }) ( ({ 35 }) LTR ({ 36 }) ) ({ 37 }) via ({ 38 }) [ ({ 39 }) its ({ 40 }) ] ({ 41 }) binding ({ 42 }) to ({ 43 }) the ({ 44 }) transactivation ({ 45 }) response ({ 46 }) element ({ 47 }) ( ({ 48 }) TAR ({ 49 }) ) ({ 50 }) and ({ 51 }) , ({ 52 }) . ({ 53 }) . ({ 54 }) . ({ 55 }) " ({ 56 }) ( ({ 57 }) PMID-9261367 ({ 58 }) ) ({ 59 }) 
# Sentence pair (2614) source length 43 target length 42 alignment score : 7.84819e-13
In all the above examples , the appearance of words such as binding , transactivation , DNA target sequence in the noun phrases of which the anaphor plays a role as a determiner , is contextual indicator for the protein type . 
NULL ({ }) In ({ 1 }) all ({ 2 }) the ({ 3 }) examples ({ 5 }) above ({ 4 }) , ({ 6 }) the ({ 7 }) appearance ({ 8 }) of ({ 9 }) words ({ 10 }) such ({ 11 }) as ({ 12 }) binding ({ 13 }) , ({ 14 }) transactivation ({ 15 }) , ({ 16 }) DNA ({ 17 }) target ({ 18 }) sequence ({ 19 }) in ({ 20 }) the ({ 21 }) noun ({ 22 }) phrases ({ 23 }) for ({ 24 }) which ({ 25 }) the ({ 26 }) anaphor ({ 27 }) plays ({ 28 }) a ({ 29 }) role ({ 30 }) as ({ 31 }) a ({ 32 }) determiner ({ 33 }) , ({ 34 }) is ({ 35 }) a ({ }) contextual ({ 36 }) indicator ({ 37 }) for ({ 38 }) the ({ 39 }) protein ({ 40 }) type ({ 41 }) . ({ 42 }) 
# Sentence pair (2615) source length 20 target length 20 alignment score : 0.000740821
Since the anaphors are predicted as protein reference from their context , the system correctly detects their protein antecedents . 
NULL ({ }) Since ({ 1 }) the ({ 2 }) anaphors ({ 3 }) are ({ 4 }) predicted ({ 5 }) as ({ 6 }) protein ({ 7 }) reference ({ 8 }) from ({ 9 }) their ({ 10 }) context ({ 11 }) , ({ 12 }) the ({ 13 }) system ({ 14 }) correctly ({ 15 }) detects ({ 16 }) their ({ 17 }) protein ({ 18 }) antecedents ({ 19 }) . ({ 20 }) 
# Sentence pair (2616) source length 17 target length 17 alignment score : 0.00162172
Other challenges specific to the protein coreference task Number agreement is a constraint in English writing . 
NULL ({ }) Other ({ 1 }) challenges ({ 2 }) specific ({ 3 }) to ({ 4 }) the ({ 5 }) protein ({ 6 }) coreference ({ 7 }) task ({ 8 }) Number ({ 9 }) agreement ({ 10 }) is ({ 11 }) a ({ 12 }) constraint ({ 13 }) in ({ 14 }) English ({ 15 }) writing ({ 16 }) . ({ 17 }) 
# Sentence pair (2617) source length 16 target length 14 alignment score : 7.65162e-08
However , we found in the data several coreferential expressions violating this constraint . 
NULL ({ }) However ({ 1 }) , ({ 2 }) in ({ 5 }) the ({ 6 }) data ({ 7 }) , ({ }) we ({ 3 }) found ({ 4 }) several ({ 8 }) coreferential ({ 9 }) expressions ({ 10 }) that ({ }) violate ({ 11 }) this ({ 12 }) constraint ({ 13 }) . ({ 14 }) 
# Sentence pair (2618) source length 14 target length 11 alignment score : 1.06293e-13
For instance , the anaphor and antecedent in the following : 
NULL ({ 3 }) The ({ }) anaphor ({ 5 }) and ({ 6 }) antecedent ({ 7 }) in ({ 8 }) the ({ 9 }) following ({ 10 }) is ({ }) an ({ }) instance ({ 2 }) of ({ }) this ({ 4 }) violation ({ 1 }) : ({ 11 }) 
# Sentence pair (2619) source length 11 target length 11 alignment score : 0.0301484
- " . . .for OTF-2 in DRA gene transcription . 
NULL ({ }) - ({ 1 }) " ({ 2 }) . ({ 3 }) . ({ 4 }) .for ({ 5 }) OTF-2 ({ 6 }) in ({ 7 }) DRA ({ 8 }) gene ({ 9 }) transcription ({ 10 }) . ({ 11 }) 
# Sentence pair (2620) source length 31 target length 31 alignment score : 1.92372e-06
In contrast , [ OTF-1-enriched protein fractions ] did not affect DRA gene transcription although [ it ] functionally enhanced the transcription of another . . . " ( PMID-1560002 ) 
NULL ({ }) In ({ 1 }) contrast ({ 2 }) , ({ 3 }) [ ({ 4 }) OTF-1-enriched ({ 5 }) protein ({ 6 }) fractions ({ 7 }) ] ({ 8 }) did ({ 9 }) not ({ 10 }) affect ({ 11 }) DRA ({ 12 }) gene ({ 13 }) transcription ({ 14 }) although ({ 15 }) [ ({ 16 }) it ({ 17 }) ] ({ 18 }) functionally ({ 19 }) enhanced ({ 20 }) the ({ 21 }) transcription ({ 22 }) of ({ 23 }) another ({ 24 }) . ({ 25 }) . ({ 26 }) . ({ 27 }) " ({ 28 }) ( ({ 29 }) PMID-1560002 ({ 30 }) ) ({ 31 }) 
# Sentence pair (2621) source length 45 target length 45 alignment score : 6.55639e-09
Coreference annotation and evaluation Current protein coreference evaluation scheme generates protein links ( links between anaphors and antecedent proteins ) from surface links ( links between anaphors and antecedent expressions ) , without concerning the relative position of antecedent proteins in the antecedent expression . 
NULL ({ }) Coreference ({ 1 }) annotation ({ 2 }) and ({ 3 }) evaluation ({ 4 }) Current ({ 5 }) protein ({ 6 }) coreference ({ 7 }) evaluation ({ 8 }) schemes ({ 9 }) generate ({ 10 }) protein ({ 11 }) links ({ 12 }) ( ({ 13 }) links ({ 14 }) between ({ 15 }) anaphors ({ 16 }) and ({ 17 }) antecedent ({ 18 }) proteins ({ 19 }) ) ({ 20 }) from ({ 21 }) surface ({ 22 }) links ({ 23 }) ( ({ 24 }) links ({ 25 }) between ({ 26 }) anaphors ({ 27 }) and ({ 28 }) antecedent ({ 29 }) expressions ({ 30 }) ) ({ 31 }) , ({ 32 }) without ({ 33 }) concerning ({ 34 }) the ({ 35 }) relative ({ 36 }) position ({ 37 }) of ({ 38 }) antecedent ({ 39 }) proteins ({ 40 }) in ({ 41 }) the ({ 42 }) antecedent ({ 43 }) expression ({ 44 }) . ({ 45 }) 
# Sentence pair (2622) source length 29 target length 28 alignment score : 4.17478e-06
Therefore , when the proteins appear in premodifiers or postmodifers of noun phrases as [ cDNAs encoding EBF or a covalent homodimer of E47 ] in this example 
NULL ({ }) Therefore ({ 1 }) , ({ 2 }) when ({ 3 }) the ({ 4 }) proteins ({ 5 }) appear ({ 6 }) in ({ 7 }) premodifiers ({ 8 }) or ({ 9 }) postmodifers ({ 10 }) of ({ 11 }) noun ({ 12 }) phrases ({ 13 }) as ({ 14 }) [ ({ 15 }) cDNAs ({ 16 }) encoding ({ 17 }) EBF ({ 18 }) or ({ 19 }) a ({ 20 }) covalent ({ 21 }) homodimer ({ 22 }) of ({ 23 }) E47 ({ 24 }) ] ({ 25 }) in ({ 26 }) this ({ 27 }) example ({ 28 }) : ({ }) 
# Sentence pair (2623) source length 52 target length 52 alignment score : 3.59812e-10
- " With the aim of identifying genetic targets for these transcription factors , we stably transfected [ cDNAs encoding EBF or a covalent homodimer of E47 ] , individually or together , into immature hematopoietic Ba / F3 cells , which lack [ both factors ] . " ( PMID-9252117 ) 
NULL ({ }) - ({ 1 }) " ({ 2 }) With ({ 3 }) the ({ 4 }) aim ({ 5 }) of ({ 6 }) identifying ({ 7 }) genetic ({ 8 }) targets ({ 9 }) for ({ 10 }) these ({ 11 }) transcription ({ 12 }) factors ({ 13 }) , ({ 14 }) we ({ 15 }) stably ({ 16 }) transfected ({ 17 }) [ ({ 18 }) cDNAs ({ 19 }) encoding ({ 20 }) EBF ({ 21 }) or ({ 22 }) a ({ 23 }) covalent ({ 24 }) homodimer ({ 25 }) of ({ 26 }) E47 ({ 27 }) ] ({ 28 }) , ({ 29 }) individually ({ 30 }) or ({ 31 }) together ({ 32 }) , ({ 33 }) into ({ 34 }) immature ({ 35 }) hematopoietic ({ 36 }) Ba ({ 37 }) / ({ 38 }) F3 ({ 39 }) cells ({ 40 }) , ({ 41 }) which ({ 42 }) lack ({ 43 }) [ ({ 44 }) both ({ 45 }) factors ({ 46 }) ] ({ 47 }) . ({ 48 }) " ({ 49 }) ( ({ 50 }) PMID-9252117 ({ 51 }) ) ({ 52 }) 
# Sentence pair (2624) source length 10 target length 10 alignment score : 0.00113094
Such proteins might not be the right antecedent proteins . 
NULL ({ }) Such ({ 1 }) proteins ({ 2 }) might ({ 3 }) not ({ 4 }) be ({ 5 }) the ({ 6 }) correct ({ 7 }) antecedent ({ 8 }) proteins ({ 9 }) . ({ 10 }) 
# Sentence pair (2625) source length 20 target length 20 alignment score : 1.88206e-12
In furture , corpus annotation and evaluation scheme should be revised for the ease of automation of coreference resolution . 
NULL ({ 12 }) In ({ 1 }) future ({ 2 }) , ({ 3 }) revision ({ 9 }) of ({ }) corpus ({ 4 }) annotation ({ 5 }) and ({ 6 }) evaluation ({ 7 }) schemes ({ 8 }) would ({ 10 }) benefit ({ 11 }) the ({ 13 }) ease ({ 14 }) of ({ 15 }) automation ({ 16 }) of ({ 17 }) coreference ({ 18 }) resolution ({ 19 }) . ({ 20 }) 
# Sentence pair (2626) source length 18 target length 17 alignment score : 0.000403914
Parse error Coreference expression boundary is determined mostly based on noun phrase boundary output from parser . 
NULL ({ }) Parse ({ 1 }) error ({ 2 }) Coreference ({ 3 }) expression ({ 4 }) boundary ({ 5 }) is ({ 6 }) determined ({ 7 }) mostly ({ 8 }) based ({ 9 }) on ({ 10 }) noun ({ 11 }) phrase ({ 12 }) boundary ({ 13 }) output ({ 14 }) from ({ 15 }) the ({ }) parser ({ 16 }) . ({ 17 }) 
# Sentence pair (2627) source length 16 target length 16 alignment score : 0.00174893
Therefore , parse error on noun phrase boundary strongly affects the performance of coreference resolution . 
NULL ({ }) Therefore ({ 1 }) , ({ 2 }) parse ({ 3 }) error ({ 4 }) on ({ 5 }) noun ({ 6 }) phrase ({ 7 }) boundary ({ 8 }) strongly ({ 9 }) affects ({ 10 }) the ({ 11 }) performance ({ 12 }) of ({ 13 }) coreference ({ 14 }) resolution ({ 15 }) . ({ 16 }) 
# Sentence pair (2628) source length 29 target length 29 alignment score : 1.34764e-05
Examining the data , we found that many antecedent expressions of plural anaphors are coordinated noun phrases , which are unfortunately difficult cases to many parsers including Enju . 
NULL ({ }) Examining ({ 1 }) the ({ 2 }) data ({ 3 }) , ({ 4 }) we ({ 5 }) found ({ 6 }) that ({ 7 }) many ({ 8 }) antecedent ({ 9 }) expressions ({ 10 }) of ({ 11 }) plural ({ 12 }) anaphors ({ 13 }) are ({ 14 }) coordinated ({ 15 }) noun ({ 16 }) phrases ({ 17 }) , ({ 18 }) which ({ 19 }) are ({ 20 }) unfortunately ({ 21 }) difficult ({ 22 }) cases ({ 23 }) to ({ 24 }) many ({ 25 }) parsers ({ 26 }) including ({ 27 }) Enju ({ 28 }) . ({ 29 }) 
# Sentence pair (2629) source length 19 target length 19 alignment score : 3.21028e-06
Incorporation of recent works for coordination resolution like [ 20 ] should be useful to improve the performance . 
NULL ({ }) Incorporation ({ 1 }) of ({ 2 }) recent ({ 3 }) works ({ 4 }) for ({ 5 }) coordination ({ 6 }) resolution ({ 7 }) like ({ 8 }) [ ({ 9 }) 20 ({ 10 }) ] ({ 11 }) should ({ 12 }) be ({ 13 }) useful ({ 14 }) for ({ 15 }) improving ({ 16 }) the ({ 17 }) performance ({ 18 }) . ({ 19 }) 
# Sentence pair (2630) source length 33 target length 34 alignment score : 1.4735e-08
The following example shows a coordination-structured antecedent AML1 / CBF beta , C / EBP , Ets , c-Myb , HOX , and MZF-1 that was failed to be detected by the parser . 
NULL ({ }) The ({ 1 }) following ({ 2 }) example ({ 3 }) shows ({ 4 }) a ({ 5 }) coordination-structured ({ 6 }) antecedent ({ 7 }) AML1 ({ 8 }) / ({ 9 }) CBF ({ 10 }) beta ({ 11 }) , ({ 12 }) C ({ 13 }) / ({ 14 }) EBP ({ 15 }) , ({ 16 }) Ets ({ 17 }) , ({ 18 }) c-Myb ({ 19 }) , ({ 20 }) HOX ({ 21 }) , ({ 22 }) and ({ 23 }) MZF-1 ({ 24 }) that ({ 25 }) failed ({ 26 27 }) to ({ 28 }) be ({ 29 }) detected ({ 30 }) by ({ 31 }) the ({ 32 }) parser ({ 33 }) . ({ 34 }) 
# Sentence pair (2631) source length 11 target length 11 alignment score : 0.0186688
The spurious response expression is transcription factors from several families . 
NULL ({ }) The ({ 1 }) spurious ({ 2 }) response ({ 3 }) expression ({ 4 }) is ({ 5 }) transcription ({ 6 }) factors ({ 7 }) from ({ 8 }) several ({ 9 }) families ({ 10 }) . ({ 11 }) 
# Sentence pair (2632) source length 36 target length 36 alignment score : 1.60688e-06
- " granulocytic and monocytic lineages , transcription factors from several families are active , including [ AML1 / CBF beta , C / EBP , Ets , c-Myb , HOX , and MZF-1 ] . 
NULL ({ }) - ({ 1 }) " ({ 2 }) granulocytic ({ 3 }) and ({ 4 }) monocytic ({ 5 }) lineages ({ 6 }) , ({ 7 }) transcription ({ 8 }) factors ({ 9 }) from ({ 10 }) several ({ 11 }) families ({ 12 }) are ({ 13 }) active ({ 14 }) , ({ 15 }) including ({ 16 }) [ ({ 17 }) AML1 ({ 18 }) / ({ 19 }) CBF ({ 20 }) beta ({ 21 }) , ({ 22 }) C ({ 23 }) / ({ 24 }) EBP ({ 25 }) , ({ 26 }) Ets ({ 27 }) , ({ 28 }) c-Myb ({ 29 }) , ({ 30 }) HOX ({ 31 }) , ({ 32 }) and ({ 33 }) MZF-1 ({ 34 }) ] ({ 35 }) . ({ 36 }) 
# Sentence pair (2633) source length 20 target length 20 alignment score : 0.000534411
Few of [ these factors ] are expressed exclusively in myeloid cells ; . . . " ( PMID-9291089 ) 
NULL ({ }) Few ({ 1 }) of ({ 2 }) [ ({ 3 }) these ({ 4 }) factors ({ 5 }) ] ({ 6 }) are ({ 7 }) expressed ({ 8 }) exclusively ({ 9 }) in ({ 10 }) myeloid ({ 11 }) cells ({ 12 }) ; ({ 13 }) . ({ 14 }) . ({ 15 }) . ({ 16 }) " ({ 17 }) ( ({ 18 }) PMID-9291089 ({ 19 }) ) ({ 20 }) 
# Sentence pair (2634) source length 14 target length 14 alignment score : 1.14345e-06
Our work has confirmed again that domain knowledge is indispensable for coreference resolution . 
NULL ({ }) Our ({ 1 }) current ({ }) work ({ 2 }) has ({ 3 }) reconfirmed ({ 4 5 }) that ({ 6 }) domain ({ 7 }) knowledge ({ 8 }) is ({ 9 }) indispensable ({ 10 }) for ({ 11 }) coreference ({ 12 }) resolution ({ 13 }) . ({ 14 }) 
# Sentence pair (2635) source length 35 target length 34 alignment score : 4.05382e-09
Since the biologicaldomain has richer knowledge resources than any other domain , it would be interesting to continue studying how to exploit and employ domain-specific semantic information in coreference resolution for this domain . 
NULL ({ }) Since ({ 1 }) the ({ 2 }) biological ({ 3 }) domain ({ }) has ({ 4 }) richer ({ 5 }) knowledge ({ 6 }) resources ({ 7 }) than ({ 8 }) any ({ 9 }) other ({ 10 }) domain ({ 11 }) , ({ 12 }) it ({ 13 }) would ({ 14 }) be ({ 15 }) interesting ({ 16 }) to ({ 17 }) continue ({ 18 }) studying ({ 19 }) how ({ 20 }) to ({ 21 }) exploit ({ 22 }) and ({ 23 }) employ ({ 24 }) domain-specific ({ 25 }) semantic ({ 26 }) information ({ 27 }) in ({ 28 }) coreference ({ 29 }) resolution ({ 30 }) for ({ 31 }) this ({ 32 }) domain ({ 33 }) . ({ 34 }) 
# Sentence pair (2636) source length 6 target length 7 alignment score : 0.000421678
Another conclusion concerns with markable detection . 
NULL ({ }) Another ({ 1 }) conclusion ({ 2 }) concerns ({ 3 4 }) markable ({ 5 }) detection ({ 6 }) . ({ 7 }) 
# Sentence pair (2637) source length 34 target length 31 alignment score : 3.14598e-10
This subproblem is often thought as an easy task in coreference resolution systems , however , indeed it is an important subtask which strongly affects the performance of coreference system . 
NULL ({ }) This ({ 1 }) sub-problem ({ 2 }) is ({ 3 }) often ({ 4 }) regarded ({ 5 }) as ({ 6 }) an ({ 7 }) easy ({ 8 }) task ({ 9 }) in ({ 10 }) coreference ({ 11 }) resolution ({ 12 }) systems ({ 13 }) ; ({ 14 }) however ({ 15 }) , ({ 16 }) in ({ }) actuality ({ 17 }) , ({ }) it ({ 18 }) is ({ 19 }) an ({ 20 }) important ({ 21 }) subtask ({ 22 }) , ({ }) which ({ 23 }) strongly ({ 24 }) affects ({ 25 }) the ({ 26 }) performance ({ 27 }) of ({ 28 }) coreference ({ 29 }) system ({ 30 }) . ({ 31 }) 
# Sentence pair (2638) source length 23 target length 23 alignment score : 8.60422e-16
Sticking to the gold data in the designing markable detection method as we did in this paper is one of the strategies . 
NULL ({ 7 13 21 }) Sticking ({ 1 }) to ({ 2 }) the ({ 3 }) gold ({ 4 }) data ({ 5 }) in ({ 6 }) designing ({ 8 }) the ({ }) markable ({ 9 }) detection ({ 10 }) method ({ 11 }) , ({ }) as ({ 12 }) done ({ 14 }) in ({ 15 }) this ({ 16 }) paper ({ 17 }) , ({ }) is ({ 18 }) one ({ 19 }) employed ({ 20 }) strategy ({ 22 }) . ({ 23 }) 
# Sentence pair (2639) source length 24 target length 30 alignment score : 6.08572e-26
However , from another perspective , the perspective of coreference data creation , we should revise the markable annotations , for the sake of automatic and robust markable detection . 
NULL ({ 6 7 21 22 }) However ({ 1 }) , ({ 2 }) from ({ 3 }) the ({ }) perspective ({ 4 5 8 }) of ({ 9 }) coreference ({ 10 }) data ({ 11 }) creation ({ 12 }) , ({ 13 }) revision ({ 14 15 16 }) of ({ }) the ({ 17 }) markable ({ 18 }) annotations ({ 19 }) would ({ 20 }) aid ({ 23 }) in ({ 24 }) automatic ({ 25 }) and ({ 26 }) robust ({ 27 }) markable ({ 28 }) detection ({ 29 }) . ({ 30 }) 
# Sentence pair (2640) source length 21 target length 21 alignment score : 2.9482e-12
As for the future , more effort should be spent on automating the semantic classification for coreference expressions using context . 
NULL ({ 2 3 }) For ({ 1 }) future ({ 4 }) opportunities ({ }) , ({ 5 }) more ({ 6 }) effort ({ 7 }) should ({ 8 }) be ({ 9 }) spent ({ 10 }) on ({ 11 }) automating ({ 12 }) the ({ 13 }) semantic ({ 14 }) classification ({ 15 }) for ({ 16 }) coreference ({ 17 }) expressions ({ 18 }) , ({ }) using ({ 19 }) context ({ 20 }) . ({ 21 }) 
# Sentence pair (2641) source length 18 target length 19 alignment score : 9.15829e-06
Furthermore , it would be interesting to test the results in this study in a machine learning framework . 
NULL ({ }) Furthermore ({ 1 }) , ({ 2 }) it ({ 3 }) would ({ 4 }) be ({ 5 }) interesting ({ 6 }) to ({ 7 }) test ({ 8 }) the ({ 9 }) results ({ 10 }) in ({ 11 }) this ({ 12 }) study ({ 13 }) in ({ 14 }) a ({ 15 }) machine-learning ({ 16 17 }) framework ({ 18 }) . ({ 19 }) 
# Sentence pair (2642) source length 22 target length 17 alignment score : 2.22544e-19
The success of corpus-based methods has made syntactically annotated corpora important resources for natural language processing . 
NULL ({ }) Syntactically ({ 1 6 7 8 }) annotated ({ 9 }) corpora ({ 10 }) have ({ }) become ({ }) important ({ 11 }) resources ({ 12 }) for ({ 13 }) natural ({ 14 }) language ({ 15 }) processing ({ 16 }) , ({ }) due ({ }) in ({ }) part ({ }) to ({ }) the ({ }) success ({ 2 }) of ({ 3 }) corpus-based ({ 4 }) methods ({ 5 }) . ({ 17 }) 
# Sentence pair (2643) source length 24 target length 25 alignment score : 3.05777e-06
Since words are often considered as the primitive units of language structures , the annotation of word segmentation forms the basis of these corpora . 
NULL ({ 7 }) Since ({ 1 }) words ({ 2 }) are ({ 3 }) often ({ 4 }) considered ({ 5 }) as ({ 6 }) primitive ({ 8 }) units ({ 9 }) of ({ 10 }) language ({ 11 }) structures ({ 12 }) , ({ 13 }) the ({ 14 }) annotation ({ 15 }) of ({ 16 }) word ({ 17 }) segmentation ({ 18 }) forms ({ 19 }) the ({ 20 }) basis ({ 21 }) of ({ 22 }) these ({ 23 }) corpora ({ 24 }) . ({ 25 }) 
# Sentence pair (2644) source length 31 target length 29 alignment score : 1.42235e-12
This is also a concern of Vietnamese Treebank ( VTB ) , the first and the only publicly available syntactically annotated corpus so far for the Vietnamese language . 
NULL ({ 16 }) This ({ 1 }) is ({ 2 }) also ({ 3 }) a ({ 4 }) concern ({ 5 }) for ({ 6 }) the ({ }) Vietnamese ({ 7 }) Treebank ({ 8 }) ( ({ 9 }) VTB ({ 10 }) ) ({ 11 }) , ({ 12 }) which ({ }) is ({ }) the ({ 13 }) first ({ 14 }) and ({ 15 }) only ({ 17 }) publicly ({ 18 }) available ({ 19 }) syntactically ({ 20 }) annotated ({ 21 }) corpus ({ 22 }) thus ({ 23 }) far ({ 24 }) for ({ 25 }) the ({ 26 }) Vietnamese ({ 27 }) language ({ 28 }) . ({ 29 }) 
# Sentence pair (2645) source length 32 target length 29 alignment score : 1.44076e-14
Although word segmentation is straight-forward for space-delimited languages like English , this is not true for languages like Vietnamese of which no standard criterion for word segmentation exists . 
NULL ({ }) Although ({ 1 }) word ({ 2 }) segmentation ({ 3 }) is ({ 4 }) straight-forward ({ 5 }) for ({ 6 }) space-delimited ({ 7 }) languages ({ 8 }) like ({ 9 }) English ({ 10 }) , ({ 11 }) this ({ 12 }) is ({ 13 }) not ({ 14 }) the ({ }) case ({ 15 }) for ({ 16 }) languages ({ 17 }) like ({ 18 }) Vietnamese ({ 19 }) for ({ 20 }) which ({ 21 }) a ({ 22 }) standard ({ 23 }) criterion ({ 24 }) for ({ 25 }) word ({ 26 }) segmentation ({ 27 }) does ({ }) not ({ }) exist ({ 28 }) . ({ 29 }) 
# Sentence pair (2646) source length 19 target length 19 alignment score : 0.00100172
This work explores the challenges of Vietnamese word segmentation through the detection and correction of inconsistency for VTB . 
NULL ({ }) This ({ 1 }) work ({ 2 }) explores ({ 3 }) the ({ 4 }) challenges ({ 5 }) of ({ 6 }) Vietnamese ({ 7 }) word ({ 8 }) segmentation ({ 9 }) through ({ 10 }) the ({ 11 }) detection ({ 12 }) and ({ 13 }) correction ({ 14 }) of ({ 15 }) inconsistency ({ 16 }) for ({ 17 }) VTB ({ 18 }) . ({ 19 }) 
# Sentence pair (2647) source length 46 target length 42 alignment score : 4.33758e-12
Then , by combining and splitting the inconsistent annotations detected , we could observe the influence of different word segmentation criteria on automatic word segmentation , and the applications of word segmentation , including text classification and English-Vietnamese statistical machine translation . 
NULL ({ }) Then ({ 1 }) , ({ 2 }) by ({ 3 }) combining ({ 4 }) and ({ 5 }) splitting ({ 6 }) the ({ 7 }) inconsistent ({ 8 }) annotations ({ 9 }) that ({ }) were ({ }) detected ({ 10 }) , ({ 11 }) we ({ 12 }) are ({ }) able ({ 13 }) to ({ }) observe ({ 14 }) the ({ 15 }) influence ({ 16 }) of ({ 17 }) different ({ 18 }) word ({ 19 }) segmentation ({ 20 }) criteria ({ 21 }) on ({ 22 }) automatic ({ 23 }) word ({ 24 }) segmentation ({ 25 }) , ({ 26 }) and ({ 27 }) the ({ 28 }) applications ({ 29 }) of ({ 30 }) word ({ 31 }) segmentation ({ 32 }) , ({ 33 }) including ({ 34 }) text ({ 35 }) classification ({ 36 }) and ({ 37 }) English-Vietnamese ({ 38 }) statistical ({ 39 }) machine ({ 40 }) translation ({ 41 }) . ({ 42 }) 
# Sentence pair (2648) source length 24 target length 24 alignment score : 4.14399e-05
The analysis and experimental results showed that our methods improved the quality of VTB , which positively affected the performance of its applications . 
NULL ({ }) The ({ 1 }) analysis ({ 2 }) and ({ 3 }) experimental ({ 4 }) results ({ 5 }) showed ({ 6 }) that ({ 7 }) our ({ 8 }) methods ({ 9 }) improved ({ 10 }) the ({ 11 }) quality ({ 12 }) of ({ 13 }) VTB ({ 14 }) , ({ 15 }) which ({ 16 }) positively ({ 17 }) affected ({ 18 }) the ({ 19 }) performance ({ 20 }) of ({ 21 }) its ({ 22 }) applications ({ 23 }) . ({ 24 }) 
# Sentence pair (2649) source length 20 target length 18 alignment score : 3.53329e-09
Treebanks , corpora annotated with syntatic structures , have become more and more impor-tant for language processing . 
NULL ({ }) Treebanks ({ 1 }) , ({ 2 }) which ({ }) are ({ }) corpora ({ 3 }) annotated ({ 4 }) with ({ 5 }) syntactic ({ 6 }) structures ({ 7 }) , ({ 8 }) have ({ 9 }) become ({ 10 }) more ({ 11 }) and ({ 12 }) more ({ 13 }) important ({ 14 }) for ({ 15 }) language ({ 16 }) processing ({ 17 }) . ({ 18 }) 
# Sentence pair (2650) source length 47 target length 44 alignment score : 1.93174e-15
To strengthen the automatic processing of the Vietnamese language , the Vietnamese treebank ( VTB ) has been built as a part of the national project `` Vietnamese language and speech processing ( VLSP ) '' ( Nguyen et al ., 2009b ) . 
NULL ({ }) In ({ }) order ({ 2 }) to ({ }) strengthen ({ 1 }) the ({ 3 }) automatic ({ 4 }) processing ({ 5 }) of ({ 6 }) the ({ 7 }) Vietnamese ({ 8 }) language ({ 9 }) , ({ 10 }) the ({ 11 }) Vietnamese ({ 12 }) Treebank ({ 13 }) ( ({ 14 }) VTB ({ 15 }) ) ({ 16 }) has ({ 17 }) been ({ 18 }) built ({ 19 }) as ({ 20 }) a ({ 21 }) part ({ 22 }) of ({ 23 }) the ({ 24 }) national ({ 25 }) project ({ 26 }) , ({ }) `` ({ 27 }) Vietnamese ({ 28 }) language ({ 29 }) and ({ 30 }) speech ({ 31 }) processing ({ 32 }) ( ({ 33 }) VLSP ({ 34 }) ) ({ 35 }) '' ({ 36 }) ( ({ 37 }) Nguyen ({ 38 }) et ({ 39 }) al ({ 40 }) ., ({ 41 }) 2009b ({ 42 }) ) ({ 43 }) . ({ 44 }) 
# Sentence pair (2651) source length 39 target length 38 alignment score : 1.17923e-08
However , in our preliminary experiment with VTB , when we trained the Berkeley parser ( Petrov et al ., 2006 ) and evaluated it using the corpus , the parser achieved only 65 .8% in F-score . 
NULL ({ }) However ({ 1 }) , ({ 2 }) in ({ 3 }) our ({ 4 }) preliminary ({ 5 }) experiment ({ 6 }) with ({ 7 }) VTB ({ 8 }) , ({ 9 }) when ({ 10 }) we ({ 11 }) trained ({ 12 }) the ({ 13 }) Berkeley ({ 14 }) parser ({ 15 }) ( ({ 16 }) Petrov ({ 17 }) et ({ 18 }) al ({ 19 }) ., ({ 20 }) 2006 ({ 21 }) ) ({ 22 }) and ({ 23 }) evaluated ({ 24 }) it ({ 25 }) by ({ }) using ({ 26 }) the ({ 27 }) corpus ({ 28 }) , ({ 29 }) the ({ 30 }) parser ({ 31 }) achieved ({ 32 }) only ({ 33 }) 65 ({ 34 }) .8% ({ 35 }) in ({ 36 }) F-score ({ 37 }) . ({ 38 }) 
# Sentence pair (2652) source length 34 target length 30 alignment score : 5.92489e-12
This performance is far lower than the state-of-the-art performance reported for Berkeley Parser on English Penn Treebank , 90 .3% in F-score ( Petrov et al ., 2006 ) . 
NULL ({ }) This ({ 1 }) score ({ 2 }) is ({ 3 }) far ({ 4 }) lower ({ 5 }) than ({ 6 }) the ({ 7 }) state-of-the-art ({ 8 }) performance ({ 9 }) reported ({ 10 }) for ({ 11 }) the ({ }) Berkeley ({ 12 }) Parser ({ 13 }) on ({ 14 }) the ({ }) English ({ 15 }) Penn ({ 16 }) Treebank ({ 17 }) , ({ 18 }) which ({ }) reported ({ }) 90 ({ 19 }) .3% ({ 20 }) in ({ 21 }) F-score ({ 22 }) ( ({ 23 }) Petrov ({ 24 }) et ({ 25 }) al ({ 26 }) ., ({ 27 }) 2006 ({ 28 }) ) ({ 29 }) . ({ 30 }) 
# Sentence pair (2653) source length 10 target length 8 alignment score : 0.000132679
There are two possible reasons for this . 
NULL ({ }) There ({ 1 }) are ({ 2 }) two ({ 3 }) possible ({ 4 }) reasons ({ 5 }) to ({ }) explain ({ 6 }) this ({ 7 }) outcome ({ }) . ({ 8 }) 
# Sentence pair (2654) source length 28 target length 34 alignment score : 1.00963e-43
First , the quality of VTB is not good enough to build a good a parser , including the quality of the annotation scheme , the annotation guidelines , and the annotation process . 
NULL ({ 2 11 13 15 }) One ({ }) reason ({ }) for ({ }) this ({ }) outcome ({ }) is ({ 7 }) the ({ 3 }) quality ({ 4 }) of ({ 5 }) VTB ({ 6 }) , ({ 17 }) including ({ 18 }) the ({ 19 }) quality ({ 20 }) of ({ 21 }) the ({ 22 }) annotation ({ 23 }) scheme ({ 24 }) , ({ 25 }) the ({ 26 }) annotation ({ 8 10 14 27 }) guidelines ({ 1 9 12 16 28 }) , ({ 29 }) and ({ 30 }) the ({ 31 }) annotation ({ 32 }) process ({ 33 }) . ({ 34 }) 
# Sentence pair (2655) source length 21 target length 23 alignment score : 3.61907e-33
Second , parsing Vietnamese is a diffcult problem by its own , and we need to seek new solutions to the problem . 
NULL ({ 9 12 21 }) The ({ }) second ({ 2 }) reason ({ 8 }) is ({ 5 }) the ({ }) difficulty ({ 6 }) of ({ }) parsing ({ 3 }) Vietnamese ({ 4 }) ; ({ 13 }) we ({ 14 }) need ({ 15 }) to ({ 16 }) seek ({ 17 }) new ({ 18 }) solutions ({ 1 10 11 19 }) to ({ 20 }) address ({ 7 }) this ({ }) problem ({ 22 }) . ({ 23 }) 
# Sentence pair (2656) source length 16 target length 16 alignment score : 0.00116809
VTB is annotated with three layers : word segmentation , POS tagging , and bracketing . 
NULL ({ }) VTB ({ 1 }) is ({ 2 }) annotated ({ 3 }) with ({ 4 }) three ({ 5 }) layers ({ 6 }) : ({ 7 }) word ({ 8 }) segmentation ({ 9 }) , ({ 10 }) POS ({ 11 }) tagging ({ 12 }) , ({ 13 }) and ({ 14 }) bracketing ({ 15 }) . ({ 16 }) 
# Sentence pair (2657) source length 51 target length 60 alignment score : 3.74293e-46
This paper focuses on the word segmentation issues since the most basic unit of a treebank is word ( Di Sciullo and Edwin , 1987 ) , and defining `` What are words ? '' is the first problem that a treebank has to solve ( Xia , 2000b ,a ; Sornlertlamvanich et al ., 1997 , 1999 ) . 
NULL ({ 17 41 44 }) This ({ 1 }) paper ({ 2 }) focuses ({ 3 }) on ({ 4 }) the ({ 5 }) word ({ 6 }) segmentation ({ 7 }) , ({ 8 }) since ({ 9 }) the ({ 10 }) most ({ 11 }) basic ({ 12 }) unit ({ 13 }) of ({ 14 }) a ({ 15 }) treebank ({ 16 31 42 }) are ({ 32 }) words ({ 18 }) ( ({ 19 }) Di ({ 20 34 39 43 }) Sciullo ({ 21 40 45 }) and ({ 22 }) Edwin ({ 23 }) , ({ 24 }) 1987 ({ 25 }) ) ({ 26 }) , ({ 27 }) and ({ 28 }) defining ({ 29 }) `` ({ 30 }) words ({ 33 }) '' ({ 35 }) is ({ 36 }) the ({ 37 }) first ({ 38 }) step ({ }) ( ({ 46 }) Xia ({ 47 }) , ({ 48 }) 2000b ({ 49 }) ,a ({ 50 }) ; ({ 51 }) Sornlertlamvanich ({ 52 }) et ({ 53 }) al ({ 54 }) ., ({ 55 }) 1997 ({ 56 }) , ({ 57 }) 1999 ({ 58 }) ) ({ 59 }) . ({ 60 }) 
# Sentence pair (2658) source length 21 target length 19 alignment score : 2.45755e-09
For languages like English , answering this question is almost trivial because the blank spaces denote word delimiters . 
NULL ({ }) For ({ 1 }) languages ({ 2 }) like ({ 3 }) English ({ 4 }) , ({ 5 }) defining ({ 6 }) `` ({ 7 }) words ({ }) '' ({ 8 }) is ({ 9 }) almost ({ 10 }) trivial ({ 11 }) , ({ }) because ({ 12 }) the ({ 13 }) blank ({ 14 }) spaces ({ 15 }) denote ({ 16 }) word ({ 17 }) delimiters ({ 18 }) . ({ 19 }) 
# Sentence pair (2659) source length 32 target length 31 alignment score : 5.16725e-09
However , for an isolating language like Vietnamese , where blank spaces play a role of syllable delimiters , `` What are words ? '' is not a trivial question . 
NULL ({ }) However ({ 1 }) , ({ 2 }) for ({ 3 }) an ({ 4 }) isolating ({ 5 }) language ({ 6 }) like ({ 7 }) Vietnamese ({ 8 }) , ({ 9 }) for ({ }) which ({ 10 }) blank ({ 11 }) spaces ({ 12 }) play ({ 13 }) a ({ 14 }) role ({ 15 }) of ({ 16 }) syllable ({ 17 }) delimiters ({ 18 }) , ({ 19 }) `` ({ 20 }) What ({ 21 }) are ({ 22 }) words ({ 23 }) ? ({ 24 }) '' ({ 25 }) is ({ 26 }) not ({ 27 }) a ({ 28 }) trivial ({ 29 }) question ({ 30 }) . ({ 31 }) 
# Sentence pair (2660) source length 82 target length 81 alignment score : 1.50522e-23
For example , the sentence `` Hc sinh hc sinh hc ( students learn biology )1 '' is composed of three words `` hc sinh ( student ) '' , `` hc ( learn ) , '' and `` sinh hc ( biology ) ; '' Word segmentation is expected to break down the sentence at the boundaries of these words , not to split `` hc sinh ( student ) '' and `` sinh hc ( biology ) '' . 
NULL ({ 45 64 }) For ({ 1 }) example ({ 2 }) , ({ 3 }) the ({ 4 }) sentence ({ 5 }) `` ({ 6 }) Hc ({ 7 }) sinh ({ 8 }) hc ({ 9 }) sinh ({ 10 }) hc ({ 11 }) ( ({ 12 }) students ({ 13 }) learn ({ 14 }) biology ({ 15 }) )1 ({ 16 }) '' ({ 17 }) is ({ 18 }) composed ({ 19 }) of ({ 20 }) three ({ 21 }) words ({ 22 }) , ({ }) `` ({ 23 }) hc ({ 24 }) sinh ({ 25 }) ( ({ 26 }) student ({ 27 }) ) ({ 28 }) '' ({ 29 }) , ({ 30 }) `` ({ 31 }) hc ({ 32 }) ( ({ 33 }) learn ({ 34 }) ) ({ 35 }) , ({ 36 }) '' ({ 37 }) and ({ 38 }) `` ({ 39 }) sinh ({ 40 }) hc ({ 41 }) ( ({ 42 }) biology ({ 43 }) ) ({ 44 }) '' ({ 46 }) . ({ }) Word ({ 47 }) segmentation ({ 48 }) is ({ 49 }) expected ({ 50 }) to ({ 51 }) break ({ 52 }) down ({ 53 }) the ({ 54 }) sentence ({ 55 }) at ({ 56 }) the ({ 57 }) boundaries ({ 58 }) of ({ 59 }) these ({ 60 }) words ({ 61 }) , ({ 62 }) instead ({ 63 }) of ({ }) splitting ({ 65 }) `` ({ 66 }) hc ({ 67 }) sinh ({ 68 }) ( ({ 69 }) student ({ 70 }) ) ({ 71 }) '' ({ 72 }) and ({ 73 }) `` ({ 74 }) sinh ({ 75 }) hc ({ 76 }) ( ({ 77 }) biology ({ 78 }) ) ({ 79 }) '' ({ 80 }) . ({ 81 }) 
# Sentence pair (2661) source length 38 target length 38 alignment score : 3.60238e-08
Note that the terminology `` word segmentation '' also refers to the task of extracting words statistically without concerning a gold-standard for segmentation , as in ( Ha , 2003 ; Le et al ., 2010 ) . 
NULL ({ }) Note ({ 1 }) that ({ 2 }) the ({ 3 }) terminology ({ 4 }) `` ({ 5 }) word ({ 6 }) segmentation ({ 7 }) '' ({ 8 }) also ({ 9 }) refers ({ 10 }) to ({ 11 }) the ({ 12 }) task ({ 13 }) of ({ 14 }) extracting ({ 15 }) words ({ 16 }) statistically ({ 17 }) without ({ 18 }) concerning ({ 19 }) a ({ 20 }) gold-standard ({ 21 }) for ({ 22 }) segmentation ({ 23 }) , ({ 24 }) as ({ 25 }) in ({ 26 }) ( ({ 27 }) Ha ({ 28 }) , ({ 29 }) 2003 ({ 30 }) ; ({ 31 }) Le ({ 32 }) et ({ 33 }) al ({ 34 }) ., ({ 35 }) 2010 ({ 36 }) ) ({ 37 }) . ({ 38 }) 
# Sentence pair (2662) source length 33 target length 30 alignment score : 4.8492e-10
In such context , the extracted words are more appropriate for building a dictionary than for corpus-based language processing , which are out of the focus of this paper . 
NULL ({ }) In ({ 1 }) such ({ 2 }) a ({ }) context ({ 3 }) , ({ 4 }) the ({ 5 }) extracted ({ 6 }) words ({ 7 }) are ({ 8 }) more ({ 9 }) appropriate ({ 10 }) for ({ 11 }) building ({ 12 }) a ({ 13 }) dictionary ({ 14 }) , ({ }) rather ({ }) than ({ 15 }) for ({ 16 }) corpus-based ({ 17 }) language ({ 18 }) processing ({ 19 }) , ({ 20 }) which ({ 21 }) are ({ 22 }) outside ({ 23 }) of ({ 24 }) the ({ 25 }) scope ({ 26 }) of ({ 27 }) this ({ 28 }) paper ({ 29 }) . ({ 30 }) 
# Sentence pair (2663) source length 22 target length 19 alignment score : 3.06801e-22
Establishing a gold standard for Vietnamese word segmentation faces some diffcuties coming from the characteristics of the language . 
NULL ({ 14 }) Because ({ 1 }) of ({ }) the ({ }) discussed ({ 13 }) characteristics ({ 15 }) of ({ 16 }) the ({ 17 }) language ({ 18 }) , ({ }) there ({ }) are ({ }) challenges ({ 9 }) in ({ }) establishing ({ 10 11 12 }) a ({ 2 }) gold ({ 3 }) standard ({ 4 }) for ({ 5 }) Vietnamese ({ 6 }) word ({ 7 }) segmentation ({ 8 }) . ({ 19 }) 
# Sentence pair (2664) source length 32 target length 32 alignment score : 2.71405e-08
The diffculties of Vietnamese word segmentation have been recognized by many researchers ( Ha , 2003 ; Nguyen et al ., 2004 , 2006 ; Le et al ., 2010 ) . 
NULL ({ }) The ({ 1 }) difficulties ({ 2 }) in ({ 3 }) Vietnamese ({ 4 }) word ({ 5 }) segmentation ({ 6 }) have ({ 7 }) been ({ 8 }) recognized ({ 9 }) by ({ 10 }) many ({ 11 }) researchers ({ 12 }) ( ({ 13 }) Ha ({ 14 }) , ({ 15 }) 2003 ({ 16 }) ; ({ 17 }) Nguyen ({ 18 }) et ({ 19 }) al ({ 20 }) ., ({ 21 }) 2004 ({ 22 }) , ({ 23 }) 2006 ({ 24 }) ; ({ 25 }) Le ({ 26 }) et ({ 27 }) al ({ 28 }) ., ({ 29 }) 2010 ({ 30 }) ) ({ 31 }) . ({ 32 }) 
# Sentence pair (2665) source length 33 target length 31 alignment score : 6.55346e-12
Although most people agree that the Vietnamese language has two types of words : single and compound , there is little consensus on how to segment a sentence into words . 
NULL ({ }) Although ({ 1 }) most ({ 2 }) people ({ 3 }) agree ({ 4 }) that ({ 5 }) the ({ 6 }) Vietnamese ({ 7 }) language ({ 8 }) has ({ 9 }) two ({ 10 }) types ({ 11 }) of ({ 12 }) words ({ 13 }) : ({ 14 }) single ({ 15 }) and ({ 16 }) compound ({ 17 }) , ({ 18 }) there ({ 19 }) is ({ 20 }) little ({ 21 }) consensus ({ 22 }) as ({ }) to ({ 23 }) the ({ }) methodology ({ 24 }) for ({ 25 }) segmenting ({ 26 }) a ({ 27 }) sentence ({ 28 }) into ({ 29 }) words ({ 30 }) . ({ 31 }) 
# Sentence pair (2666) source length 50 target length 42 alignment score : 2.74445e-22
The disagreement is not only because of the different functions of blank spaces as mentioned above , but also because Vietnamese is not an inflectional language like English or Japanese , where morphological forms can be useful clues for word segmentation . 
NULL ({ }) The ({ 1 }) disagreement ({ 2 }) occurs ({ 3 }) not ({ 4 }) only ({ 5 }) because ({ 6 }) of ({ 7 }) the ({ 8 }) different ({ 9 }) functions ({ 10 }) of ({ 11 }) blank ({ 12 }) spaces ({ 13 }) ( ({ }) as ({ 14 }) mentioned ({ 15 }) above ({ 16 }) ) ({ }) , ({ 17 }) but ({ 18 }) also ({ 19 }) because ({ 20 }) Vietnamese ({ 21 }) is ({ 22 }) not ({ 23 }) an ({ 24 }) inflectional ({ 25 }) language ({ 26 }) , ({ }) as ({ }) is ({ }) the ({ }) case ({ 27 }) for ({ }) English ({ 28 }) or ({ 29 }) Japanese ({ 30 }) , ({ 31 }) for ({ }) which ({ 32 }) morphological ({ 33 }) forms ({ 34 }) can ({ 35 }) provide ({ 36 }) useful ({ 37 }) clues ({ 38 }) for ({ 39 }) word ({ 40 }) segmentation ({ 41 }) . ({ 42 }) 
# Sentence pair (2667) source length 47 target length 46 alignment score : 1.26497e-13
While the similar problems also happen with Chinese word segmentation ( Xia , 2000b ) , Vietnamese word segmentation may be more diffcult because the modern Vietnamese writing system is based on Latin characters , which represents the pronunciation but not the meaning of words . 
NULL ({ 2 }) While ({ 1 }) similar ({ 3 }) problems ({ 4 }) also ({ 5 }) occur ({ 6 }) with ({ 7 }) Chinese ({ 8 }) word ({ 9 }) segmentation ({ 10 }) ( ({ 11 }) Xia ({ 12 }) , ({ 13 }) 2000b ({ 14 }) ) ({ 15 }) , ({ 16 }) Vietnamese ({ 17 }) word ({ 18 }) segmentation ({ 19 }) may ({ 20 }) be ({ 21 }) more ({ 22 }) difficult ({ 23 }) , ({ }) because ({ 24 }) the ({ 25 }) modern ({ 26 }) Vietnamese ({ 27 }) writing ({ 28 }) system ({ 29 }) is ({ 30 }) based ({ 31 }) on ({ 32 }) Latin ({ 33 }) characters ({ 34 }) , ({ 35 }) which ({ 36 }) represent ({ 37 }) the ({ 38 }) pronunciation ({ 39 }) , ({ }) but ({ 40 }) not ({ 41 }) the ({ 42 }) meaning ({ 43 }) of ({ 44 }) words ({ 45 }) . ({ 46 }) 
# Sentence pair (2668) source length 30 target length 27 alignment score : 2.8414e-10
All these characteristics make it diffcult to perform word segmentation for Vietnamese both manually and automatically , and have resulted in different criteria for word segmenation . 
NULL ({ }) All ({ 1 }) of ({ }) these ({ 2 }) characteristics ({ 3 }) make ({ 4 }) it ({ 5 }) diffcult ({ 6 }) to ({ 7 }) perform ({ 8 }) word ({ 9 }) segmentation ({ 10 }) for ({ 11 }) Vietnamese ({ 12 }) , ({ }) both ({ 13 }) manually ({ 14 }) and ({ 15 }) automatically ({ 16 }) , ({ 17 }) and ({ 18 }) have ({ 19 }) thus ({ }) resulted ({ 20 }) in ({ 21 }) different ({ 22 }) criteria ({ 23 }) for ({ 24 }) word ({ 25 }) segmentation ({ 26 }) . ({ 27 }) 
# Sentence pair (2669) source length 26 target length 25 alignment score : 8.86838e-06
However , so far there have been few studies on the challenges in word segmentation , and the comparison of different word segmentation criteria . 
NULL ({ }) However ({ 1 }) , ({ 2 }) so ({ 3 }) far ({ 4 }) , ({ }) there ({ 5 }) have ({ 6 }) been ({ 7 }) few ({ 8 }) studies ({ 9 }) on ({ 10 }) the ({ 11 }) challenges ({ 12 }) in ({ 13 }) word ({ 14 }) segmentation ({ 15 }) , ({ 16 }) and ({ 17 }) the ({ 18 }) comparison ({ 19 }) of ({ 20 }) different ({ 21 }) word ({ 22 }) segmentation ({ 23 }) criteria ({ 24 }) . ({ 25 }) 
# Sentence pair (2670) source length 22 target length 22 alignment score : 1.10601e-05
In this paper , a brief introduction of the Vietnamese treebank VTB and its annotation scheme are given in Section 2 . 
NULL ({ }) In ({ 1 }) this ({ 2 }) paper ({ 3 }) , ({ 4 }) a ({ 5 }) brief ({ 6 }) introduction ({ 7 }) of ({ 8 }) the ({ 9 }) Vietnamese ({ 10 }) Treebank ({ 11 }) VTB ({ 12 }) and ({ 13 }) its ({ 14 }) annotation ({ 15 }) scheme ({ 16 }) are ({ 17 }) provided ({ 18 }) in ({ 19 }) Section ({ 20 }) 2 ({ 21 }) . ({ 22 }) 
# Sentence pair (2671) source length 25 target length 25 alignment score : 7.15804e-05
Then , we described our methods for the detection and correction of the problematic annotations in the VTB corpus ( Section 4 .2 ) . 
NULL ({ }) Then ({ 1 }) , ({ 2 }) we ({ 3 }) described ({ 4 }) our ({ 5 }) methods ({ 6 }) for ({ 7 }) the ({ 8 }) detection ({ 9 }) and ({ 10 }) correction ({ 11 }) of ({ 12 }) the ({ 13 }) problematic ({ 14 }) annotations ({ 15 }) in ({ 16 }) the ({ 17 }) VTB ({ 18 }) corpus ({ 19 }) ( ({ 20 }) Section ({ 21 }) 4 ({ 22 }) .2 ({ 23 }) ) ({ 24 }) . ({ 25 }) 
# Sentence pair (2672) source length 25 target length 25 alignment score : 2.9913e-05
We classified the problematic annotations into several patterns of inconsistency , part of which were manually fixed to improve the quality of the corpus . 
NULL ({ }) We ({ 1 }) classified ({ 2 }) the ({ 3 }) problematic ({ 4 }) annotations ({ 5 }) into ({ 6 }) several ({ 7 }) patterns ({ 8 }) of ({ 9 }) inconsistency ({ 10 }) , ({ 11 }) part ({ 12 }) of ({ 13 }) which ({ 14 }) were ({ 15 }) manually ({ 16 }) fixed ({ 17 }) to ({ 18 }) improve ({ 19 }) the ({ 20 }) quality ({ 21 }) of ({ 22 }) the ({ 23 }) corpus ({ 24 }) . ({ 25 }) 
# Sentence pair (2673) source length 35 target length 34 alignment score : 6.29065e-10
The rest , which can be considered as the most diffcult and controversial cases of word segmentation , were used to create different versions of the VTB corpus representing different word segmentation criteria . 
NULL ({ }) The ({ 1 }) rest ({ 2 }) , ({ 3 }) which ({ 4 }) can ({ 5 }) be ({ 6 }) considered ({ 7 }) as ({ 8 }) the ({ 9 }) most ({ 10 }) difficult ({ 11 }) and ({ 12 }) controversial ({ 13 }) instances ({ 14 }) of ({ 15 }) word ({ 16 }) segmentation ({ 17 }) , ({ 18 }) were ({ 19 }) used ({ 20 }) to ({ 21 }) create ({ 22 }) different ({ 23 }) versions ({ 24 }) of ({ 25 }) the ({ 26 }) VTB ({ 27 }) corpus ({ 28 }) , ({ }) representing ({ 29 }) different ({ 30 }) word ({ 31 }) segmentation ({ 32 }) criteria ({ 33 }) . ({ 34 }) 
# Sentence pair (2674) source length 27 target length 26 alignment score : 1.44779e-05
Finally , we evaluated these criteria in automatic word segmentation , and its application in text classification and English-Vietnamese statistical machine translation in Section 4 . 
NULL ({ }) Finally ({ 1 }) , ({ 2 }) we ({ 3 }) evaluated ({ 4 }) these ({ 5 }) criteria ({ 6 }) in ({ 7 }) automatic ({ 8 }) word ({ 9 }) segmentation ({ 10 }) , ({ 11 }) and ({ 12 }) its ({ 13 }) application ({ 14 }) in ({ 15 }) text ({ 16 }) classification ({ 17 }) and ({ 18 }) English-Vietnamese ({ 19 }) statistical ({ 20 }) machine ({ 21 }) translation ({ 22 }) , ({ }) in ({ 23 }) Section ({ 24 }) 4 ({ 25 }) . ({ 26 }) 
# Sentence pair (2675) source length 40 target length 41 alignment score : 3.7857e-10
This study is not only beneficial for the development of computational processing technologies for Vietnamese , a language spoken by over 90 million people , but also for the similar languages such as Thai , Laos , and so on . 
NULL ({ 29 }) This ({ 1 }) study ({ 2 }) is ({ 3 }) not ({ 4 }) only ({ 5 }) beneficial ({ 6 }) for ({ 7 }) the ({ 8 }) development ({ 9 }) of ({ 10 }) computational ({ 11 }) processing ({ 12 }) technologies ({ 13 }) for ({ 14 }) Vietnamese ({ 15 }) , ({ 16 }) a ({ 17 }) language ({ 18 }) spoken ({ 19 }) by ({ 20 }) over ({ 21 }) 90 ({ 22 }) million ({ 23 }) people ({ 24 }) , ({ 25 }) but ({ 26 }) also ({ 27 }) for ({ 28 }) similar ({ 30 }) languages ({ 31 }) such ({ 32 }) as ({ 33 }) Thai ({ 34 }) , ({ 35 }) Laos ({ 36 }) , ({ 37 }) and ({ 38 }) so ({ 39 }) on ({ 40 }) . ({ 41 }) 
# Sentence pair (2676) source length 33 target length 30 alignment score : 2.07082e-08
This study also promotes the computational linguistic studies on how to transfer methods developed for a popular language like English to a language that has not yet intensively studied . 
NULL ({ }) This ({ 1 }) study ({ 2 }) also ({ 3 }) promotes ({ 4 }) the ({ 5 }) computational ({ 6 }) linguistic ({ 7 }) studies ({ 8 }) on ({ 9 }) how ({ 10 }) to ({ 11 }) transfer ({ 12 }) methods ({ 13 }) developed ({ 14 }) for ({ 15 }) a ({ 16 }) popular ({ 17 }) language ({ 18 }) , ({ }) like ({ 19 }) English ({ 20 }) , ({ }) to ({ 21 }) a ({ 22 }) language ({ 23 }) that ({ 24 }) has ({ 25 }) not ({ 26 }) yet ({ 27 }) been ({ }) intensively ({ 28 }) studied ({ 29 }) . ({ 30 }) 
# Sentence pair (2677) source length 20 target length 20 alignment score : 4.78302e-06
Word segmentation in VTB aims to found a standard for word segmentation in a context of multi-level language processing . 
NULL ({ }) Word ({ 1 }) segmentation ({ 2 }) in ({ 3 }) VTB ({ 4 }) aims ({ 5 }) at ({ 6 }) establishing ({ 7 }) a ({ 8 }) standard ({ 9 }) for ({ 10 }) word ({ 11 }) segmentation ({ 12 }) in ({ 13 }) a ({ 14 }) context ({ 15 }) of ({ 16 }) multi-level ({ 17 }) language ({ 18 }) processing ({ 19 }) . ({ 20 }) 
# Sentence pair (2678) source length 43 target length 42 alignment score : 2.29584e-08
VTB specifies 12 types of units that should be identified as words ( Table 1 ) ( Nguyen et al ., a ) , which can be divided into three groups : single , compound , and special `` words '' . 
NULL ({ }) VTB ({ 1 }) specifies ({ 2 }) 12 ({ 3 }) types ({ 4 }) of ({ 5 }) units ({ 6 }) that ({ 7 }) should ({ 8 }) be ({ 9 }) identified ({ 10 }) as ({ 11 }) words ({ 12 }) ( ({ 13 }) Table ({ 14 }) 1 ({ 15 }) ) ({ 16 }) ( ({ 17 }) Nguyen ({ 18 }) et ({ 19 }) al ({ 20 }) ., ({ 21 }) a ({ 22 }) ) ({ 23 }) , ({ 24 }) which ({ 25 }) can ({ 26 }) be ({ 27 }) divided ({ 28 }) up ({ }) into ({ 29 }) three ({ 30 }) groups ({ 31 }) : ({ 32 }) single ({ 33 }) , ({ 34 }) compound ({ 35 }) , ({ 36 }) and ({ 37 }) special ({ 38 }) `` ({ 39 }) words ({ 40 }) '' ({ 41 }) . ({ 42 }) 
# Sentence pair (2679) source length 7 target length 7 alignment score : 0.0967733
Single words contain only one token . 
NULL ({ }) Single ({ 1 }) words ({ 2 }) contain ({ 3 }) only ({ 4 }) one ({ 5 }) token ({ 6 }) . ({ 7 }) 
# Sentence pair (2680) source length 17 target length 15 alignment score : 2.68586e-07
The terminology tokens refers to text spans separated with each other by blank spaces . 
NULL ({ }) The ({ 1 }) terminology ({ 2 }) tokens ({ 3 }) refers ({ 4 }) to ({ 5 }) text ({ 6 }) spans ({ 7 }) that ({ }) are ({ }) separated ({ 8 }) from ({ 9 }) each ({ 10 }) other ({ 11 }) by ({ 12 }) blank ({ 13 }) spaces ({ 14 }) . ({ 15 }) 
# Sentence pair (2681) source length 47 target length 46 alignment score : 2.27402e-08
Compound words have two or more tokens , and are divided into four types : compound words composed by semantic coordination ( semantic-coordinated compound ) , compound words composed by semantic subordination ( semantic-subordinated compound ) , compound words with affx , and reduplicated words . 
NULL ({ }) Compound ({ 1 }) words ({ 2 }) have ({ 3 }) two ({ 4 }) or ({ 5 }) more ({ 6 }) tokens ({ 7 }) , ({ 8 }) and ({ 9 }) are ({ 10 }) divided ({ 11 }) into ({ 12 }) four ({ 13 }) types ({ 14 }) : ({ 15 }) compound ({ 16 }) words ({ 17 }) composed ({ 18 }) by ({ 19 }) semantic ({ 20 }) coordination ({ 21 }) ( ({ 22 }) semantic-coordinated ({ 23 }) compound ({ 24 }) ) ({ 25 }) , ({ 26 }) compound ({ 27 }) words ({ 28 }) composed ({ 29 }) by ({ 30 }) semantic ({ 31 }) subordination ({ 32 }) ( ({ 33 }) semantic-subordinated ({ 34 }) compound ({ 35 }) ) ({ 36 }) , ({ 37 }) compound ({ 38 }) words ({ 39 }) with ({ 40 }) an ({ }) affx ({ 41 }) , ({ 42 }) and ({ 43 }) reduplicated ({ 44 }) words ({ 45 }) . ({ 46 }) 
# Sentence pair (2682) source length 28 target length 29 alignment score : 2.79161e-09
Special `` words '' can be idioms , locutions , proper names , date times , numbers , symbols , sentence marks , foreign words , or abbreviations . 
NULL ({ }) Special ({ 1 }) `` ({ 2 }) words ({ 3 }) '' ({ 4 }) include ({ 5 }) idioms ({ 6 7 }) , ({ 8 }) locutions ({ 9 }) , ({ 10 }) proper ({ 11 }) names ({ 12 }) , ({ 13 }) date ({ 14 }) times ({ 15 }) , ({ 16 }) numbers ({ 17 }) , ({ 18 }) symbols ({ 19 }) , ({ 20 }) sentence ({ 21 }) marks ({ 22 }) , ({ 23 }) foreign ({ 24 }) words ({ 25 }) , ({ 26 }) or ({ 27 }) abbreviations ({ 28 }) . ({ 29 }) 
# Sentence pair (2683) source length 34 target length 32 alignment score : 5.03222e-08
The segmentation of these types of words forms a basis for the POS tagging , with 18 different POS tags shown in Table 2 ( Nguyen et al ., c ) . 
NULL ({ }) The ({ 1 }) segmentation ({ 2 }) of ({ 3 }) these ({ 4 }) types ({ 5 }) of ({ 6 }) words ({ 7 }) forms ({ 8 }) a ({ 9 }) basis ({ 10 }) for ({ 11 }) the ({ 12 }) POS ({ 13 }) tagging ({ 14 }) , ({ 15 }) with ({ 16 }) 18 ({ 17 }) different ({ 18 }) POS ({ 19 }) tags ({ 20 }) , ({ }) as ({ }) shown ({ 21 }) in ({ 22 }) Table ({ 23 }) 2 ({ 24 }) ( ({ 25 }) Nguyen ({ 26 }) et ({ 27 }) al ({ 28 }) ., ({ 29 }) c ({ 30 }) ) ({ 31 }) . ({ 32 }) 
# Sentence pair (2684) source length 18 target length 19 alignment score : 8.70493e-08
Each unit in Table 1 goes with several example words of which English translations are given in parentheses . 
NULL ({ 11 }) Each ({ 1 }) unit ({ 2 }) in ({ 3 }) Table ({ 4 }) 1 ({ 5 }) goes ({ 6 }) with ({ 7 }) several ({ 8 }) example ({ 9 }) words ({ 10 }) ; ({ 12 }) English ({ 13 }) translations ({ 14 }) are ({ 15 }) provided ({ 16 }) in ({ 17 }) parentheses ({ 18 }) . ({ 19 }) 
# Sentence pair (2685) source length 35 target length 32 alignment score : 2.56608e-18
Besides , we added a translation for each token when possible , so that the readers unfamiliar with Vietnamese can have an intuitive idea of how the compound words are formed . 
NULL ({ 15 25 }) Furthermore ({ 1 }) , ({ 2 }) we ({ 3 }) added ({ 4 }) a ({ 5 }) translation ({ 6 }) for ({ 7 }) each ({ 8 }) token ({ 9 }) , ({ }) where ({ 10 }) possible ({ 11 }) , ({ 12 }) so ({ 13 }) that ({ 14 }) readers ({ 16 }) who ({ }) are ({ }) unfamiliar ({ 17 }) with ({ 18 }) Vietnamese ({ 19 }) can ({ 20 }) have ({ 21 }) an ({ 22 }) intuitive ({ 23 }) idea ({ 24 }) as ({ }) to ({ }) how ({ 26 }) the ({ 27 }) compound ({ 28 }) words ({ 29 }) are ({ 30 }) formed ({ 31 }) . ({ 32 }) 
# Sentence pair (2686) source length 17 target length 17 alignment score : 0.00215777
The subscript of a token translation is the index of that token in the compound word . 
NULL ({ }) The ({ 1 }) subscript ({ 2 }) of ({ 3 }) a ({ 4 }) token ({ 5 }) translation ({ 6 }) is ({ 7 }) the ({ 8 }) index ({ 9 }) of ({ 10 }) that ({ 11 }) token ({ 12 }) in ({ 13 }) the ({ 14 }) compound ({ 15 }) word ({ 16 }) . ({ 17 }) 
# Sentence pair (2687) source length 28 target length 27 alignment score : 1.82453e-06
However , for some tokens , we could not find any appropriate English translation , so we give it an empty translation marked with an asterisk . 
NULL ({ }) However ({ 1 }) , ({ 2 }) for ({ 3 }) some ({ 4 }) tokens ({ 5 }) , ({ 6 }) we ({ 7 }) could ({ 8 }) not ({ 9 }) find ({ 10 }) any ({ 11 }) appropriate ({ 12 }) English ({ 13 }) translation ({ 14 }) , ({ 15 }) so ({ 16 }) we ({ 17 }) gave ({ 18 }) it ({ 19 }) an ({ 20 }) empty ({ 21 }) translation ({ 22 }) , ({ }) marked ({ 23 }) with ({ 24 }) an ({ 25 }) asterisk ({ 26 }) . ({ 27 }) 
# Sentence pair (2688) source length 22 target length 21 alignment score : 3.34438e-05
Note that a Vietnamese word or a token in context can have other meanings in addition to the given translations . 
NULL ({ }) Note ({ 1 }) that ({ 2 }) a ({ 3 }) Vietnamese ({ 4 }) word ({ 5 }) or ({ 6 }) a ({ 7 }) token ({ 8 }) in ({ 9 }) context ({ 10 }) can ({ 11 }) have ({ 12 }) other ({ 13 }) meanings ({ 14 }) , ({ }) in ({ 15 }) addition ({ 16 }) to ({ 17 }) the ({ 18 }) given ({ 19 }) translations ({ 20 }) . ({ 21 }) 
# Sentence pair (2689) source length 22 target length 20 alignment score : 1.03711e-13
A special type of words in Vietnamese is classifer noun , denoted by the part-of-speech Nc in Table 2 . 
NULL ({ }) A ({ 1 }) classifier ({ 9 }) noun ({ 10 }) , ({ 11 }) denoted ({ 12 }) by ({ 13 }) the ({ 14 }) part-of-speech ({ 15 }) Nc ({ 16 }) in ({ 17 }) Table ({ 18 }) 2 ({ 19 }) , ({ }) is ({ 8 }) a ({ }) special ({ 2 }) type ({ 3 }) of ({ 4 }) word ({ 5 }) in ({ 6 }) Vietnamese ({ 7 }) . ({ 20 }) 
# Sentence pair (2690) source length 15 target length 14 alignment score : 0.0016437
Classifier nouns are specific to several Southeast Asian languages like Vietnamese and Thai . 
NULL ({ }) Classifier ({ 1 }) nouns ({ 2 }) are ({ 3 }) specific ({ 4 }) to ({ 5 }) several ({ 6 }) Southeast ({ 7 }) Asian ({ 8 }) languages ({ 9 }) , ({ }) like ({ 10 }) Vietnamese ({ 11 }) and ({ 12 }) Thai ({ 13 }) . ({ 14 }) 
# Sentence pair (2691) source length 13 target length 13 alignment score : 0.010582
One of the functions of classifier nouns is to express the definiteness . 
NULL ({ }) One ({ 1 }) of ({ 2 }) the ({ 3 }) functions ({ 4 }) of ({ 5 }) classifier ({ 6 }) nouns ({ 7 }) is ({ 8 }) to ({ 9 }) express ({ 10 }) the ({ 11 }) definiteness ({ 12 }) . ({ 13 }) 
# Sentence pair (2692) source length 30 target length 30 alignment score : 1.46777e-11
For example , the common noun `` bn '' means tables in general , while `` ci bn '' means a specific table similar to the table in English . 
NULL ({ 12 }) For ({ 1 }) example ({ 2 }) , ({ 3 }) the ({ 4 }) common ({ 5 }) noun ({ 6 }) `` ({ 7 }) bn ({ 8 }) '' ({ 9 }) generally ({ 13 }) means ({ 10 }) tables ({ 11 }) , ({ 14 }) while ({ 15 }) `` ({ 16 }) ci ({ 17 }) bn ({ 18 }) '' ({ 19 }) means ({ 20 }) a ({ 21 }) specific ({ 22 }) table ({ 23 }) , ({ }) similar ({ 24 }) to ({ 25 }) the ({ 26 }) table ({ 27 }) in ({ 28 }) English ({ 29 }) . ({ 30 }) 
# Sentence pair (2693) source length 25 target length 25 alignment score : 3.40562e-06
In this section , we analyzed the VTB corpus to know whether the diffculties in Vietnamese word segmentation affected the quality of VTB annotations . 
NULL ({ }) In ({ 1 }) this ({ 2 }) section ({ 3 }) , ({ 4 }) we ({ 5 }) analyzed ({ 6 }) the ({ 7 }) VTB ({ 8 }) corpus ({ 9 }) to ({ 10 }) determine ({ 11 }) whether ({ 12 }) the ({ 13 }) difficulties ({ 14 }) in ({ 15 }) Vietnamese ({ 16 }) word ({ 17 }) segmentation ({ 18 }) affected ({ 19 }) the ({ 20 }) quality ({ 21 }) of ({ 22 }) VTB ({ 23 }) annotations ({ 24 }) . ({ 25 }) 
# Sentence pair (2694) source length 12 target length 13 alignment score : 2.43818e-05
The analysis results revealed several types of inconsistent annotations , which are also 
NULL ({ }) The ({ 1 }) analysis ({ 2 }) revealed ({ 3 4 }) several ({ 5 }) types ({ 6 }) of ({ 7 }) inconsistent ({ 8 }) annotations ({ 9 }) , ({ 10 }) which ({ 11 }) are ({ 12 }) also ({ 13 }) 
# Sentence pair (2695) source length 4 target length 4 alignment score : 0.351567
Vietnamese word segmentation . 
NULL ({ }) Vietnamese ({ 1 }) word ({ 2 }) segmentation ({ 3 }) . ({ 4 }) 
# Sentence pair (2696) source length 20 target length 23 alignment score : 1.38835e-20
Our analysis is based on two types of inconsistency : variation and structural inconsistency , whose definitions and details are given below . 
NULL ({ 18 19 }) Our ({ 1 }) analysis ({ 2 }) is ({ 3 }) based ({ 4 }) on ({ 5 }) two ({ 6 }) types ({ 7 }) of ({ 8 }) inconsistencies ({ 9 }) : ({ 10 }) variation ({ 11 }) and ({ 12 }) structural ({ 13 }) inconsistency ({ 14 }) , ({ 15 }) which ({ 16 17 }) are ({ 20 }) defined ({ 21 }) below ({ 22 }) . ({ 23 }) 
# Sentence pair (2697) source length 21 target length 20 alignment score : 2.50322e-08
Variation inconsistency : is a sequence of tokens which have more than one way of seg-mentation in the corpus . 
NULL ({ }) Variation ({ 1 }) inconsistency ({ 2 }) : ({ 3 }) is ({ 4 }) a ({ 5 }) sequence ({ 6 }) of ({ 7 }) tokens ({ 8 }) , ({ }) which ({ 9 }) has ({ 10 }) more ({ 11 }) than ({ 12 }) one ({ 13 }) way ({ 14 }) of ({ 15 }) segmentation ({ 16 }) in ({ 17 }) the ({ 18 }) corpus ({ 19 }) . ({ 20 }) 
# Sentence pair (2698) source length 28 target length 27 alignment score : 6.99281e-06
For example , `` con gi/girl '' can remain as one word , or be segmented into two words `` con '' and `` gi '' . 
NULL ({ }) For ({ 1 }) example ({ 2 }) , ({ 3 }) `` ({ 4 }) con ({ 5 }) gi/girl ({ 6 }) '' ({ 7 }) can ({ 8 }) remain ({ 9 }) as ({ 10 }) one ({ 11 }) word ({ 12 }) , ({ 13 }) or ({ 14 }) be ({ 15 }) segmented ({ 16 }) into ({ 17 }) two ({ 18 }) words ({ 19 }) , ({ }) `` ({ 20 }) con ({ 21 }) '' ({ 22 }) and ({ 23 }) `` ({ 24 }) gi ({ 25 }) '' ({ 26 }) . ({ 27 }) 
# Sentence pair (2699) source length 14 target length 13 alignment score : 9.81246e-06
A variation can be an annotation inconsistency , or an ambiguity inVietnamese . 
NULL ({ }) A ({ 1 }) variation ({ 2 }) can ({ 3 }) be ({ 4 }) an ({ 5 }) annotation ({ 6 }) inconsistency ({ 7 }) , ({ 8 }) or ({ 9 }) an ({ 10 }) ambiguity ({ 11 }) in ({ }) Vietnamese ({ 12 }) . ({ 13 }) 
# Sentence pair (2700) source length 31 target length 31 alignment score : 1.3826e-07
While ambiguity cases reflect the diffculty of the language , annotation inconsistencies are usually caused by the confusion in the decision of annotators , which should be eliminated in annotation . 
NULL ({ }) While ({ 1 }) ambiguity ({ 2 }) cases ({ 3 }) reflect ({ 4 }) the ({ 5 }) difficulty ({ 6 }) of ({ 7 }) the ({ 8 }) language ({ 9 }) , ({ 10 }) annotation ({ 11 }) inconsistencies ({ 12 }) are ({ 13 }) usually ({ 14 }) caused ({ 15 }) by ({ 16 }) the ({ 17 }) confusion ({ 18 }) in ({ 19 }) the ({ 20 }) decision ({ 21 }) of ({ 22 }) annotators ({ 23 }) , ({ 24 }) which ({ 25 }) should ({ 26 }) be ({ 27 }) eliminated ({ 28 }) in ({ 29 }) annotation ({ 30 }) . ({ 31 }) 
# Sentence pair (2701) source length 16 target length 15 alignment score : 0.000304502
We use the term variation instance to refer a single occurence of a variation . 
NULL ({ }) We ({ 1 }) use ({ 2 }) the ({ 3 }) term ({ 4 }) variation ({ 5 }) instance ({ 6 }) to ({ 7 }) refer ({ 8 }) to ({ }) a ({ 9 }) single ({ 10 }) occurrence ({ 11 }) of ({ 12 }) a ({ 13 }) variation ({ 14 }) . ({ 15 }) 
# Sentence pair (2702) source length 31 target length 30 alignment score : 1.43371e-07
Structural inconsistency : happens when different sequences have similar structures , thus should be splitted in the same way , but are segmented in different ways in the corpus . 
NULL ({ }) Structural ({ 1 }) inconsistency ({ 2 }) : ({ 3 }) happens ({ 4 }) when ({ 5 }) different ({ 6 }) sequences ({ 7 }) have ({ 8 }) similar ({ 9 }) structures ({ 10 }) , ({ 11 }) and ({ }) thus ({ 12 }) should ({ 13 }) be ({ 14 }) split ({ 15 }) in ({ 16 }) the ({ 17 }) same ({ 18 }) way ({ 19 }) , ({ 20 }) but ({ 21 }) are ({ 22 }) segmented ({ 23 }) in ({ 24 }) different ({ 25 }) ways ({ 26 }) in ({ 27 }) the ({ 28 }) corpus ({ 29 }) . ({ 30 }) 
# Sentence pair (2703) source length 58 target length 56 alignment score : 4.58294e-13
For example , `` con gi/girl '' and `` con trai/boy '' have similar structures , a combination of a classifier noun and a common noun Nc + N , so when `` con gi/girl '' is splitted and `` con trai/boy '' is not , it is considered as a structural inconsistency of Nc . 
NULL ({ 16 }) For ({ 1 }) example ({ 2 }) , ({ 3 }) `` ({ 4 }) con ({ 5 }) gi/girl ({ 6 }) '' ({ 7 }) and ({ 8 }) `` ({ 9 }) con ({ 10 }) trai/boy ({ 11 }) '' ({ 12 }) have ({ 13 }) similar ({ 14 }) structures ({ 15 }) : ({ }) a ({ 17 }) combination ({ 18 }) of ({ 19 }) a ({ 20 }) classifier ({ 21 }) noun ({ 22 }) and ({ 23 }) a ({ 24 }) common ({ 25 }) noun ({ 26 }) , ({ }) Nc ({ 27 }) + ({ 28 }) N ({ 29 }) , ({ 30 }) so ({ 31 }) when ({ 32 }) `` ({ 33 }) con ({ 34 }) gi/girl ({ 35 }) '' ({ 36 }) is ({ 37 }) split ({ 38 }) , ({ }) and ({ 39 }) `` ({ 40 }) con ({ 41 }) trai/boy ({ 42 }) '' ({ 43 }) is ({ 44 }) not ({ 45 }) , ({ 46 }) it ({ 47 }) is ({ 48 }) considered ({ 49 }) as ({ 50 }) a ({ 51 }) structural ({ 52 }) inconsistency ({ 53 }) of ({ 54 }) Nc ({ 55 }) . ({ 56 }) 
# Sentence pair (2704) source length 24 target length 26 alignment score : 7.54476e-17
It is likely that structural inconsistency in word segmentation level makes the higher levels of processing , POS tagging and bracketing , become more complicated . 
NULL ({ 22 }) It ({ 1 }) is ({ 2 }) likely ({ 3 }) that ({ 4 }) structural ({ 5 }) inconsistency ({ 6 }) at ({ 7 }) the ({ }) word ({ 8 }) segmentation ({ 9 }) level ({ 10 }) complicates ({ 11 }) the ({ 12 }) higher ({ 13 }) levels ({ 14 }) of ({ 15 }) processing ({ 16 }) , ({ 17 }) including ({ }) POS ({ 18 }) tagging ({ 19 }) and ({ 20 }) bracketing ({ 21 23 24 25 }) . ({ 26 }) 
# Sentence pair (2705) source length 28 target length 27 alignment score : 8.44046e-12
The detection method for variation inconsistency is based on N-gram sequences and the phrase structures in VTB treebank , following the definition of variation inconsistency above . 
NULL ({ }) The ({ 1 }) detection ({ 2 }) method ({ 3 }) for ({ 4 }) variation ({ 5 }) inconsistency ({ 6 }) is ({ 7 }) based ({ 8 }) on ({ 9 }) N-gram ({ 10 }) sequences ({ 11 }) and ({ 12 }) the ({ 13 }) phrase ({ 14 }) structures ({ 15 }) in ({ 16 }) the ({ }) VTB ({ 17 18 }) , ({ 19 }) following ({ 20 }) the ({ 21 }) definition ({ 22 }) for ({ 23 }) variation ({ 24 }) inconsistency ({ 25 }) , ({ }) above ({ 26 }) . ({ 27 }) 
# Sentence pair (2706) source length 30 target length 30 alignment score : 5.37042e-06
In details , we counted N-gram sequences of different lengths in VTB that have two or more ways of word segmentation , satisfying one of the following two conditions : 
NULL ({ }) In ({ 1 }) detail ({ 2 }) , ({ 3 }) we ({ 4 }) counted ({ 5 }) N-gram ({ 6 }) sequences ({ 7 }) of ({ 8 }) different ({ 9 }) lengths ({ 10 }) in ({ 11 }) VTB ({ 12 }) that ({ 13 }) have ({ 14 }) two ({ 15 }) or ({ 16 }) more ({ 17 }) ways ({ 18 }) of ({ 19 }) word ({ 20 }) segmentation ({ 21 }) , ({ 22 }) satisfying ({ 23 }) one ({ 24 }) of ({ 25 }) the ({ 26 }) following ({ 27 }) two ({ 28 }) conditions ({ 29 }) : ({ 30 }) 
# Sentence pair (2707) source length 18 target length 18 alignment score : 0.0015438
N tokens are all in the same phrase , and all have the same depth in phrase . 
NULL ({ }) N ({ 1 }) tokens ({ 2 }) are ({ 3 }) all ({ 4 }) in ({ 5 }) the ({ 6 }) same ({ 7 }) phrase ({ 8 }) , ({ 9 }) and ({ 10 }) all ({ 11 }) have ({ 12 }) the ({ 13 }) same ({ 14 }) depth ({ 15 }) in ({ 16 }) phrase ({ 17 }) . ({ 18 }) 
# Sentence pair (2708) source length 38 target length 38 alignment score : 1.2697e-06
For example , the 3-gram " nh tnh ngha ( house of gratitude ) " in this structure " ( NP ( Nc-H cn ) ( N nh ) ( A tnh ngha ) ) , " OR 
NULL ({ }) For ({ 1 }) example ({ 2 }) , ({ 3 }) the ({ 4 }) 3-gram ({ 5 }) " ({ 6 }) nh ({ 7 }) tnh ({ 8 }) ngha ({ 9 }) ( ({ 10 }) house ({ 11 }) of ({ 12 }) gratitude ({ 13 }) ) ({ 14 }) " ({ 15 }) in ({ 16 }) this ({ 17 }) structure ({ 18 }) " ({ 19 }) ( ({ 20 }) NP ({ 21 }) ( ({ 22 }) Nc-H ({ 23 }) cn ({ 24 }) ) ({ 25 }) ( ({ 26 }) N ({ 27 }) nh ({ 28 }) ) ({ 29 }) ( ({ 30 }) A ({ 31 }) tnh ({ 32 }) ngha ({ 33 }) ) ({ 34 }) ) ({ 35 }) , ({ 36 }) " ({ 37 }) OR ({ 38 }) 
# Sentence pair (2709) source length 37 target length 37 alignment score : 1.28065e-06
nh tnh ngha " in this structure " ( NP ( Nc-H cn ) ( N nh ) ( ADJP ( A tnh ngha ) ) ) , " where the ADJP contains only one word . 
NULL ({ }) nh ({ 1 }) tnh ({ 2 }) ngha ({ 3 }) " ({ 4 }) in ({ 5 }) this ({ 6 }) structure ({ 7 }) " ({ 8 }) ( ({ 9 }) NP ({ 10 }) ( ({ 11 }) Nc-H ({ 12 }) cn ({ 13 }) ) ({ 14 }) ( ({ 15 }) N ({ 16 }) nh ({ 17 }) ) ({ 18 }) ( ({ 19 }) ADJP ({ 20 }) ( ({ 21 }) A ({ 22 }) tnh ({ 23 }) ngha ({ 24 }) ) ({ 25 }) ) ({ 26 }) ) ({ 27 }) , ({ 28 }) " ({ 29 }) where ({ 30 }) the ({ 31 }) ADJP ({ 32 }) contains ({ 33 }) only ({ 34 }) one ({ 35 }) word ({ 36 }) . ({ 37 }) 
# Sentence pair (2710) source length 17 target length 16 alignment score : 2.48668e-07
Table 3 shows the overall statistics of the variation inconsistency detected by the above method . 
NULL ({ }) Table ({ 1 }) 3 ({ 2 }) shows ({ 3 }) the ({ 4 }) overall ({ 5 }) statistics ({ 6 }) of ({ 7 }) the ({ 8 }) variation ({ 9 }) inconsistency ({ 10 }) detected ({ 11 }) by ({ 12 }) the ({ 13 }) method ({ 15 }) described ({ }) above ({ 14 }) . ({ 16 }) 
# Sentence pair (2711) source length 23 target length 23 alignment score : 3.36151e-05
Most of the diffcult cases of word segmentation lie in two-token variations , occupying the majority of variations ( 92 .9% ) . 
NULL ({ }) Most ({ 1 }) of ({ 2 }) the ({ 3 }) diffcult ({ 4 }) cases ({ 5 }) of ({ 6 }) word ({ 7 }) segmentation ({ 8 }) occur ({ 9 }) in ({ 10 }) two-token ({ 11 }) variations ({ 12 }) , ({ 13 }) occupying ({ 14 }) the ({ 15 }) majority ({ 16 }) of ({ 17 }) variations ({ 18 }) ( ({ 19 }) 92 ({ 20 }) .9% ({ 21 }) ) ({ 22 }) . ({ 23 }) 
# Sentence pair (2712) source length 32 target length 31 alignment score : 1.38133e-11
This ratio of 2-gram variations is much higher than the evarage ratio of two-token words in Vietnamese reported in ( Nguyen et al., 2009a ) , which is 80% percent . 
NULL ({ }) This ({ 1 }) ratio ({ 2 }) of ({ 3 }) 2-gram ({ 4 }) variations ({ 5 }) is ({ 6 }) much ({ 7 }) higher ({ 8 }) than ({ 9 }) the ({ 10 }) average ({ 11 }) ratio ({ 12 }) of ({ 13 }) two-token ({ 14 }) words ({ 15 }) in ({ 16 }) Vietnamese ({ 17 }) , ({ }) as ({ }) reported ({ 18 }) in ({ 19 }) ( ({ 20 }) Nguyen ({ 21 }) et ({ 22 }) al., ({ 23 }) 2009a ({ 24 }) ) ({ 25 }) , ({ 26 }) which ({ 27 }) is ({ 28 }) 80% ({ 29 30 }) . ({ 31 }) 
# Sentence pair (2713) source length 18 target length 17 alignment score : 0.000108907
Variations have lengths of three and four tokens occupy 6 .1% and 1 .0% , respectively . 
NULL ({ }) Variations ({ 1 }) that ({ }) have ({ 2 }) lengths ({ 3 }) of ({ 4 }) three ({ 5 }) and ({ 6 }) four ({ 7 }) tokens ({ 8 }) occupy ({ 9 }) 6 ({ 10 }) .1% ({ 11 }) and ({ 12 }) 1 ({ 13 }) .0% ({ 14 }) , ({ 15 }) respectively ({ 16 }) . ({ 17 }) 
# Sentence pair (2714) source length 31 target length 29 alignment score : 6.65207e-17
We estimated the precision of our method by randomly selected 130 2-gram variation instances extracted from the above method , and manually checked whether they are true inconsistency . 
NULL ({ 17 }) We ({ 1 }) estimated ({ 2 }) the ({ 3 }) precision ({ 4 }) of ({ 5 }) our ({ 6 }) method ({ 7 }) by ({ 8 }) randomly ({ 9 }) selecting ({ 10 }) 130 ({ 11 }) 2-gram ({ 12 }) variation ({ 13 }) instances ({ 14 }) , ({ }) extracted ({ 15 }) from ({ 16 }) the ({ }) method ({ 19 }) described ({ }) above ({ 18 }) , ({ 20 }) and ({ 21 }) manually ({ 22 }) checked ({ 23 }) whether ({ 24 }) the ({ }) inconsistencies ({ 25 28 }) are ({ 26 }) true ({ 27 }) . ({ 29 }) 
# Sentence pair (2715) source length 16 target length 16 alignment score : 0.00128907
We found that 129 cases occupying 99 .2% of all extracted 2-grams are true inconsistency . 
NULL ({ }) We ({ 1 }) found ({ 2 }) that ({ 3 }) 129 ({ 4 }) cases ({ 5 }) occupying ({ 6 }) 99 ({ 7 }) .2% ({ 8 }) of ({ 9 }) all ({ 10 }) extracted ({ 11 }) 2-grams ({ 12 }) are ({ 13 }) true ({ 14 }) inconsistencies ({ 15 }) . ({ 16 }) 
# Sentence pair (2716) source length 44 target length 42 alignment score : 1.03327e-10
Only one instance is an ambiguous sequence gi c , which is one word when it means price , and two words gi / price c / all in u c gi c / all have ( their own ) price . 
NULL ({ }) Only ({ 1 }) one ({ 2 }) instance ({ 3 }) of ({ }) inconsistency ({ }) was ({ 4 }) an ({ 5 }) ambiguous ({ 6 }) sequence ({ 7 }) gi ({ 8 }) c ({ 9 }) , ({ 10 }) which ({ 11 }) is ({ 12 }) one ({ 13 }) word ({ 14 }) when ({ 15 }) it ({ 16 }) means ({ 17 }) price ({ 18 }) , ({ 19 }) and ({ 20 }) two ({ 21 }) words ({ 22 }) gi ({ 23 }) / ({ 24 }) price ({ 25 }) c ({ 26 }) / ({ 27 }) all ({ 28 }) in ({ 29 }) u ({ 30 }) c ({ 31 }) gi ({ 32 }) c ({ 33 }) / ({ 34 }) all ({ 35 }) have ({ 36 }) ( ({ 37 }) their ({ 38 }) own ({ 39 }) ) ({ 40 }) price ({ 41 }) . ({ 42 }) 
# Sentence pair (2717) source length 24 target length 26 alignment score : 3.21463e-20
The precision of our method is high enough so that so we can use the extracted variations to study the insights of word segmentation problem . 
NULL ({ 20 }) The ({ 1 }) precision ({ 2 }) for ({ 3 }) our ({ 4 }) method ({ 5 }) is ({ 6 }) high ({ 7 }) , ({ 8 }) so ({ 9 10 11 }) we ({ 12 }) can ({ 13 }) use ({ 14 }) the ({ 15 }) extracted ({ 16 }) variations ({ 17 }) to ({ 18 }) provide ({ 19 }) insights ({ 21 }) on ({ 22 }) the ({ }) word ({ 23 }) segmentation ({ 24 }) problem ({ 25 }) . ({ 26 }) 
# Sentence pair (2718) source length 18 target length 18 alignment score : 3.08683e-06
We further analyzed the 2-gram variations to know what types of 2-grams were most confusing to annotators . 
NULL ({ }) We ({ 1 }) further ({ 2 }) analyzed ({ 3 }) the ({ 4 }) 2-gram ({ 5 }) variations ({ 6 }) to ({ 7 }) understand ({ 8 }) what ({ 9 }) types ({ 10 }) of ({ 11 }) 2-grams ({ 12 }) were ({ 13 }) most ({ 14 }) confusing ({ 15 }) for ({ 16 }) annotators ({ 17 }) . ({ 18 }) 
# Sentence pair (2719) source length 22 target length 23 alignment score : 1.51005e-09
The analysis results showed that compound nouns , compound verbs , and compound adjectives are the top diffcult cases of word segmentation . 
NULL ({ }) The ({ 1 }) analysis ({ 2 }) revealed ({ 3 4 }) that ({ 5 }) compound ({ 6 }) nouns ({ 7 }) , ({ 8 }) compound ({ 9 }) verbs ({ 10 }) , ({ 11 }) and ({ 12 }) compound ({ 13 }) adjectives ({ 14 }) are ({ 15 }) the ({ 16 }) most ({ 17 }) difficult ({ 18 }) cases ({ 19 }) of ({ 20 }) word ({ 21 }) segmentation ({ 22 }) . ({ 23 }) 
# Sentence pair (2720) source length 20 target length 20 alignment score : 0.000200355
We classified the 2-gram variations according to their POS sequences in case the tokens in the 2-gram are splitted . 
NULL ({ }) We ({ 1 }) classified ({ 2 }) the ({ 3 }) 2-gram ({ 4 }) variations ({ 5 }) according ({ 6 }) to ({ 7 }) their ({ 8 }) POS ({ 9 }) sequences ({ 10 }) in ({ 11 }) case ({ 12 }) the ({ 13 }) tokens ({ 14 }) in ({ 15 }) the ({ 16 }) 2-gram ({ 17 }) are ({ 18 }) split ({ 19 }) . ({ 20 }) 
# Sentence pair (2721) source length 31 target length 33 alignment score : 1.43499e-31
There are totally 54 patterns of POS sequence , of which top 10 confusing patterns , a long with their counts of 2-gram variations , and examples are shown in Table 4 . 
NULL ({ 9 10 11 20 }) There ({ 1 }) are ({ 2 }) a ({ }) total ({ }) of ({ }) 54 ({ 3 4 }) patterns ({ 5 }) of ({ 6 }) POS ({ 7 }) sequences ({ 8 }) . ({ }) The ({ }) top ({ 12 }) 10 ({ 13 }) confusing ({ 14 }) patterns ({ 15 }) , ({ 16 }) their ({ 17 }) counts ({ 18 19 21 }) of ({ 22 }) 2-gram ({ 23 }) variations ({ 24 }) , ({ 25 }) and ({ 26 }) examples ({ 27 }) are ({ 28 }) depicted ({ 29 }) in ({ 30 }) Table ({ 31 }) 4 ({ 32 }) . ({ 33 }) 
# Sentence pair (2722) source length 26 target length 24 alignment score : 6.27549e-08
Table 5 and Table 6 show the POS patterns which a specific POS tag appearing at the beginning or ending of the sequence . 
NULL ({ }) Table ({ 1 }) 5 ({ 2 }) and ({ 3 }) Table ({ 4 }) 6 ({ 5 }) show ({ 6 }) the ({ 7 }) POS ({ 8 }) patterns ({ 9 }) that ({ 10 }) are ({ }) a ({ 11 }) specific ({ 12 }) POS ({ 13 }) tag ({ 14 }) , ({ }) appearing ({ 15 }) at ({ 16 }) the ({ 17 }) beginning ({ 18 }) or ({ 19 }) ending ({ 20 }) of ({ 21 }) the ({ 22 }) sequence ({ 23 }) . ({ 24 }) 
# Sentence pair (2723) source length 26 target length 25 alignment score : 3.97506e-06
Investigating the inconsistent 2-grams extracted , we found that most of them are compound words according to the VTB guidelines ( Section 2 ) . 
NULL ({ }) Investigating ({ 1 }) the ({ 2 }) inconsistent ({ 3 }) 2-grams ({ 4 }) extracted ({ 5 }) , ({ 6 }) we ({ 7 }) found ({ 8 }) that ({ 9 }) most ({ 10 }) of ({ 11 }) them ({ 12 }) are ({ 13 }) compound ({ 14 }) words ({ 15 }) , ({ }) according ({ 16 }) to ({ 17 }) the ({ 18 }) VTB ({ 19 }) guidelines ({ 20 }) ( ({ 21 }) Section ({ 22 }) 2 ({ 23 }) ) ({ 24 }) . ({ 25 }) 
# Sentence pair (2724) source length 37 target length 37 alignment score : 1.04214e-08
One of the reasons why the compound words are sometimes splitted , is because the tokens in those compound words have their own meanings , which seem to contribute to the whole meaning of the compounds . 
NULL ({ }) One ({ 1 }) of ({ 2 }) the ({ 3 }) reasons ({ 4 }) why ({ 5 }) the ({ 6 }) compound ({ 7 }) words ({ 8 }) are ({ 9 }) sometimes ({ 10 }) split ({ 11 }) , ({ 12 }) is ({ 13 }) because ({ 14 }) the ({ 15 }) tokens ({ 16 }) in ({ 17 }) those ({ 18 }) compound ({ 19 }) words ({ 20 }) have ({ 21 }) their ({ 22 }) own ({ 23 }) meanings ({ 24 }) , ({ 25 }) which ({ 26 }) seem ({ 27 }) to ({ 28 }) contribute ({ 29 }) to ({ 30 }) the ({ 31 }) overall ({ 32 }) meaning ({ 33 }) of ({ 34 }) the ({ 35 }) compounds ({ 36 }) . ({ 37 }) 
# Sentence pair (2725) source length 23 target length 23 alignment score : 2.86741e-05
This can be seen through the examples given in Table 4 , where the meanings of tokens are given with a subscript . 
NULL ({ }) This ({ 1 }) can ({ 2 }) be ({ 3 }) seen ({ 4 }) through ({ 5 }) the ({ 6 }) examples ({ 7 }) provided ({ 8 }) in ({ 9 }) Table ({ 10 }) 4 ({ 11 }) , ({ 12 }) where ({ 13 }) the ({ 14 }) meanings ({ 15 }) of ({ 16 }) tokens ({ 17 }) are ({ 18 }) given ({ 19 }) with ({ 20 }) a ({ 21 }) subscript ({ 22 }) . ({ 23 }) 
# Sentence pair (2726) source length 13 target length 16 alignment score : 3.97248e-20
This problem seems to have caused a lot of trouble for the annotators of VTB . 
NULL ({ 7 8 9 }) This ({ 1 }) scenario ({ 2 }) has ({ 5 }) proven ({ 3 }) to ({ 4 }) be ({ 6 }) problematic ({ 10 }) for ({ 11 }) the ({ 12 }) annotators ({ 13 }) of ({ 14 }) VTB ({ 15 }) . ({ 16 }) 
# Sentence pair (2727) source length 29 target length 29 alignment score : 3.4329e-10
Furthermore , observing the POS patterns in Table 5 and Table 6 , we can see the potential of structural inconsistency , in particular for closed-set POS tags . 
NULL ({ 23 }) Furthermore ({ 1 }) , ({ 2 }) by ({ }) observing ({ 3 }) the ({ 4 }) POS ({ 5 }) patterns ({ 6 }) in ({ 7 }) Table ({ 8 }) 5 ({ 9 }) and ({ 10 }) Table ({ 11 }) 6 ({ 12 }) , ({ 13 }) we ({ 14 }) can ({ 15 }) see ({ 16 }) the ({ 17 }) potential ({ 18 }) for ({ 19 }) structural ({ 20 }) inconsistency ({ 21 }) , ({ 22 }) particularly ({ 24 }) for ({ 25 }) closed-set ({ 26 }) POS ({ 27 }) tags ({ 28 }) . ({ 29 }) 
# Sentence pair (2728) source length 32 target length 32 alignment score : 8.08779e-07
Among them , classifier nouns ( Nc ) and affxes ( S ) are two typical cases of structural inconsistency , which will be used in several settings of our experiments . 
NULL ({ }) Among ({ 1 }) them ({ 2 }) , ({ 3 }) classifier ({ 4 }) nouns ({ 5 }) ( ({ 6 }) Nc ({ 7 }) ) ({ 8 }) and ({ 9 }) affixes ({ 10 }) ( ({ 11 }) S ({ 12 }) ) ({ 13 }) are ({ 14 }) two ({ 15 }) typical ({ 16 }) cases ({ 17 }) of ({ 18 }) structural ({ 19 }) inconsistency ({ 20 }) , ({ 21 }) which ({ 22 }) will ({ 23 }) be ({ 24 }) used ({ 25 }) in ({ 26 }) several ({ 27 }) settings ({ 28 }) for ({ 29 }) our ({ 30 }) experiments ({ 31 }) . ({ 32 }) 
# Sentence pair (2729) source length 35 target length 38 alignment score : 1.5457e-14
The same affx or classifier noun can modify different nouns , so when they are sometimes splitted , and sometimes combined in the variations , we can conclude that classifier nouns and affxes involve in structural inconsistency . 
NULL ({ 18 }) The ({ 1 }) same ({ 2 }) affx ({ 3 }) or ({ 4 }) classifier ({ 5 }) noun ({ 6 }) can ({ 7 }) modify ({ 8 }) different ({ 9 }) nouns ({ 10 }) , ({ 11 }) so ({ 12 }) when ({ 13 }) they ({ 14 }) are ({ 15 }) sometimes ({ 16 }) split ({ 17 }) and ({ 19 }) combined ({ 20 21 }) in ({ 22 }) the ({ 23 }) variations ({ 24 }) , ({ 25 }) we ({ 26 }) can ({ 27 }) conclude ({ 28 }) that ({ 29 }) classifier ({ 30 }) nouns ({ 31 }) and ({ 32 }) affixes ({ 33 }) involve ({ 34 }) in-structural ({ 35 36 }) inconsistencies ({ 37 }) . ({ 38 }) 
# Sentence pair (2730) source length 19 target length 19 alignment score : 6.30779e-05
In the following section , we presents our detection method for structural inconsistency for classifier nouns and affxes . 
NULL ({ }) In ({ 1 }) the ({ 2 }) following ({ 3 }) section ({ 4 }) , ({ 5 }) we ({ 6 }) present ({ 7 }) our ({ 8 }) detection ({ 9 }) method ({ 10 }) for ({ 11 }) structural ({ 12 }) inconsistency ({ 13 }) for ({ 14 }) classifier ({ 15 }) nouns ({ 16 }) and ({ 17 }) affixes ({ 18 }) . ({ 19 }) 
# Sentence pair (2731) source length 14 target length 14 alignment score : 0.0119226
The detection method for structural inconsistency of classifier nouns and affxes is simple . 
NULL ({ }) The ({ 1 }) detection ({ 2 }) method ({ 3 }) for ({ 4 }) structural ({ 5 }) inconsistency ({ 6 }) of ({ 7 }) classifier ({ 8 }) nouns ({ 9 }) and ({ 10 }) affixes ({ 11 }) is ({ 12 }) simple ({ 13 }) . ({ 14 }) 
# Sentence pair (2732) source length 29 target length 32 alignment score : 2.25717e-27
First , we collected all affxes and classifier nouns in the VTB corpus . Then , extracted 2-grams containing these affxes or classifier nouns , which also are the structural inconsistencies . 
NULL ({ 2 3 14 16 29 }) We ({ 1 }) collected ({ 4 }) all ({ 5 }) affixes ({ 6 }) and ({ 7 }) classifier ({ 8 }) nouns ({ 9 }) in ({ 10 }) the ({ 11 }) VTB ({ 12 }) corpus ({ 13 }) , ({ }) and ({ }) then ({ 15 }) extracted ({ 17 }) 2-grams ({ 18 }) containing ({ 19 }) these ({ 20 }) affixes ({ 21 }) or ({ 22 }) classifier ({ 23 }) nouns ({ 24 }) , ({ 25 }) which ({ 26 }) are ({ 28 }) also ({ 27 }) structural ({ 30 }) inconsistencies ({ 31 }) . ({ 32 }) 
# Sentence pair (2733) source length 40 target length 40 alignment score : 1.02277e-07
For example , since " con " is tagged as a classifier noun in VTB , we extracted all 2-grams of " con " including both " con gi / girl " and " con trai / boy " . 
NULL ({ }) For ({ 1 }) example ({ 2 }) , ({ 3 }) since ({ 4 }) " ({ 5 }) con ({ 6 }) " ({ 7 }) is ({ 8 }) tagged ({ 9 }) as ({ 10 }) a ({ 11 }) classifier ({ 12 }) noun ({ 13 }) in ({ 14 }) VTB ({ 15 }) , ({ 16 }) we ({ 17 }) extracted ({ 18 }) all ({ 19 }) 2-grams ({ 20 }) of ({ 21 }) " ({ 22 }) con ({ 23 }) " ({ 24 }) including ({ 25 }) both ({ 26 }) " ({ 27 }) con ({ 28 }) gi ({ 29 }) / ({ 30 }) girl ({ 31 }) " ({ 32 }) and ({ 33 }) " ({ 34 }) con ({ 35 }) trai ({ 36 }) / ({ 37 }) boy ({ 38 }) " ({ 39 }) . ({ 40 }) 
# Sentence pair (2734) source length 38 target length 38 alignment score : 1.10522e-14
Note that even though the sequence " con trai " is always splitted into two words throughout the corpus , it can still be an inconsistency if we consider similar structures such as " con gi " . 
NULL ({ 2 }) Even ({ 1 3 }) though ({ 4 }) the ({ 5 }) sequence ({ 6 }) , ({ }) " ({ 7 }) con ({ 8 }) trai ({ 9 }) " ({ 10 }) is ({ 11 }) always ({ 12 }) split ({ 13 }) into ({ 14 }) two ({ 15 }) words ({ 16 }) throughout ({ 17 }) the ({ 18 }) corpus ({ 19 }) , ({ 20 }) it ({ 21 }) can ({ 22 }) still ({ 23 }) be ({ 24 }) an ({ 25 }) inconsistency ({ 26 }) , ({ }) if ({ 27 }) we ({ 28 }) consider ({ 29 }) similar ({ 30 }) structures ({ 31 }) such ({ 32 }) as ({ 33 }) " ({ 34 }) con ({ 35 }) gi ({ 36 }) " ({ 37 }) . ({ 38 }) 
# Sentence pair (2735) source length 36 target length 35 alignment score : 2.03357e-07
In other words , by this method , we extract sequences that may be consistent at the surface level , but are not consistent if we consider the higher analysis levels , POS tagging . 
NULL ({ }) In ({ 1 }) other ({ 2 }) words ({ 3 }) , ({ 4 }) by ({ 5 }) this ({ 6 }) method ({ 7 }) , ({ 8 }) we ({ 9 }) extract ({ 10 }) sequences ({ 11 }) that ({ 12 }) may ({ 13 }) be ({ 14 }) consistent ({ 15 }) at ({ 16 }) the ({ 17 }) surface ({ 18 }) level ({ 19 }) , ({ 20 }) but ({ 21 }) are ({ 22 }) not ({ 23 }) consistent ({ 24 }) , ({ }) if ({ 25 }) we ({ 26 }) consider ({ 27 }) the ({ 28 }) higher ({ 29 }) analysis ({ 30 }) levels ({ 31 }) , ({ 32 }) POS ({ 33 }) tagging ({ 34 }) . ({ 35 }) 
# Sentence pair (2736) source length 26 target length 25 alignment score : 9.00692e-06
According to the VTB POS-tagging annotation guidelines ( Nguyen et al., c ) , classifier nouns should be separated from the words they modify . 
NULL ({ }) According ({ 1 }) to ({ 2 }) the ({ 3 }) VTB ({ 4 }) POS-tagging ({ 5 }) annotation ({ 6 }) guidelines ({ 7 }) ( ({ 8 }) Nguyen ({ 9 }) et ({ 10 }) al., ({ 11 }) c ({ 12 }) ) ({ 13 }) , ({ 14 }) classifier ({ 15 }) nouns ({ 16 }) should ({ 17 }) be ({ 18 }) separated ({ 19 }) from ({ 20 }) the ({ 21 }) words ({ 22 }) that ({ }) they ({ 23 }) modify ({ 24 }) . ({ 25 }) 
# Sentence pair (2737) source length 20 target length 20 alignment score : 3.36491e-07
However , in practice it is confusing when the classifier noun can be stand alone as a single word . 
NULL ({ }) However ({ 1 }) , ({ 2 }) in ({ 3 }) practice ({ 4 }) , ({ }) it ({ 5 }) is ({ 6 }) confusing ({ 7 }) when ({ 8 }) the ({ 9 }) classifier ({ 10 }) noun ({ 11 }) can ({ 12 }) be ({ 13 }) standalone ({ 14 15 }) as ({ 16 }) a ({ 17 }) single ({ 18 }) word ({ 19 }) . ({ 20 }) 
# Sentence pair (2738) source length 72 target length 71 alignment score : 3.03187e-14
For example a classifier noun , e.g. , " con " in " con trai ( boy ) " , or " con gi ( girl ) " , can also be a simple word which means " I ( first person pronoun used by a child when talking to his / her parents ) " , or part of a complex noun " con ci ( children ) " . 
NULL ({ }) For ({ 1 }) example ({ 2 }) a ({ 3 }) classifier ({ 4 }) noun ({ 5 }) , ({ 6 }) e.g. ({ 7 }) , ({ 8 }) " ({ 9 }) con ({ 10 }) " ({ 11 }) in ({ 12 }) " ({ 13 }) con ({ 14 }) trai ({ 15 }) ( ({ 16 }) boy ({ 17 }) ) ({ 18 }) " ({ 19 }) , ({ 20 }) or ({ 21 }) " ({ 22 }) con ({ 23 }) gi ({ 24 }) ( ({ 25 }) girl ({ 26 }) ) ({ 27 }) " ({ 28 }) , ({ 29 }) can ({ 30 }) also ({ 31 }) be ({ 32 }) a ({ 33 }) simple ({ 34 }) word ({ 35 }) , ({ }) which ({ 36 }) means ({ 37 }) " ({ 38 }) I ({ 39 }) ( ({ 40 }) first ({ 41 }) person ({ 42 }) pronoun ({ 43 }) used ({ 44 }) by ({ 45 }) a ({ 46 }) child ({ 47 }) when ({ 48 }) talking ({ 49 }) to ({ 50 }) his ({ 51 }) / ({ 52 }) her ({ 53 }) parents ({ 54 }) ) ({ 55 }) " ({ 56 }) , ({ 57 }) or ({ 58 }) part ({ 59 }) of ({ 60 }) a ({ 61 }) complex ({ 62 }) noun ({ 63 }) " ({ 64 }) con ({ 65 }) ci ({ 66 }) ( ({ 67 }) children ({ 68 }) ) ({ 69 }) " ({ 70 }) . ({ 71 }) 
# Sentence pair (2739) source length 37 target length 36 alignment score : 5.45243e-13
Therefore , in our experiments , we want to evaluate the " splitting " and " combining " of these diffcult cases , to see whether the solution is fruitful for applications of the corpus . 
NULL ({ }) Therefore ({ 1 }) , ({ 2 }) in ({ 3 }) our ({ 4 }) experiments ({ 5 }) , ({ 6 }) we ({ 7 }) want ({ 8 }) to ({ 9 }) evaluate ({ 10 }) the ({ 11 }) " ({ 12 }) splitting ({ 13 }) " ({ 14 }) and ({ 15 }) " ({ 16 }) combining ({ 17 }) " ({ 18 }) of ({ 19 }) these ({ 20 }) cases ({ 21 22 }) , ({ 23 }) in ({ }) order ({ }) to ({ 24 }) see ({ 25 }) whether ({ 26 }) the ({ 27 }) solution ({ 28 }) is ({ 29 }) successful ({ 30 }) for ({ 31 }) applications ({ 32 }) of ({ 33 }) the ({ 34 }) corpus ({ 35 }) . ({ 36 }) 
# Sentence pair (2740) source length 41 target length 37 alignment score : 1.43054e-11
Examing the variations extracted by the variation inconsistency detection , we found that there are cases when a special character like percentage % in " 30% " , is splitted or combined with " 30 " . 
NULL ({ }) By ({ }) examining ({ 1 }) the ({ 2 }) variations ({ 3 }) extracted ({ 4 }) by ({ 5 }) the ({ 6 }) variation ({ 7 }) inconsistency ({ 8 }) detection ({ 9 }) , ({ 10 }) we ({ 11 }) found ({ 12 }) that ({ 13 }) there ({ 14 }) are ({ 15 }) cases ({ 16 }) when ({ 17 }) a ({ 18 }) special ({ 19 }) character ({ 20 }) like ({ 21 }) a ({ }) percentage ({ 22 }) ( ({ }) % ({ 23 }) ) ({ }) in ({ 24 }) " ({ 25 }) 30% ({ 26 }) " ({ 27 }) , ({ 28 }) is ({ 29 }) split ({ 30 }) or ({ 31 }) combined ({ 32 }) with ({ 33 }) " ({ 34 }) 30 ({ 35 }) " ({ 36 }) . ({ 37 }) 
# Sentence pair (2741) source length 12 target length 12 alignment score : 0.0184121
Such inconsistent annotations are manually fixed based on their textual context . 
NULL ({ }) Such ({ 1 }) inconsistent ({ 2 }) annotations ({ 3 }) are ({ 4 }) manually ({ 5 }) fixed ({ 6 }) based ({ 7 }) on ({ 8 }) their ({ 9 }) textual ({ 10 }) context ({ 11 }) . ({ 12 }) 
# Sentence pair (2742) source length 34 target length 27 alignment score : 3.25707e-19
Checking structural inconsistency of these special characters including percentage% , hyphen - , and so on , we found quite a significant amount of inconsistent annotations . 
NULL ({ }) By ({ }) checking ({ 1 }) structural ({ 2 }) inconsistencies ({ 3 }) of ({ 4 }) these ({ 5 }) special ({ 6 }) characters ({ 7 }) , ({ }) including ({ 8 }) percentages ({ 9 }) ( ({ }) % ({ }) ) ({ }) , ({ 10 }) hyphens ({ 11 }) ( ({ }) - ({ 12 }) ) ({ }) , ({ 13 }) and ({ 14 }) other ({ 15 }) symbols ({ 16 }) , ({ 17 }) we ({ 18 }) found ({ 19 }) quite ({ 20 }) a ({ 21 }) significant ({ 22 }) number ({ 23 }) of ({ 24 }) inconsistent ({ 25 }) annotations ({ 26 }) . ({ 27 }) 
# Sentence pair (2743) source length 36 target length 32 alignment score : 1.76351e-13
For example , the character % in " 30% " is splitted but is combined with the number in " 50 % " , which is considered as a structural inconsistency . 
NULL ({ }) For ({ 1 }) example ({ 2 }) , ({ 3 }) the ({ 4 }) character ({ 5 }) , ({ }) % ({ 6 }) , ({ }) in ({ 7 }) " ({ 8 }) 30% ({ 9 }) " ({ 10 }) is ({ 11 }) split ({ 12 }) , ({ }) but ({ 13 }) is ({ 14 }) combined ({ 15 }) with ({ 16 }) a ({ 17 }) number ({ 18 }) in ({ 19 }) " ({ 20 }) 50 ({ 21 }) % ({ 22 }) " ({ 23 }) , ({ 24 }) which ({ 25 }) is ({ 26 }) considered ({ 27 }) to ({ }) be ({ 28 }) a ({ 29 }) structural ({ 30 }) inconsistency ({ 31 }) . ({ 32 }) 
# Sentence pair (2744) source length 32 target length 37 alignment score : 7.39446e-29
Note that although it can be argued that whether " N% " can be splitted into two words or combined in one word is dependent on the blank space in between N and " % " . 
NULL ({ 13 14 30 }) Note ({ 1 }) that ({ 2 }) it ({ 4 }) can ({ 5 }) be ({ 6 }) argued ({ 7 15 }) that ({ 8 }) splitting ({ 9 }) " ({ 12 }) N% ({ 3 11 }) " ({ 10 }) into ({ 16 }) two ({ 17 }) words ({ 18 }) or ({ 19 }) combined ({ 20 }) in ({ 21 }) one ({ 22 }) word ({ 23 }) is ({ 24 }) dependent ({ 25 }) on ({ 26 }) the ({ 27 }) blank ({ 28 }) space ({ 29 }) in-between ({ 31 }) N ({ 32 }) and ({ 33 }) " ({ 34 }) % ({ 35 }) " ({ 36 }) . ({ 37 }) 
# Sentence pair (2745) source length 27 target length 26 alignment score : 1.51338e-16
It does matter higher-levels of annotation such as POS tagging because we may need one or two different POS tags for different ways of annotation . 
NULL ({ }) Higher-levels ({ 1 2 3 4 }) of ({ 5 }) annotation ({ 6 }) such ({ 7 }) as ({ 8 }) POS ({ 9 }) tagging ({ 10 }) is ({ }) significant ({ }) , ({ }) because ({ 11 }) we ({ 12 }) may ({ 13 }) need ({ 14 }) one ({ 15 }) or ({ 16 }) two ({ 17 }) different ({ 18 }) POS ({ 19 }) tags ({ 20 }) for ({ 21 }) the ({ }) different ({ 22 }) methods ({ 23 }) of ({ 24 }) annotation ({ 25 }) . ({ 26 }) 
# Sentence pair (2746) source length 22 target length 21 alignment score : 1.22019e-05
Therefore , we think it is better to carefully preprocess text and segment these special characters in a consistent way . 
NULL ({ }) Therefore ({ 1 }) , ({ 2 }) we ({ 3 }) think ({ 4 }) that ({ }) it ({ 5 }) is ({ 6 }) better ({ 7 }) to ({ 8 }) carefully ({ 9 }) preprocess ({ 10 }) text ({ 11 }) and ({ 12 }) segment ({ 13 }) these ({ 14 }) special ({ 15 }) characters ({ 16 }) in ({ 17 }) a ({ 18 }) consistent ({ 19 }) way ({ 20 }) . ({ 21 }) 
# Sentence pair (2747) source length 29 target length 29 alignment score : 1.00011e-08
To improve the quality of VTB corpus , we extracted the probably problematic sequences using patterns of the special characters , and manually fixed this type of inconsistency . 
NULL ({ }) To ({ 1 }) improve ({ 2 }) the ({ 3 }) quality ({ 4 }) of ({ 5 }) the ({ }) VTB ({ 6 }) corpus ({ 7 }) , ({ 8 }) we ({ 9 }) extracted ({ 10 }) the ({ 11 }) problematic ({ 12 13 }) sequences ({ 14 }) using ({ 15 }) patterns ({ 16 }) of ({ 17 }) the ({ 18 }) special ({ 19 }) characters ({ 20 }) , ({ 21 }) and ({ 22 }) manually ({ 23 }) fixed ({ 24 }) this ({ 25 }) type ({ 26 }) of ({ 27 }) inconsistency ({ 28 }) . ({ 29 }) 
# Sentence pair (2748) source length 19 target length 18 alignment score : 0.000218801
Automatically modification is diffcult since we must check the semantics of the special characters in their contexts . 
NULL ({ }) Automatically ({ 1 }) modification ({ 2 }) is ({ 3 }) diffcult ({ 4 }) , ({ }) since ({ 5 }) we ({ 6 }) must ({ 7 }) check ({ 8 }) the ({ 9 }) semantics ({ 10 }) of ({ 11 }) the ({ 12 }) special ({ 13 }) characters ({ 14 }) in ({ 15 }) their ({ 16 }) contexts ({ 17 }) . ({ 18 }) 
# Sentence pair (2749) source length 33 target length 30 alignment score : 7.0282e-12
For example , hyphens in date expressions like " 5-4-1975 " , which means the date " April the fifth , 1975 , " are combined with the numbers . 
NULL ({ 21 }) For ({ 1 }) example ({ 2 }) , ({ 3 }) hyphens ({ 4 }) in ({ 5 }) date ({ 6 }) expressions ({ 7 }) like ({ 8 }) " ({ 9 }) 5-4-1975 ({ 10 }) " ({ 11 }) , ({ 12 }) which ({ 13 }) refers ({ 14 }) to ({ }) the ({ 15 }) date ({ 16 }) , ({ }) " ({ 17 }) the ({ 19 }) fifth ({ 20 }) of ({ }) April ({ 18 }) , ({ }) 1975 ({ 22 }) , ({ 23 }) " ({ 24 }) are ({ 25 }) combined ({ 26 }) with ({ 27 }) the ({ 28 }) numbers ({ 29 }) . ({ 30 }) 
# Sentence pair (2750) source length 16 target length 19 alignment score : 4.88578e-12
However , when the hypen has a meaning of " ( from ) to " or " around . 
NULL ({ 9 }) However ({ 1 }) , ({ 2 }) when ({ 3 }) the ({ 4 }) hyphen ({ 5 6 8 }) indicates ({ 7 }) " ({ 10 }) ( ({ 11 }) from ({ 12 }) ) ({ 13 }) to ({ 14 }) " ({ 15 }) or ({ 16 }) " ({ 17 }) around ({ 18 }) . ({ 19 }) 
# Sentence pair (2751) source length 2 target length 2 alignment score : 0.668293
. . 
NULL ({ }) . ({ 1 }) . ({ 2 }) 
# Sentence pair (2752) source length 33 target length 32 alignment score : 1.92677e-07
or " , as in " 2-3 gi sng " meaning " around 2 or 3 oclock in the morning " , we decided to separate it from the surrounding numbers . 
NULL ({ }) or ({ 1 }) " ({ 2 }) , ({ 3 }) as ({ 4 }) in ({ 5 }) " ({ 6 }) 2-3 ({ 7 }) gi ({ 8 }) sng ({ 9 }) " ({ 10 }) , ({ }) meaning ({ 11 }) " ({ 12 }) around ({ 13 }) 2 ({ 14 }) or ({ 15 }) 3 ({ 16 }) oclock ({ 17 }) in ({ 18 }) the ({ 19 }) morning ({ 20 }) " ({ 21 }) , ({ 22 }) we ({ 23 }) decided ({ 24 }) to ({ 25 }) separate ({ 26 }) it ({ 27 }) from ({ 28 }) the ({ 29 }) surrounding ({ 30 }) numbers ({ 31 }) . ({ 32 }) 
# Sentence pair (2753) source length 17 target length 17 alignment score : 0.0020965
As a result , we have fixed 685 inconsistent annotations of 21 special characters in VTB . 
NULL ({ }) As ({ 1 }) a ({ 2 }) result ({ 3 }) , ({ 4 }) we ({ 5 }) have ({ 6 }) fixed ({ 7 }) 685 ({ 8 }) inconsistent ({ 9 }) annotations ({ 10 }) of ({ 11 }) 21 ({ 12 }) special ({ 13 }) characters ({ 14 }) in ({ 15 }) VTB ({ 16 }) . ({ 17 }) 
# Sentence pair (2754) source length 24 target length 25 alignment score : 1.20512e-08
The variation inconsistency and structural inconsistency found in Section 3 above can also be seen as representatives of different word segmentation criteria for Vietnamese . 
NULL ({ 11 }) The ({ 1 }) variation ({ 2 }) inconsistency ({ 3 }) and ({ 4 }) structural ({ 5 }) inconsistency ({ 6 }) found ({ 7 }) in ({ 8 }) Section ({ 9 }) 3 ({ 10 }) can ({ 12 }) also ({ 13 }) be ({ 14 }) seen ({ 15 }) as ({ 16 }) representatives ({ 17 }) of ({ 18 }) different ({ 19 }) word ({ 20 }) segmentation ({ 21 }) criteria ({ 22 }) for ({ 23 }) Vietnamese ({ 24 }) . ({ 25 }) 
# Sentence pair (2755) source length 14 target length 14 alignment score : 0.00526126
We organized the inconsistency detected in seven configurations of the original VTB corpus . 
NULL ({ }) We ({ 1 }) organized ({ 2 }) the ({ 3 }) inconsistency ({ 4 }) detected ({ 5 }) in ({ 6 }) seven ({ 7 }) configurations ({ 8 }) of ({ 9 }) the ({ 10 }) original ({ 11 }) VTB ({ 12 }) corpus ({ 13 }) . ({ 14 }) 
# Sentence pair (2756) source length 36 target length 36 alignment score : 1.85381e-08
Then , by using these data sets , we could observe the influence of the different word segmentation criteria on three tasks : automatic word segmenation , text classification , and English-Vietnamese statistical machine translation . 
NULL ({ }) Then ({ 1 }) , ({ 2 }) by ({ 3 }) using ({ 4 }) these ({ 5 }) data ({ 6 }) sets ({ 7 }) , ({ 8 }) we ({ 9 }) could ({ 10 }) observe ({ 11 }) the ({ 12 }) influence ({ 13 }) of ({ 14 }) the ({ 15 }) different ({ 16 }) word ({ 17 }) segmentation ({ 18 }) criteria ({ 19 }) on ({ 20 }) three ({ 21 }) tasks ({ 22 }) : ({ 23 }) automatic ({ 24 }) word ({ 25 }) segmentation ({ 26 }) , ({ 27 }) text ({ 28 }) classification ({ 29 }) , ({ 30 }) and ({ 31 }) English-Vietnamese ({ 32 }) statistical ({ 33 }) machine ({ 34 }) translation ({ 35 }) . ({ 36 }) 
# Sentence pair (2757) source length 13 target length 13 alignment score : 0.0131151
Seven data sets corresponding to different segmentation criteria are organized as follows . 
NULL ({ }) Seven ({ 1 }) data ({ 2 }) sets ({ 3 }) corresponding ({ 4 }) to ({ 5 }) different ({ 6 }) segmentation ({ 7 }) criteria ({ 8 }) are ({ 9 }) organized ({ 10 }) as ({ 11 }) follows ({ 12 }) . ({ 13 }) 
# Sentence pair (2758) source length 7 target length 7 alignment score : 0.0984275
ORG : The original VTB corpus . 
NULL ({ }) ORG ({ 1 }) : ({ 2 }) The ({ 3 }) original ({ 4 }) VTB ({ 5 }) corpus ({ 6 }) . ({ 7 }) 
# Sentence pair (2759) source length 18 target length 18 alignment score : 0.00225599
BASE : The original VTB corpus + Manual modification of special characters done in Section 3 .3 . 
NULL ({ }) BASE ({ 1 }) : ({ 2 }) The ({ 3 }) original ({ 4 }) VTB ({ 5 }) corpus ({ 6 }) + ({ 7 }) Manual ({ 8 }) modification ({ 9 }) of ({ 10 }) special ({ 11 }) characters ({ 12 }) done ({ 13 }) in ({ 14 }) Section ({ 15 }) 3 ({ 16 }) .3 ({ 17 }) . ({ 18 }) 
# Sentence pair (2760) source length 13 target length 13 alignment score : 0.00657141
VAR_SPLIT : BASE + split all variations detected in Section 3 .1 . 
NULL ({ }) VAR_SPLIT ({ 1 }) : ({ 2 }) BASE ({ 3 }) + ({ 4 }) split ({ 5 }) all ({ 6 }) variations ({ 7 }) detected ({ 8 }) in ({ 9 }) Section ({ 10 }) 3 ({ 11 }) .1 ({ 12 }) . ({ 13 }) 
# Sentence pair (2761) source length 13 target length 13 alignment score : 0.0150955
VAR_COMB : BASE + combine all variations detected in Section 3 .1 . 
NULL ({ }) VAR_COMB ({ 1 }) : ({ 2 }) BASE ({ 3 }) + ({ 4 }) combine ({ 5 }) all ({ 6 }) variations ({ 7 }) detected ({ 8 }) in ({ 9 }) Section ({ 10 }) 3 ({ 11 }) .1 ({ 12 }) . ({ 13 }) 
# Sentence pair (2762) source length 19 target length 19 alignment score : 0.00149322
VAR_FREQ : BASE + select the segmentation with higher frequency among all variations detected in Section 3 .1 . 
NULL ({ }) VAR_FREQ ({ 1 }) : ({ 2 }) BASE ({ 3 }) + ({ 4 }) select ({ 5 }) the ({ 6 }) segmentation ({ 7 }) with ({ 8 }) higher ({ 9 }) frequency ({ 10 }) among ({ 11 }) all ({ 12 }) variations ({ 13 }) detected ({ 14 }) in ({ 15 }) Section ({ 16 }) 3 ({ 17 }) .1 ({ 18 }) . ({ 19 }) 
# Sentence pair (2763) source length 19 target length 19 alignment score : 0.00169193
STRUCT_NC : BASE + combine all classifier nouns detected in Section 3 .2 with the words they modify . 
NULL ({ }) STRUCT_NC ({ 1 }) : ({ 2 }) BASE ({ 3 }) + ({ 4 }) combine ({ 5 }) all ({ 6 }) classifier ({ 7 }) nouns ({ 8 }) detected ({ 9 }) in ({ 10 }) Section ({ 11 }) 3 ({ 12 }) .2 ({ 13 }) with ({ 14 }) the ({ 15 }) words ({ 16 }) they ({ 17 }) modify ({ 18 }) . ({ 19 }) 
# Sentence pair (2764) source length 18 target length 18 alignment score : 0.00217636
STRUCT_AFFIX : BASE + combine all suffxes detected in Section 3 .2 with the words they modify . 
NULL ({ }) STRUCT_AFFIX ({ 1 }) : ({ 2 }) BASE ({ 3 }) + ({ 4 }) combine ({ 5 }) all ({ 6 }) suffxes ({ 7 }) detected ({ 8 }) in ({ 9 }) Section ({ 10 }) 3 ({ 11 }) .2 ({ 12 }) with ({ 13 }) the ({ 14 }) words ({ 15 }) they ({ 16 }) modify ({ 17 }) . ({ 18 }) 
# Sentence pair (2765) source length 15 target length 14 alignment score : 0.000765772
These data sets are used in our experiments as illustrated in Figure 1 . 
NULL ({ }) These ({ 1 }) data ({ 2 }) sets ({ 3 }) are ({ 4 }) used ({ 5 }) in ({ 6 }) our ({ 7 }) experiments ({ 8 }) , ({ }) as ({ 9 }) illustrated ({ 10 }) in ({ 11 }) Figure ({ 12 }) 1 ({ 13 }) . ({ 14 }) 
# Sentence pair (2766) source length 15 target length 15 alignment score : 0.00455995
The names of the data sets are also used to label our experimental configurations . 
NULL ({ }) The ({ 1 }) names ({ 2 }) of ({ 3 }) the ({ 4 }) data ({ 5 }) sets ({ 6 }) are ({ 7 }) also ({ 8 }) used ({ 9 }) to ({ 10 }) label ({ 11 }) our ({ 12 }) experimental ({ 13 }) configurations ({ 14 }) . ({ 15 }) 
# Sentence pair (2767) source length 36 target length 36 alignment score : 1.45346e-06
In this section , we briefly describe the task settings and the methods used for word segmentation ( WS ) , text classification ( TC ) , and English-Vietnamese statistical machine translation ( SMT ) . 
NULL ({ }) In ({ 1 }) this ({ 2 }) section ({ 3 }) , ({ 4 }) we ({ 5 }) briefly ({ 6 }) describe ({ 7 }) the ({ 8 }) task ({ 9 }) settings ({ 10 }) and ({ 11 }) the ({ 12 }) methods ({ 13 }) used ({ 14 }) for ({ 15 }) word ({ 16 }) segmentation ({ 17 }) ( ({ 18 }) WS ({ 19 }) ) ({ 20 }) , ({ 21 }) text ({ 22 }) classification ({ 23 }) ( ({ 24 }) TC ({ 25 }) ) ({ 26 }) , ({ 27 }) and ({ 28 }) English-Vietnamese ({ 29 }) statistical ({ 30 }) machine ({ 31 }) translation ({ 32 }) ( ({ 33 }) SMT ({ 34 }) ) ({ 35 }) . ({ 36 }) 
# Sentence pair (2768) source length 23 target length 23 alignment score : 0.000286348
We used YamCha ( Kudo and Matsumoto , 2003 ) , a multi-purpose chunking tool , to train our word segmentation models . 
NULL ({ }) We ({ 1 }) used ({ 2 }) YamCha ({ 3 }) ( ({ 4 }) Kudo ({ 5 }) and ({ 6 }) Matsumoto ({ 7 }) , ({ 8 }) 2003 ({ 9 }) ) ({ 10 }) , ({ 11 }) a ({ 12 }) multi-purpose ({ 13 }) chunking ({ 14 }) tool ({ 15 }) , ({ 16 }) to ({ 17 }) train ({ 18 }) our ({ 19 }) word ({ 20 }) segmentation ({ 21 }) models ({ 22 }) . ({ 23 }) 
# Sentence pair (2769) source length 27 target length 27 alignment score : 6.49574e-08
The core of YamCha is the Support Vector Machine ( SVM ) machine learning method , which has been proved to be effective in NLP tasks . 
NULL ({ }) The ({ 1 }) core ({ 2 }) of ({ 3 }) YamCha ({ 4 }) is ({ 5 }) the ({ 6 }) Support ({ 7 }) Vector ({ 8 }) Machine ({ 9 }) ( ({ 10 }) SVM ({ 11 }) ) ({ 12 }) machine ({ 13 }) learning ({ 14 }) method ({ 15 }) , ({ 16 }) which ({ 17 }) has ({ 18 }) been ({ 19 }) proven ({ 20 }) to ({ 21 }) be ({ 22 }) effective ({ 23 }) for ({ 24 }) NLP ({ 25 }) tasks ({ 26 }) . ({ 27 }) 
# Sentence pair (2770) source length 34 target length 33 alignment score : 2.79503e-07
For the Vietnamese word segmentation problem , each token is labeled with standard B , I , or O labels , corresponding to beginning , inside , and outside positions , respectively . 
NULL ({ }) For ({ 1 }) the ({ 2 }) Vietnamese ({ 3 }) word ({ 4 }) segmentation ({ 5 }) problem ({ 6 }) , ({ 7 }) each ({ 8 }) token ({ 9 }) is ({ 10 }) labeled ({ 11 }) with ({ 12 }) standard ({ 13 }) B ({ 14 }) , ({ 15 }) I ({ 16 }) , ({ 17 }) or ({ 18 }) O ({ 19 }) labels ({ 20 }) , ({ 21 }) corresponding ({ 22 }) to ({ 23 }) the ({ }) beginning ({ 24 }) , ({ 25 }) inside ({ 26 }) , ({ 27 }) and ({ 28 }) outside ({ 29 }) positions ({ 30 }) , ({ 31 }) respectively ({ 32 }) . ({ 33 }) 
# Sentence pair (2771) source length 26 target length 23 alignment score : 4.23657e-08
Label of each token is determined based on the lexical features of two preceding words and two following words of that token . 
NULL ({ }) The ({ }) label ({ 1 }) of ({ 2 }) each ({ 3 }) token ({ 4 }) is ({ 5 }) determined ({ 6 }) based ({ 7 }) on ({ 8 }) the ({ 9 }) lexical ({ 10 }) features ({ 11 }) of ({ 12 }) two ({ 13 }) preceding ({ 14 }) words ({ 15 }) , ({ }) and ({ 16 }) the ({ }) two ({ 17 }) following ({ 18 }) words ({ 19 }) of ({ 20 }) that ({ 21 }) token ({ 22 }) . ({ 23 }) 
# Sentence pair (2772) source length 17 target length 16 alignment score : 0.000449424
Since Vietnamese language is not inflectional , we cannot utilize inflection features for word segmentation . 
NULL ({ }) Since ({ 1 }) the ({ }) Vietnamese ({ 2 }) language ({ 3 }) is ({ 4 }) not ({ 5 }) inflectional ({ 6 }) , ({ 7 }) we ({ 8 }) cannot ({ 9 }) utilize ({ 10 }) inflection ({ 11 }) features ({ 12 }) for ({ 13 }) word ({ 14 }) segmentation ({ 15 }) . ({ 16 }) 
# Sentence pair (2773) source length 19 target length 19 alignment score : 0.000621956
Each of the seven data sets is splitted into two subsets for training and testing our WS models . 
NULL ({ }) Each ({ 1 }) of ({ 2 }) the ({ 3 }) seven ({ 4 }) data ({ 5 }) sets ({ 6 }) is ({ 7 }) split ({ 8 }) into ({ 9 }) two ({ 10 }) subsets ({ 11 }) for ({ 12 }) training ({ 13 }) and ({ 14 }) testing ({ 15 }) our ({ 16 }) WS ({ 17 }) models ({ 18 }) . ({ 19 }) 
# Sentence pair (2774) source length 15 target length 15 alignment score : 0.00609833
The training set contains 8443 sentences , and the test set contains 2000 sentences . 
NULL ({ }) The ({ 1 }) training ({ 2 }) set ({ 3 }) contains ({ 4 }) 8443 ({ 5 }) sentences ({ 6 }) , ({ 7 }) and ({ 8 }) the ({ 9 }) test ({ 10 }) set ({ 11 }) contains ({ 12 }) 2000 ({ 13 }) sentences ({ 14 }) . ({ 15 }) 
# Sentence pair (2775) source length 23 target length 22 alignment score : 2.6774e-10
Text classification is defined as a task of determining for an input document the most suitable topic from the predefined topics . 
NULL ({ }) Text ({ 1 }) classification ({ 2 }) is ({ 3 }) defined ({ 4 }) as ({ 5 }) a ({ 6 }) task ({ 7 }) of ({ 8 }) determining ({ 9 }) the ({ 14 }) most ({ 15 }) suitable ({ 16 }) topic ({ 17 }) from ({ 18 }) the ({ 19 }) predefined ({ 20 }) topics ({ 21 }) , ({ }) for ({ 10 }) an ({ 11 }) input ({ 12 }) document ({ 13 }) . ({ 22 }) 
# Sentence pair (2776) source length 19 target length 19 alignment score : 0.000790387
We implemented a text classification system similar to the system presented in ( Nguyen et al., 2012 ) . 
NULL ({ }) We ({ 1 }) implemented ({ 2 }) a ({ 3 }) text ({ 4 }) classification ({ 5 }) system ({ 6 }) similar ({ 7 }) to ({ 8 }) the ({ 9 }) system ({ 10 }) presented ({ 11 }) in ({ 12 }) ( ({ 13 }) Nguyen ({ 14 }) et ({ 15 }) al., ({ 16 }) 2012 ({ 17 }) ) ({ 18 }) . ({ 19 }) 
# Sentence pair (2777) source length 20 target length 15 alignment score : 1.69681e-13
The difference is that we performed for document level , not for sentence level . 
NULL ({ }) The ({ 1 }) difference ({ 2 }) is ({ 3 }) that ({ 4 }) we ({ 5 }) performed ({ 6 }) the ({ }) task ({ 7 }) at ({ }) the ({ }) document ({ 8 }) level ({ 9 }) , ({ 10 }) instead ({ 11 }) of ({ 12 }) at ({ }) the ({ }) sentence ({ 13 }) level ({ 14 }) . ({ 15 }) 
# Sentence pair (2778) source length 10 target length 9 alignment score : 5.141e-05
Processing of the system is summarized as follows . 
NULL ({ }) The ({ }) processing ({ 1 }) of ({ 2 }) the ({ 3 }) system ({ 4 }) is ({ 5 }) summarized ({ 6 }) as ({ 7 }) follows ({ 8 }) . ({ 9 }) 
# Sentence pair (2779) source length 12 target length 12 alignment score : 0.00828755
An input document is preprocessed with word segmentation and stop-word removals . 
NULL ({ }) An ({ 1 }) input ({ 2 }) document ({ 3 }) is ({ 4 }) preprocessed ({ 5 }) with ({ 6 }) word ({ 7 }) segmentation ({ 8 }) and ({ 9 }) stop-word ({ 10 }) removals ({ 11 }) . ({ 12 }) 
# Sentence pair (2780) source length 20 target length 20 alignment score : 0.000426
Then , the document is represented in the form of a vector of weighted words appearing in the document . 
NULL ({ }) Then ({ 1 }) , ({ 2 }) the ({ 3 }) document ({ 4 }) is ({ 5 }) represented ({ 6 }) in ({ 7 }) the ({ 8 }) form ({ 9 }) of ({ 10 }) a ({ 11 }) vector ({ 12 }) of ({ 13 }) weighted ({ 14 }) words ({ 15 }) appearing ({ 16 }) in ({ 17 }) the ({ 18 }) document ({ 19 }) . ({ 20 }) 
# Sentence pair (2781) source length 9 target length 9 alignment score : 0.0362416
The weight is calculated using standard tf-idf product . 
NULL ({ }) The ({ 1 }) weight ({ 2 }) is ({ 3 }) calculated ({ 4 }) using ({ 5 }) standard ({ 6 }) tf-idf ({ 7 }) product ({ 8 }) . ({ 9 }) 
# Sentence pair (2782) source length 22 target length 22 alignment score : 1.09452e-05
An SVM-based classifier predicts the most probable topic for the vector , which also is the topic of the input document . 
NULL ({ }) An ({ 1 }) SVM-based ({ 2 }) classifier ({ 3 }) predicts ({ 4 }) the ({ 5 }) most ({ 6 }) probable ({ 7 }) topic ({ 8 }) for ({ 9 }) the ({ 10 }) vector ({ 11 }) , ({ 12 }) which ({ 13 }) also ({ 14 }) is ({ 15 }) the ({ 16 }) topic ({ 17 }) for ({ 18 }) the ({ 19 }) input ({ 20 }) document ({ 21 }) . ({ 22 }) 
# Sentence pair (2783) source length 32 target length 31 alignment score : 9.79647e-07
In our experiment for comparison of different word segmentation criteria in topic classification , we only vary the word segmentation model used for this task , while fixing other configurations . 
NULL ({ }) In ({ 1 }) our ({ 2 }) experiment ({ 3 }) , ({ }) for ({ 4 }) comparison ({ 5 }) of ({ 6 }) different ({ 7 }) word ({ 8 }) segmentation ({ 9 }) criteria ({ 10 }) in ({ 11 }) topic ({ 12 }) classification ({ 13 }) , ({ 14 }) we ({ 15 }) only ({ 16 }) vary ({ 17 }) the ({ 18 }) word ({ 19 }) segmentation ({ 20 }) model ({ 21 }) used ({ 22 }) for ({ 23 }) this ({ 24 }) task ({ 25 }) , ({ 26 }) while ({ 27 }) fixing ({ 28 }) other ({ 29 }) configurations ({ 30 }) . ({ 31 }) 
# Sentence pair (2784) source length 19 target length 19 alignment score : 0.00107341
News articles of five topics : music , stock , entertainment , education , and fashion are used . 
NULL ({ }) News ({ 1 }) articles ({ 2 }) of ({ 3 }) five ({ 4 }) topics ({ 5 }) : ({ 6 }) music ({ 7 }) , ({ 8 }) stock ({ 9 }) , ({ 10 }) entertainment ({ 11 }) , ({ 12 }) education ({ 13 }) , ({ 14 }) and ({ 15 }) fashion ({ 16 }) are ({ 17 }) used ({ 18 }) . ({ 19 }) 
# Sentence pair (2785) source length 15 target length 15 alignment score : 0.00693868
The sizes of the training and test data sets are summarized in Table 8 . 
NULL ({ }) The ({ 1 }) sizes ({ 2 }) of ({ 3 }) the ({ 4 }) training ({ 5 }) and ({ 6 }) test ({ 7 }) data ({ 8 }) sets ({ 9 }) are ({ 10 }) summarized ({ 11 }) in ({ 12 }) Table ({ 13 }) 8 ({ 14 }) . ({ 15 }) 
# Sentence pair (2786) source length 10 target length 10 alignment score : 0.014236
A phrase-based SMT system for English-Vietnamese translation was implemented . 
NULL ({ }) A ({ 1 }) phrase-based ({ 2 }) SMT ({ 3 }) system ({ 4 }) for ({ 5 }) English-Vietnamese ({ 6 }) translation ({ 7 }) was ({ 8 }) implemented ({ 9 }) . ({ 10 }) 
# Sentence pair (2787) source length 48 target length 48 alignment score : 5.20145e-08
In this system , we used SRILM ( Stolcke , 2002 ) to build the language model , GIZA++ ( Och and Ney , 2003 ) to train the word-aligned model , and Moses ( Holmqvist et al., 2007 ) to train the phrase-based statistical translation model . 
NULL ({ }) In ({ 1 }) this ({ 2 }) system ({ 3 }) , ({ 4 }) we ({ 5 }) used ({ 6 }) SRILM ({ 7 }) ( ({ 8 }) Stolcke ({ 9 }) , ({ 10 }) 2002 ({ 11 }) ) ({ 12 }) to ({ 13 }) build ({ 14 }) the ({ 15 }) language ({ 16 }) model ({ 17 }) , ({ 18 }) GIZA++ ({ 19 }) ( ({ 20 }) Och ({ 21 }) and ({ 22 }) Ney ({ 23 }) , ({ 24 }) 2003 ({ 25 }) ) ({ 26 }) to ({ 27 }) train ({ 28 }) the ({ 29 }) word-aligned ({ 30 }) model ({ 31 }) , ({ 32 }) and ({ 33 }) Moses ({ 34 }) ( ({ 35 }) Holmqvist ({ 36 }) et ({ 37 }) al., ({ 38 }) 2007 ({ 39 }) ) ({ 40 }) to ({ 41 }) train ({ 42 }) the ({ 43 }) phrase-based ({ 44 }) statistical ({ 45 }) translation ({ 46 }) model ({ 47 }) . ({ 48 }) 
# Sentence pair (2788) source length 15 target length 14 alignment score : 0.00154728
Translation results are evaluated using BLUE score ( Papineni et al., 2002 ) . 
NULL ({ }) Translation ({ 1 }) results ({ 2 }) are ({ 3 }) evaluated ({ 4 }) using ({ 5 }) the ({ }) BLUE ({ 6 }) score ({ 7 }) ( ({ 8 }) Papineni ({ 9 }) et ({ 10 }) al., ({ 11 }) 2002 ({ 12 }) ) ({ 13 }) . ({ 14 }) 
# Sentence pair (2789) source length 14 target length 14 alignment score : 0.00339642
Both training and test data are word-segmented using the word segmentation models achieved . 
NULL ({ }) Both ({ 1 }) training ({ 2 }) and ({ 3 }) test ({ 4 }) data ({ 5 }) are ({ 6 }) word-segmented ({ 7 }) using ({ 8 }) the ({ 9 }) word ({ 10 }) segmentation ({ 11 }) models ({ 12 }) achieved ({ 13 }) . ({ 14 }) 
# Sentence pair (2790) source length 24 target length 24 alignment score : 0.000183581
For the experiment , we used the VCL_EVC bilingual corpus , 18000 pairs of sentences for training , and 1000 pairs for testing . 
NULL ({ }) For ({ 1 }) the ({ 2 }) experiment ({ 3 }) , ({ 4 }) we ({ 5 }) used ({ 6 }) the ({ 7 }) VCL_EVC ({ 8 }) bilingual ({ 9 }) corpus ({ 10 }) , ({ 11 }) 18000 ({ 12 }) pairs ({ 13 }) of ({ 14 }) sentences ({ 15 }) for ({ 16 }) training ({ 17 }) , ({ 18 }) and ({ 19 }) 1000 ({ 20 }) pairs ({ 21 }) for ({ 22 }) testing ({ 23 }) . ({ 24 }) 
# Sentence pair (2791) source length 18 target length 18 alignment score : 0.00152031
Evaluation of word segmentation models trained on different versions of the VTB are given in Table 9 . 
NULL ({ }) Evaluation ({ 1 }) of ({ 2 }) word ({ 3 }) segmentation ({ 4 }) models ({ 5 }) trained ({ 6 }) on ({ 7 }) different ({ 8 }) versions ({ 9 }) of ({ 10 }) the ({ 11 }) VTB ({ 12 }) are ({ 13 }) given ({ 14 }) in ({ 15 }) Table ({ 16 }) 9 ({ 17 }) . ({ 18 }) 
# Sentence pair (2792) source length 22 target length 23 alignment score : 6.5791e-09
And the experimental results with text classification and English-Vietnamese statistical machine translation are shown in Table 10 and Table 11 , respectively . 
NULL ({ 2 }) The ({ 1 }) experimental ({ 3 }) results ({ 4 }) with ({ 5 }) text ({ 6 }) classification ({ 7 }) and ({ 8 }) English-Vietnamese ({ 9 }) statistical ({ 10 }) machine ({ 11 }) translation ({ 12 }) are ({ 13 }) shown ({ 14 }) in ({ 15 }) Table ({ 16 }) 10 ({ 17 }) and ({ 18 }) Table ({ 19 }) 11 ({ 20 }) , ({ 21 }) respectively ({ 22 }) . ({ 23 }) 
# Sentence pair (2793) source length 77 target length 73 alignment score : 5.22648e-20
There are two important conclusions can be drawn from these tables : ( 1 ) Quality of the treebank strongly affects the applications since our BASE model and most of other enhanced models improved the performance of TC and SMT systems ; ( 2 ) " Splitting " seems to be a good solution for word segmentation of controversial cases , including the split of variations , affxes , and classifier nouns . 
NULL ({ }) There ({ 1 }) are ({ 2 }) two ({ 3 }) important ({ 4 }) conclusions ({ 5 }) that ({ }) can ({ 6 }) be ({ 7 }) drawn ({ 8 }) from ({ 9 }) these ({ 10 }) tables ({ 11 }) : ({ 12 }) ( ({ 13 }) 1 ({ 14 }) ) ({ 15 }) The ({ }) quality ({ 16 }) of ({ 17 }) the ({ 18 }) treebank ({ 19 }) strongly ({ 20 }) affects ({ 21 }) the ({ 22 }) applications ({ 23 }) , ({ }) since ({ 24 }) our ({ 25 }) BASE ({ 26 }) model ({ 27 }) and ({ 28 }) most ({ 29 }) of ({ 30 }) the ({ }) other ({ 31 }) enhanced ({ 32 }) models ({ 33 }) improved ({ 34 }) the ({ 35 }) performance ({ 36 }) of ({ 37 }) TC ({ 38 }) and ({ 39 }) SMT ({ 40 }) systems ({ 41 }) ; ({ 42 }) ( ({ 43 }) 2 ({ 44 }) ) ({ 45 }) " ({ 46 }) Splitting ({ 47 }) " ({ 48 }) seems ({ 49 }) to ({ 50 }) be ({ 51 }) a ({ 52 }) good ({ 53 }) solution ({ 54 }) for ({ 55 }) word ({ 56 }) segmentation ({ 57 }) for ({ 58 }) controversial ({ 59 }) cases ({ 60 }) , ({ 61 }) including ({ 62 }) the ({ 63 }) split ({ 64 }) of ({ 65 }) variations ({ 66 }) , ({ 67 }) affxes ({ 68 }) , ({ 69 }) and ({ 70 }) classifier ({ 71 }) nouns ({ 72 }) . ({ 73 }) 
# Sentence pair (2794) source length 17 target length 17 alignment score : 0.000945707
According to the result in Table 9 , the VAR_SPLIT criterion gives the highest WS performance . 
NULL ({ }) According ({ 1 }) to ({ 2 }) the ({ 3 }) result ({ 4 }) in ({ 5 }) Table ({ 6 }) 9 ({ 7 }) , ({ 8 }) the ({ 9 }) VAR_SPLIT ({ 10 }) criterion ({ 11 }) gives ({ 12 }) the ({ 13 }) highest ({ 14 }) WS ({ 15 }) performance ({ 16 }) . ({ 17 }) 
# Sentence pair (2795) source length 21 target length 18 alignment score : 6.2902e-09
Except for STRUCT_NC , all the modifications to the original VTB corpus increase the performance of WS . 
NULL ({ }) With ({ 1 }) the ({ }) exception ({ 2 }) of ({ }) STRUCT_NC ({ 3 }) , ({ 4 }) all ({ 5 }) of ({ }) the ({ 6 }) modifications ({ 7 }) to ({ 8 }) the ({ 9 }) original ({ 10 }) VTB ({ 11 }) corpus ({ 12 }) increase ({ 13 }) the ({ 14 }) performance ({ 15 }) of ({ 16 }) WS ({ 17 }) . ({ 18 }) 
# Sentence pair (2796) source length 29 target length 29 alignment score : 9.55664e-06
However , the word segmentation criterion with higher performance is not necessarily a better criterion , but a criterion should also be judged through applications of word segmentation . 
NULL ({ }) However ({ 1 }) , ({ 2 }) the ({ 3 }) word ({ 4 }) segmentation ({ 5 }) criterion ({ 6 }) with ({ 7 }) higher ({ 8 }) performance ({ 9 }) is ({ 10 }) not ({ 11 }) necessarily ({ 12 }) a ({ 13 }) better ({ 14 }) criterion ({ 15 }) , ({ 16 }) but ({ 17 }) a ({ 18 }) criterion ({ 19 }) should ({ 20 }) also ({ 21 }) be ({ 22 }) judged ({ 23 }) through ({ 24 }) applications ({ 25 }) of ({ 26 }) word ({ 27 }) segmentation ({ 28 }) . ({ 29 }) 
# Sentence pair (2797) source length 30 target length 29 alignment score : 2.14286e-06
In both SMT and TC experiments , the BASE model which is based on the manually-modified inconsistency of special characters , achieved better results than the ORG model . 
NULL ({ }) In ({ 1 }) both ({ 2 }) SMT ({ 3 }) and ({ 4 }) TC ({ 5 }) experiments ({ 6 }) , ({ 7 }) the ({ 8 }) BASE ({ 9 }) model ({ 10 }) , ({ }) which ({ 11 }) is ({ 12 }) based ({ 13 }) on ({ 14 }) the ({ 15 }) manually-modified ({ 16 }) inconsistency ({ 17 }) of ({ 18 }) special ({ 19 }) characters ({ 20 }) , ({ 21 }) achieved ({ 22 }) better ({ 23 }) results ({ 24 }) than ({ 25 }) the ({ 26 }) ORG ({ 27 }) model ({ 28 }) . ({ 29 }) 
# Sentence pair (2798) source length 25 target length 25 alignment score : 4.42939e-05
In particular , in the TC experiment , the BASE model achieved 0 .66 point higher than ORG , which is a significant improvement . 
NULL ({ }) In ({ 1 }) particular ({ 2 }) , ({ 3 }) in ({ 4 }) the ({ 5 }) TC ({ 6 }) experiment ({ 7 }) , ({ 8 }) the ({ 9 }) BASE ({ 10 }) model ({ 11 }) achieved ({ 12 }) 0 ({ 13 }) .66 ({ 14 }) point ({ 15 }) higher ({ 16 }) than ({ 17 }) ORG ({ 18 }) , ({ 19 }) which ({ 20 }) is ({ 21 }) a ({ 22 }) significant ({ 23 }) improvement ({ 24 }) . ({ 25 }) 
# Sentence pair (2799) source length 20 target length 19 alignment score : 6.0975e-05
The results support the conclusion that the quality of word-segmentation corpus is very important for building NLP applications . 
NULL ({ }) The ({ 1 }) results ({ 2 }) support ({ 3 }) the ({ 4 }) conclusion ({ 5 }) that ({ 6 }) the ({ 7 }) quality ({ 8 }) of ({ 9 }) the ({ }) word-segmentation ({ 10 }) corpus ({ 11 }) is ({ 12 }) very ({ 13 }) important ({ 14 }) for ({ 15 }) building ({ 16 }) NLP ({ 17 }) applications ({ 18 }) . ({ 19 }) 
# Sentence pair (2800) source length 25 target length 26 alignment score : 3.80997e-11
The SMT results show that three out of six augmented models , VAR_SPLIT , VAR_FREQ and BASE , gave higher performance than the ORG configuration . 
NULL ({ }) The ({ 1 }) SMT ({ 2 }) results ({ 3 }) show ({ 4 }) that ({ 5 }) three ({ 6 }) out ({ 7 }) of ({ 8 }) six ({ 9 }) augmented ({ 10 }) models ({ 11 }) , ({ 12 }) VAR_SPLIT ({ 13 }) , ({ 14 }) VAR_FREQ ({ 15 }) and ({ 16 }) BASE ({ 17 }) , ({ 18 }) performed ({ 19 20 }) better ({ 21 }) than ({ 22 }) the ({ 23 }) ORG ({ 24 }) configuration ({ 25 }) . ({ 26 }) 
# Sentence pair (2801) source length 22 target length 21 alignment score : 2.83857e-05
Among them , the best model VAR_SPLIT achieved 36 .91 BLEU score , which is 0 .55 higher than ORG . 
NULL ({ }) Among ({ 1 }) them ({ 2 }) , ({ 3 }) the ({ 4 }) best-performing ({ 5 }) model ({ 6 }) , ({ }) VAR_SPLIT ({ 7 }) achieved ({ 8 }) 36 ({ 9 }) .91 ({ 10 }) BLEU ({ 11 }) score ({ 12 }) , ({ 13 }) which ({ 14 }) is ({ 15 }) 0 ({ 16 }) .55 ({ 17 }) higher ({ 18 }) than ({ 19 }) ORG ({ 20 }) . ({ 21 }) 
# Sentence pair (2802) source length 14 target length 14 alignment score : 0.000196685
In TC results , all six augmented models have higher results than ORG . 
NULL ({ }) In ({ 1 }) TC ({ 2 }) results ({ 3 }) , ({ 4 }) all ({ 5 }) six ({ 6 }) augmented ({ 7 }) models ({ 8 }) achieved ({ 9 }) higher ({ 10 }) results ({ 11 }) than ({ 12 }) ORG ({ 13 }) . ({ 14 }) 
# Sentence pair (2803) source length 12 target length 12 alignment score : 0.00026057
In general , the augmented models are better than the ORG . 
NULL ({ }) In ({ 1 }) general ({ 2 }) , ({ 3 }) the ({ 4 }) augmented ({ 5 }) models ({ 6 }) performed ({ 7 }) better ({ 8 }) than ({ 9 }) the ({ 10 }) ORG ({ 11 }) . ({ 12 }) 
# Sentence pair (2804) source length 31 target length 29 alignment score : 3.29137e-08
Additionally , because our automatic methods for inconsistency detection could not cover all types of inconsistency in word segmentation annotation , further improvement of corpus quality is demanded . 
NULL ({ }) Additionally ({ 1 }) , ({ 2 }) because ({ 3 }) our ({ 4 }) automatic ({ 5 }) methods ({ 6 }) for ({ 7 }) inconsistency ({ 8 }) detection ({ 9 }) could ({ 10 }) not ({ 11 }) cover ({ 12 }) all ({ 13 }) of ({ }) the ({ }) types ({ 14 }) of ({ 15 }) inconsistencies ({ 16 }) in ({ 17 }) word ({ 18 }) segmentation ({ 19 }) annotation ({ 20 }) , ({ 21 }) further ({ 22 }) improvement ({ 23 }) of ({ 24 }) corpus ({ 25 }) quality ({ 26 }) is ({ 27 }) demanded ({ 28 }) . ({ 29 }) 
# Sentence pair (2805) source length 46 target length 46 alignment score : 2.5672e-11
Comparing the results of STRUCT_AFFIX and STRUCT_NC with BASE in WS , TC , and SMT , we can observe that combining affxes with their head nouns resulted in slightly better results for WS , TC , and does not change the performance of SMT . 
NULL ({ 35 }) Comparing ({ 1 }) the ({ 2 }) results ({ 3 }) of ({ 4 }) STRUCT_AFFIX ({ 5 }) and ({ 6 }) STRUCT_NC ({ 7 }) with ({ 8 }) BASE ({ 9 }) in ({ 10 }) WS ({ 11 }) , ({ 12 }) TC ({ 13 }) , ({ 14 }) and ({ 15 }) SMT ({ 16 }) , ({ 17 }) we ({ 18 }) can ({ 19 }) observe ({ 20 }) that ({ 21 }) combining ({ 22 }) affxes ({ 23 }) with ({ 24 }) their ({ 25 }) head ({ 26 }) nouns ({ 27 }) resulted ({ 28 }) in ({ 29 }) slightly ({ 30 }) better ({ 31 }) results ({ 32 }) for ({ 33 }) WS ({ 34 }) and ({ }) TC ({ 36 }) , ({ 37 }) and ({ 38 }) did ({ 39 }) not ({ 40 }) change ({ 41 }) the ({ 42 }) performance ({ 43 }) of ({ 44 }) SMT ({ 45 }) . ({ 46 }) 
# Sentence pair (2806) source length 19 target length 19 alignment score : 7.0342e-06
However , the combination of clasifier nouns with their head nouns had negative effects on WS and SMT . 
NULL ({ }) However ({ 1 }) , ({ 2 }) the ({ 3 }) combination ({ 4 }) of ({ 5 }) classifier ({ 6 }) nouns ({ 7 }) with ({ 8 }) their ({ 9 }) head ({ 10 }) nouns ({ 11 }) had ({ 12 }) negative ({ 13 }) effects ({ 14 }) on ({ 15 }) WS ({ 16 }) and ({ 17 }) SMT ({ 18 }) . ({ 19 }) 
# Sentence pair (2807) source length 24 target length 21 alignment score : 1.10909e-07
Another intention of our experiment is to compare two solutions for controversial cases of word segmentation , splitting and combining . 
NULL ({ }) Another ({ 1 }) part ({ }) of ({ }) the ({ }) scope ({ 2 }) of ({ 3 }) our ({ 4 }) experiment ({ 5 }) is ({ 6 }) to ({ 7 }) compare ({ 8 }) two ({ 9 }) solutions ({ 10 }) for ({ 11 }) controversial ({ 12 }) cases ({ 13 }) of ({ 14 }) word ({ 15 }) segmentation ({ 16 }) , ({ 17 }) splitting ({ 18 }) and ({ 19 }) combining ({ 20 }) . ({ 21 }) 
# Sentence pair (2808) source length 30 target length 29 alignment score : 3.14735e-06
Splitting and combining variations are reflected by VAR_COMB and VAR_SPLIT , while STRUCT_AFFIX and STRUCT_NC represent the combination of affxes or classifier nouns with the words they modify . 
NULL ({ }) Splitting ({ 1 }) and ({ 2 }) combining ({ 3 }) variations ({ 4 }) are ({ 5 }) reflected ({ 6 }) by ({ 7 }) VAR_COMB ({ 8 }) and ({ 9 }) VAR_SPLIT ({ 10 }) , ({ 11 }) while ({ 12 }) STRUCT_AFFIX ({ 13 }) and ({ 14 }) STRUCT_NC ({ 15 }) represent ({ 16 }) the ({ 17 }) combination ({ 18 }) of ({ 19 }) affixes ({ 20 }) or ({ 21 }) classifier ({ 22 }) nouns ({ 23 }) with ({ 24 }) the ({ 25 }) words ({ 26 }) that ({ }) they ({ 27 }) modify ({ 28 }) . ({ 29 }) 
# Sentence pair (2809) source length 15 target length 15 alignment score : 0.00674314
STRUCT_AFFIX and STRUCT_NC are contrasted with BASE where affxes and classifier nouns remain untouched . 
NULL ({ }) STRUCT_AFFIX ({ 1 }) and ({ 2 }) STRUCT_NC ({ 3 }) are ({ 4 }) contrasted ({ 5 }) with ({ 6 }) BASE ({ 7 }) where ({ 8 }) affxes ({ 9 }) and ({ 10 }) classifier ({ 11 }) nouns ({ 12 }) remain ({ 13 }) untouched ({ 14 }) . ({ 15 }) 
# Sentence pair (2810) source length 25 target length 24 alignment score : 3.24038e-05
Comparing VAR_COMB and VAR_SPLIT in both TC experiment and SMT experiment , we see that the VAR_SPLIT results are better in both cases . 
NULL ({ }) Comparing ({ 1 }) VAR_COMB ({ 2 }) and ({ 3 }) VAR_SPLIT ({ 4 }) in ({ 5 }) both ({ 6 }) the ({ }) TC ({ 7 }) experiment ({ 8 }) and ({ 9 }) SMT ({ 10 }) experiment ({ 11 }) , ({ 12 }) we ({ 13 }) see ({ 14 }) that ({ 15 }) the ({ 16 }) VAR_SPLIT ({ 17 }) results ({ 18 }) are ({ 19 }) better ({ 20 }) in ({ 21 }) both ({ 22 }) cases ({ 23 }) . ({ 24 }) 
# Sentence pair (2811) source length 33 target length 33 alignment score : 1.69072e-06
Since the ratio of combined variations in the ORG corpus is 60 .9% , it can be observed that splitting seems to be better than combining for WS , TC and SMT . 
NULL ({ }) Since ({ 1 }) the ({ 2 }) ratio ({ 3 }) of ({ 4 }) combined ({ 5 }) variations ({ 6 }) in ({ 7 }) the ({ 8 }) ORG ({ 9 }) corpus ({ 10 }) is ({ 11 }) 60 ({ 12 }) .9% ({ 13 }) , ({ 14 }) it ({ 15 }) can ({ 16 }) be ({ 17 }) observed ({ 18 }) that ({ 19 }) splitting ({ 20 }) seems ({ 21 }) to ({ 22 }) be ({ 23 }) better ({ 24 }) than ({ 25 }) combining ({ 26 }) for ({ 27 }) WS ({ 28 }) , ({ 29 }) TC ({ 30 }) and ({ 31 }) SMT ({ 32 }) . ({ 33 }) 
# Sentence pair (2812) source length 28 target length 28 alignment score : 1.86067e-07
In this paper , we have shown a quantitative analysis of the diffculties in word segmentation , through the detection of problematic cases in the Vietnamese treebank . 
NULL ({ }) In ({ 1 }) this ({ 2 }) paper ({ 3 }) , ({ 4 }) we ({ 5 }) have ({ 6 }) provided ({ 7 }) a ({ 8 }) quantitative ({ 9 }) analysis ({ 10 }) of ({ 11 }) the ({ 12 }) difficulties ({ 13 }) in ({ 14 }) word ({ 15 }) segmentation ({ 16 }) , ({ 17 }) through ({ 18 }) the ({ 19 }) detection ({ 20 }) of ({ 21 }) problematic ({ 22 }) cases ({ 23 }) in ({ 24 }) the ({ 25 }) Vietnamese ({ 26 }) Treebank ({ 27 }) . ({ 28 }) 
# Sentence pair (2813) source length 26 target length 25 alignment score : 1.05436e-06
Based on the analysis , we automatically created data representing the different word segmentation criteria , and evaluated the criteria indirectly through their applications . 
NULL ({ }) Based ({ 1 }) on ({ 2 }) the ({ 3 }) analysis ({ 4 }) , ({ 5 }) we ({ 6 }) automatically ({ 7 }) created ({ 8 }) data ({ 9 }) that ({ }) represent ({ 10 }) the ({ 11 }) different ({ 12 }) word ({ 13 }) segmentation ({ 14 }) criteria ({ 15 }) , ({ 16 }) and ({ 17 }) evaluated ({ 18 }) the ({ 19 }) criteria ({ 20 }) indirectly ({ 21 }) through ({ 22 }) their ({ 23 }) applications ({ 24 }) . ({ 25 }) 
# Sentence pair (2814) source length 49 target length 46 alignment score : 4.89653e-16
Our experimental results showed that manual modification done for annotation of spe-cial characters and most of other word segmentation criteria significantly improved the performances of automatic word segmentation , text classification and statistical machine translation , comparing with the use of the original VTB corpus . 
NULL ({ 16 }) Our ({ 1 }) experimental ({ 2 }) results ({ 3 }) showed ({ 4 }) that ({ 5 }) manual ({ 6 }) modification ({ 7 }) , ({ }) done ({ 8 }) for ({ 9 }) annotation ({ 10 }) of ({ 11 }) special ({ 12 }) characters ({ 13 }) , ({ }) and ({ 14 }) most ({ 15 }) other ({ 17 }) word ({ 18 }) segmentation ({ 19 }) criteria ({ 20 }) , ({ }) significantly ({ 21 }) improved ({ 22 }) the ({ 23 }) performances ({ 24 }) of ({ 25 }) automatic ({ 26 }) word ({ 27 }) segmentation ({ 28 }) , ({ 29 }) text ({ 30 }) classification ({ 31 }) and ({ 32 }) statistical ({ 33 }) machine ({ 34 }) translation ({ 35 }) , ({ 36 }) in ({ }) comparison ({ 37 }) with ({ 38 }) the ({ 39 }) use ({ 40 }) of ({ 41 }) the ({ 42 }) original ({ 43 }) VTB ({ 44 }) corpus ({ 45 }) . ({ 46 }) 
# Sentence pair (2815) source length 48 target length 46 alignment score : 2.18365e-12
Since the VTB corpus is the first effort in building a treebank for Vietnamese , and is the only corpus publicly available for NLP research , this study contributes to further improvement of the corpus quality , which is essential for building effcient NLP systems . 
NULL ({ }) Since ({ 1 }) the ({ 2 }) VTB ({ 3 }) corpus ({ 4 }) is ({ 5 }) the ({ 6 }) first ({ 7 }) effort ({ 8 }) in ({ 9 }) building ({ 10 }) a ({ 11 }) treebank ({ 12 }) for ({ 13 }) Vietnamese ({ 14 }) , ({ 15 }) and ({ 16 }) is ({ 17 }) the ({ 18 }) only ({ 19 }) corpus ({ 20 }) that ({ }) is ({ }) publicly ({ 21 }) available ({ 22 }) for ({ 23 }) NLP ({ 24 }) research ({ 25 }) , ({ 26 }) this ({ 27 }) study ({ 28 }) contributes ({ 29 }) to ({ 30 }) further ({ 31 }) improvement ({ 32 }) of ({ 33 }) the ({ 34 }) corpus ({ 35 }) quality ({ 36 }) , ({ 37 }) which ({ 38 }) is ({ 39 }) essential ({ 40 }) for ({ 41 }) building ({ 42 }) efficient ({ 43 }) NLP ({ 44 }) systems ({ 45 }) . ({ 46 }) 
# Sentence pair (2816) source length 7 target length 7 alignment score : 0.00235669
Face retrieval on large-scale news video datasets 
NULL ({ }) Face ({ 1 }) retrieval ({ 2 }) in ({ 3 }) large-scale ({ 4 }) news ({ 5 }) video ({ 6 }) datasets ({ 7 }) 
# Sentence pair (2817) source length 25 target length 23 alignment score : 3.00119e-06
Face retrieval in news video has been identified as a challenging task due to huge variations in visual appearance of human face . 
NULL ({ }) Face ({ 1 }) retrieval ({ 2 }) in ({ 3 }) news ({ 4 }) video ({ 5 }) has ({ 6 }) been ({ 7 }) identified ({ 8 }) as ({ 9 }) a ({ 10 }) challenging ({ 11 }) task ({ 12 }) due ({ 13 }) to ({ 14 }) huge ({ 15 }) variations ({ 16 }) in ({ 17 }) the ({ }) visual ({ 18 }) appearance ({ 19 }) of ({ 20 }) the ({ }) human ({ 21 }) face ({ 22 }) . ({ 23 }) 
# Sentence pair (2818) source length 35 target length 33 alignment score : 1.74474e-20
Although there are several approaches proposed to cope with this problem , their extremely high computational cost limits their scalability on largescale video datasets that may contain millions faces of hundreds characters . 
NULL ({ 2 3 }) Although ({ 1 }) several ({ 4 }) approaches ({ 5 }) have ({ }) been ({ }) proposed ({ 6 }) to ({ 7 }) deal ({ 8 }) with ({ 9 }) this ({ 10 }) problem ({ 11 }) , ({ 12 }) their ({ 13 }) extremely ({ 14 }) high ({ 15 }) computational ({ 16 }) cost ({ 17 }) limits ({ 18 }) their ({ 19 }) scalability ({ 20 }) to ({ 21 }) large-scale ({ 22 }) video ({ 23 }) datasets ({ 24 }) that ({ 25 }) may ({ 26 }) contain ({ 27 }) millions ({ 28 }) of ({ }) faces ({ 29 }) of ({ 30 }) hundreds ({ 31 }) of ({ }) characters ({ 32 }) . ({ 33 }) 
# Sentence pair (2819) source length 24 target length 25 alignment score : 3.37205e-12
In this paper , we introduce approaches for face retrieval which are scalable on such datasets while maintaining competitive performances with the state-of-the-art approaches . 
NULL ({ 22 }) In ({ 1 }) this ({ 2 }) paper ({ 3 }) , ({ 4 }) we ({ 5 }) introduce ({ 6 }) approaches ({ 7 }) to ({ 8 }) face ({ 9 }) retrieval ({ 10 }) that ({ 11 }) are ({ 12 }) scalable ({ 13 }) to ({ 14 }) such ({ 15 }) datasets ({ 16 }) while ({ 17 }) maintaining ({ 18 }) competitive ({ 19 }) performances ({ 20 }) with ({ 21 }) state-of-the-art ({ 23 }) approaches ({ 24 }) . ({ 25 }) 
# Sentence pair (2820) source length 32 target length 32 alignment score : 2.29844e-10
To utilize the variability of face appearances in video , we use a set of face images called face-track to represent for the appearance of a character in a video shot . 
NULL ({ 22 }) To ({ 1 }) utilize ({ 2 }) the ({ 3 }) variability ({ 4 }) of ({ 5 }) face ({ 6 }) appearances ({ 7 }) in ({ 8 }) video ({ 9 }) , ({ 10 }) we ({ 11 }) use ({ 12 }) a ({ 13 }) set ({ 14 }) of ({ 15 }) face ({ 16 }) images ({ 17 }) called ({ 18 }) face ({ }) track ({ 19 }) to ({ 20 }) represent ({ 21 }) the ({ 23 }) appearance ({ 24 }) of ({ 25 }) a ({ 26 }) character ({ 27 }) in ({ 28 }) a ({ 29 }) video ({ 30 }) shot ({ 31 }) . ({ 32 }) 
# Sentence pair (2821) source length 11 target length 10 alignment score : 0.000163368
Our first proposal is an approach for extracting face-tracks . 
NULL ({ }) Our ({ 1 }) first ({ 2 }) proposal ({ 3 }) is ({ 4 }) an ({ 5 }) approach ({ 6 }) to ({ 7 }) extracting ({ 8 }) face ({ }) tracks ({ 9 }) . ({ 10 }) 
# Sentence pair (2822) source length 27 target length 25 alignment score : 9.24008e-11
We use a point tracker for exploring the connections between detected faces belonging to the same character , then grouping them into one face-track . 
NULL ({ }) We ({ 1 }) use ({ 2 }) a ({ 3 }) point ({ 4 }) tracker ({ 5 }) to ({ 6 }) explore ({ 7 }) the ({ 8 }) connections ({ 9 }) between ({ 10 }) detected ({ 11 }) faces ({ 12 }) belonging ({ 13 }) to ({ 14 }) the ({ 15 }) same ({ 16 }) character ({ 17 }) and ({ }) , ({ 18 }) then ({ 19 }) group ({ 20 }) them ({ 21 }) into ({ 22 }) one ({ 23 }) face ({ }) track ({ 24 }) . ({ 25 }) 
# Sentence pair (2823) source length 29 target length 29 alignment score : 1.70546e-05
We present techniques to make the approach robust to common problems caused by sudden illumination changes , partial occlusions , and scattered appearances of characters in news videos . 
NULL ({ }) We ({ 1 }) present ({ 2 }) techniques ({ 3 }) to ({ 4 }) make ({ 5 }) the ({ 6 }) approach ({ 7 }) robust ({ 8 }) to ({ 9 }) common ({ 10 }) problems ({ 11 }) caused ({ 12 }) by ({ 13 }) sudden ({ 14 }) illumination ({ 15 }) changes ({ 16 }) , ({ 17 }) partial ({ 18 }) occlusions ({ 19 }) , ({ 20 }) and ({ 21 }) scattered ({ 22 }) appearances ({ 23 }) of ({ 24 }) characters ({ 25 }) in ({ 26 }) news ({ 27 }) videos ({ 28 }) . ({ 29 }) 
# Sentence pair (2824) source length 17 target length 16 alignment score : 1.51717e-05
In the second proposal , we introduce an efficient approach to match face-tracks for retrieval . 
NULL ({ }) In ({ 1 }) the ({ 2 }) second ({ 3 }) proposal ({ 4 }) , ({ 5 }) we ({ 6 }) introduce ({ 7 }) an ({ 8 }) efficient ({ 9 }) approach ({ 10 }) to ({ 11 }) matching ({ 12 }) face ({ }) tracks ({ 13 }) for ({ 14 }) retrieval ({ 15 }) . ({ 16 }) 
# Sentence pair (2825) source length 25 target length 21 alignment score : 1.06291e-07
Instead of using all faces in face-tracks to compute their similarity , our approach select representative faces for each face-track . 
NULL ({ }) Instead ({ 1 }) of ({ 2 }) using ({ 3 }) all ({ 4 }) the ({ }) faces ({ 5 }) in ({ 6 }) the ({ }) face ({ }) tracks ({ 7 }) to ({ 8 }) compute ({ 9 }) their ({ 10 }) similarity ({ 11 }) , ({ 12 }) our ({ 13 }) approach ({ 14 }) selects ({ 15 }) representative ({ 16 }) faces ({ 17 }) for ({ 18 }) each ({ 19 }) face ({ }) track ({ 20 }) . ({ 21 }) 
# Sentence pair (2826) source length 11 target length 10 alignment score : 0.00358429
The representative faces are sampled from the original face-track . 
NULL ({ }) The ({ 1 }) representative ({ 2 }) faces ({ 3 }) are ({ 4 }) sampled ({ 5 }) from ({ 6 }) the ({ 7 }) original ({ 8 }) face ({ }) track ({ 9 }) . ({ 10 }) 
# Sentence pair (2827) source length 30 target length 27 alignment score : 1.18847e-10
As a result , we significantly reduce the computational cost for face-track matching while taking into account variability of faces in face-tracks for high matching accuracy . 
NULL ({ }) As ({ 1 }) a ({ 2 }) result ({ 3 }) , ({ 4 }) we ({ 5 }) significantly ({ 6 }) reduce ({ 7 }) the ({ 8 }) computational ({ 9 }) cost ({ 10 }) of ({ 11 }) face-track ({ 12 }) matching ({ 13 }) while ({ 14 }) taking ({ 15 }) into ({ 16 }) account ({ 17 }) the ({ }) variability ({ 18 }) of ({ 19 }) faces ({ 20 }) in ({ 21 }) face ({ }) tracks ({ 22 }) to ({ }) achieve ({ 23 }) high ({ 24 }) matching ({ 25 }) accuracy ({ 26 }) . ({ 27 }) 
# Sentence pair (2828) source length 16 target length 14 alignment score : 3.14932e-05
Experiments are conducted on two face-track datasets extracted from real-world news videos , . 
NULL ({ }) Experiments ({ 1 }) are ({ 2 }) conducted ({ 3 }) on ({ 4 }) two ({ 5 }) face-track ({ 6 }) datasets ({ 7 }) extracted ({ 8 }) from ({ 9 }) real-world ({ 10 }) news ({ 11 }) videos ({ 12 }) , ({ 13 }) of ({ }) such ({ }) . ({ 14 }) 
# Sentence pair (2829) source length 10 target length 10 alignment score : 2.98614e-09
Their scales have not been considered in literature ever . 
NULL ({ }) scales ({ 1 2 }) that ({ }) have ({ 3 }) never ({ 4 }) been ({ 5 }) considered ({ 6 }) in ({ 7 }) the ({ }) literature ({ 8 9 }) . ({ 10 }) 
# Sentence pair (2830) source length 17 target length 16 alignment score : 0.000619102
One dataset contains 1,497 face-tracks of 41 characters extracted from 370 hours of TRECVID videos . 
NULL ({ }) One ({ 1 }) dataset ({ 2 }) contains ({ 3 }) 1,497 ({ 4 }) face ({ }) tracks ({ 5 }) of ({ 6 }) 41 ({ 7 }) characters ({ 8 }) extracted ({ 9 }) from ({ 10 }) 370 ({ 11 }) hours ({ 12 }) of ({ 13 }) TRECVID ({ 14 }) videos ({ 15 }) . ({ 16 }) 
# Sentence pair (2831) source length 25 target length 24 alignment score : 2.6499e-10
The other dataset provides 5,567 face-tracks of 111 characters observed from television news program ( NHK News 7 ) channel in 11 years . 
NULL ({ 21 }) The ({ 1 }) other ({ 2 }) dataset ({ 3 }) provides ({ 4 }) 5,567 ({ 5 }) face ({ }) tracks ({ 6 }) of ({ 7 }) 111 ({ 8 }) characters ({ 9 }) observed ({ 10 }) from ({ 11 }) a ({ }) television ({ 12 }) news ({ 13 }) program ({ 14 }) ( ({ 15 }) NHK ({ 16 }) News ({ 17 }) 7 ({ 18 }) ) ({ 19 }) over ({ 20 }) 11 ({ 22 }) years ({ 23 }) . ({ 24 }) 
# Sentence pair (2832) source length 10 target length 9 alignment score : 0.00488413
We make both datasets public for research community . 
NULL ({ }) We ({ 1 }) make ({ 2 }) both ({ 3 }) datasets ({ 4 }) public ({ 5 }) for ({ 6 }) the ({ }) research ({ 7 }) community ({ 8 }) . ({ 9 }) 
# Sentence pair (2833) source length 16 target length 16 alignment score : 2.99344e-05
The experimental results demonstrate that our proposed approaches achieved a remarkable balance between accuracy and efficiency. 
NULL ({ }) The ({ 1 }) experimental ({ 2 }) results ({ 3 }) show ({ 4 }) that ({ 5 }) our ({ 6 }) proposed ({ 7 }) approaches ({ 8 }) achieved ({ 9 }) a ({ 10 }) remarkable ({ 11 }) balance ({ 12 }) between ({ 13 }) accuracy ({ 14 }) and ({ 15 }) efficiency. ({ 16 }) 
# Sentence pair (2834) source length 20 target length 20 alignment score : 6.87158e-12
News videos play an important role in our sources of information nowadays because of their rich and important contents . 
NULL ({ 7 }) News ({ 1 }) videos ({ 2 }) play ({ 3 }) an ({ 4 }) important ({ 5 }) role ({ 6 }) as ({ }) a ({ }) source ({ 8 9 }) of ({ 10 }) information ({ 11 }) nowadays ({ 12 }) because ({ 13 }) of ({ 14 }) their ({ 15 }) rich ({ 16 }) and ({ 17 }) relevant ({ 18 }) contents ({ 19 }) . ({ 20 }) 
# Sentence pair (2835) source length 18 target length 18 alignment score : 3.18569e-05
With the advances of modern technology , a huge amount of news videos can be obtained easily . 
NULL ({ }) With ({ 1 }) the ({ 2 }) advances ({ 3 }) in ({ 4 }) modern ({ 5 }) technology ({ 6 }) , ({ 7 }) a ({ 8 }) huge ({ 9 }) amount ({ 10 }) of ({ 11 }) news ({ 12 }) videos ({ 13 }) can ({ 14 }) be ({ 15 }) obtained ({ 16 }) easily ({ 17 }) . ({ 18 }) 
# Sentence pair (2836) source length 17 target length 17 alignment score : 3.71204e-09
Accordingly , it creates an urgent demand for retrieving useful information in such news video datasets . 
NULL ({ }) Accordingly ({ 1 }) , ({ 2 }) this ({ 3 }) creates ({ 4 }) an ({ 5 }) urgent ({ 6 }) demand ({ 7 }) to ({ 8 }) retrieve ({ 9 }) useful ({ 10 }) information ({ 11 }) from ({ 12 }) such ({ 13 }) news ({ 14 }) video ({ 15 }) datasets ({ 16 }) . ({ 17 }) 
# Sentence pair (2837) source length 35 target length 37 alignment score : 1.93057e-12
Since most of the news is related to human , human face retrieval , which is defined as the task of extracting and returning faces relevant to a given query , obviously becomes an important task . 
NULL ({ 3 4 }) Because ({ 1 }) most ({ 2 }) news ({ 5 }) are ({ 6 }) related ({ 7 }) to ({ 8 }) people ({ 9 }) , ({ 10 }) human ({ 11 }) face ({ 12 }) retrieval ({ 13 }) , ({ 14 }) which ({ 15 }) is ({ 16 }) defined ({ 17 }) as ({ 18 }) the ({ 19 }) task ({ 20 }) of ({ 21 }) extracting ({ 22 }) and ({ 23 }) returning ({ 24 }) faces ({ 25 }) relevant ({ 26 }) to ({ 27 }) a ({ 28 }) given ({ 29 }) query ({ 30 }) , ({ 31 }) obviously ({ 32 }) becomes ({ 33 }) an ({ 34 }) important ({ 35 }) task ({ 36 }) . ({ 37 }) 
# Sentence pair (2838) source length 22 target length 22 alignment score : 2.56015e-09
A robust face retrieval system on large-scale news video datasets is indeed of much benefit to a wide range of applications . 
NULL ({ }) A ({ 1 }) robust ({ 2 }) face ({ 3 }) retrieval ({ 4 }) system ({ 5 }) for ({ 6 }) large-scale ({ 7 }) news ({ 8 }) video ({ 9 }) datasets ({ 10 }) is ({ 11 }) indeed ({ 12 }) of ({ 13 }) much ({ 14 }) benefit ({ 15 }) in ({ 16 }) a ({ 17 }) wide ({ 18 }) range ({ 19 }) of ({ 20 }) applications ({ 21 }) . ({ 22 }) 
# Sentence pair (2839) source length 32 target length 31 alignment score : 1.38842e-06
For example , by applying face retrieval to a news video dataset , we are returned a list of relevant shots or scenes containing appearance of a selected well-known character . 
NULL ({ }) For ({ 1 }) example ({ 2 }) , ({ 3 }) by ({ 4 }) applying ({ 5 }) face ({ 6 }) retrieval ({ 7 }) to ({ 8 }) a ({ 9 }) news ({ 10 }) video ({ 11 }) dataset ({ 12 }) , ({ 13 }) we ({ 14 }) are ({ 15 }) returned ({ 16 }) a ({ 17 }) list ({ 18 }) of ({ 19 }) relevant ({ 20 }) shots ({ 21 }) or ({ 22 }) scenes ({ 23 }) containing ({ 24 }) the ({ }) appearance ({ 25 }) of ({ 26 }) a ({ 27 }) selected ({ 28 }) well-known ({ 29 }) character ({ 30 }) . ({ 31 }) 
# Sentence pair (2840) source length 16 target length 15 alignment score : 5.23258e-08
With the list , important events related to the character can be detected or summarized. 
NULL ({ 2 }) With ({ 1 }) such ({ }) a ({ }) list ({ 3 }) , ({ 4 }) important ({ 5 }) events ({ 6 }) related ({ 7 }) to ({ 8 }) the ({ 9 }) character ({ 10 }) can ({ 11 }) be ({ 12 }) found ({ 13 }) or ({ 14 }) summarized. ({ 15 }) 
# Sentence pair (2841) source length 40 target length 39 alignment score : 1.90405e-08
However , developing an accurate face retrieval system is not a trivial task because of the fact that imaged appearance of a face changes dramatically under large variations in poses , facial expressions , and complex capturing conditions . 
NULL ({ }) However ({ 1 }) , ({ 2 }) developing ({ 3 }) an ({ 4 }) accurate ({ 5 }) face ({ 6 }) retrieval ({ 7 }) system ({ 8 }) is ({ 9 }) not ({ 10 }) a ({ 11 }) trivial ({ 12 }) task ({ 13 }) because ({ 14 }) of ({ 15 }) the ({ 16 }) fact ({ 17 }) that ({ 18 }) the ({ }) imaged ({ 19 }) appearance ({ 20 }) of ({ 21 }) a ({ 22 }) face ({ 23 }) changes ({ 24 }) dramatically ({ 25 }) under ({ 26 }) large ({ 27 }) variations ({ 28 }) in ({ 29 }) poses ({ 30 }) , ({ 31 }) facial ({ 32 }) expressions ({ 33 }) , ({ 34 }) and ({ 35 }) complex ({ 36 }) capturing ({ 37 }) conditions ({ 38 }) . ({ 39 }) 
# Sentence pair (2842) source length 43 target length 44 alignment score : 3.46792e-33
On the other hand , efficiency is also an issue of such a face retrieval system beside its accuracy since scales of available datasets are getting larger rapidly , for instance , exceeding thousands hours of videos with millions faces of hundreds character . 
NULL ({ 2 }) Besides ({ 1 }) accuracy ({ 19 }) , ({ 5 }) efficiency ({ 6 }) is ({ 7 }) also ({ 8 }) an ({ 9 }) issue ({ 10 }) in ({ 11 }) such ({ 12 }) a ({ 13 }) face ({ 14 }) retrieval ({ 15 }) system ({ 16 }) because ({ 20 }) the ({ }) scales ({ 21 }) of ({ 22 }) available ({ 23 }) datasets ({ 24 }) are ({ 25 }) rapidly ({ 17 28 }) getting ({ 3 4 18 26 }) larger ({ 27 }) , ({ 29 }) for ({ 30 }) instance ({ 31 }) , ({ 32 }) exceeding ({ 33 }) thousands ({ 34 }) of ({ }) hours ({ 35 }) of ({ 36 }) videos ({ 37 }) with ({ 38 }) millions ({ 39 }) of ({ }) faces ({ 40 }) of ({ 41 }) hundreds ({ 42 }) of ({ }) characters ({ 43 }) . ({ 44 }) 
# Sentence pair (2843) source length 12 target length 12 alignment score : 0.000304218
Thus , accurate and efficient approaches for face retrieval are always required. 
NULL ({ }) Thus ({ 1 }) , ({ 2 }) accurate ({ 3 }) and ({ 4 }) efficient ({ 5 }) approaches ({ 6 }) to ({ 7 }) face ({ 8 }) retrieval ({ 9 }) are ({ 10 }) always ({ 11 }) required. ({ 12 }) 
# Sentence pair (2844) source length 12 target length 13 alignment score : 1.43688e-14
Generally , there are two principle steps in a face retrieval system . 
NULL ({ 4 8 }) Generally ({ 1 }) , ({ 2 }) a ({ 9 }) face ({ 10 }) retrieval ({ 11 }) system ({ 12 }) consists ({ 6 }) of ({ }) two ({ 5 }) principal ({ 3 }) steps ({ 7 }) . ({ 13 }) 
# Sentence pair (2845) source length 12 target length 11 alignment score : 0.000247845
The first step is extracting appearance of faces in video . 
NULL ({ }) The ({ 1 }) first ({ 2 }) step ({ 3 }) is ({ 4 }) extracting ({ 5 }) the ({ }) appearance ({ 6 }) of ({ 7 }) faces ({ 8 }) in ({ 9 }) videos ({ 10 }) . ({ 11 }) 
# Sentence pair (2846) source length 21 target length 20 alignment score : 1.77088e-12
And , the second step is matching the extracted ones with a given query to return a rank list . 
NULL ({ 3 }) , ({ 2 }) The ({ 1 }) second ({ 4 }) step ({ 5 }) is ({ 6 }) matching ({ 7 }) the ({ 8 }) extracted ({ 9 }) appearances ({ 10 }) with ({ 11 }) a ({ 12 }) given ({ 13 }) query ({ 14 }) so ({ }) as ({ }) to ({ 15 }) return ({ 16 }) a ({ 17 }) rank ({ 18 }) list ({ 19 }) . ({ 20 }) 
# Sentence pair (2847) source length 33 target length 29 alignment score : 3.24331e-12
While conventional approaches consider single face images as the basic units for extracting and matching \CITE , recently proposed approaches sifted towards sets of face images called face-tracks . 
NULL ({ }) Whereas ({ 1 }) conventional ({ 2 }) approaches ({ 3 }) consider ({ 4 }) single ({ 5 }) face ({ 6 }) images ({ 7 }) as ({ 8 }) the ({ 9 }) basic ({ 10 }) units ({ 11 }) in ({ 12 }) extracting ({ 13 }) and ({ 14 }) matching ({ 15 }) \CITE ({ 16 }) , ({ 17 }) recently ({ 18 }) proposed ({ 19 }) approaches ({ 20 }) shifted ({ 21 }) toward ({ 22 }) the ({ }) use ({ }) of ({ }) sets ({ 23 }) of ({ 24 }) face ({ 25 }) images ({ 26 }) called ({ 27 }) face ({ }) tracks ({ 28 }) . ({ 29 }) 
# Sentence pair (2848) source length 18 target length 17 alignment score : 0.000300968
A face-track contains multiple face images belonging to the same individual character within a video shot . 
NULL ({ }) A ({ 1 }) face ({ }) track ({ 2 }) contains ({ 3 }) multiple ({ 4 }) face ({ 5 }) images ({ 6 }) belonging ({ 7 }) to ({ 8 }) the ({ 9 }) same ({ 10 }) individual ({ 11 }) character ({ 12 }) within ({ 13 }) a ({ 14 }) video ({ 15 }) shot ({ 16 }) . ({ 17 }) 
# Sentence pair (2849) source length 28 target length 24 alignment score : 2.85322e-13
Face images in a face-track may present the corresponding character under different viewpoints and facial expressions ( as shown in Figure 1 ) . 
NULL ({ }) The ({ 1 }) face ({ }) images ({ 2 }) in ({ 3 }) a ({ 4 }) face ({ }) track ({ 5 }) may ({ 6 }) present ({ 7 }) the ({ 8 }) corresponding ({ 9 }) character ({ 10 }) from ({ 11 }) different ({ 12 }) viewpoints ({ 13 }) and ({ 14 }) with ({ }) different ({ }) facial ({ 15 }) expressions ({ 16 }) ( ({ 17 }) as ({ 18 }) shown ({ 19 }) in ({ 20 }) Figure ({ 21 }) 1 ({ 22 }) ) ({ 23 }) . ({ 24 }) 
# Sentence pair (2850) source length 28 target length 24 alignment score : 2.05952e-10
By exploiting the plenteous information from multiple exemplar faces in face-tracks , face-track based approaches are expected to achieve more robust and stable performance. 
NULL ({ }) By ({ 1 }) exploiting ({ 2 }) the ({ 3 }) plenteous ({ 4 }) information ({ 5 }) from ({ 6 }) the ({ }) multiple ({ 7 }) exemplar ({ 8 }) faces ({ 9 }) in ({ 10 }) the ({ }) face ({ }) tracks ({ 11 }) , ({ 12 }) face ({ 13 }) track-based ({ 14 }) approaches ({ 15 }) are ({ 16 }) expected ({ 17 }) to ({ 18 }) achieve ({ 19 }) a ({ }) more ({ 20 }) robust ({ 21 }) and ({ 22 }) stable ({ 23 }) performance. ({ 24 }) 
# Sentence pair (2851) source length 32 target length 29 alignment score : 9.72008e-08
Once all face-tracks in video shots are extracted , they are matched with the query to return a ranked list as the output of the face retrieval system . 
NULL ({ }) Once ({ 1 }) all ({ 2 }) the ({ }) face ({ }) tracks ({ 3 }) in ({ 4 }) the ({ }) video ({ 5 }) shots ({ 6 }) are ({ 7 }) extracted ({ 8 }) , ({ 9 }) they ({ 10 }) are ({ 11 }) matched ({ 12 }) with ({ 13 }) the ({ 14 }) query ({ 15 }) to ({ 16 }) return ({ 17 }) a ({ 18 }) ranked ({ 19 }) list ({ 20 }) as ({ 21 }) the ({ 22 }) output ({ 23 }) of ({ 24 }) the ({ 25 }) face ({ 26 }) retrieval ({ 27 }) system ({ 28 }) . ({ 29 }) 
# Sentence pair (2852) source length 27 target length 25 alignment score : 2.18355e-09
Since each face-track is a set of face images , matching face-tracks essentially can be thought of as a problem of matching image sets . 
NULL ({ }) Because ({ 1 }) each ({ 2 }) face ({ }) track ({ 3 }) is ({ 4 }) a ({ 5 }) set ({ 6 }) of ({ 7 }) face ({ 8 }) images ({ 9 }) , ({ 10 }) matching ({ 11 }) face ({ }) tracks ({ 12 }) can ({ 14 }) essentially ({ 13 }) be ({ 15 }) thought ({ 16 }) of ({ 17 }) as ({ 18 }) a ({ 19 }) problem ({ 20 }) of ({ 21 }) matching ({ 22 }) image ({ 23 }) sets ({ 24 }) . ({ 25 }) 
# Sentence pair (2853) source length 12 target length 12 alignment score : 1.13572e-10
There are several approaches introduced to deal with this problem \CITE . 
NULL ({ 2 }) Several ({ 1 3 }) approaches ({ 4 }) have ({ }) been ({ }) introduced ({ 5 }) to ({ 6 }) deal ({ 7 }) with ({ 8 }) this ({ 9 }) problem ({ 10 }) \CITE ({ 11 }) . ({ 12 }) 
# Sentence pair (2854) source length 19 target length 19 alignment score : 0.000278433
They differ in the ways in which the sets are modeled and the similarity between sets is computed . 
NULL ({ }) They ({ 1 }) differ ({ 2 }) in ({ 3 }) the ({ 4 }) ways ({ 5 }) in ({ 6 }) which ({ 7 }) the ({ 8 }) sets ({ 9 }) are ({ 10 }) modeled ({ 11 }) and ({ 12 }) the ({ 13 }) similarity ({ 14 }) between ({ 15 }) sets ({ 16 }) is ({ 17 }) computed ({ 18 }) . ({ 19 }) 
# Sentence pair (2855) source length 38 target length 35 alignment score : 2.4306e-14
In these works , image set has been modeled in different way , such as distributions \CITE , subspaces \CITE , convex geometric region in feature space \CITE , or more general manifolds \CITE . 
NULL ({ }) Using ({ 1 }) these ({ 2 }) approaches ({ 3 }) , ({ 4 }) the ({ }) image ({ 5 }) set ({ 6 }) has ({ 7 }) been ({ 8 }) modeled ({ 9 }) in ({ 10 }) different ({ 11 }) ways ({ 12 }) , ({ 13 }) including ({ 14 }) as ({ 15 }) distributions ({ 16 }) \CITE ({ 17 }) , ({ 18 }) subspaces ({ 19 }) \CITE ({ 20 }) , ({ 21 }) a ({ }) convex ({ 22 }) geometric ({ 23 }) region ({ 24 }) in ({ 25 }) a ({ }) feature ({ 26 }) space ({ 27 }) \CITE ({ 28 }) , ({ 29 }) or ({ 30 }) more ({ 31 }) general ({ 32 }) manifolds ({ 33 }) \CITE ({ 34 }) . ({ 35 }) 
# Sentence pair (2856) source length 45 target length 43 alignment score : 4.14228e-11
Although these approaches shown promising results on benchmark datasets , they require high computational costs to characterize the representation of face-tracks , such as computing the convex geometric region in \CITE , the probability in \CITE , and the eigenvectors in \CITE . 
NULL ({ }) Although ({ 1 }) these ({ 2 }) approaches ({ 3 }) have ({ }) shown ({ 4 }) promising ({ 5 }) results ({ 6 }) in ({ 7 }) benchmark ({ 8 }) datasets ({ 9 }) , ({ 10 }) they ({ 11 }) require ({ 12 }) high ({ 13 }) computational ({ 14 }) costs ({ 15 }) to ({ 16 }) characterize ({ 17 }) the ({ 18 }) representation ({ 19 }) of ({ 20 }) face ({ }) tracks ({ 21 }) , ({ 22 }) such ({ 23 }) as ({ 24 }) computing ({ 25 }) the ({ 26 }) convex ({ 27 }) geometric ({ 28 }) region ({ 29 }) in ({ 30 }) \CITE ({ 31 }) , ({ 32 }) the ({ 33 }) probability ({ 34 }) in ({ 35 }) \CITE ({ 36 }) , ({ 37 }) and ({ 38 }) the ({ 39 }) eigenvectors ({ 40 }) in ({ 41 }) \CITE ({ 42 }) . ({ 43 }) 
# Sentence pair (2857) source length 19 target length 16 alignment score : 3.16235e-08
Their complexity in modeling facetracks and estimating similarity between face-tracks limits their practicability on large-scale datasets. 
NULL ({ }) Their ({ 1 }) complexity ({ 2 }) in ({ 3 }) modeling ({ 4 }) face ({ }) tracks ({ 5 }) and ({ 6 }) estimating ({ 7 }) the ({ }) similarity ({ 8 }) between ({ 9 }) face ({ }) tracks ({ 10 }) limits ({ 11 }) their ({ 12 }) practicability ({ 13 }) in ({ 14 }) large-scale ({ 15 }) datasets. ({ 16 }) 
# Sentence pair (2858) source length 13 target length 14 alignment score : 1.6768e-19
Working toward solving the above problems , our contributions in this paper is three-fold. 
NULL ({ 10 11 }) This ({ 1 }) paper ({ 12 }) provides ({ 13 }) a ({ 14 }) threefold ({ 8 }) contribution ({ 9 }) toward ({ 2 }) solving ({ 3 }) the ({ 4 }) above ({ 5 }) problems ({ 6 }) , ({ 7 }) . ({ }) 
# Sentence pair (2859) source length 7 target length 7 alignment score : 0.00115845
Robust face-track extraction on news video . 
NULL ({ }) Robust ({ 1 }) face-track ({ 2 }) extraction ({ 3 }) from ({ 4 }) news ({ 5 }) video ({ 6 }) . ({ 7 }) 
# Sentence pair (2860) source length 16 target length 15 alignment score : 6.63738e-06
To enhance the performance of face-track matching , face-tracks should be first extracted accurately . 
NULL ({ }) To ({ 1 }) enhance ({ 2 }) the ({ 3 }) performance ({ 4 }) of ({ 5 }) face-track ({ 6 }) matching ({ 7 }) , ({ 8 }) face ({ }) tracks ({ 9 }) should ({ 10 }) first ({ 12 }) be ({ 11 }) extracted ({ 13 }) accurately ({ 14 }) . ({ 15 }) 
# Sentence pair (2861) source length 9 target length 9 alignment score : 5.14598e-10
, We introduce an approach for this purpose . 
NULL ({ }) For ({ 6 }) this ({ 7 }) purpose ({ 8 }) , ({ 1 }) we ({ 2 }) introduce ({ 3 }) an ({ 4 }) approach ({ 5 }) . ({ 9 }) 
# Sentence pair (2862) source length 9 target length 12 alignment score : 6.13687e-11
Our approach is motivated by a study of Everingham et al . 
NULL ({ 3 }) motivated ({ 1 2 4 }) by ({ 5 }) a ({ 6 }) study ({ 7 }) of ({ 8 }) Everingham ({ 9 }) et ({ 10 }) al ({ 11 }) . ({ 12 }) 
# Sentence pair (2863) source length 32 target length 32 alignment score : 3.31244e-07
The basic idea is to employ a point tracker ( Kanade-Lucas-Tomasi tracker \CITE ) to establish the connections between faces belonging to the same character in consecutive frames of a shot . 
NULL ({ }) The ({ 1 }) basic ({ 2 }) idea ({ 3 }) is ({ 4 }) to ({ 5 }) use ({ 6 }) a ({ 7 }) point ({ 8 }) tracker ({ 9 }) ( ({ 10 }) Kanade-Lucas-Tomasi ({ 11 }) tracker ({ 12 }) \CITE ({ 13 }) ) ({ 14 }) to ({ 15 }) establish ({ 16 }) the ({ 17 }) connections ({ 18 }) between ({ 19 }) faces ({ 20 }) belonging ({ 21 }) to ({ 22 }) the ({ 23 }) same ({ 24 }) character ({ 25 }) in ({ 26 }) consecutive ({ 27 }) frames ({ 28 }) of ({ 29 }) a ({ 30 }) shot ({ 31 }) . ({ 32 }) 
# Sentence pair (2864) source length 37 target length 39 alignment score : 1.32245e-26
, In constrast to the approach in \CITE , which is failed to deal with specific problems of news video caused by sudden illumination change and partial occlusion , our approach is incorporated techniques to overcome the problems . 
NULL ({ 1 11 32 37 }) Our ({ 30 }) approach ({ 31 }) incorporates ({ 33 }) techniques ({ 34 }) to ({ 35 }) overcome ({ 36 }) specific ({ 16 }) problems ({ 17 }) with ({ 18 }) news ({ 19 }) video ({ 20 }) caused ({ 21 }) by ({ 22 }) sudden ({ 23 }) illumination ({ 24 }) change ({ 25 }) and ({ 26 }) partial ({ 27 }) occlusion ({ 28 }) , ({ 29 }) in ({ 2 }) contrast ({ 3 }) to ({ 4 }) the ({ 5 }) approach ({ 6 }) in ({ 7 }) \CITE ({ 8 }) , ({ 9 }) which ({ 10 }) failed ({ 12 }) to ({ 13 }) deal ({ 14 }) with ({ 15 }) , ({ }) these ({ }) problems ({ 38 }) . ({ 39 }) 
# Sentence pair (2865) source length 30 target length 29 alignment score : 8.5395e-11
Evaluations on a collection of real-world news videos showed that our proposed face-track extraction approach achieved approximately 95% accuracy , a significant improvement compare the approach in \CITE . 
NULL ({ }) Evaluations ({ 1 }) of ({ 2 }) a ({ 3 }) collection ({ 4 }) of ({ 5 }) real-world ({ 6 }) news ({ 7 }) videos ({ 8 }) showed ({ 9 }) that ({ 10 }) our ({ 11 }) proposed ({ 12 }) face-track ({ 13 }) extraction ({ 14 }) approach ({ 15 }) achieved ({ 16 }) approximately ({ 17 }) 95% ({ 18 }) accuracy ({ 19 }) , ({ 20 }) a ({ 21 }) significant ({ 22 }) improvement ({ 23 }) compared ({ 24 }) to ({ }) the ({ 25 }) approach ({ 26 }) in ({ 27 }) \CITE ({ 28 }) . ({ 29 }) 
# Sentence pair (2866) source length 4 target length 4 alignment score : 0.298422
Efficient face-track matching . 
NULL ({ }) Efficient ({ 1 }) face-track ({ 2 }) matching ({ 3 }) . ({ 4 }) 
# Sentence pair (2867) source length 22 target length 26 alignment score : 9.06469e-20
We introduce an approach which significantly reduces the computational cost for face-track matching while maintaining a competitive performance compare to those of the state-of-the-art approaches . 
NULL ({ 20 22 23 }) We ({ 1 }) introduce ({ 2 }) an ({ 3 }) approach ({ 4 }) that ({ 5 }) significantly ({ 6 }) reduces ({ 7 19 21 }) the ({ 8 }) computational ({ 9 }) cost ({ 10 }) for ({ 11 }) face-track ({ 12 }) matching ({ 13 }) while ({ 14 }) maintaining ({ 15 }) a ({ 16 }) competitive ({ 17 }) performance ({ 18 }) with ({ }) state-of-the-art ({ 24 }) approaches ({ 25 }) . ({ 26 }) 
# Sentence pair (2868) source length 40 target length 37 alignment score : 4.19795e-09
Based on the observation that face-tracks obtained by tracking provide highly similar faces in consecutive frames , we argue that it is redundant to use all faces in a face-track for learning the variation of faces . 
NULL ({ }) Based ({ 1 }) on ({ 2 }) the ({ 3 }) observation ({ 4 }) that ({ 5 }) face ({ }) tracks ({ 6 }) obtained ({ 7 }) by ({ 8 }) tracking ({ 9 }) provide ({ 10 }) highly ({ 11 }) similar ({ 12 }) faces ({ 13 }) in ({ 14 }) consecutive ({ 15 }) frames ({ 16 }) , ({ 17 }) we ({ 18 }) argue ({ 19 }) that ({ 20 }) it ({ 21 }) is ({ 22 }) redundant ({ 23 }) to ({ 24 }) use ({ 25 }) all ({ 26 }) the ({ }) faces ({ 27 }) in ({ 28 }) a ({ 29 }) face ({ }) track ({ 30 }) for ({ 31 }) learning ({ 32 }) the ({ 33 }) variation ({ 34 }) of ({ 35 }) faces ({ 36 }) . ({ 37 }) 
# Sentence pair (2869) source length 16 target length 15 alignment score : 0.000453122
Thus , a set of faces is sampled from the original face-track for matching . 
NULL ({ }) Thus ({ 1 }) , ({ 2 }) a ({ 3 }) set ({ 4 }) of ({ 5 }) faces ({ 6 }) is ({ 7 }) sampled ({ 8 }) from ({ 9 }) the ({ 10 }) original ({ 11 }) face ({ }) track ({ 12 }) for ({ 13 }) matching ({ 14 }) . ({ 15 }) 
# Sentence pair (2870) source length 16 target length 15 alignment score : 5.03879e-09
The size of the set is much smaller than the size of original face-track . 
NULL ({ 10 }) The ({ 1 }) size ({ 2 }) of ({ 3 }) the ({ 4 }) set ({ 5 }) is ({ 6 }) much ({ 7 }) smaller ({ 8 }) than ({ 9 }) that ({ 11 }) of ({ 12 }) the ({ }) original ({ 13 }) face ({ }) track ({ 14 }) . ({ 15 }) 
# Sentence pair (2871) source length 15 target length 14 alignment score : 1.75222e-09
Then , the mean face of sampled faces in the set is computed . 
NULL ({ 3 }) The ({ 1 }) , ({ 2 }) mean ({ 4 }) face ({ 5 }) of ({ 6 }) the ({ }) sampled ({ 7 }) faces ({ 8 }) in ({ 9 }) the ({ 10 }) set ({ 11 }) is ({ 12 }) then ({ }) computed ({ 13 }) . ({ 14 }) 
# Sentence pair (2872) source length 13 target length 12 alignment score : 0.00181943
The similarity between two face-tracks is the distance between their mean faces. 
NULL ({ }) The ({ 1 }) similarity ({ 2 }) between ({ 3 }) two ({ 4 }) face ({ }) tracks ({ 5 }) is ({ 6 }) the ({ 7 }) distance ({ 8 }) between ({ 9 }) their ({ 10 }) mean ({ 11 }) faces. ({ 12 }) 
# Sentence pair (2873) source length 8 target length 8 alignment score : 0.0808046
Large-scale face-track datasets from real-world news videos . 
NULL ({ }) Large-scale ({ 1 }) face-track ({ 2 }) datasets ({ 3 }) from ({ 4 }) real-world ({ 5 }) news ({ 6 }) videos ({ 7 }) . ({ 8 }) 
# Sentence pair (2874) source length 21 target length 20 alignment score : 3.251e-11
We investigated the problem of face-retrieval on news video datasets whose scales have not been considered in literature ever . 
NULL ({ }) We ({ 1 }) investigated ({ 2 }) the ({ 3 }) problem ({ 4 }) of ({ 5 }) face ({ }) retrieval ({ 6 }) in ({ 7 }) news ({ 8 }) video ({ 9 }) datasets ({ 10 }) whose ({ 11 }) scales ({ 12 }) have ({ 13 }) never ({ 14 }) been ({ 15 }) considered ({ 16 }) in ({ 17 }) the ({ }) literature ({ 18 19 }) . ({ 20 }) 
# Sentence pair (2875) source length 21 target length 20 alignment score : 4.53053e-08
Our first dataset is from 370 hours TRECVID news videos which contains 405,887 detected faces belonging to 41 individuals . 
NULL ({ }) Our ({ 1 }) first ({ 2 }) dataset ({ 3 }) is ({ 4 }) from ({ 5 }) 370 ({ 6 }) hours ({ 7 }) of ({ }) TRECVID ({ 8 }) news ({ 9 }) videos ({ 10 }) and ({ 11 }) contains ({ 12 }) 405,887 ({ 13 }) detected ({ 14 }) faces ({ 15 }) belonging ({ 16 }) to ({ 17 }) 41 ({ 18 }) individuals ({ 19 }) . ({ 20 }) 
# Sentence pair (2876) source length 21 target length 13 alignment score : 1.1604e-19
The second dataset is observed from NHK News7 channel in 11 years . 
NULL ({ 4 }) The ({ 1 }) second ({ 2 }) dataset ({ 3 }) includes ({ 5 }) 1.2 ({ 6 }) million ({ }) faces ({ }) of ({ }) 111 ({ }) individuals ({ }) observed ({ }) in ({ }) the ({ }) NHK ({ 7 }) News ({ 8 }) 7 ({ }) program ({ 9 }) over ({ 10 }) 11 ({ 11 }) years ({ 12 }) . ({ 13 }) 
# Sentence pair (2877) source length 2 target length 13 alignment score : 9.4555e-52
In this dataset , 1.2 millions faces of 111 individuals are provided . 
NULL ({ 4 5 7 8 9 11 }) , ({ 1 }) . ({ 2 3 6 10 12 13 }) 
# Sentence pair (2878) source length 10 target length 9 alignment score : 0.000381466
The total number of available face-track is 5,567 . 
NULL ({ }) The ({ 1 }) total ({ 2 }) number ({ 3 }) of ({ 4 }) available ({ 5 }) face ({ }) tracks ({ 6 }) is ({ 7 }) 5,567 ({ 8 }) . ({ 9 }) 
# Sentence pair (2879) source length 14 target length 13 alignment score : 4.8074e-08
Number of occurrence of each individual character varies from 4 to 550 . 
NULL ({ }) The ({ 1 }) number ({ }) of ({ 2 }) occurrences ({ 3 }) of ({ 4 }) each ({ 5 }) individual ({ 6 }) character ({ 7 }) varies ({ 8 }) from ({ 9 }) 4 ({ 10 }) to ({ 11 }) 550 ({ 12 }) . ({ 13 }) 
# Sentence pair (2880) source length 8 target length 8 alignment score : 0.0349187
Both datasets are published for the research community. 
NULL ({ }) Both ({ 1 }) datasets ({ 2 }) are ({ 3 }) published ({ 4 }) for ({ 5 }) the ({ 6 }) research ({ 7 }) community. ({ 8 }) 
# Sentence pair (2881) source length 10 target length 10 alignment score : 0.0182893
The remaining of this paper is organized as follows . 
NULL ({ }) The ({ 1 }) remainder ({ 2 }) of ({ 3 }) this ({ 4 }) paper ({ 5 }) is ({ 6 }) organized ({ 7 }) as ({ 8 }) follows ({ 9 }) . ({ 10 }) 
# Sentence pair (2882) source length 11 target length 11 alignment score : 0.0163311
In Section 2 , we introduce related works in details . 
NULL ({ }) In ({ 1 }) Section ({ 2 }) 2 ({ 3 }) , ({ 4 }) we ({ 5 }) introduce ({ 6 }) related ({ 7 }) works ({ 8 }) in ({ 9 }) detail ({ 10 }) . ({ 11 }) 
# Sentence pair (2883) source length 15 target length 15 alignment score : 3.83499e-11
Section 3 and Section 4 describe our face-track extraction and matching , approaches respectively . 
NULL ({ }) Sections ({ 1 4 }) 3 ({ 2 }) and ({ 3 }) 4 ({ 5 }) describe ({ 6 }) our ({ 7 }) approaches ({ 13 }) to ({ }) face-track ({ 8 }) extraction ({ 9 }) and ({ 10 }) matching ({ 11 }) , ({ 12 }) respectively ({ 14 }) . ({ 15 }) 
# Sentence pair (2884) source length 13 target length 8 alignment score : 2.35077e-08
Section 5 presents our experimental settings , . 
NULL ({ }) Section ({ 1 }) 5 ({ 2 }) presents ({ 3 }) our ({ 4 }) experimental ({ 5 }) settings ({ 6 }) , ({ 7 }) and ({ }) Section ({ }) 6 ({ }) provides ({ }) our ({ }) . ({ 8 }) 
# Sentence pair (2885) source length 1 target length 8 alignment score : 5.19644e-13
Conclusion is given in the final Section 6. 
NULL ({ 5 }) conclusions. ({ 1 2 3 4 6 7 8 }) 
# Sentence pair (2886) source length 3 target length 3 alignment score : 0.466325
Face-track extraction . 
NULL ({ }) Face-track ({ 1 }) extraction ({ 2 }) . ({ 3 }) 
# Sentence pair (2887) source length 13 target length 13 alignment score : 0.00816452
Face-track extraction is a key step in a video-based face retrieval system . 
NULL ({ }) Face-track ({ 1 }) extraction ({ 2 }) is ({ 3 }) a ({ 4 }) key ({ 5 }) step ({ 6 }) in ({ 7 }) a ({ 8 }) video-based ({ 9 }) face ({ 10 }) retrieval ({ 11 }) system ({ 12 }) . ({ 13 }) 
# Sentence pair (2888) source length 33 target length 31 alignment score : 1.28954e-08
Existing studies on automatic face-track extraction follow a standard paradigm that consists of two basic steps , detecting faces in frames and grouping faces of the same character into face-tracks . 
NULL ({ }) The ({ }) existing ({ 1 }) studies ({ 2 }) on ({ 3 }) automatic ({ 4 }) face-track ({ 5 }) extraction ({ 6 }) follow ({ 7 }) a ({ 8 }) standard ({ 9 }) paradigm ({ 10 }) that ({ 11 }) consists ({ 12 }) of ({ 13 }) two ({ 14 }) basic ({ 15 }) steps ({ 16 }) , ({ 17 }) detecting ({ 18 }) faces ({ 19 }) in ({ 20 }) frames ({ 21 }) and ({ 22 }) grouping ({ 23 }) faces ({ 24 }) of ({ 25 }) the ({ 26 }) same ({ 27 }) character ({ 28 }) into ({ 29 }) face ({ }) tracks ({ 30 }) . ({ 31 }) 
# Sentence pair (2889) source length 21 target length 20 alignment score : 9.82707e-07
In the first step , Viola-Jones detector is usually employed to detect near frontal faces in frames of videos . 
NULL ({ }) In ({ 1 }) the ({ 2 }) first ({ 3 }) step ({ 4 }) , ({ 5 }) the ({ }) Viola-Jones ({ 6 }) detector ({ 7 }) is ({ 8 }) usually ({ 9 }) used ({ 10 }) to ({ 11 }) detect ({ 12 }) near ({ 13 }) frontal ({ 14 }) faces ({ 15 }) in ({ 16 }) frames ({ 17 }) of ({ 18 }) videos ({ 19 }) . ({ 20 }) 
# Sentence pair (2890) source length 25 target length 27 alignment score : 2.41487e-21
Then , in the second step , detected faces of the same character will be grouped by using either clustering approaches \CITE or tracking approaches \CITE . 
NULL ({ 3 }) , ({ 2 }) In ({ 1 }) the ({ 4 }) second ({ 5 }) step ({ 6 }) , ({ 7 }) the ({ }) detected ({ 8 }) faces ({ 9 }) of ({ 10 }) the ({ 11 }) same ({ 12 }) character ({ 13 }) are ({ 14 }) grouped ({ 15 16 }) by ({ 17 }) using ({ 18 }) either ({ 19 }) clustering ({ 20 21 }) \CITE ({ 22 }) or ({ 23 }) tracking ({ 24 }) approaches ({ 25 }) \CITE ({ 26 }) . ({ 27 }) 
# Sentence pair (2891) source length 7 target length 7 alignment score : 0.0977832
In \CITE , Ramanan et al . 
NULL ({ }) In ({ 1 }) \CITE ({ 2 }) , ({ 3 }) Ramanan ({ 4 }) et ({ 5 }) al ({ 6 }) . ({ 7 }) 
# Sentence pair (2892) source length 21 target length 21 alignment score : 1.5667e-05
builds a color histogram for the hair , face , and torso associated with each detected face in a frame . 
NULL ({ }) built ({ 1 }) a ({ 2 }) color ({ 3 }) histogram ({ 4 }) for ({ 5 }) the ({ 6 }) hair ({ 7 }) , ({ 8 }) face ({ 9 }) , ({ 10 }) and ({ 11 }) torso ({ 12 }) associated ({ 13 }) with ({ 14 }) each ({ 15 }) detected ({ 16 }) face ({ 17 }) in ({ 18 }) a ({ 19 }) frame ({ 20 }) . ({ 21 }) 
# Sentence pair (2893) source length 12 target length 12 alignment score : 1.96097e-05
A concatenated vector of the normalized color histograms represents the face . 
NULL ({ }) A ({ 1 }) concatenated ({ 2 }) vector ({ 3 }) of ({ 4 }) the ({ 5 }) normalized ({ 6 }) color ({ 7 }) histogram ({ 8 }) represented ({ 9 }) the ({ 10 }) face ({ 11 }) . ({ 12 }) 
# Sentence pair (2894) source length 16 target length 16 alignment score : 0.000841833
They then cluster all vectors to obtain groups of similar faces , using agglomerative clustering . 
NULL ({ }) They ({ 1 }) then ({ 2 }) clustered ({ 3 }) all ({ 4 }) vectors ({ 5 }) to ({ 6 }) obtain ({ 7 }) groups ({ 8 }) of ({ 9 }) similar ({ 10 }) faces ({ 11 }) , ({ 12 }) using ({ 13 }) agglomerative ({ 14 }) clustering ({ 15 }) . ({ 16 }) 
# Sentence pair (2895) source length 47 target length 45 alignment score : 5.77794e-18
Limitations of this approach includes the expensive computational cost for constructing and clustering high dimensional representation feature vectors; and , its dependence on determining a reasonable threshold for the clustering algorithm to ensure no group contains faces of multiple characters and groups are not over-fragmented. 
NULL ({ }) The ({ }) limitations ({ 1 }) of ({ 2 }) this ({ 3 }) approach ({ 4 }) include ({ 5 }) its ({ 6 }) high ({ 7 }) computational ({ 8 }) cost ({ 9 }) for ({ 10 }) constructing ({ 11 }) and ({ 12 }) clustering ({ 13 }) high-dimensional ({ 14 15 }) representation ({ 16 }) feature ({ 17 }) vectors ({ 18 }) and ({ 19 }) , ({ 20 }) its ({ 21 }) dependence ({ 22 }) on ({ 23 }) determining ({ 24 }) a ({ 25 }) reasonable ({ 26 }) threshold ({ 27 }) for ({ 28 }) the ({ 29 }) clustering ({ 30 }) algorithm ({ 31 }) to ({ 32 }) ensure ({ 33 }) that ({ }) no ({ 34 }) group ({ 35 }) contains ({ 36 }) faces ({ 37 }) of ({ 38 }) multiple ({ 39 }) characters ({ 40 }) and ({ 41 }) that ({ }) groups ({ 42 }) are ({ 43 }) not ({ 44 }) over-fragmented. ({ 45 }) 
# Sentence pair (2896) source length 9 target length 9 alignment score : 0.000601568
On the other hand , Everingham etl al . 
NULL ({ }) On ({ 1 }) the ({ 2 }) other ({ 3 }) hand ({ 4 }) , ({ 5 }) Everingham ({ 6 }) et ({ 7 }) al ({ 8 }) . ({ 9 }) 
# Sentence pair (2897) source length 6 target length 7 alignment score : 0.000976147
in \CITE and Sivic et al . 
NULL ({ 1 }) \CITE ({ 2 }) and ({ 3 }) Sivic ({ 4 }) et ({ 5 }) al ({ 6 }) . ({ 7 }) 
# Sentence pair (2898) source length 12 target length 12 alignment score : 0.0146738
In \CITE , an affine covariance tracker of \CITE is used . 
NULL ({ }) In ({ 1 }) \CITE ({ 2 }) , ({ 3 }) an ({ 4 }) affine ({ 5 }) covariance ({ 6 }) tracker ({ 7 }) of ({ 8 }) \CITE ({ 9 }) is ({ 10 }) used ({ 11 }) . ({ 12 }) 
# Sentence pair (2899) source length 25 target length 26 alignment score : 5.15486e-09
This tracker can develop tracks on deforming objects , where the between frame region deformation can be modelled by an affine geometric transformation plus perturbations . 
NULL ({ }) This ({ 1 }) tracker ({ 2 }) can ({ 3 }) develop ({ 4 }) tracks ({ 5 }) on ({ 6 }) deforming ({ 7 }) objects ({ 8 }) , ({ 9 }) where ({ 10 }) the ({ 11 }) between-frame ({ 12 13 }) region ({ 14 }) deformation ({ 15 }) can ({ 16 }) be ({ 17 }) modeled ({ 18 }) by ({ 19 }) an ({ 20 }) affine ({ 21 }) geometric ({ 22 }) transformation ({ 23 }) plus ({ 24 }) perturbations ({ 25 }) . ({ 26 }) 
# Sentence pair (2900) source length 35 target length 34 alignment score : 4.27451e-07
The outcome is that a face can be tracked ( by the collection of regions on it ) through significant pose variations and expression changes , allowing association of possibly distant face detections . 
NULL ({ }) The ({ 1 }) outcome ({ 2 }) is ({ 3 }) that ({ 4 }) a ({ 5 }) face ({ 6 }) can ({ 7 }) be ({ 8 }) tracked ({ 9 }) ( ({ 10 }) by ({ 11 }) the ({ 12 }) collection ({ 13 }) of ({ 14 }) regions ({ 15 }) on ({ 16 }) it ({ 17 }) ) ({ 18 }) through ({ 19 }) significant ({ 20 }) pose ({ 21 }) variations ({ 22 }) and ({ 23 }) expression ({ 24 }) changes ({ 25 }) , ({ 26 }) allowing ({ 27 }) the ({ }) association ({ 28 }) of ({ 29 }) possibly ({ 30 }) distant ({ 31 }) face ({ 32 }) detections ({ 33 }) . ({ 34 }) 
# Sentence pair (2901) source length 18 target length 17 alignment score : 2.96749e-06
The disadvantage of this tracker is the computational cost for locating and tracking affine covariance regions . 
NULL ({ }) The ({ 1 }) disadvantage ({ 2 }) of ({ 3 }) this ({ 4 }) tracker ({ 5 }) is ({ 6 }) its ({ 7 }) high ({ }) computational ({ 8 }) cost ({ 9 }) for ({ 10 }) locating ({ 11 }) and ({ 12 }) tracking ({ 13 }) affine ({ 14 }) covariance ({ 15 }) regions ({ 16 }) . ({ 17 }) 
# Sentence pair (2902) source length 13 target length 12 alignment score : 0.00130922
Another way of using tracker is introduced by Everingham et al . 
NULL ({ }) Another ({ 1 }) way ({ 2 }) of ({ 3 }) using ({ 4 }) a ({ }) tracker ({ 5 }) was ({ 6 }) introduced ({ 7 }) by ({ 8 }) Everingham ({ 9 }) et ({ 10 }) al ({ 11 }) . ({ 12 }) 
# Sentence pair (2903) source length 6 target length 4 alignment score : 0.00107413
in \CITE , . 
NULL ({ }) in ({ 1 }) \CITE ({ 2 }) , ({ 3 }) in ({ }) which ({ }) . ({ 4 }) 
# Sentence pair (2904) source length 29 target length 29 alignment score : 4.49399e-13
The authors employ Kanade-Lucas-Tomasi ( KLT ) tracker to create a set of point tracks starting at some frame in a shot and continuing until some later frame . 
NULL ({ }) they ({ 1 }) used ({ }) a ({ }) Kanade-Lucas-Tomasi ({ 2 3 4 }) ( ({ 5 }) KLT ({ 6 }) ) ({ 7 }) tracker ({ 8 }) to ({ 9 }) create ({ 10 }) a ({ 11 }) set ({ 12 }) of ({ 13 }) point ({ 14 }) tracks ({ 15 }) starting ({ 16 }) at ({ 17 }) some ({ 18 }) frame ({ 19 }) in ({ 20 }) a ({ 21 }) shot ({ 22 }) and ({ 23 }) continuing ({ 24 }) until ({ 25 }) some ({ 26 }) later ({ 27 }) frame ({ 28 }) . ({ 29 }) 
# Sentence pair (2905) source length 19 target length 18 alignment score : 1.00792e-05
Grouping faces in different frames of one character is based on enumerating track points shared between faces . 
NULL ({ }) Grouping ({ 1 }) faces ({ 2 }) in ({ 3 }) different ({ 4 }) frames ({ 5 }) for ({ 6 }) one ({ 7 }) character ({ 8 }) is ({ 9 }) based ({ 10 }) on ({ 11 }) enumerating ({ 12 }) the ({ }) track ({ 13 }) points ({ 14 }) shared ({ 15 }) between ({ 16 }) faces ({ 17 }) . ({ 18 }) 
# Sentence pair (2906) source length 26 target length 26 alignment score : 6.58694e-06
Although using tracking is an efficient solution , it may return poor tracking results since trackers are very sensitive to illumination changes and partial occlusions . 
NULL ({ }) Although ({ 1 }) using ({ 2 }) tracking ({ 3 }) is ({ 4 }) an ({ 5 }) efficient ({ 6 }) solution ({ 7 }) , ({ 8 }) it ({ 9 }) may ({ 10 }) return ({ 11 }) poor ({ 12 }) tracking ({ 13 }) results ({ 14 }) because ({ 15 }) trackers ({ 16 }) are ({ 17 }) very ({ 18 }) sensitive ({ 19 }) to ({ 20 }) illumination ({ 21 }) changes ({ 22 }) and ({ 23 }) partial ({ 24 }) occlusions ({ 25 }) . ({ 26 }) 
# Sentence pair (2907) source length 3 target length 3 alignment score : 0.426911
Face-track matching . 
NULL ({ }) Face-track ({ 1 }) matching ({ 2 }) . ({ 3 }) 
# Sentence pair (2908) source length 31 target length 30 alignment score : 6.40057e-14
There are two major categories of approaches target to employ multiple-exemplar of faces in face-tracks ( i.e. , sets of face images ) for robust face matching and recognition . 
NULL ({ 8 }) There ({ 1 }) are ({ 2 }) two ({ 3 }) major ({ 4 }) categories ({ 5 }) of ({ 6 }) approaches ({ 7 }) to ({ 9 }) using ({ }) multiple ({ 10 }) exemplars ({ 11 }) of ({ 12 }) faces ({ 13 }) in ({ 14 }) face ({ }) tracks ({ 15 }) ( ({ 16 }) i.e. ({ 17 }) , ({ 18 }) sets ({ 19 }) of ({ 20 }) face ({ 21 }) images ({ 22 }) ) ({ 23 }) for ({ 24 }) robust ({ 25 }) face ({ 26 }) matching ({ 27 }) and ({ 28 }) recognition ({ 29 }) . ({ 30 }) 
# Sentence pair (2909) source length 21 target length 19 alignment score : 1.11886e-07
Approaches in the first category \CITE make use of both face images and temporal order of their appearances . 
NULL ({ }) The ({ }) approaches ({ 1 }) in ({ 2 }) the ({ 3 }) first ({ 4 }) category ({ 5 }) \CITE ({ 6 }) make ({ 7 }) use ({ 8 }) of ({ 9 }) both ({ 10 }) face ({ 11 }) images ({ 12 }) and ({ 13 }) the ({ }) temporal ({ 14 }) order ({ 15 }) of ({ 16 }) their ({ 17 }) appearances ({ 18 }) . ({ 19 }) 
# Sentence pair (2910) source length 16 target length 15 alignment score : 4.19926e-06
Face dynamics within the video sequence are modeled and exploited to improve recognition accuracy . 
NULL ({ }) The ({ 1 }) face ({ }) dynamics ({ 2 }) within ({ 3 }) the ({ 4 }) video ({ 5 }) sequence ({ 6 }) are ({ 7 }) modeled ({ 8 }) and ({ 9 }) exploited ({ 10 }) to ({ 11 }) improve ({ 12 }) recognition ({ 13 }) accuracy ({ 14 }) . ({ 15 }) 
# Sentence pair (2911) source length 7 target length 7 alignment score : 0.062884
For instance , Li et al . 
NULL ({ }) For ({ 1 }) instance ({ 2 }) , ({ 3 }) Li ({ 4 }) et ({ 5 }) al ({ 6 }) . ({ 7 }) 
# Sentence pair (2912) source length 4 target length 4 alignment score : 0.312795
Edwards et al . 
NULL ({ }) Edwards ({ 1 }) et ({ 2 }) al ({ 3 }) . ({ 4 }) 
# Sentence pair (2913) source length 16 target length 16 alignment score : 9.23904e-07
They than use the trained statistical face model to incorporate identity evidence over a sequence . 
NULL ({ }) They ({ 1 }) then ({ 2 }) used ({ 3 }) the ({ 4 }) trained ({ 5 }) statistical ({ 6 }) face ({ 7 }) model ({ 8 }) to ({ 9 }) incorporate ({ 10 }) identity ({ 11 }) evidence ({ 12 }) over ({ 13 }) a ({ 14 }) sequence ({ 15 }) . ({ 16 }) 
# Sentence pair (2914) source length 21 target length 21 alignment score : 1.41072e-07
In \CITE , Liu and Chen use an adaptive Hidden Markov Model ( HMM ) for this face recognition problem . 
NULL ({ }) In ({ 1 }) \CITE ({ 2 }) , ({ 3 }) Liu ({ 4 }) and ({ 5 }) Chen ({ 6 }) used ({ 7 }) an ({ 8 }) adaptive ({ 9 }) hidden ({ 10 }) Markov ({ 11 }) model ({ 12 }) ( ({ 13 }) HMM ({ 14 }) ) ({ 15 }) for ({ 16 }) this ({ 17 }) face ({ 18 }) recognition ({ 19 }) problem ({ 20 }) . ({ 21 }) 
# Sentence pair (2915) source length 25 target length 26 alignment score : 1.37168e-08
In the training face , they create a HMM model for each character to learn the statistics and temporal dynamics using the eigen-face image sequence . 
NULL ({ }) In ({ 1 }) the ({ 2 }) training ({ 3 }) face ({ 4 }) , ({ 5 }) they ({ 6 }) created ({ 7 }) a ({ 8 }) HMM ({ 9 10 }) for ({ 11 }) each ({ 12 }) character ({ 13 }) to ({ 14 }) learn ({ 15 }) the ({ 16 }) statistics ({ 17 }) and ({ 18 }) temporal ({ 19 }) dynamics ({ 20 }) using ({ 21 }) the ({ 22 }) eigen-face ({ 23 }) image ({ 24 }) sequence ({ 25 }) . ({ 26 }) 
# Sentence pair (2916) source length 17 target length 16 alignment score : 0.000699276
The implicit constraint of these approaches is that dynamics of faces should be temporally consecutive . 
NULL ({ }) The ({ 1 }) implicit ({ 2 }) constraint ({ 3 }) of ({ 4 }) these ({ 5 }) approaches ({ 6 }) is ({ 7 }) that ({ 8 }) the ({ }) dynamics ({ 9 }) of ({ 10 }) faces ({ 11 }) should ({ 12 }) be ({ 13 }) temporally ({ 14 }) consecutive ({ 15 }) . ({ 16 }) 
# Sentence pair (2917) source length 9 target length 9 alignment score : 0.0288543
In general , this constraint is not always satisfied. 
NULL ({ }) In ({ 1 }) general ({ 2 }) , ({ 3 }) this ({ 4 }) constraint ({ 5 }) is ({ 6 }) not ({ 7 }) always ({ 8 }) satisfied. ({ 9 }) 
# Sentence pair (2918) source length 22 target length 20 alignment score : 1.46278e-07
Without relying on temporal coherence between consecutive images , approaches in the second category uses multiple face images only . 
NULL ({ }) Without ({ 1 }) relying ({ 2 }) on ({ 3 }) temporal ({ 4 }) coherence ({ 5 }) between ({ 6 }) consecutive ({ 7 }) images ({ 8 }) , ({ 9 }) the ({ }) approaches ({ 10 }) in ({ 11 }) the ({ 12 }) second ({ 13 }) category ({ 14 }) use ({ 15 }) multiple ({ 16 }) face ({ 17 }) images ({ 18 }) only ({ 19 }) and ({ }) . ({ 20 }) 
# Sentence pair (2919) source length 8 target length 10 alignment score : 3.32613e-07
They treat the problem as a set matching problem . 
NULL ({ }) treat ({ 1 2 }) the ({ 3 }) problem ({ 4 }) as ({ 5 }) a ({ 6 }) set-matching ({ 7 8 }) problem ({ 9 }) . ({ 10 }) 
# Sentence pair (2920) source length 22 target length 22 alignment score : 0.000192237
These approaches are differentiated based on the ways in which the sets are modeled and the similarity between sets is computed . 
NULL ({ }) These ({ 1 }) approaches ({ 2 }) are ({ 3 }) differentiated ({ 4 }) based ({ 5 }) on ({ 6 }) the ({ 7 }) ways ({ 8 }) in ({ 9 }) which ({ 10 }) the ({ 11 }) sets ({ 12 }) are ({ 13 }) modeled ({ 14 }) and ({ 15 }) the ({ 16 }) similarity ({ 17 }) between ({ 18 }) sets ({ 19 }) is ({ 20 }) computed ({ 21 }) . ({ 22 }) 
# Sentence pair (2921) source length 4 target length 4 alignment score : 0.300214
Shakhnarovich et al . 
NULL ({ }) Shakhnarovich ({ 1 }) et ({ 2 }) al ({ 3 }) . ({ 4 }) 
# Sentence pair (2922) source length 25 target length 25 alignment score : 1.5209e-07
However , to make the computation tractable , they made a assumption that faces are normally distributed , which may not be true \CITE . 
NULL ({ 11 }) However ({ 1 }) , ({ 2 }) to ({ 3 }) make ({ 4 }) the ({ 5 }) computation ({ 6 }) tractable ({ 7 }) , ({ 8 }) they ({ 9 }) made ({ 10 }) the ({ }) assumption ({ 12 }) that ({ 13 }) faces ({ 14 }) are ({ 15 }) normally ({ 16 }) distributed ({ 17 }) , ({ 18 }) which ({ 19 }) may ({ 20 }) not ({ 21 }) be ({ 22 }) true ({ 23 }) \CITE ({ 24 }) . ({ 25 }) 
# Sentence pair (2923) source length 25 target length 24 alignment score : 4.53551e-08
Cevikalp and Triggs \CITE claimed a face sequence was a set of points and discovered a convex geometric region expanded by these points . 
NULL ({ }) Cevikalp ({ 1 }) and ({ 2 }) Triggs ({ 3 }) \CITE ({ 4 }) claimed ({ 5 }) that ({ }) a ({ 6 }) face ({ 7 }) sequence ({ 8 }) is ({ 9 }) a ({ 10 }) set ({ 11 }) of ({ 12 }) points ({ 13 }) and ({ 14 }) discovered ({ 15 }) a ({ 16 }) convex ({ 17 }) geometric ({ 18 }) region ({ 19 }) expanded ({ 20 }) by ({ 21 }) these ({ 22 }) points ({ 23 }) . ({ 24 }) 
# Sentence pair (2924) source length 21 target length 21 alignment score : 0.000599195
The min-min approach \CITE considered a face sequence as a cluster of points and measured the distance between these clusters . 
NULL ({ }) The ({ 1 }) min-min ({ 2 }) approach ({ 3 }) \CITE ({ 4 }) considered ({ 5 }) a ({ 6 }) face ({ 7 }) sequence ({ 8 }) as ({ 9 }) a ({ 10 }) cluster ({ 11 }) of ({ 12 }) points ({ 13 }) and ({ 14 }) measured ({ 15 }) the ({ 16 }) distance ({ 17 }) between ({ 18 }) these ({ 19 }) clusters ({ 20 }) . ({ 21 }) 
# Sentence pair (2925) source length 14 target length 14 alignment score : 0.00536296
Subspace methods \CITE viewed a face sequence as points spread over a subspace . 
NULL ({ }) Subspace ({ 1 }) methods ({ 2 }) \CITE ({ 3 }) viewed ({ 4 }) a ({ 5 }) face ({ 6 }) sequence ({ 7 }) as ({ 8 }) points ({ 9 }) spread ({ 10 }) over ({ 11 }) a ({ 12 }) subspace ({ 13 }) . ({ 14 }) 
# Sentence pair (2926) source length 44 target length 44 alignment score : 3.45592e-08
Although these methods can be highly accurate , a lot of computation is needed to represent the distribution of the face sequence , such as computing the convex hulls in \CITE , the probability models in \CITE , and the eigenvectors in \CITE . 
NULL ({ }) Although ({ 1 }) these ({ 2 }) methods ({ 3 }) can ({ 4 }) be ({ 5 }) highly ({ 6 }) accurate ({ 7 }) , ({ 8 }) a ({ 9 }) lot ({ 10 }) of ({ 11 }) computation ({ 12 }) is ({ 13 }) needed ({ 14 }) to ({ 15 }) represent ({ 16 }) the ({ 17 }) distribution ({ 18 }) of ({ 19 }) the ({ 20 }) face ({ 21 }) sequence ({ 22 }) , ({ 23 }) such ({ 24 }) as ({ 25 }) computing ({ 26 }) the ({ 27 }) convex ({ 28 }) hulls ({ 29 }) in ({ 30 }) \CITE ({ 31 }) , ({ 32 }) the ({ 33 }) probability ({ 34 }) models ({ 35 }) in ({ 36 }) \CITE ({ 37 }) , ({ 38 }) and ({ 39 }) the ({ 40 }) eigenvectors ({ 41 }) in ({ 42 }) \CITE ({ 43 }) . ({ 44 }) 
# Sentence pair (2927) source length 13 target length 13 alignment score : 0.000253489
For this reason , they are not scalable for large-scale video datasets . 
NULL ({ }) For ({ 1 }) this ({ 2 }) reason ({ 3 }) , ({ 4 }) they ({ 5 }) are ({ 6 }) not ({ 7 }) scalable ({ 8 }) to ({ 9 }) large-scale ({ 10 }) video ({ 11 }) datasets ({ 12 }) . ({ 13 }) 
# Sentence pair (2928) source length 3 target length 3 alignment score : 0.0087881
Face Datasets . 
NULL ({ }) Face ({ 1 }) datasets ({ 2 }) . ({ 3 }) 
# Sentence pair (2929) source length 35 target length 34 alignment score : 3.21864e-14
To evaluate performance of face matching approaches , most of recent works on face retrieval in video uses two benchmark datasets Mobo ( Motion of Body ) \CITE and Honda / UCSD \CITE . 
NULL ({ }) In ({ 1 }) evaluating ({ 2 }) the ({ }) performance ({ 3 }) of ({ 4 }) face-matching ({ 5 6 }) approaches ({ 7 }) , ({ 8 }) most ({ 9 }) of ({ 10 }) the ({ }) recent ({ 11 }) works ({ 12 }) on ({ 13 }) face ({ 14 }) retrieval ({ 15 }) in ({ 16 }) video ({ 17 }) use ({ 18 }) two ({ 19 }) benchmark ({ 20 }) datasets: ({ 21 }) Mobo ({ 22 }) ( ({ 23 }) Motion ({ 24 }) of ({ 25 }) Body ({ 26 }) ) ({ 27 }) \CITE ({ 28 }) and ({ 29 }) Honda ({ 30 }) / ({ 31 }) UCSD ({ 32 }) \CITE ({ 33 }) . ({ 34 }) 
# Sentence pair (2930) source length 22 target length 21 alignment score : 3.58138e-14
Scales of these datasets are limited , they are varying from hundreds to thousands face images of tens individual characters . 
NULL ({ 9 }) The ({ }) scales ({ 1 }) of ({ 2 }) these ({ 3 }) datasets ({ 4 }) are ({ 5 }) limited ({ 6 }) , ({ 7 }) varying ({ 8 10 }) from ({ 11 }) hundreds ({ 12 }) to ({ 13 }) thousands ({ 14 }) of ({ }) face ({ 15 }) images ({ 16 }) of ({ 17 }) tens ({ 18 }) of ({ }) individual ({ 19 }) characters ({ 20 }) . ({ 21 }) 
# Sentence pair (2931) source length 13 target length 13 alignment score : 0.00135873
Particularly , Honda / UCSD consists of 75 videos involving 20 individual . 
NULL ({ }) Particularly ({ 1 }) , ({ 2 }) Honda ({ 3 }) / ({ 4 }) UCSD ({ 5 }) consists ({ 6 }) of ({ 7 }) 75 ({ 8 }) videos ({ 9 }) involving ({ 10 }) 20 ({ 11 }) individuals ({ 12 }) . ({ 13 }) 
# Sentence pair (2932) source length 7 target length 7 alignment score : 0.0628297
Each video contains approximately 300-500 frames . 
NULL ({ }) Each ({ 1 }) video ({ 2 }) contains ({ 3 }) approximately ({ 4 }) 300-500 ({ 5 }) frames ({ 6 }) . ({ 7 }) 
# Sentence pair (2933) source length 11 target length 11 alignment score : 0.0120354
Meanwhile , Mobo provides 96 image sets of 24 individuals . 
NULL ({ }) Meanwhile ({ 1 }) , ({ 2 }) Mobo ({ 3 }) provides ({ 4 }) 96 ({ 5 }) image ({ 6 }) sets ({ 7 }) of ({ 8 }) 24 ({ 9 }) individuals ({ 10 }) . ({ 11 }) 
# Sentence pair (2934) source length 12 target length 12 alignment score : 0.0188549
Hence , there are only 4 image sets for each individual . 
NULL ({ }) Hence ({ 1 }) , ({ 2 }) there ({ 3 }) are ({ 4 }) only ({ 5 }) 4 ({ 6 }) image ({ 7 }) sets ({ 8 }) for ({ 9 }) each ({ 10 }) individual ({ 11 }) . ({ 12 }) 
# Sentence pair (2935) source length 17 target length 16 alignment score : 1.13286e-08
One of the largest available face dataset recently is the Youtube Faces dataset \CITE , . 
NULL ({ }) One ({ 1 }) of ({ 2 }) the ({ 3 }) largest ({ 4 }) face ({ 6 }) datasets ({ 7 }) recently ({ 8 }) available ({ 5 }) is ({ 9 }) the ({ 10 }) YouTube ({ 11 }) Faces ({ 12 }) dataset ({ 13 }) \CITE ({ 14 }) , ({ 15 }) which ({ }) . ({ 16 }) 
# Sentence pair (2936) source length 8 target length 9 alignment score : 2.08673e-05
It provides 3,425 videos of 1,595 individual characters . 
NULL ({ }) provides ({ 1 2 }) 3,425 ({ 3 }) videos ({ 4 }) of ({ 5 }) 1,595 ({ 6 }) individual ({ 7 }) characters ({ 8 }) . ({ 9 }) 
# Sentence pair (2937) source length 10 target length 10 alignment score : 7.69335e-05
However , one character has only around 2.15 videos . 
NULL ({ }) However ({ 1 }) , ({ 2 }) each ({ 3 }) character ({ 4 }) has ({ 5 }) only ({ 6 }) around ({ 7 }) 2.15 ({ 8 }) videos ({ 9 }) . ({ 10 }) 
# Sentence pair (2938) source length 32 target length 33 alignment score : 1.19869e-10
Such a small number of samples for each character is not sufficient for stably evaluating a face matching or recognition approach , which is an important part of a face retrieval system . 
NULL ({ }) Such ({ 1 }) a ({ 2 }) small ({ 3 }) number ({ 4 }) of ({ 5 }) samples ({ 6 }) for ({ 7 }) each ({ 8 }) character ({ 9 }) is ({ 10 }) not ({ 11 }) sufficient ({ 12 }) to ({ 13 }) stably ({ 14 }) evaluate ({ 15 }) a ({ 16 }) face-matching ({ 17 18 }) or ({ 19 }) recognition ({ 20 }) approach ({ 21 }) , ({ 22 }) which ({ 23 }) is ({ 24 }) an ({ 25 }) important ({ 26 }) part ({ 27 }) of ({ 28 }) a ({ 29 }) face ({ 30 }) retrieval ({ 31 }) system ({ 32 }) . ({ 33 }) 
# Sentence pair (2939) source length 20 target length 20 alignment score : 0.0003873
In addition , there is no face dataset related to real-world news videos , which is our targeted domain . 
NULL ({ }) In ({ 1 }) addition ({ 2 }) , ({ 3 }) there ({ 4 }) is ({ 5 }) no ({ 6 }) face ({ 7 }) dataset ({ 8 }) related ({ 9 }) to ({ 10 }) real-world ({ 11 }) news ({ 12 }) videos ({ 13 }) , ({ 14 }) which ({ 15 }) is ({ 16 }) our ({ 17 }) targeted ({ 18 }) domain ({ 19 }) . ({ 20 }) 
# Sentence pair (2940) source length 16 target length 15 alignment score : 1.04246e-07
Because of all above mentioned reasons , we prepare new datasets for evaluating the approaches. 
NULL ({ }) In ({ }) view ({ 1 }) of ({ 2 }) all ({ 3 }) the ({ }) above-mentioned ({ 4 5 }) considerations ({ 6 }) , ({ 7 }) we ({ 8 }) prepare ({ 9 }) new ({ 10 }) datasets ({ 11 }) for ({ 12 }) evaluating ({ 13 }) the ({ 14 }) approaches. ({ 15 }) 
# Sentence pair (2941) source length 9 target length 9 alignment score : 0.0148423
Figure 2 illustrates the overview of our framework . 
NULL ({ }) Figure ({ 1 }) 2 ({ 2 }) illustrates ({ 3 }) the ({ 4 }) overview ({ 5 }) of ({ 6 }) our ({ 7 }) framework ({ 8 }) . ({ 9 }) 
# Sentence pair (2942) source length 26 target length 25 alignment score : 3.97875e-13
In the offline stage , face-tracks in all shots of videos are extracted using our face-track extraction approach ( described in Section 4 ) . 
NULL ({ 10 }) In ({ 1 }) the ({ 2 }) off-line ({ 3 }) stage ({ 4 }) , ({ 5 }) the ({ }) face ({ }) tracks ({ 6 }) in ({ 7 }) all ({ 8 }) video ({ 11 }) shots ({ 9 }) are ({ 12 }) extracted ({ 13 }) using ({ 14 }) our ({ 15 }) face-track ({ 16 }) extraction ({ 17 }) approach ({ 18 }) ( ({ 19 }) described ({ 20 }) in ({ 21 }) Section ({ 22 }) 4 ({ 23 }) ) ({ 24 }) . ({ 25 }) 
# Sentence pair (2943) source length 27 target length 26 alignment score : 3.16175e-07
One extracted face-track contains multiple face images of one individual character , varied under different viewpoints , illumination conditions , and expressions within a shot . 
NULL ({ }) Each ({ 1 }) extracted ({ 2 }) face ({ }) track ({ 3 }) contains ({ 4 }) multiple ({ 5 }) face ({ 6 }) images ({ 7 }) of ({ 8 }) one ({ 9 }) individual ({ 10 }) character ({ 11 }) , ({ 12 }) varied ({ 13 }) under ({ 14 }) different ({ 15 }) viewpoints ({ 16 }) , ({ 17 }) illumination ({ 18 }) conditions ({ 19 }) , ({ 20 }) and ({ 21 }) expressions ({ 22 }) within ({ 23 }) a ({ 24 }) shot ({ 25 }) . ({ 26 }) 
# Sentence pair (2944) source length 15 target length 14 alignment score : 4.15011e-05
A single face image in a face-track is represented by a feature vector . 
NULL ({ }) Each ({ 1 }) single ({ 2 }) face ({ 3 }) image ({ 4 }) in ({ 5 }) a ({ 6 }) face ({ }) track ({ 7 }) is ({ 8 }) represented ({ 9 }) by ({ 10 }) a ({ 11 }) feature ({ 12 }) vector ({ 13 }) . ({ 14 }) 
# Sentence pair (2945) source length 19 target length 19 alignment score : 0.000312529
The process consisting of face-track extraction and face image representation is performed once for the entire video dataset . 
NULL ({ }) The ({ 1 }) process ({ 2 }) consisting ({ 3 }) of ({ 4 }) face-track ({ 5 }) extraction ({ 6 }) and ({ 7 }) face ({ 8 }) image ({ 9 }) representation ({ 10 }) is ({ 11 }) performed ({ 12 }) once ({ 13 }) for ({ 14 }) the ({ 15 }) entire ({ 16 }) video ({ 17 }) dataset ({ 18 }) . ({ 19 }) 
# Sentence pair (2946) source length 22 target length 23 alignment score : 3.19329e-07
Our contribution here is to make the face-track extraction approach robust to sudden illumination changes , scattered appearance of characters , and occlusions. 
NULL ({ 5 }) Our ({ 1 }) contribution ({ 2 }) here ({ 3 }) is ({ 4 }) making ({ 6 }) the ({ 7 }) face-track ({ 8 }) extraction ({ 9 }) approach ({ 10 }) robust ({ 11 }) to ({ 12 }) sudden ({ 13 }) illumination ({ 14 }) changes ({ 15 }) , ({ 16 }) scattered ({ 17 }) appearances ({ 18 }) of ({ 19 }) characters ({ 20 }) , ({ 21 }) and ({ 22 }) occlusions. ({ 23 }) 
# Sentence pair (2947) source length 60 target length 56 alignment score : 1.36315e-12
Given a face-track as an input retrieval query , the online stage of our system starts by using our proposed face-track matching algorithm ( described in Section 5 ) to estimate the similarity between a query face-track and each face-track in the retrieved set containing all face-tracks extracted from the dataset in the offline stage . 
NULL ({ }) Given ({ 1 }) a ({ 2 }) face ({ }) track ({ 3 }) as ({ 4 }) an ({ 5 }) input ({ 6 }) retrieval ({ 7 }) query ({ 8 }) , ({ 9 }) the ({ 10 }) online ({ 11 }) stage ({ 12 }) of ({ 13 }) our ({ 14 }) system ({ 15 }) starts ({ 16 }) by ({ 17 }) using ({ 18 }) our ({ 19 }) proposed ({ 20 }) face-track ({ 21 }) matching ({ 22 }) algorithm ({ 23 }) ( ({ 24 }) described ({ 25 }) in ({ 26 }) Section ({ 27 }) 5 ({ 28 }) ) ({ 29 }) to ({ 30 }) estimate ({ 31 }) the ({ 32 }) similarity ({ 33 }) between ({ 34 }) a ({ 35 }) query ({ 36 }) face ({ }) track ({ 37 }) and ({ 38 }) each ({ 39 }) face ({ }) track ({ 40 }) in ({ 41 }) the ({ 42 }) retrieved ({ 43 }) set ({ 44 }) containing ({ 45 }) all ({ 46 }) face ({ }) tracks ({ 47 }) extracted ({ 48 }) from ({ 49 }) the ({ 50 }) dataset ({ 51 }) in ({ 52 }) the ({ 53 }) offline ({ 54 }) stage ({ 55 }) . ({ 56 }) 
# Sentence pair (2948) source length 19 target length 17 alignment score : 1.07455e-06
A ranked list of the evaluated face-tracks is returned as retrieval results of the online stage . 
NULL ({ }) A ({ 1 }) ranked ({ 2 }) list ({ 3 }) of ({ 4 }) the ({ 5 }) evaluated ({ 6 }) face ({ }) tracks ({ 7 }) is ({ 8 }) returned ({ 9 }) as ({ 10 }) the ({ }) retrieval ({ 11 }) result ({ 12 }) of ({ 13 }) the ({ 14 }) online ({ 15 }) stage ({ 16 }) . ({ 17 }) 
# Sentence pair (2949) source length 24 target length 23 alignment score : 4.26035e-07
Since the retrieved set is huge , our approach targets an extremely efficient face-track matching strategy while maintaining competitive performance with state-ofthe-art approaches. 
NULL ({ }) Because ({ 1 }) the ({ 2 }) retrieved ({ 3 }) set ({ 4 }) is ({ 5 }) huge ({ 6 }) , ({ 7 }) our ({ 8 }) approach ({ 9 }) targets ({ 10 }) an ({ 11 }) extremely ({ 12 }) efficient ({ 13 }) face-track ({ 14 }) matching ({ 15 }) strategy ({ 16 }) while ({ 17 }) maintaining ({ 18 }) a ({ }) competitive ({ 19 }) performance ({ 20 }) with ({ 21 }) state-of-the-art ({ 22 }) approaches. ({ 23 }) 
# Sentence pair (2950) source length 22 target length 22 alignment score : 8.1702e-05
Given a video shot with occurrences of multiple characters , face-track extraction is the process of extracting sets of face images . 
NULL ({ }) Given ({ 1 }) a ({ 2 }) video ({ 3 }) shot ({ 4 }) with ({ 5 }) occurrences ({ 6 }) of ({ 7 }) multiple ({ 8 }) characters ({ 9 }) , ({ 10 }) face-track ({ 11 }) extraction ({ 12 }) is ({ 13 }) the ({ 14 }) process ({ 15 }) of ({ 16 }) extracting ({ 17 }) sets ({ 18 }) of ({ 19 }) face ({ 20 }) images ({ 21 }) . ({ 22 }) 
# Sentence pair (2951) source length 19 target length 18 alignment score : 0.00013221
A set is supposed to contain face images of only one character who appears in the shot . 
NULL ({ }) A ({ 1 }) set ({ 2 }) is ({ 3 }) supposed ({ 4 }) to ({ 5 }) contain ({ 6 }) the ({ }) face ({ 7 }) images ({ 8 }) of ({ 9 }) only ({ 10 }) one ({ 11 }) character ({ 12 }) who ({ 13 }) appears ({ 14 }) in ({ 15 }) the ({ 16 }) shot ({ 17 }) . ({ 18 }) 
# Sentence pair (2952) source length 16 target length 15 alignment score : 0.000494069
Such sets of face images are called face-tracks ( sometimes called face sequences ) . 
NULL ({ }) Such ({ 1 }) sets ({ 2 }) of ({ 3 }) face ({ 4 }) images ({ 5 }) are ({ 6 }) called ({ 7 }) face ({ }) tracks ({ 8 }) ( ({ 9 }) sometimes ({ 10 }) called ({ 11 }) face ({ 12 }) sequences ({ 13 }) ) ({ 14 }) . ({ 15 }) 
# Sentence pair (2953) source length 25 target length 24 alignment score : 4.89978e-10
A common strategy of existing approaches for face-track extraction consists of detecting faces in frames and grouping detected faces of the same character . 
NULL ({ }) A ({ 1 }) common ({ 2 }) strategy ({ 3 }) in ({ 4 }) the ({ }) existing ({ 5 }) approaches ({ 6 }) to ({ 7 }) face-track ({ 8 }) extraction ({ 9 }) consists ({ 10 }) in ({ 11 }) detecting ({ 12 }) faces ({ 13 }) in ({ 14 }) frames ({ 15 }) and ({ 16 }) grouping ({ 17 }) detected ({ 18 }) faces ({ 19 }) of ({ 20 }) the ({ 21 }) same ({ 22 }) character ({ 23 }) . ({ 24 }) 
# Sentence pair (2954) source length 33 target length 33 alignment score : 1.08822e-06
While detecting faces is done by using a standard face detector ( e.g. , Viola-Jones face detector ) \CITE , grouping detected faces requires comprehensive techniques to identify faces of the same character. 
NULL ({ }) Whereas ({ 1 }) detecting ({ 2 }) faces ({ 3 }) is ({ 4 }) done ({ 5 }) by ({ 6 }) using ({ 7 }) a ({ 8 }) standard ({ 9 }) face ({ 10 }) detector ({ 11 }) ( ({ 12 }) e.g. ({ 13 }) , ({ 14 }) Viola-Jones ({ 15 }) face ({ 16 }) detector ({ 17 }) ) ({ 18 }) \CITE ({ 19 }) , ({ 20 }) grouping ({ 21 }) detected ({ 22 }) faces ({ 23 }) requires ({ 24 }) comprehensive ({ 25 }) techniques ({ 26 }) to ({ 27 }) identify ({ 28 }) faces ({ 29 }) of ({ 30 }) the ({ 31 }) same ({ 32 }) character. ({ 33 }) 
# Sentence pair (2955) source length 19 target length 19 alignment score : 3.1424e-05
In this section , we first briefly introduce an approach for face-track extraction proposed by Everingham et al . 
NULL ({ }) In ({ 1 }) this ({ 2 }) section ({ 3 }) , ({ 4 }) we ({ 5 }) first ({ 6 }) briefly ({ 7 }) introduce ({ 8 }) an ({ 9 }) approach ({ 10 }) to ({ 11 }) face-track ({ 12 }) extraction ({ 13 }) proposed ({ 14 }) by ({ 15 }) Everingham ({ 16 }) et ({ 17 }) al ({ 18 }) . ({ 19 }) 
# Sentence pair (2956) source length 17 target length 20 alignment score : 4.60033e-27
Its problems as it is applied to news video and our proposed solutions to overcome the problems is then presented. 
NULL ({ 5 14 }) We ({ }) then ({ 19 }) present ({ 4 }) the ({ 16 }) problems ({ 17 }) with ({ 18 }) this ({ }) approach ({ }) as ({ 3 }) applied ({ 6 }) to ({ 7 }) news ({ 8 }) video ({ 9 }) and ({ 10 }) our ({ 11 }) proposed ({ 12 }) solutions. ({ 1 2 13 15 20 }) 
# Sentence pair (2957) source length 23 target length 22 alignment score : 1.33628e-08
To group detected faces into face-tracks , connections between faces belonging to the same character in different frames should be established . 
NULL ({ }) To ({ 1 }) group ({ 2 }) detected ({ 3 }) faces ({ 4 }) into ({ 5 }) face ({ }) tracks ({ 6 }) , ({ 7 }) connections ({ 8 }) should ({ 19 }) be ({ 20 }) established ({ 21 }) between ({ 9 }) faces ({ 10 }) belonging ({ 11 }) to ({ 12 }) the ({ 13 }) same ({ 14 }) character ({ 15 }) in ({ 16 }) different ({ 17 }) frames ({ 18 }) . ({ 22 }) 
# Sentence pair (2958) source length 10 target length 10 alignment score : 0.0221385
Motion analysis can be used to investigate such connections . 
NULL ({ }) Motion ({ 1 }) analysis ({ 2 }) can ({ 3 }) be ({ 4 }) used ({ 5 }) to ({ 6 }) investigate ({ 7 }) such ({ 8 }) connections ({ 9 }) . ({ 10 }) 
# Sentence pair (2959) source length 30 target length 30 alignment score : 1.16181e-05
If two faces in different frames are defined that they are translated faces of each other according to a motion , they are likely faces of the same character . 
NULL ({ }) If ({ 1 }) two ({ 2 }) faces ({ 3 }) in ({ 4 }) different ({ 5 }) frames ({ 6 }) are ({ 7 }) defined ({ 8 }) that ({ 9 }) they ({ 10 }) are ({ 11 }) translated ({ 12 }) faces ({ 13 }) of ({ 14 }) each ({ 15 }) other ({ 16 }) according ({ 17 }) to ({ 18 }) a ({ 19 }) motion ({ 20 }) , ({ 21 }) they ({ 22 }) are ({ 23 }) likely ({ 24 }) faces ({ 25 }) of ({ 26 }) the ({ 27 }) same ({ 28 }) character ({ 29 }) . ({ 30 }) 
# Sentence pair (2960) source length 4 target length 4 alignment score : 0.317521
Everingham et al . 
NULL ({ }) Everingham ({ 1 }) et ({ 2 }) al ({ 3 }) . ({ 4 }) 
# Sentence pair (2961) source length 13 target length 11 alignment score : 3.53574e-08
in \CITE propose to use KLT tracker for this purpose . 
NULL ({ 4 }) in ({ 1 }) \CITE ({ 2 }) proposed ({ 3 }) the ({ }) use ({ 5 }) of ({ }) a ({ }) KLT ({ 6 }) tracker ({ 7 }) for ({ 8 }) this ({ 9 }) purpose ({ 10 }) . ({ 11 }) 
# Sentence pair (2962) source length 27 target length 27 alignment score : 6.18771e-05
Their algorithm starts by detecting interest points in the first frame of the shot and propagating them to the next frames based on local appearance matching . 
NULL ({ }) Their ({ 1 }) algorithm ({ 2 }) starts ({ 3 }) by ({ 4 }) detecting ({ 5 }) interest ({ 6 }) points ({ 7 }) in ({ 8 }) the ({ 9 }) first ({ 10 }) frame ({ 11 }) of ({ 12 }) the ({ 13 }) shot ({ 14 }) and ({ 15 }) propagating ({ 16 }) them ({ 17 }) to ({ 18 }) the ({ 19 }) next ({ 20 }) frames ({ 21 }) based ({ 22 }) on ({ 23 }) local ({ 24 }) appearance ({ 25 }) matching ({ 26 }) . ({ 27 }) 
# Sentence pair (2963) source length 19 target length 20 alignment score : 1.91801e-07
Points which can not be propagated from one frame to the next are eliminated and replaced with new points . 
NULL ({ }) Points ({ 1 }) that ({ 2 }) cannot ({ 3 4 }) be ({ 5 }) propagated ({ 6 }) from ({ 7 }) one ({ 8 }) frame ({ 9 }) to ({ 10 }) the ({ 11 }) next ({ 12 }) are ({ 13 }) eliminated ({ 14 }) and ({ 15 }) replaced ({ 16 }) with ({ 17 }) new ({ 18 }) points ({ 19 }) . ({ 20 }) 
# Sentence pair (2964) source length 44 target length 43 alignment score : 4.18407e-15
Given two faces in different frames , if the number of point tracks passing through both faces is larger than half of the total number of point tracks which are not in common to both faces , they are grouped into one face-track. 
NULL ({ 32 }) Given ({ 1 }) two ({ 2 }) faces ({ 3 }) in ({ 4 }) different ({ 5 }) frames ({ 6 }) , ({ 7 }) if ({ 8 }) the ({ 9 }) number ({ 10 }) of ({ 11 }) point ({ 12 }) tracks ({ 13 }) passing ({ 14 }) through ({ 15 }) both ({ 16 }) faces ({ 17 }) is ({ 18 }) larger ({ 19 }) than ({ 20 }) half ({ 21 }) of ({ 22 }) the ({ 23 }) total ({ 24 }) number ({ 25 }) of ({ 26 }) point ({ 27 }) tracks ({ 28 }) that ({ 29 }) are ({ 30 }) not ({ 31 }) common ({ 33 }) to ({ 34 }) both ({ 35 }) faces ({ 36 }) , ({ 37 }) the ({ }) faces ({ 38 }) are ({ 39 }) grouped ({ 40 }) into ({ 41 }) one ({ 42 }) face ({ }) track. ({ 43 }) 
# Sentence pair (2965) source length 8 target length 8 alignment score : 0.0712011
Although the approach by Everingham et al . 
NULL ({ }) Although ({ 1 }) the ({ 2 }) approach ({ 3 }) by ({ 4 }) Everingham ({ 5 }) et ({ 6 }) al ({ 7 }) . ({ 8 }) 
# Sentence pair (2966) source length 27 target length 25 alignment score : 1.32658e-12
has demonstrated its efficiency and robustness on drama videos \CITE , directly applying the approach to news videos results poor performances due to following issues. 
NULL ({ }) has ({ 1 }) shown ({ 2 }) its ({ 3 }) efficiency ({ 4 }) and ({ 5 }) robustness ({ 6 }) with ({ 7 }) drama ({ 8 }) videos ({ 9 }) \CITE ({ 10 }) , ({ 11 }) directly ({ 12 }) applying ({ 13 }) the ({ 14 }) approach ({ 15 }) to ({ 16 }) news ({ 17 }) videos ({ 18 }) results ({ 19 }) in ({ }) poor ({ 20 }) performance ({ 21 }) due ({ 22 }) to ({ 23 }) the ({ }) following ({ 24 }) issues. ({ 25 }) 
# Sentence pair (2967) source length 8 target length 8 alignment score : 0.0598904
Tracking errors due to sudden illumination change . 
NULL ({ }) Tracking ({ 1 }) errors ({ 2 }) due ({ 3 }) to ({ 4 }) sudden ({ 5 }) illumination ({ 6 }) change ({ 7 }) . ({ 8 }) 
# Sentence pair (2968) source length 36 target length 36 alignment score : 3.66558e-07
Since the KLT tracker uses intensity variance for computing the image motion to find the correspondence between points in different frames , it is unreliable when there is a sudden and significant change in illumination . 
NULL ({ }) Because ({ 1 }) the ({ 2 }) KLT ({ 3 }) tracker ({ 4 }) uses ({ 5 }) intensity ({ 6 }) variance ({ 7 }) for ({ 8 }) computing ({ 9 }) the ({ 10 }) image ({ 11 }) motion ({ 12 }) to ({ 13 }) find ({ 14 }) the ({ 15 }) correspondence ({ 16 }) between ({ 17 }) points ({ 18 }) in ({ 19 }) different ({ 20 }) frames ({ 21 }) , ({ 22 }) it ({ 23 }) is ({ 24 }) unreliable ({ 25 }) when ({ 26 }) there ({ 27 }) is ({ 28 }) a ({ 29 }) sudden ({ 30 }) and ({ 31 }) significant ({ 32 }) change ({ 33 }) in ({ 34 }) illumination ({ 35 }) . ({ 36 }) 
# Sentence pair (2969) source length 17 target length 16 alignment score : 0.000248303
As shown in Figure 3 ( top ) , points are distracted when flash occurs . 
NULL ({ }) As ({ 1 }) shown ({ 2 }) in ({ 3 }) Figure ({ 4 }) 3 ({ 5 }) ( ({ 6 }) top ({ 7 }) ) ({ 8 }) , ({ 9 }) points ({ 10 }) are ({ 11 }) distracted ({ 12 }) when ({ 13 }) a ({ }) flash ({ 14 }) occurs ({ 15 }) . ({ 16 }) 
# Sentence pair (2970) source length 10 target length 10 alignment score : 0.0281357
As a result , the points are badly tracked . 
NULL ({ }) As ({ 1 }) a ({ 2 }) result ({ 3 }) , ({ 4 }) the ({ 5 }) points ({ 6 }) are ({ 7 }) badly ({ 8 }) tracked ({ 9 }) . ({ 10 }) 
# Sentence pair (2971) source length 15 target length 14 alignment score : 0.000250223
The flash breaks all connections between faces in frames before and after its occurrence. 
NULL ({ }) The ({ 1 }) flash ({ 2 }) breaks ({ 3 }) all ({ 4 }) connections ({ 5 }) between ({ 6 }) faces ({ 7 }) in ({ 8 }) the ({ }) frames ({ 9 }) before ({ 10 }) and ({ 11 }) after ({ 12 }) its ({ 13 }) occurrence. ({ 14 }) 
# Sentence pair (2972) source length 5 target length 5 alignment score : 0.0818593
Unadaptive track point generation . 
NULL ({ }) Unadaptive ({ 1 }) track ({ 2 }) point ({ 3 }) generation ({ 4 }) . ({ 5 }) 
# Sentence pair (2973) source length 14 target length 13 alignment score : 4.49057e-06
In \CITE , track point generation is totally independent with face appearances . 
NULL ({ }) In ({ 1 }) \CITE ({ 2 }) , ({ 3 }) the ({ }) track ({ 4 }) point ({ 5 }) generation ({ 6 }) is ({ 7 }) totally ({ 8 }) independent ({ 9 }) from ({ 10 }) face ({ 11 }) appearances ({ 12 }) . ({ 13 }) 
# Sentence pair (2974) source length 24 target length 25 alignment score : 5.32493e-07
New points are generated at the first frame of the shot or at a frame in which some existing points can not be propagated . 
NULL ({ }) New ({ 1 }) points ({ 2 }) are ({ 3 }) generated ({ 4 }) at ({ 5 }) the ({ 6 }) first ({ 7 }) frame ({ 8 }) of ({ 9 }) the ({ 10 }) shot ({ 11 }) or ({ 12 }) at ({ 13 }) a ({ 14 }) frame ({ 15 }) in ({ 16 }) which ({ 17 }) some ({ 18 }) existing ({ 19 }) points ({ 20 }) cannot ({ 21 22 }) be ({ 23 }) propagated ({ 24 }) . ({ 25 }) 
# Sentence pair (2975) source length 22 target length 22 alignment score : 4.20334e-08
As a result , a face , which does not appear in the aforementioned frames , may not contain any point . 
NULL ({ 7 }) As ({ 1 }) a ({ 2 }) result ({ 3 }) , ({ 4 }) a ({ 5 }) face ({ 6 }) that ({ 8 }) , ({ }) does ({ 9 }) not ({ 10 }) appear ({ 11 }) in ({ 12 }) the ({ 13 }) aforementioned ({ 14 }) frames ({ 15 }) , ({ 16 }) may ({ 17 }) not ({ 18 }) contain ({ 19 }) any ({ 20 }) point ({ 21 }) . ({ 22 }) 
# Sentence pair (2976) source length 13 target length 13 alignment score : 0.00344695
Its connections with other faces in the shot cannot be established for grouping. 
NULL ({ }) Its ({ 1 }) connections ({ 2 }) with ({ 3 }) other ({ 4 }) faces ({ 5 }) in ({ 6 }) the ({ 7 }) shot ({ 8 }) cannot ({ 9 }) be ({ 10 }) established ({ 11 }) for ({ 12 }) grouping. ({ 13 }) 
# Sentence pair (2977) source length 6 target length 6 alignment score : 0.108888
Tracking errors due to occlusion . 
NULL ({ }) Tracking ({ 1 }) errors ({ 2 }) due ({ 3 }) to ({ 4 }) occlusion ({ 5 }) . ({ 6 }) 
# Sentence pair (2978) source length 40 target length 39 alignment score : 4.48218e-08
To successfully connect actual faces of the same character in different frames , track points generated for the first face should be tracked and retained inside the latter faces for a sufficient number of shared points between faces . 
NULL ({ }) To ({ 1 }) successfully ({ 2 }) connect ({ 3 }) actual ({ 4 }) faces ({ 5 }) of ({ 6 }) the ({ 7 }) same ({ 8 }) character ({ 9 }) in ({ 10 }) different ({ 11 }) frames ({ 12 }) , ({ 13 }) the ({ }) track ({ 14 }) points ({ 15 }) generated ({ 16 }) for ({ 17 }) the ({ 18 }) first ({ 19 }) face ({ 20 }) should ({ 21 }) be ({ 22 }) tracked ({ 23 }) and ({ 24 }) retained ({ 25 }) inside ({ 26 }) the ({ 27 }) latter ({ 28 }) faces ({ 29 }) for ({ 30 }) a ({ 31 }) sufficient ({ 32 }) number ({ 33 }) of ({ 34 }) shared ({ 35 }) points ({ 36 }) between ({ 37 }) faces ({ 38 }) . ({ 39 }) 
# Sentence pair (2979) source length 14 target length 13 alignment score : 0.00159278
However , when occlusion occurs , points are distracted by occluded regions . 
NULL ({ }) However ({ 1 }) , ({ 2 }) when ({ 3 }) occlusion ({ 4 }) occurs ({ 5 }) , ({ 6 }) the ({ }) points ({ 7 }) are ({ 8 }) distracted ({ 9 }) by ({ 10 }) occluded ({ 11 }) regions ({ 12 }) . ({ 13 }) 
# Sentence pair (2980) source length 10 target length 10 alignment score : 0.0162638
Thus , the number of shared points drops , . 
NULL ({ }) Thus ({ 1 }) , ({ 2 }) the ({ 3 }) number ({ 4 }) of ({ 5 }) shared ({ 6 }) points ({ 7 }) drops ({ 8 }) , ({ 9 }) . ({ 10 }) 
# Sentence pair (2981) source length 6 target length 7 alignment score : 9.34265e-06
It results in face connection failure . 
NULL ({ }) resulting ({ 1 2 }) in ({ 3 }) face ({ 4 }) connection ({ 5 }) failure ({ 6 }) . ({ 7 }) 
# Sentence pair (2982) source length 37 target length 37 alignment score : 1.57239e-06
As shown in Figure 3 ( bottom ) , when the woman moves the paper , which partially occludes her face in several frames , some points in her facial region are drifted with the paper . 
NULL ({ }) As ({ 1 }) shown ({ 2 }) in ({ 3 }) Figure ({ 4 }) 3 ({ 5 }) ( ({ 6 }) bottom ({ 7 }) ) ({ 8 }) , ({ 9 }) when ({ 10 }) the ({ 11 }) woman ({ 12 }) moves ({ 13 }) the ({ 14 }) paper ({ 15 }) , ({ 16 }) which ({ 17 }) partially ({ 18 }) occludes ({ 19 }) her ({ 20 }) face ({ 21 }) in ({ 22 }) several ({ 23 }) frames ({ 24 }) , ({ 25 }) some ({ 26 }) points ({ 27 }) in ({ 28 }) her ({ 29 }) facial ({ 30 }) region ({ 31 }) are ({ 32 }) drifted ({ 33 }) with ({ 34 }) the ({ 35 }) paper ({ 36 }) . ({ 37 }) 
# Sentence pair (2983) source length 14 target length 14 alignment score : 0.00257704
These points are not lost so they are not replaced by new points . 
NULL ({ }) These ({ 1 }) points ({ 2 }) are ({ 3 }) not ({ 4 }) lost ({ 5 }) so ({ 6 }) they ({ 7 }) are ({ 8 }) not ({ 9 }) replaced ({ 10 }) by ({ 11 }) new ({ 12 }) points ({ 13 }) . ({ 14 }) 
# Sentence pair (2984) source length 11 target length 11 alignment score : 2.11714e-07
But , they become meaningless to determine the connection between faces. 
NULL ({ }) However ({ 1 }) , ({ 2 }) they ({ 3 }) become ({ 4 }) meaningless ({ 5 }) in ({ 6 }) determining ({ 7 }) the ({ 8 }) connection ({ 9 }) between ({ 10 }) faces. ({ 11 }) 
# Sentence pair (2985) source length 33 target length 31 alignment score : 2.40775e-16
Based on above observed limitations of the approach in \CITE on news videos , we integrate techniques to bypass these liminations in our proposed approach for face-track extraction on news videos. 
NULL ({ }) Based ({ 1 }) on ({ 2 }) the ({ 3 }) observed ({ 4 }) limitations ({ 5 }) of ({ 6 }) the ({ 7 }) approach ({ 8 }) in ({ 9 }) \CITE ({ 10 }) when ({ 11 }) applied ({ }) to ({ }) news ({ 12 }) videos ({ 13 }) , ({ 14 }) we ({ 15 }) integrate ({ 16 }) techniques ({ 17 }) to ({ 18 }) bypass ({ 19 }) these ({ 20 }) restrictions ({ 21 }) in ({ 22 }) our ({ 23 }) proposed ({ 24 }) approach ({ 25 }) to ({ 26 }) face-track ({ 27 }) extraction ({ 28 }) in ({ 29 }) news ({ 30 }) videos. ({ 31 }) 
# Sentence pair (2986) source length 23 target length 24 alignment score : 1.54547e-11
Firstly , \CITE , our approach does not compare all possible pairs of faces in a shot for face grouping as in \CITE . 
NULL ({ 21 }) First ({ 1 }) , ({ 2 }) unlike ({ 3 }) in ({ 22 }) \CITE ({ 23 }) , ({ 4 }) our ({ 5 }) approach ({ 6 }) does ({ 7 }) not ({ 8 }) compare ({ 9 }) all ({ 10 }) possible ({ 11 }) pairs ({ 12 }) of ({ 13 }) faces ({ 14 }) in ({ 15 }) a ({ 16 }) shot ({ 17 }) for ({ 18 }) face ({ 19 }) grouping\CITE; ({ 20 }) . ({ 24 }) 
# Sentence pair (2987) source length 16 target length 16 alignment score : 4.31003e-06
Such pair-wise comparison rapidly becomes intractable as the number of faces in a shot increases . 
NULL ({ }) such ({ 1 }) pairwise ({ 2 }) comparison ({ 3 }) rapidly ({ 4 }) becomes ({ 5 }) intractable ({ 6 }) as ({ 7 }) the ({ 8 }) number ({ 9 }) of ({ 10 }) faces ({ 11 }) in ({ 12 }) a ({ 13 }) shot ({ 14 }) increases ({ 15 }) . ({ 16 }) 
# Sentence pair (2988) source length 17 target length 16 alignment score : 1.80276e-13
Instead of that , we group faces into face-track following temporal order of their appearances . 
NULL ({ 2 3 }) Instead ({ 1 }) , ({ 4 }) we ({ 5 }) group ({ 6 }) faces ({ 7 }) into ({ 8 }) face ({ }) tracks ({ 9 }) according ({ 10 }) to ({ }) the ({ }) temporal ({ 11 }) order ({ 12 }) of ({ 13 }) their ({ 14 }) appearances ({ 15 }) . ({ 16 }) 
# Sentence pair (2989) source length 22 target length 21 alignment score : 2.36287e-07
A detected face in the current frame is considered to group into existing face-tracks formed by previously detected faces only . 
NULL ({ }) A ({ 1 }) detected ({ 2 }) face ({ 3 }) in ({ 4 }) the ({ 5 }) current ({ 6 }) frame ({ 7 }) is ({ 8 }) considered ({ 9 }) for ({ 10 }) grouping ({ 11 }) into ({ 12 }) existing ({ 13 }) face ({ }) tracks ({ 14 }) formed ({ 15 }) by ({ 16 }) previously ({ 17 }) detected ({ 18 }) faces ({ 19 }) only ({ 20 }) . ({ 21 }) 
# Sentence pair (2990) source length 9 target length 9 alignment score : 0.0215797
By doing this , we avoid greedy pairwise comparison. 
NULL ({ }) By ({ 1 }) doing ({ 2 }) this ({ 3 }) , ({ 4 }) we ({ 5 }) avoid ({ 6 }) greedy ({ 7 }) pairwise ({ 8 }) comparison. ({ 9 }) 
# Sentence pair (2991) source length 27 target length 24 alignment score : 2.79134e-09
Secondly , as our first observation , a sudden illumination change in any frame make the KLT tracker failed to track points properly . 
NULL ({ }) Second ({ 1 }) , ({ 2 }) as ({ 3 }) described ({ }) in ({ }) our ({ 4 }) first ({ 5 }) observation ({ 6 }) , ({ 7 }) a ({ 8 }) sudden ({ 9 }) illumination ({ 10 }) change ({ 11 }) in ({ 12 }) any ({ 13 }) frame ({ 14 }) causes ({ 15 }) the ({ 16 }) KLT ({ 17 }) tracker ({ 18 }) to ({ }) fail ({ 19 }) to ({ 20 }) track ({ 21 }) points ({ 22 }) properly ({ 23 }) . ({ 24 }) 
# Sentence pair (2992) source length 28 target length 27 alignment score : 1.92248e-14
Because such illumination changes are very common and they mostly appear together with important character in a news , a solution to this problem is vital . 
NULL ({ }) Because ({ 1 }) such ({ 2 }) illumination ({ 3 }) changes ({ 4 }) are ({ 5 }) very ({ 6 }) common ({ 7 }) and ({ 8 }) mostly ({ 9 10 }) occur ({ 11 }) simultaneously ({ 12 }) with ({ 13 }) important ({ 14 }) characters ({ 15 }) in ({ 16 }) a ({ 17 }) news ({ 18 }) video ({ }) , ({ 19 }) finding ({ }) a ({ 20 }) solution ({ 21 }) to ({ 22 }) this ({ 23 }) problem ({ 24 }) is ({ 25 }) vital ({ 26 }) . ({ 27 }) 
# Sentence pair (2993) source length 20 target length 20 alignment score : 0.000377245
We learn that the occurences of such illumination changes are usually very short ( less than 3 frames ) . 
NULL ({ }) We ({ 1 }) learn ({ 2 }) that ({ 3 }) the ({ 4 }) occurrences ({ 5 }) of ({ 6 }) such ({ 7 }) illumination ({ 8 }) changes ({ 9 }) are ({ 10 }) usually ({ 11 }) very ({ 12 }) short ({ 13 }) ( ({ 14 }) less ({ 15 }) than ({ 16 }) 3 ({ 17 }) frames ({ 18 }) ) ({ 19 }) . ({ 20 }) 
# Sentence pair (2994) source length 28 target length 25 alignment score : 6.69532e-13
And , faces appeared in those frames are less informative for recognition since most of the facial identity characteristics are loss due to overlighting . 
NULL ({ }) and ({ 1 }) that ({ }) the ({ }) , ({ 2 }) faces ({ 3 }) that ({ }) appear ({ 4 }) in ({ 5 }) those ({ 6 }) frames ({ 7 }) are ({ 8 }) less ({ 9 }) informative ({ 10 }) for ({ 11 }) recognition ({ 12 }) because ({ 13 }) most ({ 14 }) of ({ 15 }) the ({ 16 }) facial ({ 17 }) identity ({ 18 }) characteristics ({ 19 }) are ({ 20 }) lost ({ 21 }) due ({ 22 }) to ({ 23 }) over-lighting ({ 24 }) . ({ 25 }) 
# Sentence pair (2995) source length 20 target length 16 alignment score : 2.14575e-15
, They can not enrich information of its corresponding face-track , but may add noise . 
NULL ({ }) Thus ({ }) , ({ 1 }) the ({ }) faces ({ 2 }) cannot ({ 3 4 }) enrich ({ 5 }) the ({ }) information ({ 6 }) on ({ 7 }) its ({ 8 }) corresponding ({ 9 }) face ({ }) track ({ 10 }) , ({ 11 }) but ({ 12 }) may ({ 13 }) only ({ }) add ({ 14 }) noise ({ 15 }) . ({ 16 }) 
# Sentence pair (2996) source length 18 target length 17 alignment score : 4.31071e-06
Therefore , our solution is to detect and skip all frames contain sudden illumination changes , . 
NULL ({ }) Therefore ({ 1 }) , ({ 2 }) our ({ 3 }) solution ({ 4 }) is ({ 5 }) to ({ 6 }) detect ({ 7 }) and ({ 8 }) skip ({ 9 }) all ({ 10 }) frames ({ 11 }) containing ({ 12 }) sudden ({ 13 }) illumination ({ 14 }) changes ({ 15 }) , ({ 16 }) which ({ }) . ({ 17 }) 
# Sentence pair (2997) source length 4 target length 6 alignment score : 5.98089e-10
We call such frames as flashframes. 
NULL ({ 5 }) we ({ 1 }) call ({ 2 }) flash ({ 3 }) frames. ({ 4 6 }) 
# Sentence pair (2998) source length 17 target length 15 alignment score : 1.11065e-07
To indetify flash-frames , we measures the brightness of frames in the video shot . 
NULL ({ }) To ({ 1 }) identify ({ 2 }) flash ({ 3 }) frames ({ }) , ({ 4 }) we ({ 5 }) measure ({ 6 }) the ({ 7 }) brightness ({ 8 }) of ({ 9 }) the ({ }) frames ({ 10 }) in ({ 11 }) the ({ 12 }) video ({ 13 }) shot ({ 14 }) . ({ 15 }) 
# Sentence pair (2999) source length 26 target length 28 alignment score : 2.71574e-23
If the brightness of a frame significantly increases compared with those of its neighbors , the frame is declared as a flash-frame and is skipped for processing . 
NULL ({ 11 12 24 }) If ({ 1 }) the ({ 2 }) brightness ({ 3 }) of ({ 4 }) a ({ 5 }) frame ({ 6 }) is ({ }) significantly ({ 7 }) increased ({ 8 }) compared ({ 9 }) with ({ 10 }) its ({ 13 }) neighbors ({ 14 }) , ({ 15 }) the ({ 16 }) frame ({ 17 }) is ({ 18 }) declared ({ 19 }) a ({ 21 }) flash ({ 22 }) frame ({ 20 }) and ({ 23 }) skipped ({ 25 }) in ({ 26 }) processing ({ 27 }) . ({ 28 }) 
# Sentence pair (3000) source length 49 target length 49 alignment score : 9.24698e-10
Particularly , given a frame \SYM with t indicates its frame index , we compute the average luminosity L of the frame \SYM and its consicutive frames \SYM , where i = \SYM; t +W+ 1 , and W is the potential length of a sudden illumination change . 
NULL ({ }) Particularly ({ 1 }) , ({ 2 }) given ({ 3 }) a ({ 4 }) frame ({ 5 }) \SYM ({ 6 }) with ({ 7 }) t ({ 8 }) indicating ({ 9 }) its ({ 10 }) frame ({ 11 }) index ({ 12 }) , ({ 13 }) we ({ 14 }) compute ({ 15 }) the ({ 16 }) average ({ 17 }) luminosity ({ 18 }) L ({ 19 }) of ({ 20 }) the ({ 21 }) frame ({ 22 }) \SYM ({ 23 }) and ({ 24 }) its ({ 25 }) consecutive ({ 26 }) frames ({ 27 }) \SYM ({ 28 }) , ({ 29 }) where ({ 30 }) i ({ 31 }) = ({ 32 }) \SYM; ({ 33 }) t ({ 34 }) +W+ ({ 35 }) 1 ({ 36 }) , ({ 37 }) and ({ 38 }) W ({ 39 }) is ({ 40 }) the ({ 41 }) potential ({ 42 }) length ({ 43 }) of ({ 44 }) a ({ 45 }) sudden ({ 46 }) illumination ({ 47 }) change ({ 48 }) . ({ 49 }) 
# Sentence pair (3001) source length 31 target length 31 alignment score : 9.72022e-06
Then , we compare the average luminosity L of each frame \SYM in the set S = \SYM with s = t; t +W to those of \SYM and \SYM . 
NULL ({ }) Then ({ 1 }) , ({ 2 }) we ({ 3 }) compare ({ 4 }) the ({ 5 }) average ({ 6 }) luminosity ({ 7 }) L ({ 8 }) of ({ 9 }) each ({ 10 }) frame ({ 11 }) \SYM ({ 12 }) in ({ 13 }) the ({ 14 }) set ({ 15 }) S ({ 16 }) = ({ 17 }) \SYM ({ 18 }) with ({ 19 }) s ({ 20 }) = ({ 21 }) t; ({ 22 }) t ({ 23 }) +W ({ 24 }) to ({ 25 }) those ({ 26 }) of ({ 27 }) \SYM ({ 28 }) and ({ 29 }) \SYM ({ 30 }) . ({ 31 }) 
# Sentence pair (3002) source length 32 target length 30 alignment score : 4.72253e-09
If L( \SYM ) > L( \SYM ) and L( \SYM ) > L( \SYM ) , \SYM is defined as flash-frames regarding a predefined brightness sensitive threshold \SYM . 
NULL ({ }) If ({ 1 }) L( ({ 2 }) \SYM ({ 3 }) ) ({ 4 }) > ({ 5 }) L( ({ 6 }) \SYM ({ 7 }) ) ({ 8 }) and ({ 9 }) L( ({ 10 }) \SYM ({ 11 }) ) ({ 12 }) > ({ 13 }) L( ({ 14 }) \SYM ({ 15 }) ) ({ 16 }) , ({ 17 }) \SYM ({ 18 }) is ({ 19 }) defined ({ 20 }) as ({ 21 }) flash ({ 22 }) frames ({ }) according ({ 23 }) to ({ }) a ({ 24 }) predefined ({ 25 }) brightness ({ 26 }) sensitive ({ 27 }) threshold ({ 28 }) \SYM ({ 29 }) . ({ 30 }) 
# Sentence pair (3003) source length 29 target length 28 alignment score : 8.30354e-07
In our experiments , we found that \SYM = 1:25 and W = {1; 2; 3} are optimal for detecting all flash-frames with a low false alarm rate. 
NULL ({ }) In ({ 1 }) our ({ 2 }) experiments ({ 3 }) , ({ 4 }) we ({ 5 }) found ({ 6 }) that ({ 7 }) \SYM ({ 8 }) = ({ 9 }) 1:25 ({ 10 }) and ({ 11 }) W ({ 12 }) = ({ 13 }) {1; ({ 14 }) 2; ({ 15 }) 3} ({ 16 }) are ({ 17 }) optimal ({ 18 }) for ({ 19 }) detecting ({ 20 }) all ({ 21 }) flash ({ 22 }) frames ({ }) with ({ 23 }) a ({ 24 }) low ({ 25 }) false ({ 26 }) alarm ({ 27 }) rate. ({ 28 }) 
# Sentence pair (3004) source length 19 target length 19 alignment score : 0.00126867
Given a video shot , our approach starts by finding the first frame in which faces are detected . 
NULL ({ }) Given ({ 1 }) a ({ 2 }) video ({ 3 }) shot ({ 4 }) , ({ 5 }) our ({ 6 }) approach ({ 7 }) starts ({ 8 }) by ({ 9 }) finding ({ 10 }) the ({ 11 }) first ({ 12 }) frame ({ 13 }) in ({ 14 }) which ({ 15 }) faces ({ 16 }) are ({ 17 }) detected ({ 18 }) . ({ 19 }) 
# Sentence pair (3005) source length 23 target length 25 alignment score : 7.7985e-09
All point tracking and face grouping processes are initialized from this frame , not at the first frame of the shot as in \CITE . 
NULL ({ }) All ({ 1 }) point-tracking ({ 2 3 }) and ({ 4 }) face-grouping ({ 5 6 }) processes ({ 7 }) are ({ 8 }) initialized ({ 9 }) from ({ 10 }) this ({ 11 }) frame ({ 12 }) , ({ 13 }) not ({ 14 }) at ({ 15 }) the ({ 16 }) first ({ 17 }) frame ({ 18 }) of ({ 19 }) the ({ 20 }) shot ({ 21 }) as ({ 22 }) in ({ 23 }) \CITE ({ 24 }) . ({ 25 }) 
# Sentence pair (3006) source length 19 target length 21 alignment score : 2.9913e-16
This helps us to save computational cost as well as to avoid tracking errors caused by transition effects between shots . 
NULL ({ 8 10 11 }) This ({ 1 }) helps ({ 2 }) us ({ 3 }) to ({ 4 }) save ({ 5 }) on ({ }) computational ({ 6 }) cost ({ 7 }) and ({ 9 }) avoid ({ 12 }) tracking ({ 13 }) errors ({ 14 }) caused ({ 15 }) by ({ 16 }) transition ({ 17 }) effects ({ 18 }) between ({ 19 }) shots ({ 20 }) . ({ 21 }) 
# Sentence pair (3007) source length 14 target length 14 alignment score : 0.00229287
Initial track points will be generated for all detected faces in the frame . 
NULL ({ }) Initial ({ 1 }) track ({ 2 }) points ({ 3 }) will ({ 4 }) be ({ 5 }) generated ({ 6 }) for ({ 7 }) all ({ 8 }) detected ({ 9 }) faces ({ 10 }) in ({ 11 }) the ({ 12 }) frame ({ 13 }) . ({ 14 }) 
# Sentence pair (3008) source length 14 target length 13 alignment score : 0.00109393
Each face now becomes the first face of a corresponding newly formed face-track. 
NULL ({ }) Each ({ 1 }) face ({ 2 }) now ({ 3 }) becomes ({ 4 }) the ({ 5 }) first ({ 6 }) face ({ 7 }) of ({ 8 }) a ({ 9 }) corresponding ({ 10 }) newly ({ 11 }) formed ({ 12 }) face ({ }) track. ({ 13 }) 
# Sentence pair (3009) source length 18 target length 18 alignment score : 3.44431e-10
After the initialization , we sequentially process each frame afterwards , knowing all flash-frames will be skipped . 
NULL ({ }) After ({ 1 }) the ({ 2 }) initialization ({ 3 }) , ({ 4 }) we ({ 5 }) sequentially ({ 6 10 }) process ({ 7 }) each ({ 8 }) frame ({ 9 }) , ({ 11 }) knowing ({ 12 }) all ({ 13 }) flash ({ 14 }) frames ({ }) will ({ 15 }) be ({ 16 }) skipped ({ 17 }) . ({ 18 }) 
# Sentence pair (3010) source length 22 target length 21 alignment score : 9.00704e-07
At a given frame , points from the previous frame are tracked by the KLT tracker to update their locations . 
NULL ({ }) In ({ 1 }) a ({ 2 }) given ({ 3 }) frame ({ 4 }) , ({ 5 }) the ({ }) points ({ 6 }) from ({ 7 }) the ({ 8 }) previous ({ 9 }) frame ({ 10 }) are ({ 11 }) tracked ({ 12 }) by ({ 13 }) the ({ 14 }) KLT ({ 15 }) tracker ({ 16 }) to ({ 17 }) update ({ 18 }) their ({ 19 }) locations ({ 20 }) . ({ 21 }) 
# Sentence pair (3011) source length 32 target length 28 alignment score : 3.86606e-15
If there are faces detected , each face is checked against all existing facetracks formed in the previous frames to find out which facetrack it belongs to . 
NULL ({ 25 }) If ({ 1 }) there ({ 2 }) are ({ 3 }) faces ({ 4 }) detected ({ 5 }) , ({ 6 }) each ({ 7 }) face ({ 8 }) is ({ 9 }) checked ({ 10 }) against ({ 11 }) all ({ 12 }) the ({ }) existing ({ 13 }) face ({ }) tracks ({ 14 }) formed ({ 15 }) in ({ 16 }) the ({ 17 }) previous ({ 18 }) frames ({ 19 }) to ({ 20 }) find ({ 21 }) out ({ 22 }) to ({ 27 }) which ({ 23 }) face ({ }) track ({ 24 }) the ({ }) face ({ }) belongs ({ 26 }) . ({ 28 }) 
# Sentence pair (3012) source length 31 target length 26 alignment score : 9.66641e-16
Checking between a face and a facetrack is based on enumerating points shared by both the face and the last appeared face of the face-track . 
NULL ({ 23 24 }) The ({ }) checking ({ 1 }) between ({ 2 }) a ({ 3 }) face ({ 4 }) and ({ 5 }) a ({ 6 }) face ({ }) track ({ 7 }) is ({ 8 }) based ({ 9 }) on ({ 10 }) enumerating ({ 11 }) the ({ }) points ({ 12 }) shared ({ 13 }) by ({ 14 }) both ({ 15 }) the ({ 16 }) face ({ 17 }) and ({ 18 }) the ({ 19 }) last ({ 20 }) face ({ }) that ({ }) appeared ({ 21 }) on ({ }) the ({ }) face ({ 22 }) track ({ 25 }) . ({ 26 }) 
# Sentence pair (3013) source length 31 target length 31 alignment score : 4.7784e-12
If the enumerated number is larger than half of the total number of points which are not in common to both faces , the faces is grouped into the face-track . 
NULL ({ 18 }) If ({ 1 }) the ({ 2 }) enumerated ({ 3 }) number ({ 4 }) is ({ 5 }) larger ({ 6 }) than ({ 7 }) half ({ 8 }) of ({ 9 }) the ({ 10 }) total ({ 11 }) number ({ 12 }) of ({ 13 }) points ({ 14 }) that ({ 15 }) are ({ 16 }) not ({ 17 }) common ({ 19 }) to ({ 20 }) both ({ 21 }) faces ({ 22 }) , ({ 23 }) the ({ 24 }) face ({ 25 }) is ({ 26 }) grouped ({ 27 }) into ({ 28 }) the ({ 29 }) face ({ }) track ({ 30 }) . ({ 31 }) 
# Sentence pair (3014) source length 11 target length 9 alignment score : 0.000422276
Our grouping criterion here is similar to \CITE . 
NULL ({ }) Our ({ 1 }) grouping ({ 2 }) criterion ({ 3 }) here ({ 4 }) is ({ 5 }) similar ({ 6 }) to ({ 7 }) that ({ }) in ({ }) \CITE ({ 8 }) . ({ 9 }) 
# Sentence pair (3015) source length 22 target length 21 alignment score : 1.11335e-12
A face which can not be grouped into any face-track is treated as an initial face of a new face-track . 
NULL ({ }) A ({ 1 }) face ({ 2 }) that ({ 3 }) cannot ({ 4 5 }) be ({ 6 }) grouped ({ 7 }) into ({ 8 }) any ({ 9 }) face ({ }) track ({ 10 }) is ({ 11 }) treated ({ 12 }) as ({ 13 }) the ({ 14 }) initial ({ 15 }) face ({ 16 }) of ({ 17 }) a ({ 18 }) new ({ 19 }) face ({ }) track ({ 20 }) . ({ 21 }) 
# Sentence pair (3016) source length 20 target length 20 alignment score : 5.22144e-09
We then generate new track points inside such faces for tracking an grouping its corresponding faces in latter frames . 
NULL ({ }) We ({ 1 }) then ({ 2 }) generate ({ 3 }) new ({ 4 }) track ({ 5 }) points ({ 6 }) within ({ 7 }) such ({ 8 }) faces ({ 9 }) for ({ 10 }) tracking ({ 11 }) and ({ 12 }) grouping ({ 13 }) its ({ 14 }) corresponding ({ 15 }) faces ({ 16 }) in ({ 17 }) latter ({ 18 }) frames ({ 19 }) . ({ 20 }) 
# Sentence pair (3017) source length 14 target length 14 alignment score : 0.00121734
In our approach , track points are generated in conjunction with face appearances . 
NULL ({ }) In ({ 1 }) our ({ 2 }) approach ({ 3 }) , ({ 4 }) track ({ 5 }) points ({ 6 }) are ({ 7 }) generated ({ 8 }) in ({ 9 }) conjunction ({ 10 }) with ({ 11 }) face ({ 12 }) appearances ({ 13 }) . ({ 14 }) 
# Sentence pair (3018) source length 17 target length 17 alignment score : 4.32864e-09
We can ensure that there are always track points for all faces appear in the shot . 
NULL ({ 7 }) We ({ 1 }) can ({ 2 }) ensure ({ 3 }) that ({ 4 }) there ({ 5 }) are ({ 6 }) track ({ 8 }) points ({ 9 }) for ({ 10 }) all ({ 11 }) faces ({ 12 }) that ({ }) appear ({ 13 }) in ({ 14 }) the ({ 15 }) shot ({ 16 }) . ({ 17 }) 
# Sentence pair (3019) source length 11 target length 11 alignment score : 0.000339708
Consequently , our approach overcomes the second observed limitation of \CITE. 
NULL ({ }) Consequently ({ 1 }) , ({ 2 }) our ({ 3 }) approach ({ 4 }) overcomes ({ 5 }) the ({ 6 }) second ({ 7 }) observed ({ 8 }) limitation ({ 9 }) in ({ 10 }) \CITE. ({ 11 }) 
# Sentence pair (3020) source length 26 target length 25 alignment score : 2.66339e-08
In other case , when a face in the current frame is grouped to an existing face-track , we prepare points for further tracking . 
NULL ({ }) In ({ 1 }) other ({ 2 }) cases ({ 3 }) , ({ 4 }) when ({ 5 }) a ({ 6 }) face ({ 7 }) in ({ 8 }) the ({ 9 }) current ({ 10 }) frame ({ 11 }) is ({ 12 }) grouped ({ 13 }) into ({ 14 }) an ({ 15 }) existing ({ 16 }) face ({ }) track ({ 17 }) , ({ 18 }) we ({ 19 }) prepare ({ 20 }) points ({ 21 }) for ({ 22 }) further ({ 23 }) tracking ({ 24 }) . ({ 25 }) 
# Sentence pair (3021) source length 28 target length 25 alignment score : 2.59247e-14
We remove all points which are inside the last appeared face of the face-track but not inside the current face , and vice versa . 
NULL ({ 12 13 }) We ({ 1 }) remove ({ 2 }) all ({ 3 }) points ({ 4 }) that ({ 5 }) are ({ 6 }) inside ({ 7 }) the ({ 8 }) last ({ 9 }) face ({ }) that ({ }) appeared ({ 10 }) on ({ }) the ({ }) face ({ 11 }) track ({ 14 }) but ({ 15 }) are ({ }) not ({ 16 }) inside ({ 17 }) the ({ 18 }) current ({ 19 }) face ({ 20 }) , ({ 21 }) and ({ 22 }) vice ({ 23 }) versa ({ 24 }) . ({ 25 }) 
# Sentence pair (3022) source length 20 target length 20 alignment score : 0.000146354
Since such points are likely tracked incorrectly , eliminating them prevent us from transferring tracking errors to latter frames . 
NULL ({ }) Because ({ 1 }) such ({ 2 }) points ({ 3 }) are ({ 4 }) likely ({ 5 }) tracked ({ 6 }) incorrectly ({ 7 }) , ({ 8 }) eliminating ({ 9 }) them ({ 10 }) prevents ({ 11 }) us ({ 12 }) from ({ 13 }) transferring ({ 14 }) tracking ({ 15 }) errors ({ 16 }) to ({ 17 }) latter ({ 18 }) frames ({ 19 }) . ({ 20 }) 
# Sentence pair (3023) source length 10 target length 10 alignment score : 0.00150407
Points which are shared by both faces are kept . 
NULL ({ }) Points ({ 1 }) that ({ 2 }) are ({ 3 }) shared ({ 4 }) by ({ 5 }) both ({ 6 }) faces ({ 7 }) are ({ 8 }) kept ({ 9 }) . ({ 10 }) 
# Sentence pair (3024) source length 17 target length 17 alignment score : 0.000572334
Besides , we generate additional points to replace the removed ones and to provide updated points . 
NULL ({ }) Besides ({ 1 }) , ({ 2 }) we ({ 3 }) generate ({ 4 }) additional ({ 5 }) points ({ 6 }) to ({ 7 }) replace ({ 8 }) the ({ 9 }) removed ({ 10 }) ones ({ 11 }) and ({ 12 }) to ({ 13 }) provide ({ 14 }) updated ({ 15 }) points ({ 16 }) . ({ 17 }) 
# Sentence pair (3025) source length 19 target length 19 alignment score : 6.30846e-07
By doing that , our tracking results through a long sequence of frames become more accurate and reliable . 
NULL ({ }) By ({ 1 }) doing ({ 2 }) so ({ 3 }) , ({ 4 }) our ({ 5 }) tracking ({ 6 }) results ({ 7 }) over ({ 8 }) a ({ 9 }) long ({ 10 }) sequence ({ 11 }) of ({ 12 }) frames ({ 13 }) become ({ 14 }) more ({ 15 }) accurate ({ 16 }) and ({ 17 }) reliable ({ 18 }) . ({ 19 }) 
# Sentence pair (3026) source length 15 target length 15 alignment score : 0.0044538
As a result , we can partly bypass the third observed limitation of \CITE . 
NULL ({ }) As ({ 1 }) a ({ 2 }) result ({ 3 }) , ({ 4 }) we ({ 5 }) can ({ 6 }) partly ({ 7 }) bypass ({ 8 }) the ({ 9 }) third ({ 10 }) observed ({ 11 }) limitation ({ 12 }) of ({ 13 }) \CITE ({ 14 }) . ({ 15 }) 
# Sentence pair (3027) source length 28 target length 28 alignment score : 3.48496e-16
When a face is partly and slowly occluded , our approach can discard incorrectly tracked points as well as reproduce points for the face after being occluded . 
NULL ({ }) When ({ 1 }) a ({ 2 }) face ({ 3 }) is ({ 4 }) partly ({ 5 }) and ({ 6 }) slowly ({ 7 }) occluded ({ 8 }) , ({ 9 }) our ({ 10 }) approach ({ 11 }) can ({ 12 }) discard ({ 13 }) incorrectly ({ 14 }) tracked ({ 15 }) points ({ 16 }) and ({ }) reproduce ({ 17 18 19 20 26 }) points ({ 21 }) for ({ 22 }) the ({ 23 }) face ({ 24 }) after ({ 25 }) it ({ }) has ({ }) been ({ }) occluded ({ 27 }) . ({ 28 }) 
# Sentence pair (3028) source length 13 target length 13 alignment score : 7.59387e-05
Thus , the connection between faces before and after the occlusion are retained. 
NULL ({ }) Thus ({ 1 }) , ({ 2 }) the ({ 3 }) connection ({ 4 }) between ({ 5 }) faces ({ 6 }) before ({ 7 }) and ({ 8 }) after ({ 9 }) the ({ 10 }) occlusion ({ 11 }) is ({ 12 }) retained. ({ 13 }) 
# Sentence pair (3029) source length 16 target length 15 alignment score : 9.52551e-09
Our approach continuously process the next frame until reaching the end of the shot . 
NULL ({ }) Our ({ 1 }) approach ({ 2 }) continuously ({ 3 }) processes ({ 4 }) the ({ 5 }) next ({ 6 }) frame ({ 7 }) until ({ 8 }) the ({ 10 }) end ({ 11 }) of ({ 12 }) the ({ 13 }) shot ({ 14 }) is ({ }) reached ({ 9 }) . ({ 15 }) 
# Sentence pair (3030) source length 9 target length 10 alignment score : 4.28011e-05
The pseudo-code is presented in the Algorithm 1 as follows. 
NULL ({ 6 }) The ({ 1 }) pseudo-code ({ 2 }) is ({ 3 }) presented ({ 4 }) in ({ 5 }) Algorithm ({ 7 }) 1 ({ 8 }) as ({ 9 }) follows. ({ 10 }) 
# Sentence pair (3031) source length 17 target length 18 alignment score : 4.9368e-15
There are several approaches have been proposed for matching face-tracks ( as presented in Section 2 ) . 
NULL ({ 2 8 }) Several ({ 1 }) approaches ({ 4 }) to ({ 3 }) matching ({ 9 }) face ({ }) tracks ({ 10 }) have ({ 5 }) been ({ 6 }) proposed ({ 7 }) ( ({ 11 }) as ({ 12 }) presented ({ 13 }) in ({ 14 }) Section ({ 15 }) 2 ({ 16 }) ) ({ 17 }) . ({ 18 }) 
# Sentence pair (3032) source length 25 target length 24 alignment score : 8.5018e-19
, Although these existing approaches achive high accuracy on benchmark datasets , their expensive computational costs limits their practical applications on large-scale datasets . 
NULL ({ 1 }) However ({ 4 }) , ({ }) although ({ 2 }) these ({ 3 }) approaches ({ 5 }) have ({ }) shown ({ 6 }) high ({ 7 }) accuracy ({ 8 }) in ({ 9 }) benchmark ({ 10 }) datasets ({ 11 }) , ({ 12 }) their ({ 13 }) high ({ 14 }) computational ({ 15 }) costs ({ 16 }) limit ({ 17 }) their ({ 18 }) practical ({ 19 }) applications ({ 20 }) in ({ 21 }) large-scale ({ 22 }) datasets ({ 23 }) . ({ 24 }) 
# Sentence pair (3033) source length 19 target length 17 alignment score : 2.67891e-11
This motivate us to target an matching approach which is balanced between accuracy and computational cost . 
NULL ({ }) This ({ 1 }) motivates ({ 2 }) us ({ 3 }) to ({ 4 }) target ({ 5 }) a ({ 6 }) matching ({ 7 }) approach ({ 8 }) that ({ 9 }) provides ({ 10 }) a ({ }) good ({ }) balance ({ 11 }) between ({ 12 }) accuracy ({ 13 }) and ({ 14 }) computational ({ 15 }) cost ({ 16 }) . ({ 17 }) 
# Sentence pair (3034) source length 14 target length 14 alignment score : 4.67639e-11
The approach should be extremely efficient while archiving competitive performance compare to state-of-the-art approachesf. 
NULL ({ }) The ({ 1 }) approach ({ 2 }) should ({ 3 }) be ({ 4 }) extremely ({ 5 }) efficient ({ 6 }) while ({ 7 }) achieving ({ 8 }) a ({ }) competitive ({ 9 }) performance ({ 10 }) with ({ 12 }) state-of-the-art ({ 13 }) approaches. ({ 11 14 }) 
# Sentence pair (3035) source length 24 target length 24 alignment score : 7.1598e-21
In order to maintain a competitive accuracy , we still employ plenteous information from multiple faces of a facetrack to enrich its representation . 
NULL ({ 3 5 }) To ({ 1 }) maintain ({ 2 4 }) competitive ({ 6 }) accuracy ({ 7 }) , ({ 8 }) we ({ 9 }) still ({ 10 }) use ({ 11 }) the ({ }) plenteous ({ 12 }) information ({ 13 }) from ({ 14 }) the ({ }) multiple ({ 15 }) faces ({ 16 }) of ({ 17 }) a ({ 18 }) face ({ }) track ({ 19 }) to ({ 20 }) enrich ({ 21 22 }) the ({ }) representation ({ 23 }) . ({ 24 }) 
# Sentence pair (3036) source length 21 target length 18 alignment score : 1.87623e-09
However , instead of using all faces in a face-track , we propose to subsample the faces . 
NULL ({ 16 }) However ({ 1 }) , ({ 2 }) instead ({ 3 }) of ({ 4 }) using ({ 5 }) all ({ 6 }) the ({ }) faces ({ 7 }) in ({ 8 }) a ({ 9 }) face ({ }) track ({ 10 }) , ({ 11 }) we ({ 12 }) propose ({ 13 }) taking ({ 14 }) a ({ }) subsample ({ 15 }) of ({ }) faces ({ 17 }) . ({ 18 }) 
# Sentence pair (3037) source length 22 target length 23 alignment score : 2.16913e-18
By doing that , the require computational cost can be reduced while a sufficient amount of information is kept for improving accuracy . 
NULL ({ 13 18 }) In ({ 1 }) doing ({ 2 }) so ({ 3 }) , ({ 4 }) the ({ 5 }) required ({ 6 }) computational ({ 7 }) cost ({ 8 }) can ({ 9 }) be ({ 10 }) reduced ({ 11 }) while ({ 12 }) keeping ({ 14 }) the ({ }) amount ({ 15 }) of ({ 16 }) information ({ 17 }) sufficient ({ 19 }) to ({ 20 }) improve ({ 21 }) accuracy ({ 22 }) . ({ 23 }) 
# Sentence pair (3038) source length 5 target length 6 alignment score : 0.000146746
We called our approach as k-Faces. 
NULL ({ }) We ({ 1 }) call ({ 2 }) our ({ 3 }) approach ({ 4 }) k-Faces. ({ 5 6 }) 
# Sentence pair (3039) source length 40 target length 35 alignment score : 1.66244e-15
Given a specific value of k , which indicates the expected size of the sub-sampled set of a face-track , the approach starts by dividing each face-track into k parts following its temporal order . 
NULL ({ }) Given ({ 1 }) a ({ 2 }) specific ({ 3 }) value ({ 4 }) of ({ 5 }) k ({ 6 }) , ({ 7 }) which ({ 8 }) indicates ({ 9 }) the ({ 10 }) expected ({ 11 }) size ({ 12 }) of ({ 13 }) the ({ 14 }) subsampled ({ 15 }) set ({ 16 }) of ({ 17 }) a ({ 18 }) face ({ }) track ({ 19 }) , ({ 20 }) the ({ 21 }) approach ({ 22 }) starts ({ 23 }) by ({ 24 }) dividing ({ 25 }) each ({ 26 }) face ({ }) track ({ 27 }) into ({ 28 }) k ({ 29 }) parts ({ 30 }) according ({ 31 }) to ({ 32 }) the ({ }) temporal ({ 33 }) order ({ 34 }) of ({ }) appearances ({ }) . ({ 35 }) 
# Sentence pair (3040) source length 16 target length 17 alignment score : 5.91066e-07
For each part , one face is selected to represent for all faces within the part . 
NULL ({ 11 }) For ({ 1 }) each ({ 2 }) part ({ 3 }) , ({ 4 }) one ({ 5 }) face ({ 6 }) is ({ 7 }) selected ({ 8 }) to ({ 9 }) represent ({ 10 }) all ({ 12 }) faces ({ 13 }) within ({ 14 }) the ({ 15 }) part ({ 16 }) . ({ 17 }) 
# Sentence pair (3041) source length 11 target length 11 alignment score : 0.0105734
The mean face of k selected faces is then computed . 
NULL ({ }) The ({ 1 }) mean ({ 2 }) face ({ 3 }) of ({ 4 }) k ({ 5 }) selected ({ 6 }) faces ({ 7 }) is ({ 8 }) then ({ 9 }) computed ({ 10 }) . ({ 11 }) 
# Sentence pair (3042) source length 14 target length 13 alignment score : 0.00123714
The similarity between two face-tracks is now the distance between their mean faces. 
NULL ({ }) The ({ 1 }) similarity ({ 2 }) between ({ 3 }) two ({ 4 }) face ({ }) tracks ({ 5 }) is ({ 6 }) now ({ 7 }) the ({ 8 }) distance ({ 9 }) between ({ 10 }) their ({ 11 }) mean ({ 12 }) faces. ({ 13 }) 
# Sentence pair (3043) source length 42 target length 43 alignment score : 4.01941e-19
Let denote mA = {\SYM; \SYM; : :; \SYM} and mB = {\SYM ; \SYM; : :; \SYM} are two mean faces of two face-track A and B , respectively , with N imposes the number of dimension of the feature space . 
NULL ({ 19 }) Let ({ 1 }) mA ({ 2 3 }) = ({ 4 }) {\SYM; ({ 5 }) \SYM; ({ 6 }) : ({ 7 }) :; ({ 8 }) \SYM} ({ 9 }) and ({ 10 }) mB ({ 11 }) = ({ 12 }) {\SYM ({ 13 }) ; ({ 14 }) \SYM; ({ 15 }) : ({ 16 }) :; ({ 17 }) \SYM} ({ 18 }) denote ({ 20 }) the ({ }) mean ({ 21 }) faces ({ 22 }) of ({ 23 }) face ({ 24 }) tracks ({ 25 }) A ({ 26 }) and ({ 27 }) B ({ 28 }) , ({ 29 }) respectively ({ 30 }) , ({ 31 }) with ({ 32 }) N ({ 33 }) representing ({ 34 }) the ({ 35 }) number ({ 36 }) of ({ 37 }) dimensions ({ 38 }) of ({ 39 }) the ({ 40 }) feature ({ 41 }) space ({ 42 }) . ({ 43 }) 
# Sentence pair (3044) source length 14 target length 14 alignment score : 0.000250348
We employ following standard distance types to compute the distance between mA and mB. 
NULL ({ }) We ({ 1 }) use ({ 2 }) following ({ 3 }) standard ({ 4 }) distance ({ 5 }) types ({ 6 }) to ({ 7 }) compute ({ 8 }) the ({ 9 }) distance ({ 10 }) between ({ 11 }) mA ({ 12 }) and ({ 13 }) mB. ({ 14 }) 
# Sentence pair (3045) source length 10 target length 12 alignment score : 4.27085e-20
An illustration of our k-Faces , is shown in Figure 4 . 
NULL ({ 9 }) Figure ({ 1 10 }) 4 ({ 11 }) illustrates ({ 2 3 }) our ({ 4 }) k-Faces ({ 5 }) , ({ 6 }) with ({ 7 }) the ({ }) following ({ 8 }) . ({ 12 }) 
# Sentence pair (3046) source length 2 target length 7 alignment score : 1.51203e-11
Its pseudo-code is presented as follows . 
NULL ({ 3 }) pseudo-code: ({ 1 2 4 5 6 }) . ({ 7 }) 
# Sentence pair (3047) source length 26 target length 28 alignment score : 1.13929e-21
Clearly , the higher value of k is selected , the more faces in each face-track are selected to compute the representative face of the face track . 
NULL ({ 8 17 24 25 }) Clearly ({ 1 }) , ({ 2 }) the ({ 3 }) higher ({ 4 }) the ({ }) value ({ 5 }) of ({ 6 }) k ({ 7 }) selected ({ 9 }) , ({ 10 }) the ({ 11 }) more ({ 12 }) faces ({ 13 }) in ({ 14 }) each ({ 15 }) face ({ 26 }) track ({ 16 }) selected ({ 18 }) to ({ 19 }) compute ({ 20 }) the ({ 21 }) representative ({ 22 }) face ({ 23 }) and ({ 27 }) the ({ }) . ({ 28 }) 
# Sentence pair (3048) source length 12 target length 11 alignment score : 1.90744e-08
And , better approximations , may result in higher accuracies . 
NULL ({ }) , ({ 2 }) better ({ 3 }) the ({ }) approximations ({ 1 4 }) , ({ 5 }) which ({ }) may ({ 6 }) result ({ 7 }) in ({ 8 }) higher ({ 9 }) accuracies ({ 10 }) . ({ 11 }) 
# Sentence pair (3049) source length 9 target length 9 alignment score : 0.030885
However , the computational cost can overly increases . 
NULL ({ }) However ({ 1 }) , ({ 2 }) the ({ 3 }) computational ({ 4 }) cost ({ 5 }) can ({ 6 }) overly ({ 7 }) increases ({ 8 }) . ({ 9 }) 
# Sentence pair (3050) source length 37 target length 35 alignment score : 4.76516e-19
By using k as a predefined parameter , k-Faces provides flexibility for users in balancing their expected accuracy and the cost which they can afford ( or time they can wait for the result ). 
NULL ({ 22 }) By ({ 1 }) using ({ 2 }) k ({ 3 }) as ({ 4 }) a ({ 5 }) predefined ({ 6 }) parameter ({ 7 }) , ({ 8 }) k-Faces ({ 9 }) provides ({ 10 }) users ({ 11 }) with ({ 12 }) flexibility ({ 13 }) in ({ 14 }) balancing ({ 15 }) the ({ }) accuracy ({ 18 }) they ({ }) expect ({ 17 }) and ({ 19 }) the ({ 20 }) cost ({ 21 }) they ({ 23 }) can ({ 24 }) afford ({ 25 }) ( ({ 26 }) or ({ 27 }) the ({ }) time ({ 28 }) they ({ 29 }) can ({ 30 }) spend ({ 16 }) waiting ({ 31 }) for ({ 32 }) the ({ 33 }) result ({ 34 }) ). ({ 35 }) 
# Sentence pair (3051) source length 34 target length 33 alignment score : 1.67855e-14
Besides that , since k-Faces averages multiple faces for a representative face of a face-track , the effects of noisy or outliers faces on estimating the similarity of face-tracks will be substantially reduced. 
NULL ({ 2 }) Besides ({ 1 }) , ({ 3 }) because ({ 4 }) k-Faces ({ 5 }) averages ({ 6 }) multiple ({ 7 }) faces ({ 8 }) for ({ 9 }) the ({ 10 }) representative ({ 11 }) face ({ 12 }) of ({ 13 }) a ({ 14 }) face ({ }) track ({ 15 }) , ({ 16 }) the ({ 17 }) effects ({ 18 }) of ({ 19 }) noisy ({ 20 }) or ({ 21 }) outlier ({ 22 }) faces ({ 23 }) on ({ 24 }) estimating ({ 25 }) the ({ 26 }) similarity ({ 27 }) of ({ 28 }) face ({ }) tracks ({ 29 }) will ({ 30 }) be ({ 31 }) substantially ({ 32 }) reduced. ({ 33 }) 
# Sentence pair (3052) source length 14 target length 14 alignment score : 0.00527533
In this section , we present our experiments to evaluate the proposed approaches . 
NULL ({ }) In ({ 1 }) this ({ 2 }) section ({ 3 }) , ({ 4 }) we ({ 5 }) present ({ 6 }) our ({ 7 }) experiments ({ 8 }) to ({ 9 }) evaluate ({ 10 }) the ({ 11 }) proposed ({ 12 }) approaches ({ 13 }) . ({ 14 }) 
# Sentence pair (3053) source length 8 target length 8 alignment score : 0.0660235
The experiments are divided into two parts . 
NULL ({ }) The ({ 1 }) experiments ({ 2 }) are ({ 3 }) divided ({ 4 }) into ({ 5 }) two ({ 6 }) parts; ({ 7 }) . ({ 8 }) 
# Sentence pair (3054) source length 19 target length 18 alignment score : 9.76882e-20
In the first part , we evaluate the performance of the proposed approach for face-track extraction , . 
NULL ({ }) the ({ 2 }) first ({ 3 }) , ({ 5 }) evaluates ({ 1 4 6 7 }) the ({ 8 }) performance ({ 9 }) of ({ 10 }) the ({ 11 }) proposed ({ 12 }) approach ({ 13 }) in ({ 14 }) face-track ({ 15 }) extraction ({ 16 }) , ({ 17 }) and ({ }) the ({ }) second ({ }) in ({ }) . ({ 18 }) 
# Sentence pair (3055) source length 2 target length 14 alignment score : 1.31268e-24
Evaluation of the proposed approach for face-track matching is given in the second part. 
NULL ({ 3 9 11 12 }) face-track ({ 7 }) matching. ({ 1 2 4 5 6 8 10 13 14 }) 
# Sentence pair (3056) source length 29 target length 29 alignment score : 8.07866e-07
We tested our proposed approach for face-track extraction on 8 video sequences from different video broadcasting stations , including NHK News 7 , ABC News , and CNN News. 
NULL ({ }) We ({ 1 }) tested ({ 2 }) our ({ 3 }) proposed ({ 4 }) approach ({ 5 }) to ({ 6 }) face-track ({ 7 }) extraction ({ 8 }) on ({ 9 }) 8 ({ 10 }) video ({ 11 }) sequences ({ 12 }) from ({ 13 }) different ({ 14 }) video ({ 15 }) broadcasting ({ 16 }) stations ({ 17 }) , ({ 18 }) including ({ 19 }) NHK ({ 20 }) News ({ 21 }) 7 ({ 22 }) , ({ 23 }) ABC ({ 24 }) News ({ 25 }) , ({ 26 }) and ({ 27 }) CNN ({ 28 }) News. ({ 29 }) 
# Sentence pair (3057) source length 8 target length 8 alignment score : 0.0468418
All shot boundaries are provided in advance . 
NULL ({ }) All ({ 1 }) shot ({ 2 }) boundaries ({ 3 }) are ({ 4 }) provided ({ 5 }) in ({ 6 }) advance ({ 7 }) . ({ 8 }) 
# Sentence pair (3058) source length 24 target length 23 alignment score : 4.99767e-14
A face detector based on Viola-Jones approach \CITE was used for detecting near frontal faces in every frame of these video sequences . 
NULL ({ }) A ({ 1 }) face ({ 2 }) detector ({ 3 }) based ({ 4 }) on ({ 5 }) the ({ }) Viola-Jones ({ 6 }) approach ({ 7 }) \CITE ({ 8 }) is ({ 9 }) used ({ 10 }) to ({ 11 }) detect ({ 12 }) near ({ 13 }) frontal ({ 14 }) faces ({ 15 }) in ({ 16 }) every ({ 17 }) frame ({ 18 }) of ({ 19 }) the ({ 20 }) video ({ 21 }) sequences ({ 22 }) . ({ 23 }) 
# Sentence pair (3059) source length 22 target length 22 alignment score : 0.000229278
A conservative threshold is used to reduce the number of false positives ( i.e. , a non-face classified as a face ). 
NULL ({ }) A ({ 1 }) conservative ({ 2 }) threshold ({ 3 }) is ({ 4 }) used ({ 5 }) to ({ 6 }) reduce ({ 7 }) the ({ 8 }) number ({ 9 }) of ({ 10 }) false ({ 11 }) positives ({ 12 }) ( ({ 13 }) i.e. ({ 14 }) , ({ 15 }) a ({ 16 }) non-face ({ 17 }) classified ({ 18 }) as ({ 19 }) a ({ 20 }) face ({ 21 }) ). ({ 22 }) 
# Sentence pair (3060) source length 12 target length 10 alignment score : 0.000477293
Ground-truth information on face-tracks in videos is manually prepared . 
NULL ({ }) Ground-truth ({ 1 }) information ({ 2 }) on ({ 3 }) the ({ }) face ({ }) tracks ({ 4 }) in ({ 5 }) videos ({ 6 }) is ({ 7 }) manually ({ 8 }) prepared ({ 9 }) . ({ 10 }) 
# Sentence pair (3061) source length 32 target length 30 alignment score : 3.32659e-12
A face-track of one character appearing in a video shot is annotated by indexes of the frames which the first face and the last face of that character occur . 
NULL ({ }) Each ({ 1 }) face ({ }) track ({ 2 }) of ({ 3 }) a ({ 4 }) character ({ 5 }) appearing ({ 6 }) in ({ 7 }) a ({ 8 }) video ({ 9 }) shot ({ 10 }) is ({ 11 }) annotated ({ 12 }) by ({ 13 }) indexes ({ 14 }) of ({ 15 }) the ({ 16 }) frames ({ 17 }) in ({ }) which ({ 18 }) the ({ 19 }) first ({ 20 }) face ({ 21 }) and ({ 22 }) the ({ 23 }) last ({ 24 }) face ({ 25 }) of ({ 26 }) that ({ 27 }) character ({ 28 }) occur ({ 29 }) . ({ 30 }) 
# Sentence pair (3062) source length 29 target length 26 alignment score : 9.34242e-10
An approach is called exactly extracting a face-track if it provides precise starting and ending frame indexes of the face-track , compared to ground-truth annotation . 
NULL ({ }) An ({ 1 }) approach ({ 2 }) is ({ 3 }) considered ({ 4 }) as ({ }) exactly ({ 5 }) extracting ({ 6 }) a ({ 7 }) face ({ }) track ({ 8 }) if ({ 9 }) it ({ 10 }) provides ({ 11 }) precise ({ 12 }) starting ({ 13 }) and ({ 14 }) ending ({ 15 }) frame ({ 16 }) indexes ({ 17 }) of ({ 18 }) the ({ 19 }) face ({ }) track ({ 20 }) , ({ 21 }) compared ({ 22 }) to ({ 23 }) ground-truth ({ 24 }) annotation ({ 25 }) . ({ 26 }) 
# Sentence pair (3063) source length 35 target length 31 alignment score : 8.19219e-13
Note that if a character moves out of the frame then moves in again , annotators will divide the appearance of that character into two independent face-tracks in our ground-truth . 
NULL ({ }) Note ({ 1 }) that ({ 2 }) if ({ 3 }) a ({ 4 }) character ({ 5 }) moves ({ 6 }) out ({ 7 }) of ({ 8 }) the ({ 9 }) frame ({ 10 }) and ({ }) then ({ 11 }) moves ({ 12 }) back ({ 13 }) into ({ }) it ({ }) again ({ 14 }) , ({ 15 }) annotators ({ 16 }) will ({ 17 }) divide ({ 18 }) the ({ 19 }) appearance ({ 20 }) of ({ 21 }) that ({ 22 }) character ({ 23 }) into ({ 24 }) two ({ 25 }) independent ({ 26 }) face ({ }) tracks ({ 27 }) in ({ 28 }) ground-truth ({ 29 }) annotation ({ 30 }) . ({ 31 }) 
# Sentence pair (3064) source length 14 target length 16 alignment score : 9.32803e-22
The number of frames , faces , and face tracks are shown in Table 1 . 
NULL ({ 11 13 }) Table ({ 1 12 14 }) 1 ({ 15 }) shows ({ }) the ({ }) number ({ 2 }) of ({ 3 }) frames ({ 4 }) , ({ 5 }) faces ({ 6 }) , ({ 7 }) and ({ 8 }) face ({ 9 }) tracks ({ 10 }) . ({ 16 }) 
# Sentence pair (3065) source length 17 target length 17 alignment score : 1.05201e-05
In this experiment , we directly compare our approach with one proposed by Everingham et al . 
NULL ({ }) In ({ 1 }) this ({ 2 }) experiment ({ 3 }) , ({ 4 }) we ({ 5 }) directly ({ 6 }) compare ({ 7 }) our ({ 8 }) approach ({ 9 }) with ({ 10 }) that ({ 11 }) proposed ({ 12 }) by ({ 13 }) Everingham ({ 14 }) et ({ 15 }) al ({ 16 }) . ({ 17 }) 
# Sentence pair (3066) source length 2 target length 2 alignment score : 0.446651
in \CITE. 
NULL ({ }) in ({ 1 }) \CITE. ({ 2 }) 
# Sentence pair (3067) source length 25 target length 24 alignment score : 2.06761e-06
As shown in Table 2 , by detecting flash-frames , our approach successfully overcomes the problem of face-track fragmentation due to illumination changes . 
NULL ({ }) As ({ 1 }) shown ({ 2 }) in ({ 3 }) Table ({ 4 }) 2 ({ 5 }) , ({ 6 }) by ({ 7 }) detecting ({ 8 }) flash ({ 9 }) frames ({ }) , ({ 10 }) our ({ 11 }) approach ({ 12 }) successfully ({ 13 }) overcomes ({ 14 }) the ({ 15 }) problem ({ 16 }) of ({ 17 }) face-track ({ 18 }) fragmentation ({ 19 }) due ({ 20 }) to ({ 21 }) illumination ({ 22 }) changes ({ 23 }) . ({ 24 }) 
# Sentence pair (3068) source length 9 target length 9 alignment score : 0.0472431
Meanwhile , the approach by Everingham et al . 
NULL ({ }) Meanwhile ({ 1 }) , ({ 2 }) the ({ 3 }) approach ({ 4 }) by ({ 5 }) Everingham ({ 6 }) et ({ 7 }) al ({ 8 }) . ({ 9 }) 
# Sentence pair (3069) source length 7 target length 7 alignment score : 0.000125519
is almost failed to do that . 
NULL ({ }) almost ({ 1 }) completely ({ 2 }) fails ({ 3 }) to ({ 4 }) do ({ 5 }) that ({ 6 }) . ({ 7 }) 
# Sentence pair (3070) source length 19 target length 20 alignment score : 3.86433e-13
In addition , the results also shows that our approach is superior to the approach by Everingham et al . 
NULL ({ 14 }) In ({ 1 }) addition ({ 2 }) , ({ 3 }) the ({ 4 }) results ({ 5 }) also ({ 6 }) show ({ 7 }) that ({ 8 }) our ({ 9 }) approach ({ 10 }) is ({ 11 }) superior ({ 12 }) to ({ 13 }) that ({ 15 }) of ({ 16 }) Everingham ({ 17 }) et ({ 18 }) al ({ 19 }) . ({ 20 }) 
# Sentence pair (3071) source length 20 target length 18 alignment score : 1.33618e-06
in handling problem caused by partial occlusion and appearance of character in the middle of a shot . 
NULL ({ }) in ({ 1 }) handling ({ 2 }) problems ({ 3 }) caused ({ 4 }) by ({ 5 }) partial ({ 6 }) occlusion ({ 7 }) and ({ 8 }) the ({ }) appearance ({ 9 }) of ({ 10 }) a ({ }) character ({ 11 }) in ({ 12 }) the ({ 13 }) middle ({ 14 }) of ({ 15 }) a ({ 16 }) shot ({ 17 }) . ({ 18 }) 
# Sentence pair (3072) source length 21 target length 19 alignment score : 2.9676e-12
All face-tracks which we could not extract exactly are those fully occluded at some frames during their occurences . 
NULL ({ }) The ({ 1 }) only ({ }) face ({ }) tracks ({ 2 }) that ({ 3 }) we ({ 4 }) could ({ 5 }) not ({ 6 }) extract ({ 7 }) exactly ({ 8 }) are ({ 9 }) those ({ 10 }) fully ({ 11 }) occluded ({ 12 }) in ({ 13 }) some ({ 14 }) frames ({ 15 }) during ({ 16 }) their ({ 17 }) occurrences ({ 18 }) . ({ 19 }) 
# Sentence pair (3073) source length 17 target length 15 alignment score : 0.000119142
In those cases , all points in face regions are drifted to background region . 
NULL ({ }) In ({ 1 }) those ({ 2 }) cases ({ 3 }) , ({ 4 }) all ({ 5 }) points ({ 6 }) in ({ 7 }) the ({ }) face ({ 8 }) regions ({ 9 }) are ({ 10 }) drifted ({ 11 }) to ({ 12 }) the ({ }) background ({ 13 }) region ({ 14 }) . ({ 15 }) 
# Sentence pair (3074) source length 17 target length 17 alignment score : 3.92015e-14
Thus , there is no clue to re-group face of that person after such full occlusions . 
NULL ({ }) After ({ 1 }) such ({ 14 }) full ({ 15 }) occlusions ({ 16 }) , ({ 2 }) there ({ 3 }) is ({ 4 }) no ({ 5 }) clue ({ 6 }) to ({ 7 }) regrouping ({ 8 13 }) the ({ }) face ({ 9 }) of ({ 10 }) that ({ 11 }) person ({ 12 }) . ({ 17 }) 
# Sentence pair (3075) source length 13 target length 12 alignment score : 6.65606e-11
To handle this problem , using only tracker is not enough . 
NULL ({ }) , ({ 5 }) Using ({ 6 }) only ({ 7 }) a ({ }) tracker ({ 8 }) is ({ 9 }) not ({ 10 }) enough ({ 11 }) to ({ 1 }) handle ({ 2 }) this ({ 3 }) problem ({ 4 }) . ({ 12 }) 
# Sentence pair (3076) source length 20 target length 18 alignment score : 2.13771e-08
One can apply visual information based clustering to group the fragmented face-track , as in \CITE , . 
NULL ({ }) One ({ 1 }) can ({ 2 }) apply ({ 3 }) visual ({ 4 }) information-based ({ 5 6 }) clustering ({ 7 }) to ({ 8 }) group ({ 9 }) the ({ 10 }) fragmented ({ 11 }) face ({ }) track ({ 12 }) , ({ 13 }) as ({ 14 }) in ({ 15 }) \CITE ({ 16 }) , ({ 17 }) but ({ }) this ({ }) . ({ 18 }) 
# Sentence pair (3077) source length 6 target length 7 alignment score : 2.03491e-10
Obviously , extra cost is required . 
NULL ({ 5 }) obviously ({ 1 }) , ({ 2 }) requires ({ 3 }) extra ({ 6 }) cost ({ 4 }) . ({ 7 }) 
# Sentence pair (3078) source length 31 target length 31 alignment score : 1.57915e-17
However , we observe that fully occlusion is rarely happened in news video since characters reported in the news are recorded with care , especially with important and well-known character . 
NULL ({ 8 26 }) Nevertheless ({ 1 }) , ({ 2 }) we ({ 3 }) observe ({ 4 }) that ({ 5 }) full ({ 6 }) occlusion ({ 7 }) rarely ({ 9 }) happens ({ 10 }) in ({ 11 }) news ({ 12 }) video ({ 13 }) because ({ 14 }) the ({ }) characters ({ 15 }) featured ({ 16 }) in ({ 17 }) the ({ 18 }) news ({ 19 }) are ({ 20 }) recorded ({ 21 }) with ({ 22 }) care ({ 23 }) , ({ 24 }) especially ({ 25 }) the ({ }) important ({ 27 }) and ({ 28 }) well-known ({ 29 }) ones ({ 30 }) . ({ 31 }) 
# Sentence pair (3079) source length 9 target length 9 alignment score : 0.0228462
This is a special property of news videos . 
NULL ({ }) This ({ 1 }) is ({ 2 }) a ({ 3 }) special ({ 4 }) characteristic ({ 5 }) of ({ 6 }) news ({ 7 }) videos ({ 8 }) . ({ 9 }) 
# Sentence pair (3080) source length 15 target length 15 alignment score : 0.00345328
The last column of the table shows the overall extraction performance of both approaches . 
NULL ({ }) The ({ 1 }) last ({ 2 }) column ({ 3 }) of ({ 4 }) the ({ 5 }) table ({ 6 }) shows ({ 7 }) the ({ 8 }) overall ({ 9 }) extraction ({ 10 }) performance ({ 11 }) of ({ 12 }) both ({ 13 }) approaches ({ 14 }) . ({ 15 }) 
# Sentence pair (3081) source length 17 target length 18 alignment score : 1.11178e-06
These facts clearly indicate that our approach is robust and outperforms the approach of Everingham et al . 
NULL ({ 12 }) These ({ 1 }) facts ({ 2 }) clearly ({ 3 }) indicate ({ 4 }) that ({ 5 }) our ({ 6 }) approach ({ 7 }) is ({ 8 }) robust ({ 9 }) and ({ 10 }) outperforms ({ 11 }) that ({ 13 }) of ({ 14 }) Everingham ({ 15 }) et ({ 16 }) al ({ 17 }) . ({ 18 }) 
# Sentence pair (3082) source length 2 target length 2 alignment score : 0.446651
in \CITE. 
NULL ({ }) in ({ 1 }) \CITE. ({ 2 }) 
# Sentence pair (3083) source length 19 target length 18 alignment score : 5.31144e-09
In terms of speed , our approach is approximately 2 times slower than the approach of Everingham . 
NULL ({ 14 }) In ({ 1 }) terms ({ 2 }) of ({ 3 }) speed ({ 4 }) , ({ 5 }) our ({ 6 }) approach ({ 7 }) is ({ 8 }) approximately ({ 9 }) 2 ({ 10 }) times ({ 11 }) slower ({ 12 }) than ({ 13 }) that ({ 15 }) of ({ 16 }) Everingham ({ 17 }) et ({ }) al ({ }) . ({ 18 }) 
# Sentence pair (3084) source length 41 target length 35 alignment score : 1.48991e-20
However , our complexity is somehow linear to total number of face , because we consequently enlarge face-tracks following temporal order by checking new faces with only one last appeared face of each face-track . 
NULL ({ 32 }) However ({ 1 }) , ({ 2 }) our ({ 3 }) complexity ({ 4 }) is ({ 5 }) somehow ({ 6 }) linear ({ 7 }) to ({ 8 }) the ({ }) total ({ 9 }) number ({ 10 }) of ({ 11 }) faces ({ 12 }) , ({ 13 }) because ({ 14 }) we ({ 15 }) consequently ({ 16 }) enlarge ({ 17 }) face ({ }) tracks ({ 18 }) according ({ 19 }) to ({ }) the ({ }) temporal ({ 20 }) order ({ 21 }) by ({ 22 }) checking ({ 23 }) new ({ 24 }) faces ({ 25 }) with ({ 26 }) only ({ 27 }) the ({ }) last ({ 29 }) face ({ 31 }) that ({ 28 }) appeared ({ 30 }) on ({ }) each ({ 33 }) face ({ }) track ({ 34 }) . ({ 35 }) 
# Sentence pair (3085) source length 6 target length 6 alignment score : 0.147079
Meanwhile , Everingham et al . 
NULL ({ }) Meanwhile ({ 1 }) , ({ 2 }) Everingham ({ 3 }) et ({ 4 }) al ({ 5 }) . ({ 6 }) 
# Sentence pair (3086) source length 9 target length 9 alignment score : 0.00390002
compare all pairs of faces in the shot . 
NULL ({ }) compared ({ 1 }) all ({ 2 }) pairs ({ 3 }) of ({ 4 }) faces ({ 5 }) in ({ 6 }) the ({ 7 }) shot ({ 8 }) . ({ 9 }) 
# Sentence pair (3087) source length 11 target length 11 alignment score : 0.0259473
Their complexity is polynomial to the total number of faces . 
NULL ({ }) Their ({ 1 }) complexity ({ 2 }) is ({ 3 }) polynomial ({ 4 }) to ({ 5 }) the ({ 6 }) total ({ 7 }) number ({ 8 }) of ({ 9 }) faces ({ 10 }) . ({ 11 }) 
# Sentence pair (3088) source length 21 target length 22 alignment score : 3.49737e-17
If this number is getting larger , the gap in speed between our approach and the approach by Everingham et al . 
NULL ({ 4 16 }) If ({ 1 }) the ({ 2 }) number ({ 3 }) of ({ }) faces ({ 5 }) increases ({ 6 }) , ({ 7 }) the ({ 8 }) gap ({ 9 }) in ({ 10 }) speed ({ 11 }) between ({ 12 }) our ({ 13 }) approach ({ 14 }) and ({ 15 }) that ({ 17 }) by ({ 18 }) Everingham ({ 19 }) et ({ 20 }) al ({ 21 }) . ({ 22 }) 
# Sentence pair (3089) source length 3 target length 4 alignment score : 0.000908912
will be narrowed rapidly. 
NULL ({ }) will ({ 1 }) narrow ({ 2 }) rapidly. ({ 3 4 }) 
# Sentence pair (3090) source length 37 target length 32 alignment score : 1.67065e-15
Because all presented problems here , such as those due to flash , occlusion , and in-the-middle face appearance , are practically observed , overcoming them is vital for practical application . 
NULL ({ }) Because ({ 1 }) all ({ 2 }) the ({ }) problems ({ 4 }) presented ({ 3 }) here ({ 5 }) , ({ 6 }) such ({ 7 }) as ({ 8 }) those ({ 9 }) due ({ 10 }) to ({ 11 }) flash ({ 12 }) , ({ 13 }) occlusion ({ 14 }) , ({ 15 }) and ({ 16 }) in-the-middle ({ 17 }) face ({ 18 }) appearance ({ 19 }) , ({ 20 }) are ({ 21 }) practically ({ 22 }) observed ({ 23 }) , ({ 24 }) overcoming ({ 25 }) them ({ 26 }) is ({ 27 }) vital ({ 28 }) for ({ 29 }) the ({ }) practical ({ 30 }) application ({ 31 }) of ({ }) our ({ }) approach ({ }) . ({ 32 }) 
# Sentence pair (3091) source length 37 target length 35 alignment score : 7.03659e-10
In this experiment , we show that our proposed techniques and solutions for the problems are robust and efficient enough for extracting face-tracks in real-world news videos by successfully extracting 94% of all face-tracks . 
NULL ({ }) In ({ 1 }) this ({ 2 }) experiment ({ 3 }) , ({ 4 }) we ({ 5 }) show ({ 6 }) that ({ 7 }) our ({ 8 }) proposed ({ 9 }) techniques ({ 10 }) and ({ 11 }) solutions ({ 12 }) to ({ 13 }) the ({ 14 }) problems ({ 15 }) are ({ 16 }) robust ({ 17 }) and ({ 18 }) efficient ({ 19 }) enough ({ 20 }) for ({ 21 }) extracting ({ 22 }) face ({ }) tracks ({ 23 }) in ({ 24 }) real-world ({ 25 }) news ({ 26 }) videos ({ 27 }) by ({ 28 }) successfully ({ 29 }) extracting ({ 30 }) 94% ({ 31 }) of ({ 32 }) all ({ 33 }) face ({ }) tracks ({ 34 }) . ({ 35 }) 
# Sentence pair (3092) source length 16 target length 15 alignment score : 2.78499e-15
From our observations , one can use other complex techniques to handle the problems . 
NULL ({ 4 }) Based ({ 1 }) on ({ }) our ({ 2 }) observations ({ 3 5 7 }) , ({ }) other ({ 8 }) complex ({ 9 }) techniques ({ 10 }) can ({ 6 }) be ({ }) applied ({ }) to ({ 11 }) handle ({ 12 }) the ({ 13 }) problems ({ 14 }) . ({ 15 }) 
# Sentence pair (3093) source length 23 target length 21 alignment score : 1.25561e-13
However , a trade-o_ between completely obtaining 6% remaining face-tracks and an overly expensive computational cost should be considered with care. 
NULL ({ 3 }) However ({ 1 }) , ({ 2 }) the ({ }) trade-off ({ 4 }) between ({ 5 }) obtaining ({ 6 7 }) the ({ }) 6% ({ 8 }) remaining ({ 9 }) face ({ }) tracks ({ 10 }) and ({ 11 }) incurring ({ 12 }) an ({ }) overly ({ 13 }) high ({ 14 }) computational ({ 15 }) cost ({ 16 }) should ({ 17 }) be ({ 18 }) considered ({ 19 }) with ({ 20 }) care. ({ 21 }) 
# Sentence pair (3094) source length 17 target length 16 alignment score : 0.000330463
Due to the limitations of existing public datasets , we prepare new datasets for experiments . 
NULL ({ }) Due ({ 1 }) to ({ 2 }) the ({ 3 }) limitations ({ 4 }) of ({ 5 }) existing ({ 6 }) public ({ 7 }) datasets ({ 8 }) , ({ 9 }) we ({ 10 }) prepared ({ 11 }) new ({ 12 }) datasets ({ 13 }) for ({ 14 }) the ({ }) experiments ({ 15 }) . ({ 16 }) 
# Sentence pair (3095) source length 23 target length 22 alignment score : 6.79676e-14
Face-tracks in videos of the datasets are extracted by using our proposed approach for face-track extraction ( see section 4.2 ) . 
NULL ({ }) Face ({ 1 }) tracks ({ 2 }) are ({ 7 }) extracted ({ 8 }) from ({ }) videos ({ 3 }) of ({ 4 }) the ({ 5 }) datasets ({ 6 }) by ({ 9 }) using ({ 10 }) our ({ 11 }) proposed ({ 12 }) approach ({ 13 }) to ({ 14 }) face-track ({ 15 }) extraction ({ 16 }) ( ({ 17 }) see ({ 18 }) section ({ 19 }) 4.2 ({ 20 }) ) ({ 21 }) . ({ 22 }) 
# Sentence pair (3096) source length 16 target length 14 alignment score : 1.37763e-05
Identity of the character associated with each extracted face-track is given by annotators . 
NULL ({ }) The ({ }) identity ({ 1 }) of ({ 2 }) the ({ 3 }) character ({ 4 }) associated ({ 5 }) with ({ 6 }) each ({ 7 }) extracted ({ 8 }) face ({ }) track ({ 9 }) is ({ 10 }) given ({ 11 }) by ({ 12 }) annotators ({ 13 }) . ({ 14 }) 
# Sentence pair (3097) source length 19 target length 17 alignment score : 9.45093e-08
Since our approach extract face-tracks in each video shot , shot boundaries for videos are required . 
NULL ({ }) Because ({ 1 }) our ({ 2 }) approach ({ 3 }) extracts ({ 4 }) face ({ }) tracks ({ 5 }) in ({ 6 }) each ({ 7 }) video ({ 8 }) shot ({ 9 }) , ({ 10 }) the ({ }) shot ({ 11 }) boundaries ({ 12 }) of ({ 13 }) videos ({ 14 }) are ({ 15 }) required ({ 16 }) . ({ 17 }) 
# Sentence pair (3098) source length 15 target length 14 alignment score : 0.00126849
A simple shot boundary detector based on color histogram of frames is used . 
NULL ({ }) A ({ 1 }) simple ({ 2 }) shot ({ 3 }) boundary ({ 4 }) detector ({ 5 }) based ({ 6 }) on ({ 7 }) a ({ }) color ({ 8 }) histogram ({ 9 }) of ({ 10 }) frames ({ 11 }) is ({ 12 }) used ({ 13 }) . ({ 14 }) 
# Sentence pair (3099) source length 15 target length 15 alignment score : 9.75422e-09
The whole process , including detecting shot boundaries and face-track extraction , is fully automatic. 
NULL ({ }) The ({ 1 }) whole ({ 2 }) process ({ 3 }) , ({ 4 }) including ({ 5 }) shot ({ 7 }) boundary ({ 6 }) detection ({ 8 }) and ({ 9 }) face-track ({ 10 }) extraction ({ 11 }) , ({ 12 }) is ({ 13 }) fully ({ 14 }) automated. ({ 15 }) 
# Sentence pair (3100) source length 3 target length 3 alignment score : 0.0174313
TRECVID Dataset . 
NULL ({ }) TRECVID ({ 1 }) dataset ({ 2 }) . ({ 3 }) 
# Sentence pair (3101) source length 10 target length 11 alignment score : 0.000512288
We used the TRECVID news videos from 2004 to 2006 . 
NULL ({ 3 }) We ({ 1 }) used ({ 2 }) TRECVID ({ 4 }) news ({ 5 }) videos ({ 6 }) from ({ 7 }) 2004 ({ 8 }) to ({ 9 }) 2006 ({ 10 }) . ({ 11 }) 
# Sentence pair (3102) source length 20 target length 20 alignment score : 0.00069177
This dataset contains 370 hours of videos in different languages , such as English , Chinese , and Arabic . 
NULL ({ }) This ({ 1 }) dataset ({ 2 }) contains ({ 3 }) 370 ({ 4 }) hours ({ 5 }) of ({ 6 }) videos ({ 7 }) in ({ 8 }) different ({ 9 }) languages ({ 10 }) , ({ 11 }) such ({ 12 }) as ({ 13 }) English ({ 14 }) , ({ 15 }) Chinese ({ 16 }) , ({ 17 }) and ({ 18 }) Arabic ({ 19 }) . ({ 20 }) 
# Sentence pair (3103) source length 13 target length 14 alignment score : 1.24402e-06
The total number of frames that we processed was approximately 35 millions frames . 
NULL ({ }) The ({ 1 }) total ({ 2 }) number ({ 3 }) of ({ 4 }) frames ({ 5 }) that ({ 6 }) we ({ 7 }) processed ({ 8 }) was ({ 9 }) approximately ({ 10 }) 35 ({ 11 }) million ({ 12 13 }) . ({ 14 }) 
# Sentence pair (3104) source length 13 target length 13 alignment score : 0.000361926
Among those , 20 millions faces were grouped into 157,524 face tracks . 
NULL ({ }) Among ({ 1 }) those ({ 2 }) , ({ 3 }) 20 ({ 4 }) million ({ 5 }) faces ({ 6 }) were ({ 7 }) grouped ({ 8 }) into ({ 9 }) 157,524 ({ 10 }) face ({ 11 }) tracks ({ 12 }) . ({ 13 }) 
# Sentence pair (3105) source length 15 target length 14 alignment score : 4.25654e-06
We filtered out short face tracks that had less than ten faces , . 
NULL ({ }) We ({ 1 }) filtered ({ 2 }) out ({ 3 }) short ({ 4 }) face ({ 5 }) tracks ({ 6 }) that ({ 7 }) had ({ 8 }) less ({ 9 }) than ({ 10 }) 10 ({ 11 }) faces ({ 12 }) , ({ 13 }) which ({ }) . ({ 14 }) 
# Sentence pair (3106) source length 6 target length 7 alignment score : 6.91644e-05
This resulted in 35,836 face tracks . 
NULL ({ }) resulted ({ 1 2 }) in ({ 3 }) 35,836 ({ 4 }) face ({ 5 }) tracks ({ 6 }) . ({ 7 }) 
# Sentence pair (3107) source length 16 target length 17 alignment score : 4.8231e-07
Finally , we annotated 1,497 face tracks containing 405,887 faces of 41 well known individual characters . 
NULL ({ }) Finally ({ 1 }) , ({ 2 }) we ({ 3 }) annotated ({ 4 }) 1,497 ({ 5 }) face ({ 6 }) tracks ({ 7 }) containing ({ 8 }) 405,887 ({ 9 }) faces ({ 10 }) of ({ 11 }) 41 ({ 12 }) well-known ({ 13 14 }) individual ({ 15 }) characters ({ 16 }) . ({ 17 }) 
# Sentence pair (3108) source length 3 target length 3 alignment score : 0.0162172
NHKNews7 Dataset . 
NULL ({ }) NHKNews7 ({ 1 }) dataset ({ 2 }) . ({ 3 }) 
# Sentence pair (3109) source length 15 target length 11 alignment score : 1.85781e-10
This dataset is observed from NHKNews7 channel in 11 years . 
NULL ({ }) This ({ 1 }) dataset ({ 2 }) consists ({ 3 }) of ({ }) observations ({ 4 }) from ({ 5 }) the ({ }) NHK ({ 6 }) News ({ }) 7 ({ }) program ({ 7 }) over ({ 8 }) 11 ({ 9 }) years ({ 10 }) . ({ 11 }) 
# Sentence pair (3110) source length 13 target length 13 alignment score : 0.00352105
After the annotation process , 1,259,320 faces of 111 individuals are provided . 
NULL ({ }) After ({ 1 }) the ({ 2 }) annotation ({ 3 }) process ({ 4 }) , ({ 5 }) 1,259,320 ({ 6 }) faces ({ 7 }) of ({ 8 }) 111 ({ 9 }) individuals ({ 10 }) are ({ 11 }) provided ({ 12 }) . ({ 13 }) 
# Sentence pair (3111) source length 9 target length 8 alignment score : 0.00924026
The total number of face-tracks is 5,567 . 
NULL ({ }) The ({ 1 }) total ({ 2 }) number ({ 3 }) of ({ 4 }) face ({ }) tracks ({ 5 }) is ({ 6 }) 5,567 ({ 7 }) . ({ 8 }) 
# Sentence pair (3112) source length 10 target length 9 alignment score : 0.00380106
Each character has from 4 to 550 face-tracks . 
NULL ({ }) Each ({ 1 }) character ({ 2 }) has ({ 3 }) from ({ 4 }) 4 ({ 5 }) to ({ 6 }) 550 ({ 7 }) face ({ }) tracks ({ 8 }) . ({ 9 }) 
# Sentence pair (3113) source length 19 target length 18 alignment score : 9.80601e-06
In this dataset , we discard facetracks with fewer than 100 faces and more than 500 faces . 
NULL ({ }) In ({ 1 }) this ({ 2 }) dataset ({ 3 }) , ({ 4 }) we ({ 5 }) discard ({ 6 }) face ({ }) tracks ({ 7 }) with ({ 8 }) fewer ({ 9 }) than ({ 10 }) 100 ({ 11 }) faces ({ 12 }) and ({ 13 }) more ({ 14 }) than ({ 15 }) 500 ({ 16 }) faces ({ 17 }) . ({ 18 }) 
# Sentence pair (3114) source length 13 target length 12 alignment score : 0.00271702
Compared to the TRECVID dataset , NHKNews7 dataset is much more challenging. 
NULL ({ }) Compared ({ 1 }) to ({ 2 }) the ({ 3 }) TRECVID ({ 4 }) dataset ({ 5 }) , ({ 6 }) the ({ }) NHKNews7 ({ 7 }) dataset ({ 8 }) is ({ 9 }) much ({ 10 }) more ({ 11 }) challenging. ({ 12 }) 
# Sentence pair (3115) source length 15 target length 15 alignment score : 4.18828e-18
In the Table 4 , we compare our datasets with some public benchmark datasets . 
NULL ({ 2 }) Table ({ 1 }) 4 ({ 4 }) shows ({ 3 }) a ({ }) , ({ 5 }) comparison ({ 6 }) between ({ 7 }) our ({ 8 }) datasets ({ 9 }) and ({ 10 }) some ({ 11 }) public ({ 12 }) benchmark ({ 13 }) datasets ({ 14 }) . ({ 15 }) 
# Sentence pair (3116) source length 45 target length 40 alignment score : 2.68329e-29
, It is obvious that our datasets are extremely higher than datasets , such as MoBo and Honda / UCSD , on all statistical terms , including the number of videos , characters , and average length of face-track . 
NULL ({ 28 38 }) Based ({ }) on ({ }) the ({ }) results ({ }) , ({ 1 }) it ({ 2 }) is ({ 3 }) obvious ({ 4 }) that ({ 5 }) our ({ 6 }) datasets ({ 7 }) are ({ 8 }) superior ({ 9 10 }) over ({ 11 }) the ({ }) other ({ }) datasets ({ 12 }) , ({ 13 }) such ({ 14 }) as ({ 15 }) MoBo ({ 16 }) and ({ 17 }) Honda ({ 18 }) / ({ 19 }) UCSD ({ 20 }) , ({ 21 }) on ({ 22 }) all ({ 23 }) statistical ({ 24 }) terms ({ 25 }) , ({ 26 }) including ({ 27 }) number ({ 29 }) of ({ 30 }) videos ({ 31 }) , ({ 32 }) number ({ }) of ({ }) characters ({ 33 }) , ({ 34 }) and ({ 35 }) average ({ 36 }) face-track ({ 39 }) length ({ 37 }) . ({ 40 }) 
# Sentence pair (3117) source length 35 target length 32 alignment score : 6.63919e-17
Compared to Youtube Faces dataset , although ours have less number of character ( or subjects ) , we provide much more face-tracks ( or video shots ) per character , . 
NULL ({ }) Compared ({ 1 }) to ({ 2 }) the ({ }) YouTube ({ 3 }) Faces ({ 4 }) dataset ({ 5 }) , ({ 6 }) , ({ 18 }) we ({ 19 }) provide ({ 20 }) much ({ 21 }) more ({ 22 }) face ({ }) tracks ({ 23 }) ( ({ 24 }) or ({ 25 }) video ({ 26 }) shots ({ 27 }) ) ({ 28 }) per ({ 29 }) character ({ 30 }) , ({ 31 }) although ({ 7 }) our ({ }) datasets ({ 8 }) have ({ 9 }) smaller ({ 10 }) numbers ({ 11 }) of ({ 12 }) characters ({ 13 }) ( ({ 14 }) or ({ 15 }) subjects ({ 16 }) ) ({ 17 }) . ({ 32 }) 
# Sentence pair (3118) source length 13 target length 10 alignment score : 1.59582e-08
Thus , ours are more relevant for evaluating retrieval system. 
NULL ({ }) Thus ({ 1 }) , ({ 2 }) our ({ }) datasets ({ 3 }) are ({ 4 }) more ({ 5 }) relevant ({ 6 }) in ({ 7 }) evaluating ({ 8 }) a ({ }) face ({ }) retrieval ({ 9 }) system. ({ 10 }) 
# Sentence pair (3119) source length 9 target length 12 alignment score : 1.6722e-16
Statistical information of our datasets is given in the Figure 5 . 
NULL ({ 6 8 9 }) Figure ({ 10 }) 5 ({ 11 }) presents ({ 7 }) statistical ({ 1 }) information ({ 2 }) on ({ 3 }) our ({ 4 }) datasets ({ 5 }) . ({ 12 }) 
# Sentence pair (3120) source length 11 target length 11 alignment score : 3.88903e-05
The datasets can be downloaded at http: / / satohlab . 
NULL ({ }) The ({ 1 }) datasets ({ 2 }) can ({ 3 }) be ({ 4 }) downloaded ({ 5 }) from ({ 6 }) http: ({ 7 }) / ({ 8 }) / ({ 9 }) satohlab ({ 10 }) . ({ 11 }) 
# Sentence pair (3121) source length 8 target length 8 alignment score : 0.035828
ex.nii.ac.jp / users / ndthanh / NIIFacetrackDatasets . 
NULL ({ }) ex.nii.ac.jp ({ 1 }) / ({ 2 }) users ({ 3 }) / ({ 4 }) ndthanh ({ 5 }) / ({ 6 }) NIIFacetrackDatasets ({ 7 }) . ({ 8 }) 
# Sentence pair (3122) source length 18 target length 16 alignment score : 3.19104e-08
However , due to copyright issues , face images in face-tracks can not be published . 
NULL ({ }) However ({ 1 }) , ({ 2 }) due ({ 3 }) to ({ 4 }) copyright ({ 5 }) issues ({ 6 }) , ({ 7 }) the ({ }) face ({ 8 }) images ({ 9 }) in ({ 10 }) the ({ }) face ({ }) tracks ({ 11 }) cannot ({ 12 13 }) be ({ 14 }) published ({ 15 }) . ({ 16 }) 
# Sentence pair (3123) source length 17 target length 17 alignment score : 0.00110797
Instead , we provide a feature vector , used in \CITE , for each face image . 
NULL ({ }) Instead ({ 1 }) , ({ 2 }) we ({ 3 }) provide ({ 4 }) a ({ 5 }) feature ({ 6 }) vector ({ 7 }) , ({ 8 }) used ({ 9 }) in ({ 10 }) \CITE ({ 11 }) , ({ 12 }) for ({ 13 }) each ({ 14 }) face ({ 15 }) image ({ 16 }) . ({ 17 }) 
# Sentence pair (3124) source length 27 target length 26 alignment score : 9.33114e-08
A feature vector of a face is extracted by computing descriptors of the local appearance of the face around each of the located facial features . 
NULL ({ }) The ({ 1 }) feature ({ 2 }) vector ({ 3 }) of ({ 4 }) a ({ 5 }) face ({ 6 }) is ({ 7 }) extracted ({ 8 }) by ({ 9 }) computing ({ 10 }) the ({ }) descriptors ({ 11 }) of ({ 12 }) the ({ 13 }) local ({ 14 }) appearance ({ 15 }) of ({ 16 }) the ({ 17 }) face ({ 18 }) around ({ 19 }) each ({ 20 }) of ({ 21 }) the ({ 22 }) located ({ 23 }) facial ({ 24 }) features ({ 25 }) . ({ 26 }) 
# Sentence pair (3125) source length 18 target length 17 alignment score : 0.000209012
Before extracting descriptors , the face is geometrically normalized to reduce the effect of pose variation . 
NULL ({ }) Before ({ 1 }) extracting ({ 2 }) the ({ }) descriptors ({ 3 }) , ({ 4 }) the ({ 5 }) face ({ 6 }) is ({ 7 }) geometrically ({ 8 }) normalized ({ 9 }) to ({ 10 }) reduce ({ 11 }) the ({ 12 }) effect ({ 13 }) of ({ 14 }) pose ({ 15 }) variation ({ 16 }) . ({ 17 }) 
# Sentence pair (3126) source length 21 target length 21 alignment score : 5.2272e-11
They estimate an affine transformation , which transform the located facial feature points to a canonical set of feature positions . 
NULL ({ }) An ({ 1 }) affine ({ 2 4 }) transformation ({ 3 }) is ({ }) estimated ({ 5 }) , ({ 6 }) which ({ 7 }) transforms ({ 8 }) the ({ 9 }) located ({ 10 }) facial ({ 11 }) feature ({ 12 }) points ({ 13 }) to ({ 14 }) a ({ 15 }) canonical ({ 16 }) set ({ 17 }) of ({ 18 }) feature ({ 19 }) positions ({ 20 }) . ({ 21 }) 
# Sentence pair (3127) source length 12 target length 11 alignment score : 3.86983e-05
Then , appearance descriptors are computed around each facial feature . 
NULL ({ }) Then ({ 1 }) , ({ 2 }) the ({ }) appearance ({ 3 }) descriptors ({ 4 }) around ({ 7 }) each ({ 8 }) facial ({ 9 }) feature ({ 10 }) are ({ 5 }) computed ({ 6 }) . ({ 11 }) 
# Sentence pair (3128) source length 18 target length 17 alignment score : 0.000460815
The final feature representation of the face is formed by concatenating all descriptors of its facial features. 
NULL ({ }) The ({ 1 }) final ({ 2 }) feature ({ 3 }) representation ({ 4 }) of ({ 5 }) the ({ 6 }) face ({ 7 }) is ({ 8 }) formed ({ 9 }) by ({ 10 }) concatenating ({ 11 }) all ({ 12 }) the ({ }) descriptors ({ 13 }) of ({ 14 }) its ({ 15 }) facial ({ 16 }) features. ({ 17 }) 
# Sentence pair (3129) source length 19 target length 19 alignment score : 9.78781e-06
We compare k-Faces with several approaches , including approaches based on pair-wise distances , MSM \CITE and CMSM \CITE. 
NULL ({ }) We ({ 1 }) compared ({ 2 }) k-Faces ({ 3 }) with ({ 4 }) several ({ 5 }) approaches ({ 6 }) , ({ 7 }) including ({ 8 }) those ({ 9 }) based ({ 10 }) on ({ 11 }) pair-wise ({ 12 }) distances ({ 13 }) , ({ 14 }) MSM ({ 15 }) \CITE ({ 16 }) and ({ 17 }) CMSM ({ 18 }) \CITE. ({ 19 }) 
# Sentence pair (3130) source length 30 target length 28 alignment score : 3.91842e-09
Given two face-tracks having multiple face images represented as feature vectors , pair-wise based approaches compute distances between each possible pair of feature vectors in two face-tracks . 
NULL ({ }) Given ({ 1 }) two ({ 2 }) face ({ }) tracks ({ 3 }) having ({ 4 }) multiple ({ 5 }) face ({ 6 }) images ({ 7 }) represented ({ 8 }) as ({ 9 }) feature ({ 10 }) vectors ({ 11 }) , ({ 12 }) pair-wise-based ({ 13 14 }) approaches ({ 15 }) compute ({ 16 }) the ({ }) distances ({ 17 }) between ({ 18 }) each ({ 19 }) possible ({ 20 }) pair ({ 21 }) of ({ 22 }) feature ({ 23 }) vectors ({ 24 }) in ({ 25 }) two ({ 26 }) face ({ }) tracks ({ 27 }) . ({ 28 }) 
# Sentence pair (3131) source length 29 target length 28 alignment score : 9.70481e-19
They then use the maximum distance , the minimum distance , or the mean distance of the computed pair-wise distances as the similarity measurement between two face-tracks . 
NULL ({ 2 4 }) The ({ 1 }) maximum ({ 5 }) distance ({ 6 }) , ({ 7 }) the ({ 8 }) minimum ({ 9 }) distance ({ 10 }) , ({ 11 }) or ({ 12 }) the ({ 13 }) mean ({ 14 }) distance ({ 15 }) of ({ 16 }) the ({ 17 }) computed ({ 18 }) pair-wise ({ 19 }) distances ({ 20 }) is ({ }) the ({ }) used ({ 3 }) as ({ 21 }) the ({ 22 }) similarity ({ 23 }) measurement ({ 24 }) between ({ 25 }) two ({ 26 }) face ({ }) tracks ({ 27 }) . ({ 28 }) 
# Sentence pair (3132) source length 23 target length 21 alignment score : 2.56608e-06
We denote the approaches as pair:max , pair:min , and pair:mean , respectively ( see Figure 6 for illustration ) . 
NULL ({ }) We ({ 1 }) refer ({ 2 }) to ({ }) the ({ 3 }) approaches ({ 4 }) as ({ 5 }) pair:max ({ 6 }) , ({ 7 }) pair:min ({ 8 }) , ({ 9 }) and ({ 10 }) pair:mean ({ 11 }) , ({ 12 }) respectively ({ 13 }) ( ({ 14 }) see ({ 15 }) Figure ({ 16 }) 6 ({ 17 }) for ({ 18 }) the ({ }) illustration ({ 19 }) ) ({ 20 }) . ({ 21 }) 
# Sentence pair (3133) source length 17 target length 17 alignment score : 0.000804569
The pair:min ( sometimes called min-min ) is a state-of-the-art approach widely used in other studies \CITE. 
NULL ({ }) The ({ 1 }) pair:min ({ 2 }) ( ({ 3 }) sometimes ({ 4 }) called ({ 5 }) min-min ({ 6 }) ) ({ 7 }) is ({ 8 }) a ({ 9 }) state-of-the-art ({ 10 }) approach ({ 11 }) widely ({ 12 }) used ({ 13 }) in ({ 14 }) other ({ 15 }) studies ({ 16 }) \CITE. ({ 17 }) 
# Sentence pair (3134) source length 27 target length 29 alignment score : 1.96298e-16
Regarding to \CITE , if the pair-wise based approaches are representative for non-parametric sampled based approaches , MSM and CMSM are representative for approaches based on parametric model . 
NULL ({ 2 }) Regarding ({ 1 }) \CITE ({ 3 }) , ({ 4 }) if ({ 5 }) the ({ 6 }) pair-wise-based ({ 7 8 }) approaches ({ 9 }) are ({ 10 }) representative ({ 11 }) of ({ 12 }) nonparametric ({ 13 }) sample-based ({ 14 15 }) approaches ({ 16 }) , ({ 17 }) MSM ({ 18 }) and ({ 19 }) CMSM ({ 20 }) are ({ 21 }) representative ({ 22 }) of ({ 23 }) approaches ({ 24 }) based ({ 25 }) on ({ 26 }) a ({ }) parametric ({ 27 }) model ({ 28 }) . ({ 29 }) 
# Sentence pair (3135) source length 8 target length 8 alignment score : 0.0584752
MSM , introduced by Yamaguchi et al . 
NULL ({ }) MSM ({ 1 }) , ({ 2 }) introduced ({ 3 }) by ({ 4 }) Yamaguchi ({ 5 }) et ({ 6 }) al ({ 7 }) . ({ 8 }) 
# Sentence pair (3136) source length 13 target length 13 alignment score : 0.0109336
The similarity between the sets is computed using the angle between subspaces . 
NULL ({ }) The ({ 1 }) similarity ({ 2 }) between ({ 3 }) the ({ 4 }) sets ({ 5 }) is ({ 6 }) computed ({ 7 }) using ({ 8 }) the ({ 9 }) angle ({ 10 }) between ({ 11 }) subspaces ({ 12 }) . ({ 13 }) 
# Sentence pair (3137) source length 20 target length 20 alignment score : 0.000891992
CMSM is an extension of MSM , in which subspaces of the sets are projected on a constraint subspace . 
NULL ({ }) CMSM ({ 1 }) is ({ 2 }) an ({ 3 }) extension ({ 4 }) of ({ 5 }) MSM ({ 6 }) , ({ 7 }) in ({ 8 }) which ({ 9 }) subspaces ({ 10 }) of ({ 11 }) the ({ 12 }) sets ({ 13 }) are ({ 14 }) projected ({ 15 }) onto ({ 16 }) a ({ 17 }) constraint ({ 18 }) subspace ({ 19 }) . ({ 20 }) 
# Sentence pair (3138) source length 13 target length 13 alignment score : 5.88653e-08
By doing that , the subspaces are expected to be better separatable . 
NULL ({ }) In ({ 1 }) doing ({ 2 }) so ({ 3 }) , ({ 4 }) the ({ 5 }) subspaces ({ 6 }) are ({ 7 }) expected ({ 8 }) to ({ 9 }) be ({ 10 }) more ({ 11 }) separable ({ 12 }) . ({ 13 }) 
# Sentence pair (3139) source length 22 target length 23 alignment score : 1.3998e-12
All of these approaches had been shown their robustness on benchmark datasets , such as MoBo , HondaUCSD , and Youtube Faces . 
NULL ({ 5 }) All ({ 1 }) of ({ 2 }) these ({ 3 }) approaches ({ 4 }) have ({ 6 }) shown ({ 7 }) their ({ 8 }) robustness ({ 9 }) in ({ 10 }) benchmark ({ 11 }) datasets ({ 12 }) , ({ 13 }) such ({ 14 }) as ({ 15 }) MoBo ({ 16 }) , ({ 17 }) HondaUCSD ({ 18 }) , ({ 19 }) and ({ 20 }) YouTube ({ 21 }) Faces ({ 22 }) . ({ 23 }) 
# Sentence pair (3140) source length 15 target length 15 alignment score : 0.00306974
Therefore , it is appealing to compare our k-Faces with them for a comprehensive evaluation. 
NULL ({ }) Therefore ({ 1 }) , ({ 2 }) it ({ 3 }) is ({ 4 }) appealing ({ 5 }) to ({ 6 }) compare ({ 7 }) our ({ 8 }) k-Faces ({ 9 }) with ({ 10 }) them ({ 11 }) for ({ 12 }) a ({ 13 }) comprehensive ({ 14 }) evaluation. ({ 15 }) 
# Sentence pair (3141) source length 38 target length 38 alignment score : 1.80397e-19
Besides evaluating k-Faces with different values of k as well as different types of distance ( e.g. , Euclidean , L1 , cosine ) , we try another criterion to select k representative faces in a face-track . 
NULL ({ 9 11 }) Besides ({ 1 }) evaluating ({ 2 }) k-Faces ({ 3 }) with ({ 4 }) different ({ 5 }) values ({ 6 }) of ({ 7 }) k ({ 8 }) and ({ 10 }) different ({ 12 }) types ({ 13 }) of ({ 14 }) distance ({ 15 }) ( ({ 16 }) e.g. ({ 17 }) , ({ 18 }) Euclidean ({ 19 }) , ({ 20 }) L1 ({ 21 }) , ({ 22 }) and ({ }) cosine ({ 23 }) ) ({ 24 }) , ({ 25 }) we ({ 26 }) try ({ 27 }) another ({ 28 }) criterion ({ 29 }) for ({ 30 }) selecting ({ 31 }) k ({ 32 }) representative ({ 33 }) faces ({ 34 }) in ({ 35 }) a ({ 36 }) face ({ }) track ({ 37 }) . ({ 38 }) 
# Sentence pair (3142) source length 29 target length 27 alignment score : 1.36625e-11
In the original way , we proposed to select these faces by partitioning the face-track following temporal order and selecting the middle face of each partition . 
NULL ({ 8 }) In ({ 1 }) the ({ 2 }) original ({ 3 }) way ({ 4 }) , ({ 5 }) we ({ 6 }) proposed ({ 7 }) selecting ({ 9 }) these ({ 10 }) faces ({ 11 }) by ({ 12 }) partitioning ({ 13 }) the ({ 14 }) face ({ }) track ({ 15 }) according ({ 16 }) to ({ }) the ({ }) temporal ({ 17 }) order ({ 18 }) and ({ 19 }) choosing ({ 20 }) the ({ 21 }) middle ({ 22 }) face ({ 23 }) of ({ 24 }) each ({ 25 }) partition ({ 26 }) . ({ 27 }) 
# Sentence pair (3143) source length 18 target length 19 alignment score : 5.72952e-19
However , an yet another criterion can be applied to select these representative faces is based on clustering . 
NULL ({ }) However ({ 1 }) , ({ 2 }) another ({ 3 }) criterion ({ 4 6 }) that ({ 5 }) is ({ 15 }) based ({ 16 }) on ({ 17 }) clustering ({ 18 }) can ({ 7 }) be ({ 8 }) applied ({ 9 }) in ({ 10 }) selecting ({ 11 }) these ({ 12 }) representative ({ 13 }) faces ({ 14 }) . ({ 19 }) 
# Sentence pair (3144) source length 24 target length 22 alignment score : 1.44095e-10
In this new way , all faces in a face-track will be clustered in to k groups by a clustering algorithm . 
NULL ({ 14 }) In ({ 1 }) this ({ 2 }) new ({ 3 }) way ({ 4 }) , ({ 5 }) all ({ 6 }) the ({ }) faces ({ 7 }) in ({ 8 }) a ({ 9 }) face ({ }) track ({ 10 }) will ({ 11 }) be ({ 12 }) clustered ({ 13 }) to ({ 15 }) k ({ 16 }) groups ({ 17 }) by ({ 18 }) using ({ }) a ({ 19 }) clustering ({ 20 }) algorithm ({ 21 }) . ({ 22 }) 
# Sentence pair (3145) source length 8 target length 8 alignment score : 0.0752248
The centroid of each group is selected . 
NULL ({ }) The ({ 1 }) centroid ({ 2 }) of ({ 3 }) each ({ 4 }) group ({ 5 }) is ({ 6 }) selected ({ 7 }) . ({ 8 }) 
# Sentence pair (3146) source length 18 target length 17 alignment score : 0.000172862
Then , the mean of k centroids is used as the representative face for the face-track . 
NULL ({ }) Then ({ 1 }) , ({ 2 }) the ({ 3 }) mean ({ 4 }) of ({ 5 }) k ({ 6 }) centroids ({ 7 }) is ({ 8 }) used ({ 9 }) as ({ 10 }) the ({ 11 }) representative ({ 12 }) face ({ 13 }) for ({ 14 }) the ({ 15 }) face ({ }) track ({ 16 }) . ({ 17 }) 
# Sentence pair (3147) source length 12 target length 12 alignment score : 0.0151863
In this experiment , we use the standard K-Means for clustering . 
NULL ({ }) In ({ 1 }) this ({ 2 }) experiment ({ 3 }) , ({ 4 }) we ({ 5 }) use ({ 6 }) the ({ 7 }) standard ({ 8 }) K-Means ({ 9 }) for ({ 10 }) clustering ({ 11 }) . ({ 12 }) 
# Sentence pair (3148) source length 15 target length 13 alignment score : 1.07938e-05
We denote the former k-Faces as k-Faces.Temporal and the latter k-Faces as k-Faces.KMeans. 
NULL ({ }) We ({ 1 }) refer ({ 2 }) to ({ }) the ({ 3 }) former ({ 4 }) k-Faces ({ 5 }) as ({ 6 }) k-Faces.Temporal ({ 7 }) and ({ 8 }) to ({ }) the ({ 9 }) latter ({ 10 }) k-Faces ({ 11 }) as ({ 12 }) k-Faces.KMeans. ({ 13 }) 
# Sentence pair (3149) source length 22 target length 22 alignment score : 5.68159e-16
We evaluate performance of a face-track matching approach by computing the average precision on the rank list returned by the approach . 
NULL ({ 19 20 }) We ({ 1 }) evaluate ({ 2 }) the ({ }) performance ({ 3 }) of ({ 4 }) a ({ 5 }) face-track ({ 6 }) matching ({ 7 }) approach ({ 8 }) by ({ 9 }) computing ({ 10 }) the ({ 11 }) average ({ 12 }) precision ({ 13 }) of ({ 14 }) the ({ 15 }) rank ({ 16 }) list ({ 17 }) that ({ 21 }) it ({ }) returned ({ 18 }) . ({ 22 }) 
# Sentence pair (3150) source length 32 target length 29 alignment score : 9.63703e-14
In particular , for each dataset , each face-track is alternatively picked out as a query facetrack , while the remaining face-tracks are used as the retrieved database . 
NULL ({ }) In ({ 1 }) particular ({ 2 }) , ({ 3 }) in ({ 4 }) each ({ 5 }) dataset ({ 6 }) , ({ 7 }) a ({ 8 }) face ({ }) track ({ 9 }) is ({ 10 }) alternatively ({ 11 }) picked ({ 12 }) out ({ 13 }) as ({ 14 }) a ({ 15 }) query ({ 16 }) face ({ }) track ({ 17 }) , ({ 18 }) while ({ 19 }) the ({ 20 }) remaining ({ 21 }) face ({ }) tracks ({ 22 }) are ({ 23 }) used ({ 24 }) as ({ 25 }) the ({ 26 }) retrieved ({ 27 }) database ({ 28 }) . ({ 29 }) 
# Sentence pair (3151) source length 16 target length 15 alignment score : 1.33448e-09
, Average precision of the returned ranked list is computed , given a query . 
NULL ({ }) Given ({ 12 }) a ({ 13 }) query ({ 14 }) , ({ 1 }) the ({ }) average ({ 2 }) precision ({ 3 }) of ({ 4 }) the ({ 5 }) returned ({ 6 }) ranked ({ 7 }) list ({ 8 }) is ({ 9 }) computed ({ 10 }) , ({ 11 }) . ({ 15 }) 
# Sentence pair (3152) source length 29 target length 27 alignment score : 2.33268e-12
Finally , the mean of all average precision ( MAP ) from all query is reported as the overall evaluation metric for the approach on the database. 
NULL ({ }) Finally ({ 1 }) , ({ 2 }) the ({ 3 }) mean ({ 4 }) of ({ 5 }) all ({ 6 }) average ({ 7 }) precision ({ 8 }) ( ({ 9 }) MAP ({ 10 }) ) ({ 11 }) values ({ 12 }) for ({ }) all ({ 13 }) queries ({ 14 }) is ({ 15 }) reported ({ 16 }) as ({ 17 }) the ({ 18 }) overall ({ 19 }) evaluation ({ 20 }) metric ({ 21 }) for ({ 22 }) the ({ 23 }) approach ({ 24 }) with ({ 25 }) the ({ 26 }) given ({ }) database. ({ 27 }) 
# Sentence pair (3153) source length 77 target length 80 alignment score : 1.14427e-35
Let denote r as a rank in the returned face-track list , Pre( r ) as is the precision at the rank r of the list , Nl as the length of the list , Nhit as the total number of face-tracks matched with the query face-track q , and I sMatched( k ) as a binary function returning 1 if the face-track at rank r is matched with q ( based on ground-truth annotations ) , zero otherwise . 
NULL ({ 4 16 17 21 29 37 55 }) Let ({ 1 }) r ({ 3 }) denote ({ 2 }) a ({ 5 }) rank ({ 6 }) in ({ 7 }) the ({ 8 }) returned ({ 9 }) face-track ({ 10 }) list ({ 11 }) , ({ 12 }) Pre( ({ 13 }) r ({ 14 }) ) ({ 15 }) the ({ 18 }) precision ({ 19 }) at ({ 20 }) rank ({ 22 }) r ({ 23 }) of ({ 24 }) the ({ 25 }) list ({ 26 }) , ({ 27 }) Nl ({ 28 }) the ({ 30 }) length ({ 31 }) of ({ 32 }) the ({ 33 }) list ({ 34 }) , ({ 35 }) Nhit ({ 36 }) the ({ 38 }) total ({ 39 }) number ({ 40 }) of ({ 41 }) face ({ }) tracks ({ 42 }) matched ({ 43 }) with ({ 44 }) the ({ 45 }) query ({ 46 }) face ({ }) track ({ 47 }) q ({ 48 }) , ({ 49 }) and ({ 50 }) I ({ 51 }) sMatched( ({ 52 }) k ({ 53 }) ) ({ 54 }) a ({ 56 }) binary ({ 57 }) function ({ 58 }) returning ({ 59 }) 1 ({ 60 }) if ({ 61 }) the ({ 62 }) face ({ }) track ({ 63 }) at ({ 64 }) rank ({ 65 }) r ({ 66 }) is ({ 67 }) matched ({ 68 }) with ({ 69 }) q ({ 70 }) ( ({ 71 }) based ({ 72 }) on ({ 73 }) ground-truth ({ 74 }) annotations ({ 75 }) ) ({ 76 }) and ({ }) , ({ 77 }) zero ({ 78 }) otherwise ({ 79 }) . ({ 80 }) 
# Sentence pair (3154) source length 14 target length 14 alignment score : 0.00496695
Then , the MAP of the evaluated approach can be computed as following: \MATH 
NULL ({ }) Then ({ 1 }) , ({ 2 }) the ({ 3 }) MAP ({ 4 }) of ({ 5 }) the ({ 6 }) evaluated ({ 7 }) approach ({ 8 }) can ({ 9 }) be ({ 10 }) computed ({ 11 }) as ({ 12 }) follows: ({ 13 }) \MATH ({ 14 }) 
# Sentence pair (3155) source length 13 target length 12 alignment score : 4.68544e-06
MAP is a standard metric to evaluate retrieval and matching systems . 
NULL ({ }) The ({ }) MAP ({ 1 }) is ({ 2 }) a ({ 3 }) standard ({ 4 }) metric ({ 5 }) for ({ 6 }) evaluating ({ 7 }) retrieval ({ 8 }) and ({ 9 }) matching ({ 10 }) systems ({ 11 }) . ({ 12 }) 
# Sentence pair (3156) source length 19 target length 16 alignment score : 9.03068e-11
Besides MAP , we record processing times of the approaches on each dataset for efficiency comparison. 
NULL ({ }) Besides ({ 1 }) the ({ }) MAP ({ 2 }) , ({ 3 }) we ({ 4 }) record ({ 5 }) the ({ }) processing ({ 6 }) times ({ 7 }) of ({ 8 }) the ({ 9 }) approaches ({ 10 }) in ({ 11 }) each ({ 12 }) dataset ({ 13 }) to ({ 14 }) compare ({ 15 }) their ({ }) efficiency. ({ 16 }) 
# Sentence pair (3157) source length 24 target length 22 alignment score : 1.22131e-11
Figure 7 presents Mean Average Precision ( MAP ) of all evaluated approaches on our two datasets , Trecvid and NHKNews7 . 
NULL ({ }) Figure ({ 1 }) 7 ({ 2 }) presents ({ 3 }) the ({ }) mean ({ 4 }) average ({ 5 }) precision ({ 6 }) ( ({ 7 }) MAP ({ 8 }) ) ({ 9 }) of ({ 10 }) all ({ 11 }) the ({ }) evaluated ({ 12 }) approaches ({ 13 }) in ({ 14 }) our ({ 15 }) two ({ 16 }) datasets ({ 17 }) , ({ 18 }) Trecvid ({ 19 }) and ({ 20 }) NHKNews7 ({ 21 }) . ({ 22 }) 
# Sentence pair (3158) source length 15 target length 13 alignment score : 5.66002e-06
Generally , all MAPs vary from 64.61% to 76.54% on Trecvid dataset . 
NULL ({ }) Generally ({ 1 }) , ({ 2 }) all ({ 3 }) the ({ }) MAPs ({ 4 }) vary ({ 5 }) from ({ 6 }) 64.61% ({ 7 }) to ({ 8 }) 76.54% ({ 9 }) in ({ 10 }) the ({ }) Trecvid ({ 11 }) dataset ({ 12 }) . ({ 13 }) 
# Sentence pair (3159) source length 19 target length 19 alignment score : 4.03672e-16
Meanwhile , , the best MAP is 60.99% , and the worst MAP is 42.75% on NHKNews7 dataset . 
NULL ({ }) Meanwhile ({ 1 }) , ({ 2 }) in ({ 16 }) the ({ }) NHKNews7 ({ 17 }) dataset ({ 18 }) , ({ 3 }) the ({ 4 }) best ({ 5 }) MAP ({ 6 13 }) is ({ 7 }) 60.99% ({ 8 }) , ({ 9 }) and ({ 10 }) the ({ 11 }) worst ({ 12 }) is ({ 14 }) 42.75% ({ 15 }) . ({ 19 }) 
# Sentence pair (3160) source length 16 target length 14 alignment score : 1.31937e-06
The gap of MAPs between two datasets can be explained by following reasons . 
NULL ({ }) The ({ 1 }) difference ({ 2 }) in ({ 3 }) the ({ }) MAPs ({ 4 }) between ({ 5 }) the ({ }) two ({ 6 }) datasets ({ 7 }) can ({ 8 }) be ({ 9 }) explained ({ 10 }) by ({ 11 }) following ({ 12 }) reasons ({ 13 }) . ({ 14 }) 
# Sentence pair (3161) source length 26 target length 27 alignment score : 5.76109e-12
Firstly , the number of characters in NHKNews7 is more larger than those in Trecvid , 111 characters in NHKNews7 compared to 41 characters in Trecvid . 
NULL ({ }) First ({ 1 }) , ({ 2 }) the ({ 3 }) number ({ 4 }) of ({ 5 }) characters ({ 6 }) in ({ 7 }) NHKNews7 ({ 8 }) is ({ 9 }) larger ({ 10 11 }) than ({ 12 }) that ({ 13 }) in ({ 14 }) Trecvid ({ 15 }) , ({ 16 }) 111 ({ 17 }) characters ({ 18 }) in ({ 19 }) NHKNews7 ({ 20 }) compared ({ 21 }) to ({ 22 }) 41 ({ 23 }) characters ({ 24 }) in ({ 25 }) Trecvid ({ 26 }) . ({ 27 }) 
# Sentence pair (3162) source length 10 target length 9 alignment score : 0.0048895
This clearly increases the probability of mismatching face-tracks . 
NULL ({ }) This ({ 1 }) clearly ({ 2 }) increases ({ 3 }) the ({ 4 }) probability ({ 5 }) of ({ 6 }) mismatching ({ 7 }) face ({ }) tracks ({ 8 }) . ({ 9 }) 
# Sentence pair (3163) source length 19 target length 18 alignment score : 1.17445e-06
Secondly , videos in NHKNews7 are recorded during a long time ( i.e. , 11 years ) . 
NULL ({ }) Second ({ 1 }) , ({ 2 }) the ({ }) videos ({ 3 }) in ({ 4 }) NHKNews7 ({ 5 }) were ({ 6 }) recorded ({ 7 }) over ({ 8 }) a ({ 9 }) long ({ 10 }) time ({ 11 }) ( ({ 12 }) i.e. ({ 13 }) , ({ 14 }) 11 ({ 15 }) years ({ 16 }) ) ({ 17 }) . ({ 18 }) 
# Sentence pair (3164) source length 47 target length 42 alignment score : 5.24023e-22
Thus , besides facial variations caused by enviromental conditions at the time of recording ( e.g. , illumination , pose , viewpoint ) in each face-track , face-tracks of a character themself also contain biological variation of the character during time . 
NULL ({ 27 }) Thus ({ 1 }) , ({ 2 }) besides ({ 3 }) facial ({ 4 }) variations ({ 5 }) in ({ 24 }) each ({ 25 }) face ({ }) track ({ 26 }) caused ({ 6 }) by ({ 7 }) the ({ }) environmental ({ 8 }) conditions ({ 9 }) at ({ 10 }) the ({ 11 }) time ({ 12 }) of ({ 13 }) recording ({ 14 }) ( ({ 15 }) e.g. ({ 16 }) , ({ 17 }) illumination ({ 18 }) , ({ 19 }) pose ({ 20 }) , ({ 21 }) viewpoint ({ 22 }) ) ({ 23 }) , ({ }) the ({ }) face ({ }) tracks ({ 28 }) of ({ 29 }) the ({ 30 }) character ({ 31 }) themselves ({ 32 }) also ({ 33 }) reflect ({ 34 }) the ({ }) biological ({ 35 }) variations ({ 36 }) of ({ 37 }) the ({ 38 }) character ({ 39 }) over ({ 40 }) time; ({ 41 }) . ({ 42 }) 
# Sentence pair (3165) source length 20 target length 20 alignment score : 3.35013e-06
For instance , a character may look older after several years ( see Figure 8 , for example ) . 
NULL ({ }) for ({ 1 }) instance ({ 2 }) , ({ 3 }) a ({ 4 }) character ({ 5 }) may ({ 6 }) look ({ 7 }) older ({ 8 }) after ({ 9 }) several ({ 10 }) years ({ 11 }) ( ({ 12 }) see ({ 13 }) Figure ({ 14 }) 8 ({ 15 }) , ({ 16 }) for ({ 17 }) example ({ 18 }) ) ({ 19 }) . ({ 20 }) 
# Sentence pair (3166) source length 14 target length 14 alignment score : 1.45559e-10
Due to those reasons , matching faces in NHKNews7 becomes more challenging , . 
NULL ({ 2 }) For ({ 1 }) these ({ 3 }) reasons ({ 4 }) , ({ 5 }) matching ({ 6 }) faces ({ 7 }) in ({ 8 }) NHKNews7 ({ 9 }) becomes ({ 10 }) more ({ 11 }) challenging ({ 12 }) , ({ 13 }) which ({ }) . ({ 14 }) 
# Sentence pair (3167) source length 11 target length 12 alignment score : 1.52799e-11
It results in drops of MAP( s ) of all evaluated approaches. 
NULL ({ 5 }) resulted ({ 1 2 }) in ({ 3 }) decreased ({ 4 }) MAP( ({ 6 }) s ({ 7 }) ) ({ 8 }) for ({ 9 }) all ({ 10 }) the ({ }) evaluated ({ 11 }) approaches. ({ 12 }) 
# Sentence pair (3168) source length 34 target length 33 alignment score : 7.17862e-10
A clear and consistent observation from both datasets is that pair:min ( i.e. , min-min ) always achieves the best MAPs , which are 76.54% and 60.99% on two dataset , respectively . 
NULL ({ }) A ({ 1 }) clear ({ 2 }) and ({ 3 }) consistent ({ 4 }) observation ({ 5 }) from ({ 6 }) both ({ 7 }) datasets ({ 8 }) is ({ 9 }) that ({ 10 }) pair:min ({ 11 }) ( ({ 12 }) i.e. ({ 13 }) , ({ 14 }) min-min ({ 15 }) ) ({ 16 }) always ({ 17 }) achieves ({ 18 }) the ({ 19 }) best ({ 20 }) MAPs ({ 21 }) , ({ 22 }) which ({ 23 }) are ({ 24 }) 76.54% ({ 25 }) and ({ 26 }) 60.99% ({ 27 }) in ({ 28 }) the ({ }) two ({ 29 }) datasets ({ 30 }) , ({ 31 }) respectively ({ 32 }) . ({ 33 }) 
# Sentence pair (3169) source length 14 target length 16 alignment score : 2.46699e-20
Among several distance types , L1 is the optimal one to be used with pair:min . 
NULL ({ 12 }) Among ({ 1 }) the ({ }) distance ({ 3 }) types ({ 4 }) , ({ 5 }) L1 ({ 2 6 10 13 }) is ({ 7 }) the ({ 8 }) optimal ({ 9 }) for ({ 11 }) use ({ }) with ({ 14 }) pair:min ({ 15 }) . ({ 16 }) 
# Sentence pair (3170) source length 8 target length 8 alignment score : 4.05448e-09
A reasonable replacement can be Euclidean distance . 
NULL ({ 5 }) A ({ 1 }) reasonable ({ 2 }) replacement ({ 3 }) is ({ 4 }) the ({ }) Euclidean ({ 6 }) distance ({ 7 }) . ({ 8 }) 
# Sentence pair (3171) source length 19 target length 17 alignment score : 4.34895e-06
However , there is a minor accuracy gap between pair:min using L1 and pair:min using Euclidean . 
NULL ({ }) However ({ 1 }) , ({ 2 }) there ({ 3 }) is ({ 4 }) a ({ 5 }) minor ({ 6 }) accuracy ({ 7 }) gap ({ 8 }) between ({ 9 }) pair:min ({ 10 }) using ({ 11 }) L1 ({ 12 }) and ({ 13 }) pair:min ({ 14 }) using ({ 15 }) the ({ }) Euclidean ({ 16 }) distance ({ }) . ({ 17 }) 
# Sentence pair (3172) source length 20 target length 18 alignment score : 4.35463e-07
And , computing Euclidean distance between two feature vectors is more expensive than computing their L1 distance . 
NULL ({ }) In ({ }) addition ({ 1 }) , ({ 2 }) computing ({ 3 }) the ({ }) Euclidean ({ 4 }) distance ({ 5 }) between ({ 6 }) two ({ 7 }) feature ({ 8 }) vectors ({ 9 }) is ({ 10 }) more ({ 11 }) expensive ({ 12 }) than ({ 13 }) computing ({ 14 }) their ({ 15 }) L1 ({ 16 }) distance ({ 17 }) . ({ 18 }) 
# Sentence pair (3173) source length 11 target length 11 alignment score : 0.00802459
The results also show that pair:min is better than pair:mean . 
NULL ({ }) The ({ 1 }) results ({ 2 }) also ({ 3 }) show ({ 4 }) that ({ 5 }) pair:min ({ 6 }) is ({ 7 }) better ({ 8 }) than ({ 9 }) pair:mean ({ 10 }) . ({ 11 }) 
# Sentence pair (3174) source length 20 target length 19 alignment score : 3.5906e-08
This is because pair:mean uses the mean of all pair-wise distances between two face-tracks as their similarity score . 
NULL ({ }) This ({ 1 }) is ({ 2 }) because ({ 3 }) pair:mean ({ 4 }) uses ({ 5 }) the ({ 6 }) mean ({ 7 }) of ({ 8 }) all ({ 9 }) pair-wise ({ 10 }) distances ({ 11 }) between ({ 12 }) two ({ 13 }) face ({ }) tracks ({ 14 }) as ({ 15 }) the ({ 16 }) similarity ({ 17 }) score ({ 18 }) . ({ 19 }) 
# Sentence pair (3175) source length 13 target length 13 alignment score : 0.00260407
By computing the mean , pair:mean reduces the effect of noisy pairs . 
NULL ({ }) By ({ 1 }) computing ({ 2 }) the ({ 3 }) mean ({ 4 }) , ({ 5 }) pair:mean ({ 6 }) reduces ({ 7 }) the ({ 8 }) effect ({ 9 }) of ({ 10 }) noisy ({ 11 }) pairs ({ 12 }) . ({ 13 }) 
# Sentence pair (3176) source length 30 target length 29 alignment score : 7.96345e-13
At the same time , it eliminates the influence of pairs containing identical faces , which can help to instantly determine they are belong to the same character . 
NULL ({ 23 }) At ({ 1 }) the ({ 2 }) same ({ 3 }) time ({ 4 }) , ({ 5 }) it ({ 6 }) eliminates ({ 7 }) the ({ 8 }) influence ({ 9 }) of ({ 10 }) pairs ({ 11 }) containing ({ 12 }) identical ({ 13 }) faces ({ 14 }) , ({ 15 }) which ({ 16 }) can ({ 17 }) help ({ 18 }) to ({ 19 }) instantly ({ 20 }) determine ({ 21 }) that ({ }) the ({ }) faces ({ 22 }) belong ({ 24 }) to ({ 25 }) the ({ 26 }) same ({ 27 }) character ({ 28 }) . ({ 29 }) 
# Sentence pair (3177) source length 20 target length 19 alignment score : 2.52083e-07
Thus , discriminative power of the computed similarity score is reduced , compared to one computed by pair:min . 
NULL ({ }) Thus ({ 1 }) , ({ 2 }) the ({ }) discriminative ({ 3 }) power ({ 4 }) of ({ 5 }) the ({ 6 }) computed ({ 7 }) similarity ({ 8 }) score ({ 9 }) is ({ 10 }) reduced ({ 11 }) , ({ 12 }) compared ({ 13 }) to ({ 14 }) that ({ 15 }) computed ({ 16 }) by ({ 17 }) pair:min ({ 18 }) . ({ 19 }) 
# Sentence pair (3178) source length 11 target length 11 alignment score : 1.64587e-06
It causes the gap of MAPs between pair:min and pair:min . 
NULL ({ }) This ({ 1 }) causes ({ 2 }) the ({ 3 }) difference ({ 4 }) in ({ 5 }) MAPs ({ 6 }) between ({ 7 }) pair:min ({ 8 }) and ({ 9 }) pair:min ({ 10 }) . ({ 11 }) 
# Sentence pair (3179) source length 21 target length 21 alignment score : 1.16661e-10
More generally , this explains why such a gap between pair:min and pair:mean on NHKNews7 is larger than on Trecvid . 
NULL ({ }) More ({ 1 }) generally ({ 2 }) , ({ 3 }) this ({ 4 }) explains ({ 5 }) why ({ 6 }) such ({ 7 }) a ({ 8 }) gap ({ 9 }) between ({ 10 }) pair:min ({ 11 }) and ({ 12 }) pair:mean ({ 13 }) is ({ 16 }) larger ({ 17 }) in ({ 14 }) NHKNews7 ({ 15 }) than ({ 18 }) in ({ 19 }) Trecvid ({ 20 }) . ({ 21 }) 
# Sentence pair (3180) source length 42 target length 38 alignment score : 7.44948e-12
Since the average length of face-tracks on NHKNews7 is longer ( i.e. , each face-track contains more sample faces of a character ) , there is more chance that two face-tracks of the same character contain identical faces. 
NULL ({ }) Because ({ 1 }) the ({ 2 }) average ({ 3 }) length ({ 4 }) of ({ 5 }) face ({ }) tracks ({ 6 }) on ({ 7 }) NHKNews7 ({ 8 }) is ({ 9 }) longer ({ 10 }) ( ({ 11 }) i.e. ({ 12 }) , ({ 13 }) each ({ 14 }) face ({ }) track ({ 15 }) contains ({ 16 }) more ({ 17 }) sample ({ 18 }) faces ({ 19 }) of ({ 20 }) a ({ 21 }) character ({ 22 }) ) ({ 23 }) , ({ 24 }) there ({ 25 }) is ({ 26 }) a ({ }) greater ({ 27 }) chance ({ 28 }) that ({ 29 }) two ({ 30 }) face ({ }) tracks ({ 31 }) of ({ 32 }) the ({ 33 }) same ({ 34 }) character ({ 35 }) contain ({ 36 }) identical ({ 37 }) faces. ({ 38 }) 
# Sentence pair (3181) source length 11 target length 11 alignment score : 0.00402186
About our k-Faces , its MAP increases when k increases . 
NULL ({ }) Regarding ({ 1 }) our ({ 2 }) k-Faces ({ 3 }) , ({ 4 }) its ({ 5 }) MAP ({ 6 }) increases ({ 7 }) when ({ 8 }) k ({ 9 }) increases ({ 10 }) . ({ 11 }) 
# Sentence pair (3182) source length 18 target length 17 alignment score : 0.000199644
Between k-Faces.Temporal and k-Faces.KMeans , the impact of k on MAP of k-Faces.KMeans is less significant . 
NULL ({ }) Between ({ 1 }) k-Faces.Temporal ({ 2 }) and ({ 3 }) k-Faces.KMeans ({ 4 }) , ({ 5 }) the ({ 6 }) impact ({ 7 }) of ({ 8 }) k ({ 9 }) on ({ 10 }) the ({ }) MAP ({ 11 }) of ({ 12 }) k-Faces.KMeans ({ 13 }) is ({ 14 }) less ({ 15 }) significant ({ 16 }) . ({ 17 }) 
# Sentence pair (3183) source length 30 target length 28 alignment score : 8.13008e-09
Since k-Faces.KMeans always use all faces in a facetrack for clustering and selecting centroids for representative faces , the final mean face is less sensitive to k . 
NULL ({ }) Because ({ 1 }) k-Faces.KMeans ({ 2 }) always ({ 3 }) uses ({ 4 }) all ({ 5 }) the ({ }) faces ({ 6 }) in ({ 7 }) a ({ 8 }) face ({ }) track ({ 9 }) for ({ 10 }) clustering ({ 11 }) and ({ 12 }) selecting ({ 13 }) centroids ({ 14 }) for ({ 15 }) representative ({ 16 }) faces ({ 17 }) , ({ 18 }) the ({ 19 }) final ({ 20 }) mean ({ 21 }) face ({ 22 }) is ({ 23 }) less ({ 24 }) sensitive ({ 25 }) to ({ 26 }) k ({ 27 }) . ({ 28 }) 
# Sentence pair (3184) source length 11 target length 12 alignment score : 3.88415e-07
On the contrary , k plays an important role in k-Faces.Temporal . 
NULL ({ 2 }) In ({ 1 }) contrast ({ 3 }) , ({ 4 }) k ({ 5 }) plays ({ 6 }) an ({ 7 }) important ({ 8 }) role ({ 9 }) in ({ 10 }) k-Faces.Temporal ({ 11 }) . ({ 12 }) 
# Sentence pair (3185) source length 16 target length 16 alignment score : 5.71393e-10
The higher k is set , the more representative faces of each facetrack are selected . 
NULL ({ 4 14 }) The ({ 1 }) higher ({ 2 }) the ({ }) k ({ 3 }) set ({ 5 }) , ({ 6 }) the ({ 7 }) more ({ 8 }) representative ({ 9 }) faces ({ 10 }) of ({ 11 }) each ({ 12 }) face ({ }) track ({ 13 }) selected ({ 15 }) . ({ 16 }) 
# Sentence pair (3186) source length 16 target length 15 alignment score : 6.73646e-05
Thus , the final mean face of each facetrack becomes more reliable and accurate . 
NULL ({ }) Thus ({ 1 }) , ({ 2 }) the ({ 3 }) final ({ 4 }) mean ({ 5 }) face ({ 6 }) of ({ 7 }) each ({ 8 }) face ({ }) track ({ 9 }) becomes ({ 10 }) more ({ 11 }) reliable ({ 12 }) and ({ 13 }) accurate ({ 14 }) . ({ 15 }) 
# Sentence pair (3187) source length 18 target length 18 alignment score : 0.000415375
The advantages of k-Faces.KMeans is that it can achieve high accuracy even when k is very small . 
NULL ({ }) The ({ 1 }) advantages ({ 2 }) of ({ 3 }) k-Faces.KMeans ({ 4 }) is ({ 5 }) that ({ 6 }) it ({ 7 }) can ({ 8 }) achieve ({ 9 }) high ({ 10 }) accuracy ({ 11 }) even ({ 12 }) when ({ 13 }) k ({ 14 }) is ({ 15 }) very ({ 16 }) small ({ 17 }) . ({ 18 }) 
# Sentence pair (3188) source length 24 target length 26 alignment score : 1.98938e-14
Meanwhile , its disadvantage is the expensive computational cost to perform clustering faces on a high dimensional feature space ( i.e. , 1937 dimensions ) . 
NULL ({ 10 }) However ({ 1 }) , ({ 2 }) its ({ 3 }) disadvantage ({ 4 }) is ({ 5 }) the ({ 6 }) high ({ 7 }) computational ({ 8 }) cost ({ 9 }) of ({ 11 }) clustering ({ 12 }) faces ({ 13 }) on ({ 14 }) a ({ 15 }) high-dimensional ({ 16 17 }) feature ({ 18 }) space ({ 19 }) ( ({ 20 }) i.e. ({ 21 }) , ({ 22 }) 1,937 ({ 23 }) dimensions ({ 24 }) ) ({ 25 }) . ({ 26 }) 
# Sentence pair (3189) source length 17 target length 17 alignment score : 0.000446289
When k is large enough , there is no substantial difference in MAP between k-Faces.KMeans and k-Faces.Temporal. 
NULL ({ }) When ({ 1 }) k ({ 2 }) is ({ 3 }) large ({ 4 }) enough ({ 5 }) , ({ 6 }) there ({ 7 }) is ({ 8 }) no ({ 9 }) substantial ({ 10 }) difference ({ 11 }) in ({ 12 }) MAP ({ 13 }) between ({ 14 }) k-Faces.KMeans ({ 15 }) and ({ 16 }) k-Faces.Temporal. ({ 17 }) 
# Sentence pair (3190) source length 20 target length 19 alignment score : 7.18312e-07
On both datasets , when k increases from 2 to 20 , MAPs of k-Faces approaches grow rapidly . 
NULL ({ }) In ({ 1 }) both ({ 2 }) datasets ({ 3 }) , ({ 4 }) when ({ 5 }) k ({ 6 }) increases ({ 7 }) from ({ 8 }) 2 ({ 9 }) to ({ 10 }) 20 ({ 11 }) , ({ 12 }) the ({ }) MAPs ({ 13 }) of ({ 14 }) k-Faces ({ 15 }) approaches ({ 16 }) grow ({ 17 }) rapidly ({ 18 }) . ({ 19 }) 
# Sentence pair (3191) source length 12 target length 10 alignment score : 3.27115e-09
However , theirs MAPs become stable from 20 afterwards . 
NULL ({ }) However ({ 1 }) , ({ 2 }) the ({ }) MAPs ({ 4 }) become ({ 5 }) stable ({ 6 }) from ({ 7 }) k ({ }) = ({ 9 }) 20 ({ 8 }) upward ({ 3 }) . ({ 10 }) 
# Sentence pair (3192) source length 38 target length 38 alignment score : 3.15772e-29
Since keep increasing k does not help to obtain imporant accuracy improvement but expensive computational cost , we select k = 20 to investigate the trade-off between accuracy and computational costs of k-Faces approaches compared to others . 
NULL ({ 8 9 12 }) Because ({ 1 }) further ({ 2 }) increasing ({ 3 }) k ({ 4 }) does ({ 5 }) not ({ 6 }) help ({ 7 }) improve ({ 10 }) accuracy ({ 11 }) but ({ 13 }) increases ({ 14 }) the ({ }) computational ({ 15 }) cost ({ 16 }) , ({ 17 }) we ({ 18 }) select ({ 19 }) k ({ 20 }) = ({ 21 }) 20 ({ 22 }) for ({ 23 }) investigating ({ 24 }) the ({ 25 }) trade-off ({ 26 }) between ({ 27 }) the ({ }) accuracy ({ 28 }) and ({ 29 }) computational ({ 30 }) cost ({ 31 }) of ({ 32 }) k-Faces ({ 33 }) approaches ({ 34 }) in ({ }) comparison ({ 35 }) to ({ 36 }) others ({ 37 }) . ({ 38 }) 
# Sentence pair (3193) source length 12 target length 14 alignment score : 8.09132e-17
We report MAP and processing time of each approach in the Table 5 . 
NULL ({ 10 }) Table ({ 12 }) 5 ({ 13 }) shows ({ 2 }) the ({ 11 }) MAP ({ 1 3 }) and ({ 4 }) processing ({ 5 }) time ({ 6 }) of ({ 7 }) each ({ 8 }) approach ({ 9 }) . ({ 14 }) 
# Sentence pair (3194) source length 12 target length 16 alignment score : 2.69965e-13
Processing time is separated into two parts , corresponding to preprocessing time and matching time . 
NULL ({ 10 }) Processing ({ 1 }) time ({ 2 }) is ({ 3 }) divided ({ 4 }) into ({ 5 }) two ({ 6 }) parts ({ 7 }) , ({ 8 }) preprocessing ({ 9 11 12 15 }) and ({ 13 }) matching ({ 14 }) . ({ 16 }) 
# Sentence pair (3195) source length 15 target length 11 alignment score : 1.39549e-09
Preprocessing time presents time required for preprocessing face-tracks before matching . 
NULL ({ }) The ({ }) preprocessing ({ 1 }) time ({ 2 }) refers ({ 3 }) to ({ }) the ({ }) time ({ 4 }) required ({ 5 }) to ({ 6 }) preprocess ({ 7 }) face ({ }) tracks ({ 8 }) before ({ 9 }) matching ({ 10 }) . ({ 11 }) 
# Sentence pair (3196) source length 19 target length 16 alignment score : 4.51523e-10
With k-Faces approaches , preprocessing facetracks includes selecting representative faces and computing their mean face . 
NULL ({ }) In ({ 1 }) k-Faces ({ 2 }) approaches ({ 3 }) , ({ 4 }) the ({ }) preprocessing ({ 5 }) of ({ }) face ({ }) tracks ({ 6 }) includes ({ 7 }) selecting ({ 8 }) representative ({ 9 }) faces ({ 10 }) and ({ 11 }) computing ({ 12 }) their ({ 13 }) mean ({ 14 }) face ({ 15 }) . ({ 16 }) 
# Sentence pair (3197) source length 13 target length 14 alignment score : 4.5003e-11
In MSM and CMSM , it indicates time for computing subspaces for face-tracks . 
NULL ({ 9 }) In ({ 1 }) MSM ({ 2 }) and ({ 3 }) CMSM ({ 4 }) , ({ 5 }) preprocessing ({ 6 8 }) includes ({ 7 }) computing ({ 10 }) subspaces ({ 11 }) for ({ 12 }) face ({ }) tracks ({ 13 }) . ({ 14 }) 
# Sentence pair (3198) source length 10 target length 9 alignment score : 1.25269e-06
Matching time is averaged for one query run . 
NULL ({ }) The ({ }) matching ({ 1 }) time ({ 2 }) is ({ 3 }) averaged ({ 4 }) over ({ 5 }) one ({ 6 }) query ({ 7 }) run ({ 8 }) . ({ 9 }) 
# Sentence pair (3199) source length 6 target length 4 alignment score : 1.42816e-07
Time unit is second. 
NULL ({ }) The ({ 1 }) time ({ }) unit ({ 2 }) used ({ }) is ({ 3 }) seconds. ({ 4 }) 
# Sentence pair (3200) source length 28 target length 27 alignment score : 1.42547e-11
According to Table 5 , k-Faces.KMeans and k- Faces.Temporal achieve almost equal accuracy and consume the same amount of time for one query on both datasets . 
NULL ({ }) As ({ 1 }) shown ({ 2 }) in ({ }) Table ({ 3 }) 5 ({ 4 }) , ({ 5 }) k-Faces.KMeans ({ 6 }) and ({ 7 }) k- ({ 8 }) Faces.Temporal ({ 9 }) achieve ({ 10 }) almost ({ 11 }) equal ({ 12 }) accuracy ({ 13 }) and ({ 14 }) consume ({ 15 }) the ({ 16 }) same ({ 17 }) amount ({ 18 }) of ({ 19 }) time ({ 20 }) for ({ 21 }) one ({ 22 }) query ({ 23 }) in ({ 24 }) both ({ 25 }) datasets ({ 26 }) . ({ 27 }) 
# Sentence pair (3201) source length 26 target length 25 alignment score : 1.29762e-09
However , k-Faces.Temporal is hundreds times ( 240 times on Trecvid and 360 times on NHKNews7 ) faster than k-Faces.Temporal in the preprocessing phase . 
NULL ({ }) However ({ 1 }) , ({ 2 }) k-Faces.Temporal ({ 3 }) is ({ 4 }) hundreds ({ 5 }) of ({ }) times ({ 6 }) ( ({ 7 }) 240 ({ 8 }) times ({ 9 }) in ({ 10 }) Trecvid ({ 11 }) and ({ 12 }) 360 ({ 13 }) times ({ 14 }) in ({ 15 }) NHKNews7 ({ 16 }) ) ({ 17 }) faster ({ 18 }) than ({ 19 }) k-Faces.Temporal ({ 20 }) in ({ 21 }) the ({ 22 }) preprocessing ({ 23 }) phase ({ 24 }) . ({ 25 }) 
# Sentence pair (3202) source length 26 target length 11 alignment score : 3.20891e-25
This suggest that , selecting presentative faces based on tempo . 
NULL ({ }) This ({ 1 }) suggests ({ 2 }) that ({ 3 }) in ({ }) terms ({ }) of ({ }) both ({ }) accuracy ({ }) and ({ }) efficiency ({ }) , ({ 4 }) selecting ({ 5 }) representative ({ 6 }) faces ({ 7 }) based ({ 8 }) on ({ 9 }) temporal ({ 10 }) sampling ({ }) is ({ }) better ({ }) than ({ }) that ({ }) based ({ }) on ({ }) clustering ({ }) . ({ 11 }) 
# Sentence pair (3203) source length 1 target length 1 alignment score : 0.000250019
ral 
NULL ({ }) , ({ 1 }) 
# Sentence pair (3204) source length 35 target length 33 alignment score : 3.6081e-11
Compared to state-of-the-art approaches , our k- Faces.Temporal is thousands times faster than the best approach , which is pair:min , and hundred times faster than MSM and CMSM on both datasets . 
NULL ({ }) Compared ({ 1 }) to ({ 2 }) state-of-the-art ({ 3 }) approaches ({ 4 }) , ({ 5 }) our ({ 6 }) k- ({ 7 }) Faces.Temporal ({ 8 }) is ({ 9 }) thousands ({ 10 }) of ({ }) times ({ 11 }) faster ({ 12 }) than ({ 13 }) the ({ 14 }) best ({ 15 }) approach ({ 16 }) , ({ 17 }) which ({ 18 }) is ({ 19 }) pair:min ({ 20 }) , ({ 21 }) and ({ 22 }) hundreds ({ 23 }) of ({ }) times ({ 24 }) faster ({ 25 }) than ({ 26 }) MSM ({ 27 }) and ({ 28 }) CMSM ({ 29 }) in ({ 30 }) both ({ 31 }) datasets ({ 32 }) . ({ 33 }) 
# Sentence pair (3205) source length 20 target length 19 alignment score : 1.65391e-06
In terms of accuracy , k-Faces take second place , with 73.65% on Trevid dataset , after pair:min . 
NULL ({ }) In ({ 1 }) terms ({ 2 }) of ({ 3 }) accuracy ({ 4 }) , ({ 5 }) k-Faces ({ 6 }) takes ({ 7 }) second ({ 8 }) place ({ 9 }) , ({ 10 }) with ({ 11 }) 73.65% ({ 12 }) in ({ 13 }) the ({ }) Trevid ({ 14 }) dataset ({ 15 }) , ({ 16 }) after ({ 17 }) pair:min ({ 18 }) . ({ 19 }) 
# Sentence pair (3206) source length 12 target length 10 alignment score : 1.3503e-14
The gap with pair:min is 2.89% difference in MAP . 
NULL ({ }) The ({ 1 }) difference ({ 2 }) in ({ 8 }) MAP ({ 9 }) between ({ }) our ({ 6 }) approach ({ 7 }) and ({ }) pair:min ({ 4 }) is ({ 5 }) 2.89% ({ 3 }) . ({ 10 }) 
# Sentence pair (3207) source length 20 target length 18 alignment score : 2.92931e-07
Meanwhile , it is significantly better than MSM and CMSM , which respectively achieve 69.20% and 64.62% . 
NULL ({ }) Meanwhile ({ 1 }) , ({ 2 }) k- ({ }) Faces.Temporal ({ 3 }) is ({ 4 }) significantly ({ 5 }) better ({ 6 }) than ({ 7 }) MSM ({ 8 }) and ({ 9 }) CMSM ({ 10 }) , ({ 11 }) which ({ 12 }) respectively ({ 13 }) achieved ({ 14 }) 69.20% ({ 15 }) and ({ 16 }) 64.62% ({ 17 }) accuracy ({ }) . ({ 18 }) 
# Sentence pair (3208) source length 18 target length 20 alignment score : 1.27999e-14
On NHKNews7 dataset , our k-Faces.Temporal is still better than CMSM , but is worse than pair:min and MSM . 
NULL ({ 14 }) In ({ 1 }) the ({ }) NHKNews7 ({ 2 }) dataset ({ 3 }) , ({ 4 }) k-Faces.Temporal ({ 5 6 }) is ({ 7 }) better ({ 8 9 }) than ({ 10 }) CMSM ({ 11 }) , ({ 12 }) but ({ 13 }) worse ({ 15 }) than ({ 16 }) pair:min ({ 17 }) and ({ 18 }) MSM ({ 19 }) . ({ 20 }) 
# Sentence pair (3209) source length 20 target length 22 alignment score : 2.21845e-21
One may concern that why MSM perform poorly on Trecvid dataset , but it is superior to our k-Faces.Temporal on NHKNews7 . 
NULL ({ 4 14 }) One ({ 1 }) may ({ 2 }) question ({ 3 }) why ({ 5 }) MSM ({ 6 }) performed ({ 7 }) poorly ({ 8 }) in ({ 9 }) the ({ }) Trecvid ({ 10 }) dataset ({ 11 }) , ({ 12 }) but ({ 13 }) was ({ 15 }) superior ({ 16 }) to ({ 17 }) k-Faces.Temporal ({ 18 19 }) in ({ 20 }) NHKNews7 ({ 21 }) . ({ 22 }) 
# Sentence pair (3210) source length 24 target length 19 alignment score : 3.73789e-22
This is due to the fact that face-tracks on NHKNews7 dataset is larger than those on Trecvid dataset . 
NULL ({ 4 }) The ({ }) reason ({ 1 }) for ({ 3 }) this ({ }) is ({ 2 }) the ({ 5 }) fact ({ 6 }) that ({ 7 }) the ({ }) face ({ }) tracks ({ 8 }) in ({ 9 }) the ({ }) NHKNews7 ({ 10 }) dataset ({ 11 }) are ({ 12 }) larger ({ 13 }) than ({ 14 }) those ({ 15 }) in ({ 16 }) the ({ }) Trecvid ({ 17 }) dataset ({ 18 }) . ({ 19 }) 
# Sentence pair (3211) source length 18 target length 17 alignment score : 0.000240516
Therefore , more sample faces in each face-track can be used to obtain a reliable subspace . 
NULL ({ }) Therefore ({ 1 }) , ({ 2 }) more ({ 3 }) sample ({ 4 }) faces ({ 5 }) in ({ 6 }) each ({ 7 }) face ({ }) track ({ 8 }) can ({ 9 }) be ({ 10 }) used ({ 11 }) to ({ 12 }) obtain ({ 13 }) a ({ 14 }) reliable ({ 15 }) subspace ({ 16 }) . ({ 17 }) 
# Sentence pair (3212) source length 24 target length 23 alignment score : 6.18456e-13
As expected , the results in this experiment demonstrate that our proposed approach is extremely efficient while archiving comparable performance with state-of-the-art approachesf. 
NULL ({ 6 }) As ({ 1 }) expected ({ 2 }) , ({ 3 }) the ({ 4 }) results ({ 5 }) of ({ }) this ({ 7 }) experiment ({ 8 }) show ({ 9 }) that ({ 10 }) our ({ 11 }) proposed ({ 12 }) approach ({ 13 }) is ({ 14 }) extremely ({ 15 }) efficient ({ 16 }) while ({ 17 }) achieving ({ 18 }) comparable ({ 19 }) performance ({ 20 }) with ({ 21 }) state-of-the-art ({ 22 }) approaches ({ 23 }) . ({ }) 
# Sentence pair (3213) source length 14 target length 14 alignment score : 0.000131408
In this paper , we investigate face retrieval on large-scale news video datasets . 
NULL ({ }) In ({ 1 }) this ({ 2 }) paper ({ 3 }) , ({ 4 }) we ({ 5 }) investigate ({ 6 }) face ({ 7 }) retrieval ({ 8 }) in ({ 9 }) large-scale ({ 10 }) news ({ 11 }) video ({ 12 }) datasets ({ 13 }) . ({ 14 }) 
# Sentence pair (3214) source length 5 target length 5 alignment score : 0.00398101
Our contributions is 3-fold . 
NULL ({ }) Our ({ 1 }) contribution ({ 2 }) is ({ 3 }) threefold ({ 4 }) . ({ 5 }) 
# Sentence pair (3215) source length 21 target length 18 alignment score : 1.15103e-08
Firstly , we presented practical problems when a tracker is used to extract face-tracks in news videos . 
NULL ({ }) First ({ 1 }) , ({ 2 }) we ({ 3 }) present ({ 4 }) the ({ }) practical ({ 5 }) problems ({ 6 }) encountered ({ 7 }) when ({ }) a ({ 8 }) tracker ({ 9 }) is ({ 10 }) used ({ 11 }) to ({ 12 }) extract ({ 13 }) face ({ }) tracks ({ 14 }) in ({ 15 }) news ({ 16 }) videos ({ 17 }) . ({ 18 }) 
# Sentence pair (3216) source length 19 target length 18 alignment score : 1.92967e-10
Based on that , we introduce techniques and solutions to bypass the problems for robust face-track extraction . 
NULL ({ }) Based ({ 1 }) on ({ 2 }) these ({ 3 }) , ({ 4 }) we ({ 5 }) introduce ({ 6 }) techniques ({ 7 }) and ({ 8 }) solutions ({ 9 }) to ({ 10 }) overcome ({ 11 }) these ({ 12 }) problems ({ 13 }) to ({ }) achieve ({ 14 }) robust ({ 15 }) face-track ({ 16 }) extraction ({ 17 }) . ({ 18 }) 
# Sentence pair (3217) source length 24 target length 24 alignment score : 3.33895e-11
Secondly , we present an approach for face-track matching which significantly reduces the computational cost and achive competitive performance compared to state-of-the-art approaches . 
NULL ({ }) Second ({ 1 }) , ({ 2 }) we ({ 3 }) present ({ 4 }) an ({ 5 }) approach ({ 6 }) for ({ 7 }) face-track ({ 8 }) matching ({ 9 }) that ({ 10 }) significantly ({ 11 }) reduces ({ 12 }) the ({ 13 }) computational ({ 14 }) cost ({ 15 }) while ({ 16 }) achieving ({ 17 }) competitive ({ 18 }) performance ({ 19 }) compared ({ 20 }) with ({ 21 }) state-of-the-art ({ 22 }) approaches ({ 23 }) . ({ 24 }) 
# Sentence pair (3218) source length 28 target length 25 alignment score : 7.46361e-18
Thirdly , we prepare , evaluate state-of-the-art face retreival approaches , and publish real-world face-track datasets whose scale have not been considered in literature ever. 
NULL ({ }) Third ({ 1 }) , ({ 2 }) we ({ 3 }) prepare ({ 4 }) datasets ({ }) , ({ 5 }) evaluate ({ 6 }) state-of-the-art ({ 7 }) face ({ 8 }) retrieval ({ 9 }) approaches ({ 10 }) , ({ 11 }) and ({ 12 }) publish ({ 13 }) real-world ({ 14 }) face-track ({ 15 }) datasets ({ 16 }) of ({ }) such ({ 17 }) scales ({ 18 }) that ({ }) have ({ 19 }) never ({ 20 }) been ({ 21 }) considered ({ 22 }) in ({ 23 }) the ({ }) literature. ({ 24 25 }) 
# Sentence pair (3219) source length 8 target length 8 alignment score : 0.0577452
Recommend-Me : recommending query regions for image search 
NULL ({ }) Recommend-Me ({ 1 }) : ({ 2 }) recommending ({ 3 }) query ({ 4 }) regions ({ 5 }) for ({ 6 }) image ({ 7 }) search ({ 8 }) 
# Sentence pair (3220) source length 24 target length 25 alignment score : 2.34524e-10
This paper presents a novel recommendation system , named Recommend-Me , to faciliate users in searching and exploring images of an unknown image database . 
NULL ({ 21 }) This ({ 1 }) paper ({ 2 }) presents ({ 3 }) a ({ 4 }) novel ({ 5 }) recommendation ({ 6 }) system ({ 7 }) , ({ 8 }) named ({ 9 }) Recommend-Me ({ 10 }) , ({ 11 }) to ({ 12 }) facilitate ({ 13 }) users ({ 14 }) in ({ 15 }) searching ({ 16 }) and ({ 17 }) exploring ({ 18 }) images ({ 19 }) in ({ 20 }) unknown ({ 22 }) image ({ 23 }) databases ({ 24 }) . ({ 25 }) 
# Sentence pair (3221) source length 14 target length 14 alignment score : 0.000106244
Given an initial query image , Recommend-Me automatically introduces its recommendations to users . 
NULL ({ }) Given ({ 1 }) an ({ 2 }) initial ({ 3 }) query ({ 4 }) image ({ 5 }) , ({ 6 }) Recommend-Me ({ 7 }) automatically ({ 8 }) shows ({ 9 }) its ({ 10 }) recommendations ({ 11 }) to ({ 12 }) users ({ 13 }) . ({ 14 }) 
# Sentence pair (3222) source length 18 target length 18 alignment score : 0.000437267
The recommendations indicate which and how frequent items in the initial query image occur in the database . 
NULL ({ }) The ({ 1 }) recommendations ({ 2 }) indicate ({ 3 }) which ({ 4 }) and ({ 5 }) how ({ 6 }) frequent ({ 7 }) items ({ 8 }) in ({ 9 }) the ({ 10 }) initial ({ 11 }) query ({ 12 }) image ({ 13 }) occur ({ 14 }) in ({ 15 }) the ({ 16 }) database ({ 17 }) . ({ 18 }) 
# Sentence pair (3223) source length 15 target length 14 alignment score : 9.73406e-09
So that , users can make their own decisions before any actual search . 
NULL ({ }) In ({ 1 }) this ({ 2 }) way ({ }) , ({ 3 }) users ({ 4 }) can ({ 5 }) make ({ 6 }) their ({ 7 }) own ({ 8 }) decisions ({ 9 }) before ({ 10 }) any ({ 11 }) actual ({ 12 }) search ({ 13 }) . ({ 14 }) 
# Sentence pair (3224) source length 16 target length 16 alignment score : 8.4649e-05
If there is a recommendation matched their search intention , relevant search results are ensured . 
NULL ({ }) If ({ 1 }) there ({ 2 }) is ({ 3 }) a ({ 4 }) recommendation ({ 5 }) matching ({ 6 }) their ({ 7 }) search ({ 8 }) intention ({ 9 }) , ({ 10 }) relevant ({ 11 }) search ({ 12 }) results ({ 13 }) are ({ 14 }) ensured ({ 15 }) . ({ 16 }) 
# Sentence pair (3225) source length 15 target length 15 alignment score : 0.00601149
Otherwise , users should refine their initial query image for a better query sample . 
NULL ({ }) Otherwise ({ 1 }) , ({ 2 }) users ({ 3 }) should ({ 4 }) refine ({ 5 }) their ({ 6 }) initial ({ 7 }) query ({ 8 }) image ({ 9 }) for ({ 10 }) a ({ 11 }) better ({ 12 }) query ({ 13 }) sample ({ 14 }) . ({ 15 }) 
# Sentence pair (3226) source length 16 target length 16 alignment score : 0.00369219
Or , they can start exploring the database by using the recommended items as hints . 
NULL ({ }) Or ({ 1 }) , ({ 2 }) they ({ 3 }) can ({ 4 }) start ({ 5 }) exploring ({ 6 }) the ({ 7 }) database ({ 8 }) by ({ 9 }) using ({ 10 }) the ({ 11 }) recommended ({ 12 }) items ({ 13 }) as ({ 14 }) hints ({ 15 }) . ({ 16 }) 
# Sentence pair (3227) source length 12 target length 12 alignment score : 0.00490504
Recommend-Me helps users to avoid unnecessary trials and poor searching experiences . 
NULL ({ }) Recommend-Me ({ 1 }) helps ({ 2 }) users ({ 3 }) to ({ 4 }) avoid ({ 5 }) unnecessary ({ 6 }) trials ({ 7 }) and ({ 8 }) poor ({ 9 }) searching ({ 10 }) experiences ({ 11 }) . ({ 12 }) 
# Sentence pair (3228) source length 23 target length 22 alignment score : 7.10938e-09
We introduce an efficient approach for Recommend-Me to deal with quantifying occurences of multiple candidate items over images of the database . 
NULL ({ }) We ({ 1 }) describe ({ 2 }) an ({ 3 }) efficient ({ 4 }) approach ({ 5 }) for ({ 6 }) Recommend-Me ({ 7 }) to ({ 8 }) deal ({ 9 }) with ({ 10 }) quantifying ({ 11 }) occurrences ({ 12 }) of ({ 13 }) multiple ({ 14 }) candidate ({ 15 }) items ({ 16 }) in ({ 17 }) the ({ }) images ({ 18 }) of ({ 19 }) the ({ 20 }) database ({ 21 }) . ({ 22 }) 
# Sentence pair (3229) source length 49 target length 50 alignment score : 6.15601e-14
Instead of scanning the database for each candidate item repspectively , the approach enumerate occurences of multiple candidate items simultaneously by investigating pairs of highly similar regions , knowing one pair is formed by a region in the intial image and a region in an image of the database . 
NULL ({ }) Instead ({ 1 }) of ({ 2 }) scanning ({ 3 }) the ({ 4 }) database ({ 5 }) for ({ 6 }) each ({ 7 }) candidate ({ 8 }) item ({ 9 10 }) , ({ 11 }) the ({ 12 }) approach ({ 13 }) enumerate ({ 14 }) occurrences ({ 15 }) of ({ 16 }) multiple ({ 17 }) candidate ({ 18 }) items ({ 19 }) simultaneously ({ 20 }) by ({ 21 }) investigating ({ 22 }) pairs ({ 23 }) of ({ 24 }) highly ({ 25 }) similar ({ 26 }) regions ({ 27 }) , ({ 28 }) knowing ({ 29 }) one ({ 30 }) pair ({ 31 }) is ({ 32 }) formed ({ 33 }) by ({ 34 }) a ({ 35 }) region ({ 36 }) in ({ 37 }) the ({ 38 }) initial ({ 39 }) image ({ 40 }) and ({ 41 }) a ({ 42 }) region ({ 43 }) in ({ 44 }) an ({ 45 }) image ({ 46 }) of ({ 47 }) the ({ 48 }) database ({ 49 }) . ({ 50 }) 
# Sentence pair (3230) source length 22 target length 22 alignment score : 3.04665e-05
We formulate the problem of finding such pairs as an opmization problem , which can be solved by a branch-and-bound algorithm . 
NULL ({ }) We ({ 1 }) formulate ({ 2 }) the ({ 3 }) problem ({ 4 }) of ({ 5 }) finding ({ 6 }) such ({ 7 }) pairs ({ 8 }) as ({ 9 }) an ({ 10 }) optimization ({ 11 }) problem ({ 12 }) , ({ 13 }) which ({ 14 }) can ({ 15 }) be ({ 16 }) solved ({ 17 }) by ({ 18 }) a ({ 19 }) branch-and-bound ({ 20 }) algorithm ({ 21 }) . ({ 22 }) 
# Sentence pair (3231) source length 22 target length 23 alignment score : 2.87065e-11
Experiments conducted on a real-life and publicly available dataset demonstrate the efficiency , the robustness and a promissing application of our system . 
NULL ({ 14 17 }) Experiments ({ 1 }) conducted ({ 2 }) on ({ 3 }) a ({ 4 }) real-life ({ 5 }) and ({ 6 }) publicly ({ 7 }) available ({ 8 }) dataset ({ 9 }) demonstrate ({ 10 }) the ({ 11 }) efficiency ({ 12 }) , ({ 13 }) robustness ({ 15 }) , ({ }) and ({ 16 }) promising ({ 18 }) application ({ 19 }) of ({ 20 }) our ({ 21 }) system ({ 22 }) . ({ 23 }) 
# Sentence pair (3232) source length 22 target length 21 alignment score : 6.07028e-12
With the advances of modern technology , a large amount of digital images nowadays can be created and stored easily . 
NULL ({ }) Thanks ({ 1 }) to ({ }) the ({ 2 }) advances ({ 3 }) of ({ 4 }) modern ({ 5 }) technology ({ 6 }) , ({ 7 }) a ({ 8 }) large ({ 9 }) amount ({ 10 }) of ({ 11 }) digital ({ 12 }) images ({ 13 }) can ({ 15 }) be ({ 16 }) easily ({ 20 }) created ({ 17 }) and ({ 18 }) stored ({ 19 }) nowadays ({ 14 }) . ({ 21 }) 
# Sentence pair (3233) source length 22 target length 36 alignment score : 2.99194e-65
As a result , the exponential growth of image repositories creates the urgent needs for searching images . Because of its importance and wide applications , image search has attracted more interest in recent years . 
NULL ({ 4 5 20 26 33 36 }) The ({ 1 }) resulting ({ 2 3 23 32 }) exponential ({ 6 21 24 30 34 }) growth ({ 7 19 22 25 31 35 }) of ({ 8 }) image ({ 27 }) repositories ({ 10 28 }) , ({ }) however ({ 9 }) , ({ }) has ({ 29 }) created ({ 11 }) an ({ 12 }) urgent ({ 13 }) need ({ 14 }) for ({ 15 }) effective ({ }) ways ({ }) of ({ }) searching ({ 16 }) images ({ 17 }) . ({ 18 }) 
# Sentence pair (3234) source length 41 target length 25 alignment score : 2.71699e-37
In a typical scenario of image search , users supply a query item which is usually represented by a region cropped from an image . 
NULL ({ 8 }) Moreover ({ }) , ({ }) image ({ 6 }) search ({ 7 }) has ({ }) gained ({ }) interest ({ }) in ({ }) recent ({ }) years ({ }) because ({ }) of ({ 5 }) its ({ }) importance ({ }) and ({ }) wide ({ }) range ({ }) of ({ }) applications ({ }) . ({ }) In ({ 1 }) a ({ 2 }) typical ({ 3 }) scenario ({ 4 }) , ({ }) users ({ 9 }) supply ({ 10 }) a ({ 11 }) query ({ 12 }) item ({ 13 }) , ({ }) which ({ 14 }) is ({ 15 }) usually ({ 16 }) a ({ 19 }) region ({ 20 }) cropped ({ 17 18 21 }) from ({ 22 }) an ({ 23 }) image ({ 24 }) . ({ 25 }) 
# Sentence pair (3235) source length 15 target length 15 alignment score : 0.00623847
The search system then returns a list of relevant images retrieved from a database . 
NULL ({ }) The ({ 1 }) search ({ 2 }) system ({ 3 }) then ({ 4 }) returns ({ 5 }) a ({ 6 }) list ({ 7 }) of ({ 8 }) relevant ({ 9 }) images ({ 10 }) retrieved ({ 11 }) from ({ 12 }) a ({ 13 }) database ({ 14 }) . ({ 15 }) 
# Sentence pair (3236) source length 10 target length 10 alignment score : 0.0288163
The images are expected to contain the query item . 
NULL ({ }) The ({ 1 }) images ({ 2 }) are ({ 3 }) expected ({ 4 }) to ({ 5 }) contain ({ 6 }) the ({ 7 }) query ({ 8 }) item ({ 9 }) . ({ 10 }) 
# Sentence pair (3237) source length 19 target length 15 alignment score : 3.31022e-19
Several extensive works have been conducted with great interest on improving search performance \CITE . 
NULL ({ }) Extensive ({ 1 2 }) studies ({ 3 }) have ({ 4 }) been ({ 5 }) conducted ({ 6 }) with ({ 7 }) an ({ }) eye ({ 8 }) to ({ 10 }) improving ({ 11 }) the ({ }) performance ({ 13 }) of ({ }) this ({ }) sort ({ 9 }) of ({ }) search ({ 12 }) \CITE ({ 14 }) . ({ 15 }) 
# Sentence pair (3238) source length 25 target length 24 alignment score : 3.1562e-06
However , regardless of the powerfulness of state-of-the-art search techniques , there are still cases in which users are disappointed with search results . 
NULL ({ }) However ({ 1 }) , ({ 2 }) regardless ({ 3 }) of ({ 4 }) the ({ 5 }) powerfulness ({ 6 }) of ({ 7 }) state-of-the-art ({ 8 }) search ({ 9 }) techniques ({ 10 }) , ({ 11 }) there ({ 12 }) are ({ 13 }) still ({ 14 }) cases ({ 15 }) in ({ 16 }) which ({ 17 }) users ({ 18 }) are ({ 19 }) disappointed ({ 20 }) with ({ 21 }) their ({ }) search ({ 22 }) results ({ 23 }) . ({ 24 }) 
# Sentence pair (3239) source length 12 target length 12 alignment score : 2.08714e-05
The reason is because relevant items are not in the database . 
NULL ({ }) The ({ 1 }) reason ({ 2 }) is ({ 3 }) that ({ 4 }) relevant ({ 5 }) items ({ 6 }) are ({ 7 }) not ({ 8 }) in ({ 9 }) the ({ 10 }) database ({ 11 }) . ({ 12 }) 
# Sentence pair (3240) source length 17 target length 17 alignment score : 0.00151795
Under such circumstances , whatever the search technique is , results are obviously irrelevant and unexpected . 
NULL ({ }) Under ({ 1 }) such ({ 2 }) circumstances ({ 3 }) , ({ 4 }) whatever ({ 5 }) the ({ 6 }) search ({ 7 }) technique ({ 8 }) is ({ 9 }) , ({ 10 }) results ({ 11 }) are ({ 12 }) obviously ({ 13 }) irrelevant ({ 14 }) and ({ 15 }) unexpected ({ 16 }) . ({ 17 }) 
# Sentence pair (3241) source length 19 target length 18 alignment score : 1.64197e-10
A normal user without prior knowledge about the retrieved database has no choice but search by trial-and-error . 
NULL ({ 8 }) A ({ 1 }) normal ({ 2 }) user ({ 3 }) without ({ 4 }) prior ({ 5 }) knowledge ({ 6 }) about ({ 7 }) a ({ 9 }) database ({ 10 }) has ({ 11 }) no ({ 12 }) choice ({ 13 }) but ({ 14 }) to ({ }) search ({ 15 }) it ({ }) by ({ 16 }) trial-and-error ({ 17 }) . ({ 18 }) 
# Sentence pair (3242) source length 18 target length 17 alignment score : 7.02232e-10
We tackle this problem to facilitate users in searching and exploring images of such unknown database . 
NULL ({ }) We ({ 1 }) decided ({ 2 }) to ({ }) tackle ({ 14 }) this ({ 3 }) problem ({ 4 }) to ({ 5 }) help ({ 6 }) users ({ 7 }) in ({ 8 }) searching ({ 9 }) and ({ 10 }) exploring ({ 11 }) images ({ 12 }) in ({ 13 }) unknown ({ 15 }) databases ({ 16 }) . ({ 17 }) 
# Sentence pair (3243) source length 11 target length 11 alignment score : 0.0177069
Our proposal is a novel recommendation system , named Recommend-Me . 
NULL ({ }) Our ({ 1 }) proposal ({ 2 }) is ({ 3 }) a ({ 4 }) novel ({ 5 }) recommendation ({ 6 }) system ({ 7 }) , ({ 8 }) named ({ 9 }) Recommend-Me ({ 10 }) . ({ 11 }) 
# Sentence pair (3244) source length 17 target length 17 alignment score : 0.00254735
The expected scheme can be described as follows ( see Figure \REF for an example ) . 
NULL ({ }) The ({ 1 }) envisioned ({ 2 }) scheme ({ 3 }) can ({ 4 }) be ({ 5 }) described ({ 6 }) as ({ 7 }) follows ({ 8 }) ( ({ 9 }) see ({ 10 }) Figure ({ 11 }) \REF ({ 12 }) for ({ 13 }) an ({ 14 }) example ({ 15 }) ) ({ 16 }) . ({ 17 }) 
# Sentence pair (3245) source length 19 target length 19 alignment score : 3.35444e-07
Given an unknown database and an initial query image , our Recommend-Me automatically presents its recommendations to user . 
NULL ({ }) Given ({ 1 }) an ({ 2 }) unknown ({ 3 }) database ({ 4 }) and ({ 5 }) an ({ 6 }) initial ({ 7 }) query ({ 8 }) image ({ 9 }) , ({ 10 }) Recommend-Me ({ 11 12 }) automatically ({ 13 }) presents ({ 14 }) its ({ 15 }) recommendations ({ 16 }) to ({ 17 }) the ({ }) user ({ 18 }) . ({ 19 }) 
# Sentence pair (3246) source length 18 target length 18 alignment score : 0.00187784
One recommendation is one item , bounded by a rectangular region , in the initial query image . 
NULL ({ }) One ({ 1 }) recommendation ({ 2 }) is ({ 3 }) one ({ 4 }) item ({ 5 }) , ({ 6 }) bounded ({ 7 }) by ({ 8 }) a ({ 9 }) rectangular ({ 10 }) region ({ 11 }) , ({ 12 }) in ({ 13 }) the ({ 14 }) initial ({ 15 }) query ({ 16 }) image ({ 17 }) . ({ 18 }) 
# Sentence pair (3247) source length 19 target length 18 alignment score : 6.36615e-07
Each recommended item is assigned a number to clarify how many images of the database it occurs . 
NULL ({ }) Each ({ 1 }) recommended ({ 2 }) item ({ 3 }) is ({ 4 }) assigned ({ 5 }) a ({ 6 }) number ({ 7 }) to ({ 8 }) show ({ 9 }) in ({ }) how ({ 10 }) many ({ 11 }) images ({ 12 }) of ({ 13 }) the ({ 14 }) database ({ 15 }) it ({ 16 }) occurs ({ 17 }) . ({ 18 }) 
# Sentence pair (3248) source length 10 target length 10 alignment score : 0.000470097
Items with higher assigned numbers will be more recommended . 
NULL ({ }) Items ({ 1 }) with ({ 2 }) larger ({ 3 }) assigned ({ 4 }) numbers ({ 5 }) will ({ 6 }) be ({ 7 }) more ({ 8 }) recommended ({ 9 }) . ({ 10 }) 
# Sentence pair (3249) source length 10 target length 10 alignment score : 0.00510371
By providing such recommendations , Recommend-Me supports users to : 
NULL ({ }) By ({ 1 }) providing ({ 2 }) such ({ 3 }) recommendations ({ 4 }) , ({ 5 }) Recommend-Me ({ 6 }) helps ({ 7 }) users ({ 8 }) to ({ 9 }) : ({ 10 }) 
# Sentence pair (3250) source length 18 target length 18 alignment score : 0.00129314
- avoid unexpected search experience with poor queries that are subjectively ( and sometimes randomly ) selected , 
NULL ({ }) - ({ 1 }) avoid ({ 2 }) unexpected ({ 3 }) search ({ 4 }) experience ({ 5 }) with ({ 6 }) poor ({ 7 }) queries ({ 8 }) that ({ 9 }) are ({ 10 }) subjectively ({ 11 }) ( ({ 12 }) and ({ 13 }) sometimes ({ 14 }) randomly ({ 15 }) ) ({ 16 }) selected ({ 17 }) , ({ 18 }) 
# Sentence pair (3251) source length 26 target length 26 alignment score : 3.79789e-05
- rapidly refine the initial query image before any actual search , if the recommendations show that current search intention can not return relevant results , 
NULL ({ }) - ({ 1 }) rapidly ({ 2 }) refine ({ 3 }) the ({ 4 }) initial ({ 5 }) query ({ 6 }) image ({ 7 }) before ({ 8 }) any ({ 9 }) actual ({ 10 }) search ({ 11 }) , ({ 12 }) if ({ 13 }) the ({ 14 }) recommendations ({ 15 }) show ({ 16 }) that ({ 17 }) current ({ 18 }) search ({ 19 }) intention ({ 20 }) can ({ 21 }) not ({ 22 }) return ({ 23 }) relevant ({ 24 }) results ({ 25 }) , ({ 26 }) 
# Sentence pair (3252) source length 10 target length 10 alignment score : 0.0227985
- explore the database using the recommendations as hints . 
NULL ({ }) - ({ 1 }) explore ({ 2 }) the ({ 3 }) database ({ 4 }) using ({ 5 }) the ({ 6 }) recommendations ({ 7 }) as ({ 8 }) hints ({ 9 }) . ({ 10 }) 
# Sentence pair (3253) source length 8 target length 8 alignment score : 0.0664905
Recommend-Me is a pure visual recommendation system . 
NULL ({ }) Recommend-Me ({ 1 }) is ({ 2 }) a ({ 3 }) pure ({ 4 }) visual ({ 5 }) recommendation ({ 6 }) system ({ 7 }) . ({ 8 }) 
# Sentence pair (3254) source length 42 target length 19 alignment score : 1.06293e-26
No extra information or knowledge is required for input but an initial query image and a retrieved database . 
NULL ({ }) No ({ 1 }) extra ({ 2 }) information ({ 3 }) or ({ 4 }) knowledge ({ 5 }) is ({ 6 }) required ({ 7 }) for ({ 8 }) an ({ }) input ({ 9 }) besides ({ 10 }) an ({ 11 }) initial ({ 12 }) query ({ 13 }) image ({ 14 }) and ({ 15 }) a ({ 16 }) database ({ }) . ({ 19 }) //<" ({ 17 }) and ({ }) the ({ }) name ({ }) of ({ }) the ({ }) database ({ 18 }) " ({ }) ? ({ }) ? ({ }) Or ({ }) " ({ }) and ({ }) the ({ }) location ({ }) and ({ }) name ({ }) of ({ }) the ({ }) database ({ }) " ({ }) ? ({ }) ?> ({ }) 
# Sentence pair (3255) source length 12 target length 13 alignment score : 6.68991e-06
To automatically generate recommendations , we need to address several critical issues . 
NULL ({ }) To ({ 1 }) automatically ({ 2 }) generate ({ 3 }) recommendations ({ 4 }) , ({ 5 }) we ({ 6 }) need ({ 7 }) to ({ 8 }) address ({ 9 }) several ({ 10 }) issues ({ 11 12 }) . ({ 13 }) 
# Sentence pair (3256) source length 18 target length 16 alignment score : 6.24424e-06
First , there is a huge pool of candidate items in the initial query image . 
NULL ({ }) First ({ 1 }) , ({ 2 }) there ({ 3 }) tends ({ 4 }) to ({ }) be ({ }) a ({ 5 }) huge ({ 6 }) pool ({ 7 }) of ({ 8 }) candidate ({ 9 }) items ({ 10 }) in ({ 11 }) the ({ 12 }) initial ({ 13 }) query ({ 14 }) image ({ 15 }) . ({ 16 }) 
# Sentence pair (3257) source length 16 target length 16 alignment score : 0.00362823
Basically , any rectangular region in the image can be considered as a candidate item . 
NULL ({ }) Basically ({ 1 }) , ({ 2 }) any ({ 3 }) rectangular ({ 4 }) region ({ 5 }) in ({ 6 }) the ({ 7 }) image ({ 8 }) can ({ 9 }) be ({ 10 }) considered ({ 11 }) as ({ 12 }) a ({ 13 }) candidate ({ 14 }) item ({ 15 }) . ({ 16 }) 
# Sentence pair (3258) source length 11 target length 9 alignment score : 0.000490102
Examining all of them requires enormous computational cost . 
NULL ({ }) Examining ({ 1 }) all ({ 2 }) of ({ 3 }) them ({ 4 }) would ({ }) incur ({ 5 }) an ({ }) enormous ({ 6 }) computational ({ 7 }) cost ({ 8 }) . ({ 9 }) 
# Sentence pair (3259) source length 38 target length 37 alignment score : 5.2443e-27
Second , even if a candidate item is known , enumerating its occurrences in the database is not trivial because it is subject to many variations such as viewpoint and scale changes , rotation or occlusion . 
NULL ({ 27 28 30 }) Second ({ 1 }) , ({ 2 }) even ({ 3 }) if ({ 4 }) a ({ 5 }) candidate ({ 6 }) item ({ 7 }) is ({ 8 }) known ({ 9 }) , ({ 10 }) enumerating ({ 11 }) its ({ 12 }) occurrences ({ 13 }) in ({ 14 }) the ({ 15 }) database ({ 16 }) is ({ 17 }) a ({ }) not ({ 18 }) trivial ({ 19 }) task ({ }) because ({ 20 }) it ({ 21 }) is ({ 22 }) subject ({ 23 }) to ({ 24 }) many ({ 25 }) variations ({ 26 }) in ({ }) viewpoint ({ 29 }) , ({ }) scale ({ 31 32 }) , ({ 33 }) rotation ({ 34 35 }) , ({ }) occlusion ({ 36 }) , ({ }) etc. ({ 37 }) 
# Sentence pair (3260) source length 22 target length 23 alignment score : 4.7044e-22
Furthermore , scanning over all regions in images of the database will inevitably be prohibitive , if not infeasible for practical purposes . 
NULL ({ 16 }) Furthermore ({ 1 }) , ({ 2 }) the ({ }) cost ({ 4 }) of ({ }) scanning ({ 3 }) all ({ 5 }) regions ({ 6 }) of ({ 7 }) the ({ }) images ({ 8 }) of ({ 9 }) the ({ 10 }) database ({ 11 }) will ({ 12 }) inevitably ({ 13 }) be ({ 14 }) prohibitive ({ 15 17 18 19 }) for ({ 20 }) practical ({ 21 }) purposes ({ 22 }) . ({ 23 }) 
# Sentence pair (3261) source length 30 target length 24 alignment score : 5.27585e-12
In this paper , we employ state-of-the-art techniques such as SIFT and Bag-of-Words ( BoW ) model to handle matching regions under variations . 
NULL ({ }) In ({ 1 }) this ({ 2 }) paper ({ 3 }) , ({ 4 }) we ({ 5 }) employ ({ 6 }) state-of-the-art ({ 7 }) techniques ({ 8 }) such ({ 9 }) as ({ 10 }) SIFT ({ 11 }) and ({ 12 }) the ({ }) Bag-of-Words ({ 13 }) ( ({ 14 }) BoW ({ 15 }) ) ({ 16 }) model ({ 17 }) to ({ 18 }) handle ({ 19 }) the ({ }) task ({ }) of ({ }) matching ({ 20 }) regions ({ 21 }) with ({ }) the ({ }) above ({ 22 }) variations ({ 23 }) . ({ 24 }) 
# Sentence pair (3262) source length 24 target length 20 alignment score : 2.55432e-11
Our main focus is an efficient approach for quantifying occurences of candidate items over the database to generate recommendations . 
NULL ({ }) Our ({ 1 }) main ({ 2 }) focus ({ 3 }) is ({ 4 }) to ({ }) devise ({ 14 }) an ({ 5 }) efficient ({ 6 }) approach ({ 7 }) for ({ 8 }) quantifying ({ 9 }) occurrences ({ 10 }) of ({ 11 }) candidate ({ 12 }) items ({ 13 }) in ({ }) the ({ 15 }) database ({ 16 }) in ({ }) order ({ }) to ({ 17 }) generate ({ 18 }) recommendations ({ 19 }) . ({ 20 }) 
# Sentence pair (3263) source length 12 target length 11 alignment score : 9.0476e-13
The efficiency advantages of our approach come from various methodologies . 
NULL ({ }) The ({ 1 }) advantage ({ 3 }) in ({ }) efficiency ({ 2 }) comes ({ 7 }) from ({ 8 }) our ({ 5 }) use ({ 6 }) of ({ 4 }) various ({ 9 }) methodologies ({ 10 }) . ({ 11 }) 
# Sentence pair (3264) source length 43 target length 41 alignment score : 1.17769e-12
Based on an observation that users are mostly interested in object-like items , we use a selective search approach proposed by Van de Sande et al. \CITE to sample regions bounding object-like items in all images as a preprocessing step . 
NULL ({ }) Based ({ 1 }) on ({ 2 }) the ({ 3 }) observation ({ 4 }) that ({ 5 }) users ({ 6 }) are ({ 7 }) mostly ({ 8 }) interested ({ 9 }) in ({ 10 }) object-like ({ 11 }) items ({ 12 }) , ({ 13 }) we ({ 14 }) decided ({ }) to ({ }) use ({ 15 }) a ({ 16 }) selective ({ 17 }) search ({ 18 }) approach ({ 19 }) proposed ({ 20 }) by ({ 21 }) Van ({ 22 }) de ({ 23 }) Sande ({ 24 }) et ({ 25 }) al. ({ 26 }) \CITE ({ 27 }) to ({ 28 }) sample ({ 29 }) regions ({ 30 }) bounding ({ 31 }) object-like ({ 32 }) items ({ 33 }) in ({ 34 }) all ({ 35 }) images ({ 36 }) as ({ 37 }) a ({ 38 }) preprocessing ({ 39 }) step ({ 40 }) . ({ 41 }) 
# Sentence pair (3265) source length 38 target length 34 alignment score : 1.61262e-22
By applying the approach instead of other naive sampling approach such as sliding windows , the number of items ( i.e. regions ) that need to be processed in each image dramatically reduces . 
NULL ({ 16 }) By ({ 1 }) applying ({ 2 }) this ({ 3 }) approach ({ 4 }) instead ({ 5 }) of ({ 6 }) a ({ }) naive ({ 7 8 }) sampling ({ 9 }) approach ({ 10 }) such ({ 11 }) as ({ 12 }) sliding ({ 13 }) windows ({ 14 }) , ({ 15 }) we ({ }) were ({ }) able ({ }) to ({ }) dramatically ({ 32 }) reduce ({ 33 }) the ({ }) number ({ 17 }) of ({ 18 }) items ({ 19 }) ( ({ 20 }) i.e. ({ 21 }) regions ({ 22 }) ) ({ 23 }) that ({ 24 }) need ({ 25 }) to ({ 26 }) be ({ 27 }) processed ({ 28 }) in ({ 29 }) each ({ 30 }) image ({ 31 }) . ({ 34 }) 
# Sentence pair (3266) source length 44 target length 30 alignment score : 9.2046e-24
Given two sets of regions , one contains regions of candidate items in the initial query image and the other contains regions of items in images of the database . 
NULL ({ }) Given ({ 1 }) two ({ 2 }) sets ({ 3 }) of ({ 4 }) regions ({ 5 }) , ({ 6 }) one ({ 7 }) containing ({ 8 }) regions ({ 9 }) of ({ 10 }) candidate ({ 11 }) items ({ 12 }) in ({ 13 }) the ({ 14 }) initial ({ 15 }) query ({ 16 }) image ({ 17 }) and ({ 18 }) the ({ 19 }) other ({ 20 }) containing ({ 21 }) regions ({ 22 }) of ({ 23 }) items ({ 24 }) in ({ 25 }) images ({ 26 }) of ({ 27 }) the ({ 28 }) database ({ 29 }) , ({ }) our ({ }) task ({ }) is ({ }) to ({ }) find ({ }) occurrences ({ }) of ({ }) all ({ }) candidate ({ }) items ({ }) in ({ }) the ({ }) database ({ }) . ({ 30 }) 
# Sentence pair (3267) source length 34 target length 40 alignment score : 6.9489e-26
Finding occurences of all candidate items in the database can be equally treated as finding pairs of matched regions , knowing a pair is formed by a region in one of the sets with a region in the other . 
NULL ({ 3 7 8 }) This ({ }) task ({ }) can ({ 10 }) be ({ 11 }) equivalently ({ 1 2 4 5 6 9 12 }) treated ({ 13 }) as ({ 14 }) finding ({ 15 }) pairs ({ 16 }) of ({ 17 }) matched ({ 18 }) regions ({ 19 }) , ({ 20 }) knowing ({ 21 }) that ({ }) a ({ 22 }) pair ({ 23 }) is ({ 24 }) formed ({ 25 }) by ({ 26 }) a ({ 27 }) region ({ 28 }) in ({ 29 }) one ({ 30 }) of ({ 31 }) the ({ 32 }) sets ({ 33 }) with ({ 34 }) a ({ 35 }) region ({ 36 }) in ({ 37 }) the ({ 38 }) other ({ 39 }) . ({ 40 }) 
# Sentence pair (3268) source length 24 target length 22 alignment score : 4.80255e-11
So , if top region pairs with sufficient high similarity scores are found , we can enumerate occurences of the items . 
NULL ({ }) So ({ 1 }) , ({ 2 }) if ({ 3 }) the ({ }) top ({ 4 }) region ({ 5 }) pairs ({ 6 }) are ({ 12 }) found ({ 13 }) with ({ 7 }) sufficiently ({ 8 }) high ({ 9 }) similarity ({ 10 }) scores ({ 11 }) , ({ 14 }) we ({ 15 }) can ({ 16 }) enumerate ({ 17 }) the ({ }) occurrences ({ 18 }) of ({ 19 }) the ({ 20 }) items ({ 21 }) . ({ 22 }) 
# Sentence pair (3269) source length 29 target length 30 alignment score : 1.95869e-20
Based on these insights , we make an yet another efficiency boost by formulating the problem as an optimization problem which can be solved by applying a branh-and-bound algorithm . 
NULL ({ 8 }) Based ({ 1 }) on ({ 2 }) this ({ 3 }) insight ({ 4 }) , ({ 5 }) we ({ 6 }) can ({ 7 }) boost ({ 12 }) efficiency ({ 11 }) yet ({ 9 }) again ({ 10 }) by ({ 13 }) formulating ({ 14 }) the ({ 15 }) problem ({ 16 }) as ({ 17 }) an ({ 18 }) optimization ({ 19 }) problem ({ 20 }) that ({ 21 }) can ({ 22 }) be ({ 23 }) solved ({ 24 }) by ({ 25 }) applying ({ 26 }) a ({ 27 }) branch-and-bound ({ 28 }) algorithm ({ 29 }) . ({ 30 }) 
# Sentence pair (3270) source length 37 target length 37 alignment score : 2.15362e-09
In order to do that , we introduce a novel representation based on hierarchical structure to describe a set of region pairs and a corresponding function bounding the similarity scores of pairs over such a set . 
NULL ({ 16 }) In ({ 1 }) order ({ 2 }) to ({ 3 }) do ({ 4 }) that ({ 5 }) , ({ 6 }) we ({ 7 }) introduce ({ 8 }) a ({ 9 }) novel ({ 10 }) representation ({ 11 }) based ({ 12 }) on ({ 13 }) a ({ }) hierarchical ({ 14 }) structure ({ 15 }) describing ({ 17 }) a ({ 18 }) set ({ 19 }) of ({ 20 }) region ({ 21 }) pairs ({ 22 }) and ({ 23 }) a ({ 24 }) corresponding ({ 25 }) function ({ 26 }) bounding ({ 27 }) the ({ 28 }) similarity ({ 29 }) scores ({ 30 }) of ({ 31 }) pairs ({ 32 }) over ({ 33 }) such ({ 34 }) a ({ 35 }) set ({ 36 }) . ({ 37 }) 
# Sentence pair (3271) source length 3 target length 3 alignment score : 0.225789
Related Works . 
NULL ({ }) Related ({ 1 }) Work ({ 2 }) . ({ 3 }) 
# Sentence pair (3272) source length 25 target length 24 alignment score : 7.2626e-10
With respect to discovering common items , Recommend-Me is related to recent studies on mining common items in image databases such as \CITE . 
NULL ({ }) On ({ 1 }) the ({ }) topic ({ 2 }) of ({ 3 }) discovering ({ 4 }) common ({ 5 }) items ({ 6 }) , ({ 7 }) Recommend-Me ({ 8 }) is ({ 9 }) related ({ 10 }) to ({ 11 }) recent ({ 12 }) studies ({ 13 }) on ({ 14 }) mining ({ 15 }) common ({ 16 }) items ({ 17 }) in ({ 18 }) image ({ 19 }) databases ({ 20 }) such ({ 21 }) as ({ 22 }) \CITE ({ 23 }) . ({ 24 }) 
# Sentence pair (3273) source length 30 target length 29 alignment score : 6.50437e-11
However , in contrast to these studies , Recommend-Me targets items which are shared by both an image database and user interest limited in an input initial image . 
NULL ({ 24 }) However ({ 1 }) , ({ 2 }) in ({ 3 }) contrast ({ 4 }) to ({ 5 }) these ({ 6 }) studies ({ 7 }) , ({ 8 }) Recommend-Me ({ 9 }) targets ({ 10 }) items ({ 11 }) which ({ 12 }) are ({ 13 }) shared ({ 14 }) by ({ 15 }) both ({ 16 }) an ({ 17 }) image ({ 18 }) database ({ 19 }) and ({ 20 }) the ({ }) user ({ 21 }) 's ({ }) particular ({ 23 }) interest ({ 22 }) inthe ({ 25 }) input ({ 26 }) initial ({ 27 }) image ({ 28 }) . ({ 29 }) 
# Sentence pair (3274) source length 13 target length 13 alignment score : 0.00226315
Meanwhile , \CITE only aim at finding common items within the database . 
NULL ({ }) Meanwhile ({ 1 }) , ({ 2 }) \CITE ({ 3 }) only ({ 4 }) aims ({ 5 }) at ({ 6 }) finding ({ 7 }) common ({ 8 }) items ({ 9 }) within ({ 10 }) the ({ 11 }) database ({ 12 }) . ({ 13 }) 
# Sentence pair (3275) source length 35 target length 33 alignment score : 1.86876e-15
One can employ these techniques to our problem by firstly figuring out common items among images of the database , then looking them up in the initial query image again for recommendations . 
NULL ({ }) One ({ 1 }) can ({ 2 }) employ ({ 3 }) these ({ 4 }) techniques ({ 5 }) to ({ 6 }) solve ({ }) our ({ 7 }) problem ({ 8 }) by ({ 9 }) first ({ 10 }) identifying ({ 11 12 }) common ({ 13 }) items ({ 14 }) among ({ 15 }) the ({ }) images ({ 16 }) of ({ 17 }) the ({ 18 }) database ({ 19 }) , ({ 20 }) then ({ 21 }) looking ({ 22 }) them ({ 23 }) up ({ 24 }) in ({ 25 }) the ({ 26 }) initial ({ 27 }) query ({ 28 }) image ({ 29 }) again ({ 30 }) to ({ 31 }) make ({ }) recommendations ({ 32 }) . ({ 33 }) 
# Sentence pair (3276) source length 26 target length 27 alignment score : 4.03515e-28
However , by doing that , extra costs for mining unnecessary items , which appear in the database but the initial query image , arise accordingly . 
NULL ({ 6 13 24 }) However ({ 1 }) , ({ 2 }) doing ({ 3 4 25 }) that ({ 5 }) incurs ({ 26 }) the ({ }) extra ({ 7 }) cost ({ 8 }) of ({ 9 }) mining ({ 10 }) unnecessary ({ 11 }) items ({ 12 }) that ({ 14 }) appear ({ 15 }) in ({ 16 }) the ({ 17 }) database ({ 18 }) , ({ }) but ({ 19 }) not ({ }) in ({ }) the ({ 20 }) initial ({ 21 }) query ({ 22 }) image ({ 23 }) . ({ 27 }) 
# Sentence pair (3277) source length 17 target length 20 alignment score : 1.42421e-19
One of the most related works to Recommend-Me for query suggestion is proposed by Zha et al in \CITE . 
NULL ({ 9 }) One ({ 1 }) of ({ 2 }) the ({ 3 }) most ({ 4 }) related ({ 5 }) studies ({ 6 }) to ({ 7 }) ours ({ 8 10 11 }) is ({ 12 }) that ({ }) of ({ }) Zha ({ 13 14 15 }) et ({ 16 }) al ({ 17 }) in ({ 18 }) \CITE ({ 19 }) . ({ 20 }) 
# Sentence pair (3278) source length 24 target length 22 alignment score : 8.20621e-10
They introduced a system called Visual Query Suggestion ( VQS ) which simultanously provides both keyword and image suggestions for users . 
NULL ({ }) They ({ 1 }) introduced ({ 2 }) a ({ 3 }) system ({ 4 }) , ({ }) called ({ 5 }) Visual ({ 6 }) Query ({ 7 }) Suggestion ({ 8 }) ( ({ 9 }) VQS ({ 10 }) ) ({ 11 }) , ({ }) that ({ 12 }) simultaneously ({ 13 }) provides ({ 14 }) both ({ 15 }) keyword ({ 16 }) and ({ 17 }) image ({ 18 }) suggestions ({ 19 }) to ({ 20 }) users ({ 21 }) . ({ 22 }) 
# Sentence pair (3279) source length 9 target length 10 alignment score : 4.7585e-05
There are clear differences between our Recommend-Me and VQS . 
NULL ({ }) There ({ 1 }) are ({ 2 }) clear ({ 3 }) differences ({ 4 }) between ({ 5 }) Recommend-Me ({ 6 7 }) and ({ 8 }) VQS ({ 9 }) . ({ 10 }) 
# Sentence pair (3280) source length 20 target length 18 alignment score : 4.56927e-06
VQS requires an initial text query for suggestion formulation and its suggestions are both keywords and images . 
NULL ({ }) VQS ({ 1 }) requires ({ 2 }) an ({ 3 }) initial ({ 4 }) text ({ 5 }) query ({ 6 }) for ({ 7 }) formulating ({ 8 }) the ({ }) suggestion ({ 9 }) , ({ }) and ({ 10 }) its ({ 11 }) suggestions ({ 12 }) are ({ 13 }) both ({ 14 }) keywords ({ 15 }) and ({ 16 }) images ({ 17 }) . ({ 18 }) 
# Sentence pair (3281) source length 21 target length 20 alignment score : 4.34555e-05
On the other hand , Recommend-Me takes an image as input and its outputs are regions in the image . 
NULL ({ }) On ({ 1 }) the ({ 2 }) other ({ 3 }) hand ({ 4 }) , ({ 5 }) Recommend-Me ({ 6 }) takes ({ 7 }) an ({ 8 }) image ({ 9 }) as ({ 10 }) input ({ 11 }) , ({ }) and ({ 12 }) its ({ 13 }) outputs ({ 14 }) are ({ 15 }) regions ({ 16 }) in ({ 17 }) the ({ 18 }) image ({ 19 }) . ({ 20 }) 
# Sentence pair (3282) source length 12 target length 12 alignment score : 0.0154298
Recommend-Me is a query suggestion system based on pure visual information . 
NULL ({ }) Recommend-Me ({ 1 }) is ({ 2 }) a ({ 3 }) query ({ 4 }) suggestion ({ 5 }) system ({ 6 }) based ({ 7 }) on ({ 8 }) pure ({ 9 }) visual ({ 10 }) information ({ 11 }) . ({ 12 }) 
# Sentence pair (3283) source length 22 target length 22 alignment score : 6.56872e-11
Above all , although both Recommend-Me and VQS aim at facilitating users in searching images , the targeted problems are different . 
NULL ({ 13 }) Above ({ 1 }) all ({ 2 }) , ({ 3 }) although ({ 4 }) both ({ 5 }) Recommend-Me ({ 6 }) and ({ 7 }) VQS ({ 8 }) aim ({ 9 }) at ({ 10 }) helping ({ 11 }) users ({ 12 }) search ({ 14 }) for ({ }) images ({ 15 }) , ({ 16 }) their ({ 17 }) targeted ({ 18 }) problems ({ 19 }) are ({ 20 }) different ({ 21 }) . ({ 22 }) 
# Sentence pair (3284) source length 27 target length 23 alignment score : 1.02643e-10
VQS proposes to help users to overcome query ambiguity formulation by precisely expressing search intents , assuming relevant items are always available . 
NULL ({ }) VQS ({ 1 }) proposes ({ 2 }) to ({ 3 }) help ({ 4 }) users ({ 5 }) to ({ 6 }) overcome ({ 7 }) their ({ }) tendency ({ 8 }) to ({ }) formulate ({ 9 }) ambiguous ({ 10 }) queries ({ }) by ({ 11 }) precisely ({ 12 }) expressing ({ 13 }) search ({ 14 }) intents ({ 15 }) , ({ 16 }) assuming ({ 17 }) the ({ }) relevant ({ 18 }) items ({ 19 }) are ({ 20 }) always ({ 21 }) available ({ 22 }) . ({ 23 }) 
# Sentence pair (3285) source length 20 target length 21 alignment score : 3.75824e-09
Meanwhile , Recommend-Me supports users to select queries based on the existence of their relevant items in the retrieved database . 
NULL ({ 14 }) Meanwhile ({ 1 }) , ({ 2 }) Recommend-Me ({ 3 }) helps ({ 4 }) users ({ 5 }) to ({ 6 }) select ({ 7 }) queries ({ 8 }) based ({ 9 }) on ({ 10 }) the ({ 11 }) existence ({ 12 }) of ({ 13 }) relevant ({ 15 }) items ({ 16 }) in ({ 17 }) the ({ 18 }) retrieved ({ 19 }) database ({ 20 }) . ({ 21 }) 
# Sentence pair (3286) source length 20 target length 18 alignment score : 4.61389e-08
To the best of our knowledge , Recommend-Me is the first attempt towards its targeted suggestion scheme . 
NULL ({ }) To ({ 1 }) the ({ 2 }) best ({ 3 }) of ({ 4 }) our ({ 5 }) knowledge ({ 6 }) , ({ 7 }) Recommend-Me ({ 8 }) is ({ 9 }) the ({ 10 }) first ({ 11 }) attempt ({ 12 }) at ({ 13 }) this ({ }) sort ({ 14 }) of ({ }) targeted ({ 15 }) suggestion ({ 16 }) scheme ({ 17 }) . ({ 18 }) 
# Sentence pair (3287) source length 26 target length 25 alignment score : 5.71948e-09
From technical point of view , our solution is motivated by recent works for object localization and subimage retrieval based on branch-and-bound optimization \CITE . 
NULL ({ }) From ({ 1 }) a ({ }) technical ({ 2 }) point ({ 3 }) of ({ 4 }) view ({ 5 }) , ({ 6 }) our ({ 7 }) solution ({ 8 }) is ({ 9 }) motivated ({ 10 }) by ({ 11 }) recent ({ 12 }) work ({ 13 }) on ({ 14 }) object ({ 15 }) localization ({ 16 }) and ({ 17 }) subimage ({ 18 }) retrieval ({ 19 }) based ({ 20 }) on ({ 21 }) branch-and-bound ({ 22 }) optimization ({ 23 }) \CITE ({ 24 }) . ({ 25 }) 
# Sentence pair (3288) source length 25 target length 22 alignment score : 1.61952e-14
However , ours is differentiated in the way we represent sets of region pairs , instead of sets of regions only . 
NULL ({ }) However ({ 1 }) , ({ 2 }) ours ({ 3 }) is ({ 4 }) differentiated ({ 5 }) from ({ 6 }) the ({ 7 }) other ({ }) studies ({ 8 }) in ({ }) that ({ }) we ({ 9 }) represent ({ 10 }) sets ({ 11 }) of ({ 12 }) region ({ 13 }) pairs ({ 14 }) , ({ 15 }) instead ({ 16 }) of ({ 17 }) only ({ 21 }) sets ({ 18 }) of ({ 19 }) regions ({ 20 }) . ({ 22 }) 
# Sentence pair (3289) source length 11 target length 11 alignment score : 0.00663842
ESS and ESR \CITE use coordinate intervals for their presentation . 
NULL ({ }) ESS ({ 1 }) and ({ 2 }) ESR ({ 3 }) \CITE ({ 4 }) use ({ 5 }) coordinate ({ 6 }) intervals ({ 7 }) for ({ 8 }) their ({ 9 }) presentation ({ 10 }) . ({ 11 }) 
# Sentence pair (3290) source length 19 target length 18 alignment score : 1.26356e-05
Meanwhile , we utilize hierarchical structures in order to do that , since our regions are discrete . 
NULL ({ }) In ({ }) contrast ({ 1 }) , ({ 2 }) we ({ 3 }) utilize ({ 4 }) hierarchical ({ 5 }) structures ({ 6 }) in ({ 7 }) order ({ 8 }) to ({ 9 }) do ({ 10 }) that ({ 11 }) , ({ 12 }) since ({ 13 }) our ({ 14 }) regions ({ 15 }) are ({ 16 }) discrete ({ 17 }) . ({ 18 }) 
# Sentence pair (3291) source length 46 target length 41 alignment score : 3.26673e-22
Although coordinate intervals as in ESS ( or ESR ) can be extended to represent set of region pairs , such criterion may suffer the branch-and-bound algorithm from curse-of-dimensionality problem since the number of dimension required is at least doubled . 
NULL ({ 37 }) Although ({ 1 }) coordinate ({ 2 }) intervals ({ 3 }) as ({ 4 }) in ({ 5 }) ESS ({ 6 }) ( ({ 7 }) or ({ 8 }) ESR ({ 9 }) ) ({ 10 }) can ({ 11 }) be ({ 12 }) extended ({ 13 }) to ({ 14 }) represent ({ 15 }) sets ({ 16 }) of ({ 17 }) region ({ 18 }) pairs ({ 19 }) , ({ 20 }) such ({ 21 }) a ({ }) criterion ({ 22 }) in ({ }) the ({ }) context ({ }) of ({ }) the ({ 25 }) branch-and-bound ({ 26 }) algorithm ({ 27 }) may ({ 23 }) suffer ({ 24 }) from ({ 28 }) the ({ }) curse-of-dimensionality ({ 29 }) problem ({ 30 }) since ({ 31 }) the ({ 32 }) number ({ 33 }) of ({ 34 }) dimensions ({ 35 }) required ({ 36 }) at ({ 38 }) least ({ 39 }) doubles ({ 40 }) . ({ 41 }) 
# Sentence pair (3292) source length 29 target length 26 alignment score : 6.16328e-32
Finally , ours and ESS , ESR do not share common approach to construct bounding quality function and to compute bounding values over the sets . 
NULL ({ }) Finally ({ 1 }) , ({ 2 }) ESS ({ 3 5 }) , ({ 6 }) ESR ({ 7 8 9 10 11 12 }) and ({ 4 }) Recommend-Me ({ }) differ ({ }) in ({ }) that ({ }) they ({ }) have ({ }) different ({ }) approaches ({ }) to ({ 13 }) constructing ({ 14 }) a ({ }) bounding ({ 15 }) quality ({ 16 }) function ({ 17 }) and ({ 18 }) to ({ 19 }) computing ({ 20 }) bounding ({ 21 }) values ({ 22 }) over ({ 23 }) the ({ 24 }) sets ({ 25 }) . ({ 26 }) 
# Sentence pair (3293) source length 10 target length 10 alignment score : 0.0373592
The rest of this paper is organized as follows . 
NULL ({ }) The ({ 1 }) rest ({ 2 }) of ({ 3 }) this ({ 4 }) paper ({ 5 }) is ({ 6 }) organized ({ 7 }) as ({ 8 }) follows ({ 9 }) . ({ 10 }) 
# Sentence pair (3294) source length 9 target length 9 alignment score : 0.028501
Section 2 presents an overview of the system . 
NULL ({ }) Section ({ 1 }) 2 ({ 2 }) presents ({ 3 }) an ({ 4 }) overview ({ 5 }) of ({ 6 }) the ({ 7 }) system ({ 8 }) . ({ 9 }) 
# Sentence pair (3295) source length 19 target length 19 alignment score : 2.01593e-16
Details of our proposed approaches for finding region pairs with highest similarity scores are given in Section 3 . 
NULL ({ 4 6 }) The ({ }) details ({ 1 }) of ({ 2 }) how ({ 3 }) we ({ 5 }) find ({ 7 }) region ({ 8 }) pairs ({ 9 }) with ({ 10 }) the ({ }) highest ({ 11 }) similarity ({ 12 }) scores ({ 13 }) are ({ 14 }) given ({ 15 }) in ({ 16 }) Section ({ 17 }) 3 ({ 18 }) . ({ 19 }) 
# Sentence pair (3296) source length 8 target length 8 alignment score : 0.0449671
Section 4 presents our experiments and evaluations . 
NULL ({ }) Section ({ 1 }) 4 ({ 2 }) presents ({ 3 }) our ({ 4 }) experiments ({ 5 }) and ({ 6 }) evaluations ({ 7 }) . ({ 8 }) 
# Sentence pair (3297) source length 6 target length 6 alignment score : 4.88957e-05
Section 5 concludes our paper . 
NULL ({ }) Section ({ 1 }) 5 ({ 2 }) concludes ({ 3 }) the ({ 4 }) paper ({ 5 }) . ({ 6 }) 
# Sentence pair (3298) source length 10 target length 16 alignment score : 4.07784e-21
The framework of Recommend-Me consists of 4 main steps towards formulating final recommendations for users . 
NULL ({ 13 14 }) The ({ 1 }) framework ({ 2 }) of ({ 3 }) Recommend-Me ({ 4 }) consists ({ 5 }) of ({ 6 }) four ({ 7 }) main ({ 8 }) steps ({ 9 10 11 12 15 }) . ({ 16 }) 
# Sentence pair (3299) source length 6 target length 6 alignment score : 0.155067
Figure \REF summarizes the pipeline . 
NULL ({ }) Figure ({ 1 }) \REF ({ 2 }) summarizes ({ 3 }) the ({ 4 }) pipeline ({ 5 }) . ({ 6 }) 
# Sentence pair (3300) source length 9 target length 9 alignment score : 6.6515e-06
Step 1 : Candidate item selection in images . 
NULL ({ }) Step ({ 1 }) 1 ({ 2 }) : ({ 3 }) Select ({ 4 }) candidate ({ 5 }) items ({ 6 }) in ({ 7 }) images ({ 8 }) . ({ 9 }) 
# Sentence pair (3301) source length 18 target length 17 alignment score : 1.02407e-06
Using all possible rectangular regions in images as candidate items is overly expensive for further processing . 
NULL ({ }) Using ({ 1 }) all ({ 2 }) possible ({ 3 }) rectangular ({ 4 }) regions ({ 5 }) in ({ 6 }) images ({ 7 }) as ({ 8 }) candidate ({ 9 }) items ({ 10 }) is ({ 11 }) overly ({ 12 }) expensive ({ 13 }) in ({ 14 }) the ({ }) subsequent ({ 15 }) processing ({ 16 }) . ({ 17 }) 
# Sentence pair (3302) source length 11 target length 13 alignment score : 8.1697e-09
More importantly , human users are often get attracted by object-like items . 
NULL ({ }) More ({ 1 }) importantly ({ 2 }) , ({ 3 }) users ({ 4 5 }) are ({ 6 }) often ({ 7 }) attracted ({ 8 9 }) by ({ 10 }) object-like ({ 11 }) items ({ 12 }) . ({ 13 }) 
# Sentence pair (3303) source length 18 target length 18 alignment score : 0.000810545
Thus , we employ an approach proposed by Van de Sande et al. \CITE for item selection . 
NULL ({ }) Thus ({ 1 }) , ({ 2 }) we ({ 3 }) employ ({ 4 }) an ({ 5 }) approach ({ 6 }) proposed ({ 7 }) by ({ 8 }) Van ({ 9 }) de ({ 10 }) Sande ({ 11 }) et ({ 12 }) al. ({ 13 }) \CITE ({ 14 }) for ({ 15 }) item ({ 16 }) selection ({ 17 }) . ({ 18 }) 
# Sentence pair (3304) source length 11 target length 11 alignment score : 0.0243039
The approach starts by oversegmenting an image into disjoint regions . 
NULL ({ }) The ({ 1 }) approach ({ 2 }) starts ({ 3 }) by ({ 4 }) over-segmenting ({ 5 }) an ({ 6 }) image ({ 7 }) into ({ 8 }) disjoint ({ 9 }) regions ({ 10 }) . ({ 11 }) 
# Sentence pair (3305) source length 29 target length 25 alignment score : 6.57865e-10
Then , it performs a greedy algorithm which iteratively merges the two most similar regions together until the whole image becomes a single region . 
NULL ({ }) Then ({ 1 }) , ({ 2 }) it ({ 3 }) performs ({ 4 }) a ({ 5 }) greedy ({ 6 }) search ({ }) < ({ }) ? ({ }) ?> ({ }) algorithm ({ 7 }) that ({ 8 }) iteratively ({ 9 }) merges ({ 10 }) the ({ 11 }) two ({ 12 }) most ({ 13 }) similar ({ 14 }) regions ({ 15 }) together ({ 16 }) until ({ 17 }) the ({ 18 }) whole ({ 19 }) image ({ 20 }) becomes ({ 21 }) a ({ 22 }) single ({ 23 }) region ({ 24 }) . ({ 25 }) 
# Sentence pair (3306) source length 12 target length 11 alignment score : 3.93991e-09
All region throughout the hierarchy is considered as candidate items . 
NULL ({ }) All ({ 1 }) regions ({ 2 }) throughout ({ 3 }) the ({ 4 }) hierarchy ({ 5 }) are ({ 6 }) considered ({ 7 }) to ({ }) be ({ 8 }) candidate ({ 9 }) items ({ 10 }) . ({ 11 }) 
# Sentence pair (3307) source length 10 target length 10 alignment score : 0.024532
Each item is represented by its rectangular bounding region . 
NULL ({ }) Each ({ 1 }) item ({ 2 }) is ({ 3 }) represented ({ 4 }) by ({ 5 }) its ({ 6 }) rectangular ({ 7 }) bounding ({ 8 }) region ({ 9 }) . ({ 10 }) 
# Sentence pair (3308) source length 13 target length 12 alignment score : 0.00344575
Step 2 : Finding top region pairs with highest similarity scores . 
NULL ({ }) Step ({ 1 }) 2 ({ 2 }) : ({ 3 }) Find ({ 4 }) top ({ 5 }) region ({ 6 }) pairs ({ 7 }) with ({ 8 }) the ({ }) highest ({ 9 }) similarity ({ 10 }) scores ({ 11 }) . ({ 12 }) 
# Sentence pair (3309) source length 27 target length 26 alignment score : 6.80935e-07
There is a pool of region pairs if we compare each region in the initial query image with each region in images of the database . 
NULL ({ }) There ({ 1 }) will ({ 2 }) be ({ }) a ({ 3 }) pool ({ 4 }) of ({ 5 }) region ({ 6 }) pairs ({ 7 }) if ({ 8 }) we ({ 9 }) compare ({ 10 }) each ({ 11 }) region ({ 12 }) in ({ 13 }) the ({ 14 }) initial ({ 15 }) query ({ 16 }) image ({ 17 }) with ({ 18 }) each ({ 19 }) region ({ 20 }) in ({ 21 }) images ({ 22 }) of ({ 23 }) the ({ 24 }) database ({ 25 }) . ({ 26 }) 
# Sentence pair (3310) source length 19 target length 19 alignment score : 0.000132293
However , only region pairs with sufficient high similarity scores are meaningful for identifying occurrences of candidate items . 
NULL ({ }) However ({ 1 }) , ({ 2 }) only ({ 3 }) region ({ 4 }) pairs ({ 5 }) with ({ 6 }) sufficiently ({ 7 }) high ({ 8 }) similarity ({ 9 }) scores ({ 10 }) are ({ 11 }) meaningful ({ 12 }) for ({ 13 }) identifying ({ 14 }) occurrences ({ 15 }) of ({ 16 }) candidate ({ 17 }) items ({ 18 }) . ({ 19 }) 
# Sentence pair (3311) source length 33 target length 35 alignment score : 9.59261e-24
In this step , we perform our proposed approach , explained in Section 3 , to find top \MATH ( an expected number of returned region pairs ) of such pairs in the pool . 
NULL ({ 10 15 }) In ({ 1 }) this ({ 2 }) step ({ 3 }) , ({ 4 }) we ({ 5 }) use ({ }) the ({ }) approach ({ 9 }) explained ({ 11 }) in ({ 12 }) Section ({ 13 }) 3 ({ 14 }) to ({ 16 }) find ({ 17 }) the ({ }) top ({ 18 }) \MATH ({ 19 }) ( ({ 20 }) the ({ 21 }) expected ({ 22 }) number ({ 23 }) of ({ 24 }) returned ({ 25 }) region ({ 26 }) pairs ({ 27 }) ) ({ 28 }) of ({ 29 }) such ({ 30 }) pairs ({ 31 }) in ({ 32 }) the ({ 33 }) pool ({ 6 7 8 34 }) . ({ 35 }) 
# Sentence pair (3312) source length 7 target length 7 alignment score : 0.131849
Step 3 : Grouping overlapping regions . 
NULL ({ }) Step ({ 1 }) 3 ({ 2 }) : ({ 3 }) Group ({ 4 }) overlapping ({ 5 }) regions ({ 6 }) . ({ 7 }) 
# Sentence pair (3313) source length 39 target length 39 alignment score : 1.32176e-12
Given \MATH region pairs returned in Step 2 and assuming each region pair in \MATH pairs is formed by a candidate item and its corresponding match , we now can enumerate the number of occurences of the items . 
NULL ({ 29 }) Given ({ 1 }) \MATH ({ 2 }) region ({ 3 }) pairs ({ 4 }) returned ({ 5 }) in ({ 6 }) Step ({ 7 }) 2 ({ 8 }) and ({ 9 }) assuming ({ 10 }) each ({ 11 }) region ({ 12 }) pair ({ 13 }) in ({ 14 }) the ({ }) \MATH ({ 15 }) pairs ({ 16 }) is ({ 17 }) formed ({ 18 }) by ({ 19 }) a ({ 20 }) candidate ({ 21 }) item ({ 22 }) and ({ 23 }) its ({ 24 }) corresponding ({ 25 }) match ({ 26 }) , ({ 27 }) we ({ 28 }) can ({ 30 }) enumerate ({ 31 }) the ({ 32 }) number ({ 33 }) of ({ 34 }) occurrences ({ 35 }) of ({ 36 }) the ({ 37 }) items ({ 38 }) . ({ 39 }) 
# Sentence pair (3314) source length 20 target length 17 alignment score : 1.43002e-09
However , there are several regions highly overlap each other due to merging in Step 1 . 
NULL ({ }) However ({ 1 }) , ({ 2 }) there ({ 3 }) are ({ 4 }) likely ({ }) several ({ 5 }) regions ({ 6 }) that ({ }) overlap ({ 7 8 }) each ({ 9 }) other ({ 10 }) due ({ 11 }) to ({ 12 }) the ({ }) merging ({ 13 }) done ({ }) in ({ 14 }) Step ({ 15 }) 1 ({ 16 }) . ({ 17 }) 
# Sentence pair (3315) source length 12 target length 11 alignment score : 2.97831e-13
They are perceived as the same item by human being . 
NULL ({ }) These ({ 1 }) regions ({ }) would ({ 2 }) be ({ }) perceived ({ 3 }) as ({ 4 }) the ({ 5 }) same ({ 6 }) item ({ 7 }) by ({ 8 }) users ({ 9 10 }) . ({ 11 }) 
# Sentence pair (3316) source length 21 target length 18 alignment score : 1.7492e-13
Thus , we propose to use maximal clique analysis technique to group such regions for consistent recommendations . 
NULL ({ }) Thus ({ 1 }) , ({ 2 }) we ({ 3 }) propose ({ 4 }) to ({ 5 }) use ({ 6 }) maximal ({ 7 }) clique ({ 8 }) analysis ({ 9 }) to ({ 11 }) group ({ 12 }) such ({ 13 }) regions ({ 14 }) so ({ 15 }) that ({ }) the ({ }) recommendations ({ 17 }) will ({ 10 }) be ({ }) consistent ({ 16 }) . ({ 18 }) 
# Sentence pair (3317) source length 8 target length 8 alignment score : 0.0670304
One clique is one group of regions . 
NULL ({ }) One ({ 1 }) clique ({ 2 }) is ({ 3 }) one ({ 4 }) group ({ 5 }) of ({ 6 }) regions ({ 7 }) . ({ 8 }) 
# Sentence pair (3318) source length 6 target length 6 alignment score : 0.111652
Step 4 : Formulating recommendations . 
NULL ({ }) Step ({ 1 }) 4 ({ 2 }) : ({ 3 }) Formulate ({ 4 }) recommendations ({ 5 }) . ({ 6 }) 
# Sentence pair (3319) source length 27 target length 27 alignment score : 5.28628e-05
Finally , for each group of regions , we count the number of images containing at least one match of one member region of the group . 
NULL ({ }) Finally ({ 1 }) , ({ 2 }) for ({ 3 }) each ({ 4 }) group ({ 5 }) of ({ 6 }) regions ({ 7 }) , ({ 8 }) we ({ 9 }) count ({ 10 }) the ({ 11 }) number ({ 12 }) of ({ 13 }) images ({ 14 }) containing ({ 15 }) at ({ 16 }) least ({ 17 }) one ({ 18 }) match ({ 19 }) of ({ 20 }) one ({ 21 }) member ({ 22 }) region ({ 23 }) of ({ 24 }) the ({ 25 }) group ({ 26 }) . ({ 27 }) 
# Sentence pair (3320) source length 18 target length 18 alignment score : 0.000377743
The number indicates how frequent the item , represented by the group , occurs in the database . 
NULL ({ }) The ({ 1 }) number ({ 2 }) indicates ({ 3 }) how ({ 4 }) frequent ({ 5 }) the ({ 6 }) item ({ 7 }) , ({ 8 }) represented ({ 9 }) by ({ 10 }) the ({ 11 }) group ({ 12 }) , ({ 13 }) occurs ({ 14 }) in ({ 15 }) the ({ 16 }) database ({ 17 }) . ({ 18 }) 
# Sentence pair (3321) source length 16 target length 18 alignment score : 3.17296e-16
Using those numbers , we rank all groups and then introduce them to users as our recommendations . 
NULL ({ 10 }) Using ({ 1 }) those ({ 2 }) numbers ({ 3 }) , ({ 4 }) we ({ 5 }) rank ({ 6 }) all ({ 7 }) groups ({ 8 }) and ({ 9 }) show ({ 11 }) them ({ 12 }) as ({ 15 }) recommendations ({ 16 17 }) to ({ 13 }) users ({ 14 }) . ({ 18 }) 
# Sentence pair (3322) source length 22 target length 20 alignment score : 1.23779e-06
Representative of each group is a rectangular region located by averaging coordinates of all member regions of the group . 
NULL ({ }) A ({ }) representative ({ 1 }) of ({ 2 }) each ({ 3 }) group ({ 4 }) is ({ 5 }) a ({ 6 }) rectangular ({ 7 }) region ({ 8 }) located ({ 9 }) by ({ 10 }) averaging ({ 11 }) the ({ }) coordinates ({ 12 }) of ({ 13 }) all ({ 14 }) member ({ 15 }) regions ({ 16 }) of ({ 17 }) the ({ 18 }) group ({ 19 }) . ({ 20 }) 
# Sentence pair (3323) source length 26 target length 26 alignment score : 1.29601e-10
In this section , we introduce our proposed approach for efficiently finding top \MATH similar region pairs in the pool of all possible region pairs . 
NULL ({ 8 }) In ({ 1 }) this ({ 2 }) section ({ 3 }) , ({ 4 }) we ({ 5 }) describe ({ 6 }) our ({ 7 }) approach ({ 9 }) for ({ 10 }) efficiently ({ 11 }) finding ({ 12 }) the ({ }) top ({ 13 }) \MATH ({ 14 }) similar ({ 15 }) region ({ 16 }) pairs ({ 17 }) in ({ 18 }) the ({ 19 }) pool ({ 20 }) of ({ 21 }) all ({ 22 }) possible ({ 23 }) region ({ 24 }) pairs ({ 25 }) . ({ 26 }) 
# Sentence pair (3324) source length 23 target length 23 alignment score : 2.84066e-07
Given two sets of regions \MATH and \MATH , the set of all possible region pairs then can be represented as \MATH . 
NULL ({ }) Given ({ 1 }) two ({ 2 }) sets ({ 3 }) of ({ 4 }) regions ({ 5 }) \MATH ({ 6 }) and ({ 7 }) \MATH ({ 8 }) , ({ 9 }) the ({ 10 }) set ({ 11 }) of ({ 12 }) all ({ 13 }) possible ({ 14 }) region ({ 15 }) pairs ({ 16 }) can ({ 18 }) then ({ 17 }) be ({ 19 }) represented ({ 20 }) as ({ 21 }) \MATH ({ 22 }) . ({ 23 }) 
# Sentence pair (3325) source length 29 target length 28 alignment score : 7.93633e-10
With a similarity function \MATH , we have to solve the following optimization problem in order to find the region pair \MATH with the highest similarity score . 
NULL ({ }) By ({ 1 }) using ({ 2 }) the ({ }) similarity ({ 3 }) function ({ 4 }) \MATH ({ 5 }) , ({ 6 }) we ({ 7 }) have ({ 8 }) to ({ 9 }) solve ({ 10 }) the ({ 11 }) following ({ 12 }) optimization ({ 13 }) problem ({ 14 }) in ({ 15 }) order ({ 16 }) to ({ 17 }) find ({ 18 }) the ({ 19 }) region ({ 20 }) pair ({ 21 }) \MATH ({ 22 }) with ({ 23 }) the ({ 24 }) highest ({ 25 }) similarity ({ 26 }) score ({ 27 }) . ({ 28 }) 
# Sentence pair (3326) source length 13 target length 13 alignment score : 0.00302324
Because \MATH elements , it is expensive to perform this maximization exhaustively . 
NULL ({ }) Because ({ 1 }) \MATH ({ 2 }) elements ({ 3 }) , ({ 4 }) it ({ 5 }) is ({ 6 }) expensive ({ 7 }) to ({ 8 }) perform ({ 9 }) this ({ 10 }) maximization ({ 11 }) exhaustively ({ 12 }) . ({ 13 }) 
# Sentence pair (3327) source length 14 target length 12 alignment score : 4.2395e-06
We propose to use a branch-and-bound algorithm \CITE for the problem . 
NULL ({ }) We ({ 1 }) hence ({ }) propose ({ 2 }) to ({ 3 }) use ({ 4 }) a ({ 5 }) branch-and-bound ({ 6 }) algorithm ({ 7 }) \CITE ({ 8 }) to ({ }) solve ({ 9 }) the ({ 10 }) problem ({ 11 }) . ({ 12 }) 
# Sentence pair (3328) source length 34 target length 31 alignment score : 1.10924e-11
Once \MATH is found , we can obtain the other top region pairs by continuing the search processs with the remaining search spaces , in which found top pairs eliminated . 
NULL ({ }) Once ({ 1 }) \MATH ({ 2 }) is ({ 3 }) found ({ 4 }) , ({ 5 }) we ({ 6 }) can ({ 7 }) obtain ({ 8 }) the ({ 9 }) other ({ 10 }) top ({ 11 }) region ({ 12 }) pairs ({ 13 }) by ({ 14 }) continuing ({ 15 }) the ({ 16 }) search ({ 17 }) process ({ 18 }) with ({ 19 }) the ({ 20 }) remaining ({ 21 }) search ({ 22 }) space ({ 23 }) , ({ 24 }) in ({ 25 }) which ({ 26 }) the ({ }) found ({ 27 }) top ({ 28 }) pairs ({ 29 }) have ({ }) been ({ }) eliminated ({ 30 }) . ({ 31 }) 
# Sentence pair (3329) source length 22 target length 20 alignment score : 4.27481e-11
A general branch-and-bound algorithm works by hierarchically dividing the parameter space into disjoint parts , known as branching step . 
NULL ({ 17 }) A ({ 1 }) general ({ 2 }) branch-and-bound ({ 3 }) algorithm ({ 4 }) works ({ 5 }) by ({ 6 }) hierarchically ({ 7 }) dividing ({ 8 }) the ({ 9 }) parameter ({ 10 }) space ({ 11 }) into ({ 12 }) disjoint ({ 13 }) parts ({ 14 }) ; ({ 15 }) this ({ }) is ({ }) called ({ 16 }) the ({ }) branching ({ 18 }) step ({ 19 }) . ({ 20 }) 
# Sentence pair (3330) source length 68 target length 28 alignment score : 2.00924e-48
In the bounding step , each part is assigned an upper bound value that the quality function could take on any of the members of the part . 
NULL ({ }) In ({ 1 }) the ({ 2 }) bounding ({ 3 }) step ({ 4 }) , ({ 5 }) each ({ 6 }) part ({ 7 }) is ({ 8 }) assigned ({ 9 }) an ({ 10 }) upper ({ 11 }) bound ({ 12 }) for ({ }) which ({ }) the ({ }) quality ({ 16 }) function ({ 17 }) could ({ 18 }) take ({ 19 }) on ({ 20 }) any ({ 21 }) of ({ 22 }) the ({ 23 }) members ({ 24 }) of ({ 25 }) the ({ 26 }) part ({ 27 }) . ({ 28 }) //<The ({ }) rewrite ({ }) is ({ }) grammatical ({ }) but ({ }) I ({ }) don ({ 13 }) 't ({ 14 }) know ({ }) what ({ }) " ({ }) the ({ 15 }) quality ({ }) function ({ }) could ({ }) take ({ }) on ({ }) any ({ }) of ({ }) the ({ }) members ({ }) of ({ }) the ({ }) part ({ }) " ({ }) . ({ }) Inparticular ({ }) what ({ }) are ({ }) these ({ }) members ({ }) and ({ }) can ({ }) they ({ }) be ({ }) computed ({ }) in ({ }) a ({ }) function ({ }) ?> ({ }) 
# Sentence pair (3331) source length 15 target length 14 alignment score : 0.000111212
Parts of the parameter space with higher upper bound values are examined first . 
NULL ({ }) Those ({ 1 }) parts ({ }) of ({ 2 }) the ({ 3 }) parameter ({ 4 }) space ({ 5 }) with ({ 6 }) higher ({ 7 }) upper ({ 8 }) bound ({ 9 }) values ({ 10 }) are ({ 11 }) examined ({ 12 }) first ({ 13 }) . ({ 14 }) 
# Sentence pair (3332) source length 24 target length 24 alignment score : 3.78734e-06
So , many portions of the parameter space can be eliminated if their upper bound values imply that they cannot contain the maximum . 
NULL ({ }) Thus ({ 1 }) , ({ 2 }) many ({ 3 }) portions ({ 4 }) of ({ 5 }) the ({ 6 }) parameter ({ 7 }) space ({ 8 }) can ({ 9 }) be ({ 10 }) eliminated ({ 11 }) if ({ 12 }) their ({ 13 }) upper ({ 14 }) bound ({ 15 }) values ({ 16 }) imply ({ 17 }) that ({ 18 }) they ({ 19 }) cannot ({ 20 }) contain ({ 21 }) the ({ 22 }) maximum ({ 23 }) . ({ 24 }) 
# Sentence pair (3333) source length 26 target length 27 alignment score : 1.68007e-10
Adapting to our problem , the parameter space is the set of all region pairs \MATH , and the quality function is the similarity function \MATH . 
NULL ({ 2 }) In ({ 1 }) our ({ 3 }) problem ({ 4 }) , ({ 5 }) the ({ 6 }) parameter ({ 7 }) space ({ 8 }) is ({ 9 }) the ({ 10 }) set ({ 11 }) of ({ 12 }) all ({ 13 }) region ({ 14 }) pairs ({ 15 }) \MATH ({ 16 }) , ({ 17 }) and ({ 18 }) the ({ 19 }) quality ({ 20 }) function ({ 21 }) is ({ 22 }) the ({ 23 }) similarity ({ 24 }) function ({ 25 }) \MATH ({ 26 }) . ({ 27 }) 
# Sentence pair (3334) source length 21 target length 21 alignment score : 0.000304475
Assuming we can organize regions in \MATH and \MATH into two hierarchical structures \MATH and \MATH respectively , so that : 
NULL ({ }) Assuming ({ 1 }) we ({ 2 }) can ({ 3 }) organize ({ 4 }) regions ({ 5 }) in ({ 6 }) \MATH ({ 7 }) and ({ 8 }) \MATH ({ 9 }) into ({ 10 }) two ({ 11 }) hierarchical ({ 12 }) structures ({ 13 }) \MATH ({ 14 }) and ({ 15 }) \MATH ({ 16 }) respectively ({ 17 }) , ({ 18 }) so ({ 19 }) that ({ 20 }) : ({ 21 }) 
# Sentence pair (3335) source length 17 target length 17 alignment score : 0.00239861
- all regions are leaf nodes of the structures and non-leaf nodes are {\it virtual} nodes , 
NULL ({ }) - ({ 1 }) all ({ 2 }) regions ({ 3 }) are ({ 4 }) leaf ({ 5 }) nodes ({ 6 }) of ({ 7 }) the ({ 8 }) structures ({ 9 }) and ({ 10 }) non-leaf ({ 11 }) nodes ({ 12 }) are ({ 13 }) {\it ({ 14 }) virtual} ({ 15 }) nodes ({ 16 }) , ({ 17 }) 
# Sentence pair (3336) source length 42 target length 41 alignment score : 1.16922e-15
- if each node is repsented by a histgoram \MATH with \MATH bins , the value at each bin of a child node is constrainted to be equal or smaller the value at the same bin of its parent node . 
NULL ({ }) - ({ 1 }) if ({ 2 }) each ({ 3 }) node ({ 4 }) is ({ 5 }) represented ({ 6 }) by ({ 7 }) a ({ 8 }) histogram ({ 9 }) \MATH ({ 10 }) with ({ 11 }) \MATH ({ 12 }) bins ({ 13 }) , ({ 14 }) the ({ 15 }) value ({ 16 }) in ({ 17 }) each ({ 18 }) bin ({ 19 }) of ({ 20 }) a ({ 21 }) child ({ 22 }) node ({ 23 }) is ({ 24 }) constrained ({ 25 }) to ({ 26 }) be ({ 27 }) equal ({ 28 }) or ({ 29 }) smaller ({ 30 }) than ({ }) the ({ 31 }) value ({ 32 }) in ({ 33 }) the ({ 34 }) same ({ 35 }) bin ({ 36 }) of ({ 37 }) its ({ 38 }) parent ({ 39 }) node ({ 40 }) . ({ 41 }) 
# Sentence pair (3337) source length 21 target length 18 alignment score : 1.9457e-15
Given such structures , we show in the following how a branch-and-bound algorithm applied to our problem . 
NULL ({ 8 }) Given ({ 1 }) such ({ 2 }) structures ({ 3 }) , ({ 4 }) we ({ 5 }) show ({ 6 }) in ({ 7 }) what ({ }) follows ({ 9 }) how ({ 10 }) the ({ 11 }) branch-and-bound ({ 12 }) algorithm ({ 13 }) can ({ }) be ({ }) used ({ 14 }) to ({ 15 }) solve ({ }) our ({ 16 }) problem ({ 17 }) . ({ 18 }) 
# Sentence pair (3338) source length 12 target length 12 alignment score : 0.020085
Let \MATH and \MATH denote two nodes on \MATH and \MATH . 
NULL ({ }) Let ({ 1 }) \MATH ({ 2 }) and ({ 3 }) \MATH ({ 4 }) denote ({ 5 }) two ({ 6 }) nodes ({ 7 }) on ({ 8 }) \MATH ({ 9 }) and ({ 10 }) \MATH ({ 11 }) . ({ 12 }) 
# Sentence pair (3339) source length 14 target length 14 alignment score : 0.000181333
And , \MATH denotes the set containing all leaf nodes explored from \MATH . 
NULL ({ }) And ({ 1 }) let ({ 2 }) \MATH ({ 3 }) denote ({ 4 }) the ({ 5 }) set ({ 6 }) containing ({ 7 }) all ({ 8 }) leaf ({ 9 }) nodes ({ 10 }) explored ({ 11 }) from ({ 12 }) \MATH ({ 13 }) . ({ 14 }) 
# Sentence pair (3340) source length 9 target length 9 alignment score : 0.0449834
If \MATH is a leaf node , \MATH . 
NULL ({ }) If ({ 1 }) \MATH ({ 2 }) is ({ 3 }) a ({ 4 }) leaf ({ 5 }) node ({ 6 }) , ({ 7 }) \MATH ({ 8 }) . ({ 9 }) 
# Sentence pair (3341) source length 22 target length 22 alignment score : 9.03876e-05
Otherwise , given \MATH with \MATH are direct child nodes of \MATH , \MATH can be recursively defined as follows : \MATH 
NULL ({ }) Otherwise ({ 1 }) , ({ 2 }) given ({ 3 }) \MATH ({ 4 }) with ({ 5 }) \MATH ({ 6 }) being ({ 7 }) direct ({ 8 }) child ({ 9 }) nodes ({ 10 }) of ({ 11 }) \MATH ({ 12 }) , ({ 13 }) \MATH ({ 14 }) can ({ 15 }) be ({ 16 }) recursively ({ 17 }) defined ({ 18 }) as ({ 19 }) follows ({ 20 }) : ({ 21 }) \MATH ({ 22 }) 
# Sentence pair (3342) source length 9 target length 9 alignment score : 0.0400364
In a similar way , we have : \MATH 
NULL ({ }) In ({ 1 }) a ({ 2 }) similar ({ 3 }) way ({ 4 }) , ({ 5 }) we ({ 6 }) have ({ 7 }) : ({ 8 }) \MATH ({ 9 }) 
# Sentence pair (3343) source length 30 target length 23 alignment score : 5.4965e-13
Given \MATH indicates the set of node pairs formed by paring nodes in \MATH with nodes in \MATH , we have : \MATH 
NULL ({ }) Letting ({ 1 }) \MATH ({ 2 }) indicate ({ 3 }) the ({ 4 }) set ({ 5 }) of ({ 6 }) node ({ 7 }) pairs ({ 8 }) formed ({ 9 }) by ({ 10 }) pairing ({ 11 }) nodes ({ 12 }) in ({ 13 }) \MATH ({ 14 }) with ({ 15 }) nodes ({ 16 }) in ({ 17 }) \MATH ({ 18 }) , ({ 19 }) we ({ 20 }) get ({ 21 }) : ({ 22 }) \MATH ({ 23 }) . ({ }) //<the ({ }) rewrite ({ }) is ({ }) a ({ }) guess ({ }) .> ({ }) 
# Sentence pair (3344) source length 24 target length 24 alignment score : 1.16386e-09
So , if \MATH and \MATH are roots of \MATH and \MATH respectively , \MATH will exactly be the entire search space \MATH . 
NULL ({ }) Thus ({ 1 }) , ({ 2 }) if ({ 3 }) \MATH ({ 4 }) and ({ 5 }) \MATH ({ 6 }) are ({ 7 }) roots ({ 8 }) of ({ 9 }) \MATH ({ 10 }) and ({ 11 }) \MATH ({ 12 }) respectively ({ 13 }) , ({ 14 }) \MATH ({ 15 }) will ({ 16 }) be ({ 18 }) exactly ({ 17 }) the ({ 19 }) entire ({ 20 }) search ({ 21 }) space ({ 22 }) \MATH ({ 23 }) . ({ 24 }) 
# Sentence pair (3345) source length 3 target length 3 alignment score : 0.458062
Branching Step . 
NULL ({ }) Branching ({ 1 }) Step ({ 2 }) . ({ 3 }) 
# Sentence pair (3346) source length 43 target length 31 alignment score : 1.02124e-18
Dividing the search space ( i.e. set of region pairs ) covered by \MATH is straightforward by utilizing the hierarchical structures \MATH , \MATH at certain nodes \MATH , \MATH . 
NULL ({ }) Dividing ({ 1 }) up ({ }) the ({ 2 }) search ({ 3 }) space ({ 4 }) ( ({ 5 }) i.e. ({ 6 }) set ({ 7 }) of ({ 8 }) region ({ 9 }) pairs ({ 10 }) ) ({ 11 }) covered ({ 12 }) by ({ 13 }) \MATH ({ 14 }) can ({ }) be ({ }) done ({ }) straightforwardly ({ 16 }) by ({ 17 }) utilizing ({ 18 }) the ({ 19 }) hierarchical ({ 20 }) structures ({ 21 }) \MATH ({ 22 }) , ({ 23 }) \MATH ({ 24 }) at ({ 25 }) certain ({ 26 }) nodes ({ 27 }) \MATH ({ 28 }) , ({ 29 }) \MATH ({ 30 }) . ({ 31 }) //<The ({ 15 }) rewrite ({ }) is ({ }) better ({ }) if ({ }) it ({ }) is ({ }) correct ({ }) .> ({ }) 
# Sentence pair (3347) source length 18 target length 19 alignment score : 3.60352e-05
Regarding to \REF , \REF and \REF , \MATH can be divided into disjoint parts as follows : \MATH 
NULL ({ 2 }) Regarding ({ 1 }) \REF ({ 3 }) , ({ 4 }) \REF ({ 5 }) and ({ 6 }) \REF ({ 7 }) , ({ 8 }) \MATH ({ 9 }) can ({ 10 }) be ({ 11 }) divided ({ 12 }) into ({ 13 }) disjoint ({ 14 }) parts ({ 15 }) as ({ 16 }) follows ({ 17 }) : ({ 18 }) \MATH ({ 19 }) 
# Sentence pair (3348) source length 3 target length 3 alignment score : 0.415797
Or , \MATH 
NULL ({ }) Or ({ 1 }) , ({ 2 }) \MATH ({ 3 }) 
# Sentence pair (3349) source length 15 target length 15 alignment score : 1.20268e-10
Selecting which way to divide can be based on sizes of \MATH and \MATH . 
NULL ({ 2 }) The ({ 1 }) way ({ 3 }) to ({ 4 }) divide ({ 5 }) can ({ 6 }) be ({ 7 }) based ({ 8 }) on ({ 9 }) the ({ }) sizes ({ 10 }) of ({ 11 }) \MATH ({ 12 }) and ({ 13 }) \MATH ({ 14 }) . ({ 15 }) 
# Sentence pair (3350) source length 7 target length 10 alignment score : 8.52642e-12
We select the larger one to be divided first . 
NULL ({ 6 }) We ({ 1 }) divide ({ 2 7 8 }) the ({ 3 }) larger ({ 4 }) one ({ 5 }) first ({ 9 }) . ({ 10 }) 
# Sentence pair (3351) source length 9 target length 12 alignment score : 3.90219e-14
An illustration of a branching step is given in Figure \REF . 
NULL ({ 3 4 }) The ({ }) branching ({ 1 2 5 }) step ({ 6 }) is ({ 7 }) illustrated ({ 8 }) in ({ 9 }) Figure ({ 10 }) \REF ({ 11 }) . ({ 12 }) 
# Sentence pair (3352) source length 3 target length 3 alignment score : 0.460604
Bounding Step . 
NULL ({ }) Bounding ({ 1 }) Step ({ 2 }) . ({ 3 }) 
# Sentence pair (3353) source length 36 target length 26 alignment score : 2.71557e-17
An essential requirement for branch-and-bound is the quality bounding function \MATH used to evaluate how necessary a part of the search space should be examined . 
NULL ({ }) An ({ 1 }) essential ({ 2 }) requirement ({ 3 }) for ({ 4 }) the ({ }) branch-and-bound ({ 5 }) algorithm ({ }) is ({ 6 }) the ({ 7 }) quality ({ 8 }) bounding ({ 9 }) function ({ 10 }) \MATH ({ 11 }) used ({ 12 }) to ({ 13 }) determine ({ }) whether ({ }) a ({ 17 }) part ({ 18 }) of ({ 19 }) the ({ 20 }) search ({ 21 }) space ({ 22 }) should ({ 23 }) be ({ 24 }) examined ({ 25 }) . ({ 26 }) //<Or ({ 16 }) " ({ }) determine ({ }) the ({ }) extent ({ 14 }) that ({ }) " ({ }) ? ({ }) ?> ({ 15 }) 
# Sentence pair (3354) source length 22 target length 21 alignment score : 2.52751e-06
Particularly , \MATH bounds the upper values of \MATH over a set of node pairs ( i.e. region pairs ) . 
NULL ({ }) In ({ }) particular ({ 1 }) , ({ 2 }) \MATH ({ 3 }) bounds ({ 4 }) the ({ 5 }) upper ({ 6 }) values ({ 7 }) of ({ 8 }) \MATH ({ 9 }) over ({ 10 }) a ({ 11 }) set ({ 12 }) of ({ 13 }) node ({ 14 }) pairs ({ 15 }) ( ({ 16 }) i.e. ({ 17 }) region ({ 18 }) pairs ({ 19 }) ) ({ 20 }) . ({ 21 }) 
# Sentence pair (3355) source length 19 target length 17 alignment score : 2.20798e-09
Assuming we are now evaluating the upper bound of \MATH over all region pairs in \MATH . 
NULL ({ }) Let ({ 1 }) us ({ }) assume ({ 4 }) that ({ }) we ({ 2 }) are ({ 3 }) evaluating ({ 5 }) the ({ 6 }) upper ({ 7 }) bound ({ 8 }) of ({ 9 }) \MATH ({ 10 }) over ({ 11 }) all ({ 12 }) region ({ 13 }) pairs ({ 14 }) in ({ 15 }) \MATH ({ 16 }) . ({ 17 }) 
# Sentence pair (3356) source length 34 target length 33 alignment score : 1.32705e-17
Among several types of distance for estimating the similarity of two regions , we stick to Normalized Histogram Intersection ( NHI ) distance since it is well-balanced between computational efficiency and robustness~\cite{ESR} . 
NULL ({ 4 16 }) Among ({ 1 }) the ({ }) several ({ 2 }) distance ({ 5 }) formulas ({ 3 }) for ({ 6 }) estimating ({ 7 }) the ({ 8 }) similarity ({ 9 }) of ({ 10 }) two ({ 11 }) regions ({ 12 }) , ({ 13 }) we ({ 14 }) will ({ 15 }) use ({ }) the ({ }) Normalized ({ 17 }) Histogram ({ 18 }) Intersection ({ 19 }) ( ({ 20 }) NHI ({ 21 }) ) ({ 22 }) distance ({ 23 }) since ({ 24 }) it ({ 25 }) is ({ 26 }) well-balanced ({ 27 }) between ({ 28 }) computational ({ 29 }) efficiency ({ 30 }) and ({ 31 }) robustness~\cite{ESR} ({ 32 }) . ({ 33 }) 
# Sentence pair (3357) source length 18 target length 17 alignment score : 0.000217372
We then rely on NHI to define \MATH bounding the values of \MATH , with : \MATH 
NULL ({ }) We ({ 1 }) will ({ }) then ({ 2 }) rely ({ 3 }) on ({ 4 }) NHI ({ 5 }) to ({ 6 }) define ({ 7 }) \MATH ({ 8 }) bounding ({ 9 }) the ({ 10 }) values ({ 11 }) of ({ 12 }) \MATH ({ 13 }) , ({ 14 }) with ({ 15 }) : ({ 16 }) \MATH ({ 17 }) 
# Sentence pair (3358) source length 16 target length 17 alignment score : 0.000146654
Referring to the constraint ( b ) in constructing \MATH and \MATH , we have : \MATH 
NULL ({ 3 }) Referring ({ 1 }) to ({ 2 }) constraint ({ 4 }) ( ({ 5 }) b ({ 6 }) ) ({ 7 }) in ({ 8 }) constructing ({ 9 }) \MATH ({ 10 }) and ({ 11 }) \MATH ({ 12 }) , ({ 13 }) we ({ 14 }) have ({ 15 }) : ({ 16 }) \MATH ({ 17 }) 
# Sentence pair (3359) source length 40 target length 17 alignment score : 8.98341e-27
As a result , the bounding value \MATH over \MATH can be clearly observed as : \MATH 
NULL ({ }) As ({ 1 }) a ({ 2 }) result ({ 3 }) , ({ 4 }) the ({ 5 }) bounding ({ 6 }) value ({ 7 }) \MATH ({ 8 }) over ({ 9 }) \MATH ({ 10 }) can ({ 11 }) be ({ 12 }) clearly ({ 13 }) observed ({ 14 }) as ({ 15 }) : ({ 16 }) \MATH ({ 17 }) . ({ }) //<I ({ }) 'm ({ }) not ({ }) sure ({ }) what ({ }) observed ({ }) means ({ }) in ({ }) this ({ }) context ({ }) . ({ }) Do ({ }) you ({ }) mean ({ }) " ({ }) can ({ }) be ({ }) derived ({ }) as ({ }) " ({ }) ? ({ }) ?> ({ }) 
# Sentence pair (3360) source length 28 target length 28 alignment score : 3.01006e-08
We can efficiently evaluate \MATH for the set of region pairs \MATH because \MATH is relied only on histogram representation of single rectangular regions \MATH and \MATH . 
NULL ({ 15 }) We ({ 1 }) can ({ 2 }) efficiently ({ 3 }) evaluate ({ 4 }) \MATH ({ 5 }) for ({ 6 }) the ({ 7 }) set ({ 8 }) of ({ 9 }) region ({ 10 }) pairs ({ 11 }) \MATH ({ 12 }) because ({ 13 }) \MATH ({ 14 }) relies ({ 16 }) only ({ 17 }) on ({ 18 }) the ({ }) histogram ({ 19 }) representation ({ 20 }) of ({ 21 }) single ({ 22 }) rectangular ({ 23 }) regions ({ 24 }) \MATH ({ 25 }) and ({ 26 }) \MATH ({ 27 }) . ({ 28 }) 
# Sentence pair (3361) source length 33 target length 32 alignment score : 5.02805e-07
And , the normalization terms , which indicate the minimum number of visual words inside any member region of \MATH , \MATH , are computed once by using integral image technique . 
NULL ({ }) Moreover ({ 1 }) , ({ 2 }) the ({ 3 }) normalization ({ 4 }) terms ({ 5 }) , ({ 6 }) which ({ 7 }) indicate ({ 8 }) the ({ 9 }) minimum ({ 10 }) number ({ 11 }) of ({ 12 }) visual ({ 13 }) words ({ 14 }) inside ({ 15 }) any ({ 16 }) member ({ 17 }) region ({ 18 }) of ({ 19 }) \MATH ({ 20 }) , ({ 21 }) \MATH ({ 22 }) , ({ 23 }) are ({ 24 }) computed ({ 25 }) once ({ 26 }) by ({ 27 }) using ({ 28 }) the ({ }) integral ({ 29 }) image ({ 30 }) technique ({ 31 }) . ({ 32 }) 
# Sentence pair (3362) source length 39 target length 12 alignment score : 6.4004e-31
Inspired by \CITE , we form the algorithm in best-first manner . 
NULL ({ }) Inspired ({ 1 }) by ({ 2 }) \CITE ({ 3 }) , ({ 4 }) we ({ 5 }) devised ({ 6 }) the ({ 7 }) algorithm ({ 8 }) to ({ }) work ({ }) in ({ 9 }) a ({ }) best-first ({ 10 }) manner ({ 11 }) . ({ 12 }) //<The ({ }) original ({ }) describes ({ }) the ({ }) way ({ }) you ({ }) decided ({ }) to ({ }) write ({ }) the ({ }) algorithm ({ }) . ({ }) In ({ }) contrast ({ }) , ({ }) the ({ }) rewrite ({ }) describes ({ }) the ({ }) way ({ }) the ({ }) algorithm ({ }) works ({ }) .> ({ }) 
# Sentence pair (3363) source length 24 target length 12 alignment score : 7.75616e-14
The algorithm examines next the set having highest bounding value \MATH . 
NULL ({ }) The ({ 1 }) algorithm ({ 2 }) examines ({ 3 }) the ({ }) set ({ 6 }) having ({ 7 }) the ({ }) highest ({ 8 }) bounding ({ 9 }) value ({ 10 }) \MATH ({ 11 }) . ({ 12 }) //<" ({ }) next ({ 4 }) " ({ }) is ({ }) unclear ({ }) . ({ }) The ({ }) rewrite ({ }) is ({ }) a ({ }) guess ({ 5 }) .> ({ }) 
# Sentence pair (3364) source length 13 target length 13 alignment score : 0.00868278
The algorithm stops if the set contain only one pair of region . 
NULL ({ }) The ({ 1 }) algorithm ({ 2 }) stops ({ 3 }) if ({ 4 }) the ({ 5 }) set ({ 6 }) contain ({ 7 }) only ({ 8 }) one ({ 9 }) pair ({ 10 }) of ({ 11 }) region ({ 12 }) . ({ 13 }) 
# Sentence pair (3365) source length 14 target length 14 alignment score : 0.00543889
Otherwise , the set is then divided into disjoint subsets for further search . 
NULL ({ }) Otherwise ({ 1 }) , ({ 2 }) the ({ 3 }) set ({ 4 }) is ({ 5 }) then ({ 6 }) divided ({ 7 }) into ({ 8 }) disjoint ({ 9 }) subsets ({ 10 }) for ({ 11 }) further ({ 12 }) search ({ 13 }) . ({ 14 }) 
# Sentence pair (3366) source length 20 target length 20 alignment score : 0.000836269
Pseudo-code for the algorithm using a priority queue to store sets of region pairs , is given as follows . 
NULL ({ }) Pseudo-code ({ 1 }) for ({ 2 }) the ({ 3 }) algorithm ({ 4 }) using ({ 5 }) a ({ 6 }) priority ({ 7 }) queue ({ 8 }) to ({ 9 }) store ({ 10 }) sets ({ 11 }) of ({ 12 }) region ({ 13 }) pairs ({ 14 }) , ({ 15 }) is ({ 16 }) given ({ 17 }) as ({ 18 }) follows ({ 19 }) . ({ 20 }) 
# Sentence pair (3367) source length 27 target length 29 alignment score : 5.91172e-15
To obtain more than one region pair , we simply continue the loop in the Algorithm 1 until the expected number of region pairs \MATH have been reached . 
NULL ({ 15 }) To ({ 1 }) obtain ({ 2 }) more ({ 3 }) than ({ 4 }) one ({ 5 }) region ({ 6 }) pair ({ 7 }) , ({ 8 }) we ({ 9 }) simply ({ 10 }) repeat ({ 11 }) the ({ 12 }) loop ({ 13 }) in ({ 14 }) Algorithm ({ 16 }) 1 ({ 17 }) until ({ 18 }) the ({ 19 }) expected ({ 20 }) number ({ 21 }) of ({ 22 }) region ({ 23 }) pairs ({ 24 }) \MATH ({ 25 }) is ({ }) reached ({ 26 27 28 }) . ({ 29 }) 
# Sentence pair (3368) source length 32 target length 33 alignment score : 1.9637e-07
So far , our approach is based on an assumption that the sets of regions are already organized into hierarchical structures which satisfy the constraints ( a ) and ( b ) . 
NULL ({ 24 }) So ({ 1 }) far ({ 2 }) , ({ 3 }) our ({ 4 }) approach ({ 5 }) is ({ 6 }) based ({ 7 }) on ({ 8 }) an ({ 9 }) assumption ({ 10 }) that ({ 11 }) the ({ 12 }) sets ({ 13 }) of ({ 14 }) regions ({ 15 }) are ({ 16 }) already ({ 17 }) organized ({ 18 }) into ({ 19 }) hierarchical ({ 20 }) structures ({ 21 }) which ({ 22 }) satisfy ({ 23 }) constraints ({ 25 }) ( ({ 26 }) a ({ 27 }) ) ({ 28 }) and ({ 29 }) ( ({ 30 }) b ({ 31 }) ) ({ 32 }) . ({ 33 }) 
# Sentence pair (3369) source length 24 target length 25 alignment score : 3.2644e-06
In the remaining of this section , we show how to organize such sets , given the initial query image and the image database . 
NULL ({ 22 }) In ({ 1 }) the ({ 2 }) remaining ({ 3 }) of ({ 4 }) this ({ 5 }) section ({ 6 }) , ({ 7 }) we ({ 8 }) show ({ 9 }) how ({ 10 }) to ({ 11 }) organize ({ 12 }) such ({ 13 }) sets ({ 14 }) , ({ 15 }) given ({ 16 }) the ({ 17 }) initial ({ 18 }) query ({ 19 }) image ({ 20 }) and ({ 21 }) image ({ 23 }) database ({ 24 }) . ({ 25 }) 
# Sentence pair (3370) source length 8 target length 10 alignment score : 4.06031e-10
There are two type of region set for organization . 
NULL ({ 8 9 }) There ({ 1 }) are ({ 2 }) two ({ 3 }) type ({ 4 }) of ({ 5 }) region ({ 6 }) set ({ 7 }) . ({ 10 }) 
# Sentence pair (3371) source length 10 target length 9 alignment score : 0.00902919
One is set containing regions of one image . 
NULL ({ }) One ({ 1 }) is ({ 2 }) a ({ }) set ({ 3 }) containing ({ 4 }) regions ({ 5 }) of ({ 6 }) one ({ 7 }) image ({ 8 }) . ({ 9 }) 
# Sentence pair (3372) source length 15 target length 14 alignment score : 0.00160467
The other is set containing regions of multiple images ( i.e. database ) . 
NULL ({ }) The ({ 1 }) other ({ 2 }) is ({ 3 }) a ({ }) set ({ 4 }) containing ({ 5 }) regions ({ 6 }) of ({ 7 }) multiple ({ 8 }) images ({ 9 }) ( ({ 10 }) i.e. ({ 11 }) database ({ 12 }) ) ({ 13 }) . ({ 14 }) 
# Sentence pair (3373) source length 32 target length 32 alignment score : 1.10519e-05
With the first type of set , by applying the selective search approach introduced in \CITE for item selection , regions in each image are already organized into a binary tree . 
NULL ({ }) With ({ 1 }) the ({ 2 }) first ({ 3 }) type ({ 4 }) of ({ 5 }) set ({ 6 }) , ({ 7 }) by ({ 8 }) applying ({ 9 }) the ({ 10 }) selective ({ 11 }) search ({ 12 }) approach ({ 13 }) introduced ({ 14 }) in ({ 15 }) \CITE ({ 16 }) for ({ 17 }) item ({ 18 }) selection ({ 19 }) , ({ 20 }) regions ({ 21 }) in ({ 22 }) each ({ 23 }) image ({ 24 }) are ({ 25 }) already ({ 26 }) organized ({ 27 }) into ({ 28 }) a ({ 29 }) binary ({ 30 }) tree ({ 31 }) . ({ 32 }) 
# Sentence pair (3374) source length 33 target length 31 alignment score : 9.32849e-08
Because such binary tree were constructed by bottom-up merging regions , a parent region on the trees spatially covers its child regions in image space ( see Figure \REF ) . 
NULL ({ }) Because ({ 1 }) such ({ 2 }) binary ({ 3 }) tree ({ 4 }) were ({ 5 }) constructed ({ 6 }) by ({ 7 }) bottom-up ({ 8 }) merging ({ 9 }) of ({ }) regions ({ 10 }) , ({ 11 }) a ({ 12 }) parent ({ 13 }) region ({ 14 }) on ({ 15 }) the ({ 16 }) trees ({ 17 }) spatially ({ 18 }) covers ({ 19 }) its ({ 20 }) child ({ 21 }) regions ({ 22 }) in ({ 23 }) the ({ }) image ({ 24 }) space ({ 25 }) ( ({ 26 }) see ({ 27 }) Figure ({ 28 }) \REF ({ 29 }) ) ({ 30 }) . ({ 31 }) 
# Sentence pair (3375) source length 11 target length 13 alignment score : 3.12081e-11
As a result , we have the constraint ( b ) satisfied . 
NULL ({ 5 6 7 }) As ({ 1 }) a ({ 2 }) result ({ 3 }) , ({ 4 }) constraint ({ 8 }) ( ({ 9 }) b ({ 10 }) ) ({ 11 }) is ({ }) satisfied ({ 12 }) . ({ 13 }) 
# Sentence pair (3376) source length 39 target length 41 alignment score : 1.4213e-10
However , because we want to use all regions corresponding to all nodes throughout the tree as candidate item regions , the constraint ( a ) will be violated if we keep using the tree for the branch-and-bound based algorithm . 
NULL ({ 22 }) However ({ 1 }) , ({ 2 }) because ({ 3 }) we ({ 4 }) want ({ 5 }) to ({ 6 }) use ({ 7 }) all ({ 8 }) regions ({ 9 }) corresponding ({ 10 }) to ({ 11 }) all ({ 12 }) nodes ({ 13 }) throughout ({ 14 }) the ({ 15 }) tree ({ 16 }) as ({ 17 }) candidate ({ 18 }) item ({ 19 }) regions ({ 20 }) , ({ 21 }) constraint ({ 23 }) ( ({ 24 }) a ({ 25 }) ) ({ 26 }) will ({ 27 }) be ({ 28 }) violated ({ 29 }) if ({ 30 }) we ({ 31 }) keep ({ 32 }) using ({ 33 }) the ({ 34 }) tree ({ 35 }) for ({ 36 }) the ({ 37 }) branch-and-bound ({ 38 39 }) algorithm ({ 40 }) . ({ 41 }) 
# Sentence pair (3377) source length 28 target length 28 alignment score : 3.02933e-05
In other words , all current non-leaf nodes of the tree will be treated as {\it vitual nodes} and will not be used as candidate item regions . 
NULL ({ }) In ({ 1 }) other ({ 2 }) words ({ 3 }) , ({ 4 }) all ({ 5 }) current ({ 6 }) non-leaf ({ 7 }) nodes ({ 8 }) of ({ 9 }) the ({ 10 }) tree ({ 11 }) will ({ 12 }) be ({ 13 }) treated ({ 14 }) as ({ 15 }) {\it ({ 16 }) vitual ({ 17 }) nodes} ({ 18 }) and ({ 19 }) will ({ 20 }) not ({ 21 }) be ({ 22 }) used ({ 23 }) as ({ 24 }) candidate ({ 25 }) item ({ 26 }) regions ({ 27 }) . ({ 28 }) 
# Sentence pair (3378) source length 8 target length 8 alignment score : 0.0358823
Our solution to this problem is straightforward . 
NULL ({ }) Our ({ 1 }) solution ({ 2 }) to ({ 3 }) this ({ 4 }) problem ({ 5 }) is ({ 6 }) straightforward ({ 7 }) . ({ 8 }) 
# Sentence pair (3379) source length 17 target length 17 alignment score : 0.000184881
We generate and attach a new leaf node to each non-leaf nodes of the current tree . 
NULL ({ }) We ({ 1 }) generate ({ 2 }) and ({ 3 }) attach ({ 4 }) a ({ 5 }) new ({ 6 }) leaf ({ 7 }) node ({ 8 }) to ({ 9 }) each ({ 10 }) non-leaf ({ 11 }) node ({ 12 }) of ({ 13 }) the ({ 14 }) current ({ 15 }) tree ({ 16 }) . ({ 17 }) 
# Sentence pair (3380) source length 23 target length 22 alignment score : 1.81452e-05
The generated node is exactly the same as the non-leaf node it attach to , which now becomes a virtual node . 
NULL ({ }) The ({ 1 }) generated ({ 2 }) node ({ 3 }) is ({ 4 }) exactly ({ 5 }) the ({ 6 }) same ({ 7 }) as ({ 8 }) the ({ 9 }) non-leaf ({ 10 }) node ({ 11 }) it ({ 12 }) is ({ }) attached ({ 13 }) to ({ 14 }) , ({ 15 }) which ({ 16 }) now ({ 17 }) becomes ({ 18 }) a ({ 19 }) virtual ({ 20 }) node ({ 21 }) . ({ 22 }) 
# Sentence pair (3381) source length 21 target length 21 alignment score : 5.08106e-06
By doing that , we keep the spatial covering property of the orginal binary tree for the new hierarchical structure . 
NULL ({ }) By ({ 1 }) doing ({ 2 }) that ({ 3 }) , ({ 4 }) we ({ 5 }) keep ({ 6 }) the ({ 7 }) spatial ({ 8 }) covering ({ 9 }) property ({ 10 }) of ({ 11 }) the ({ 12 }) original ({ 13 }) binary ({ 14 }) tree ({ 15 }) for ({ 16 }) the ({ 17 }) new ({ 18 }) hierarchical ({ 19 }) structure ({ 20 }) . ({ 21 }) 
# Sentence pair (3382) source length 18 target length 18 alignment score : 0.000379691
And , all non-leaf nodes will be taken into account as candidate item regions via their attachments . 
NULL ({ }) Moreover ({ 1 }) , ({ 2 }) all ({ 3 }) non-leaf ({ 4 }) nodes ({ 5 }) will ({ 6 }) be ({ 7 }) taken ({ 8 }) into ({ 9 }) account ({ 10 }) as ({ 11 }) candidate ({ 12 }) item ({ 13 }) regions ({ 14 }) via ({ 15 }) their ({ 16 }) attachments ({ 17 }) . ({ 18 }) 
# Sentence pair (3383) source length 9 target length 17 alignment score : 5.65186e-22
The new hierarchical structure therefore satisfy both the constraints ( a ) and ( b ) . 
NULL ({ 8 11 13 }) The ({ 1 }) new ({ 2 }) hierarchical ({ 3 }) structure ({ 4 }) therefore ({ 5 }) satisfies ({ 6 }) both ({ 7 }) constraints ({ 9 10 12 14 15 16 }) . ({ 17 }) 
# Sentence pair (3384) source length 9 target length 8 alignment score : 5.66346e-13
An illustration is presented in Figure X . 
NULL ({ 5 }) Figure ({ 6 }) X ({ 7 }) is ({ 3 }) an ({ 1 }) illustration ({ 2 }) of ({ }) this ({ }) organization ({ 4 }) . ({ 8 }) 
# Sentence pair (3385) source length 16 target length 16 alignment score : 4.76703e-05
With a set containing regions of multiple images , we perform a two-stage organization procedure . 
NULL ({ }) With ({ 1 }) a ({ 2 }) set ({ 3 }) containing ({ 4 }) regions ({ 5 }) from ({ 6 }) multiple ({ 7 }) images ({ 8 }) , ({ 9 }) we ({ 10 }) perform ({ 11 }) a ({ 12 }) two-stage ({ 13 }) organization ({ 14 }) procedure ({ 15 }) . ({ 16 }) 
# Sentence pair (3386) source length 20 target length 20 alignment score : 7.15126e-10
At the first stage , regions in each image are organized into a hierarchical structure as we presented above . 
NULL ({ 17 }) In ({ 1 }) the ({ 2 }) first ({ 3 }) stage ({ 4 }) , ({ 5 }) regions ({ 6 }) in ({ 7 }) each ({ 8 }) image ({ 9 }) are ({ 10 }) organized ({ 11 }) into ({ 12 }) a ({ 13 }) hierarchical ({ 14 }) structure ({ 15 }) , ({ }) as ({ 16 }) presented ({ 18 }) above ({ 19 }) . ({ 20 }) 
# Sentence pair (3387) source length 39 target length 31 alignment score : 2.16865e-17
Given multiple hierarchical structures returned from the first stage , we use their root nodes as initial elements to construct an yet another hierarchical structure over them by divisive clustering . 
NULL ({ }) If ({ 1 }) multiple ({ 2 }) hierarchical ({ 3 }) structures ({ 4 }) are ({ }) returned ({ 5 }) by ({ 6 }) the ({ 7 }) first ({ 8 }) stage ({ 9 }) , ({ 10 }) we ({ 11 }) use ({ 12 }) their ({ 13 }) root ({ 14 }) nodes ({ 15 }) as ({ 16 }) the ({ }) initial ({ 17 }) elements ({ 18 }) to ({ 19 }) construct ({ 20 }) an ({ 21 }) yet ({ 22 }) another ({ 23 }) hierarchical ({ 24 }) structure ({ 25 }) over ({ 26 }) them ({ 27 }) by ({ 28 }) divisive ({ 29 }) clustering ({ 30 }) . ({ 31 }) //<the ({ }) rewrite ({ }) is ({ }) a ({ }) guess ({ }) .> ({ }) 
# Sentence pair (3388) source length 10 target length 10 alignment score : 0.0199837
We start with the full set of the elements . 
NULL ({ }) We ({ 1 }) start ({ 2 }) with ({ 3 }) the ({ 4 }) full ({ 5 }) set ({ 6 }) of ({ 7 }) the ({ 8 }) elements ({ 9 }) . ({ 10 }) 
# Sentence pair (3389) source length 13 target length 13 alignment score : 1.36784e-07
Then , splits are peformed recursively as one moves down the hierarcy . 
NULL ({ }) Then ({ 1 }) , ({ 2 }) we ({ 3 }) perform ({ 4 }) splits ({ 5 }) recursively ({ 6 }) as ({ 7 }) one ({ 8 }) moves ({ 9 }) down ({ 10 }) the ({ 11 }) hierarchy ({ 12 }) . ({ 13 }) 
# Sentence pair (3390) source length 18 target length 19 alignment score : 8.39715e-08
In each splitting step , the splitted set is divided into $k$ parts by using $k$-means clustering algorithm . 
NULL ({ }) In ({ 1 }) each ({ 2 }) splitting ({ 3 }) step ({ 4 }) , ({ 5 }) the ({ 6 }) split ({ 7 }) set ({ 8 }) is ({ 9 }) divided ({ 10 }) into ({ 11 }) $k$ ({ 12 }) parts ({ 13 }) by ({ 14 }) using ({ 15 }) $k$-means ({ 16 }) clustering ({ 17 18 }) . ({ 19 }) 
# Sentence pair (3391) source length 19 target length 19 alignment score : 3.78204e-10
Once the hierchical structure is completed , we then compute histogram representation for all of its non-leaf nodes . 
NULL ({ 9 }) Once ({ 1 }) the ({ 2 }) hierarchical ({ 3 }) structure ({ 4 }) is ({ 5 }) completed ({ 6 }) , ({ 7 }) we ({ 8 }) compute ({ 10 }) a ({ }) histogram ({ 11 }) representation ({ 12 }) for ({ 13 }) all ({ 14 }) of ({ 15 }) its ({ 16 }) non-leaf ({ 17 }) nodes ({ 18 }) . ({ 19 }) 
# Sentence pair (3392) source length 25 target length 25 alignment score : 3.02743e-09
The value at each hitogram bin of a non-leaf nodes is the maximum of all values at the same bin of its child nodes . 
NULL ({ }) The ({ 1 }) value ({ 2 }) at ({ 3 }) each ({ 4 }) histogram ({ 5 }) bin ({ 6 }) of ({ 7 }) a ({ 8 }) non-leaf ({ 9 }) node ({ 10 }) is ({ 11 }) the ({ 12 }) maximum ({ 13 }) of ({ 14 }) all ({ 15 }) values ({ 16 }) in ({ 17 }) the ({ 18 }) same ({ 19 }) bin ({ 20 }) of ({ 21 }) its ({ 22 }) child ({ 23 }) nodes ({ 24 }) . ({ 25 }) 
# Sentence pair (3393) source length 11 target length 11 alignment score : 9.49345e-06
This is to ensure the constraint ( b ) sastified . 
NULL ({ 5 }) This ({ 1 }) is ({ 2 }) to ({ 3 }) ensure ({ 4 }) constraint ({ 6 }) ( ({ 7 }) b ({ 8 }) ) ({ 9 }) is ({ }) satisfied ({ 10 }) . ({ 11 }) 
# Sentence pair (3394) source length 30 target length 31 alignment score : 1.28441e-13
At last , by unifying results of both stages , we have a unique hierarchical structure over the set of regions of multiple images , which satisfies the both constraints . 
NULL ({ 28 }) Finally ({ 1 2 }) , ({ 3 }) by ({ 4 }) unifying ({ 5 }) the ({ }) results ({ 6 }) of ({ 7 }) both ({ 8 }) stages ({ 9 }) , ({ 10 }) we ({ 11 }) have ({ 12 }) a ({ 13 }) unique ({ 14 }) hierarchical ({ 15 }) structure ({ 16 }) over ({ 17 }) the ({ 18 }) set ({ 19 }) of ({ 20 }) regions ({ 21 }) of ({ 22 }) multiple ({ 23 }) images ({ 24 }) , ({ 25 }) which ({ 26 }) satisfies ({ 27 }) both ({ 29 }) constraints ({ 30 }) . ({ 31 }) 
# Sentence pair (3395) source length 7 target length 8 alignment score : 2.1189e-07
We show an illustration in Figure Y . 
NULL ({ }) We ({ 1 }) illustratie ({ 2 3 4 }) this ({ }) in ({ 5 }) Figure ({ 6 }) Y ({ 7 }) . ({ 8 }) 
# Sentence pair (3396) source length 19 target length 19 alignment score : 0.00124564
So , given the initial query image and a database , we now can construct two hierarchical structures . 
NULL ({ }) So ({ 1 }) , ({ 2 }) given ({ 3 }) the ({ 4 }) initial ({ 5 }) query ({ 6 }) image ({ 7 }) and ({ 8 }) a ({ 9 }) database ({ 10 }) , ({ 11 }) we ({ 12 }) now ({ 13 }) can ({ 14 }) construct ({ 15 }) two ({ 16 }) hierarchical ({ 17 }) structures ({ 18 }) . ({ 19 }) 
# Sentence pair (3397) source length 11 target length 10 alignment score : 0.00635975
One is for regions of the initial query image . 
NULL ({ }) One ({ 1 }) is ({ 2 }) for ({ 3 }) the ({ }) regions ({ 4 }) of ({ 5 }) the ({ 6 }) initial ({ 7 }) query ({ 8 }) image ({ 9 }) . ({ 10 }) 
# Sentence pair (3398) source length 13 target length 12 alignment score : 0.00279055
The other is for regions of all images in the database . 
NULL ({ }) The ({ 1 }) other ({ 2 }) is ({ 3 }) for ({ 4 }) the ({ }) regions ({ 5 }) of ({ 6 }) all ({ 7 }) images ({ 8 }) in ({ 9 }) the ({ 10 }) database ({ 11 }) . ({ 12 }) 
# Sentence pair (3399) source length 24 target length 23 alignment score : 2.98444e-17
Both structures are then becomes input for our proposed approach to find top region pairs with highest similarity scores for recommendation generation . 
NULL ({ 3 }) Both ({ 1 }) structures ({ 2 }) then ({ 4 }) become ({ 5 }) the ({ }) input ({ 6 }) for ({ 7 }) our ({ 8 9 }) approach ({ 10 }) to ({ 11 }) find ({ 12 }) the ({ }) top ({ 13 }) region ({ 14 }) pairs ({ 15 }) with ({ 16 }) the ({ }) highest ({ 17 }) similarity ({ 18 }) scores ({ 19 }) for ({ 20 }) making ({ 21 }) recommendations ({ 22 }) . ({ 23 }) 
# Sentence pair (3400) source length 26 target length 25 alignment score : 6.0879e-11
Note that , because the hierarchical for regions of images in the database is independent of query , we construct it only one time . 
NULL ({ 3 }) Note ({ 1 }) that ({ 2 }) because ({ 4 }) the ({ 5 }) hierarchy ({ 6 }) of ({ 7 }) the ({ }) regions ({ 8 }) of ({ 9 }) images ({ 10 }) in ({ 11 }) the ({ 12 }) database ({ 13 }) is ({ 14 }) independent ({ 15 }) of ({ 16 }) the ({ }) query ({ 17 }) , ({ 18 }) we ({ 19 }) construct ({ 20 }) it ({ 21 }) only ({ 22 }) one ({ 23 }) time ({ 24 }) . ({ 25 }) 
# Sentence pair (3401) source length 16 target length 18 alignment score : 6.01301e-12
A recommendation is a good one if it exactly locates an item which exists in the database . 
NULL ({ 13 }) A ({ 1 }) recommendation ({ 2 }) is ({ 3 }) a ({ 4 }) good ({ 5 }) one ({ 6 }) if ({ 7 }) it ({ 8 }) exactly ({ 9 }) locates ({ 10 14 }) an ({ 11 }) item ({ 12 }) in ({ 15 }) the ({ 16 }) database ({ 17 }) . ({ 18 }) 
# Sentence pair (3402) source length 20 target length 23 alignment score : 1.05407e-21
We call such recommendations as hit recommendations . Thus , a good recommendation system should accurately provide such hit recommendation to users . 
NULL ({ 8 }) We ({ 1 }) call ({ 2 }) such ({ 3 }) recommendations" ({ 4 5 }) hit ({ 6 19 }) recommendations ({ 7 20 }) " ({ 9 }) , ({ 10 }) and ({ }) a ({ 11 }) good ({ 12 }) recommendation ({ 13 }) system ({ 14 }) should ({ 15 }) accurately ({ 16 }) provide ({ 17 }) them ({ 18 }) to ({ 21 }) users ({ 22 }) . ({ 23 }) 
# Sentence pair (3403) source length 34 target length 34 alignment score : 2.38211e-16
More importantly , users always expect that hit recommendations are ranked higher than false recommendations ( if there are some of them ) on the list of all recommendations introduced by the system . 
NULL ({ }) More ({ 1 }) importantly ({ 2 }) , ({ 3 }) users ({ 4 }) always ({ 5 }) expect ({ 6 }) that ({ 7 }) hit ({ 8 }) recommendations ({ 9 }) are ({ 10 }) ranked ({ 11 }) higher ({ 12 }) than ({ 13 }) false ({ 14 }) recommendations ({ 15 }) ( ({ 16 }) if ({ 17 }) there ({ 18 }) are ({ 19 }) a ({ }) number ({ 20 }) of ({ 21 }) them ({ 22 }) ) ({ 23 }) on ({ 24 }) the ({ 25 }) list ({ 26 }) of ({ 27 }) the ({ 28 }) recommendations ({ 29 30 }) by ({ 31 }) the ({ 32 }) system ({ 33 }) . ({ 34 }) 
# Sentence pair (3404) source length 30 target length 29 alignment score : 9.32532e-12
Based on those insights , we evaluate Recommend-Me system using two evaluation metrics : precision on introducing recommendation and rank of the first hit recommendation on the list . 
NULL ({ }) Based ({ 1 }) on ({ 2 }) these ({ 3 }) insights ({ 4 }) , ({ 5 }) we ({ 6 }) evaluated ({ 7 }) the ({ }) Recommend-Me ({ 8 }) system ({ 9 }) using ({ 10 }) two ({ 11 }) evaluation ({ 12 }) metrics ({ 13 }) : ({ 14 }) precision ({ 15 }) in ({ 16 }) pesenting ({ 17 }) recommendations ({ 18 }) and ({ 19 }) rank ({ 20 }) of ({ 21 }) the ({ 22 }) first ({ 23 }) hit ({ 24 }) recommendation ({ 25 }) on ({ 26 }) the ({ 27 }) list ({ 28 }) . ({ 29 }) 
# Sentence pair (3405) source length 38 target length 39 alignment score : 3.79332e-23
Given an initial query image with ground-truth annotation indicates bounding box of an item known existed in the database , Recommend-Me is determined to precisely introduce recommendation if at least one of its recommendation is a hit recommendation . 
NULL ({ 17 }) Given ({ 1 }) an ({ 2 }) initial ({ 3 }) query ({ 4 }) image ({ 5 }) with ({ 6 }) ground-truth ({ 7 }) annotations ({ 8 }) indicating ({ 9 }) the ({ }) bounding ({ 10 }) box ({ 11 }) of ({ 12 }) an ({ 13 }) item ({ 14 }) known ({ 15 }) to ({ 24 }) existin ({ 16 25 26 }) the ({ 18 }) database ({ 19 }) , ({ 20 }) Recommend-Me ({ 21 }) will ({ 22 }) provide ({ 23 }) a ({ }) recommendation ({ 27 }) if ({ 28 }) at ({ 29 }) least ({ 30 }) one ({ 31 }) of ({ 32 }) its ({ 33 }) recommendations ({ 34 }) is ({ 35 }) a ({ 36 }) hit ({ 37 }) recommendation ({ 38 }) . ({ 39 }) 
# Sentence pair (3406) source length 21 target length 19 alignment score : 1.1433e-14
We apply an approach used in Pascal VOC challenge to clarify whether a recommendation is a hit recommendation . 
NULL ({ 6 }) We ({ 1 }) used ({ 2 }) an ({ 3 }) approach ({ 4 }) from ({ 5 }) the ({ }) Pascal ({ 7 }) VOC ({ 8 }) challenge ({ 9 }) to ({ 10 }) clarify ({ 11 }) whether ({ 12 }) a ({ 13 }) recommendation ({ 14 }) is ({ 15 }) a ({ 16 }) hit ({ 17 }) recommendation ({ 18 }) or ({ }) not ({ }) . ({ 19 }) 
# Sentence pair (3407) source length 22 target length 23 alignment score : 5.43807e-07
In particular , the intersection area between a hit recommendation and an item should be larger than half of their union area . 
NULL ({ 19 }) In ({ 1 }) particular ({ 2 }) , ({ 3 }) the ({ 4 }) intersection ({ 5 }) area ({ 6 }) between ({ 7 }) a ({ 8 }) hit ({ 9 }) recommendation ({ 10 }) and ({ 11 }) an ({ 12 }) item ({ 13 }) should ({ 14 }) be ({ 15 }) larger ({ 16 }) than ({ 17 }) half ({ 18 }) their ({ 20 }) union ({ 21 }) area ({ 22 }) . ({ 23 }) 
# Sentence pair (3408) source length 32 target length 33 alignment score : 5.85143e-17
Because our target is not to improve search techniques but to facilitate query selection procedure , search performance simply relies on standard techniques if users take an recommendation as a search query . 
NULL ({ 18 }) Because ({ 1 }) our ({ 2 }) target ({ 3 }) is ({ 4 }) not ({ 5 }) to ({ 6 }) improve ({ 7 }) search ({ 8 }) techniques ({ 9 }) but ({ 10 }) to ({ 11 }) facilitate ({ 12 15 }) query ({ 13 }) selection ({ 14 }) , ({ 16 }) the ({ }) search ({ 17 }) simply ({ 19 }) relies ({ 20 }) on ({ 21 }) standard ({ 22 }) techniques ({ 23 }) if ({ 24 }) users ({ 25 }) use ({ 26 }) an ({ 27 }) recommendation ({ 28 }) as ({ 29 }) a ({ 30 }) search ({ 31 }) query ({ 32 }) . ({ 33 }) 
# Sentence pair (3409) source length 33 target length 32 alignment score : 9.67683e-11
To evaluate the efficiency of Recommend-Me on finding \MATH region pairs with highest similarity scores , we compute the number of evaluation for the quality bounding function in the branch-and-bound algorithm . 
NULL ({ }) To ({ 1 }) evaluate ({ 2 }) the ({ 3 }) efficiency ({ 4 }) of ({ 5 }) Recommend-Me ({ 6 }) in ({ 7 }) finding ({ 8 }) \MATH ({ 9 }) region ({ 10 }) pairs ({ 11 }) with ({ 12 }) the ({ }) highest ({ 13 }) similarity ({ 14 }) scores ({ 15 }) , ({ 16 }) we ({ 17 }) computed ({ 18 }) the ({ 19 }) number ({ 20 }) of ({ 21 }) evaluations ({ 22 }) for ({ 23 }) the ({ 24 }) quality ({ 25 }) bounding ({ 26 }) function ({ 27 }) in ({ 28 }) the ({ 29 }) branch-and-bound ({ 30 }) algorithm ({ 31 }) . ({ 32 }) 
# Sentence pair (3410) source length 68 target length 29 alignment score : 4.39934e-47
This number is then divided by the size of all possible region pairs formed by regions in the initial query image and regions in images of the database . 
NULL ({ }) This ({ 1 }) number ({ 2 }) was ({ 3 }) then ({ 4 }) divided ({ 5 }) by ({ 6 }) the ({ 7 }) size ({ 8 }) of ({ 9 }) all ({ 10 }) possible ({ 11 }) region ({ 12 }) pairs ({ 13 }) formed ({ 14 }) by ({ 15 }) regions ({ 16 }) in ({ 17 }) the ({ 18 }) initial ({ 19 }) query ({ 20 }) image ({ 21 }) and ({ 22 }) regions ({ 23 }) in ({ 24 }) images ({ 25 }) of ({ 26 }) the ({ 27 }) database ({ 28 }) . ({ 29 }) //< ({ }) " ({ }) the ({ }) size ({ }) of ({ }) all ({ }) possible ({ }) region ({ }) pairs ({ }) " ({ }) is ({ }) unclear ({ }) to ({ }) me ({ }) . ({ }) Do ({ }) you ({ }) mean ({ }) " ({ }) the ({ }) average ({ }) size ({ }) of ({ }) all ({ }) possible ({ }) region ({ }) pairs ({ }) " ({ }) or ({ }) " ({ }) the ({ }) sizes ({ }) of ({ }) all ({ }) possible ({ }) region ({ }) pairs ({ }) " ({ }) ?> ({ }) 
# Sentence pair (3411) source length 12 target length 11 alignment score : 9.17805e-07
The fraction is reported as the efficiency improvement of Recommend-Me . 
NULL ({ }) The ({ 1 }) fraction ({ 2 }) was ({ 3 }) taken ({ 4 }) to ({ }) be ({ 5 }) the ({ 6 }) efficiency ({ 7 }) improvement ({ 8 }) of ({ 9 }) Recommend-Me ({ 10 }) . ({ 11 }) 
# Sentence pair (3412) source length 15 target length 16 alignment score : 1.42279e-05
Note that , regions in images are pre-selected as in Step 1 of our framework . 
NULL ({ 3 }) Note ({ 1 }) that ({ 2 }) regions ({ 4 }) in ({ 5 }) images ({ 6 }) were ({ 7 }) pre-selected ({ 8 }) as ({ 9 }) in ({ 10 }) Step ({ 11 }) 1 ({ 12 }) of ({ 13 }) our ({ 14 }) framework ({ 15 }) . ({ 16 }) 
# Sentence pair (3413) source length 3 target length 3 alignment score : 0.373677
Feature presentation . 
NULL ({ }) Feature ({ 1 }) presentation ({ 2 }) . ({ 3 }) 
# Sentence pair (3414) source length 17 target length 15 alignment score : 3.90103e-05
We employ BoF model to represent features of images and regions in the images . 
NULL ({ }) We ({ 1 }) employed ({ 2 }) a ({ }) BoF ({ 3 }) model ({ 4 }) to ({ 5 }) represent ({ 6 }) the ({ }) features ({ 7 }) of ({ 8 }) images ({ 9 }) and ({ 10 }) regions ({ 11 }) in ({ 12 }) the ({ 13 }) images ({ 14 }) . ({ 15 }) 
# Sentence pair (3415) source length 20 target length 16 alignment score : 2.76878e-07
Visual words in images are located by dense grid sampling and Different-of-Gaussian( DoG ) detector . 
NULL ({ }) Visual ({ 1 }) words ({ 2 }) in ({ 3 }) the ({ }) images ({ 4 }) were ({ 5 }) located ({ 6 }) by ({ 7 }) using ({ }) dense ({ 8 }) grid ({ 9 }) sampling ({ 10 }) and ({ 11 }) a ({ }) Different-of-Gaussian ({ 12 }) ( ({ }) DoG ({ 13 }) ) ({ 14 }) detector ({ 15 }) . ({ 16 }) 
# Sentence pair (3416) source length 14 target length 13 alignment score : 0.000837173
A codebook of 2000 visual words is built using standard K-Means algorithm . 
NULL ({ }) A ({ 1 }) codebook ({ 2 }) of ({ 3 }) 2000 ({ 4 }) visual ({ 5 }) words ({ 6 }) was ({ 7 }) built ({ 8 }) using ({ 9 }) the ({ }) standard ({ 10 }) K-Means ({ 11 }) algorithm ({ 12 }) . ({ 13 }) 
# Sentence pair (3417) source length 37 target length 36 alignment score : 9.28114e-13
%to cluster points on a set of random images .% Additionally , the set of interest points obtained by DoG in the query image is used to remove regions without any of such points inside . 
NULL ({ 32 }) %to ({ 1 }) cluster ({ 2 }) points ({ 3 }) on ({ 4 }) a ({ 5 }) set ({ 6 }) of ({ 7 }) random ({ 8 }) images ({ 9 }) .% ({ 10 }) Additionally ({ 11 }) , ({ 12 }) the ({ 13 }) set ({ 14 }) of ({ 15 }) points ({ 17 }) of ({ }) interest ({ 16 }) obtained ({ 18 }) by ({ 19 }) the ({ }) DoG ({ 20 }) in ({ 21 }) the ({ 22 }) query ({ 23 }) image ({ 24 }) was ({ 25 }) used ({ 26 }) to ({ 27 }) remove ({ 28 }) regions ({ 29 }) without ({ 30 }) any ({ 31 }) such ({ 33 }) points ({ 34 }) inside ({ 35 }) . ({ 36 }) 
# Sentence pair (3418) source length 23 target length 24 alignment score : 8.96415e-21
This helps us to eliminate less meaningful regions such as a portion of the sky , solid color regions , etc for recommendation . 
NULL ({ 13 14 22 }) This ({ 1 }) helped ({ 2 }) us ({ 3 }) to ({ 4 }) eliminate ({ 5 }) less ({ 6 }) meaningful ({ 7 }) regions ({ 8 }) such ({ 9 }) as ({ 10 }) the ({ 11 }) sky ({ 12 15 }) , ({ 16 }) solid ({ 17 }) color ({ 18 }) regions ({ 19 }) , ({ 20 }) etc. ({ 21 }) , ({ }) from ({ }) the ({ }) recommendations ({ 23 }) . ({ 24 }) 
# Sentence pair (3419) source length 5 target length 5 alignment score : 0.233212
Region selection in images . 
NULL ({ }) Region ({ 1 }) selection ({ 2 }) in ({ 3 }) images ({ 4 }) . ({ 5 }) 
# Sentence pair (3420) source length 21 target length 19 alignment score : 4.92883e-08
As mentioned above , we use the approach introduced in \CITE on different color channel for region selection . 
NULL ({ }) As ({ 1 }) mentioned ({ 2 }) above ({ 3 }) , ({ 4 }) we ({ 5 }) used ({ 6 }) the ({ 7 }) approach ({ 8 }) first ({ }) introduced ({ 9 }) in ({ 10 }) \CITE ({ 11 }) on ({ 12 }) different ({ 13 }) color ({ 14 }) channels ({ 15 }) for ({ 16 }) the ({ }) region ({ 17 }) selection ({ 18 }) . ({ 19 }) 
# Sentence pair (3421) source length 37 target length 35 alignment score : 3.04576e-14
In this experiment , we used two color channels which are RGB and Hue , since regions generated on those channels can cover 99 .72\% area of the annotated item regions in our dataset . 
NULL ({ }) In ({ 1 }) this ({ 2 }) experiment ({ 3 }) , ({ 4 }) we ({ 5 }) used ({ 6 }) two ({ 7 }) color ({ 8 }) channels ({ 9 }) , ({ }) RGB ({ 10 11 12 }) and ({ 13 }) Hue ({ 14 }) , ({ 15 }) since ({ 16 }) the ({ }) regions ({ 17 }) generated ({ 18 }) on ({ 19 }) those ({ 20 }) channels ({ 21 }) can ({ 22 }) cover ({ 23 }) 99 ({ 24 }) .72\% ({ 25 }) of ({ }) the ({ }) area ({ 26 }) of ({ 27 }) the ({ 28 }) annotated ({ 29 }) item ({ 30 }) regions ({ 31 }) in ({ 32 }) our ({ 33 }) dataset ({ 34 }) . ({ 35 }) 
# Sentence pair (3422) source length 21 target length 21 alignment score : 9.61525e-05
A virtual root node is created to compose two color-dependent binary trees into one unique binary tree for each image . 
NULL ({ }) A ({ 1 }) virtual ({ 2 }) root ({ 3 }) node ({ 4 }) was ({ 5 }) created ({ 6 }) to ({ 7 }) compose ({ 8 }) two ({ 9 }) color-dependent ({ 10 }) binary ({ 11 }) trees ({ 12 }) into ({ 13 }) one ({ 14 }) unique ({ 15 }) binary ({ 16 }) tree ({ 17 }) for ({ 18 }) each ({ 19 }) image ({ 20 }) . ({ 21 }) 
# Sentence pair (3423) source length 32 target length 31 alignment score : 2.64124e-08
In addition , rectangular regions which do not contain any visual word or are smaller than 40 x 40 pixels are discarded .% since they can form a meaningful recommendation . 
NULL ({ }) In ({ 1 }) addition ({ 2 }) , ({ 3 }) the ({ }) rectangular ({ 4 }) regions ({ 5 }) which ({ 6 }) did ({ 7 }) not ({ 8 }) contain ({ 9 }) any ({ 10 }) visual ({ 11 }) word ({ 12 }) or ({ 13 }) were ({ 14 }) smaller ({ 15 }) than ({ 16 }) 40 ({ 17 }) x ({ 18 }) 40 ({ 19 }) pixels ({ 20 }) were ({ 21 }) discarded ({ 22 }) .% ({ 23 }) since ({ 24 }) they ({ 25 }) can ({ 26 }) form ({ 27 }) a ({ 28 }) meaningful ({ 29 }) recommendation ({ 30 }) . ({ 31 }) 
# Sentence pair (3424) source length 5 target length 5 alignment score : 0.203606
Maximal clique analysis algorithm . 
NULL ({ }) Maximal ({ 1 }) clique ({ 2 }) analysis ({ 3 }) algorithm ({ 4 }) . ({ 5 }) 
# Sentence pair (3425) source length 44 target length 43 alignment score : 1.15693e-09
Given the set of regions in the initial query image , we build a graph in which two regions are connected if they highly overlap each other ( we use the approach of Pascal VOC with tighter threshold , 0 .8 ) . 
NULL ({ }) Given ({ 1 }) the ({ 2 }) set ({ 3 }) of ({ 4 }) regions ({ 5 }) in ({ 6 }) the ({ 7 }) initial ({ 8 }) query ({ 9 }) image ({ 10 }) , ({ 11 }) we ({ 12 }) built ({ 13 }) a ({ 14 }) graph ({ 15 }) in ({ 16 }) which ({ 17 }) two ({ 18 }) regions ({ 19 }) were ({ 20 }) connected ({ 21 }) if ({ 22 }) they ({ 23 }) nearly ({ 24 }) overlapped ({ 25 }) each ({ 26 }) other ({ 27 }) ( ({ 28 }) we ({ 29 }) use ({ 30 }) the ({ 31 }) approach ({ 32 }) of ({ 33 }) Pascal ({ 34 }) VOC ({ 35 }) with ({ 36 }) a ({ }) tighter ({ 37 }) threshold ({ 38 }) , ({ 39 }) 0 ({ 40 }) .8 ({ 41 }) ) ({ 42 }) . ({ 43 }) 
# Sentence pair (3426) source length 15 target length 14 alignment score : 0.000268469
Bron-Kerbosch algorithm is then applied to find all maximal cliques in the graph . 
NULL ({ }) The ({ }) Bron-Kerbosch ({ 1 }) algorithm ({ 2 }) was ({ 3 }) then ({ 4 }) applied ({ 5 }) to ({ 6 }) find ({ 7 }) all ({ 8 }) maximal ({ 9 }) cliques ({ 10 }) in ({ 11 }) the ({ 12 }) graph ({ 13 }) . ({ 14 }) 
# Sentence pair (3427) source length 8 target length 8 alignment score : 0.0281353
One clique is one group of regions . 
NULL ({ }) One ({ 1 }) clique ({ 2 }) was ({ 3 }) one ({ 4 }) group ({ 5 }) of ({ 6 }) regions ({ 7 }) . ({ 8 }) 
# Sentence pair (3428) source length 9 target length 7 alignment score : 6.02471e-10
Figure \REF shows our evaluation results . 
NULL ({ }) Figure ({ 1 }) \REF ({ 2 }) shows ({ 3 }) the ({ }) results ({ 6 }) of ({ }) the ({ 4 }) evaluation ({ 5 }) . ({ 7 }) 
# Sentence pair (3429) source length 31 target length 36 alignment score : 6.32432e-27
The reported numbers of precision , rank of the first hit recommendation as well as efficiency improvement are averaged as we perform Recommend-Me with 375 different initial query images and an individual value of \MATH . 
NULL ({ 4 21 }) The ({ 1 }) reported ({ 2 3 }) precision ({ 5 }) , ({ 6 }) rank ({ 7 }) of ({ 8 }) the ({ 9 }) first ({ 10 }) hit ({ 11 }) recommendation ({ 12 }) , ({ }) and ({ }) efficiency ({ 16 }) improvement ({ 17 }) are ({ 18 }) averages ({ 13 14 15 19 20 22 }) of ({ }) Recommend-Me ({ 23 }) on ({ 24 }) 375 ({ 25 }) different ({ 26 }) initial ({ 27 }) query ({ 28 }) images ({ 29 }) and ({ 30 }) an ({ 31 }) individual ({ 32 }) value ({ 33 }) of ({ 34 }) \MATH ({ 35 }) . ({ 36 }) 
# Sentence pair (3430) source length 20 target length 21 alignment score : 1.25434e-08
The results show that Recommend-Me can successfully introduce hit recommendations to users with high precision ( approximately 80 .27\% ) . 
NULL ({ }) The ({ 1 }) results ({ 2 }) show ({ 3 }) that ({ 4 }) Recommend-Me ({ 5 }) can ({ 6 }) make ({ 7 }) hit ({ 8 9 }) recommendations ({ 10 }) to ({ 11 }) users ({ 12 }) with ({ 13 }) high ({ 14 }) precision ({ 15 }) ( ({ 16 }) approximately ({ 17 }) 80 ({ 18 }) .27\% ({ 19 }) ) ({ 20 }) . ({ 21 }) 
# Sentence pair (3431) source length 20 target length 21 alignment score : 9.80939e-10
On the returned list of all recommendations , a hit recommendation usually takes the first two places on the list . 
NULL ({ 9 }) On ({ 1 }) the ({ 2 }) returned ({ 3 }) list ({ 4 }) of ({ 5 }) all ({ 6 }) recommendations ({ 7 }) , ({ 8 }) hit ({ 10 }) recommendations ({ 11 }) usually ({ 12 }) take ({ 13 }) the ({ 14 }) first ({ 15 }) two ({ 16 }) places ({ 17 }) on ({ 18 }) the ({ 19 }) list ({ 20 }) . ({ 21 }) 
# Sentence pair (3432) source length 18 target length 18 alignment score : 0.000928658
This help users to avoid choosing false recommendations ( if such false recommendations are highly ranked ) . 
NULL ({ }) This ({ 1 }) help ({ 2 }) users ({ 3 }) to ({ 4 }) avoid ({ 5 }) choosing ({ 6 }) false ({ 7 }) recommendations ({ 8 }) ( ({ 9 }) if ({ 10 }) such ({ 11 }) false ({ 12 }) recommendations ({ 13 }) are ({ 14 }) highly ({ 15 }) ranked ({ 16 }) ) ({ 17 }) . ({ 18 }) 
# Sentence pair (3433) source length 15 target length 18 alignment score : 4.52465e-19
We observed that there are two types of false recommendations on the top places of the list . 
NULL ({ 3 4 }) There ({ 1 2 }) were ({ 5 }) two ({ 6 }) types ({ 7 }) of ({ 8 }) false ({ 9 }) recommendation ({ 10 }) in ({ 11 }) the ({ 12 }) top ({ 13 }) places ({ 14 }) of ({ 15 }) the ({ 16 }) list ({ 17 }) . ({ 18 }) 
# Sentence pair (3434) source length 24 target length 22 alignment score : 2.91813e-06
The first type consists background regions ( e.g. trees , buildings , roads ) which are easily found in many images . 
NULL ({ }) The ({ 1 }) first ({ 2 }) type ({ 3 }) consisted ({ 4 }) of ({ }) background ({ 5 }) regions ({ 6 }) ( ({ 7 }) e.g. ({ 8 }) trees ({ 9 }) , ({ 10 }) buildings ({ 11 }) , ({ 12 }) roads ({ 13 }) ) ({ 14 }) , ({ }) which ({ 15 }) are ({ 16 }) easily ({ 17 }) found ({ 18 }) in ({ 19 }) many ({ 20 }) images ({ 21 }) . ({ 22 }) 
# Sentence pair (3435) source length 17 target length 18 alignment score : 7.28066e-11
The second type is the items lacking of manual annotation such as windows , cars and humans . 
NULL ({ 5 8 }) The ({ 1 }) second ({ 2 }) type ({ 3 }) was ({ 4 }) items ({ 6 }) lacking ({ 7 }) manual ({ 9 }) annotations ({ 10 }) such ({ 11 }) as ({ 12 }) windows ({ 13 }) , ({ 14 }) cars ({ 15 }) , ({ }) and ({ 16 }) humans ({ 17 }) . ({ 18 }) 
# Sentence pair (3436) source length 13 target length 13 alignment score : 0.00323765
Thus , recommendations about those items are not counted as hit recommendations . 
NULL ({ }) Thus ({ 1 }) , ({ 2 }) recommendations ({ 3 }) about ({ 4 }) those ({ 5 }) items ({ 6 }) are ({ 7 }) not ({ 8 }) counted ({ 9 }) as ({ 10 }) hit ({ 11 }) recommendations ({ 12 }) . ({ 13 }) 
# Sentence pair (3437) source length 23 target length 23 alignment score : 2.68543e-09
However , if users are interested in using them as hints to explore the database , they are still very much helpful . 
NULL ({ }) However ({ 1 }) , ({ 2 }) if ({ 3 }) users ({ 4 }) are ({ 5 }) interested ({ 6 }) in ({ 7 }) using ({ 8 }) them ({ 9 }) as ({ 10 }) hints ({ 11 }) to ({ 12 }) explore ({ 13 }) the ({ 14 }) database ({ 15 }) , ({ 16 }) they ({ 17 }) may ({ 18 }) still ({ 19 }) be ({ }) very ({ 20 }) helpful ({ 21 22 }) . ({ 23 }) 
# Sentence pair (3438) source length 15 target length 17 alignment score : 8.05598e-11
Clearly , one can realize that the performance of Recommend-Me is under the influence of \MATH . 
NULL ({ 13 15 }) Clearly ({ 1 }) , ({ 2 }) one ({ 3 }) can ({ 4 }) realize ({ 5 }) that ({ 6 }) the ({ 7 }) performance ({ 8 }) of ({ 9 }) Recommend-Me ({ 10 }) is ({ 11 }) influenced ({ 12 }) by ({ 14 }) \MATH ({ 16 }) . ({ 17 }) 
# Sentence pair (3439) source length 16 target length 15 alignment score : 4.67636e-06
By increasing \MATH , we obtain more region pairs with sufficient hight similarity scores . 
NULL ({ }) By ({ 1 }) increasing ({ 2 }) \MATH ({ 3 }) , ({ 4 }) we ({ 5 }) can ({ }) obtain ({ 6 }) more ({ 7 }) region ({ 8 }) pairs ({ 9 }) with ({ 10 }) sufficiently ({ 11 }) high ({ 12 }) similarity ({ 13 }) scores ({ 14 }) . ({ 15 }) 
# Sentence pair (3440) source length 16 target length 18 alignment score : 1.64074e-08
It brings more chances to get region pairs of the annotated item , thus improves the precision . 
NULL ({ 16 }) Thisgives ({ 1 2 }) more ({ 3 }) chances ({ 4 }) to ({ 5 }) get ({ 6 }) region ({ 7 }) pairs ({ 8 }) of ({ 9 }) the ({ 10 }) annotated ({ 11 }) item ({ 12 }) , ({ 13 }) thus ({ 14 }) improving ({ 15 }) precision ({ 17 }) . ({ 18 }) 
# Sentence pair (3441) source length 12 target length 13 alignment score : 4.4417e-07
However , the trade-off is that more unexpected items are also returned . 
NULL ({ }) However ({ 1 }) , ({ 2 }) the ({ 3 }) trade-off ({ 4 }) is ({ 5 }) that ({ 6 }) more ({ 7 }) unexpected ({ 8 }) items ({ 9 }) are ({ 10 }) returned ({ 11 12 }) . ({ 13 }) 
# Sentence pair (3442) source length 15 target length 14 alignment score : 2.34723e-05
This results in a drop of average rank of the first hit recommendation . 
NULL ({ }) This ({ 1 }) results ({ 2 }) in ({ 3 }) a ({ 4 }) drop ({ 5 }) in ({ 6 }) the ({ }) average ({ 7 }) rank ({ 8 }) of ({ 9 }) the ({ 10 }) first ({ 11 }) hit ({ 12 }) recommendation ({ 13 }) . ({ 14 }) 
# Sentence pair (3443) source length 8 target length 8 alignment score : 0.0647152
Figure 5( a ) demonstrates this circumstance . 
NULL ({ }) Figure ({ 1 }) 5( ({ 2 }) a ({ 3 }) ) ({ 4 }) demonstrates ({ 5 }) this ({ 6 }) circumstance ({ 7 }) . ({ 8 }) 
# Sentence pair (3444) source length 36 target length 37 alignment score : 1.68767e-10
When \MATH increases from 2000 to 10000 , the precision also increases from 74 .67\% to 81 .97\% ; meanwhile , the average rank of the first hit recommendation drops to 2 .27 from 1 .78 . 
NULL ({ }) When ({ 1 }) \MATH ({ 2 }) increases ({ 3 }) from ({ 4 }) 2000 ({ 5 }) to ({ 6 }) 10000 ({ 7 }) , ({ 8 }) the ({ 9 }) precision ({ 10 }) increases ({ 11 12 }) from ({ 13 }) 74 ({ 14 }) .67\% ({ 15 }) to ({ 16 }) 81 ({ 17 }) .97\% ({ 18 }) ; ({ 19 }) meanwhile ({ 20 }) , ({ 21 }) the ({ 22 }) average ({ 23 }) rank ({ 24 }) of ({ 25 }) the ({ 26 }) first ({ 27 }) hit ({ 28 }) recommendation ({ 29 }) drops ({ 30 }) to ({ 31 }) 2 ({ 32 }) .27 ({ 33 }) from ({ 34 }) 1 ({ 35 }) .78 ({ 36 }) . ({ 37 }) 
# Sentence pair (3445) source length 32 target length 31 alignment score : 2.76284e-09
It is worth noting that keeping inreasing \MATH may not always give better precision since precision relies on not only \MATH but also the robustness of the region comparision techniques . 
NULL ({ }) It ({ 1 }) is ({ 2 }) worth ({ 3 }) noting ({ 4 }) that ({ 5 }) keeping ({ 6 }) increasing ({ 7 }) \MATH ({ 8 }) may ({ 9 }) not ({ 10 }) always ({ 11 }) give ({ 12 }) better ({ 13 }) precision ({ 14 }) , ({ }) since ({ 15 }) precision ({ 16 }) relies ({ 17 }) on ({ 18 }) not ({ 19 }) only ({ 20 }) \MATH ({ 21 }) but ({ 22 }) also ({ 23 }) the ({ 24 }) robustness ({ 25 }) of ({ 26 }) the ({ 27 }) region ({ 28 }) comparison ({ 29 }) techniques ({ 30 }) . ({ 31 }) 
# Sentence pair (3446) source length 32 target length 30 alignment score : 1.78954e-10
Recommend-Me cannot provide any hit recommendation for around 20\% of initial query images due to the fact that our region comparision technique cannot deal with significant variations of items . 
NULL ({ }) Recommend-Me ({ 1 }) cannot ({ 2 }) provide ({ 3 }) any ({ 4 }) hit ({ 5 }) recommendation ({ 6 }) for ({ 7 }) around ({ 8 }) 20\% ({ 9 }) of ({ 10 }) the ({ }) initial ({ 11 }) query ({ 12 }) images ({ 13 }) due ({ 14 }) to ({ 15 }) the ({ 16 }) fact ({ 17 }) that ({ 18 }) our ({ 19 }) region ({ 20 }) comparison ({ 21 }) technique ({ 22 }) cannot ({ 23 }) deal ({ 24 }) with ({ 25 }) significant ({ 26 }) variations ({ 27 }) in ({ 28 }) the ({ }) items ({ 29 }) . ({ 30 }) 
# Sentence pair (3447) source length 12 target length 12 alignment score : 0.0142176
Figure 5( b ) shows another circumstance when we increase \MATH . 
NULL ({ }) Figure ({ 1 }) 5( ({ 2 }) b ({ 3 }) ) ({ 4 }) shows ({ 5 }) another ({ 6 }) circumstance ({ 7 }) when ({ 8 }) we ({ 9 }) increase ({ 10 }) \MATH ({ 11 }) . ({ 12 }) 
# Sentence pair (3448) source length 11 target length 10 alignment score : 6.91769e-05
It is the decline of efficiency improvement of Recommend-Me . 
NULL ({ }) It ({ 1 }) is ({ 2 }) the ({ 3 }) decline ({ 4 }) in ({ 5 }) the ({ }) efficiency ({ 6 }) improvement ({ 7 }) of ({ 8 }) Recommend-Me ({ 9 }) . ({ 10 }) 
# Sentence pair (3449) source length 24 target length 24 alignment score : 7.12838e-05
This is because the branch-and-bound algorithm has to visit more parts of the total search space in order to find extra local optimals . 
NULL ({ }) This ({ 1 }) is ({ 2 }) because ({ 3 }) the ({ 4 }) branch-and-bound ({ 5 }) algorithm ({ 6 }) has ({ 7 }) to ({ 8 }) visit ({ 9 }) more ({ 10 }) parts ({ 11 }) of ({ 12 }) the ({ 13 }) total ({ 14 }) search ({ 15 }) space ({ 16 }) in ({ 17 }) order ({ 18 }) to ({ 19 }) find ({ 20 }) extra ({ 21 }) local ({ 22 }) opitimals ({ 23 }) . ({ 24 }) 
# Sentence pair (3450) source length 20 target length 20 alignment score : 8.91846e-07
However , in all of our evaluations , Recommend-Me still performs around 3 times faster than the exhaustive search . 
NULL ({ }) However ({ 1 }) , ({ 2 }) in ({ 3 }) all ({ 4 }) of ({ 5 }) our ({ 6 }) evaluations ({ 7 }) , ({ 8 }) Recommend-Me ({ 9 }) still ({ 10 }) performed ({ 11 }) around ({ 12 }) three ({ 13 }) times ({ 14 }) faster ({ 15 }) than ({ 16 }) the ({ 17 }) exhaustive ({ 18 }) search ({ 19 }) . ({ 20 }) 
# Sentence pair (3451) source length 9 target length 8 alignment score : 2.73935e-07
Its superiority is important for practical applications . 
NULL ({ }) This ({ 1 }) advantage ({ 2 }) will ({ 3 }) be ({ }) important ({ 4 }) for ({ 5 }) practical ({ 6 }) applications ({ 7 }) . ({ 8 }) 
# Sentence pair (3452) source length 10 target length 12 alignment score : 1.67054e-07
Figure \REF presents examples of hit recommendations returned by our Recommend-Me . 
NULL ({ 9 }) Figure ({ 1 }) \REF ({ 2 }) presents ({ 3 }) examples ({ 4 }) of ({ 5 }) hit ({ 6 }) recommendations ({ 7 }) returned ({ 8 }) byRecommend-Me ({ 10 11 }) . ({ 12 }) 
# Sentence pair (3453) source length 13 target length 18 alignment score : 1.88536e-23
In this paper , we introduced a new system , named Recommend-Me , for visual query suggestion . 
NULL ({ 7 10 }) We ({ 1 }) described ({ 2 }) oursystem ({ 3 6 8 9 }) , ({ 4 }) named ({ 5 }) Recommend-Me ({ 12 }) , ({ 13 }) for ({ 14 }) making ({ 11 }) visual ({ 15 }) query ({ 16 }) suggestions ({ 17 }) . ({ 18 }) 
# Sentence pair (3454) source length 32 target length 30 alignment score : 1.17791e-09
Given an initial query image and a retrieved database , Recommend-Me introduces recommendations that imposes which and how frequent items in the initial query image appear in the database . 
NULL ({ }) Given ({ 1 }) an ({ 2 }) initial ({ 3 }) query ({ 4 }) image ({ 5 }) and ({ 6 }) a ({ 7 }) retrieved ({ 8 }) database ({ 9 }) , ({ 10 }) Recommend-Me ({ 11 }) gives ({ 12 }) recommendations ({ 13 }) that ({ 14 }) impose ({ 15 }) conditions ({ }) on ({ }) which ({ 16 }) and ({ 17 }) how ({ 18 }) frequent ({ 19 }) items ({ 20 }) in ({ 21 }) the ({ 22 }) initial ({ 23 }) query ({ 24 }) image ({ 25 }) appear ({ 26 }) in ({ 27 }) the ({ 28 }) database ({ 29 }) . ({ 30 }) 
# Sentence pair (3455) source length 23 target length 22 alignment score : 3.09538e-06
Such recommendations support users to select search query , to rapidly refine the initial query image or to explore the database . 
NULL ({ }) Such ({ 1 }) recommendations ({ 2 }) help ({ 3 }) users ({ 4 }) to ({ 5 }) select ({ 6 }) the ({ }) search ({ 7 }) query ({ 8 }) , ({ 9 }) to ({ 10 }) rapidly ({ 11 }) refine ({ 12 }) the ({ 13 }) initial ({ 14 }) query ({ 15 }) image ({ 16 }) or ({ 17 }) to ({ 18 }) explore ({ 19 }) the ({ 20 }) database ({ 21 }) . ({ 22 }) 
# Sentence pair (3456) source length 11 target length 10 alignment score : 0.000281008
An efficient solution to make Recommend-Me practical is presented . 
NULL ({ }) An ({ 1 }) efficient ({ 2 }) solution ({ 3 }) to ({ 4 }) make ({ 5 }) Recommend-Me ({ 6 }) practical ({ 7 }) was ({ 8 }) also ({ }) presented ({ 9 }) . ({ 10 }) 
# Sentence pair (3457) source length 19 target length 18 alignment score : 2.98542e-07
To the best of our knowledge , Recommend-Me is the first attempt toward its targeted suggestion scheme . 
NULL ({ }) To ({ 1 }) the ({ 2 }) best ({ 3 }) of ({ 4 }) our ({ 5 }) knowledge ({ 6 }) , ({ 7 }) Recommend-Me ({ 8 }) is ({ 9 }) the ({ 10 }) first ({ 11 }) attempt ({ 12 }) at ({ 14 }) developing ({ 13 }) a ({ }) targeted ({ 15 }) suggestion ({ 16 }) scheme ({ 17 }) . ({ 18 }) 
