============================
Tag count Meteor: {"preserved"=>69331, "bigrammar-vtense"=>202, "bigrammar-wform"=>112, "bigrammar-inter"=>17, "paraphrase"=>185, "unaligned"=>86, "mogrammar-prep"=>177, "mogrammar-det"=>837, "bigrammar-prep"=>10, "bigrammar-det"=>6, "bigrammar-others"=>282, "typo-spelling"=>44, "duplicate"=>3, "moproblematic"=>3, "biproblematic"=>1, "unspec"=>1, "wa"=>12782}

This paper analyzes the effects of structural variation of sentences on parsing performances .
#<struct ReadData::Alignment source_numbers="4", target_numbers="3,4", tag_name="wa">
This paper analyzes the effects of structural variation of sentences on parsing performances .
#<struct ReadData::Alignment source_numbers="3", target_numbers="6", tag_name="wa">
The target parsers are adapted to the sentences for these constructions extracted from fiction and query texts .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
The target parsers are adapted to the sentences for these constructions extracted from fiction and query texts .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
The analysis of the experimental results will illustrate the necessity for handling various sentence constructions by fundamental improvement of parsers such as re-construction of feature designs .
#<struct ReadData::Alignment source_numbers="7", target_numbers="5", tag_name="wa">
The analysis of the experimental results will illustrate the necessity for handling various sentence constructions by fundamental improvement of parsers such as re-construction of feature designs .
#<struct ReadData::Alignment source_numbers="9", target_numbers="7", tag_name="wa">
The analysis of the experimental results will illustrate the necessity for handling various sentence constructions by fundamental improvement of parsers such as re-construction of feature designs .
#<struct ReadData::Alignment source_numbers="10,11", target_numbers="8,9", tag_name="wa">
The analysis of the experimental results will illustrate the necessity for handling various sentence constructions by fundamental improvement of parsers such as re-construction of feature designs .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
The analysis of the experimental results will illustrate the necessity for handling various sentence constructions by fundamental improvement of parsers such as re-construction of feature designs .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
The analysis of the experimental results will illustrate the necessity for handling various sentence constructions by fundamental improvement of parsers such as re-construction of feature designs .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
The analysis of the experimental results will illustrate the necessity for handling various sentence constructions by fundamental improvement of parsers such as re-construction of feature designs .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
The analysis of the experimental results will illustrate the necessity for handling various sentence constructions by fundamental improvement of parsers such as re-construction of feature designs .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Parsing is a fundamental natural language processing task and essential for various NLP applications .
#<struct ReadData::Alignment source_numbers="10,11", target_numbers="10,11", tag_name="wa">
Recent research on parsing technologies has achieved high parsing accuracies on the same domains as the training data , but once we move to unfamiliar domains , the performances decrease at unignorable levels .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Recent research on parsing technologies has achieved high parsing accuracies on the same domains as the training data , but once we move to unfamiliar domains , the performances decrease at unignorable levels .
#<struct ReadData::Alignment source_numbers="30", target_numbers="", tag_name="wa">
Recent research on parsing technologies has achieved high parsing accuracies on the same domains as the training data , but once we move to unfamiliar domains , the performances decrease at unignorable levels .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Recent research on parsing technologies has achieved high parsing accuracies on the same domains as the training data , but once we move to unfamiliar domains , the performances decrease at unignorable levels .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
Behind their approaches , there seems to be an assumption that grammatical constructions are not largely different among domains or do not affect parsing systems , and therefore the same parsing system can be applied to a novel domain .
#<struct ReadData::Alignment source_numbers="28", target_numbers="8", tag_name="wa">
Behind their approaches , there seems to be an assumption that grammatical constructions are not largely different among domains or do not affect parsing systems , and therefore the same parsing system can be applied to a novel domain .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Behind their approaches , there seems to be an assumption that grammatical constructions are not largely different among domains or do not affect parsing systems , and therefore the same parsing system can be applied to a novel domain .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Behind their approaches , there seems to be an assumption that grammatical constructions are not largely different among domains or do not affect parsing systems , and therefore the same parsing system can be applied to a novel domain .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Behind their approaches , there seems to be an assumption that grammatical constructions are not largely different among domains or do not affect parsing systems , and therefore the same parsing system can be applied to a novel domain .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Behind their approaches , there seems to be an assumption that grammatical constructions are not largely different among domains or do not affect parsing systems , and therefore the same parsing system can be applied to a novel domain .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Behind their approaches , there seems to be an assumption that grammatical constructions are not largely different among domains or do not affect parsing systems , and therefore the same parsing system can be applied to a novel domain .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
However , there are some cases where we cannot achieve as high parsing accuracies as parsing the Penn Treebank just by re-training or adaptation .
#<struct ReadData::Alignment source_numbers="14", target_numbers="14", tag_name="wa">
However , there are some cases where we cannot achieve as high parsing accuracies as parsing the Penn Treebank just by re-training or adaptation .
#<struct ReadData::Alignment source_numbers="17", target_numbers="17", tag_name="wa">
However , there are some cases where we cannot achieve as high parsing accuracies as parsing the Penn Treebank just by re-training or adaptation .
#<struct ReadData::Alignment source_numbers="18", target_numbers="18", tag_name="wa">
However , there are some cases where we cannot achieve as high parsing accuracies as parsing the Penn Treebank just by re-training or adaptation .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
However , there are some cases where we cannot achieve as high parsing accuracies as parsing the Penn Treebank just by re-training or adaptation .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
However , there are some cases where we cannot achieve as high parsing accuracies as parsing the Penn Treebank just by re-training or adaptation .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
However , there are some cases where we cannot achieve as high parsing accuracies as parsing the Penn Treebank just by re-training or adaptation .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
However , there are some cases where we cannot achieve as high parsing accuracies as parsing the Penn Treebank just by re-training or adaptation .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
For example , the parsing accuracy for the Brown corpus is significantly lower than for the WSJ portion of the Penn Treebank , even when re-training the parser with much more in-domain training data than other successful domains .
#<struct ReadData::Alignment source_numbers="16", target_numbers="21", tag_name="wa">
For example , the parsing accuracy for the Brown corpus is significantly lower than for the WSJ portion of the Penn Treebank , even when re-training the parser with much more in-domain training data than other successful domains .
#<struct ReadData::Alignment source_numbers="22", target_numbers="28", tag_name="wa">
For example , the parsing accuracy for the Brown corpus is significantly lower than for the WSJ portion of the Penn Treebank , even when re-training the parser with much more in-domain training data than other successful domains .
#<struct ReadData::Alignment source_numbers="38", target_numbers="44", tag_name="wa">
For example , the parsing accuracy for the Brown corpus is significantly lower than for the WSJ portion of the Penn Treebank , even when re-training the parser with much more in-domain training data than other successful domains .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
For example , the parsing accuracy for the Brown corpus is significantly lower than for the WSJ portion of the Penn Treebank , even when re-training the parser with much more in-domain training data than other successful domains .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
For example , the parsing accuracy for the Brown corpus is significantly lower than for the WSJ portion of the Penn Treebank , even when re-training the parser with much more in-domain training data than other successful domains .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
For example , the parsing accuracy for the Brown corpus is significantly lower than for the WSJ portion of the Penn Treebank , even when re-training the parser with much more in-domain training data than other successful domains .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
For example , the parsing accuracy for the Brown corpus is significantly lower than for the WSJ portion of the Penn Treebank , even when re-training the parser with much more in-domain training data than other successful domains .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
This research attempts to identify the cause of these difficulties , and focuses on two types of sentence constructions which were not extensively studied in the recent parsing research : imperatives and questions .
#<struct ReadData::Alignment source_numbers="20", target_numbers="20", tag_name="wa">
This research attempts to identify the cause of these difficulties , and focuses on two types of sentence constructions which were not extensively studied in the recent parsing research : imperatives and questions .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
This research attempts to identify the cause of these difficulties , and focuses on two types of sentence constructions which were not extensively studied in the recent parsing research : imperatives and questions .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
This research attempts to identify the cause of these difficulties , and focuses on two types of sentence constructions which were not extensively studied in the recent parsing research : imperatives and questions .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
This research attempts to identify the cause of these difficulties , and focuses on two types of sentence constructions which were not extensively studied in the recent parsing research : imperatives and questions .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
In these constructions , words in some syntactic positions disappear or the orders of words change .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
In these constructions , words in some syntactic positions disappear or the orders of words change .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
In order to do so , we prepare an annotated corpus for each of the two sentence constructions by borrowing sentences from fiction and query domains .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
In order to do so , we prepare an annotated corpus for each of the two sentence constructions by borrowing sentences from fiction and query domains .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
In order to do so , we prepare an annotated corpus for each of the two sentence constructions by borrowing sentences from fiction and query domains .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
In order to do so , we prepare an annotated corpus for each of the two sentence constructions by borrowing sentences from fiction and query domains .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
In the experiments , parsing accuracies of two shallow dependency parsers and a deep parser are examined for imperatives and questions , as well as the accuracies of a part-of-speech tagger for them .
#<struct ReadData::Alignment source_numbers="31,32", target_numbers="28", tag_name="wa">
In the experiments , parsing accuracies of two shallow dependency parsers and a deep parser are examined for imperatives and questions , as well as the accuracies of a part-of-speech tagger for them .
#<struct ReadData::Alignment source_numbers="29", target_numbers="29", tag_name="wa">
In the experiments , parsing accuracies of two shallow dependency parsers and a deep parser are examined for imperatives and questions , as well as the accuracies of a part-of-speech tagger for them .
#<struct ReadData::Alignment source_numbers="28", target_numbers="", tag_name="wa">
In the experiments , parsing accuracies of two shallow dependency parsers and a deep parser are examined for imperatives and questions , as well as the accuracies of a part-of-speech tagger for them .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
In the experiments , parsing accuracies of two shallow dependency parsers and a deep parser are examined for imperatives and questions , as well as the accuracies of a part-of-speech tagger for them .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
In the experiments , parsing accuracies of two shallow dependency parsers and a deep parser are examined for imperatives and questions , as well as the accuracies of a part-of-speech tagger for them .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
Since domain adaptation has been an extensive research area in parsing research \CITE , a lot of ideas have been proposed , including un- / semi-supervised approaches \CITE and supervised approaches \CITE .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
Since domain adaptation has been an extensive research area in parsing research \CITE , a lot of ideas have been proposed , including un- / semi-supervised approaches \CITE and supervised approaches \CITE .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
Since domain adaptation has been an extensive research area in parsing research \CITE , a lot of ideas have been proposed , including un- / semi-supervised approaches \CITE and supervised approaches \CITE .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
Since domain adaptation has been an extensive research area in parsing research \CITE , a lot of ideas have been proposed , including un- / semi-supervised approaches \CITE and supervised approaches \CITE .
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
Since domain adaptation has been an extensive research area in parsing research \CITE , a lot of ideas have been proposed , including un- / semi-supervised approaches \CITE and supervised approaches \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Since domain adaptation has been an extensive research area in parsing research \CITE , a lot of ideas have been proposed , including un- / semi-supervised approaches \CITE and supervised approaches \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
Their main focus was on adapting parsing models trained with a specific genre of text ( in most cases Penn Treebank WSJ ) to other genres of text , such as biomedical research papers and broadcast news .
#<struct ReadData::Alignment source_numbers="3", target_numbers="5,6", tag_name="wa">
Their main focus was on adapting parsing models trained with a specific genre of text ( in most cases Penn Treebank WSJ ) to other genres of text , such as biomedical research papers and broadcast news .
#<struct ReadData::Alignment source_numbers="28", target_numbers="32", tag_name="wa">
Their main focus was on adapting parsing models trained with a specific genre of text ( in most cases Penn Treebank WSJ ) to other genres of text , such as biomedical research papers and broadcast news .
#<struct ReadData::Alignment source_numbers="37", target_numbers="41", tag_name="wa">
Their main focus was on adapting parsing models trained with a specific genre of text ( in most cases Penn Treebank WSJ ) to other genres of text , such as biomedical research papers and broadcast news .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Their main focus was on adapting parsing models trained with a specific genre of text ( in most cases Penn Treebank WSJ ) to other genres of text , such as biomedical research papers and broadcast news .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Their main focus was on adapting parsing models trained with a specific genre of text ( in most cases Penn Treebank WSJ ) to other genres of text , such as biomedical research papers and broadcast news .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Their main focus was on adapting parsing models trained with a specific genre of text ( in most cases Penn Treebank WSJ ) to other genres of text , such as biomedical research papers and broadcast news .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
A major problem tackled in such a task setting is the handling of unknown words and domain-specific ways of expressions .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
A major problem tackled in such a task setting is the handling of unknown words and domain-specific ways of expressions .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
A major problem tackled in such a task setting is the handling of unknown words and domain-specific ways of expressions .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
A major problem tackled in such a task setting is the handling of unknown words and domain-specific ways of expressions .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
A major problem tackled in such a task setting is the handling of unknown words and domain-specific ways of expressions .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
A major problem tackled in such a task setting is the handling of unknown words and domain-specific ways of expressions .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Compared to domain adaptation , structural types of sentences have gained little attention to date .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Compared to domain adaptation , structural types of sentences have gained little attention to date .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
The work pointed out low accuracy of state-of-the-art parsers on questions , and proposed supervised parser adaptation by manually creating a treebank of questions .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
The work pointed out low accuracy of state-of-the-art parsers on questions , and proposed supervised parser adaptation by manually creating a treebank of questions .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
The work pointed out low accuracy of state-of-the-art parsers on questions , and proposed supervised parser adaptation by manually creating a treebank of questions .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
The work pointed out low accuracy of state-of-the-art parsers on questions , and proposed supervised parser adaptation by manually creating a treebank of questions .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
The work pointed out low accuracy of state-of-the-art parsers on questions , and proposed supervised parser adaptation by manually creating a treebank of questions .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
QuestionBank was used for the supervised training of an LFG parser , and achieved a significant improvement in parsing accuracy .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
QuestionBank was used for the supervised training of an LFG parser , and achieved a significant improvement in parsing accuracy .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
QuestionBank was used for the supervised training of an LFG parser , and achieved a significant improvement in parsing accuracy .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
QuestionBank was used for the supervised training of an LFG parser , and achieved a significant improvement in parsing accuracy .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
They collected question sentences from TREC 9-12 competitions , and annotated these sentences with POSs and CCG lexical categories .
#<struct ReadData::Alignment source_numbers="8", target_numbers="3", tag_name="wa">
They collected question sentences from TREC 9-12 competitions , and annotated these sentences with POSs and CCG lexical categories .
#<struct ReadData::Alignment source_numbers="1", target_numbers="7", tag_name="wa">
They collected question sentences from TREC 9-12 competitions , and annotated these sentences with POSs and CCG lexical categories .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
They collected question sentences from TREC 9-12 competitions , and annotated these sentences with POSs and CCG lexical categories .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
They collected question sentences from TREC 9-12 competitions , and annotated these sentences with POSs and CCG lexical categories .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
They collected question sentences from TREC 9-12 competitions , and annotated these sentences with POSs and CCG lexical categories .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
They collected question sentences from TREC 9-12 competitions , and annotated these sentences with POSs and CCG lexical categories .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
They collected question sentences from TREC 9-12 competitions , and annotated these sentences with POSs and CCG lexical categories .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
They collected question sentences from TREC 9-12 competitions , and annotated these sentences with POSs and CCG lexical categories .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
They collected question sentences from TREC 9-12 competitions , and annotated these sentences with POSs and CCG lexical categories .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
They reported a significant improvement in CCG parsing without phrase structure annotations .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
They reported a significant improvement in CCG parsing without phrase structure annotations .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
They reported a significant improvement in CCG parsing without phrase structure annotations .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Although QuestionBank and the resource of \CITE are claimed to be a corpus of questions , they are biased because the sentences come from QA queries .
#<struct ReadData::Alignment source_numbers="8", target_numbers="7", tag_name="wa">
Although QuestionBank and the resource of \CITE are claimed to be a corpus of questions , they are biased because the sentences come from QA queries .
#<struct ReadData::Alignment source_numbers="12", target_numbers="10", tag_name="wa">
Although QuestionBank and the resource of \CITE are claimed to be a corpus of questions , they are biased because the sentences come from QA queries .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Although QuestionBank and the resource of \CITE are claimed to be a corpus of questions , they are biased because the sentences come from QA queries .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
For example , such queries rarely include yes / no questions and tag questions .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
For example , such queries rarely include yes / no questions and tag questions .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
In our work , sentences are collected from the Brown corpus , which includes a wider range of types of questions and imperatives .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
In our work , sentences are collected from the Brown corpus , which includes a wider range of types of questions and imperatives .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
In the experiments , we will additionally use QuestionBank for comparison .
#<struct ReadData::Alignment source_numbers="7", target_numbers="6", tag_name="wa">
In the experiments , we will additionally use QuestionBank for comparison .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
All parsers assume that the input is already POS-tagged .
#<struct ReadData::Alignment source_numbers="2,3", target_numbers="2,3", tag_name="wa">
All parsers assume that the input is already POS-tagged .
#<struct ReadData::Alignment source_numbers="6,7", target_numbers="6,7", tag_name="wa">
We use a tagger in \CITE .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
We use a tagger in \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
The MST parser and Malt parser are dependency parsers that produce non-projective dependency trees , using the spanning tree algorithm \CITE and transition-based algorithm \CITE respectively .
#<struct ReadData::Alignment source_numbers="5", target_numbers="4", tag_name="wa">
The MST parser and Malt parser are dependency parsers that produce non-projective dependency trees , using the spanning tree algorithm \CITE and transition-based algorithm \CITE respectively .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
The MST parser and Malt parser are dependency parsers that produce non-projective dependency trees , using the spanning tree algorithm \CITE and transition-based algorithm \CITE respectively .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
Although the publicly available implementation of each parser also has an option to restrict the output to be a projective dependency tree , we used the non-projective version because the dependency structures converted from the question sentences in the Brown corpus included many non-projective dependencies .
#<struct ReadData::Alignment source_numbers="38", target_numbers="10", tag_name="wa">
Although the publicly available implementation of each parser also has an option to restrict the output to be a projective dependency tree , we used the non-projective version because the dependency structures converted from the question sentences in the Brown corpus included many non-projective dependencies .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Although the publicly available implementation of each parser also has an option to restrict the output to be a projective dependency tree , we used the non-projective version because the dependency structures converted from the question sentences in the Brown corpus included many non-projective dependencies .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
Although the publicly available implementation of each parser also has an option to restrict the output to be a projective dependency tree , we used the non-projective version because the dependency structures converted from the question sentences in the Brown corpus included many non-projective dependencies .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
We used pennconverter \CITE to convert a PTB-style treebank to dependency trees .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
We used pennconverter \CITE to convert a PTB-style treebank to dependency trees .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
For the evaluation of the output from each of the MST and Malt parser , we used the labeled attachment accuracy excluding the punctuations .
#<struct ReadData::Alignment source_numbers="2,3,4", target_numbers="1,2", tag_name="wa">
For the evaluation of the output from each of the MST and Malt parser , we used the labeled attachment accuracy excluding the punctuations .
#<struct ReadData::Alignment source_numbers="13", target_numbers="8", tag_name="wa">
For the evaluation of the output from each of the MST and Malt parser , we used the labeled attachment accuracy excluding the punctuations .
#<struct ReadData::Alignment source_numbers="14", target_numbers="9", tag_name="wa">
For the evaluation of the output from each of the MST and Malt parser , we used the labeled attachment accuracy excluding the punctuations .
#<struct ReadData::Alignment source_numbers="24", target_numbers="18", tag_name="wa">
For the evaluation of the output from each of the MST and Malt parser , we used the labeled attachment accuracy excluding the punctuations .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
For the evaluation of the output from each of the MST and Malt parser , we used the labeled attachment accuracy excluding the punctuations .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
For the evaluation of the output from each of the MST and Malt parser , we used the labeled attachment accuracy excluding the punctuations .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
For the evaluation of the output from each of the MST and Malt parser , we used the labeled attachment accuracy excluding the punctuations .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
For the evaluation of the output from each of the MST and Malt parser , we used the labeled attachment accuracy excluding the punctuations .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
For the evaluation of the output from each of the MST and Malt parser , we used the labeled attachment accuracy excluding the punctuations .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
For the evaluation of the output from each of the MST and Malt parser , we used the labeled attachment accuracy excluding the punctuations .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
The Enju parser \CITE is a deep parser based on the HPSG formalism .
#<struct ReadData::Alignment source_numbers="11", target_numbers="11", tag_name="wa">
The Enju parser \CITE is a deep parser based on the HPSG formalism .
#<struct ReadData::Alignment source_numbers="13", target_numbers="20", tag_name="wa">
The Enju parser \CITE is a deep parser based on the HPSG formalism .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
The Enju parser \CITE is a deep parser based on the HPSG formalism .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
The Enju parser \CITE is a deep parser based on the HPSG formalism .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
The Enju parser \CITE is a deep parser based on the HPSG formalism .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
The Enju parser \CITE is a deep parser based on the HPSG formalism .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
The Enju parser \CITE is a deep parser based on the HPSG formalism .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
The Enju parser \CITE is a deep parser based on the HPSG formalism .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
We used a toolkit distributed with the Enju parser for training the parser with a PTB-style treebank .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
We used a toolkit distributed with the Enju parser for training the parser with a PTB-style treebank .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
The toolkit initially converts the PTB-style treebank into an HPSG treebank and then trains the parser on it .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
The toolkit initially converts the PTB-style treebank into an HPSG treebank and then trains the parser on it .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
The toolkit initially converts the PTB-style treebank into an HPSG treebank and then trains the parser on it .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
The toolkit initially converts the PTB-style treebank into an HPSG treebank and then trains the parser on it .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
As the evaluation metrics of the Enju parser , we used labeled and unlabeled precision / recall / F-score of the predicate-argument dependencies produced by the parser .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
As the evaluation metrics of the Enju parser , we used labeled and unlabeled precision / recall / F-score of the predicate-argument dependencies produced by the parser .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
This section explains how we collected the treebanks of imperatives and questions , which were used in the experiments in Section \REF .
#<struct ReadData::Alignment source_numbers="15", target_numbers="12", tag_name="wa">
This section explains how we collected the treebanks of imperatives and questions , which were used in the experiments in Section \REF .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
This section explains how we collected the treebanks of imperatives and questions , which were used in the experiments in Section \REF .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
This section explains how we collected the treebanks of imperatives and questions , which were used in the experiments in Section \REF .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
While the Wall Street Journal ( WSJ ) treebank has extensively been used for parsing experiments , we use the treebank of the Brown Corpus in our experiments .
#<struct ReadData::Alignment source_numbers="6", target_numbers="2", tag_name="wa">
While the Wall Street Journal ( WSJ ) treebank has extensively been used for parsing experiments , we use the treebank of the Brown Corpus in our experiments .
#<struct ReadData::Alignment source_numbers="16", target_numbers="11", tag_name="wa">
While the Wall Street Journal ( WSJ ) treebank has extensively been used for parsing experiments , we use the treebank of the Brown Corpus in our experiments .
#<struct ReadData::Alignment source_numbers="28", target_numbers="23", tag_name="wa">
While the Wall Street Journal ( WSJ ) treebank has extensively been used for parsing experiments , we use the treebank of the Brown Corpus in our experiments .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
While the Wall Street Journal ( WSJ ) treebank has extensively been used for parsing experiments , we use the treebank of the Brown Corpus in our experiments .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
While the Wall Street Journal ( WSJ ) treebank has extensively been used for parsing experiments , we use the treebank of the Brown Corpus in our experiments .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
While the Wall Street Journal ( WSJ ) treebank has extensively been used for parsing experiments , we use the treebank of the Brown Corpus in our experiments .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
While the Wall Street Journal ( WSJ ) treebank has extensively been used for parsing experiments , we use the treebank of the Brown Corpus in our experiments .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
While the Wall Street Journal ( WSJ ) treebank has extensively been used for parsing experiments , we use the treebank of the Brown Corpus in our experiments .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
While the Wall Street Journal ( WSJ ) treebank has extensively been used for parsing experiments , we use the treebank of the Brown Corpus in our experiments .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Because the Brown Corpus portion includes texts of literary works , it is expected that it inherently contains a larger number of imperatives and questions than the WSJ portion .
#<struct ReadData::Alignment source_numbers="13,14", target_numbers="13,14", tag_name="wa">
Because the Brown Corpus portion includes texts of literary works , it is expected that it inherently contains a larger number of imperatives and questions than the WSJ portion .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Because the Brown Corpus portion includes texts of literary works , it is expected that it inherently contains a larger number of imperatives and questions than the WSJ portion .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
Because the Brown Corpus portion includes texts of literary works , it is expected that it inherently contains a larger number of imperatives and questions than the WSJ portion .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Because the Brown Corpus portion includes texts of literary works , it is expected that it inherently contains a larger number of imperatives and questions than the WSJ portion .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
Interrogative sentences are annotated with the phrase label " SBARQ " or " SQ " , where " SBARQ " represents wh-questions , while " SQ " denotes yes / no questions .
#<struct ReadData::Alignment source_numbers="27", target_numbers="20", tag_name="wa">
Interrogative sentences are annotated with the phrase label " SBARQ " or " SQ " , where " SBARQ " represents wh-questions , while " SQ " denotes yes / no questions .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
Interrogative sentences are annotated with the phrase label " SBARQ " or " SQ " , where " SBARQ " represents wh-questions , while " SQ " denotes yes / no questions .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
We extracted those sentences annotated with these phrase labels .
#<struct ReadData::Alignment source_numbers="1", target_numbers="8", tag_name="wa">
We extracted those sentences annotated with these phrase labels .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Imperatives and questions appear not only at the top level but also appear as embedded clauses .
#<struct ReadData::Alignment source_numbers="3", target_numbers="3", tag_name="wa">
Imperatives and questions appear not only at the top level but also appear as embedded clauses .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
When they are embedded in another imperative or question , we only extracted the outermost one .
#<struct ReadData::Alignment source_numbers="2", target_numbers="3,4", tag_name="wa">
When they are embedded in another imperative or question , we only extracted the outermost one .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
When they are embedded in another imperative or question , we only extracted the outermost one .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Extracted sentences are post-processed so that they have natural sentence forms : first characters are capitalized , and question marks or periods are added when appropriate .
#<struct ReadData::Alignment source_numbers="5", target_numbers="11", tag_name="wa">
Extracted sentences are post-processed so that they have natural sentence forms : first characters are capitalized , and question marks or periods are added when appropriate .
#<struct ReadData::Alignment source_numbers="14", target_numbers="12", tag_name="wa">
Extracted sentences are post-processed so that they have natural sentence forms : first characters are capitalized , and question marks or periods are added when appropriate .
#<struct ReadData::Alignment source_numbers="15", target_numbers="17", tag_name="wa">
Extracted sentences are post-processed so that they have natural sentence forms : first characters are capitalized , and question marks or periods are added when appropriate .
#<struct ReadData::Alignment source_numbers="23", target_numbers="23", tag_name="wa">
Extracted sentences are post-processed so that they have natural sentence forms : first characters are capitalized , and question marks or periods are added when appropriate .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
Extracted sentences are post-processed so that they have natural sentence forms : first characters are capitalized , and question marks or periods are added when appropriate .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
Extracted sentences are post-processed so that they have natural sentence forms : first characters are capitalized , and question marks or periods are added when appropriate .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
Extracted sentences are post-processed so that they have natural sentence forms : first characters are capitalized , and question marks or periods are added when appropriate .
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
Extracted sentences are post-processed so that they have natural sentence forms : first characters are capitalized , and question marks or periods are added when appropriate .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Extracted sentences are post-processed so that they have natural sentence forms : first characters are capitalized , and question marks or periods are added when appropriate .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Extracted sentences are post-processed so that they have natural sentence forms : first characters are capitalized , and question marks or periods are added when appropriate .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Extracted sentences are post-processed so that they have natural sentence forms : first characters are capitalized , and question marks or periods are added when appropriate .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
The number of sentences for each section is shown in Table \REF .
#<struct ReadData::Alignment source_numbers="1,2", target_numbers="1,2", tag_name="wa">
The number of sentences for each section is shown in Table \REF .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
The number of sentences for each section is shown in Table \REF .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Although we also applied a similar method to the WSJ portion , we could obtain only 115 imperatives and 432 questions .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
Although we also applied a similar method to the WSJ portion , we could obtain only 115 imperatives and 432 questions .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
Although we also applied a similar method to the WSJ portion , we could obtain only 115 imperatives and 432 questions .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
We will not use this data in the experiments .
#<struct ReadData::Alignment source_numbers="2", target_numbers="3", tag_name="wa">
We will not use this data in the experiments .
#<struct ReadData::Alignment source_numbers="3", target_numbers="4", tag_name="wa">
We will not use this data in the experiments .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
We will not use this data in the experiments .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
We will not use this data in the experiments .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
We will not use this data in the experiments .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
We will not use this data in the experiments .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
As we will describe below , we additionally use QuestionBank in experiments .
#<struct ReadData::Alignment source_numbers="0", target_numbers="0", tag_name="wa">
As we will describe below , we additionally use QuestionBank in experiments .
#<struct ReadData::Alignment source_numbers="3", target_numbers="1", tag_name="wa">
As we will describe below , we additionally use QuestionBank in experiments .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
As we will describe below , we additionally use QuestionBank in experiments .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
However , an advantage of using the Brown treebank is that it includes annotations of function tags and empty categories . Therefore , we can apply the Penn Treebank-to-HPSG conversion program of Enju \CITE , which relies on function tags and empty categories .
#<struct ReadData::Alignment source_numbers="1", target_numbers="2", tag_name="wa">
However , an advantage of using the Brown treebank is that it includes annotations of function tags and empty categories . Therefore , we can apply the Penn Treebank-to-HPSG conversion program of Enju \CITE , which relies on function tags and empty categories .
#<struct ReadData::Alignment source_numbers="22", target_numbers="4", tag_name="wa">
However , an advantage of using the Brown treebank is that it includes annotations of function tags and empty categories . Therefore , we can apply the Penn Treebank-to-HPSG conversion program of Enju \CITE , which relies on function tags and empty categories .
#<struct ReadData::Alignment source_numbers="34", target_numbers="21", tag_name="wa">
However , an advantage of using the Brown treebank is that it includes annotations of function tags and empty categories . Therefore , we can apply the Penn Treebank-to-HPSG conversion program of Enju \CITE , which relies on function tags and empty categories .
#<struct ReadData::Alignment source_numbers="40", target_numbers="22", tag_name="wa">
However , an advantage of using the Brown treebank is that it includes annotations of function tags and empty categories . Therefore , we can apply the Penn Treebank-to-HPSG conversion program of Enju \CITE , which relies on function tags and empty categories .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
However , an advantage of using the Brown treebank is that it includes annotations of function tags and empty categories . Therefore , we can apply the Penn Treebank-to-HPSG conversion program of Enju \CITE , which relies on function tags and empty categories .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
However , an advantage of using the Brown treebank is that it includes annotations of function tags and empty categories . Therefore , we can apply the Penn Treebank-to-HPSG conversion program of Enju \CITE , which relies on function tags and empty categories .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
However , an advantage of using the Brown treebank is that it includes annotations of function tags and empty categories . Therefore , we can apply the Penn Treebank-to-HPSG conversion program of Enju \CITE , which relies on function tags and empty categories .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
However , an advantage of using the Brown treebank is that it includes annotations of function tags and empty categories . Therefore , we can apply the Penn Treebank-to-HPSG conversion program of Enju \CITE , which relies on function tags and empty categories .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
However , an advantage of using the Brown treebank is that it includes annotations of function tags and empty categories . Therefore , we can apply the Penn Treebank-to-HPSG conversion program of Enju \CITE , which relies on function tags and empty categories .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
However , an advantage of using the Brown treebank is that it includes annotations of function tags and empty categories . Therefore , we can apply the Penn Treebank-to-HPSG conversion program of Enju \CITE , which relies on function tags and empty categories .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
However , an advantage of using the Brown treebank is that it includes annotations of function tags and empty categories . Therefore , we can apply the Penn Treebank-to-HPSG conversion program of Enju \CITE , which relies on function tags and empty categories .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
However , an advantage of using the Brown treebank is that it includes annotations of function tags and empty categories . Therefore , we can apply the Penn Treebank-to-HPSG conversion program of Enju \CITE , which relies on function tags and empty categories .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
However , an advantage of using the Brown treebank is that it includes annotations of function tags and empty categories . Therefore , we can apply the Penn Treebank-to-HPSG conversion program of Enju \CITE , which relies on function tags and empty categories .
#<struct ReadData::Alignment source_numbers="", target_numbers="42", tag_name="wa">
Hence , we will show experimental results on Enju only with the Brown data .
#<struct ReadData::Alignment source_numbers="4", target_numbers="3", tag_name="wa">
Hence , we will show experimental results on Enju only with the Brown data .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
Hence , we will show experimental results on Enju only with the Brown data .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Hence , we will show experimental results on Enju only with the Brown data .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
It should also be noted that , a constituency-to-dependency converter , pennconverter \CITE , provides more accurate conversion when function tags and empty categories are available ( See footnote 6 ) .
#<struct ReadData::Alignment source_numbers="27", target_numbers="", tag_name="wa">
It should also be noted that , a constituency-to-dependency converter , pennconverter \CITE , provides more accurate conversion when function tags and empty categories are available ( See footnote 6 ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
It should also be noted that , a constituency-to-dependency converter , pennconverter \CITE , provides more accurate conversion when function tags and empty categories are available ( See footnote 6 ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
We extracted 3 ,859 sentences that are annotated with " SBARQ " or " SQ " .
#<struct ReadData::Alignment source_numbers="7", target_numbers="5", tag_name="wa">
We extracted 3 ,859 sentences that are annotated with " SBARQ " or " SQ " .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
We extracted 3 ,859 sentences that are annotated with " SBARQ " or " SQ " .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
During experiments , we found several annotation errors that caused fatal errors of treebank conversion .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
During experiments , we found several annotation errors that caused fatal errors of treebank conversion .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
We therefore corrected annotations of twelve sentences manually .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
We plan to make these corrections publicly available .
#<struct ReadData::Alignment source_numbers="3", target_numbers="2", tag_name="wa">
We plan to make these corrections publicly available .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
We plan to make these corrections publicly available .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
We plan to make these corrections publicly available .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
We also found and corrected obvious inconsistencies in the corpus : character " ' " replaced by " $<$ " ( 737 sentences ) , token " ? " tagged not with " . " but with " ? " ( 2 ,051 sentences ) , and phrase labels annotated as POS ( one sentence ) .
#<struct ReadData::Alignment source_numbers="37", target_numbers="31", tag_name="wa">
We also found and corrected obvious inconsistencies in the corpus : character " ' " replaced by " $<$ " ( 737 sentences ) , token " ? " tagged not with " . " but with " ? " ( 2 ,051 sentences ) , and phrase labels annotated as POS ( one sentence ) .
#<struct ReadData::Alignment source_numbers="39", target_numbers="33", tag_name="wa">
We also found and corrected obvious inconsistencies in the corpus : character " ' " replaced by " $<$ " ( 737 sentences ) , token " ? " tagged not with " . " but with " ? " ( 2 ,051 sentences ) , and phrase labels annotated as POS ( one sentence ) .
#<struct ReadData::Alignment source_numbers="30", target_numbers="34", tag_name="wa">
We also found and corrected obvious inconsistencies in the corpus : character " ' " replaced by " $<$ " ( 737 sentences ) , token " ? " tagged not with " . " but with " ? " ( 2 ,051 sentences ) , and phrase labels annotated as POS ( one sentence ) .
#<struct ReadData::Alignment source_numbers="32", target_numbers="36", tag_name="wa">
We also found and corrected obvious inconsistencies in the corpus : character " ' " replaced by " $<$ " ( 737 sentences ) , token " ? " tagged not with " . " but with " ? " ( 2 ,051 sentences ) , and phrase labels annotated as POS ( one sentence ) .
#<struct ReadData::Alignment source_numbers="34", target_numbers="38", tag_name="wa">
We also found and corrected obvious inconsistencies in the corpus : character " ' " replaced by " $<$ " ( 737 sentences ) , token " ? " tagged not with " . " but with " ? " ( 2 ,051 sentences ) , and phrase labels annotated as POS ( one sentence ) .
#<struct ReadData::Alignment source_numbers="31", target_numbers="", tag_name="wa">
We also found and corrected obvious inconsistencies in the corpus : character " ' " replaced by " $<$ " ( 737 sentences ) , token " ? " tagged not with " . " but with " ? " ( 2 ,051 sentences ) , and phrase labels annotated as POS ( one sentence ) .
#<struct ReadData::Alignment source_numbers="35", target_numbers="", tag_name="wa">
We also found and corrected obvious inconsistencies in the corpus : character " ' " replaced by " $<$ " ( 737 sentences ) , token " ? " tagged not with " . " but with " ? " ( 2 ,051 sentences ) , and phrase labels annotated as POS ( one sentence ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
We examined performances of the three parsers and the POS tagger for Brown imperatives and questions , and QuestionBank questions .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
We examined performances of the three parsers and the POS tagger for Brown imperatives and questions , and QuestionBank questions .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
By observing the effects of parser or tagger adaptation to each domain , we would like to see the difficulties in parsing imperative and question sentences .
#<struct ReadData::Alignment source_numbers="3", target_numbers="2,3", tag_name="wa">
By observing the effects of parser or tagger adaptation to each domain , we would like to see the difficulties in parsing imperative and question sentences .
#<struct ReadData::Alignment source_numbers="2", target_numbers="5", tag_name="wa">
By observing the effects of parser or tagger adaptation to each domain , we would like to see the difficulties in parsing imperative and question sentences .
#<struct ReadData::Alignment source_numbers="20", target_numbers="10", tag_name="wa">
By observing the effects of parser or tagger adaptation to each domain , we would like to see the difficulties in parsing imperative and question sentences .
#<struct ReadData::Alignment source_numbers="17", target_numbers="15,16", tag_name="wa">
By observing the effects of parser or tagger adaptation to each domain , we would like to see the difficulties in parsing imperative and question sentences .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
By observing the effects of parser or tagger adaptation to each domain , we would like to see the difficulties in parsing imperative and question sentences .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
By observing the effects of parser or tagger adaptation to each domain , we would like to see the difficulties in parsing imperative and question sentences .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
By observing the effects of parser or tagger adaptation to each domain , we would like to see the difficulties in parsing imperative and question sentences .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
By observing the effects of parser or tagger adaptation to each domain , we would like to see the difficulties in parsing imperative and question sentences .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
We also examined the portability of sentence construction properties between two similar domains : questions in Brown and QuestionBank .
#<struct ReadData::Alignment source_numbers="15", target_numbers="15", tag_name="wa">
We also examined the portability of sentence construction properties between two similar domains : questions in Brown and QuestionBank .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
We made experimental datasets for five domains : Wall Street Journal ( WSJ ) , Brown overall sentences , Brown imperatives , Brown questions , and QuestionBank questions .
#<struct ReadData::Alignment source_numbers="12", target_numbers="8", tag_name="wa">
We made experimental datasets for five domains : Wall Street Journal ( WSJ ) , Brown overall sentences , Brown imperatives , Brown questions , and QuestionBank questions .
#<struct ReadData::Alignment source_numbers="14", target_numbers="9", tag_name="wa">
We made experimental datasets for five domains : Wall Street Journal ( WSJ ) , Brown overall sentences , Brown imperatives , Brown questions , and QuestionBank questions .
#<struct ReadData::Alignment source_numbers="18", target_numbers="12", tag_name="wa">
We made experimental datasets for five domains : Wall Street Journal ( WSJ ) , Brown overall sentences , Brown imperatives , Brown questions , and QuestionBank questions .
#<struct ReadData::Alignment source_numbers="21", target_numbers="15", tag_name="wa">
We made experimental datasets for five domains : Wall Street Journal ( WSJ ) , Brown overall sentences , Brown imperatives , Brown questions , and QuestionBank questions .
#<struct ReadData::Alignment source_numbers="24", target_numbers="18", tag_name="wa">
We made experimental datasets for five domains : Wall Street Journal ( WSJ ) , Brown overall sentences , Brown imperatives , Brown questions , and QuestionBank questions .
#<struct ReadData::Alignment source_numbers="28", target_numbers="22", tag_name="wa">
We made experimental datasets for five domains : Wall Street Journal ( WSJ ) , Brown overall sentences , Brown imperatives , Brown questions , and QuestionBank questions .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
We made experimental datasets for five domains : Wall Street Journal ( WSJ ) , Brown overall sentences , Brown imperatives , Brown questions , and QuestionBank questions .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
We made experimental datasets for five domains : Wall Street Journal ( WSJ ) , Brown overall sentences , Brown imperatives , Brown questions , and QuestionBank questions .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
We made experimental datasets for five domains : Wall Street Journal ( WSJ ) , Brown overall sentences , Brown imperatives , Brown questions , and QuestionBank questions .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
We made experimental datasets for five domains : Wall Street Journal ( WSJ ) , Brown overall sentences , Brown imperatives , Brown questions , and QuestionBank questions .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
- Divided into three parts for training ( Section 02 - 21 , 39 ,832 sentences ) , development test ( Section 22 , 1 ,700 sentences ) , and final test ( Section 23 , 2 ,416 sentences ) .
#<struct ReadData::Alignment source_numbers="35", target_numbers="5", tag_name="wa">
- Divided into three parts for training ( Section 02 - 21 , 39 ,832 sentences ) , development test ( Section 22 , 1 ,700 sentences ) , and final test ( Section 23 , 2 ,416 sentences ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
- Randomly divided into three parts for training ( 19 ,395 sentences ) , development set ( 2 ,424 sentences ) , and final test ( 2 ,424 sentences )
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
- divided into two parts : one for ten-folds cross validation test ( 65 $\times$ 10 sentences ) and the other for error analysis ( 100 sentences )
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
- divided into two parts : one for ten-folds cross validation test ( 112 $\times$ 10 sentences ) and the other for error analysis ( 141 sentences )
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
- from the top of the corpus divided into three parts for final test ( 1 ,000 sentences ) , training ( 2 ,560 sentences ) , and analysis ( 299 sentences )
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
In order to adapt each parser or POS tagger to a target domain , we trained the parser on combined training data for the target domain and for the original parser .
#<struct ReadData::Alignment source_numbers="26", target_numbers="4", tag_name="wa">
In order to adapt each parser or POS tagger to a target domain , we trained the parser on combined training data for the target domain and for the original parser .
#<struct ReadData::Alignment source_numbers="28", target_numbers="5", tag_name="wa">
In order to adapt each parser or POS tagger to a target domain , we trained the parser on combined training data for the target domain and for the original parser .
#<struct ReadData::Alignment source_numbers="22", target_numbers="21", tag_name="wa">
In order to adapt each parser or POS tagger to a target domain , we trained the parser on combined training data for the target domain and for the original parser .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
In order to adapt each parser or POS tagger to a target domain , we trained the parser on combined training data for the target domain and for the original parser .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
In order to adapt each parser or POS tagger to a target domain , we trained the parser on combined training data for the target domain and for the original parser .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
In order to adapt each parser or POS tagger to a target domain , we trained the parser on combined training data for the target domain and for the original parser .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
In order to adapt each parser or POS tagger to a target domain , we trained the parser on combined training data for the target domain and for the original parser .
#<struct ReadData::Alignment source_numbers="27", target_numbers="", tag_name="wa">
In order to adapt each parser or POS tagger to a target domain , we trained the parser on combined training data for the target domain and for the original parser .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
In order to adapt each parser or POS tagger to a target domain , we trained the parser on combined training data for the target domain and for the original parser .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
In order to adapt each parser or POS tagger to a target domain , we trained the parser on combined training data for the target domain and for the original parser .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
For a domain which contains only small training data , we replicated the training data for certain times and just utilized the concatenated replicas for training .
#<struct ReadData::Alignment source_numbers="6", target_numbers="6", tag_name="wa">
For a domain which contains only small training data , we replicated the training data for certain times and just utilized the concatenated replicas for training .
#<struct ReadData::Alignment source_numbers="16", target_numbers="18", tag_name="wa">
For a domain which contains only small training data , we replicated the training data for certain times and just utilized the concatenated replicas for training .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
For a domain which contains only small training data , we replicated the training data for certain times and just utilized the concatenated replicas for training .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
For a domain which contains only small training data , we replicated the training data for certain times and just utilized the concatenated replicas for training .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
For a domain which contains only small training data , we replicated the training data for certain times and just utilized the concatenated replicas for training .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
For a domain which contains only small training data , we replicated the training data for certain times and just utilized the concatenated replicas for training .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
- For Brown overall , we trained the model with the combined training data for the target domain and for the original model .
#<struct ReadData::Alignment source_numbers="14", target_numbers="14", tag_name="wa">
- For Brown overall , we trained the model with the combined training data for the target domain and for the original model .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
For Brown imperatives / questions and QuestionBank , we replicated the training data for certain times and utilized the concatenated replicas and WSJ training data for training .
#<struct ReadData::Alignment source_numbers="14", target_numbers="14", tag_name="wa">
For Brown imperatives / questions and QuestionBank , we replicated the training data for certain times and utilized the concatenated replicas and WSJ training data for training .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
For Brown imperatives / questions and QuestionBank , we replicated the training data for certain times and utilized the concatenated replicas and WSJ training data for training .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
For POS tagger , the number of replicas of training data was determined among 1 , 2 , 4 , 8 , 16 , 32 , 64 , and 128 , by testing these numbers on development test sets in three of ten datasets of cross validation .
#<struct ReadData::Alignment source_numbers="47", target_numbers="51", tag_name="wa">
For POS tagger , the number of replicas of training data was determined among 1 , 2 , 4 , 8 , 16 , 32 , 64 , and 128 , by testing these numbers on development test sets in three of ten datasets of cross validation .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
For POS tagger , the number of replicas of training data was determined among 1 , 2 , 4 , 8 , 16 , 32 , 64 , and 128 , by testing these numbers on development test sets in three of ten datasets of cross validation .
#<struct ReadData::Alignment source_numbers="28", target_numbers="", tag_name="wa">
For POS tagger , the number of replicas of training data was determined among 1 , 2 , 4 , 8 , 16 , 32 , 64 , and 128 , by testing these numbers on development test sets in three of ten datasets of cross validation .
#<struct ReadData::Alignment source_numbers="44", target_numbers="", tag_name="wa">
For POS tagger , the number of replicas of training data was determined among 1 , 2 , 4 , 8 , 16 , 32 , 64 , and 128 , by testing these numbers on development test sets in three of ten datasets of cross validation .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
For POS tagger , the number of replicas of training data was determined among 1 , 2 , 4 , 8 , 16 , 32 , 64 , and 128 , by testing these numbers on development test sets in three of ten datasets of cross validation .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
For POS tagger , the number of replicas of training data was determined among 1 , 2 , 4 , 8 , 16 , 32 , 64 , and 128 , by testing these numbers on development test sets in three of ten datasets of cross validation .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
For POS tagger , the number of replicas of training data was determined among 1 , 2 , 4 , 8 , 16 , 32 , 64 , and 128 , by testing these numbers on development test sets in three of ten datasets of cross validation .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
For POS tagger , the number of replicas of training data was determined among 1 , 2 , 4 , 8 , 16 , 32 , 64 , and 128 , by testing these numbers on development test sets in three of ten datasets of cross validation .
#<struct ReadData::Alignment source_numbers="", target_numbers="48", tag_name="wa">
- For Brown overall and QuestionBank questions , we trained the model on combined data for the target domain and for the original model .
#<struct ReadData::Alignment source_numbers="15", target_numbers="15", tag_name="wa">
- For Brown overall and QuestionBank questions , we trained the model on combined data for the target domain and for the original model .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
- We used a toolkit in the Enju parser \CITE
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
- We used a toolkit in the Enju parser \CITE
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
- We used a toolkit in the Enju parser \CITE
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Table \REF shows the POS tagging accuracies for the target domains .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Table \REF shows the POS tagging accuracies for the target domains .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
When we applied WSJ tagger to other domains , the tagging accuracy more or less decreased .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
When we applied WSJ tagger to other domains , the tagging accuracy more or less decreased .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
When we applied WSJ tagger to other domains , the tagging accuracy more or less decreased .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
Among them , for Brown overall sentences , the accuracy did not decrease much from WSJ .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Among them , for Brown overall sentences , the accuracy did not decrease much from WSJ .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Among them , for Brown overall sentences , the accuracy did not decrease much from WSJ .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
Among them , for Brown overall sentences , the accuracy did not decrease much from WSJ .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
Among them , for Brown overall sentences , the accuracy did not decrease much from WSJ .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Among them , for Brown overall sentences , the accuracy did not decrease much from WSJ .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Among them , for Brown overall sentences , the accuracy did not decrease much from WSJ .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Among them , for Brown overall sentences , the accuracy did not decrease much from WSJ .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
The table shows the adaptation could improve the tagging accuracy to some extent , while the table also shows that the improved accuracy for the imperatives and questions could not reach eventhe accuracy of adapted tagger for Brown overall .
#<struct ReadData::Alignment source_numbers="0", target_numbers="0", tag_name="wa">
The table shows the adaptation could improve the tagging accuracy to some extent , while the table also shows that the improved accuracy for the imperatives and questions could not reach eventhe accuracy of adapted tagger for Brown overall .
#<struct ReadData::Alignment source_numbers="1", target_numbers="1", tag_name="wa">
The table shows the adaptation could improve the tagging accuracy to some extent , while the table also shows that the improved accuracy for the imperatives and questions could not reach eventhe accuracy of adapted tagger for Brown overall .
#<struct ReadData::Alignment source_numbers="2", target_numbers="2", tag_name="wa">
The table shows the adaptation could improve the tagging accuracy to some extent , while the table also shows that the improved accuracy for the imperatives and questions could not reach eventhe accuracy of adapted tagger for Brown overall .
#<struct ReadData::Alignment source_numbers="19", target_numbers="3", tag_name="wa">
The table shows the adaptation could improve the tagging accuracy to some extent , while the table also shows that the improved accuracy for the imperatives and questions could not reach eventhe accuracy of adapted tagger for Brown overall .
#<struct ReadData::Alignment source_numbers="21", target_numbers="6", tag_name="wa">
The table shows the adaptation could improve the tagging accuracy to some extent , while the table also shows that the improved accuracy for the imperatives and questions could not reach eventhe accuracy of adapted tagger for Brown overall .
#<struct ReadData::Alignment source_numbers="15", target_numbers="7", tag_name="wa">
The table shows the adaptation could improve the tagging accuracy to some extent , while the table also shows that the improved accuracy for the imperatives and questions could not reach eventhe accuracy of adapted tagger for Brown overall .
#<struct ReadData::Alignment source_numbers="6,7", target_numbers="17", tag_name="wa">
The table shows the adaptation could improve the tagging accuracy to some extent , while the table also shows that the improved accuracy for the imperatives and questions could not reach eventhe accuracy of adapted tagger for Brown overall .
#<struct ReadData::Alignment source_numbers="29,30", target_numbers="25", tag_name="wa">
The table shows the adaptation could improve the tagging accuracy to some extent , while the table also shows that the improved accuracy for the imperatives and questions could not reach eventhe accuracy of adapted tagger for Brown overall .
#<struct ReadData::Alignment source_numbers="33", target_numbers="27", tag_name="wa">
The table shows the adaptation could improve the tagging accuracy to some extent , while the table also shows that the improved accuracy for the imperatives and questions could not reach eventhe accuracy of adapted tagger for Brown overall .
#<struct ReadData::Alignment source_numbers="24", target_numbers="28", tag_name="wa">
The table shows the adaptation could improve the tagging accuracy to some extent , while the table also shows that the improved accuracy for the imperatives and questions could not reach eventhe accuracy of adapted tagger for Brown overall .
#<struct ReadData::Alignment source_numbers="39", target_numbers="34", tag_name="wa">
The table shows the adaptation could improve the tagging accuracy to some extent , while the table also shows that the improved accuracy for the imperatives and questions could not reach eventhe accuracy of adapted tagger for Brown overall .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
The table shows the adaptation could improve the tagging accuracy to some extent , while the table also shows that the improved accuracy for the imperatives and questions could not reach eventhe accuracy of adapted tagger for Brown overall .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
The table shows the adaptation could improve the tagging accuracy to some extent , while the table also shows that the improved accuracy for the imperatives and questions could not reach eventhe accuracy of adapted tagger for Brown overall .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
The table shows the adaptation could improve the tagging accuracy to some extent , while the table also shows that the improved accuracy for the imperatives and questions could not reach eventhe accuracy of adapted tagger for Brown overall .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
The table shows the adaptation could improve the tagging accuracy to some extent , while the table also shows that the improved accuracy for the imperatives and questions could not reach eventhe accuracy of adapted tagger for Brown overall .
#<struct ReadData::Alignment source_numbers="28", target_numbers="", tag_name="wa">
The table shows the adaptation could improve the tagging accuracy to some extent , while the table also shows that the improved accuracy for the imperatives and questions could not reach eventhe accuracy of adapted tagger for Brown overall .
#<struct ReadData::Alignment source_numbers="32", target_numbers="", tag_name="wa">
The table shows the adaptation could improve the tagging accuracy to some extent , while the table also shows that the improved accuracy for the imperatives and questions could not reach eventhe accuracy of adapted tagger for Brown overall .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
The table shows the adaptation could improve the tagging accuracy to some extent , while the table also shows that the improved accuracy for the imperatives and questions could not reach eventhe accuracy of adapted tagger for Brown overall .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
The table shows the adaptation could improve the tagging accuracy to some extent , while the table also shows that the improved accuracy for the imperatives and questions could not reach eventhe accuracy of adapted tagger for Brown overall .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
The table shows the adaptation could improve the tagging accuracy to some extent , while the table also shows that the improved accuracy for the imperatives and questions could not reach eventhe accuracy of adapted tagger for Brown overall .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
The table shows the adaptation could improve the tagging accuracy to some extent , while the table also shows that the improved accuracy for the imperatives and questions could not reach eventhe accuracy of adapted tagger for Brown overall .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
Figure \REF shows the POS tagging accuracy for the target domains given by changing the size of the target training data .
#<struct ReadData::Alignment source_numbers="14,15", target_numbers="13", tag_name="wa">
Figure \REF shows the POS tagging accuracy for the target domains given by changing the size of the target training data .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
Figure \REF shows the POS tagging accuracy for the target domains given by changing the size of the target training data .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
This graph shows that for both types of sentences , first 300 training sentences improved the accuracy rapidly , and after that , the effect of adding training corpus declined .
#<struct ReadData::Alignment source_numbers="23", target_numbers="10", tag_name="wa">
This graph shows that for both types of sentences , first 300 training sentences improved the accuracy rapidly , and after that , the effect of adding training corpus declined .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
This graph shows that for both types of sentences , first 300 training sentences improved the accuracy rapidly , and after that , the effect of adding training corpus declined .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
This graph shows that for both types of sentences , first 300 training sentences improved the accuracy rapidly , and after that , the effect of adding training corpus declined .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
This graph shows that for both types of sentences , first 300 training sentences improved the accuracy rapidly , and after that , the effect of adding training corpus declined .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
This graph shows that for both types of sentences , first 300 training sentences improved the accuracy rapidly , and after that , the effect of adding training corpus declined .
#<struct ReadData::Alignment source_numbers="28", target_numbers="", tag_name="wa">
This graph shows that for both types of sentences , first 300 training sentences improved the accuracy rapidly , and after that , the effect of adding training corpus declined .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
This graph shows that for both types of sentences , first 300 training sentences improved the accuracy rapidly , and after that , the effect of adding training corpus declined .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
This graph shows that for both types of sentences , first 300 training sentences improved the accuracy rapidly , and after that , the effect of adding training corpus declined .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
This graph shows that for both types of sentences , first 300 training sentences improved the accuracy rapidly , and after that , the effect of adding training corpus declined .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
This graph shows that for both types of sentences , first 300 training sentences improved the accuracy rapidly , and after that , the effect of adding training corpus declined .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
In order to recover the tagging accuracy of the WSJ tagger for WSJ ( 97 .53\% in Table \REF ) , it would not seem to be enough only to prepare much more training data .
#<struct ReadData::Alignment source_numbers="30", target_numbers="20", tag_name="wa">
In order to recover the tagging accuracy of the WSJ tagger for WSJ ( 97 .53\% in Table \REF ) , it would not seem to be enough only to prepare much more training data .
#<struct ReadData::Alignment source_numbers="23,24,25", target_numbers="25,26,27,28", tag_name="wa">
In order to recover the tagging accuracy of the WSJ tagger for WSJ ( 97 .53\% in Table \REF ) , it would not seem to be enough only to prepare much more training data .
#<struct ReadData::Alignment source_numbers="35", target_numbers="31", tag_name="wa">
In order to recover the tagging accuracy of the WSJ tagger for WSJ ( 97 .53\% in Table \REF ) , it would not seem to be enough only to prepare much more training data .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
In order to recover the tagging accuracy of the WSJ tagger for WSJ ( 97 .53\% in Table \REF ) , it would not seem to be enough only to prepare much more training data .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
In order to recover the tagging accuracy of the WSJ tagger for WSJ ( 97 .53\% in Table \REF ) , it would not seem to be enough only to prepare much more training data .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
In order to recover the tagging accuracy of the WSJ tagger for WSJ ( 97 .53\% in Table \REF ) , it would not seem to be enough only to prepare much more training data .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
In order to recover the tagging accuracy of the WSJ tagger for WSJ ( 97 .53\% in Table \REF ) , it would not seem to be enough only to prepare much more training data .
#<struct ReadData::Alignment source_numbers="29", target_numbers="", tag_name="wa">
In order to recover the tagging accuracy of the WSJ tagger for WSJ ( 97 .53\% in Table \REF ) , it would not seem to be enough only to prepare much more training data .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Especially , the problem would be more serious for imperatives .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Especially , the problem would be more serious for imperatives .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Especially , the problem would be more serious for imperatives .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
We then explored the tagging errors in each domain in order to observe what types of errors the WSJ tagger gave and what types of errors were solved or still unsolved by the adapted taggers .
#<struct ReadData::Alignment source_numbers="11", target_numbers="10", tag_name="wa">
We then explored the tagging errors in each domain in order to observe what types of errors the WSJ tagger gave and what types of errors were solved or still unsolved by the adapted taggers .
#<struct ReadData::Alignment source_numbers="32", target_numbers="12", tag_name="wa">
We then explored the tagging errors in each domain in order to observe what types of errors the WSJ tagger gave and what types of errors were solved or still unsolved by the adapted taggers .
#<struct ReadData::Alignment source_numbers="24", target_numbers="22", tag_name="wa">
We then explored the tagging errors in each domain in order to observe what types of errors the WSJ tagger gave and what types of errors were solved or still unsolved by the adapted taggers .
#<struct ReadData::Alignment source_numbers="28", target_numbers="31", tag_name="wa">
We then explored the tagging errors in each domain in order to observe what types of errors the WSJ tagger gave and what types of errors were solved or still unsolved by the adapted taggers .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
We then explored the tagging errors in each domain in order to observe what types of errors the WSJ tagger gave and what types of errors were solved or still unsolved by the adapted taggers .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
We then explored the tagging errors in each domain in order to observe what types of errors the WSJ tagger gave and what types of errors were solved or still unsolved by the adapted taggers .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
We then explored the tagging errors in each domain in order to observe what types of errors the WSJ tagger gave and what types of errors were solved or still unsolved by the adapted taggers .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
We then explored the tagging errors in each domain in order to observe what types of errors the WSJ tagger gave and what types of errors were solved or still unsolved by the adapted taggers .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
We then explored the tagging errors in each domain in order to observe what types of errors the WSJ tagger gave and what types of errors were solved or still unsolved by the adapted taggers .
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
We then explored the tagging errors in each domain in order to observe what types of errors the WSJ tagger gave and what types of errors were solved or still unsolved by the adapted taggers .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
We then explored the tagging errors in each domain in order to observe what types of errors the WSJ tagger gave and what types of errors were solved or still unsolved by the adapted taggers .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
We then explored the tagging errors in each domain in order to observe what types of errors the WSJ tagger gave and what types of errors were solved or still unsolved by the adapted taggers .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
We then explored the tagging errors in each domain in order to observe what types of errors the WSJ tagger gave and what types of errors were solved or still unsolved by the adapted taggers .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
We then explored the tagging errors in each domain in order to observe what types of errors the WSJ tagger gave and what types of errors were solved or still unsolved by the adapted taggers .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
We then explored the tagging errors in each domain in order to observe what types of errors the WSJ tagger gave and what types of errors were solved or still unsolved by the adapted taggers .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
We then explored the tagging errors in each domain in order to observe what types of errors the WSJ tagger gave and what types of errors were solved or still unsolved by the adapted taggers .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
We then explored the tagging errors in each domain in order to observe what types of errors the WSJ tagger gave and what types of errors were solved or still unsolved by the adapted taggers .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
Table \REF , \REF , and \REF show the most frequent tagging errors given by the WSJ tagger / adapted tagger for Brown questions , Brown imperatives , and QuestionBank respectively .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
In the tables , we could find that the major errors of the WSJ tagger for the Brown domains were the mis-tagging to verbs , that is , " VB \SPEC " .
#<struct ReadData::Alignment source_numbers="1", target_numbers="1", tag_name="wa">
In the tables , we could find that the major errors of the WSJ tagger for the Brown domains were the mis-tagging to verbs , that is , " VB \SPEC " .
#<struct ReadData::Alignment source_numbers="6", target_numbers="5", tag_name="wa">
In the tables , we could find that the major errors of the WSJ tagger for the Brown domains were the mis-tagging to verbs , that is , " VB \SPEC " .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
In the tables , we could find that the major errors of the WSJ tagger for the Brown domains were the mis-tagging to verbs , that is , " VB \SPEC " .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
In the tables , we could find that the major errors of the WSJ tagger for the Brown domains were the mis-tagging to verbs , that is , " VB \SPEC " .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
In the tables , we could find that the major errors of the WSJ tagger for the Brown domains were the mis-tagging to verbs , that is , " VB \SPEC " .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
In the tables , we could find that the major errors of the WSJ tagger for the Brown domains were the mis-tagging to verbs , that is , " VB \SPEC " .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
In the tables , we could find that the major errors of the WSJ tagger for the Brown domains were the mis-tagging to verbs , that is , " VB \SPEC " .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
In the tables , we could find that the major errors of the WSJ tagger for the Brown domains were the mis-tagging to verbs , that is , " VB \SPEC " .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
In the tables , we could find that the major errors of the WSJ tagger for the Brown domains were the mis-tagging to verbs , that is , " VB \SPEC " .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
In the tables , we could find that the major errors of the WSJ tagger for the Brown domains were the mis-tagging to verbs , that is , " VB \SPEC " .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
We then analyzed why each of such errors had occurred .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
We then analyzed why each of such errors had occurred .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
These two types of errors would respectively come from the following differences in sentence constructions between WSJ declarative and the Brown imperative sentences .
#<struct ReadData::Alignment source_numbers="19", target_numbers="14", tag_name="wa">
These two types of errors would respectively come from the following differences in sentence constructions between WSJ declarative and the Brown imperative sentences .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
These two types of errors would respectively come from the following differences in sentence constructions between WSJ declarative and the Brown imperative sentences .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
These two types of errors would respectively come from the following differences in sentence constructions between WSJ declarative and the Brown imperative sentences .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Firstly , declarative sentences normally begin with noun phrases while imperative sentences normally begin with verb phrases .
#<struct ReadData::Alignment source_numbers="3", target_numbers="4", tag_name="wa">
Firstly , declarative sentences normally begin with noun phrases while imperative sentences normally begin with verb phrases .
#<struct ReadData::Alignment source_numbers="8", target_numbers="10", tag_name="wa">
Firstly , declarative sentences normally begin with noun phrases while imperative sentences normally begin with verb phrases .
#<struct ReadData::Alignment source_numbers="11", target_numbers="15", tag_name="wa">
Firstly , declarative sentences normally begin with noun phrases while imperative sentences normally begin with verb phrases .
#<struct ReadData::Alignment source_numbers="13,14", target_numbers="17,18", tag_name="wa">
Firstly , declarative sentences normally begin with noun phrases while imperative sentences normally begin with verb phrases .
#<struct ReadData::Alignment source_numbers="15", target_numbers="20", tag_name="wa">
Firstly , declarative sentences normally begin with noun phrases while imperative sentences normally begin with verb phrases .
#<struct ReadData::Alignment source_numbers="16", target_numbers="21", tag_name="wa">
Firstly , declarative sentences normally begin with noun phrases while imperative sentences normally begin with verb phrases .
#<struct ReadData::Alignment source_numbers="17", target_numbers="22", tag_name="wa">
Firstly , declarative sentences normally begin with noun phrases while imperative sentences normally begin with verb phrases .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Firstly , declarative sentences normally begin with noun phrases while imperative sentences normally begin with verb phrases .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Firstly , declarative sentences normally begin with noun phrases while imperative sentences normally begin with verb phrases .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Firstly , declarative sentences normally begin with noun phrases while imperative sentences normally begin with verb phrases .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
Firstly , declarative sentences normally begin with noun phrases while imperative sentences normally begin with verb phrases .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
Firstly , declarative sentences normally begin with noun phrases while imperative sentences normally begin with verb phrases .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Firstly , declarative sentences normally begin with noun phrases while imperative sentences normally begin with verb phrases .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
The WSJ tagger was trained on the domain mainly consisting of declarative sentences , and the training was based on N-gram sequences of words or POSs . The tagger therefore preferred to give noun phrase-derived tags to the beginning of a sentence .
#<struct ReadData::Alignment source_numbers="40", target_numbers="7", tag_name="wa">
The WSJ tagger was trained on the domain mainly consisting of declarative sentences , and the training was based on N-gram sequences of words or POSs . The tagger therefore preferred to give noun phrase-derived tags to the beginning of a sentence .
#<struct ReadData::Alignment source_numbers="17", target_numbers="28", tag_name="wa">
The WSJ tagger was trained on the domain mainly consisting of declarative sentences , and the training was based on N-gram sequences of words or POSs . The tagger therefore preferred to give noun phrase-derived tags to the beginning of a sentence .
#<struct ReadData::Alignment source_numbers="32", target_numbers="29", tag_name="wa">
The WSJ tagger was trained on the domain mainly consisting of declarative sentences , and the training was based on N-gram sequences of words or POSs . The tagger therefore preferred to give noun phrase-derived tags to the beginning of a sentence .
#<struct ReadData::Alignment source_numbers="31", target_numbers="30", tag_name="wa">
The WSJ tagger was trained on the domain mainly consisting of declarative sentences , and the training was based on N-gram sequences of words or POSs . The tagger therefore preferred to give noun phrase-derived tags to the beginning of a sentence .
#<struct ReadData::Alignment source_numbers="37,38,39", target_numbers="34,35,36", tag_name="wa">
The WSJ tagger was trained on the domain mainly consisting of declarative sentences , and the training was based on N-gram sequences of words or POSs . The tagger therefore preferred to give noun phrase-derived tags to the beginning of a sentence .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
The WSJ tagger was trained on the domain mainly consisting of declarative sentences , and the training was based on N-gram sequences of words or POSs . The tagger therefore preferred to give noun phrase-derived tags to the beginning of a sentence .
#<struct ReadData::Alignment source_numbers="26", target_numbers="", tag_name="wa">
The WSJ tagger was trained on the domain mainly consisting of declarative sentences , and the training was based on N-gram sequences of words or POSs . The tagger therefore preferred to give noun phrase-derived tags to the beginning of a sentence .
#<struct ReadData::Alignment source_numbers="27", target_numbers="", tag_name="wa">
The WSJ tagger was trained on the domain mainly consisting of declarative sentences , and the training was based on N-gram sequences of words or POSs . The tagger therefore preferred to give noun phrase-derived tags to the beginning of a sentence .
#<struct ReadData::Alignment source_numbers="28", target_numbers="", tag_name="wa">
The WSJ tagger was trained on the domain mainly consisting of declarative sentences , and the training was based on N-gram sequences of words or POSs . The tagger therefore preferred to give noun phrase-derived tags to the beginning of a sentence .
#<struct ReadData::Alignment source_numbers="30", target_numbers="", tag_name="wa">
The WSJ tagger was trained on the domain mainly consisting of declarative sentences , and the training was based on N-gram sequences of words or POSs . The tagger therefore preferred to give noun phrase-derived tags to the beginning of a sentence .
#<struct ReadData::Alignment source_numbers="36", target_numbers="", tag_name="wa">
The WSJ tagger was trained on the domain mainly consisting of declarative sentences , and the training was based on N-gram sequences of words or POSs . The tagger therefore preferred to give noun phrase-derived tags to the beginning of a sentence .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
The WSJ tagger was trained on the domain mainly consisting of declarative sentences , and the training was based on N-gram sequences of words or POSs . The tagger therefore preferred to give noun phrase-derived tags to the beginning of a sentence .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
The WSJ tagger was trained on the domain mainly consisting of declarative sentences , and the training was based on N-gram sequences of words or POSs . The tagger therefore preferred to give noun phrase-derived tags to the beginning of a sentence .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
The WSJ tagger was trained on the domain mainly consisting of declarative sentences , and the training was based on N-gram sequences of words or POSs . The tagger therefore preferred to give noun phrase-derived tags to the beginning of a sentence .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
Secondly , main verbs in imperative sentences take base forms while main verbs in declarative sentences take the forms according to tense .
#<struct ReadData::Alignment source_numbers="17", target_numbers="2", tag_name="wa">
Secondly , main verbs in imperative sentences take base forms while main verbs in declarative sentences take the forms according to tense .
#<struct ReadData::Alignment source_numbers="9", target_numbers="12", tag_name="wa">
Secondly , main verbs in imperative sentences take base forms while main verbs in declarative sentences take the forms according to tense .
#<struct ReadData::Alignment source_numbers="15", target_numbers="21", tag_name="wa">
Secondly , main verbs in imperative sentences take base forms while main verbs in declarative sentences take the forms according to tense .
#<struct ReadData::Alignment source_numbers="22", target_numbers="28", tag_name="wa">
Secondly , main verbs in imperative sentences take base forms while main verbs in declarative sentences take the forms according to tense .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Secondly , main verbs in imperative sentences take base forms while main verbs in declarative sentences take the forms according to tense .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
Secondly , main verbs in imperative sentences take base forms while main verbs in declarative sentences take the forms according to tense .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
Secondly , main verbs in imperative sentences take base forms while main verbs in declarative sentences take the forms according to tense .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Secondly , main verbs in imperative sentences take base forms while main verbs in declarative sentences take the forms according to tense .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Secondly , main verbs in imperative sentences take base forms while main verbs in declarative sentences take the forms according to tense .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Secondly , main verbs in imperative sentences take base forms while main verbs in declarative sentences take the forms according to tense .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
Secondly , main verbs in imperative sentences take base forms while main verbs in declarative sentences take the forms according to tense .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
Secondly , main verbs in imperative sentences take base forms while main verbs in declarative sentences take the forms according to tense .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
Secondly , main verbs in imperative sentences take base forms while main verbs in declarative sentences take the forms according to tense .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
The problem is that , for present tense except for third person singular , verbs in the declarative sentences always take the same appearances as the base forms , while the tags are different : VBP and VB .
#<struct ReadData::Alignment source_numbers="15", target_numbers="3", tag_name="wa">
The problem is that , for present tense except for third person singular , verbs in the declarative sentences always take the same appearances as the base forms , while the tags are different : VBP and VB .
#<struct ReadData::Alignment source_numbers="3", target_numbers="4", tag_name="wa">
The problem is that , for present tense except for third person singular , verbs in the declarative sentences always take the same appearances as the base forms , while the tags are different : VBP and VB .
#<struct ReadData::Alignment source_numbers="16", target_numbers="7", tag_name="wa">
The problem is that , for present tense except for third person singular , verbs in the declarative sentences always take the same appearances as the base forms , while the tags are different : VBP and VB .
#<struct ReadData::Alignment source_numbers="28", target_numbers="10", tag_name="wa">
The problem is that , for present tense except for third person singular , verbs in the declarative sentences always take the same appearances as the base forms , while the tags are different : VBP and VB .
#<struct ReadData::Alignment source_numbers="30", target_numbers="17", tag_name="wa">
The problem is that , for present tense except for third person singular , verbs in the declarative sentences always take the same appearances as the base forms , while the tags are different : VBP and VB .
#<struct ReadData::Alignment source_numbers="34", target_numbers="38", tag_name="wa">
The problem is that , for present tense except for third person singular , verbs in the declarative sentences always take the same appearances as the base forms , while the tags are different : VBP and VB .
#<struct ReadData::Alignment source_numbers="38", target_numbers="44", tag_name="wa">
The problem is that , for present tense except for third person singular , verbs in the declarative sentences always take the same appearances as the base forms , while the tags are different : VBP and VB .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
The problem is that , for present tense except for third person singular , verbs in the declarative sentences always take the same appearances as the base forms , while the tags are different : VBP and VB .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
The problem is that , for present tense except for third person singular , verbs in the declarative sentences always take the same appearances as the base forms , while the tags are different : VBP and VB .
#<struct ReadData::Alignment source_numbers="29", target_numbers="", tag_name="wa">
The problem is that , for present tense except for third person singular , verbs in the declarative sentences always take the same appearances as the base forms , while the tags are different : VBP and VB .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
The problem is that , for present tense except for third person singular , verbs in the declarative sentences always take the same appearances as the base forms , while the tags are different : VBP and VB .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
The problem is that , for present tense except for third person singular , verbs in the declarative sentences always take the same appearances as the base forms , while the tags are different : VBP and VB .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
The problem is that , for present tense except for third person singular , verbs in the declarative sentences always take the same appearances as the base forms , while the tags are different : VBP and VB .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
The problem is that , for present tense except for third person singular , verbs in the declarative sentences always take the same appearances as the base forms , while the tags are different : VBP and VB .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
The problem is that , for present tense except for third person singular , verbs in the declarative sentences always take the same appearances as the base forms , while the tags are different : VBP and VB .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
The problem is that , for present tense except for third person singular , verbs in the declarative sentences always take the same appearances as the base forms , while the tags are different : VBP and VB .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
The problem is that , for present tense except for third person singular , verbs in the declarative sentences always take the same appearances as the base forms , while the tags are different : VBP and VB .
#<struct ReadData::Alignment source_numbers="", target_numbers="42", tag_name="wa">
The WSJ tagger mainly based on declarative sentences therefore prefer to give VBP tags to main verbs .
#<struct ReadData::Alignment source_numbers="4", target_numbers="6", tag_name="wa">
The WSJ tagger mainly based on declarative sentences therefore prefer to give VBP tags to main verbs .
#<struct ReadData::Alignment source_numbers="9", target_numbers="11,12", tag_name="wa">
The WSJ tagger mainly based on declarative sentences therefore prefer to give VBP tags to main verbs .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
The WSJ tagger mainly based on declarative sentences therefore prefer to give VBP tags to main verbs .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
The WSJ tagger mainly based on declarative sentences therefore prefer to give VBP tags to main verbs .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
The WSJ tagger mainly based on declarative sentences therefore prefer to give VBP tags to main verbs .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
The WSJ tagger mainly based on declarative sentences therefore prefer to give VBP tags to main verbs .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
The WSJ tagger mainly based on declarative sentences therefore prefer to give VBP tags to main verbs .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
After adapting the tagger to Brown imperatives , the N-gram model of tagger would have learned that the first word in a sentence tends to be a verb , and the main verb tends to take base form ( VB ) .
#<struct ReadData::Alignment source_numbers="30", target_numbers="12", tag_name="wa">
After adapting the tagger to Brown imperatives , the N-gram model of tagger would have learned that the first word in a sentence tends to be a verb , and the main verb tends to take base form ( VB ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
Table \REF shows that the above two types of errors did decrease to some extent . However , we can also observe that not a few mis-tags to verbs were still left after the adaptation .
#<struct ReadData::Alignment source_numbers="11", target_numbers="12", tag_name="wa">
Table \REF shows that the above two types of errors did decrease to some extent . However , we can also observe that not a few mis-tags to verbs were still left after the adaptation .
#<struct ReadData::Alignment source_numbers="24", target_numbers="18", tag_name="wa">
Table \REF shows that the above two types of errors did decrease to some extent . However , we can also observe that not a few mis-tags to verbs were still left after the adaptation .
#<struct ReadData::Alignment source_numbers="25", target_numbers="19", tag_name="wa">
Table \REF shows that the above two types of errors did decrease to some extent . However , we can also observe that not a few mis-tags to verbs were still left after the adaptation .
#<struct ReadData::Alignment source_numbers="15", target_numbers="25", tag_name="wa">
Table \REF shows that the above two types of errors did decrease to some extent . However , we can also observe that not a few mis-tags to verbs were still left after the adaptation .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Table \REF shows that the above two types of errors did decrease to some extent . However , we can also observe that not a few mis-tags to verbs were still left after the adaptation .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
Table \REF shows that the above two types of errors did decrease to some extent . However , we can also observe that not a few mis-tags to verbs were still left after the adaptation .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
Table \REF shows that the above two types of errors did decrease to some extent . However , we can also observe that not a few mis-tags to verbs were still left after the adaptation .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
Table \REF shows that the above two types of errors did decrease to some extent . However , we can also observe that not a few mis-tags to verbs were still left after the adaptation .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
Table \REF shows that the above two types of errors did decrease to some extent . However , we can also observe that not a few mis-tags to verbs were still left after the adaptation .
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
Table \REF shows that the above two types of errors did decrease to some extent . However , we can also observe that not a few mis-tags to verbs were still left after the adaptation .
#<struct ReadData::Alignment source_numbers="26", target_numbers="", tag_name="wa">
Table \REF shows that the above two types of errors did decrease to some extent . However , we can also observe that not a few mis-tags to verbs were still left after the adaptation .
#<struct ReadData::Alignment source_numbers="27", target_numbers="", tag_name="wa">
Table \REF shows that the above two types of errors did decrease to some extent . However , we can also observe that not a few mis-tags to verbs were still left after the adaptation .
#<struct ReadData::Alignment source_numbers="29", target_numbers="", tag_name="wa">
Table \REF shows that the above two types of errors did decrease to some extent . However , we can also observe that not a few mis-tags to verbs were still left after the adaptation .
#<struct ReadData::Alignment source_numbers="31", target_numbers="", tag_name="wa">
Table \REF shows that the above two types of errors did decrease to some extent . However , we can also observe that not a few mis-tags to verbs were still left after the adaptation .
#<struct ReadData::Alignment source_numbers="33", target_numbers="", tag_name="wa">
Table \REF shows that the above two types of errors did decrease to some extent . However , we can also observe that not a few mis-tags to verbs were still left after the adaptation .
#<struct ReadData::Alignment source_numbers="35", target_numbers="", tag_name="wa">
Table \REF shows that the above two types of errors did decrease to some extent . However , we can also observe that not a few mis-tags to verbs were still left after the adaptation .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Table \REF shows that the above two types of errors did decrease to some extent . However , we can also observe that not a few mis-tags to verbs were still left after the adaptation .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
Table \REF shows that the above two types of errors did decrease to some extent . However , we can also observe that not a few mis-tags to verbs were still left after the adaptation .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
Table \REF shows that the above two types of errors did decrease to some extent . However , we can also observe that not a few mis-tags to verbs were still left after the adaptation .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
When we observe each of the left errors around VB , we found that several errors still occurred even in simple imperative sentences such as " VB \SPEC NN " for " Charge " in " Charge something for it . " , and that some errors tended to occur after to-infinitive phrase or conjunction , such as " VB \SPEC NN " for " subtract " in " To find estimated net farm income , subtract . . . "
#<struct ReadData::Alignment source_numbers="40", target_numbers="80", tag_name="wa">
When we observe each of the left errors around VB , we found that several errors still occurred even in simple imperative sentences such as " VB \SPEC NN " for " Charge " in " Charge something for it . " , and that some errors tended to occur after to-infinitive phrase or conjunction , such as " VB \SPEC NN " for " subtract " in " To find estimated net farm income , subtract . . . "
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
When we observe each of the left errors around VB , we found that several errors still occurred even in simple imperative sentences such as " VB \SPEC NN " for " Charge " in " Charge something for it . " , and that some errors tended to occur after to-infinitive phrase or conjunction , such as " VB \SPEC NN " for " subtract " in " To find estimated net farm income , subtract . . . "
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
When we observe each of the left errors around VB , we found that several errors still occurred even in simple imperative sentences such as " VB \SPEC NN " for " Charge " in " Charge something for it . " , and that some errors tended to occur after to-infinitive phrase or conjunction , such as " VB \SPEC NN " for " subtract " in " To find estimated net farm income , subtract . . . "
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
When we observe each of the left errors around VB , we found that several errors still occurred even in simple imperative sentences such as " VB \SPEC NN " for " Charge " in " Charge something for it . " , and that some errors tended to occur after to-infinitive phrase or conjunction , such as " VB \SPEC NN " for " subtract " in " To find estimated net farm income , subtract . . . "
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
When we observe each of the left errors around VB , we found that several errors still occurred even in simple imperative sentences such as " VB \SPEC NN " for " Charge " in " Charge something for it . " , and that some errors tended to occur after to-infinitive phrase or conjunction , such as " VB \SPEC NN " for " subtract " in " To find estimated net farm income , subtract . . . "
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
When we observe each of the left errors around VB , we found that several errors still occurred even in simple imperative sentences such as " VB \SPEC NN " for " Charge " in " Charge something for it . " , and that some errors tended to occur after to-infinitive phrase or conjunction , such as " VB \SPEC NN " for " subtract " in " To find estimated net farm income , subtract . . . "
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
When we observe each of the left errors around VB , we found that several errors still occurred even in simple imperative sentences such as " VB \SPEC NN " for " Charge " in " Charge something for it . " , and that some errors tended to occur after to-infinitive phrase or conjunction , such as " VB \SPEC NN " for " subtract " in " To find estimated net farm income , subtract . . . "
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
When we observe each of the left errors around VB , we found that several errors still occurred even in simple imperative sentences such as " VB \SPEC NN " for " Charge " in " Charge something for it . " , and that some errors tended to occur after to-infinitive phrase or conjunction , such as " VB \SPEC NN " for " subtract " in " To find estimated net farm income , subtract . . . "
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
When we observe each of the left errors around VB , we found that several errors still occurred even in simple imperative sentences such as " VB \SPEC NN " for " Charge " in " Charge something for it . " , and that some errors tended to occur after to-infinitive phrase or conjunction , such as " VB \SPEC NN " for " subtract " in " To find estimated net farm income , subtract . . . "
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
When we observe each of the left errors around VB , we found that several errors still occurred even in simple imperative sentences such as " VB \SPEC NN " for " Charge " in " Charge something for it . " , and that some errors tended to occur after to-infinitive phrase or conjunction , such as " VB \SPEC NN " for " subtract " in " To find estimated net farm income , subtract . . . "
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
When we observe each of the left errors around VB , we found that several errors still occurred even in simple imperative sentences such as " VB \SPEC NN " for " Charge " in " Charge something for it . " , and that some errors tended to occur after to-infinitive phrase or conjunction , such as " VB \SPEC NN " for " subtract " in " To find estimated net farm income , subtract . . . "
#<struct ReadData::Alignment source_numbers="", target_numbers="48", tag_name="wa">
The former type of errors might be solved by increasing the training data , while the latter type of errors would not be easily solved with the model based on word N-gram which cannot detect the existence of long phrases .
#<struct ReadData::Alignment source_numbers="5,6", target_numbers="3", tag_name="wa">
The former type of errors might be solved by increasing the training data , while the latter type of errors would not be easily solved with the model based on word N-gram which cannot detect the existence of long phrases .
#<struct ReadData::Alignment source_numbers="22", target_numbers="4", tag_name="wa">
The former type of errors might be solved by increasing the training data , while the latter type of errors would not be easily solved with the model based on word N-gram which cannot detect the existence of long phrases .
#<struct ReadData::Alignment source_numbers="3,4", target_numbers="15", tag_name="wa">
The former type of errors might be solved by increasing the training data , while the latter type of errors would not be easily solved with the model based on word N-gram which cannot detect the existence of long phrases .
#<struct ReadData::Alignment source_numbers="17", target_numbers="16", tag_name="wa">
The former type of errors might be solved by increasing the training data , while the latter type of errors would not be easily solved with the model based on word N-gram which cannot detect the existence of long phrases .
#<struct ReadData::Alignment source_numbers="33", target_numbers="17", tag_name="wa">
The former type of errors might be solved by increasing the training data , while the latter type of errors would not be easily solved with the model based on word N-gram which cannot detect the existence of long phrases .
#<struct ReadData::Alignment source_numbers="26,27", target_numbers="22,23", tag_name="wa">
The former type of errors might be solved by increasing the training data , while the latter type of errors would not be easily solved with the model based on word N-gram which cannot detect the existence of long phrases .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
The former type of errors might be solved by increasing the training data , while the latter type of errors would not be easily solved with the model based on word N-gram which cannot detect the existence of long phrases .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
The former type of errors might be solved by increasing the training data , while the latter type of errors would not be easily solved with the model based on word N-gram which cannot detect the existence of long phrases .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
The former type of errors might be solved by increasing the training data , while the latter type of errors would not be easily solved with the model based on word N-gram which cannot detect the existence of long phrases .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
The former type of errors might be solved by increasing the training data , while the latter type of errors would not be easily solved with the model based on word N-gram which cannot detect the existence of long phrases .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
The former type of errors might be solved by increasing the training data , while the latter type of errors would not be easily solved with the model based on word N-gram which cannot detect the existence of long phrases .
#<struct ReadData::Alignment source_numbers="32", target_numbers="", tag_name="wa">
The former type of errors might be solved by increasing the training data , while the latter type of errors would not be easily solved with the model based on word N-gram which cannot detect the existence of long phrases .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
The former type of errors might be solved by increasing the training data , while the latter type of errors would not be easily solved with the model based on word N-gram which cannot detect the existence of long phrases .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
The former type of errors might be solved by increasing the training data , while the latter type of errors would not be easily solved with the model based on word N-gram which cannot detect the existence of long phrases .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
The former type of errors might be solved by increasing the training data , while the latter type of errors would not be easily solved with the model based on word N-gram which cannot detect the existence of long phrases .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
We also analyzed the errors in Brown questions and QuestionBank , and again found that the WSJ tagger seems to make many errors due to the fact that the tagger was trained on a corpus mainly consisting of declarative sentences .
#<struct ReadData::Alignment source_numbers="40", target_numbers="36", tag_name="wa">
We also analyzed the errors in Brown questions and QuestionBank , and again found that the WSJ tagger seems to make many errors due to the fact that the tagger was trained on a corpus mainly consisting of declarative sentences .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
We also analyzed the errors in Brown questions and QuestionBank , and again found that the WSJ tagger seems to make many errors due to the fact that the tagger was trained on a corpus mainly consisting of declarative sentences .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
We also analyzed the errors in Brown questions and QuestionBank , and again found that the WSJ tagger seems to make many errors due to the fact that the tagger was trained on a corpus mainly consisting of declarative sentences .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
We also analyzed the errors in Brown questions and QuestionBank , and again found that the WSJ tagger seems to make many errors due to the fact that the tagger was trained on a corpus mainly consisting of declarative sentences .
#<struct ReadData::Alignment source_numbers="28", target_numbers="", tag_name="wa">
We also analyzed the errors in Brown questions and QuestionBank , and again found that the WSJ tagger seems to make many errors due to the fact that the tagger was trained on a corpus mainly consisting of declarative sentences .
#<struct ReadData::Alignment source_numbers="29", target_numbers="", tag_name="wa">
After the adaptation , while some of the errors such as special usage of wh-words , i.e. , " WDT \SPEC WP " , were corrected , we found that some kinds or errors related to the global change of sentence structures still remained .
#<struct ReadData::Alignment source_numbers="36", target_numbers="11", tag_name="wa">
After the adaptation , while some of the errors such as special usage of wh-words , i.e. , " WDT \SPEC WP " , were corrected , we found that some kinds or errors related to the global change of sentence structures still remained .
#<struct ReadData::Alignment source_numbers="12,13", target_numbers="13", tag_name="wa">
After the adaptation , while some of the errors such as special usage of wh-words , i.e. , " WDT \SPEC WP " , were corrected , we found that some kinds or errors related to the global change of sentence structures still remained .
#<struct ReadData::Alignment source_numbers="39", target_numbers="14", tag_name="wa">
After the adaptation , while some of the errors such as special usage of wh-words , i.e. , " WDT \SPEC WP " , were corrected , we found that some kinds or errors related to the global change of sentence structures still remained .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
After the adaptation , while some of the errors such as special usage of wh-words , i.e. , " WDT \SPEC WP " , were corrected , we found that some kinds or errors related to the global change of sentence structures still remained .
#<struct ReadData::Alignment source_numbers="27", target_numbers="", tag_name="wa">
After the adaptation , while some of the errors such as special usage of wh-words , i.e. , " WDT \SPEC WP " , were corrected , we found that some kinds or errors related to the global change of sentence structures still remained .
#<struct ReadData::Alignment source_numbers="28", target_numbers="", tag_name="wa">
After the adaptation , while some of the errors such as special usage of wh-words , i.e. , " WDT \SPEC WP " , were corrected , we found that some kinds or errors related to the global change of sentence structures still remained .
#<struct ReadData::Alignment source_numbers="29", target_numbers="", tag_name="wa">
After the adaptation , while some of the errors such as special usage of wh-words , i.e. , " WDT \SPEC WP " , were corrected , we found that some kinds or errors related to the global change of sentence structures still remained .
#<struct ReadData::Alignment source_numbers="30", target_numbers="", tag_name="wa">
After the adaptation , while some of the errors such as special usage of wh-words , i.e. , " WDT \SPEC WP " , were corrected , we found that some kinds or errors related to the global change of sentence structures still remained .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
After the adaptation , while some of the errors such as special usage of wh-words , i.e. , " WDT \SPEC WP " , were corrected , we found that some kinds or errors related to the global change of sentence structures still remained .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
After the adaptation , while some of the errors such as special usage of wh-words , i.e. , " WDT \SPEC WP " , were corrected , we found that some kinds or errors related to the global change of sentence structures still remained .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
After the adaptation , while some of the errors such as special usage of wh-words , i.e. , " WDT \SPEC WP " , were corrected , we found that some kinds or errors related to the global change of sentence structures still remained .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
In order to give correct tags to words both in imperatives and questions , we might have to consider richer information than only N-gram based features , such as long distance dependencies or phrases .
#<struct ReadData::Alignment source_numbers="7", target_numbers="2", tag_name="wa">
In order to give correct tags to words both in imperatives and questions , we might have to consider richer information than only N-gram based features , such as long distance dependencies or phrases .
#<struct ReadData::Alignment source_numbers="13", target_numbers="9", tag_name="wa">
In order to give correct tags to words both in imperatives and questions , we might have to consider richer information than only N-gram based features , such as long distance dependencies or phrases .
#<struct ReadData::Alignment source_numbers="15,16", target_numbers="11,12", tag_name="wa">
In order to give correct tags to words both in imperatives and questions , we might have to consider richer information than only N-gram based features , such as long distance dependencies or phrases .
#<struct ReadData::Alignment source_numbers="26", target_numbers="22", tag_name="wa">
In order to give correct tags to words both in imperatives and questions , we might have to consider richer information than only N-gram based features , such as long distance dependencies or phrases .
#<struct ReadData::Alignment source_numbers="34", target_numbers="30", tag_name="wa">
In order to give correct tags to words both in imperatives and questions , we might have to consider richer information than only N-gram based features , such as long distance dependencies or phrases .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
In order to give correct tags to words both in imperatives and questions , we might have to consider richer information than only N-gram based features , such as long distance dependencies or phrases .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
In order to give correct tags to words both in imperatives and questions , we might have to consider richer information than only N-gram based features , such as long distance dependencies or phrases .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
In order to give correct tags to words both in imperatives and questions , we might have to consider richer information than only N-gram based features , such as long distance dependencies or phrases .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
In order to give correct tags to words both in imperatives and questions , we might have to consider richer information than only N-gram based features , such as long distance dependencies or phrases .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
In order to give correct tags to words both in imperatives and questions , we might have to consider richer information than only N-gram based features , such as long distance dependencies or phrases .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
In order to give correct tags to words both in imperatives and questions , we might have to consider richer information than only N-gram based features , such as long distance dependencies or phrases .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
In order to give correct tags to words both in imperatives and questions , we might have to consider richer information than only N-gram based features , such as long distance dependencies or phrases .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
In order to give correct tags to words both in imperatives and questions , we might have to consider richer information than only N-gram based features , such as long distance dependencies or phrases .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
In order to give correct tags to words both in imperatives and questions , we might have to consider richer information than only N-gram based features , such as long distance dependencies or phrases .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Table \REF shows the parsing accuracies of MST( first order ) , MST( second order ) , Malt , and Enju parser for WSJ , Brown overall , Brown imperatives and Brown questions .
#<struct ReadData::Alignment source_numbers="33", target_numbers="37", tag_name="wa">
Table \REF shows the parsing accuracies of MST( first order ) , MST( second order ) , Malt , and Enju parser for WSJ , Brown overall , Brown imperatives and Brown questions .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Table \REF shows the parsing accuracies of MST( first order ) , MST( second order ) , Malt , and Enju parser for WSJ , Brown overall , Brown imperatives and Brown questions .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Table \REF shows the parsing accuracies of MST( first order ) , MST( second order ) , Malt , and Enju parser for WSJ , Brown overall , Brown imperatives and Brown questions .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
Table \REF shows the parsing accuracies of MST( first order ) , MST( second order ) , Malt , and Enju parser for WSJ , Brown overall , Brown imperatives and Brown questions .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Table \REF shows the parsing accuracies of MST( first order ) , MST( second order ) , Malt , and Enju parser for WSJ , Brown overall , Brown imperatives and Brown questions .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Table \REF shows the parsing accuracies of MST( first order ) , MST( second order ) , Malt , and Enju parser for WSJ , Brown overall , Brown imperatives and Brown questions .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Table \REF shows the parsing accuracies of MST( first order ) , MST( second order ) , Malt , and Enju parser for WSJ , Brown overall , Brown imperatives and Brown questions .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Table \REF shows the parsing accuracies of MST( first order ) , MST( second order ) , Malt , and Enju parser for WSJ , Brown overall , Brown imperatives and Brown questions .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Table \REF shows the parsing accuracies of MST( first order ) , MST( second order ) , Malt , and Enju parser for WSJ , Brown overall , Brown imperatives and Brown questions .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
Figure \REF shows the parsing accuracies against the training data size of the four parsers for WSJ , Brown imperatives , Brown questions , and QuestionBank .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Figure \REF shows the parsing accuracies against the training data size of the four parsers for WSJ , Brown imperatives , Brown questions , and QuestionBank .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Note that , since training MST parser ( second order ) on Brown overall , Brown questions , and QuestionBank could not be completed in our experimental environments , the parsing accuracies represented by the bracketed hyphens in Table \REF could not be measured and we could not draw full graphs of second order MST for Brown questions and QuestionBank in Figure \REF .
#<struct ReadData::Alignment source_numbers="29", target_numbers="4", tag_name="wa">
Note that , since training MST parser ( second order ) on Brown overall , Brown questions , and QuestionBank could not be completed in our experimental environments , the parsing accuracies represented by the bracketed hyphens in Table \REF could not be measured and we could not draw full graphs of second order MST for Brown questions and QuestionBank in Figure \REF .
#<struct ReadData::Alignment source_numbers="51", target_numbers="6", tag_name="wa">
Note that , since training MST parser ( second order ) on Brown overall , Brown questions , and QuestionBank could not be completed in our experimental environments , the parsing accuracies represented by the bracketed hyphens in Table \REF could not be measured and we could not draw full graphs of second order MST for Brown questions and QuestionBank in Figure \REF .
#<struct ReadData::Alignment source_numbers="34", target_numbers="7", tag_name="wa">
Note that , since training MST parser ( second order ) on Brown overall , Brown questions , and QuestionBank could not be completed in our experimental environments , the parsing accuracies represented by the bracketed hyphens in Table \REF could not be measured and we could not draw full graphs of second order MST for Brown questions and QuestionBank in Figure \REF .
#<struct ReadData::Alignment source_numbers="63", target_numbers="68", tag_name="wa">
Note that , since training MST parser ( second order ) on Brown overall , Brown questions , and QuestionBank could not be completed in our experimental environments , the parsing accuracies represented by the bracketed hyphens in Table \REF could not be measured and we could not draw full graphs of second order MST for Brown questions and QuestionBank in Figure \REF .
#<struct ReadData::Alignment source_numbers="32", target_numbers="", tag_name="wa">
Note that , since training MST parser ( second order ) on Brown overall , Brown questions , and QuestionBank could not be completed in our experimental environments , the parsing accuracies represented by the bracketed hyphens in Table \REF could not be measured and we could not draw full graphs of second order MST for Brown questions and QuestionBank in Figure \REF .
#<struct ReadData::Alignment source_numbers="44", target_numbers="", tag_name="wa">
Note that , since training MST parser ( second order ) on Brown overall , Brown questions , and QuestionBank could not be completed in our experimental environments , the parsing accuracies represented by the bracketed hyphens in Table \REF could not be measured and we could not draw full graphs of second order MST for Brown questions and QuestionBank in Figure \REF .
#<struct ReadData::Alignment source_numbers="48", target_numbers="", tag_name="wa">
Note that , since training MST parser ( second order ) on Brown overall , Brown questions , and QuestionBank could not be completed in our experimental environments , the parsing accuracies represented by the bracketed hyphens in Table \REF could not be measured and we could not draw full graphs of second order MST for Brown questions and QuestionBank in Figure \REF .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
Note that , since training MST parser ( second order ) on Brown overall , Brown questions , and QuestionBank could not be completed in our experimental environments , the parsing accuracies represented by the bracketed hyphens in Table \REF could not be measured and we could not draw full graphs of second order MST for Brown questions and QuestionBank in Figure \REF .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
Note that , since training MST parser ( second order ) on Brown overall , Brown questions , and QuestionBank could not be completed in our experimental environments , the parsing accuracies represented by the bracketed hyphens in Table \REF could not be measured and we could not draw full graphs of second order MST for Brown questions and QuestionBank in Figure \REF .
#<struct ReadData::Alignment source_numbers="", target_numbers="47", tag_name="wa">
Note that , since training MST parser ( second order ) on Brown overall , Brown questions , and QuestionBank could not be completed in our experimental environments , the parsing accuracies represented by the bracketed hyphens in Table \REF could not be measured and we could not draw full graphs of second order MST for Brown questions and QuestionBank in Figure \REF .
#<struct ReadData::Alignment source_numbers="", target_numbers="48", tag_name="wa">
Note that , since training MST parser ( second order ) on Brown overall , Brown questions , and QuestionBank could not be completed in our experimental environments , the parsing accuracies represented by the bracketed hyphens in Table \REF could not be measured and we could not draw full graphs of second order MST for Brown questions and QuestionBank in Figure \REF .
#<struct ReadData::Alignment source_numbers="", target_numbers="49", tag_name="wa">
Note that , since training MST parser ( second order ) on Brown overall , Brown questions , and QuestionBank could not be completed in our experimental environments , the parsing accuracies represented by the bracketed hyphens in Table \REF could not be measured and we could not draw full graphs of second order MST for Brown questions and QuestionBank in Figure \REF .
#<struct ReadData::Alignment source_numbers="", target_numbers="53", tag_name="wa">
Note that , since training MST parser ( second order ) on Brown overall , Brown questions , and QuestionBank could not be completed in our experimental environments , the parsing accuracies represented by the bracketed hyphens in Table \REF could not be measured and we could not draw full graphs of second order MST for Brown questions and QuestionBank in Figure \REF .
#<struct ReadData::Alignment source_numbers="", target_numbers="56", tag_name="wa">
When we adapted the parser model ( see fifth column in Table \REF ) , the parser could give two to four points higher accuracies for each of the Brown domains than the WSJ parser .
#<struct ReadData::Alignment source_numbers="6", target_numbers="2", tag_name="wa">
When we adapted the parser model ( see fifth column in Table \REF ) , the parser could give two to four points higher accuracies for each of the Brown domains than the WSJ parser .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
When we adapted the parser model ( see fifth column in Table \REF ) , the parser could give two to four points higher accuracies for each of the Brown domains than the WSJ parser .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
When we adapted the parser model ( see fifth column in Table \REF ) , the parser could give two to four points higher accuracies for each of the Brown domains than the WSJ parser .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
When we adapted the parser model ( see fifth column in Table \REF ) , the parser could give two to four points higher accuracies for each of the Brown domains than the WSJ parser .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
When we adapted the parser model ( see fifth column in Table \REF ) , the parser could give two to four points higher accuracies for each of the Brown domains than the WSJ parser .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
When we adapted the parser model ( see fifth column in Table \REF ) , the parser could give two to four points higher accuracies for each of the Brown domains than the WSJ parser .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
When we adapted the parser model ( see fifth column in Table \REF ) , the parser could give two to four points higher accuracies for each of the Brown domains than the WSJ parser .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
When we adapted the parser model ( see fifth column in Table \REF ) , the parser could give two to four points higher accuracies for each of the Brown domains than the WSJ parser .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
When we adapted the parser model ( see fifth column in Table \REF ) , the parser could give two to four points higher accuracies for each of the Brown domains than the WSJ parser .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
When we adapted the parser model ( see fifth column in Table \REF ) , the parser could give two to four points higher accuracies for each of the Brown domains than the WSJ parser .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
When we adapted the parser model ( see fifth column in Table \REF ) , the parser could give two to four points higher accuracies for each of the Brown domains than the WSJ parser .
#<struct ReadData::Alignment source_numbers="31", target_numbers="", tag_name="wa">
When we adapted the parser model ( see fifth column in Table \REF ) , the parser could give two to four points higher accuracies for each of the Brown domains than the WSJ parser .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
When we adapted the parser model ( see fifth column in Table \REF ) , the parser could give two to four points higher accuracies for each of the Brown domains than the WSJ parser .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
When we adapted the parser model ( see fifth column in Table \REF ) , the parser could give two to four points higher accuracies for each of the Brown domains than the WSJ parser .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
When we adapted the parser model ( see fifth column in Table \REF ) , the parser could give two to four points higher accuracies for each of the Brown domains than the WSJ parser .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
When we adapted the parser model ( see fifth column in Table \REF ) , the parser could give two to four points higher accuracies for each of the Brown domains than the WSJ parser .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
When we adapted the parser model ( see fifth column in Table \REF ) , the parser could give two to four points higher accuracies for each of the Brown domains than the WSJ parser .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
When we adapted the parser model ( see fifth column in Table \REF ) , the parser could give two to four points higher accuracies for each of the Brown domains than the WSJ parser .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
When we adapted the parser model ( see fifth column in Table \REF ) , the parser could give two to four points higher accuracies for each of the Brown domains than the WSJ parser .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
When we adapted the parser model ( see fifth column in Table \REF ) , the parser could give two to four points higher accuracies for each of the Brown domains than the WSJ parser .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
For the QuestionBank , 25 to 35 points accuracy improvements were observed .
#<struct ReadData::Alignment source_numbers="8", target_numbers="9", tag_name="wa">
For the QuestionBank , 25 to 35 points accuracy improvements were observed .
#<struct ReadData::Alignment source_numbers="10,11", target_numbers="10,11", tag_name="wa">
For the QuestionBank , 25 to 35 points accuracy improvements were observed .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
For the QuestionBank , 25 to 35 points accuracy improvements were observed .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
For the QuestionBank , 25 to 35 points accuracy improvements were observed .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
For the QuestionBank , 25 to 35 points accuracy improvements were observed .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
For the QuestionBank , 25 to 35 points accuracy improvements were observed .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
For the QuestionBank , 25 to 35 points accuracy improvements were observed .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Figure \REF shows that , the improvements increased according to the size of the training data , and the tendencies would not seem to converge .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
Figure \REF shows that , the improvements increased according to the size of the training data , and the tendencies would not seem to converge .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Figure \REF shows that , the improvements increased according to the size of the training data , and the tendencies would not seem to converge .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Figure \REF shows that , the improvements increased according to the size of the training data , and the tendencies would not seem to converge .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
Figure \REF shows that , the improvements increased according to the size of the training data , and the tendencies would not seem to converge .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
Figure \REF shows that , the improvements increased according to the size of the training data , and the tendencies would not seem to converge .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
Figure \REF shows that , the improvements increased according to the size of the training data , and the tendencies would not seem to converge .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
Figure \REF shows that , the improvements increased according to the size of the training data , and the tendencies would not seem to converge .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Figure \REF shows that , the improvements increased according to the size of the training data , and the tendencies would not seem to converge .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Figure \REF shows that , the improvements increased according to the size of the training data , and the tendencies would not seem to converge .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Figure \REF shows that , the improvements increased according to the size of the training data , and the tendencies would not seem to converge .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
Figure \REF shows that , the improvements increased according to the size of the training data , and the tendencies would not seem to converge .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
This would suggest that lower accuracies than the WSJ parser for WSJ would be still brought by the lack of training data .
#<struct ReadData::Alignment source_numbers="19", target_numbers="8", tag_name="wa">
This would suggest that lower accuracies than the WSJ parser for WSJ would be still brought by the lack of training data .
#<struct ReadData::Alignment source_numbers="17", target_numbers="13", tag_name="wa">
This would suggest that lower accuracies than the WSJ parser for WSJ would be still brought by the lack of training data .
#<struct ReadData::Alignment source_numbers="13", target_numbers="17", tag_name="wa">
This would suggest that lower accuracies than the WSJ parser for WSJ would be still brought by the lack of training data .
#<struct ReadData::Alignment source_numbers="22", target_numbers="27", tag_name="wa">
This would suggest that lower accuracies than the WSJ parser for WSJ would be still brought by the lack of training data .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
This would suggest that lower accuracies than the WSJ parser for WSJ would be still brought by the lack of training data .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
This would suggest that lower accuracies than the WSJ parser for WSJ would be still brought by the lack of training data .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
This would suggest that lower accuracies than the WSJ parser for WSJ would be still brought by the lack of training data .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
This would suggest that lower accuracies than the WSJ parser for WSJ would be still brought by the lack of training data .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
This would suggest that lower accuracies than the WSJ parser for WSJ would be still brought by the lack of training data .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
This would suggest that lower accuracies than the WSJ parser for WSJ would be still brought by the lack of training data .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
This would suggest that lower accuracies than the WSJ parser for WSJ would be still brought by the lack of training data .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
This would suggest that lower accuracies than the WSJ parser for WSJ would be still brought by the lack of training data .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
In Figure \REF , when we focus on the QuestionBank where we could use much more training data than Brown questions , the parser accuracies were approaching the accuracies of WSJ parser for WSJ or exceeded the accuracy .
#<struct ReadData::Alignment source_numbers="37", target_numbers="6", tag_name="wa">
In Figure \REF , when we focus on the QuestionBank where we could use much more training data than Brown questions , the parser accuracies were approaching the accuracies of WSJ parser for WSJ or exceeded the accuracy .
#<struct ReadData::Alignment source_numbers="32", target_numbers="7", tag_name="wa">
In Figure \REF , when we focus on the QuestionBank where we could use much more training data than Brown questions , the parser accuracies were approaching the accuracies of WSJ parser for WSJ or exceeded the accuracy .
#<struct ReadData::Alignment source_numbers="21", target_numbers="9", tag_name="wa">
In Figure \REF , when we focus on the QuestionBank where we could use much more training data than Brown questions , the parser accuracies were approaching the accuracies of WSJ parser for WSJ or exceeded the accuracy .
#<struct ReadData::Alignment source_numbers="29", target_numbers="29", tag_name="wa">
In Figure \REF , when we focus on the QuestionBank where we could use much more training data than Brown questions , the parser accuracies were approaching the accuracies of WSJ parser for WSJ or exceeded the accuracy .
#<struct ReadData::Alignment source_numbers="8", target_numbers="30", tag_name="wa">
In Figure \REF , when we focus on the QuestionBank where we could use much more training data than Brown questions , the parser accuracies were approaching the accuracies of WSJ parser for WSJ or exceeded the accuracy .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
In Figure \REF , when we focus on the QuestionBank where we could use much more training data than Brown questions , the parser accuracies were approaching the accuracies of WSJ parser for WSJ or exceeded the accuracy .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
In Figure \REF , when we focus on the QuestionBank where we could use much more training data than Brown questions , the parser accuracies were approaching the accuracies of WSJ parser for WSJ or exceeded the accuracy .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
In Figure \REF , when we focus on the QuestionBank where we could use much more training data than Brown questions , the parser accuracies were approaching the accuracies of WSJ parser for WSJ or exceeded the accuracy .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
In Figure \REF , when we focus on the QuestionBank where we could use much more training data than Brown questions , the parser accuracies were approaching the accuracies of WSJ parser for WSJ or exceeded the accuracy .
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
In Figure \REF , when we focus on the QuestionBank where we could use much more training data than Brown questions , the parser accuracies were approaching the accuracies of WSJ parser for WSJ or exceeded the accuracy .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
In Figure \REF , when we focus on the QuestionBank where we could use much more training data than Brown questions , the parser accuracies were approaching the accuracies of WSJ parser for WSJ or exceeded the accuracy .
#<struct ReadData::Alignment source_numbers="26", target_numbers="", tag_name="wa">
In Figure \REF , when we focus on the QuestionBank where we could use much more training data than Brown questions , the parser accuracies were approaching the accuracies of WSJ parser for WSJ or exceeded the accuracy .
#<struct ReadData::Alignment source_numbers="27", target_numbers="", tag_name="wa">
In Figure \REF , when we focus on the QuestionBank where we could use much more training data than Brown questions , the parser accuracies were approaching the accuracies of WSJ parser for WSJ or exceeded the accuracy .
#<struct ReadData::Alignment source_numbers="28", target_numbers="", tag_name="wa">
In Figure \REF , when we focus on the QuestionBank where we could use much more training data than Brown questions , the parser accuracies were approaching the accuracies of WSJ parser for WSJ or exceeded the accuracy .
#<struct ReadData::Alignment source_numbers="35", target_numbers="", tag_name="wa">
In Figure \REF , when we focus on the QuestionBank where we could use much more training data than Brown questions , the parser accuracies were approaching the accuracies of WSJ parser for WSJ or exceeded the accuracy .
#<struct ReadData::Alignment source_numbers="36", target_numbers="", tag_name="wa">
In Figure \REF , when we focus on the QuestionBank where we could use much more training data than Brown questions , the parser accuracies were approaching the accuracies of WSJ parser for WSJ or exceeded the accuracy .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
In Figure \REF , when we focus on the QuestionBank where we could use much more training data than Brown questions , the parser accuracies were approaching the accuracies of WSJ parser for WSJ or exceeded the accuracy .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
In Figure \REF , when we focus on the QuestionBank where we could use much more training data than Brown questions , the parser accuracies were approaching the accuracies of WSJ parser for WSJ or exceeded the accuracy .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
In Figure \REF , when we focus on the QuestionBank where we could use much more training data than Brown questions , the parser accuracies were approaching the accuracies of WSJ parser for WSJ or exceeded the accuracy .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
In Figure \REF , when we focus on the QuestionBank where we could use much more training data than Brown questions , the parser accuracies were approaching the accuracies of WSJ parser for WSJ or exceeded the accuracy .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
However , we have no more training data for Brown imperatives and questions . We should prepare more training data or explore approaches to enable us to sufficiently adapt parsers with small training data .
#<struct ReadData::Alignment source_numbers="2", target_numbers="15", tag_name="wa">
However , we have no more training data for Brown imperatives and questions . We should prepare more training data or explore approaches to enable us to sufficiently adapt parsers with small training data .
#<struct ReadData::Alignment source_numbers="23", target_numbers="17", tag_name="wa">
However , we have no more training data for Brown imperatives and questions . We should prepare more training data or explore approaches to enable us to sufficiently adapt parsers with small training data .
#<struct ReadData::Alignment source_numbers="20", target_numbers="23", tag_name="wa">
However , we have no more training data for Brown imperatives and questions . We should prepare more training data or explore approaches to enable us to sufficiently adapt parsers with small training data .
#<struct ReadData::Alignment source_numbers="24", target_numbers="27", tag_name="wa">
However , we have no more training data for Brown imperatives and questions . We should prepare more training data or explore approaches to enable us to sufficiently adapt parsers with small training data .
#<struct ReadData::Alignment source_numbers="26", target_numbers="30", tag_name="wa">
However , we have no more training data for Brown imperatives and questions . We should prepare more training data or explore approaches to enable us to sufficiently adapt parsers with small training data .
#<struct ReadData::Alignment source_numbers="28", target_numbers="31,32", tag_name="wa">
However , we have no more training data for Brown imperatives and questions . We should prepare more training data or explore approaches to enable us to sufficiently adapt parsers with small training data .
#<struct ReadData::Alignment source_numbers="31", target_numbers="34", tag_name="wa">
However , we have no more training data for Brown imperatives and questions . We should prepare more training data or explore approaches to enable us to sufficiently adapt parsers with small training data .
#<struct ReadData::Alignment source_numbers="34", target_numbers="39", tag_name="wa">
However , we have no more training data for Brown imperatives and questions . We should prepare more training data or explore approaches to enable us to sufficiently adapt parsers with small training data .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
However , we have no more training data for Brown imperatives and questions . We should prepare more training data or explore approaches to enable us to sufficiently adapt parsers with small training data .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
However , we have no more training data for Brown imperatives and questions . We should prepare more training data or explore approaches to enable us to sufficiently adapt parsers with small training data .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
However , we have no more training data for Brown imperatives and questions . We should prepare more training data or explore approaches to enable us to sufficiently adapt parsers with small training data .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
However , we have no more training data for Brown imperatives and questions . We should prepare more training data or explore approaches to enable us to sufficiently adapt parsers with small training data .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
However , we have no more training data for Brown imperatives and questions . We should prepare more training data or explore approaches to enable us to sufficiently adapt parsers with small training data .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
However , we have no more training data for Brown imperatives and questions . We should prepare more training data or explore approaches to enable us to sufficiently adapt parsers with small training data .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
However , we have no more training data for Brown imperatives and questions . We should prepare more training data or explore approaches to enable us to sufficiently adapt parsers with small training data .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
However , we have no more training data for Brown imperatives and questions . We should prepare more training data or explore approaches to enable us to sufficiently adapt parsers with small training data .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
However , we have no more training data for Brown imperatives and questions . We should prepare more training data or explore approaches to enable us to sufficiently adapt parsers with small training data .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
However , we have no more training data for Brown imperatives and questions . We should prepare more training data or explore approaches to enable us to sufficiently adapt parsers with small training data .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
In order to capture the outline of the adaptation effects , we observed error reduction for the Malt parser .
#<struct ReadData::Alignment source_numbers="4", target_numbers="11", tag_name="wa">
In order to capture the outline of the adaptation effects , we observed error reduction for the Malt parser .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
In order to capture the outline of the adaptation effects , we observed error reduction for the Malt parser .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
In order to capture the outline of the adaptation effects , we observed error reduction for the Malt parser .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
In order to capture the outline of the adaptation effects , we observed error reduction for the Malt parser .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
In order to capture the outline of the adaptation effects , we observed error reduction for the Malt parser .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
In order to capture the outline of the adaptation effects , we observed error reduction for the Malt parser .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
In order to capture the outline of the adaptation effects , we observed error reduction for the Malt parser .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
In order to capture the outline of the adaptation effects , we observed error reduction for the Malt parser .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
In order to capture the outline of the adaptation effects , we observed error reduction for the Malt parser .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Table \REF and \REF show the recall errors on labeled dependencies which were observed more than ten times for 100 analysis sentences of each domain .
#<struct ReadData::Alignment source_numbers="22,23", target_numbers="23,24", tag_name="wa">
Table \REF and \REF show the recall errors on labeled dependencies which were observed more than ten times for 100 analysis sentences of each domain .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
Table \REF and \REF show the recall errors on labeled dependencies which were observed more than ten times for 100 analysis sentences of each domain .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Table \REF and \REF show the recall errors on labeled dependencies which were observed more than ten times for 100 analysis sentences of each domain .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
For each dependency shown in the first column , the second and third columns show the number of parsing errors by the WSJ parser with gold tags and the adapted parser with gold tags .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
Since ROOT dependencies , that is , heads of sentences would be critical to construction of sentences , we mainly focus on that type of errors .
#<struct ReadData::Alignment source_numbers="17", target_numbers="10", tag_name="wa">
Since ROOT dependencies , that is , heads of sentences would be critical to construction of sentences , we mainly focus on that type of errors .
#<struct ReadData::Alignment source_numbers="22,23", target_numbers="23,24", tag_name="wa">
Since ROOT dependencies , that is , heads of sentences would be critical to construction of sentences , we mainly focus on that type of errors .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
For Brown imperatives and questions , we could observe that the reduction of ROOT dependency was prominent .
#<struct ReadData::Alignment source_numbers="11,12", target_numbers="7,8", tag_name="wa">
For Brown imperatives and questions , we could observe that the reduction of ROOT dependency was prominent .
#<struct ReadData::Alignment source_numbers="17", target_numbers="13", tag_name="wa">
For Brown imperatives and questions , we could observe that the reduction of ROOT dependency was prominent .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
For Brown imperatives and questions , we could observe that the reduction of ROOT dependency was prominent .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
For Brown imperatives and questions , we could observe that the reduction of ROOT dependency was prominent .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
For Brown imperatives and questions , we could observe that the reduction of ROOT dependency was prominent .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
When we focus on this type of errors , we could find that the WSJ parser could often make mistakes in parsing sentences which began or ended with the names of persons who were talk to .
#<struct ReadData::Alignment source_numbers="8", target_numbers="2", tag_name="wa">
When we focus on this type of errors , we could find that the WSJ parser could often make mistakes in parsing sentences which began or ended with the names of persons who were talk to .
#<struct ReadData::Alignment source_numbers="11", target_numbers="4", tag_name="wa">
When we focus on this type of errors , we could find that the WSJ parser could often make mistakes in parsing sentences which began or ended with the names of persons who were talk to .
#<struct ReadData::Alignment source_numbers="18,19", target_numbers="10,11", tag_name="wa">
When we focus on this type of errors , we could find that the WSJ parser could often make mistakes in parsing sentences which began or ended with the names of persons who were talk to .
#<struct ReadData::Alignment source_numbers="29,30", target_numbers="21", tag_name="wa">
When we focus on this type of errors , we could find that the WSJ parser could often make mistakes in parsing sentences which began or ended with the names of persons who were talk to .
#<struct ReadData::Alignment source_numbers="6", target_numbers="22", tag_name="wa">
When we focus on this type of errors , we could find that the WSJ parser could often make mistakes in parsing sentences which began or ended with the names of persons who were talk to .
#<struct ReadData::Alignment source_numbers="31", target_numbers="23,24", tag_name="wa">
When we focus on this type of errors , we could find that the WSJ parser could often make mistakes in parsing sentences which began or ended with the names of persons who were talk to .
#<struct ReadData::Alignment source_numbers="36", target_numbers="27", tag_name="wa">
When we focus on this type of errors , we could find that the WSJ parser could often make mistakes in parsing sentences which began or ended with the names of persons who were talk to .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
When we focus on this type of errors , we could find that the WSJ parser could often make mistakes in parsing sentences which began or ended with the names of persons who were talk to .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
When we focus on this type of errors , we could find that the WSJ parser could often make mistakes in parsing sentences which began or ended with the names of persons who were talk to .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
When we focus on this type of errors , we could find that the WSJ parser could often make mistakes in parsing sentences which began or ended with the names of persons who were talk to .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
When we focus on this type of errors , we could find that the WSJ parser could often make mistakes in parsing sentences which began or ended with the names of persons who were talk to .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
When we focus on this type of errors , we could find that the WSJ parser could often make mistakes in parsing sentences which began or ended with the names of persons who were talk to .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
When we focus on this type of errors , we could find that the WSJ parser could often make mistakes in parsing sentences which began or ended with the names of persons who were talk to .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
When we focus on this type of errors , we could find that the WSJ parser could often make mistakes in parsing sentences which began or ended with the names of persons who were talk to .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
When we focus on this type of errors , we could find that the WSJ parser could often make mistakes in parsing sentences which began or ended with the names of persons who were talk to .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
When we focus on this type of errors , we could find that the WSJ parser could often make mistakes in parsing sentences which began or ended with the names of persons who were talk to .
#<struct ReadData::Alignment source_numbers="32", target_numbers="", tag_name="wa">
When we focus on this type of errors , we could find that the WSJ parser could often make mistakes in parsing sentences which began or ended with the names of persons who were talk to .
#<struct ReadData::Alignment source_numbers="33", target_numbers="", tag_name="wa">
When we focus on this type of errors , we could find that the WSJ parser could often make mistakes in parsing sentences which began or ended with the names of persons who were talk to .
#<struct ReadData::Alignment source_numbers="34", target_numbers="", tag_name="wa">
When we focus on this type of errors , we could find that the WSJ parser could often make mistakes in parsing sentences which began or ended with the names of persons who were talk to .
#<struct ReadData::Alignment source_numbers="35", target_numbers="", tag_name="wa">
When we focus on this type of errors , we could find that the WSJ parser could often make mistakes in parsing sentences which began or ended with the names of persons who were talk to .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
When we focus on this type of errors , we could find that the WSJ parser could often make mistakes in parsing sentences which began or ended with the names of persons who were talk to .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
When we focus on this type of errors , we could find that the WSJ parser could often make mistakes in parsing sentences which began or ended with the names of persons who were talk to .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
When we focus on this type of errors , we could find that the WSJ parser could often make mistakes in parsing sentences which began or ended with the names of persons who were talk to .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
For example in Brown imperatives , for the sentence " See for yourself , Miss Zion . " , the WSJ parser regarded the person name " Zion " as ROOT , and the main verb " See " as modifiers of the name .
#<struct ReadData::Alignment source_numbers="31", target_numbers="2", tag_name="wa">
For example in Brown imperatives , for the sentence " See for yourself , Miss Zion . " , the WSJ parser regarded the person name " Zion " as ROOT , and the main verb " See " as modifiers of the name .
#<struct ReadData::Alignment source_numbers="25", target_numbers="25", tag_name="wa">
For example in Brown imperatives , for the sentence " See for yourself , Miss Zion . " , the WSJ parser regarded the person name " Zion " as ROOT , and the main verb " See " as modifiers of the name .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
For example in Brown imperatives , for the sentence " See for yourself , Miss Zion . " , the WSJ parser regarded the person name " Zion " as ROOT , and the main verb " See " as modifiers of the name .
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
For example in Brown imperatives , for the sentence " See for yourself , Miss Zion . " , the WSJ parser regarded the person name " Zion " as ROOT , and the main verb " See " as modifiers of the name .
#<struct ReadData::Alignment source_numbers="29", target_numbers="", tag_name="wa">
For example in Brown imperatives , for the sentence " See for yourself , Miss Zion . " , the WSJ parser regarded the person name " Zion " as ROOT , and the main verb " See " as modifiers of the name .
#<struct ReadData::Alignment source_numbers="39", target_numbers="", tag_name="wa">
For example in Brown imperatives , for the sentence " See for yourself , Miss Zion . " , the WSJ parser regarded the person name " Zion " as ROOT , and the main verb " See " as modifiers of the name .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
For example in Brown imperatives , for the sentence " See for yourself , Miss Zion . " , the WSJ parser regarded the person name " Zion " as ROOT , and the main verb " See " as modifiers of the name .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
For example in Brown imperatives , for the sentence " See for yourself , Miss Zion . " , the WSJ parser regarded the person name " Zion " as ROOT , and the main verb " See " as modifiers of the name .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
For example in Brown imperatives , for the sentence " See for yourself , Miss Zion . " , the WSJ parser regarded the person name " Zion " as ROOT , and the main verb " See " as modifiers of the name .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
For example in Brown imperatives , for the sentence " See for yourself , Miss Zion . " , the WSJ parser regarded the person name " Zion " as ROOT , and the main verb " See " as modifiers of the name .
#<struct ReadData::Alignment source_numbers="", target_numbers="40", tag_name="wa">
For example in Brown imperatives , for the sentence " See for yourself , Miss Zion . " , the WSJ parser regarded the person name " Zion " as ROOT , and the main verb " See " as modifiers of the name .
#<struct ReadData::Alignment source_numbers="", target_numbers="41", tag_name="wa">
For example in Brown imperatives , for the sentence " See for yourself , Miss Zion . " , the WSJ parser regarded the person name " Zion " as ROOT , and the main verb " See " as modifiers of the name .
#<struct ReadData::Alignment source_numbers="", target_numbers="42", tag_name="wa">
The adapted parser could then correctly give ROOT to the main verb .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
The adapted parser could then correctly give ROOT to the main verb .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
The adapted parser could then correctly give ROOT to the main verb .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
We could also often find that the WSJ parser could often make mistakes in parsing sentences containing quotation , exclamation , and question marks , such as " " Hang on " !! " " or " Why did you kill it " ? ? " or " " " " .
#<struct ReadData::Alignment source_numbers="4", target_numbers="2", tag_name="wa">
We could also often find that the WSJ parser could often make mistakes in parsing sentences containing quotation , exclamation , and question marks , such as " " Hang on " !! " " or " Why did you kill it " ? ? " or " " " " .
#<struct ReadData::Alignment source_numbers="11", target_numbers="8", tag_name="wa">
We could also often find that the WSJ parser could often make mistakes in parsing sentences containing quotation , exclamation , and question marks , such as " " Hang on " !! " " or " Why did you kill it " ? ? " or " " " " .
#<struct ReadData::Alignment source_numbers="46", target_numbers="18", tag_name="wa">
We could also often find that the WSJ parser could often make mistakes in parsing sentences containing quotation , exclamation , and question marks , such as " " Hang on " !! " " or " Why did you kill it " ? ? " or " " " " .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
We could also often find that the WSJ parser could often make mistakes in parsing sentences containing quotation , exclamation , and question marks , such as " " Hang on " !! " " or " Why did you kill it " ? ? " or " " " " .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
We could also often find that the WSJ parser could often make mistakes in parsing sentences containing quotation , exclamation , and question marks , such as " " Hang on " !! " " or " Why did you kill it " ? ? " or " " " " .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
We could also often find that the WSJ parser could often make mistakes in parsing sentences containing quotation , exclamation , and question marks , such as " " Hang on " !! " " or " Why did you kill it " ? ? " or " " " " .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
We could also often find that the WSJ parser could often make mistakes in parsing sentences containing quotation , exclamation , and question marks , such as " " Hang on " !! " " or " Why did you kill it " ? ? " or " " " " .
#<struct ReadData::Alignment source_numbers="", target_numbers="43", tag_name="wa">
For such sentences , the WSJ parser regarded the first " ! " or " ? " as ROOT , and " Hang " or " did " as the modifier of the marks .
#<struct ReadData::Alignment source_numbers="33", target_numbers="", tag_name="wa">
For such sentences , the WSJ parser regarded the first " ! " or " ? " as ROOT , and " Hang " or " did " as the modifier of the marks .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
We thought that this kind of errors would partly come fromthe Brown corpus itself . The exclamation or question marks should be inside the quotation , while the Brown corpus usually put the marks outside .
#<struct ReadData::Alignment source_numbers="7", target_numbers="8", tag_name="wa">
We thought that this kind of errors would partly come fromthe Brown corpus itself . The exclamation or question marks should be inside the quotation , while the Brown corpus usually put the marks outside .
#<struct ReadData::Alignment source_numbers="21", target_numbers="9", tag_name="wa">
We thought that this kind of errors would partly come fromthe Brown corpus itself . The exclamation or question marks should be inside the quotation , while the Brown corpus usually put the marks outside .
#<struct ReadData::Alignment source_numbers="2", target_numbers="10", tag_name="wa">
We thought that this kind of errors would partly come fromthe Brown corpus itself . The exclamation or question marks should be inside the quotation , while the Brown corpus usually put the marks outside .
#<struct ReadData::Alignment source_numbers="27", target_numbers="11", tag_name="wa">
We thought that this kind of errors would partly come fromthe Brown corpus itself . The exclamation or question marks should be inside the quotation , while the Brown corpus usually put the marks outside .
#<struct ReadData::Alignment source_numbers="28", target_numbers="12", tag_name="wa">
We thought that this kind of errors would partly come fromthe Brown corpus itself . The exclamation or question marks should be inside the quotation , while the Brown corpus usually put the marks outside .
#<struct ReadData::Alignment source_numbers="29", target_numbers="13", tag_name="wa">
We thought that this kind of errors would partly come fromthe Brown corpus itself . The exclamation or question marks should be inside the quotation , while the Brown corpus usually put the marks outside .
#<struct ReadData::Alignment source_numbers="19", target_numbers="18", tag_name="wa">
We thought that this kind of errors would partly come fromthe Brown corpus itself . The exclamation or question marks should be inside the quotation , while the Brown corpus usually put the marks outside .
#<struct ReadData::Alignment source_numbers="25", target_numbers="20", tag_name="wa">
We thought that this kind of errors would partly come fromthe Brown corpus itself . The exclamation or question marks should be inside the quotation , while the Brown corpus usually put the marks outside .
#<struct ReadData::Alignment source_numbers="14", target_numbers="26", tag_name="wa">
We thought that this kind of errors would partly come fromthe Brown corpus itself . The exclamation or question marks should be inside the quotation , while the Brown corpus usually put the marks outside .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
We thought that this kind of errors would partly come fromthe Brown corpus itself . The exclamation or question marks should be inside the quotation , while the Brown corpus usually put the marks outside .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
We thought that this kind of errors would partly come fromthe Brown corpus itself . The exclamation or question marks should be inside the quotation , while the Brown corpus usually put the marks outside .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
We thought that this kind of errors would partly come fromthe Brown corpus itself . The exclamation or question marks should be inside the quotation , while the Brown corpus usually put the marks outside .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
We thought that this kind of errors would partly come fromthe Brown corpus itself . The exclamation or question marks should be inside the quotation , while the Brown corpus usually put the marks outside .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
We thought that this kind of errors would partly come fromthe Brown corpus itself . The exclamation or question marks should be inside the quotation , while the Brown corpus usually put the marks outside .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
We thought that this kind of errors would partly come fromthe Brown corpus itself . The exclamation or question marks should be inside the quotation , while the Brown corpus usually put the marks outside .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
We thought that this kind of errors would partly come fromthe Brown corpus itself . The exclamation or question marks should be inside the quotation , while the Brown corpus usually put the marks outside .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
We thought that this kind of errors would partly come fromthe Brown corpus itself . The exclamation or question marks should be inside the quotation , while the Brown corpus usually put the marks outside .
#<struct ReadData::Alignment source_numbers="26", target_numbers="", tag_name="wa">
We thought that this kind of errors would partly come fromthe Brown corpus itself . The exclamation or question marks should be inside the quotation , while the Brown corpus usually put the marks outside .
#<struct ReadData::Alignment source_numbers="31", target_numbers="", tag_name="wa">
We thought that this kind of errors would partly come fromthe Brown corpus itself . The exclamation or question marks should be inside the quotation , while the Brown corpus usually put the marks outside .
#<struct ReadData::Alignment source_numbers="33", target_numbers="", tag_name="wa">
We thought that this kind of errors would partly come fromthe Brown corpus itself . The exclamation or question marks should be inside the quotation , while the Brown corpus usually put the marks outside .
#<struct ReadData::Alignment source_numbers="35", target_numbers="", tag_name="wa">
We thought that this kind of errors would partly come fromthe Brown corpus itself . The exclamation or question marks should be inside the quotation , while the Brown corpus usually put the marks outside .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
We thought that this kind of errors would partly come fromthe Brown corpus itself . The exclamation or question marks should be inside the quotation , while the Brown corpus usually put the marks outside .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
We thought that this kind of errors would partly come fromthe Brown corpus itself . The exclamation or question marks should be inside the quotation , while the Brown corpus usually put the marks outside .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
We thought that this kind of errors would partly come fromthe Brown corpus itself . The exclamation or question marks should be inside the quotation , while the Brown corpus usually put the marks outside .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
We thought that this kind of errors would partly come fromthe Brown corpus itself . The exclamation or question marks should be inside the quotation , while the Brown corpus usually put the marks outside .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
We thought that this kind of errors would partly come fromthe Brown corpus itself . The exclamation or question marks should be inside the quotation , while the Brown corpus usually put the marks outside .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
We thought that this kind of errors would partly come fromthe Brown corpus itself . The exclamation or question marks should be inside the quotation , while the Brown corpus usually put the marks outside .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
However , the adapted parser could take in such doubtful construction and gave ROOT to the main verbs as the corpus required .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
However , the adapted parser could take in such doubtful construction and gave ROOT to the main verbs as the corpus required .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
However , the adapted parser could take in such doubtful construction and gave ROOT to the main verbs as the corpus required .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
However , the adapted parser could take in such doubtful construction and gave ROOT to the main verbs as the corpus required .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
However , the adapted parser could take in such doubtful construction and gave ROOT to the main verbs as the corpus required .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
However , the adapted parser could take in such doubtful construction and gave ROOT to the main verbs as the corpus required .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
However , the adapted parser could take in such doubtful construction and gave ROOT to the main verbs as the corpus required .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
However , the adapted parser could take in such doubtful construction and gave ROOT to the main verbs as the corpus required .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
However , the adapted parser could take in such doubtful construction and gave ROOT to the main verbs as the corpus required .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
However , the adapted parser could take in such doubtful construction and gave ROOT to the main verbs as the corpus required .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
On the other hand , we also observed some still unsolved errors . We would show the two kinds of major errors among them .
#<struct ReadData::Alignment source_numbers="10", target_numbers="9", tag_name="wa">
On the other hand , we also observed some still unsolved errors . We would show the two kinds of major errors among them .
#<struct ReadData::Alignment source_numbers="19", target_numbers="12", tag_name="wa">
On the other hand , we also observed some still unsolved errors . We would show the two kinds of major errors among them .
#<struct ReadData::Alignment source_numbers="22,23", target_numbers="13", tag_name="wa">
On the other hand , we also observed some still unsolved errors . We would show the two kinds of major errors among them .
#<struct ReadData::Alignment source_numbers="12", target_numbers="17", tag_name="wa">
On the other hand , we also observed some still unsolved errors . We would show the two kinds of major errors among them .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
On the other hand , we also observed some still unsolved errors . We would show the two kinds of major errors among them .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
On the other hand , we also observed some still unsolved errors . We would show the two kinds of major errors among them .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
On the other hand , we also observed some still unsolved errors . We would show the two kinds of major errors among them .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
On the other hand , we also observed some still unsolved errors . We would show the two kinds of major errors among them .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
On the other hand , we also observed some still unsolved errors . We would show the two kinds of major errors among them .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
On the other hand , we also observed some still unsolved errors . We would show the two kinds of major errors among them .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
On the other hand , we also observed some still unsolved errors . We would show the two kinds of major errors among them .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
On the other hand , we also observed some still unsolved errors . We would show the two kinds of major errors among them .
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
On the other hand , we also observed some still unsolved errors . We would show the two kinds of major errors among them .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
On the other hand , we also observed some still unsolved errors . We would show the two kinds of major errors among them .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
On the other hand , we also observed some still unsolved errors . We would show the two kinds of major errors among them .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
First , Brown imperatives and questions , include many conversation sentences , and therefore rather flexible constructions could be observed especially for imperatives , such as " Lift , don't shove lift! " , " Come out , come out in the meadow! " , etc.
#<struct ReadData::Alignment source_numbers="44", target_numbers="17", tag_name="wa">
First , Brown imperatives and questions , include many conversation sentences , and therefore rather flexible constructions could be observed especially for imperatives , such as " Lift , don't shove lift! " , " Come out , come out in the meadow! " , etc.
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
First , Brown imperatives and questions , include many conversation sentences , and therefore rather flexible constructions could be observed especially for imperatives , such as " Lift , don't shove lift! " , " Come out , come out in the meadow! " , etc.
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
First , Brown imperatives and questions , include many conversation sentences , and therefore rather flexible constructions could be observed especially for imperatives , such as " Lift , don't shove lift! " , " Come out , come out in the meadow! " , etc.
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
First , Brown imperatives and questions , include many conversation sentences , and therefore rather flexible constructions could be observed especially for imperatives , such as " Lift , don't shove lift! " , " Come out , come out in the meadow! " , etc.
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
First , Brown imperatives and questions , include many conversation sentences , and therefore rather flexible constructions could be observed especially for imperatives , such as " Lift , don't shove lift! " , " Come out , come out in the meadow! " , etc.
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
First , Brown imperatives and questions , include many conversation sentences , and therefore rather flexible constructions could be observed especially for imperatives , such as " Lift , don't shove lift! " , " Come out , come out in the meadow! " , etc.
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
First , Brown imperatives and questions , include many conversation sentences , and therefore rather flexible constructions could be observed especially for imperatives , such as " Lift , don't shove lift! " , " Come out , come out in the meadow! " , etc.
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
First , Brown imperatives and questions , include many conversation sentences , and therefore rather flexible constructions could be observed especially for imperatives , such as " Lift , don't shove lift! " , " Come out , come out in the meadow! " , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
First , Brown imperatives and questions , include many conversation sentences , and therefore rather flexible constructions could be observed especially for imperatives , such as " Lift , don't shove lift! " , " Come out , come out in the meadow! " , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
First , Brown imperatives and questions , include many conversation sentences , and therefore rather flexible constructions could be observed especially for imperatives , such as " Lift , don't shove lift! " , " Come out , come out in the meadow! " , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
First , Brown imperatives and questions , include many conversation sentences , and therefore rather flexible constructions could be observed especially for imperatives , such as " Lift , don't shove lift! " , " Come out , come out in the meadow! " , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="41", tag_name="wa">
The parsing models based on the plausibility of constructions could hardly capture such sentences .
#<struct ReadData::Alignment source_numbers="10", target_numbers="10", tag_name="wa">
The parsing models based on the plausibility of constructions could hardly capture such sentences .
#<struct ReadData::Alignment source_numbers="9", target_numbers="11", tag_name="wa">
The parsing models based on the plausibility of constructions could hardly capture such sentences .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
The parsing models based on the plausibility of constructions could hardly capture such sentences .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
Second , when the different constructions of sentences were in one sentence , such as , the case where to-infinitive phrases or subordinate clauses precede imperatives and questions , the parser would often be confused .
#<struct ReadData::Alignment source_numbers="4", target_numbers="3", tag_name="wa">
Second , when the different constructions of sentences were in one sentence , such as , the case where to-infinitive phrases or subordinate clauses precede imperatives and questions , the parser would often be confused .
#<struct ReadData::Alignment source_numbers="5", target_numbers="5", tag_name="wa">
Second , when the different constructions of sentences were in one sentence , such as , the case where to-infinitive phrases or subordinate clauses precede imperatives and questions , the parser would often be confused .
#<struct ReadData::Alignment source_numbers="10", target_numbers="8", tag_name="wa">
Second , when the different constructions of sentences were in one sentence , such as , the case where to-infinitive phrases or subordinate clauses precede imperatives and questions , the parser would often be confused .
#<struct ReadData::Alignment source_numbers="18", target_numbers="14", tag_name="wa">
Second , when the different constructions of sentences were in one sentence , such as , the case where to-infinitive phrases or subordinate clauses precede imperatives and questions , the parser would often be confused .
#<struct ReadData::Alignment source_numbers="34", target_numbers="28", tag_name="wa">
Second , when the different constructions of sentences were in one sentence , such as , the case where to-infinitive phrases or subordinate clauses precede imperatives and questions , the parser would often be confused .
#<struct ReadData::Alignment source_numbers="3", target_numbers="29", tag_name="wa">
Second , when the different constructions of sentences were in one sentence , such as , the case where to-infinitive phrases or subordinate clauses precede imperatives and questions , the parser would often be confused .
#<struct ReadData::Alignment source_numbers="35", target_numbers="31", tag_name="wa">
Second , when the different constructions of sentences were in one sentence , such as , the case where to-infinitive phrases or subordinate clauses precede imperatives and questions , the parser would often be confused .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
Second , when the different constructions of sentences were in one sentence , such as , the case where to-infinitive phrases or subordinate clauses precede imperatives and questions , the parser would often be confused .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Second , when the different constructions of sentences were in one sentence , such as , the case where to-infinitive phrases or subordinate clauses precede imperatives and questions , the parser would often be confused .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Second , when the different constructions of sentences were in one sentence , such as , the case where to-infinitive phrases or subordinate clauses precede imperatives and questions , the parser would often be confused .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
Second , when the different constructions of sentences were in one sentence , such as , the case where to-infinitive phrases or subordinate clauses precede imperatives and questions , the parser would often be confused .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
Second , when the different constructions of sentences were in one sentence , such as , the case where to-infinitive phrases or subordinate clauses precede imperatives and questions , the parser would often be confused .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
Second , when the different constructions of sentences were in one sentence , such as , the case where to-infinitive phrases or subordinate clauses precede imperatives and questions , the parser would often be confused .
#<struct ReadData::Alignment source_numbers="26", target_numbers="", tag_name="wa">
Second , when the different constructions of sentences were in one sentence , such as , the case where to-infinitive phrases or subordinate clauses precede imperatives and questions , the parser would often be confused .
#<struct ReadData::Alignment source_numbers="29", target_numbers="", tag_name="wa">
Second , when the different constructions of sentences were in one sentence , such as , the case where to-infinitive phrases or subordinate clauses precede imperatives and questions , the parser would often be confused .
#<struct ReadData::Alignment source_numbers="31", target_numbers="", tag_name="wa">
Second , when the different constructions of sentences were in one sentence , such as , the case where to-infinitive phrases or subordinate clauses precede imperatives and questions , the parser would often be confused .
#<struct ReadData::Alignment source_numbers="33", target_numbers="", tag_name="wa">
Second , when the different constructions of sentences were in one sentence , such as , the case where to-infinitive phrases or subordinate clauses precede imperatives and questions , the parser would often be confused .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Second , when the different constructions of sentences were in one sentence , such as , the case where to-infinitive phrases or subordinate clauses precede imperatives and questions , the parser would often be confused .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Second , when the different constructions of sentences were in one sentence , such as , the case where to-infinitive phrases or subordinate clauses precede imperatives and questions , the parser would often be confused .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Second , when the different constructions of sentences were in one sentence , such as , the case where to-infinitive phrases or subordinate clauses precede imperatives and questions , the parser would often be confused .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
Second , when the different constructions of sentences were in one sentence , such as , the case where to-infinitive phrases or subordinate clauses precede imperatives and questions , the parser would often be confused .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
For example , for the imperative sentence " To find estimated net farm income , subtract estimated annual farming expenditures . . . " , both of the WSJ and adapted parsers regarded " find " as ROOT , because the parsers regarded the words following " find " as a that-clause complement for the " find " , like " To find [ ( that ) estimated net farm income , subtract estimated annual farming . . .] " .
#<struct ReadData::Alignment source_numbers="58", target_numbers="7", tag_name="wa">
For example , for the imperative sentence " To find estimated net farm income , subtract estimated annual farming expenditures . . . " , both of the WSJ and adapted parsers regarded " find " as ROOT , because the parsers regarded the words following " find " as a that-clause complement for the " find " , like " To find [ ( that ) estimated net farm income , subtract estimated annual farming . . .] " .
#<struct ReadData::Alignment source_numbers="27", target_numbers="11", tag_name="wa">
For example , for the imperative sentence " To find estimated net farm income , subtract estimated annual farming expenditures . . . " , both of the WSJ and adapted parsers regarded " find " as ROOT , because the parsers regarded the words following " find " as a that-clause complement for the " find " , like " To find [ ( that ) estimated net farm income , subtract estimated annual farming . . .] " .
#<struct ReadData::Alignment source_numbers="40", target_numbers="18", tag_name="wa">
For example , for the imperative sentence " To find estimated net farm income , subtract estimated annual farming expenditures . . . " , both of the WSJ and adapted parsers regarded " find " as ROOT , because the parsers regarded the words following " find " as a that-clause complement for the " find " , like " To find [ ( that ) estimated net farm income , subtract estimated annual farming . . .] " .
#<struct ReadData::Alignment source_numbers="43", target_numbers="29", tag_name="wa">
For example , for the imperative sentence " To find estimated net farm income , subtract estimated annual farming expenditures . . . " , both of the WSJ and adapted parsers regarded " find " as ROOT , because the parsers regarded the words following " find " as a that-clause complement for the " find " , like " To find [ ( that ) estimated net farm income , subtract estimated annual farming . . .] " .
#<struct ReadData::Alignment source_numbers="54", target_numbers="42", tag_name="wa">
For example , for the imperative sentence " To find estimated net farm income , subtract estimated annual farming expenditures . . . " , both of the WSJ and adapted parsers regarded " find " as ROOT , because the parsers regarded the words following " find " as a that-clause complement for the " find " , like " To find [ ( that ) estimated net farm income , subtract estimated annual farming . . .] " .
#<struct ReadData::Alignment source_numbers="52", target_numbers="54", tag_name="wa">
For example , for the imperative sentence " To find estimated net farm income , subtract estimated annual farming expenditures . . . " , both of the WSJ and adapted parsers regarded " find " as ROOT , because the parsers regarded the words following " find " as a that-clause complement for the " find " , like " To find [ ( that ) estimated net farm income , subtract estimated annual farming . . .] " .
#<struct ReadData::Alignment source_numbers="71", target_numbers="58", tag_name="wa">
For example , for the imperative sentence " To find estimated net farm income , subtract estimated annual farming expenditures . . . " , both of the WSJ and adapted parsers regarded " find " as ROOT , because the parsers regarded the words following " find " as a that-clause complement for the " find " , like " To find [ ( that ) estimated net farm income , subtract estimated annual farming . . .] " .
#<struct ReadData::Alignment source_numbers="26", target_numbers="", tag_name="wa">
For example , for the imperative sentence " To find estimated net farm income , subtract estimated annual farming expenditures . . . " , both of the WSJ and adapted parsers regarded " find " as ROOT , because the parsers regarded the words following " find " as a that-clause complement for the " find " , like " To find [ ( that ) estimated net farm income , subtract estimated annual farming . . .] " .
#<struct ReadData::Alignment source_numbers="53", target_numbers="", tag_name="wa">
For example , for the imperative sentence " To find estimated net farm income , subtract estimated annual farming expenditures . . . " , both of the WSJ and adapted parsers regarded " find " as ROOT , because the parsers regarded the words following " find " as a that-clause complement for the " find " , like " To find [ ( that ) estimated net farm income , subtract estimated annual farming . . .] " .
#<struct ReadData::Alignment source_numbers="59", target_numbers="", tag_name="wa">
For example , for the imperative sentence " To find estimated net farm income , subtract estimated annual farming expenditures . . . " , both of the WSJ and adapted parsers regarded " find " as ROOT , because the parsers regarded the words following " find " as a that-clause complement for the " find " , like " To find [ ( that ) estimated net farm income , subtract estimated annual farming . . .] " .
#<struct ReadData::Alignment source_numbers="", target_numbers="45", tag_name="wa">
For example , for the imperative sentence " To find estimated net farm income , subtract estimated annual farming expenditures . . . " , both of the WSJ and adapted parsers regarded " find " as ROOT , because the parsers regarded the words following " find " as a that-clause complement for the " find " , like " To find [ ( that ) estimated net farm income , subtract estimated annual farming . . .] " .
#<struct ReadData::Alignment source_numbers="", target_numbers="59", tag_name="wa">
For example , for the imperative sentence " To find estimated net farm income , subtract estimated annual farming expenditures . . . " , both of the WSJ and adapted parsers regarded " find " as ROOT , because the parsers regarded the words following " find " as a that-clause complement for the " find " , like " To find [ ( that ) estimated net farm income , subtract estimated annual farming . . .] " .
#<struct ReadData::Alignment source_numbers="", target_numbers="60", tag_name="wa">
For example , for the imperative sentence " To find estimated net farm income , subtract estimated annual farming expenditures . . . " , both of the WSJ and adapted parsers regarded " find " as ROOT , because the parsers regarded the words following " find " as a that-clause complement for the " find " , like " To find [ ( that ) estimated net farm income , subtract estimated annual farming . . .] " .
#<struct ReadData::Alignment source_numbers="", target_numbers="73", tag_name="wa">
It would be difficult for the parsers to know where the main clause in such complex sentences .
#<struct ReadData::Alignment source_numbers="9", target_numbers="9", tag_name="wa">
It would be difficult for the parsers to know where the main clause in such complex sentences .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
This type of errors would hardly be solved only by increasing the training data .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
This type of errors would hardly be solved only by increasing the training data .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
This type of errors would hardly be solved only by increasing the training data .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
The parser would parse such complex sentences without partition into each construction , and therefore it would sometimes be confused .
#<struct ReadData::Alignment source_numbers="8", target_numbers="7", tag_name="wa">
The parser would parse such complex sentences without partition into each construction , and therefore it would sometimes be confused .
#<struct ReadData::Alignment source_numbers="1", target_numbers="17", tag_name="wa">
The parser would parse such complex sentences without partition into each construction , and therefore it would sometimes be confused .
#<struct ReadData::Alignment source_numbers="19", target_numbers="20", tag_name="wa">
The parser would parse such complex sentences without partition into each construction , and therefore it would sometimes be confused .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
The parser would parse such complex sentences without partition into each construction , and therefore it would sometimes be confused .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
The parser would parse such complex sentences without partition into each construction , and therefore it would sometimes be confused .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
The parser would parse such complex sentences without partition into each construction , and therefore it would sometimes be confused .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
The parser would parse such complex sentences without partition into each construction , and therefore it would sometimes be confused .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
The parser would parse such complex sentences without partition into each construction , and therefore it would sometimes be confused .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
The parser would parse such complex sentences without partition into each construction , and therefore it would sometimes be confused .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
The parser would parse such complex sentences without partition into each construction , and therefore it would sometimes be confused .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
The parser would parse such complex sentences without partition into each construction , and therefore it would sometimes be confused .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
The parser would parse such complex sentences without partition into each construction , and therefore it would sometimes be confused .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
The parser would parse such complex sentences without partition into each construction , and therefore it would sometimes be confused .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
The parser would parse such complex sentences without partition into each construction , and therefore it would sometimes be confused .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
The parser would parse such complex sentences without partition into each construction , and therefore it would sometimes be confused .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
The parser would parse such complex sentences without partition into each construction , and therefore it would sometimes be confused .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
The parser would parse such complex sentences without partition into each construction , and therefore it would sometimes be confused .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
The parser would parse such complex sentences without partition into each construction , and therefore it would sometimes be confused .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
The parser would parse such complex sentences without partition into each construction , and therefore it would sometimes be confused .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
The parser would parse such complex sentences without partition into each construction , and therefore it would sometimes be confused .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
Both of Brown questions and QuestionBank are in the domain of question .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
In this section , we examined whether the parser adapted to one domain would be portable to the other domain .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
In this section , we examined whether the parser adapted to one domain would be portable to the other domain .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
In this section , we examined whether the parser adapted to one domain would be portable to the other domain .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
In this section , we examined whether the parser adapted to one domain would be portable to the other domain .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
In this section , we examined whether the parser adapted to one domain would be portable to the other domain .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
In this section , we examined whether the parser adapted to one domain would be portable to the other domain .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
QuestionBankdoes not give function tags , and therefore in training and evaluation of the parsers , abstracted dependencies were extracted from the corpus .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
QuestionBankdoes not give function tags , and therefore in training and evaluation of the parsers , abstracted dependencies were extracted from the corpus .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
QuestionBankdoes not give function tags , and therefore in training and evaluation of the parsers , abstracted dependencies were extracted from the corpus .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Therefore , the parser adapted to one domain could not give correct dependency labels on such functions for the other domain .
#<struct ReadData::Alignment source_numbers="16", target_numbers="17", tag_name="wa">
Therefore , the parser adapted to one domain could not give correct dependency labels on such functions for the other domain .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Therefore , the parser adapted to one domain could not give correct dependency labels on such functions for the other domain .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Therefore , the parser adapted to one domain could not give correct dependency labels on such functions for the other domain .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
Therefore , the parser adapted to one domain could not give correct dependency labels on such functions for the other domain .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Therefore , the parser adapted to one domain could not give correct dependency labels on such functions for the other domain .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Therefore , the parser adapted to one domain could not give correct dependency labels on such functions for the other domain .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Therefore , the parser adapted to one domain could not give correct dependency labels on such functions for the other domain .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
However , we would be able to expect that sentence constructions would be basically common and portable between two domains , which would contribute to give correct boundary for phrases and therefore the correct dependencies in phrases would be introduced by the adaptation .
#<struct ReadData::Alignment source_numbers="20", target_numbers="16", tag_name="wa">
However , we would be able to expect that sentence constructions would be basically common and portable between two domains , which would contribute to give correct boundary for phrases and therefore the correct dependencies in phrases would be introduced by the adaptation .
#<struct ReadData::Alignment source_numbers="43", target_numbers="39", tag_name="wa">
However , we would be able to expect that sentence constructions would be basically common and portable between two domains , which would contribute to give correct boundary for phrases and therefore the correct dependencies in phrases would be introduced by the adaptation .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
However , we would be able to expect that sentence constructions would be basically common and portable between two domains , which would contribute to give correct boundary for phrases and therefore the correct dependencies in phrases would be introduced by the adaptation .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
However , we would be able to expect that sentence constructions would be basically common and portable between two domains , which would contribute to give correct boundary for phrases and therefore the correct dependencies in phrases would be introduced by the adaptation .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
However , we would be able to expect that sentence constructions would be basically common and portable between two domains , which would contribute to give correct boundary for phrases and therefore the correct dependencies in phrases would be introduced by the adaptation .
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
However , we would be able to expect that sentence constructions would be basically common and portable between two domains , which would contribute to give correct boundary for phrases and therefore the correct dependencies in phrases would be introduced by the adaptation .
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
However , we would be able to expect that sentence constructions would be basically common and portable between two domains , which would contribute to give correct boundary for phrases and therefore the correct dependencies in phrases would be introduced by the adaptation .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
However , we would be able to expect that sentence constructions would be basically common and portable between two domains , which would contribute to give correct boundary for phrases and therefore the correct dependencies in phrases would be introduced by the adaptation .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
However , we would be able to expect that sentence constructions would be basically common and portable between two domains , which would contribute to give correct boundary for phrases and therefore the correct dependencies in phrases would be introduced by the adaptation .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
Table \REF shows the parsing or tagging accuracies of each parser and the POS tagger for Brown questions and QuestionBank .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Table \REF shows the parsing or tagging accuracies of each parser and the POS tagger for Brown questions and QuestionBank .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
the difference from Table \REF was that the parsers and the tagger were adapted to another question domain .
#<struct ReadData::Alignment source_numbers="1", target_numbers="2", tag_name="wa">
the difference from Table \REF was that the parsers and the tagger were adapted to another question domain .
#<struct ReadData::Alignment source_numbers="3", target_numbers="6", tag_name="wa">
the difference from Table \REF was that the parsers and the tagger were adapted to another question domain .
#<struct ReadData::Alignment source_numbers="4", target_numbers="7", tag_name="wa">
the difference from Table \REF was that the parsers and the tagger were adapted to another question domain .
#<struct ReadData::Alignment source_numbers="18", target_numbers="22", tag_name="wa">
the difference from Table \REF was that the parsers and the tagger were adapted to another question domain .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
the difference from Table \REF was that the parsers and the tagger were adapted to another question domain .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
the difference from Table \REF was that the parsers and the tagger were adapted to another question domain .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
the difference from Table \REF was that the parsers and the tagger were adapted to another question domain .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
the difference from Table \REF was that the parsers and the tagger were adapted to another question domain .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
the difference from Table \REF was that the parsers and the tagger were adapted to another question domain .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
The table shows that the parsers adapted to Brown questions improved the parsing accuracies for QuestionBank , while the parsers adapted to QuestionBank decreased .
#<struct ReadData::Alignment source_numbers="11", target_numbers="8", tag_name="wa">
The table shows that the parsers adapted to Brown questions improved the parsing accuracies for QuestionBank , while the parsers adapted to QuestionBank decreased .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
The table shows that the parsers adapted to Brown questions improved the parsing accuracies for QuestionBank , while the parsers adapted to QuestionBank decreased .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
The table shows that the parsers adapted to Brown questions improved the parsing accuracies for QuestionBank , while the parsers adapted to QuestionBank decreased .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
The table shows that the parsers adapted to Brown questions improved the parsing accuracies for QuestionBank , while the parsers adapted to QuestionBank decreased .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
The table shows that the parsers adapted to Brown questions improved the parsing accuracies for QuestionBank , while the parsers adapted to QuestionBank decreased .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
The table shows that the parsers adapted to Brown questions improved the parsing accuracies for QuestionBank , while the parsers adapted to QuestionBank decreased .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
The table shows that the parsers adapted to Brown questions improved the parsing accuracies for QuestionBank , while the parsers adapted to QuestionBank decreased .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
Table \REF could explain the result .
#<struct ReadData::Alignment source_numbers="4,5", target_numbers="4,5", tag_name="wa">
With Brown questions , we could learn wh-questions which QuestionBank mainly contain , while with QuestionBank , we could not we could not learn yes-no questions which more than half of Brown corpus contain .
#<struct ReadData::Alignment source_numbers="12", target_numbers="8", tag_name="wa">
With Brown questions , we could learn wh-questions which QuestionBank mainly contain , while with QuestionBank , we could not we could not learn yes-no questions which more than half of Brown corpus contain .
#<struct ReadData::Alignment source_numbers="34", target_numbers="15", tag_name="wa">
With Brown questions , we could learn wh-questions which QuestionBank mainly contain , while with QuestionBank , we could not we could not learn yes-no questions which more than half of Brown corpus contain .
#<struct ReadData::Alignment source_numbers="16", target_numbers="20", tag_name="wa">
With Brown questions , we could learn wh-questions which QuestionBank mainly contain , while with QuestionBank , we could not we could not learn yes-no questions which more than half of Brown corpus contain .
#<struct ReadData::Alignment source_numbers="27,28,29,30", target_numbers="25,26,27,28", tag_name="wa">
With Brown questions , we could learn wh-questions which QuestionBank mainly contain , while with QuestionBank , we could not we could not learn yes-no questions which more than half of Brown corpus contain .
#<struct ReadData::Alignment source_numbers="22", target_numbers="34", tag_name="wa">
With Brown questions , we could learn wh-questions which QuestionBank mainly contain , while with QuestionBank , we could not we could not learn yes-no questions which more than half of Brown corpus contain .
#<struct ReadData::Alignment source_numbers="23", target_numbers="35", tag_name="wa">
With Brown questions , we could learn wh-questions which QuestionBank mainly contain , while with QuestionBank , we could not we could not learn yes-no questions which more than half of Brown corpus contain .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
With Brown questions , we could learn wh-questions which QuestionBank mainly contain , while with QuestionBank , we could not we could not learn yes-no questions which more than half of Brown corpus contain .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
With Brown questions , we could learn wh-questions which QuestionBank mainly contain , while with QuestionBank , we could not we could not learn yes-no questions which more than half of Brown corpus contain .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
With Brown questions , we could learn wh-questions which QuestionBank mainly contain , while with QuestionBank , we could not we could not learn yes-no questions which more than half of Brown corpus contain .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
With Brown questions , we could learn wh-questions which QuestionBank mainly contain , while with QuestionBank , we could not we could not learn yes-no questions which more than half of Brown corpus contain .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
With Brown questions , we could learn wh-questions which QuestionBank mainly contain , while with QuestionBank , we could not we could not learn yes-no questions which more than half of Brown corpus contain .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
With Brown questions , we could learn wh-questions which QuestionBank mainly contain , while with QuestionBank , we could not we could not learn yes-no questions which more than half of Brown corpus contain .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
With Brown questions , we could learn wh-questions which QuestionBank mainly contain , while with QuestionBank , we could not we could not learn yes-no questions which more than half of Brown corpus contain .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
With Brown questions , we could learn wh-questions which QuestionBank mainly contain , while with QuestionBank , we could not we could not learn yes-no questions which more than half of Brown corpus contain .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
With Brown questions , we could learn wh-questions which QuestionBank mainly contain , while with QuestionBank , we could not we could not learn yes-no questions which more than half of Brown corpus contain .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
With Brown questions , we could learn wh-questions which QuestionBank mainly contain , while with QuestionBank , we could not we could not learn yes-no questions which more than half of Brown corpus contain .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
With Brown questions , we could learn wh-questions which QuestionBank mainly contain , while with QuestionBank , we could not we could not learn yes-no questions which more than half of Brown corpus contain .
#<struct ReadData::Alignment source_numbers="33", target_numbers="", tag_name="wa">
With Brown questions , we could learn wh-questions which QuestionBank mainly contain , while with QuestionBank , we could not we could not learn yes-no questions which more than half of Brown corpus contain .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
With Brown questions , we could learn wh-questions which QuestionBank mainly contain , while with QuestionBank , we could not we could not learn yes-no questions which more than half of Brown corpus contain .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
With Brown questions , we could learn wh-questions which QuestionBank mainly contain , while with QuestionBank , we could not we could not learn yes-no questions which more than half of Brown corpus contain .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
With Brown questions , we could learn wh-questions which QuestionBank mainly contain , while with QuestionBank , we could not we could not learn yes-no questions which more than half of Brown corpus contain .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
With Brown questions , we could learn wh-questions which QuestionBank mainly contain , while with QuestionBank , we could not we could not learn yes-no questions which more than half of Brown corpus contain .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
With Brown questions , we could learn wh-questions which QuestionBank mainly contain , while with QuestionBank , we could not we could not learn yes-no questions which more than half of Brown corpus contain .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
With Brown questions , we could learn wh-questions which QuestionBank mainly contain , while with QuestionBank , we could not we could not learn yes-no questions which more than half of Brown corpus contain .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
With Brown questions , we could learn wh-questions which QuestionBank mainly contain , while with QuestionBank , we could not we could not learn yes-no questions which more than half of Brown corpus contain .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
With Brown questions , we could learn wh-questions which QuestionBank mainly contain , while with QuestionBank , we could not we could not learn yes-no questions which more than half of Brown corpus contain .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
With Brown questions , we could learn wh-questions which QuestionBank mainly contain , while with QuestionBank , we could not we could not learn yes-no questions which more than half of Brown corpus contain .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
With Brown questions , we could learn wh-questions which QuestionBank mainly contain , while with QuestionBank , we could not we could not learn yes-no questions which more than half of Brown corpus contain .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
With Brown questions , we could learn wh-questions which QuestionBank mainly contain , while with QuestionBank , we could not we could not learn yes-no questions which more than half of Brown corpus contain .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
With Brown questions , we could learn wh-questions which QuestionBank mainly contain , while with QuestionBank , we could not we could not learn yes-no questions which more than half of Brown corpus contain .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
With Brown questions , we could learn wh-questions which QuestionBank mainly contain , while with QuestionBank , we could not we could not learn yes-no questions which more than half of Brown corpus contain .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
With Brown questions , we could learn wh-questions which QuestionBank mainly contain , while with QuestionBank , we could not we could not learn yes-no questions which more than half of Brown corpus contain .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
With Brown questions , we could learn wh-questions which QuestionBank mainly contain , while with QuestionBank , we could not we could not learn yes-no questions which more than half of Brown corpus contain .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
With Brown questions , we could learn wh-questions which QuestionBank mainly contain , while with QuestionBank , we could not we could not learn yes-no questions which more than half of Brown corpus contain .
#<struct ReadData::Alignment source_numbers="", target_numbers="40", tag_name="wa">
A question domain contains various types of questions and gives various sentence constructions .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
A question domain contains various types of questions and gives various sentence constructions .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
A question domain contains various types of questions and gives various sentence constructions .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
In order to parse questions correctly , we should capture each of them correctly .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
In order to parse questions correctly , we should capture each of them correctly .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
This type of problem would not be noticed so much when we were working mainly on declarative sentences .
#<struct ReadData::Alignment source_numbers="8", target_numbers="6", tag_name="wa">
This type of problem would not be noticed so much when we were working mainly on declarative sentences .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
This type of problem would not be noticed so much when we were working mainly on declarative sentences .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
This type of problem would not be noticed so much when we were working mainly on declarative sentences .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
This type of problem would not be noticed so much when we were working mainly on declarative sentences .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
This type of problem would not be noticed so much when we were working mainly on declarative sentences .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
This type of problem would not be noticed so much when we were working mainly on declarative sentences .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
This type of problem would not be noticed so much when we were working mainly on declarative sentences .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
This type of problem would not be noticed so much when we were working mainly on declarative sentences .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Through the experiments on various parsers we observed that simple supervised adaptation methods are insufficient to arrive at theparsing accuracy comparable to that of declarative sentences .
#<struct ReadData::Alignment source_numbers="20,21", target_numbers="18,19", tag_name="wa">
Through the experiments on various parsers we observed that simple supervised adaptation methods are insufficient to arrive at theparsing accuracy comparable to that of declarative sentences .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
Through the experiments on various parsers we observed that simple supervised adaptation methods are insufficient to arrive at theparsing accuracy comparable to that of declarative sentences .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
Through the experiments on various parsers we observed that simple supervised adaptation methods are insufficient to arrive at theparsing accuracy comparable to that of declarative sentences .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Through the experiments on various parsers we observed that simple supervised adaptation methods are insufficient to arrive at theparsing accuracy comparable to that of declarative sentences .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
This observation holds both for POS tagging and syntactic parsing , and itindicates that we need fundamental improvement of parsers , such as re-constructing feature designs or changing parsing models .
#<struct ReadData::Alignment source_numbers="19", target_numbers="15", tag_name="wa">
This observation holds both for POS tagging and syntactic parsing , and itindicates that we need fundamental improvement of parsers , such as re-constructing feature designs or changing parsing models .
#<struct ReadData::Alignment source_numbers="15", target_numbers="16", tag_name="wa">
This observation holds both for POS tagging and syntactic parsing , and itindicates that we need fundamental improvement of parsers , such as re-constructing feature designs or changing parsing models .
#<struct ReadData::Alignment source_numbers="16", target_numbers="19", tag_name="wa">
This observation holds both for POS tagging and syntactic parsing , and itindicates that we need fundamental improvement of parsers , such as re-constructing feature designs or changing parsing models .
#<struct ReadData::Alignment source_numbers="17,18", target_numbers="20", tag_name="wa">
This observation holds both for POS tagging and syntactic parsing , and itindicates that we need fundamental improvement of parsers , such as re-constructing feature designs or changing parsing models .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
This observation holds both for POS tagging and syntactic parsing , and itindicates that we need fundamental improvement of parsers , such as re-constructing feature designs or changing parsing models .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
This observation holds both for POS tagging and syntactic parsing , and itindicates that we need fundamental improvement of parsers , such as re-constructing feature designs or changing parsing models .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
This observation holds both for POS tagging and syntactic parsing , and itindicates that we need fundamental improvement of parsers , such as re-constructing feature designs or changing parsing models .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
This observation holds both for POS tagging and syntactic parsing , and itindicates that we need fundamental improvement of parsers , such as re-constructing feature designs or changing parsing models .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
Following the present work , future work should include investigating parsing frameworks that are robust for sentences with various sentence constructions , and / or methods that can effectively adapt a parser to different sentence constructions including imperatives , questions , and more .
#<struct ReadData::Alignment source_numbers="0", target_numbers="0", tag_name="wa">
Following the present work , future work should include investigating parsing frameworks that are robust for sentences with various sentence constructions , and / or methods that can effectively adapt a parser to different sentence constructions including imperatives , questions , and more .
#<struct ReadData::Alignment source_numbers="8", target_numbers="8", tag_name="wa">
Following the present work , future work should include investigating parsing frameworks that are robust for sentences with various sentence constructions , and / or methods that can effectively adapt a parser to different sentence constructions including imperatives , questions , and more .
#<struct ReadData::Alignment source_numbers="33", target_numbers="18", tag_name="wa">
Following the present work , future work should include investigating parsing frameworks that are robust for sentences with various sentence constructions , and / or methods that can effectively adapt a parser to different sentence constructions including imperatives , questions , and more .
#<struct ReadData::Alignment source_numbers="40", target_numbers="40", tag_name="wa">
Following the present work , future work should include investigating parsing frameworks that are robust for sentences with various sentence constructions , and / or methods that can effectively adapt a parser to different sentence constructions including imperatives , questions , and more .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Following the present work , future work should include investigating parsing frameworks that are robust for sentences with various sentence constructions , and / or methods that can effectively adapt a parser to different sentence constructions including imperatives , questions , and more .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Following the present work , future work should include investigating parsing frameworks that are robust for sentences with various sentence constructions , and / or methods that can effectively adapt a parser to different sentence constructions including imperatives , questions , and more .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
Following the present work , future work should include investigating parsing frameworks that are robust for sentences with various sentence constructions , and / or methods that can effectively adapt a parser to different sentence constructions including imperatives , questions , and more .
#<struct ReadData::Alignment source_numbers="38", target_numbers="", tag_name="wa">
Following the present work , future work should include investigating parsing frameworks that are robust for sentences with various sentence constructions , and / or methods that can effectively adapt a parser to different sentence constructions including imperatives , questions , and more .
#<struct ReadData::Alignment source_numbers="42", target_numbers="", tag_name="wa">
Following the present work , future work should include investigating parsing frameworks that are robust for sentences with various sentence constructions , and / or methods that can effectively adapt a parser to different sentence constructions including imperatives , questions , and more .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Following the present work , future work should include investigating parsing frameworks that are robust for sentences with various sentence constructions , and / or methods that can effectively adapt a parser to different sentence constructions including imperatives , questions , and more .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Following the present work , future work should include investigating parsing frameworks that are robust for sentences with various sentence constructions , and / or methods that can effectively adapt a parser to different sentence constructions including imperatives , questions , and more .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
Following the present work , future work should include investigating parsing frameworks that are robust for sentences with various sentence constructions , and / or methods that can effectively adapt a parser to different sentence constructions including imperatives , questions , and more .
#<struct ReadData::Alignment source_numbers="", target_numbers="41", tag_name="wa">
Following the present work , future work should include investigating parsing frameworks that are robust for sentences with various sentence constructions , and / or methods that can effectively adapt a parser to different sentence constructions including imperatives , questions , and more .
#<struct ReadData::Alignment source_numbers="", target_numbers="42", tag_name="wa">
While word segmentation is a necessary step to process languages like Chinese and Japanese , its effects on Statistical Machine Translation ( SMT ) have not been discussed intensively in such languages .
#<struct ReadData::Alignment source_numbers="5", target_numbers="4", tag_name="wa">
While word segmentation is a necessary step to process languages like Chinese and Japanese , its effects on Statistical Machine Translation ( SMT ) have not been discussed intensively in such languages .
#<struct ReadData::Alignment source_numbers="8", target_numbers="6,7", tag_name="wa">
While word segmentation is a necessary step to process languages like Chinese and Japanese , its effects on Statistical Machine Translation ( SMT ) have not been discussed intensively in such languages .
#<struct ReadData::Alignment source_numbers="9", target_numbers="11", tag_name="wa">
While word segmentation is a necessary step to process languages like Chinese and Japanese , its effects on Statistical Machine Translation ( SMT ) have not been discussed intensively in such languages .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
While word segmentation is a necessary step to process languages like Chinese and Japanese , its effects on Statistical Machine Translation ( SMT ) have not been discussed intensively in such languages .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
While word segmentation is a necessary step to process languages like Chinese and Japanese , its effects on Statistical Machine Translation ( SMT ) have not been discussed intensively in such languages .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
While word segmentation is a necessary step to process languages like Chinese and Japanese , its effects on Statistical Machine Translation ( SMT ) have not been discussed intensively in such languages .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
While word segmentation is a necessary step to process languages like Chinese and Japanese , its effects on Statistical Machine Translation ( SMT ) have not been discussed intensively in such languages .
#<struct ReadData::Alignment source_numbers="28", target_numbers="", tag_name="wa">
While word segmentation is a necessary step to process languages like Chinese and Japanese , its effects on Statistical Machine Translation ( SMT ) have not been discussed intensively in such languages .
#<struct ReadData::Alignment source_numbers="29", target_numbers="", tag_name="wa">
While word segmentation is a necessary step to process languages like Chinese and Japanese , its effects on Statistical Machine Translation ( SMT ) have not been discussed intensively in such languages .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
While word segmentation is a necessary step to process languages like Chinese and Japanese , its effects on Statistical Machine Translation ( SMT ) have not been discussed intensively in such languages .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
While word segmentation is a necessary step to process languages like Chinese and Japanese , its effects on Statistical Machine Translation ( SMT ) have not been discussed intensively in such languages .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
While word segmentation is a necessary step to process languages like Chinese and Japanese , its effects on Statistical Machine Translation ( SMT ) have not been discussed intensively in such languages .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
In this paper , we investigate the effects of word segmentation methods on SMT , by comparing evaluation results of translation outputs while varying word segmentation methods .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
The experiments revealed that supervised morphological analyzers were competitive , and considerably better than an unsupervised analyzer and a heuristic segmentation method .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
The experiments revealed that supervised morphological analyzers were competitive , and considerably better than an unsupervised analyzer and a heuristic segmentation method .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
The experiments revealed that supervised morphological analyzers were competitive , and considerably better than an unsupervised analyzer and a heuristic segmentation method .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
The experiments revealed that supervised morphological analyzers were competitive , and considerably better than an unsupervised analyzer and a heuristic segmentation method .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
The experiments revealed that supervised morphological analyzers were competitive , and considerably better than an unsupervised analyzer and a heuristic segmentation method .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
The experiments revealed that supervised morphological analyzers were competitive , and considerably better than an unsupervised analyzer and a heuristic segmentation method .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
However , a character-based segmentation has achieved 10 .27 positive and 1 .95 negative differences in word-based and character-based BLEU , depending on corpus sizes and domains .
#<struct ReadData::Alignment source_numbers="6", target_numbers="5", tag_name="wa">
However , a character-based segmentation has achieved 10 .27 positive and 1 .95 negative differences in word-based and character-based BLEU , depending on corpus sizes and domains .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
For this result we discuss the problem of the comparability of evaluation metrics and the possibility of better word segmentation than popular supervised morphological analyzers .
#<struct ReadData::Alignment source_numbers="16", target_numbers="17", tag_name="wa">
For this result we discuss the problem of the comparability of evaluation metrics and the possibility of better word segmentation than popular supervised morphological analyzers .
#<struct ReadData::Alignment source_numbers="17", target_numbers="18", tag_name="wa">
For this result we discuss the problem of the comparability of evaluation metrics and the possibility of better word segmentation than popular supervised morphological analyzers .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
For this result we discuss the problem of the comparability of evaluation metrics and the possibility of better word segmentation than popular supervised morphological analyzers .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
For this result we discuss the problem of the comparability of evaluation metrics and the possibility of better word segmentation than popular supervised morphological analyzers .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
For this result we discuss the problem of the comparability of evaluation metrics and the possibility of better word segmentation than popular supervised morphological analyzers .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
For this result we discuss the problem of the comparability of evaluation metrics and the possibility of better word segmentation than popular supervised morphological analyzers .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
For this result we discuss the problem of the comparability of evaluation metrics and the possibility of better word segmentation than popular supervised morphological analyzers .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
For this result we discuss the problem of the comparability of evaluation metrics and the possibility of better word segmentation than popular supervised morphological analyzers .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
For this result we discuss the problem of the comparability of evaluation metrics and the possibility of better word segmentation than popular supervised morphological analyzers .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
For this result we discuss the problem of the comparability of evaluation metrics and the possibility of better word segmentation than popular supervised morphological analyzers .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
For this result we discuss the problem of the comparability of evaluation metrics and the possibility of better word segmentation than popular supervised morphological analyzers .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
For this result we discuss the problem of the comparability of evaluation metrics and the possibility of better word segmentation than popular supervised morphological analyzers .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
For this result we discuss the problem of the comparability of evaluation metrics and the possibility of better word segmentation than popular supervised morphological analyzers .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
Several natural languages like Chinese and Japanese do not have to put spaces between words in their written forms .
#<struct ReadData::Alignment source_numbers="7", target_numbers="8", tag_name="wa">
Several natural languages like Chinese and Japanese do not have to put spaces between words in their written forms .
#<struct ReadData::Alignment source_numbers="8", target_numbers="9", tag_name="wa">
Several natural languages like Chinese and Japanese do not have to put spaces between words in their written forms .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
Several natural languages like Chinese and Japanese do not have to put spaces between words in their written forms .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Several natural languages like Chinese and Japanese do not have to put spaces between words in their written forms .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Several natural languages like Chinese and Japanese do not have to put spaces between words in their written forms .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
Several natural languages like Chinese and Japanese do not have to put spaces between words in their written forms .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Several natural languages like Chinese and Japanese do not have to put spaces between words in their written forms .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Several natural languages like Chinese and Japanese do not have to put spaces between words in their written forms .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Several natural languages like Chinese and Japanese do not have to put spaces between words in their written forms .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Several natural languages like Chinese and Japanese do not have to put spaces between words in their written forms .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Since the process is fundamental and indispensable , we need to explore how word segmentation affects Natural Language Processing applications .
#<struct ReadData::Alignment source_numbers="13", target_numbers="1", tag_name="wa">
Since the process is fundamental and indispensable , we need to explore how word segmentation affects Natural Language Processing applications .
#<struct ReadData::Alignment source_numbers="14", target_numbers="2", tag_name="wa">
Since the process is fundamental and indispensable , we need to explore how word segmentation affects Natural Language Processing applications .
#<struct ReadData::Alignment source_numbers="4", target_numbers="5", tag_name="wa">
Since the process is fundamental and indispensable , we need to explore how word segmentation affects Natural Language Processing applications .
#<struct ReadData::Alignment source_numbers="2", target_numbers="6", tag_name="wa">
Since the process is fundamental and indispensable , we need to explore how word segmentation affects Natural Language Processing applications .
#<struct ReadData::Alignment source_numbers="7", target_numbers="12", tag_name="wa">
Since the process is fundamental and indispensable , we need to explore how word segmentation affects Natural Language Processing applications .
#<struct ReadData::Alignment source_numbers="9", target_numbers="14,15", tag_name="wa">
Since the process is fundamental and indispensable , we need to explore how word segmentation affects Natural Language Processing applications .
#<struct ReadData::Alignment source_numbers="20", target_numbers="27", tag_name="wa">
Since the process is fundamental and indispensable , we need to explore how word segmentation affects Natural Language Processing applications .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Since the process is fundamental and indispensable , we need to explore how word segmentation affects Natural Language Processing applications .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Since the process is fundamental and indispensable , we need to explore how word segmentation affects Natural Language Processing applications .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Since the process is fundamental and indispensable , we need to explore how word segmentation affects Natural Language Processing applications .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Since the process is fundamental and indispensable , we need to explore how word segmentation affects Natural Language Processing applications .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Since the process is fundamental and indispensable , we need to explore how word segmentation affects Natural Language Processing applications .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Since the process is fundamental and indispensable , we need to explore how word segmentation affects Natural Language Processing applications .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Since the process is fundamental and indispensable , we need to explore how word segmentation affects Natural Language Processing applications .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
Since the process is fundamental and indispensable , we need to explore how word segmentation affects Natural Language Processing applications .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
Since the process is fundamental and indispensable , we need to explore how word segmentation affects Natural Language Processing applications .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
Therefore , we investigate how Japanese word segmentation affects on SMT between English and Japanese , by comparing various word segmentation methods and evaluation metrics .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Therefore , we investigate how Japanese word segmentation affects on SMT between English and Japanese , by comparing various word segmentation methods and evaluation metrics .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
We also examine an unsupervised morphological analyzer and its results .
#<struct ReadData::Alignment source_numbers="1", target_numbers="1", tag_name="wa">
We also examine an unsupervised morphological analyzer and its results .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
We also examine an unsupervised morphological analyzer and its results .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
We also examine an unsupervised morphological analyzer and its results .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
We also examine an unsupervised morphological analyzer and its results .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
We also examine an unsupervised morphological analyzer and its results .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
In addition , we focus on the meta-evaluation of the current evaluation metrics and find whether the metrics are consistent or not , when we vary word segmentation methods .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
In addition , we focus on the meta-evaluation of the current evaluation metrics and find whether the metrics are consistent or not , when we vary word segmentation methods .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
In addition , we focus on the meta-evaluation of the current evaluation metrics and find whether the metrics are consistent or not , when we vary word segmentation methods .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
In addition , we focus on the meta-evaluation of the current evaluation metrics and find whether the metrics are consistent or not , when we vary word segmentation methods .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
In addition , we focus on the meta-evaluation of the current evaluation metrics and find whether the metrics are consistent or not , when we vary word segmentation methods .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
They acquired the 2 .3 score improvement from the worst to the best combinations .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
They acquired the 2 .3 score improvement from the worst to the best combinations .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
They acquired the 2 .3 score improvement from the worst to the best combinations .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
They acquired the 2 .3 score improvement from the worst to the best combinations .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
They acquired the 2 .3 score improvement from the worst to the best combinations .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
( 2010 ) suggested a new short unit word segmentation standard in Chinese which defines a more frequent string subset as a word .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
For instance , They separated one word " 全球化 globalization " into two words " 全球 global " and " 化 -lization " .
#<struct ReadData::Alignment source_numbers="4", target_numbers="8", tag_name="wa">
For instance , They separated one word " 全球化 globalization " into two words " 全球 global " and " 化 -lization " .
#<struct ReadData::Alignment source_numbers="23", target_numbers="17", tag_name="wa">
For instance , They separated one word " 全球化 globalization " into two words " 全球 global " and " 化 -lization " .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
For instance , They separated one word " 全球化 globalization " into two words " 全球 global " and " 化 -lization " .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
For instance , They separated one word " 全球化 globalization " into two words " 全球 global " and " 化 -lization " .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
For instance , They separated one word " 全球化 globalization " into two words " 全球 global " and " 化 -lization " .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
For instance , They separated one word " 全球化 globalization " into two words " 全球 global " and " 化 -lization " .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
For instance , They separated one word " 全球化 globalization " into two words " 全球 global " and " 化 -lization " .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
For instance , They separated one word " 全球化 globalization " into two words " 全球 global " and " 化 -lization " .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
For instance , They separated one word " 全球化 globalization " into two words " 全球 global " and " 化 -lization " .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
For instance , They separated one word " 全球化 globalization " into two words " 全球 global " and " 化 -lization " .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
For instance , They separated one word " 全球化 globalization " into two words " 全球 global " and " 化 -lization " .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
For instance , They separated one word " 全球化 globalization " into two words " 全球 global " and " 化 -lization " .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
For instance , They separated one word " 全球化 globalization " into two words " 全球 global " and " 化 -lization " .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
For instance , They separated one word " 全球化 globalization " into two words " 全球 global " and " 化 -lization " .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
For instance , They separated one word " 全球化 globalization " into two words " 全球 global " and " 化 -lization " .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
For instance , They separated one word " 全球化 globalization " into two words " 全球 global " and " 化 -lization " .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
For instance , They separated one word " 全球化 globalization " into two words " 全球 global " and " 化 -lization " .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
For instance , They separated one word " 全球化 globalization " into two words " 全球 global " and " 化 -lization " .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
For instance , They separated one word " 全球化 globalization " into two words " 全球 global " and " 化 -lization " .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
For instance , They separated one word " 全球化 globalization " into two words " 全球 global " and " 化 -lization " .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
For instance , They separated one word " 全球化 globalization " into two words " 全球 global " and " 化 -lization " .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
Though , they have not discussed about BLEU is a good metric for such an evaluation of word segmentation .
#<struct ReadData::Alignment source_numbers="2,3", target_numbers="3", tag_name="wa">
Though , they have not discussed about BLEU is a good metric for such an evaluation of word segmentation .
#<struct ReadData::Alignment source_numbers="4", target_numbers="4", tag_name="wa">
Though , they have not discussed about BLEU is a good metric for such an evaluation of word segmentation .
#<struct ReadData::Alignment source_numbers="5", target_numbers="7", tag_name="wa">
Though , they have not discussed about BLEU is a good metric for such an evaluation of word segmentation .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Though , they have not discussed about BLEU is a good metric for such an evaluation of word segmentation .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
Though , they have not discussed about BLEU is a good metric for such an evaluation of word segmentation .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Though , they have not discussed about BLEU is a good metric for such an evaluation of word segmentation .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Though , they have not discussed about BLEU is a good metric for such an evaluation of word segmentation .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Though , they have not discussed about BLEU is a good metric for such an evaluation of word segmentation .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Though , they have not discussed about BLEU is a good metric for such an evaluation of word segmentation .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
In addition , comparison of morphological analyzers are necessary because different analyzers produce different outputs to SMT .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Therefore , we conduct several translation tasks between English and Japanese .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Therefore , we conduct several translation tasks between English and Japanese .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Therefore , we conduct several translation tasks between English and Japanese .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Therefore , we conduct several translation tasks between English and Japanese .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Therefore , we conduct several translation tasks between English and Japanese .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
This work aims to empirically compare representative word segmentation methods in terms of SMT quality .
#<struct ReadData::Alignment source_numbers="2,3", target_numbers="2,3", tag_name="wa">
- Whether or not SMT evaluation metrics provide a consistent measure while varying word segmentation methods .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
We setup word segmentation methods , corpora , and evaluation metrics as three parameters of our experiments to see the effects of Japanese word segmentation on SMT .
#<struct ReadData::Alignment source_numbers="19", target_numbers="14", tag_name="wa">
We setup word segmentation methods , corpora , and evaluation metrics as three parameters of our experiments to see the effects of Japanese word segmentation on SMT .
#<struct ReadData::Alignment source_numbers="17", target_numbers="23", tag_name="wa">
We setup word segmentation methods , corpora , and evaluation metrics as three parameters of our experiments to see the effects of Japanese word segmentation on SMT .
#<struct ReadData::Alignment source_numbers="27", target_numbers="33", tag_name="wa">
We setup word segmentation methods , corpora , and evaluation metrics as three parameters of our experiments to see the effects of Japanese word segmentation on SMT .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
We setup word segmentation methods , corpora , and evaluation metrics as three parameters of our experiments to see the effects of Japanese word segmentation on SMT .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
We setup word segmentation methods , corpora , and evaluation metrics as three parameters of our experiments to see the effects of Japanese word segmentation on SMT .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
We setup word segmentation methods , corpora , and evaluation metrics as three parameters of our experiments to see the effects of Japanese word segmentation on SMT .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
We setup word segmentation methods , corpora , and evaluation metrics as three parameters of our experiments to see the effects of Japanese word segmentation on SMT .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
We setup word segmentation methods , corpora , and evaluation metrics as three parameters of our experiments to see the effects of Japanese word segmentation on SMT .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
We setup word segmentation methods , corpora , and evaluation metrics as three parameters of our experiments to see the effects of Japanese word segmentation on SMT .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
We setup word segmentation methods , corpora , and evaluation metrics as three parameters of our experiments to see the effects of Japanese word segmentation on SMT .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
We setup word segmentation methods , corpora , and evaluation metrics as three parameters of our experiments to see the effects of Japanese word segmentation on SMT .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
We setup word segmentation methods , corpora , and evaluation metrics as three parameters of our experiments to see the effects of Japanese word segmentation on SMT .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
As shown in Table 1 , the following word segmentation methods output delimiters ( " | " represents a delimiter ) for a given input character sequence .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
As shown in Table 1 , the following word segmentation methods output delimiters ( " | " represents a delimiter ) for a given input character sequence .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
As shown in Table 1 , the following word segmentation methods output delimiters ( " | " represents a delimiter ) for a given input character sequence .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
As shown in Table 1 , the following word segmentation methods output delimiters ( " | " represents a delimiter ) for a given input character sequence .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
It is , however , not clear which analyzer works better for the SMT task than the other analyzers .
#<struct ReadData::Alignment source_numbers="4", target_numbers="4", tag_name="wa">
It is , however , not clear which analyzer works better for the SMT task than the other analyzers .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
It is , however , not clear which analyzer works better for the SMT task than the other analyzers .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
It is , however , not clear which analyzer works better for the SMT task than the other analyzers .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
It is , however , not clear which analyzer works better for the SMT task than the other analyzers .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
It is , however , not clear which analyzer works better for the SMT task than the other analyzers .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
It is , however , not clear which analyzer works better for the SMT task than the other analyzers .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
It is , however , not clear which analyzer works better for the SMT task than the other analyzers .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
It is , however , not clear which analyzer works better for the SMT task than the other analyzers .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
- JUMAN also regards word segmentation as a sequence labeling , but it decides the minimum cost paths without machine learning , from segmentation and association costs in human annotated lexicons and automatically generated Web lexicons .
#<struct ReadData::Alignment source_numbers="9", target_numbers="9", tag_name="wa">
- JUMAN also regards word segmentation as a sequence labeling , but it decides the minimum cost paths without machine learning , from segmentation and association costs in human annotated lexicons and automatically generated Web lexicons .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
The accuracy of supervised morphological analyzers KyTea , MeCab , and JUMAN is reported to be over 98\% for news text .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
The accuracy of supervised morphological analyzers KyTea , MeCab , and JUMAN is reported to be over 98\% for news text .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
On the other hand , the unsupervised method latticelm achieved 66 .6% accuracy ( Mochihashi et al. , 2009 ) for human annotated news text , while the method does not have any answers of word definitions .
#<struct ReadData::Alignment source_numbers="17", target_numbers="8", tag_name="wa">
On the other hand , the unsupervised method latticelm achieved 66 .6% accuracy ( Mochihashi et al. , 2009 ) for human annotated news text , while the method does not have any answers of word definitions .
#<struct ReadData::Alignment source_numbers="25", target_numbers="10", tag_name="wa">
On the other hand , the unsupervised method latticelm achieved 66 .6% accuracy ( Mochihashi et al. , 2009 ) for human annotated news text , while the method does not have any answers of word definitions .
#<struct ReadData::Alignment source_numbers="34", target_numbers="", tag_name="wa">
On the other hand , the unsupervised method latticelm achieved 66 .6% accuracy ( Mochihashi et al. , 2009 ) for human annotated news text , while the method does not have any answers of word definitions .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
On the other hand , the unsupervised method latticelm achieved 66 .6% accuracy ( Mochihashi et al. , 2009 ) for human annotated news text , while the method does not have any answers of word definitions .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
On the other hand , the unsupervised method latticelm achieved 66 .6% accuracy ( Mochihashi et al. , 2009 ) for human annotated news text , while the method does not have any answers of word definitions .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
Therefore , it is not possible to compare such a result with the supervised results . Even though , it is fair to compare it with SMT contribution point of view .
#<struct ReadData::Alignment source_numbers="18", target_numbers="14", tag_name="wa">
Therefore , it is not possible to compare such a result with the supervised results . Even though , it is fair to compare it with SMT contribution point of view .
#<struct ReadData::Alignment source_numbers="15", target_numbers="28", tag_name="wa">
Therefore , it is not possible to compare such a result with the supervised results . Even though , it is fair to compare it with SMT contribution point of view .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Therefore , it is not possible to compare such a result with the supervised results . Even though , it is fair to compare it with SMT contribution point of view .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Therefore , it is not possible to compare such a result with the supervised results . Even though , it is fair to compare it with SMT contribution point of view .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
Therefore , it is not possible to compare such a result with the supervised results . Even though , it is fair to compare it with SMT contribution point of view .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
Therefore , it is not possible to compare such a result with the supervised results . Even though , it is fair to compare it with SMT contribution point of view .
#<struct ReadData::Alignment source_numbers="28", target_numbers="", tag_name="wa">
Therefore , it is not possible to compare such a result with the supervised results . Even though , it is fair to compare it with SMT contribution point of view .
#<struct ReadData::Alignment source_numbers="29", target_numbers="", tag_name="wa">
Therefore , it is not possible to compare such a result with the supervised results . Even though , it is fair to compare it with SMT contribution point of view .
#<struct ReadData::Alignment source_numbers="30", target_numbers="", tag_name="wa">
Therefore , it is not possible to compare such a result with the supervised results . Even though , it is fair to compare it with SMT contribution point of view .
#<struct ReadData::Alignment source_numbers="31", target_numbers="", tag_name="wa">
Therefore , it is not possible to compare such a result with the supervised results . Even though , it is fair to compare it with SMT contribution point of view .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Therefore , it is not possible to compare such a result with the supervised results . Even though , it is fair to compare it with SMT contribution point of view .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
Therefore , it is not possible to compare such a result with the supervised results . Even though , it is fair to compare it with SMT contribution point of view .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
Therefore , it is not possible to compare such a result with the supervised results . Even though , it is fair to compare it with SMT contribution point of view .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
Furthermore , their policies about word segmentation definitions are very much different .
#<struct ReadData::Alignment source_numbers="11", target_numbers="8", tag_name="wa">
Furthermore , their policies about word segmentation definitions are very much different .
#<struct ReadData::Alignment source_numbers="10", target_numbers="9", tag_name="wa">
Furthermore , their policies about word segmentation definitions are very much different .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Furthermore , their policies about word segmentation definitions are very much different .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
While MeCab can change its definitions by external lexicons and JUMAN has its own internal standard , KyTea is based on the short unit standard of Balanced Corpus of Contemporary Written Japanese , which is considered one of the shortest definitions of Japanese words .
#<struct ReadData::Alignment source_numbers="32", target_numbers="9", tag_name="wa">
While MeCab can change its definitions by external lexicons and JUMAN has its own internal standard , KyTea is based on the short unit standard of Balanced Corpus of Contemporary Written Japanese , which is considered one of the shortest definitions of Japanese words .
#<struct ReadData::Alignment source_numbers="38", target_numbers="27", tag_name="wa">
While MeCab can change its definitions by external lexicons and JUMAN has its own internal standard , KyTea is based on the short unit standard of Balanced Corpus of Contemporary Written Japanese , which is considered one of the shortest definitions of Japanese words .
#<struct ReadData::Alignment source_numbers="44", target_numbers="48", tag_name="wa">
While MeCab can change its definitions by external lexicons and JUMAN has its own internal standard , KyTea is based on the short unit standard of Balanced Corpus of Contemporary Written Japanese , which is considered one of the shortest definitions of Japanese words .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
While MeCab can change its definitions by external lexicons and JUMAN has its own internal standard , KyTea is based on the short unit standard of Balanced Corpus of Contemporary Written Japanese , which is considered one of the shortest definitions of Japanese words .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
While MeCab can change its definitions by external lexicons and JUMAN has its own internal standard , KyTea is based on the short unit standard of Balanced Corpus of Contemporary Written Japanese , which is considered one of the shortest definitions of Japanese words .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
While MeCab can change its definitions by external lexicons and JUMAN has its own internal standard , KyTea is based on the short unit standard of Balanced Corpus of Contemporary Written Japanese , which is considered one of the shortest definitions of Japanese words .
#<struct ReadData::Alignment source_numbers="", target_numbers="42", tag_name="wa">
For example , if we are given a string " 見れば( if someone see ) " , MeCab separates it into two words " 見れ | ば " and JUMAN keep the same string , but KyTea outputs it as three words " 見 | れ | ば " where every character is a word .
#<struct ReadData::Alignment source_numbers="34", target_numbers="9", tag_name="wa">
For example , if we are given a string " 見れば( if someone see ) " , MeCab separates it into two words " 見れ | ば " and JUMAN keep the same string , but KyTea outputs it as three words " 見 | れ | ば " where every character is a word .
#<struct ReadData::Alignment source_numbers="25", target_numbers="24", tag_name="wa">
For example , if we are given a string " 見れば( if someone see ) " , MeCab separates it into two words " 見れ | ば " and JUMAN keep the same string , but KyTea outputs it as three words " 見 | れ | ば " where every character is a word .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
For example , if we are given a string " 見れば( if someone see ) " , MeCab separates it into two words " 見れ | ば " and JUMAN keep the same string , but KyTea outputs it as three words " 見 | れ | ば " where every character is a word .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
For example , if we are given a string " 見れば( if someone see ) " , MeCab separates it into two words " 見れ | ば " and JUMAN keep the same string , but KyTea outputs it as three words " 見 | れ | ば " where every character is a word .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
For example , if we are given a string " 見れば( if someone see ) " , MeCab separates it into two words " 見れ | ば " and JUMAN keep the same string , but KyTea outputs it as three words " 見 | れ | ば " where every character is a word .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
For example , if we are given a string " 見れば( if someone see ) " , MeCab separates it into two words " 見れ | ば " and JUMAN keep the same string , but KyTea outputs it as three words " 見 | れ | ば " where every character is a word .
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
For example , if we are given a string " 見れば( if someone see ) " , MeCab separates it into two words " 見れ | ば " and JUMAN keep the same string , but KyTea outputs it as three words " 見 | れ | ば " where every character is a word .
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
For example , if we are given a string " 見れば( if someone see ) " , MeCab separates it into two words " 見れ | ば " and JUMAN keep the same string , but KyTea outputs it as three words " 見 | れ | ば " where every character is a word .
#<struct ReadData::Alignment source_numbers="26", target_numbers="", tag_name="wa">
For example , if we are given a string " 見れば( if someone see ) " , MeCab separates it into two words " 見れ | ば " and JUMAN keep the same string , but KyTea outputs it as three words " 見 | れ | ば " where every character is a word .
#<struct ReadData::Alignment source_numbers="27", target_numbers="", tag_name="wa">
For example , if we are given a string " 見れば( if someone see ) " , MeCab separates it into two words " 見れ | ば " and JUMAN keep the same string , but KyTea outputs it as three words " 見 | れ | ば " where every character is a word .
#<struct ReadData::Alignment source_numbers="42", target_numbers="", tag_name="wa">
For example , if we are given a string " 見れば( if someone see ) " , MeCab separates it into two words " 見れ | ば " and JUMAN keep the same string , but KyTea outputs it as three words " 見 | れ | ば " where every character is a word .
#<struct ReadData::Alignment source_numbers="43", target_numbers="", tag_name="wa">
For example , if we are given a string " 見れば( if someone see ) " , MeCab separates it into two words " 見れ | ば " and JUMAN keep the same string , but KyTea outputs it as three words " 見 | れ | ば " where every character is a word .
#<struct ReadData::Alignment source_numbers="47", target_numbers="", tag_name="wa">
For example , if we are given a string " 見れば( if someone see ) " , MeCab separates it into two words " 見れ | ば " and JUMAN keep the same string , but KyTea outputs it as three words " 見 | れ | ば " where every character is a word .
#<struct ReadData::Alignment source_numbers="48", target_numbers="", tag_name="wa">
For example , if we are given a string " 見れば( if someone see ) " , MeCab separates it into two words " 見れ | ば " and JUMAN keep the same string , but KyTea outputs it as three words " 見 | れ | ば " where every character is a word .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
For example , if we are given a string " 見れば( if someone see ) " , MeCab separates it into two words " 見れ | ば " and JUMAN keep the same string , but KyTea outputs it as three words " 見 | れ | ば " where every character is a word .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
For example , if we are given a string " 見れば( if someone see ) " , MeCab separates it into two words " 見れ | ば " and JUMAN keep the same string , but KyTea outputs it as three words " 見 | れ | ば " where every character is a word .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
For example , if we are given a string " 見れば( if someone see ) " , MeCab separates it into two words " 見れ | ば " and JUMAN keep the same string , but KyTea outputs it as three words " 見 | れ | ば " where every character is a word .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
For example , if we are given a string " 見れば( if someone see ) " , MeCab separates it into two words " 見れ | ば " and JUMAN keep the same string , but KyTea outputs it as three words " 見 | れ | ば " where every character is a word .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
For example , if we are given a string " 見れば( if someone see ) " , MeCab separates it into two words " 見れ | ば " and JUMAN keep the same string , but KyTea outputs it as three words " 見 | れ | ば " where every character is a word .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
For example , if we are given a string " 見れば( if someone see ) " , MeCab separates it into two words " 見れ | ば " and JUMAN keep the same string , but KyTea outputs it as three words " 見 | れ | ば " where every character is a word .
#<struct ReadData::Alignment source_numbers="", target_numbers="40", tag_name="wa">
For example , if we are given a string " 見れば( if someone see ) " , MeCab separates it into two words " 見れ | ば " and JUMAN keep the same string , but KyTea outputs it as three words " 見 | れ | ば " where every character is a word .
#<struct ReadData::Alignment source_numbers="", target_numbers="41", tag_name="wa">
For example , if we are given a string " 見れば( if someone see ) " , MeCab separates it into two words " 見れ | ば " and JUMAN keep the same string , but KyTea outputs it as three words " 見 | れ | ば " where every character is a word .
#<struct ReadData::Alignment source_numbers="", target_numbers="45", tag_name="wa">
In the case of latticelm , as it has no supervised definition of words , it uses the expectation maximized length of words for every word depending on training data .
#<struct ReadData::Alignment source_numbers="1", target_numbers="26", tag_name="wa">
In the case of latticelm , as it has no supervised definition of words , it uses the expectation maximized length of words for every word depending on training data .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
In the case of latticelm , as it has no supervised definition of words , it uses the expectation maximized length of words for every word depending on training data .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
In the case of latticelm , as it has no supervised definition of words , it uses the expectation maximized length of words for every word depending on training data .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
In the case of latticelm , as it has no supervised definition of words , it uses the expectation maximized length of words for every word depending on training data .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
In the case of latticelm , as it has no supervised definition of words , it uses the expectation maximized length of words for every word depending on training data .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
In the case of latticelm , as it has no supervised definition of words , it uses the expectation maximized length of words for every word depending on training data .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
In the case of latticelm , as it has no supervised definition of words , it uses the expectation maximized length of words for every word depending on training data .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
We also investigate such morphological analysis accuracy and word definition problems in our experiments .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
We also investigate such morphological analysis accuracy and word definition problems in our experiments .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
We also investigate such morphological analysis accuracy and word definition problems in our experiments .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
We also investigate such morphological analysis accuracy and word definition problems in our experiments .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
We also investigate such morphological analysis accuracy and word definition problems in our experiments .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
One is segmentation by character category ( CAT ) , and the other is segmentation by characters ( CHAR ) .
#<struct ReadData::Alignment source_numbers="0", target_numbers="0", tag_name="wa">
One is segmentation by character category ( CAT ) , and the other is segmentation by characters ( CHAR ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
The CHAR method considers every Unicode character as a word as proposed by Xu et al.
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Another corpus we use in the experiments is a Wikipedia corpus , Japanese-English Bilingual Corpus of Wikipedia 's Kyoto Articles 2 .01 ( WIKIPEDIA ) .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
Another corpus we use in the experiments is a Wikipedia corpus , Japanese-English Bilingual Corpus of Wikipedia 's Kyoto Articles 2 .01 ( WIKIPEDIA ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
From these corpora , we prepared three data sets as explained below .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
In the case of REUTERS , we have used all 56 ,282 sentences .
#<struct ReadData::Alignment source_numbers="8", target_numbers="4", tag_name="wa">
In the case of REUTERS , we have used all 56 ,282 sentences .
#<struct ReadData::Alignment source_numbers="13", target_numbers="9", tag_name="wa">
In the case of REUTERS , we have used all 56 ,282 sentences .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
In the case of REUTERS , we have used all 56 ,282 sentences .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
In the case of REUTERS , we have used all 56 ,282 sentences .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
In the case of REUTERS , we have used all 56 ,282 sentences .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
In the case of REUTERS , we have used all 56 ,282 sentences .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
In the case of REUTERS , we have used all 56 ,282 sentences .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
In this data , we have combined JENAAD and REUTERS news corpora to get one news corpus .
#<struct ReadData::Alignment source_numbers="6", target_numbers="5", tag_name="wa">
In this data , we have combined JENAAD and REUTERS news corpora to get one news corpus .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
In this data , we have combined JENAAD and REUTERS news corpora to get one news corpus .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
In this data , we have combined JENAAD and REUTERS news corpora to get one news corpus .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
In this data , we have combined JENAAD and REUTERS news corpora to get one news corpus .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
We have used all 56 ,282 and 150 ,000 sentences respectively .
#<struct ReadData::Alignment source_numbers="2", target_numbers="1", tag_name="wa">
We have used all 56 ,282 and 150 ,000 sentences respectively .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
We have used all 56 ,282 and 150 ,000 sentences respectively .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
For each corpus , we divide it into the first 1 ,000 , the next 500 , and the rest for test , development , and training .
#<struct ReadData::Alignment source_numbers="18", target_numbers="6", tag_name="wa">
For each corpus , we divide it into the first 1 ,000 , the next 500 , and the rest for test , development , and training .
#<struct ReadData::Alignment source_numbers="20", target_numbers="13", tag_name="wa">
For each corpus , we divide it into the first 1 ,000 , the next 500 , and the rest for test , development , and training .
#<struct ReadData::Alignment source_numbers="21", target_numbers="14", tag_name="wa">
For each corpus , we divide it into the first 1 ,000 , the next 500 , and the rest for test , development , and training .
#<struct ReadData::Alignment source_numbers="22", target_numbers="15", tag_name="wa">
For each corpus , we divide it into the first 1 ,000 , the next 500 , and the rest for test , development , and training .
#<struct ReadData::Alignment source_numbers="24", target_numbers="21", tag_name="wa">
For each corpus , we divide it into the first 1 ,000 , the next 500 , and the rest for test , development , and training .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
For each corpus , we divide it into the first 1 ,000 , the next 500 , and the rest for test , development , and training .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
For each corpus , we divide it into the first 1 ,000 , the next 500 , and the rest for test , development , and training .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
For each corpus , we divide it into the first 1 ,000 , the next 500 , and the rest for test , development , and training .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
For each corpus , we divide it into the first 1 ,000 , the next 500 , and the rest for test , development , and training .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
For each corpus , we divide it into the first 1 ,000 , the next 500 , and the rest for test , development , and training .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
For each corpus , we divide it into the first 1 ,000 , the next 500 , and the rest for test , development , and training .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
For each corpus , we divide it into the first 1 ,000 , the next 500 , and the rest for test , development , and training .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
For each corpus , we divide it into the first 1 ,000 , the next 500 , and the rest for test , development , and training .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
For each corpus , we divide it into the first 1 ,000 , the next 500 , and the rest for test , development , and training .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
We have gathered 2000 , 1000 , and 203 ,782 sentences for test , development , and training , respectively , in total .
#<struct ReadData::Alignment source_numbers="22", target_numbers="1", tag_name="wa">
We have gathered 2000 , 1000 , and 203 ,782 sentences for test , development , and training , respectively , in total .
#<struct ReadData::Alignment source_numbers="20", target_numbers="2", tag_name="wa">
We have gathered 2000 , 1000 , and 203 ,782 sentences for test , development , and training , respectively , in total .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
We have gathered 2000 , 1000 , and 203 ,782 sentences for test , development , and training , respectively , in total .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
We have gathered 2000 , 1000 , and 203 ,782 sentences for test , development , and training , respectively , in total .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
We have gathered 2000 , 1000 , and 203 ,782 sentences for test , development , and training , respectively , in total .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
We have gathered 2000 , 1000 , and 203 ,782 sentences for test , development , and training , respectively , in total .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Firstly , since the WIKIPEDIA corpus is a multi-category XML dataset , we have sorted them by the DOCID in the ascending order and by the document categories LTT , EPR , FML , BDS , CLT , BLD , GNM , SCL , ROD , SNT , PNM , HST , RLW , and SAT .
#<struct ReadData::Alignment source_numbers="14", target_numbers="11", tag_name="wa">
Firstly , since the WIKIPEDIA corpus is a multi-category XML dataset , we have sorted them by the DOCID in the ascending order and by the document categories LTT , EPR , FML , BDS , CLT , BLD , GNM , SCL , ROD , SNT , PNM , HST , RLW , and SAT .
#<struct ReadData::Alignment source_numbers="1", target_numbers="19", tag_name="wa">
Firstly , since the WIKIPEDIA corpus is a multi-category XML dataset , we have sorted them by the DOCID in the ascending order and by the document categories LTT , EPR , FML , BDS , CLT , BLD , GNM , SCL , ROD , SNT , PNM , HST , RLW , and SAT .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Firstly , since the WIKIPEDIA corpus is a multi-category XML dataset , we have sorted them by the DOCID in the ascending order and by the document categories LTT , EPR , FML , BDS , CLT , BLD , GNM , SCL , ROD , SNT , PNM , HST , RLW , and SAT .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Firstly , since the WIKIPEDIA corpus is a multi-category XML dataset , we have sorted them by the DOCID in the ascending order and by the document categories LTT , EPR , FML , BDS , CLT , BLD , GNM , SCL , ROD , SNT , PNM , HST , RLW , and SAT .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
Firstly , since the WIKIPEDIA corpus is a multi-category XML dataset , we have sorted them by the DOCID in the ascending order and by the document categories LTT , EPR , FML , BDS , CLT , BLD , GNM , SCL , ROD , SNT , PNM , HST , RLW , and SAT .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Firstly , since the WIKIPEDIA corpus is a multi-category XML dataset , we have sorted them by the DOCID in the ascending order and by the document categories LTT , EPR , FML , BDS , CLT , BLD , GNM , SCL , ROD , SNT , PNM , HST , RLW , and SAT .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
Secondly , we parsed it by xml .etree .ElementTree .parse of Python 2 .7 .2 , and obtained 477 ,036 sentence pairs without parsing errors .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Secondly , we parsed it by xml .etree .ElementTree .parse of Python 2 .7 .2 , and obtained 477 ,036 sentence pairs without parsing errors .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Thirdly , sentence pairs that include a character " | " in English or Japanese are removed because it caused a problem with Moses .
#<struct ReadData::Alignment source_numbers="15", target_numbers="13", tag_name="wa">
Thirdly , sentence pairs that include a character " | " in English or Japanese are removed because it caused a problem with Moses .
#<struct ReadData::Alignment source_numbers="16", target_numbers="14", tag_name="wa">
Thirdly , sentence pairs that include a character " | " in English or Japanese are removed because it caused a problem with Moses .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Thirdly , sentence pairs that include a character " | " in English or Japanese are removed because it caused a problem with Moses .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Thirdly , sentence pairs that include a character " | " in English or Japanese are removed because it caused a problem with Moses .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Thirdly , sentence pairs that include a character " | " in English or Japanese are removed because it caused a problem with Moses .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Thirdly , sentence pairs that include a character " | " in English or Japanese are removed because it caused a problem with Moses .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Thirdly , sentence pairs that include a character " | " in English or Japanese are removed because it caused a problem with Moses .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Thirdly , sentence pairs that include a character " | " in English or Japanese are removed because it caused a problem with Moses .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
In order to adjust the balance of the domains , we have sampled the data twice : First we extract the first line for every 477 lines .
#<struct ReadData::Alignment source_numbers="12", target_numbers="11", tag_name="wa">
In order to adjust the balance of the domains , we have sampled the data twice : First we extract the first line for every 477 lines .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
In order to adjust the balance of the domains , we have sampled the data twice : First we extract the first line for every 477 lines .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
After this , we have merged the remaining 476 ,012 lines and from this extract the first line for every 952 lines .
#<struct ReadData::Alignment source_numbers="5", target_numbers="3", tag_name="wa">
After this , we have merged the remaining 476 ,012 lines and from this extract the first line for every 952 lines .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
After this , we have merged the remaining 476 ,012 lines and from this extract the first line for every 952 lines .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
After this , we have merged the remaining 476 ,012 lines and from this extract the first line for every 952 lines .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
After this , we have merged the remaining 476 ,012 lines and from this extract the first line for every 952 lines .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
After this , we have merged the remaining 476 ,012 lines and from this extract the first line for every 952 lines .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
After this , we have merged the remaining 476 ,012 lines and from this extract the first line for every 952 lines .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
After this , we have merged the remaining 476 ,012 lines and from this extract the first line for every 952 lines .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
After this , we have merged the remaining 476 ,012 lines and from this extract the first line for every 952 lines .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
Finally , we have obtained 1 ,000 test , 500 development , and 475 ,512 training data .
#<struct ReadData::Alignment source_numbers="4", target_numbers="3", tag_name="wa">
Finally , we have obtained 1 ,000 test , 500 development , and 475 ,512 training data .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
Currently , the most popular way to evaluate Statistical Machine Translation is to use word-based evaluation metrics such as BLEU and RIBES .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Currently , the most popular way to evaluate Statistical Machine Translation is to use word-based evaluation metrics such as BLEU and RIBES .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Currently , the most popular way to evaluate Statistical Machine Translation is to use word-based evaluation metrics such as BLEU and RIBES .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Currently , the most popular way to evaluate Statistical Machine Translation is to use word-based evaluation metrics such as BLEU and RIBES .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Currently , the most popular way to evaluate Statistical Machine Translation is to use word-based evaluation metrics such as BLEU and RIBES .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
For example , in the case of English-Japanese translations , we must tokenize reference data to evaluate SMT outputs .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
For example , in the case of English-Japanese translations , we must tokenize reference data to evaluate SMT outputs .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
For example , in the case of English-Japanese translations , we must tokenize reference data to evaluate SMT outputs .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
For example , in the case of English-Japanese translations , we must tokenize reference data to evaluate SMT outputs .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
For example , in the case of English-Japanese translations , we must tokenize reference data to evaluate SMT outputs .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
On the other hand , in the case of Japanese-English translations , we must tokenize test data to evaluate the outputs .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
On the other hand , in the case of Japanese-English translations , we must tokenize test data to evaluate the outputs .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
On the other hand , in the case of Japanese-English translations , we must tokenize test data to evaluate the outputs .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
On the other hand , in the case of Japanese-English translations , we must tokenize test data to evaluate the outputs .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
On the other hand , in the case of Japanese-English translations , we must tokenize test data to evaluate the outputs .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
As a result , we need to tokenize every sentence by word segmentation before evaluation , and it is hard to independently evaluate the effects of word segmentation on training data .
#<struct ReadData::Alignment source_numbers="19,20", target_numbers="20,21", tag_name="wa">
As a result , we need to tokenize every sentence by word segmentation before evaluation , and it is hard to independently evaluate the effects of word segmentation on training data .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
However , our preliminary experiments showed that the results obtained with this method were not independent from word segmentation of training data .
#<struct ReadData::Alignment source_numbers="5,6", target_numbers="5,6", tag_name="wa">
However , our preliminary experiments showed that the results obtained with this method were not independent from word segmentation of training data .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
And the best results were obtained when we use the same word segmentation as the training data .
#<struct ReadData::Alignment source_numbers="8,9", target_numbers="7,8", tag_name="wa">
And the best results were obtained when we use the same word segmentation as the training data .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
And the best results were obtained when we use the same word segmentation as the training data .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
And the best results were obtained when we use the same word segmentation as the training data .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Hence , this problem remains if we keep our word-based evaluations .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
In order to manage such a problem , we use one character-based metric BLEU in Characters ( De-noual and Lepage , 2005 ) with 4-gram .
#<struct ReadData::Alignment source_numbers="6", target_numbers="5", tag_name="wa">
In order to manage such a problem , we use one character-based metric BLEU in Characters ( De-noual and Lepage , 2005 ) with 4-gram .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
In order to manage such a problem , we use one character-based metric BLEU in Characters ( De-noual and Lepage , 2005 ) with 4-gram .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
In order to manage such a problem , we use one character-based metric BLEU in Characters ( De-noual and Lepage , 2005 ) with 4-gram .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
As this method evaluates the character-level information , outputs are not required to be segmented and it is free from word segmentation variations .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
We have conducted English and Japanese machine translation in both directions by the following steps :
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
We have conducted English and Japanese machine translation in both directions by the following steps :
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
1Apply the Head-Finalization ( Isozaki et al. , 2010b ) to English text in the case of English-Japanese translation .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
1Apply the Head-Finalization ( Isozaki et al. , 2010b ) to English text in the case of English-Japanese translation .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
1Apply the Head-Finalization ( Isozaki et al. , 2010b ) to English text in the case of English-Japanese translation .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
2Run Japanese word segmentation methods and a normalization script which was introduced by the NTCIR-9 PATMT task .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
2Run Japanese word segmentation methods and a normalization script which was introduced by the NTCIR-9 PATMT task .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
2Run Japanese word segmentation methods and a normalization script which was introduced by the NTCIR-9 PATMT task .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
2Run Japanese word segmentation methods and a normalization script which was introduced by the NTCIR-9 PATMT task .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
3Tokenize and lowercase English text by Moses' tokenizer and lowercase scripts .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
3Tokenize and lowercase English text by Moses' tokenizer and lowercase scripts .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
3Tokenize and lowercase English text by Moses' tokenizer and lowercase scripts .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
4Create language models from target languages' training data , with SRILM 1 .5 .12 .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
4Create language models from target languages' training data , with SRILM 1 .5 .12 .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
4Create language models from target languages' training data , with SRILM 1 .5 .12 .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
5Create translation models with Giza++ 1 .0 .5 ( 2011-09-24 ) .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
5Create translation models with Giza++ 1 .0 .5 ( 2011-09-24 ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
5Create translation models with Giza++ 1 .0 .5 ( 2011-09-24 ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
6Decode source test data with Moses ( 2010-08-13 ) .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
6Decode source test data with Moses ( 2010-08-13 ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
6Decode source test data with Moses ( 2010-08-13 ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
7Compute evaluation scores of the outputs .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
7Compute evaluation scores of the outputs .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
7Compute evaluation scores of the outputs .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
- Remove articles " a " , " an " , and " the "
#<struct ReadData::Alignment source_numbers="10", target_numbers="6", tag_name="wa">
- Remove articles " a " , " an " , and " the "
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
- Remove articles " a " , " an " , and " the "
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
- Remove articles " a " , " an " , and " the "
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
- Remove articles " a " , " an " , and " the "
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
- Remove articles " a " , " an " , and " the "
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
- Remove articles " a " , " an " , and " the "
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
- Remove articles " a " , " an " , and " the "
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
- Remove articles " a " , " an " , and " the "
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
- Remove articles " a " , " an " , and " the "
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
- Remove articles " a " , " an " , and " the "
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
- Remove articles " a " , " an " , and " the "
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
- Remove articles " a " , " an " , and " the "
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
In this case , the evaluation scores created by BLEU and RIBES are not comparative due to the differences of Japanese word definitions between the outputs of word segmentation methods .
#<struct ReadData::Alignment source_numbers="18,19", target_numbers="19,20", tag_name="wa">
In this case , the evaluation scores created by BLEU and RIBES are not comparative due to the differences of Japanese word definitions between the outputs of word segmentation methods .
#<struct ReadData::Alignment source_numbers="24", target_numbers="21", tag_name="wa">
In this case , the evaluation scores created by BLEU and RIBES are not comparative due to the differences of Japanese word definitions between the outputs of word segmentation methods .
#<struct ReadData::Alignment source_numbers="23", target_numbers="25,26", tag_name="wa">
In this case , the evaluation scores created by BLEU and RIBES are not comparative due to the differences of Japanese word definitions between the outputs of word segmentation methods .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
Furthermore , the CHAR scores in BLEU and BLEU in Characters should be regarded as almost same while small changes have been introduced due to statistical errors and the differences in the methods how to treat space characters .
#<struct ReadData::Alignment source_numbers="31", target_numbers="16", tag_name="wa">
Furthermore , the CHAR scores in BLEU and BLEU in Characters should be regarded as almost same while small changes have been introduced due to statistical errors and the differences in the methods how to treat space characters .
#<struct ReadData::Alignment source_numbers="38", target_numbers="42", tag_name="wa">
Furthermore , the CHAR scores in BLEU and BLEU in Characters should be regarded as almost same while small changes have been introduced due to statistical errors and the differences in the methods how to treat space characters .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
Furthermore , the CHAR scores in BLEU and BLEU in Characters should be regarded as almost same while small changes have been introduced due to statistical errors and the differences in the methods how to treat space characters .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
Furthermore , the CHAR scores in BLEU and BLEU in Characters should be regarded as almost same while small changes have been introduced due to statistical errors and the differences in the methods how to treat space characters .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
We found that the three supervised morphological analyzers KyTea , MeCab , and JUMAN were much higher than latticelm and CAT , and were competitive .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
For instance , on REUTERS in Table 2 , BLEU scores were ranged from 27 .88 to 29 .53 , while latticelm was 15 .28 and CAT was 22 .10 .
#<struct ReadData::Alignment source_numbers="12", target_numbers="11", tag_name="wa">
For instance , on REUTERS in Table 2 , BLEU scores were ranged from 27 .88 to 29 .53 , while latticelm was 15 .28 and CAT was 22 .10 .
#<struct ReadData::Alignment source_numbers="30", target_numbers="37", tag_name="wa">
For instance , on REUTERS in Table 2 , BLEU scores were ranged from 27 .88 to 29 .53 , while latticelm was 15 .28 and CAT was 22 .10 .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
For instance , on REUTERS in Table 2 , BLEU scores were ranged from 27 .88 to 29 .53 , while latticelm was 15 .28 and CAT was 22 .10 .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
For instance , on REUTERS in Table 2 , BLEU scores were ranged from 27 .88 to 29 .53 , while latticelm was 15 .28 and CAT was 22 .10 .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
For instance , on REUTERS in Table 2 , BLEU scores were ranged from 27 .88 to 29 .53 , while latticelm was 15 .28 and CAT was 22 .10 .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
For instance , on REUTERS in Table 2 , BLEU scores were ranged from 27 .88 to 29 .53 , while latticelm was 15 .28 and CAT was 22 .10 .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
For instance , on REUTERS in Table 2 , BLEU scores were ranged from 27 .88 to 29 .53 , while latticelm was 15 .28 and CAT was 22 .10 .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
For instance , on REUTERS in Table 2 , BLEU scores were ranged from 27 .88 to 29 .53 , while latticelm was 15 .28 and CAT was 22 .10 .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
The unsupervised morphological analyzer latticelm and one of heuristic methods CAT were worse than our expectations .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
The unsupervised morphological analyzer latticelm and one of heuristic methods CAT were worse than our expectations .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
The unsupervised morphological analyzer latticelm and one of heuristic methods CAT were worse than our expectations .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
The unsupervised morphological analyzer latticelm and one of heuristic methods CAT were worse than our expectations .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
The unsupervised morphological analyzer latticelm and one of heuristic methods CAT were worse than our expectations .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
The unsupervised morphological analyzer latticelm and one of heuristic methods CAT were worse than our expectations .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
These two were the worst or the second worst results in all settings .
#<struct ReadData::Alignment source_numbers="6", target_numbers="10", tag_name="wa">
These two were the worst or the second worst results in all settings .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
These two were the worst or the second worst results in all settings .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
These two were the worst or the second worst results in all settings .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
These two were the worst or the second worst results in all settings .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
The results of CHAR were counterintuitive and yet to be discussed .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
It was relatively much better than the supervised morphological analyzers in BLEU .
#<struct ReadData::Alignment source_numbers="6", target_numbers="5", tag_name="wa">
It was relatively much better than the supervised morphological analyzers in BLEU .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
It was relatively much better than the supervised morphological analyzers in BLEU .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
It was relatively much better than the supervised morphological analyzers in BLEU .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
It was relatively much better than the supervised morphological analyzers in BLEU .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
It was relatively much better than the supervised morphological analyzers in BLEU .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
It was relatively much better than the supervised morphological analyzers in BLEU .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
It was relatively much better than the supervised morphological analyzers in BLEU .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
It was relatively much better than the supervised morphological analyzers in BLEU .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
It was relatively much better than the supervised morphological analyzers in BLEU .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Besides , it was almost competitive in RIBES and BLUE in Characters .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Besides , it was almost competitive in RIBES and BLUE in Characters .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Besides , it was almost competitive in RIBES and BLUE in Characters .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Besides , it was almost competitive in RIBES and BLUE in Characters .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
For example , CHAR achieved the best 38 .42 score in BLEU on REUTERS , but the second best KyTea was 29 .53 .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
For example , CHAR achieved the best 38 .42 score in BLEU on REUTERS , but the second best KyTea was 29 .53 .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
For example , CHAR achieved the best 38 .42 score in BLEU on REUTERS , but the second best KyTea was 29 .53 .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
For example , CHAR achieved the best 38 .42 score in BLEU on REUTERS , but the second best KyTea was 29 .53 .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
For example , CHAR achieved the best 38 .42 score in BLEU on REUTERS , but the second best KyTea was 29 .53 .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
For example , CHAR achieved the best 38 .42 score in BLEU on REUTERS , but the second best KyTea was 29 .53 .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
For example , CHAR achieved the best 38 .42 score in BLEU on REUTERS , but the second best KyTea was 29 .53 .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
For example , CHAR achieved the best 38 .42 score in BLEU on REUTERS , but the second best KyTea was 29 .53 .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
For example , CHAR achieved the best 38 .42 score in BLEU on REUTERS , but the second best KyTea was 29 .53 .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
For example , CHAR achieved the best 38 .42 score in BLEU on REUTERS , but the second best KyTea was 29 .53 .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
In the case of BLEU in Characters on REUTERS , CHAR achieved 38 .61 , while the worst supervised result was KyTea 's 39 .82 .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
In the case of BLEU in Characters on REUTERS , CHAR achieved 38 .61 , while the worst supervised result was KyTea 's 39 .82 .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
In the case of BLEU in Characters on REUTERS , CHAR achieved 38 .61 , while the worst supervised result was KyTea 's 39 .82 .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
In the case of BLEU in Characters on REUTERS , CHAR achieved 38 .61 , while the worst supervised result was KyTea 's 39 .82 .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
In the case of BLEU in Characters on REUTERS , CHAR achieved 38 .61 , while the worst supervised result was KyTea 's 39 .82 .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
In this case , the evaluation scores are lower than English-Japanese translations in general .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
In this case , the evaluation scores are lower than English-Japanese translations in general .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
In this case , the evaluation scores are lower than English-Japanese translations in general .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
In this case , the evaluation scores are lower than English-Japanese translations in general .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
In this case , the evaluation scores are lower than English-Japanese translations in general .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
In this case , the evaluation scores are lower than English-Japanese translations in general .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
It is because Japanese-English translations are conducted without Head-Finalization .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
It is because Japanese-English translations are conducted without Head-Finalization .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
All supervised analyzers were better than the unsupervised and the both heuristic methods .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
All supervised analyzers were better than the unsupervised and the both heuristic methods .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
On the other hand , the unsupervised morphological analyzer latticelm and one of heuristic methods CAT were competitive to the supervised analyzers in RIBES .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
On the other hand , the unsupervised morphological analyzer latticelm and one of heuristic methods CAT were competitive to the supervised analyzers in RIBES .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
On the other hand , the unsupervised morphological analyzer latticelm and one of heuristic methods CAT were competitive to the supervised analyzers in RIBES .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
On the other hand , the unsupervised morphological analyzer latticelm and one of heuristic methods CAT were competitive to the supervised analyzers in RIBES .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
On the other hand , the unsupervised morphological analyzer latticelm and one of heuristic methods CAT were competitive to the supervised analyzers in RIBES .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
On the other hand , the unsupervised morphological analyzer latticelm and one of heuristic methods CAT were competitive to the supervised analyzers in RIBES .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
On the other hand , the unsupervised morphological analyzer latticelm and one of heuristic methods CAT were competitive to the supervised analyzers in RIBES .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
On the other hand , the unsupervised morphological analyzer latticelm and one of heuristic methods CAT were competitive to the supervised analyzers in RIBES .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
On the other hand , the unsupervised morphological analyzer latticelm and one of heuristic methods CAT were competitive to the supervised analyzers in RIBES .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
On the other hand , the unsupervised morphological analyzer latticelm and one of heuristic methods CAT were competitive to the supervised analyzers in RIBES .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
On the other hand , the unsupervised morphological analyzer latticelm and one of heuristic methods CAT were competitive to the supervised analyzers in RIBES .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
For example , latticelm was 62 .51 and KyTea was 62 .90 on REUTERS .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
For example , latticelm was 62 .51 and KyTea was 62 .90 on REUTERS .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
For example , latticelm was 62 .51 and KyTea was 62 .90 on REUTERS .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
The results were the worst scores in BLEU and RIBES on REUTERS and JENAAD+REUTERS . The only one exception was in the case of the best 56 .55 BLEU in Characters on REUTERS .
#<struct ReadData::Alignment source_numbers="21", target_numbers="18", tag_name="wa">
The results were the worst scores in BLEU and RIBES on REUTERS and JENAAD+REUTERS . The only one exception was in the case of the best 56 .55 BLEU in Characters on REUTERS .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
The results were the worst scores in BLEU and RIBES on REUTERS and JENAAD+REUTERS . The only one exception was in the case of the best 56 .55 BLEU in Characters on REUTERS .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
The results were the worst scores in BLEU and RIBES on REUTERS and JENAAD+REUTERS . The only one exception was in the case of the best 56 .55 BLEU in Characters on REUTERS .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
The results were the worst scores in BLEU and RIBES on REUTERS and JENAAD+REUTERS . The only one exception was in the case of the best 56 .55 BLEU in Characters on REUTERS .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
The results were the worst scores in BLEU and RIBES on REUTERS and JENAAD+REUTERS . The only one exception was in the case of the best 56 .55 BLEU in Characters on REUTERS .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
The results were the worst scores in BLEU and RIBES on REUTERS and JENAAD+REUTERS . The only one exception was in the case of the best 56 .55 BLEU in Characters on REUTERS .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
The results were the worst scores in BLEU and RIBES on REUTERS and JENAAD+REUTERS . The only one exception was in the case of the best 56 .55 BLEU in Characters on REUTERS .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
The results were the worst scores in BLEU and RIBES on REUTERS and JENAAD+REUTERS . The only one exception was in the case of the best 56 .55 BLEU in Characters on REUTERS .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
The results were the worst scores in BLEU and RIBES on REUTERS and JENAAD+REUTERS . The only one exception was in the case of the best 56 .55 BLEU in Characters on REUTERS .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
The results were the worst scores in BLEU and RIBES on REUTERS and JENAAD+REUTERS . The only one exception was in the case of the best 56 .55 BLEU in Characters on REUTERS .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
The results were the worst scores in BLEU and RIBES on REUTERS and JENAAD+REUTERS . The only one exception was in the case of the best 56 .55 BLEU in Characters on REUTERS .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
The results were the worst scores in BLEU and RIBES on REUTERS and JENAAD+REUTERS . The only one exception was in the case of the best 56 .55 BLEU in Characters on REUTERS .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
The results were the worst scores in BLEU and RIBES on REUTERS and JENAAD+REUTERS . The only one exception was in the case of the best 56 .55 BLEU in Characters on REUTERS .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
We found the results of the supervised morphological analyzers are better in both English-Japanese and Japanese-English experiments .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
And the differences in the word definition of KyTea , MeCab , and JUMAN were not remarkable , especially in English-Japanese translations , although the word definition of KyTea is much shorter than MeCab and JUMAN .
#<struct ReadData::Alignment source_numbers="22", target_numbers="1", tag_name="wa">
And the differences in the word definition of KyTea , MeCab , and JUMAN were not remarkable , especially in English-Japanese translations , although the word definition of KyTea is much shorter than MeCab and JUMAN .
#<struct ReadData::Alignment source_numbers="18,19", target_numbers="19,20", tag_name="wa">
And the differences in the word definition of KyTea , MeCab , and JUMAN were not remarkable , especially in English-Japanese translations , although the word definition of KyTea is much shorter than MeCab and JUMAN .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
And the differences in the word definition of KyTea , MeCab , and JUMAN were not remarkable , especially in English-Japanese translations , although the word definition of KyTea is much shorter than MeCab and JUMAN .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
And the differences in the word definition of KyTea , MeCab , and JUMAN were not remarkable , especially in English-Japanese translations , although the word definition of KyTea is much shorter than MeCab and JUMAN .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
This result implies that phrase-based SMT can output sufficiently reasonable word / phrase alignments that can treat different word definitions in most cases .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
On the other hand , the unsupervised morphological analyzer latticelm and one of our heuristic methods CAT were very much worse than the supervised morphological analyzers .
#<struct ReadData::Alignment source_numbers="20,21", target_numbers="19,20", tag_name="wa">
On the other hand , the unsupervised morphological analyzer latticelm and one of our heuristic methods CAT were very much worse than the supervised morphological analyzers .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
On the other hand , the unsupervised morphological analyzer latticelm and one of our heuristic methods CAT were very much worse than the supervised morphological analyzers .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
On the other hand , the unsupervised morphological analyzer latticelm and one of our heuristic methods CAT were very much worse than the supervised morphological analyzers .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
It was good at English-Japanese but not at Japanese-English translations .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
It was good at English-Japanese but not at Japanese-English translations .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
It was good at English-Japanese but not at Japanese-English translations .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
It was good at English-Japanese but not at Japanese-English translations .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
It was good at English-Japanese but not at Japanese-English translations .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
It was good at English-Japanese but not at Japanese-English translations .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
It was good at English-Japanese but not at Japanese-English translations .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
It was good at English-Japanese but not at Japanese-English translations .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
It was good at English-Japanese but not at Japanese-English translations .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
We consider the possible reasons for this result :
#<struct ReadData::Alignment source_numbers="8", target_numbers="12", tag_name="wa">
We consider the possible reasons for this result :
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
We consider the possible reasons for this result :
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
We consider the possible reasons for this result :
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
We consider the possible reasons for this result :
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
- Long sentences were translated worse than the other word segmentation outputs .
#<struct ReadData::Alignment source_numbers="6", target_numbers="4", tag_name="wa">
- Long sentences were translated worse than the other word segmentation outputs .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
- Long sentences were translated worse than the other word segmentation outputs .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
- Long sentences were translated worse than the other word segmentation outputs .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
- Long sentences were translated worse than the other word segmentation outputs .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
The reasons of the CHAR results are yet to be analyzed in details .
#<struct ReadData::Alignment source_numbers="1,2", target_numbers="1,2", tag_name="wa">
The current evaluation metrics we pursued in this paper were not sufficient to discuss more accurately about the relative advantages and disadvantages of word segmentation , since they did not produce consistent scores as explained below :
#<struct ReadData::Alignment source_numbers="32", target_numbers="27", tag_name="wa">
The current evaluation metrics we pursued in this paper were not sufficient to discuss more accurately about the relative advantages and disadvantages of word segmentation , since they did not produce consistent scores as explained below :
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
The current evaluation metrics we pursued in this paper were not sufficient to discuss more accurately about the relative advantages and disadvantages of word segmentation , since they did not produce consistent scores as explained below :
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
The current evaluation metrics we pursued in this paper were not sufficient to discuss more accurately about the relative advantages and disadvantages of word segmentation , since they did not produce consistent scores as explained below :
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
The current evaluation metrics we pursued in this paper were not sufficient to discuss more accurately about the relative advantages and disadvantages of word segmentation , since they did not produce consistent scores as explained below :
#<struct ReadData::Alignment source_numbers="27", target_numbers="", tag_name="wa">
The current evaluation metrics we pursued in this paper were not sufficient to discuss more accurately about the relative advantages and disadvantages of word segmentation , since they did not produce consistent scores as explained below :
#<struct ReadData::Alignment source_numbers="28", target_numbers="", tag_name="wa">
The current evaluation metrics we pursued in this paper were not sufficient to discuss more accurately about the relative advantages and disadvantages of word segmentation , since they did not produce consistent scores as explained below :
#<struct ReadData::Alignment source_numbers="29", target_numbers="", tag_name="wa">
The current evaluation metrics we pursued in this paper were not sufficient to discuss more accurately about the relative advantages and disadvantages of word segmentation , since they did not produce consistent scores as explained below :
#<struct ReadData::Alignment source_numbers="30", target_numbers="", tag_name="wa">
The current evaluation metrics we pursued in this paper were not sufficient to discuss more accurately about the relative advantages and disadvantages of word segmentation , since they did not produce consistent scores as explained below :
#<struct ReadData::Alignment source_numbers="31", target_numbers="", tag_name="wa">
The current evaluation metrics we pursued in this paper were not sufficient to discuss more accurately about the relative advantages and disadvantages of word segmentation , since they did not produce consistent scores as explained below :
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
The current evaluation metrics we pursued in this paper were not sufficient to discuss more accurately about the relative advantages and disadvantages of word segmentation , since they did not produce consistent scores as explained below :
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
The current evaluation metrics we pursued in this paper were not sufficient to discuss more accurately about the relative advantages and disadvantages of word segmentation , since they did not produce consistent scores as explained below :
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
The current evaluation metrics we pursued in this paper were not sufficient to discuss more accurately about the relative advantages and disadvantages of word segmentation , since they did not produce consistent scores as explained below :
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
The current evaluation metrics we pursued in this paper were not sufficient to discuss more accurately about the relative advantages and disadvantages of word segmentation , since they did not produce consistent scores as explained below :
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
The current evaluation metrics we pursued in this paper were not sufficient to discuss more accurately about the relative advantages and disadvantages of word segmentation , since they did not produce consistent scores as explained below :
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
The current evaluation metrics we pursued in this paper were not sufficient to discuss more accurately about the relative advantages and disadvantages of word segmentation , since they did not produce consistent scores as explained below :
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
The current evaluation metrics we pursued in this paper were not sufficient to discuss more accurately about the relative advantages and disadvantages of word segmentation , since they did not produce consistent scores as explained below :
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
The current evaluation metrics we pursued in this paper were not sufficient to discuss more accurately about the relative advantages and disadvantages of word segmentation , since they did not produce consistent scores as explained below :
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
The current evaluation metrics we pursued in this paper were not sufficient to discuss more accurately about the relative advantages and disadvantages of word segmentation , since they did not produce consistent scores as explained below :
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
Moreover , there is also a case that RIBES and BLEU in Characters were incompatible with each other .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Moreover , there is also a case that RIBES and BLEU in Characters were incompatible with each other .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Moreover , there is also a case that RIBES and BLEU in Characters were incompatible with each other .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
For example , on WIKIPEDIA in Table 2 , while CHAR was relatively the highest and greatly better than the supervised morphological analyzers in RIBES , MeCab achieved the best score and notably better than CHAR in BLEU in Characters .
#<struct ReadData::Alignment source_numbers="25", target_numbers="14", tag_name="wa">
For example , on WIKIPEDIA in Table 2 , while CHAR was relatively the highest and greatly better than the supervised morphological analyzers in RIBES , MeCab achieved the best score and notably better than CHAR in BLEU in Characters .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
For example , on WIKIPEDIA in Table 2 , while CHAR was relatively the highest and greatly better than the supervised morphological analyzers in RIBES , MeCab achieved the best score and notably better than CHAR in BLEU in Characters .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
For example , on WIKIPEDIA in Table 2 , while CHAR was relatively the highest and greatly better than the supervised morphological analyzers in RIBES , MeCab achieved the best score and notably better than CHAR in BLEU in Characters .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
For example , on WIKIPEDIA in Table 2 , while CHAR was relatively the highest and greatly better than the supervised morphological analyzers in RIBES , MeCab achieved the best score and notably better than CHAR in BLEU in Characters .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
This work focused on how the difference of word segmentation affects SMT outputs , the quality of the unsupervised word segmentation on SMT , and the meta-evaluation of the current evaluation metrics .
#<struct ReadData::Alignment source_numbers="28", target_numbers="5", tag_name="wa">
This work focused on how the difference of word segmentation affects SMT outputs , the quality of the unsupervised word segmentation on SMT , and the meta-evaluation of the current evaluation metrics .
#<struct ReadData::Alignment source_numbers="5,6", target_numbers="6", tag_name="wa">
This work focused on how the difference of word segmentation affects SMT outputs , the quality of the unsupervised word segmentation on SMT , and the meta-evaluation of the current evaluation metrics .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
This work focused on how the difference of word segmentation affects SMT outputs , the quality of the unsupervised word segmentation on SMT , and the meta-evaluation of the current evaluation metrics .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
This work focused on how the difference of word segmentation affects SMT outputs , the quality of the unsupervised word segmentation on SMT , and the meta-evaluation of the current evaluation metrics .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
After all , a heuristic word segmentation method CHAR achieved relatively good word-based BLEU scores and competitive character-based BLEU results , compared to the supervised analyzers .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
After all , a heuristic word segmentation method CHAR achieved relatively good word-based BLEU scores and competitive character-based BLEU results , compared to the supervised analyzers .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
After all , a heuristic word segmentation method CHAR achieved relatively good word-based BLEU scores and competitive character-based BLEU results , compared to the supervised analyzers .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Additionally , as we could not always obtain consistent scores from the current evaluation metrics , they were not sufficient to discuss more accurately about the relative advantages and disadvantages of word segmentation .
#<struct ReadData::Alignment source_numbers="25", target_numbers="16", tag_name="wa">
Additionally , as we could not always obtain consistent scores from the current evaluation metrics , they were not sufficient to discuss more accurately about the relative advantages and disadvantages of word segmentation .
#<struct ReadData::Alignment source_numbers="16,17", target_numbers="18", tag_name="wa">
Additionally , as we could not always obtain consistent scores from the current evaluation metrics , they were not sufficient to discuss more accurately about the relative advantages and disadvantages of word segmentation .
#<struct ReadData::Alignment source_numbers="18,19,20", target_numbers="19,20", tag_name="wa">
Additionally , as we could not always obtain consistent scores from the current evaluation metrics , they were not sufficient to discuss more accurately about the relative advantages and disadvantages of word segmentation .
#<struct ReadData::Alignment source_numbers="21", target_numbers="21", tag_name="wa">
Additionally , as we could not always obtain consistent scores from the current evaluation metrics , they were not sufficient to discuss more accurately about the relative advantages and disadvantages of word segmentation .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
Additionally , as we could not always obtain consistent scores from the current evaluation metrics , they were not sufficient to discuss more accurately about the relative advantages and disadvantages of word segmentation .
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
Additionally , as we could not always obtain consistent scores from the current evaluation metrics , they were not sufficient to discuss more accurately about the relative advantages and disadvantages of word segmentation .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Additionally , as we could not always obtain consistent scores from the current evaluation metrics , they were not sufficient to discuss more accurately about the relative advantages and disadvantages of word segmentation .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
Additionally , as we could not always obtain consistent scores from the current evaluation metrics , they were not sufficient to discuss more accurately about the relative advantages and disadvantages of word segmentation .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
Additionally , as we could not always obtain consistent scores from the current evaluation metrics , they were not sufficient to discuss more accurately about the relative advantages and disadvantages of word segmentation .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
Additionally , as we could not always obtain consistent scores from the current evaluation metrics , they were not sufficient to discuss more accurately about the relative advantages and disadvantages of word segmentation .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
We also suggested it is possible to implement more optimized word segmentation on SMT .
#<struct ReadData::Alignment source_numbers="2", target_numbers="3", tag_name="wa">
We also suggested it is possible to implement more optimized word segmentation on SMT .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
We also suggested it is possible to implement more optimized word segmentation on SMT .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
However , problems with their approaches are the disregard of the interdependencies of word senses , and the limited applicability to those word senses for which training instances are served .
#<struct ReadData::Alignment source_numbers="7", target_numbers="2", tag_name="wa">
However , problems with their approaches are the disregard of the interdependencies of word senses , and the limited applicability to those word senses for which training instances are served .
#<struct ReadData::Alignment source_numbers="2", target_numbers="3", tag_name="wa">
However , problems with their approaches are the disregard of the interdependencies of word senses , and the limited applicability to those word senses for which training instances are served .
#<struct ReadData::Alignment source_numbers="15", target_numbers="7", tag_name="wa">
However , problems with their approaches are the disregard of the interdependencies of word senses , and the limited applicability to those word senses for which training instances are served .
#<struct ReadData::Alignment source_numbers="6", target_numbers="8", tag_name="wa">
However , problems with their approaches are the disregard of the interdependencies of word senses , and the limited applicability to those word senses for which training instances are served .
#<struct ReadData::Alignment source_numbers="25", target_numbers="19,20,21", tag_name="wa">
However , problems with their approaches are the disregard of the interdependencies of word senses , and the limited applicability to those word senses for which training instances are served .
#<struct ReadData::Alignment source_numbers="18", target_numbers="22", tag_name="wa">
However , problems with their approaches are the disregard of the interdependencies of word senses , and the limited applicability to those word senses for which training instances are served .
#<struct ReadData::Alignment source_numbers="17", target_numbers="27", tag_name="wa">
However , problems with their approaches are the disregard of the interdependencies of word senses , and the limited applicability to those word senses for which training instances are served .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
However , problems with their approaches are the disregard of the interdependencies of word senses , and the limited applicability to those word senses for which training instances are served .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
However , problems with their approaches are the disregard of the interdependencies of word senses , and the limited applicability to those word senses for which training instances are served .
#<struct ReadData::Alignment source_numbers="30", target_numbers="", tag_name="wa">
However , problems with their approaches are the disregard of the interdependencies of word senses , and the limited applicability to those word senses for which training instances are served .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
However , problems with their approaches are the disregard of the interdependencies of word senses , and the limited applicability to those word senses for which training instances are served .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
However , problems with their approaches are the disregard of the interdependencies of word senses , and the limited applicability to those word senses for which training instances are served .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
However , problems with their approaches are the disregard of the interdependencies of word senses , and the limited applicability to those word senses for which training instances are served .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
However , problems with their approaches are the disregard of the interdependencies of word senses , and the limited applicability to those word senses for which training instances are served .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
However , problems with their approaches are the disregard of the interdependencies of word senses , and the limited applicability to those word senses for which training instances are served .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
However , problems with their approaches are the disregard of the interdependencies of word senses , and the limited applicability to those word senses for which training instances are served .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
However , problems with their approaches are the disregard of the interdependencies of word senses , and the limited applicability to those word senses for which training instances are served .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
However , problems with their approaches are the disregard of the interdependencies of word senses , and the limited applicability to those word senses for which training instances are served .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
However , problems with their approaches are the disregard of the interdependencies of word senses , and the limited applicability to those word senses for which training instances are served .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
However , problems with their approaches are the disregard of the interdependencies of word senses , and the limited applicability to those word senses for which training instances are served .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
However , problems with their approaches are the disregard of the interdependencies of word senses , and the limited applicability to those word senses for which training instances are served .
#<struct ReadData::Alignment source_numbers="", target_numbers="40", tag_name="wa">
However , problems with their approaches are the disregard of the interdependencies of word senses , and the limited applicability to those word senses for which training instances are served .
#<struct ReadData::Alignment source_numbers="", target_numbers="41", tag_name="wa">
Particularly , we assume that there exist strong dependencies between the sense of a syntactic head and those of its dependents .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Particularly , we assume that there exist strong dependencies between the sense of a syntactic head and those of its dependents .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Particularly , we assume that there exist strong dependencies between the sense of a syntactic head and those of its dependents .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Particularly , we assume that there exist strong dependencies between the sense of a syntactic head and those of its dependents .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Also , we define these sense dependencies in combination with various coarse-grained sense tag sets , so that our model can even work for words that do not appear in the training data , and these combined features help relieve the data sparseness problem .
#<struct ReadData::Alignment source_numbers="20,21", target_numbers="20,21", tag_name="wa">
Also , we define these sense dependencies in combination with various coarse-grained sense tag sets , so that our model can even work for words that do not appear in the training data , and these combined features help relieve the data sparseness problem .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Also , we define these sense dependencies in combination with various coarse-grained sense tag sets , so that our model can even work for words that do not appear in the training data , and these combined features help relieve the data sparseness problem .
#<struct ReadData::Alignment source_numbers="33", target_numbers="", tag_name="wa">
Also , we define these sense dependencies in combination with various coarse-grained sense tag sets , so that our model can even work for words that do not appear in the training data , and these combined features help relieve the data sparseness problem .
#<struct ReadData::Alignment source_numbers="34", target_numbers="", tag_name="wa">
Also , we define these sense dependencies in combination with various coarse-grained sense tag sets , so that our model can even work for words that do not appear in the training data , and these combined features help relieve the data sparseness problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Also , we define these sense dependencies in combination with various coarse-grained sense tag sets , so that our model can even work for words that do not appear in the training data , and these combined features help relieve the data sparseness problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
In experiments , we show the appropriateness of considering the sense dependencies , as well as the advantage of the combination of fine- and coarse-grained tag sets .
#<struct ReadData::Alignment source_numbers="19", target_numbers="23", tag_name="wa">
In experiments , we show the appropriateness of considering the sense dependencies , as well as the advantage of the combination of fine- and coarse-grained tag sets .
#<struct ReadData::Alignment source_numbers="20", target_numbers="24", tag_name="wa">
In experiments , we show the appropriateness of considering the sense dependencies , as well as the advantage of the combination of fine- and coarse-grained tag sets .
#<struct ReadData::Alignment source_numbers="21", target_numbers="25", tag_name="wa">
In experiments , we show the appropriateness of considering the sense dependencies , as well as the advantage of the combination of fine- and coarse-grained tag sets .
#<struct ReadData::Alignment source_numbers="22", target_numbers="26", tag_name="wa">
In experiments , we show the appropriateness of considering the sense dependencies , as well as the advantage of the combination of fine- and coarse-grained tag sets .
#<struct ReadData::Alignment source_numbers="23", target_numbers="27", tag_name="wa">
In experiments , we show the appropriateness of considering the sense dependencies , as well as the advantage of the combination of fine- and coarse-grained tag sets .
#<struct ReadData::Alignment source_numbers="24", target_numbers="28", tag_name="wa">
In experiments , we show the appropriateness of considering the sense dependencies , as well as the advantage of the combination of fine- and coarse-grained tag sets .
#<struct ReadData::Alignment source_numbers="25", target_numbers="29", tag_name="wa">
In experiments , we show the appropriateness of considering the sense dependencies , as well as the advantage of the combination of fine- and coarse-grained tag sets .
#<struct ReadData::Alignment source_numbers="26", target_numbers="30", tag_name="wa">
In experiments , we show the appropriateness of considering the sense dependencies , as well as the advantage of the combination of fine- and coarse-grained tag sets .
#<struct ReadData::Alignment source_numbers="27", target_numbers="31", tag_name="wa">
In experiments , we show the appropriateness of considering the sense dependencies , as well as the advantage of the combination of fine- and coarse-grained tag sets .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
In experiments , we show the appropriateness of considering the sense dependencies , as well as the advantage of the combination of fine- and coarse-grained tag sets .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
In experiments , we show the appropriateness of considering the sense dependencies , as well as the advantage of the combination of fine- and coarse-grained tag sets .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
In experiments , we show the appropriateness of considering the sense dependencies , as well as the advantage of the combination of fine- and coarse-grained tag sets .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
We also present an in-depth analysis on the effectiveness of the sense dependency features with intuitive examples .
#<struct ReadData::Alignment source_numbers="5,6", target_numbers="5,6", tag_name="wa">
We also present an in-depth analysis on the effectiveness of the sense dependency features with intuitive examples .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
We also present an in-depth analysis on the effectiveness of the sense dependency features with intuitive examples .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
We also present an in-depth analysis on the effectiveness of the sense dependency features with intuitive examples .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
Word sense disambiguation ( WSD ) is one of the fundamental problems in computational linguistics .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
It is considered to be an intermediate , but necessary step toward many NLP applications including machine translation and information extraction , which require the knowledge of word senses to achieve better performance .
#<struct ReadData::Alignment source_numbers="22", target_numbers="26", tag_name="wa">
It is considered to be an intermediate , but necessary step toward many NLP applications including machine translation and information extraction , which require the knowledge of word senses to achieve better performance .
#<struct ReadData::Alignment source_numbers="23", target_numbers="41", tag_name="wa">
It is considered to be an intermediate , but necessary step toward many NLP applications including machine translation and information extraction , which require the knowledge of word senses to achieve better performance .
#<struct ReadData::Alignment source_numbers="24", target_numbers="42", tag_name="wa">
It is considered to be an intermediate , but necessary step toward many NLP applications including machine translation and information extraction , which require the knowledge of word senses to achieve better performance .
#<struct ReadData::Alignment source_numbers="25", target_numbers="43", tag_name="wa">
It is considered to be an intermediate , but necessary step toward many NLP applications including machine translation and information extraction , which require the knowledge of word senses to achieve better performance .
#<struct ReadData::Alignment source_numbers="26", target_numbers="44", tag_name="wa">
It is considered to be an intermediate , but necessary step toward many NLP applications including machine translation and information extraction , which require the knowledge of word senses to achieve better performance .
#<struct ReadData::Alignment source_numbers="27", target_numbers="45", tag_name="wa">
It is considered to be an intermediate , but necessary step toward many NLP applications including machine translation and information extraction , which require the knowledge of word senses to achieve better performance .
#<struct ReadData::Alignment source_numbers="28", target_numbers="46", tag_name="wa">
It is considered to be an intermediate , but necessary step toward many NLP applications including machine translation and information extraction , which require the knowledge of word senses to achieve better performance .
#<struct ReadData::Alignment source_numbers="29", target_numbers="47", tag_name="wa">
It is considered to be an intermediate , but necessary step toward many NLP applications including machine translation and information extraction , which require the knowledge of word senses to achieve better performance .
#<struct ReadData::Alignment source_numbers="32", target_numbers="48", tag_name="wa">
It is considered to be an intermediate , but necessary step toward many NLP applications including machine translation and information extraction , which require the knowledge of word senses to achieve better performance .
#<struct ReadData::Alignment source_numbers="31", target_numbers="49", tag_name="wa">
It is considered to be an intermediate , but necessary step toward many NLP applications including machine translation and information extraction , which require the knowledge of word senses to achieve better performance .
#<struct ReadData::Alignment source_numbers="33", target_numbers="50", tag_name="wa">
It is considered to be an intermediate , but necessary step toward many NLP applications including machine translation and information extraction , which require the knowledge of word senses to achieve better performance .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
It is considered to be an intermediate , but necessary step toward many NLP applications including machine translation and information extraction , which require the knowledge of word senses to achieve better performance .
#<struct ReadData::Alignment source_numbers="30", target_numbers="", tag_name="wa">
It is considered to be an intermediate , but necessary step toward many NLP applications including machine translation and information extraction , which require the knowledge of word senses to achieve better performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
It is considered to be an intermediate , but necessary step toward many NLP applications including machine translation and information extraction , which require the knowledge of word senses to achieve better performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
It is considered to be an intermediate , but necessary step toward many NLP applications including machine translation and information extraction , which require the knowledge of word senses to achieve better performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
It is considered to be an intermediate , but necessary step toward many NLP applications including machine translation and information extraction , which require the knowledge of word senses to achieve better performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
It is considered to be an intermediate , but necessary step toward many NLP applications including machine translation and information extraction , which require the knowledge of word senses to achieve better performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
It is considered to be an intermediate , but necessary step toward many NLP applications including machine translation and information extraction , which require the knowledge of word senses to achieve better performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
It is considered to be an intermediate , but necessary step toward many NLP applications including machine translation and information extraction , which require the knowledge of word senses to achieve better performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
It is considered to be an intermediate , but necessary step toward many NLP applications including machine translation and information extraction , which require the knowledge of word senses to achieve better performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
It is considered to be an intermediate , but necessary step toward many NLP applications including machine translation and information extraction , which require the knowledge of word senses to achieve better performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
It is considered to be an intermediate , but necessary step toward many NLP applications including machine translation and information extraction , which require the knowledge of word senses to achieve better performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
It is considered to be an intermediate , but necessary step toward many NLP applications including machine translation and information extraction , which require the knowledge of word senses to achieve better performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
It is considered to be an intermediate , but necessary step toward many NLP applications including machine translation and information extraction , which require the knowledge of word senses to achieve better performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
It is considered to be an intermediate , but necessary step toward many NLP applications including machine translation and information extraction , which require the knowledge of word senses to achieve better performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
It is considered to be an intermediate , but necessary step toward many NLP applications including machine translation and information extraction , which require the knowledge of word senses to achieve better performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
It is considered to be an intermediate , but necessary step toward many NLP applications including machine translation and information extraction , which require the knowledge of word senses to achieve better performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
It is considered to be an intermediate , but necessary step toward many NLP applications including machine translation and information extraction , which require the knowledge of word senses to achieve better performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
It is considered to be an intermediate , but necessary step toward many NLP applications including machine translation and information extraction , which require the knowledge of word senses to achieve better performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
It is considered to be an intermediate , but necessary step toward many NLP applications including machine translation and information extraction , which require the knowledge of word senses to achieve better performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
It is considered to be an intermediate , but necessary step toward many NLP applications including machine translation and information extraction , which require the knowledge of word senses to achieve better performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="40", tag_name="wa">
One major obstacle to large-scale and precise WSD is the data sparseness problem caused by the fine-grainedness of the sense distinction .
#<struct ReadData::Alignment source_numbers="2,3", target_numbers="2,3", tag_name="wa">
One major obstacle to large-scale and precise WSD is the data sparseness problem caused by the fine-grainedness of the sense distinction .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
One major obstacle to large-scale and precise WSD is the data sparseness problem caused by the fine-grainedness of the sense distinction .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
One major obstacle to large-scale and precise WSD is the data sparseness problem caused by the fine-grainedness of the sense distinction .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
One major obstacle to large-scale and precise WSD is the data sparseness problem caused by the fine-grainedness of the sense distinction .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
In order to resolve this problem , several semi-supervised approaches have been explored in recent years .
#<struct ReadData::Alignment source_numbers="0", target_numbers="0", tag_name="wa">
In order to resolve this problem , several semi-supervised approaches have been explored in recent years .
#<struct ReadData::Alignment source_numbers="13", target_numbers="3", tag_name="wa">
Some researchers have addressed directly the scarcity of the training data , and explored the methods to obtain more tagged instances , by the co-training and self-training .
#<struct ReadData::Alignment source_numbers="13", target_numbers="14", tag_name="wa">
Some researchers have addressed directly the scarcity of the training data , and explored the methods to obtain more tagged instances , by the co-training and self-training .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Although the use of the global information has succeeded in dramatically increase the performance of WSD , there are much room left to examine the effectiveness of local or syntactic information .
#<struct ReadData::Alignment source_numbers="11,12", target_numbers="10,11", tag_name="wa">
One of such information yet to be explored is the interdependencies of word senses .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Although the use of local and syntactic information has been common in WSD , traditional approaches to WSD are based on the individual classification framework for each word , in which each word 's sense is treated independently , regardless of any interdependencies nor cooccurrences of word senses .
#<struct ReadData::Alignment source_numbers="28", target_numbers="", tag_name="wa">
Although the use of local and syntactic information has been common in WSD , traditional approaches to WSD are based on the individual classification framework for each word , in which each word 's sense is treated independently , regardless of any interdependencies nor cooccurrences of word senses .
#<struct ReadData::Alignment source_numbers="29", target_numbers="", tag_name="wa">
Although the use of local and syntactic information has been common in WSD , traditional approaches to WSD are based on the individual classification framework for each word , in which each word 's sense is treated independently , regardless of any interdependencies nor cooccurrences of word senses .
#<struct ReadData::Alignment source_numbers="30", target_numbers="", tag_name="wa">
Although the use of local and syntactic information has been common in WSD , traditional approaches to WSD are based on the individual classification framework for each word , in which each word 's sense is treated independently , regardless of any interdependencies nor cooccurrences of word senses .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
As a result , the resulting sense assignment may not semantically consistent over the sentence .
#<struct ReadData::Alignment source_numbers="8", target_numbers="7", tag_name="wa">
As a result , the resulting sense assignment may not semantically consistent over the sentence .
#<struct ReadData::Alignment source_numbers="9", target_numbers="8", tag_name="wa">
As a result , the resulting sense assignment may not semantically consistent over the sentence .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
As a result , the resulting sense assignment may not semantically consistent over the sentence .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
As a result , the resulting sense assignment may not semantically consistent over the sentence .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
As a result , the resulting sense assignment may not semantically consistent over the sentence .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
As a result , the resulting sense assignment may not semantically consistent over the sentence .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
As a result , the resulting sense assignment may not semantically consistent over the sentence .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
To solve this problem is of great interest from both practical and theoretical perspectives .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
To solve this problem is of great interest from both practical and theoretical perspectives .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
We focus on the use of the interdependency of word senses , so that we can directly address the issue of semantic ambiguity of a whole sentence arose from the interaction of each word 's sense ambiguity .
#<struct ReadData::Alignment source_numbers="2,3,4,5", target_numbers="2,3", tag_name="wa">
We focus on the use of the interdependency of word senses , so that we can directly address the issue of semantic ambiguity of a whole sentence arose from the interaction of each word 's sense ambiguity .
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
We focus on the use of the interdependency of word senses , so that we can directly address the issue of semantic ambiguity of a whole sentence arose from the interaction of each word 's sense ambiguity .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
We focus on the use of the interdependency of word senses , so that we can directly address the issue of semantic ambiguity of a whole sentence arose from the interaction of each word 's sense ambiguity .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
We focus on the use of the interdependency of word senses , so that we can directly address the issue of semantic ambiguity of a whole sentence arose from the interaction of each word 's sense ambiguity .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
We focus on the use of the interdependency of word senses , so that we can directly address the issue of semantic ambiguity of a whole sentence arose from the interaction of each word 's sense ambiguity .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
We focus on the use of the interdependency of word senses , so that we can directly address the issue of semantic ambiguity of a whole sentence arose from the interaction of each word 's sense ambiguity .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
We focus on the use of the interdependency of word senses , so that we can directly address the issue of semantic ambiguity of a whole sentence arose from the interaction of each word 's sense ambiguity .
#<struct ReadData::Alignment source_numbers="", target_numbers="40", tag_name="wa">
We focus on the use of the interdependency of word senses , so that we can directly address the issue of semantic ambiguity of a whole sentence arose from the interaction of each word 's sense ambiguity .
#<struct ReadData::Alignment source_numbers="", target_numbers="41", tag_name="wa">
We focus on the use of the interdependency of word senses , so that we can directly address the issue of semantic ambiguity of a whole sentence arose from the interaction of each word 's sense ambiguity .
#<struct ReadData::Alignment source_numbers="", target_numbers="42", tag_name="wa">
We focus on the use of the interdependency of word senses , so that we can directly address the issue of semantic ambiguity of a whole sentence arose from the interaction of each word 's sense ambiguity .
#<struct ReadData::Alignment source_numbers="", target_numbers="43", tag_name="wa">
Specifically , we assume that there exist strong sense dependencies between a syntactic head and its dependents in the dependency tree , rather than between neighboring words in the sentence .
#<struct ReadData::Alignment source_numbers="6", target_numbers="5", tag_name="wa">
Specifically , we assume that there exist strong sense dependencies between a syntactic head and its dependents in the dependency tree , rather than between neighboring words in the sentence .
#<struct ReadData::Alignment source_numbers="21", target_numbers="13", tag_name="wa">
Specifically , we assume that there exist strong sense dependencies between a syntactic head and its dependents in the dependency tree , rather than between neighboring words in the sentence .
#<struct ReadData::Alignment source_numbers="26,27", target_numbers="26,27", tag_name="wa">
Specifically , we assume that there exist strong sense dependencies between a syntactic head and its dependents in the dependency tree , rather than between neighboring words in the sentence .
#<struct ReadData::Alignment source_numbers="28,29", target_numbers="28,29", tag_name="wa">
Specifically , we assume that there exist strong sense dependencies between a syntactic head and its dependents in the dependency tree , rather than between neighboring words in the sentence .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Specifically , we assume that there exist strong sense dependencies between a syntactic head and its dependents in the dependency tree , rather than between neighboring words in the sentence .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
We confirm the appropriateness of this assumption by showing the superiority of the tree-structured models over the linear-chain models .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
We confirm the appropriateness of this assumption by showing the superiority of the tree-structured models over the linear-chain models .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
We confirm the appropriateness of this assumption by showing the superiority of the tree-structured models over the linear-chain models .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
This is to relieve the data sparseness problem caused by the explosion of the number of features , which is roughly squared by the combination of two word senses .
#<struct ReadData::Alignment source_numbers="11,12", target_numbers="11,12", tag_name="wa">
The combined features also enable our model to work even for those words that do not appear in the training data , which the traditional individual classifiers cannot handle .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
We solve WSD as a labeling problem to a sentence described as a dependency tree , where the vertices correspond to words and the edges correspond to the sense dependencies .
#<struct ReadData::Alignment source_numbers="27", target_numbers="21", tag_name="wa">
We solve WSD as a labeling problem to a sentence described as a dependency tree , where the vertices correspond to words and the edges correspond to the sense dependencies .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
We solve WSD as a labeling problem to a sentence described as a dependency tree , where the vertices correspond to words and the edges correspond to the sense dependencies .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
T-CRFs also enable us to incorporate various sense tag sets all together in a simple framework .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
T-CRFs also enable us to incorporate various sense tag sets all together in a simple framework .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
These results are confirmed on three data sets ( the SemCor corpus and the Senseval-2 and -3 English all-words task test sets ) and on two sense inventories ( WordNet synsets and supersenses ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
Our final model is shown to perform comparably with state-of-the-art WSD systems .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Our final model is shown to perform comparably with state-of-the-art WSD systems .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
In Section 4 , we describe our model with intuitive examples , and the machine learning method we use .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
In Section 4 , we describe our model with intuitive examples , and the machine learning method we use .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
In Section 4 , we describe our model with intuitive examples , and the machine learning method we use .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
In Section 5 , 6 , and 7 , we present our experimental setup and results , and an in-depth analysis on the contribution of the sense dependency features .
#<struct ReadData::Alignment source_numbers="16", target_numbers="14", tag_name="wa">
In Section 5 , 6 , and 7 , we present our experimental setup and results , and an in-depth analysis on the contribution of the sense dependency features .
#<struct ReadData::Alignment source_numbers="25", target_numbers="15", tag_name="wa">
In Section 5 , 6 , and 7 , we present our experimental setup and results , and an in-depth analysis on the contribution of the sense dependency features .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
In Section 5 , 6 , and 7 , we present our experimental setup and results , and an in-depth analysis on the contribution of the sense dependency features .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
In Section 5 , 6 , and 7 , we present our experimental setup and results , and an in-depth analysis on the contribution of the sense dependency features .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
It also serves as an ontology , in which various kinds of meta data , relations among words and senses , and well-organized hierarchical classification of word senses are defined .
#<struct ReadData::Alignment source_numbers="25", target_numbers="6", tag_name="wa">
It also serves as an ontology , in which various kinds of meta data , relations among words and senses , and well-organized hierarchical classification of word senses are defined .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
It also serves as an ontology , in which various kinds of meta data , relations among words and senses , and well-organized hierarchical classification of word senses are defined .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
It also serves as an ontology , in which various kinds of meta data , relations among words and senses , and well-organized hierarchical classification of word senses are defined .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
It also serves as an ontology , in which various kinds of meta data , relations among words and senses , and well-organized hierarchical classification of word senses are defined .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
It also serves as an ontology , in which various kinds of meta data , relations among words and senses , and well-organized hierarchical classification of word senses are defined .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
It also serves as an ontology , in which various kinds of meta data , relations among words and senses , and well-organized hierarchical classification of word senses are defined .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
It also serves as an ontology , in which various kinds of meta data , relations among words and senses , and well-organized hierarchical classification of word senses are defined .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
In the WordNet , nouns and verbs are organized in hierarchical structures with IS-A ( hypernym-hyponym ) relationships among words , as shown in Figure 1 .
#<struct ReadData::Alignment source_numbers="9", target_numbers="6", tag_name="wa">
In the WordNet , nouns and verbs are organized in hierarchical structures with IS-A ( hypernym-hyponym ) relationships among words , as shown in Figure 1 .
#<struct ReadData::Alignment source_numbers="3", target_numbers="8", tag_name="wa">
In the WordNet , nouns and verbs are organized in hierarchical structures with IS-A ( hypernym-hyponym ) relationships among words , as shown in Figure 1 .
#<struct ReadData::Alignment source_numbers="20", target_numbers="25", tag_name="wa">
In the WordNet , nouns and verbs are organized in hierarchical structures with IS-A ( hypernym-hyponym ) relationships among words , as shown in Figure 1 .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
In the WordNet , nouns and verbs are organized in hierarchical structures with IS-A ( hypernym-hyponym ) relationships among words , as shown in Figure 1 .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
In the WordNet , nouns and verbs are organized in hierarchical structures with IS-A ( hypernym-hyponym ) relationships among words , as shown in Figure 1 .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
In the WordNet , nouns and verbs are organized in hierarchical structures with IS-A ( hypernym-hyponym ) relationships among words , as shown in Figure 1 .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Nouns have a far deeper structure than verbs , while that of verbs is transversely developed .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Nouns have a far deeper structure than verbs , while that of verbs is transversely developed .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
Nouns have a far deeper structure than verbs , while that of verbs is transversely developed .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
All nouns and verbs except some top-level concepts are classified into primitive groups called supersenses , which we describe later .
#<struct ReadData::Alignment source_numbers="15", target_numbers="20", tag_name="wa">
All nouns and verbs except some top-level concepts are classified into primitive groups called supersenses , which we describe later .
#<struct ReadData::Alignment source_numbers="18", target_numbers="24", tag_name="wa">
All nouns and verbs except some top-level concepts are classified into primitive groups called supersenses , which we describe later .
#<struct ReadData::Alignment source_numbers="20", target_numbers="26", tag_name="wa">
All nouns and verbs except some top-level concepts are classified into primitive groups called supersenses , which we describe later .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
All nouns and verbs except some top-level concepts are classified into primitive groups called supersenses , which we describe later .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
All nouns and verbs except some top-level concepts are classified into primitive groups called supersenses , which we describe later .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
Figure 1 shows the WordNet hierarchical structure for the first sense ( financial bank ) of a noun bank , where each line shows a synset with the list of words headed by its supersense label , and an arrow denotes that two synsets are in an IS-A relation .
#<struct ReadData::Alignment source_numbers="36", target_numbers="", tag_name="wa">
Figure 1 shows the WordNet hierarchical structure for the first sense ( financial bank ) of a noun bank , where each line shows a synset with the list of words headed by its supersense label , and an arrow denotes that two synsets are in an IS-A relation .
#<struct ReadData::Alignment source_numbers="37", target_numbers="", tag_name="wa">
Figure 1 shows the WordNet hierarchical structure for the first sense ( financial bank ) of a noun bank , where each line shows a synset with the list of words headed by its supersense label , and an arrow denotes that two synsets are in an IS-A relation .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
The synset {group#1 , grouping#1} is a broad semantic category that governs the supersense noun group .
#<struct ReadData::Alignment source_numbers="15", target_numbers="14", tag_name="wa">
The synset {group#1 , grouping#1} is a broad semantic category that governs the supersense noun group .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
Note that since the organizations of adjectives and adverbs are far different from those of nouns and verbs , we use this hierarchical information for only nouns and verbs .
#<struct ReadData::Alignment source_numbers="10,11", target_numbers="10,11", tag_name="wa">
Hence , we can expect them to act as a good smoothing feature for WSD , which would make up for the sparseness of features associated with finer-grained senses .
#<struct ReadData::Alignment source_numbers="21", target_numbers="21", tag_name="wa">
Hence , we can expect them to act as a good smoothing feature for WSD , which would make up for the sparseness of features associated with finer-grained senses .
#<struct ReadData::Alignment source_numbers="29", target_numbers="34", tag_name="wa">
Hence , we can expect them to act as a good smoothing feature for WSD , which would make up for the sparseness of features associated with finer-grained senses .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
Hence , we can expect them to act as a good smoothing feature for WSD , which would make up for the sparseness of features associated with finer-grained senses .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
Hence , we can expect them to act as a good smoothing feature for WSD , which would make up for the sparseness of features associated with finer-grained senses .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
Hence , we can expect them to act as a good smoothing feature for WSD , which would make up for the sparseness of features associated with finer-grained senses .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
Hence , we can expect them to act as a good smoothing feature for WSD , which would make up for the sparseness of features associated with finer-grained senses .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
Since senses of a word are ordered according to frequency , the sense ranking acts as a useful feature offering a preference for frequent senses .
#<struct ReadData::Alignment source_numbers="19", target_numbers="20", tag_name="wa">
Since senses of a word are ordered according to frequency , the sense ranking acts as a useful feature offering a preference for frequent senses .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
The first sense classifier is known as a strong baseline in WSD , which can be even considered to be a good alternative to WSD .
#<struct ReadData::Alignment source_numbers="17,18,19", target_numbers="17,18", tag_name="wa">
It is considered to be a good feature that reflects the sense frequency information when sufficient training data is available for every sense .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
It is considered to be a good feature that reflects the sense frequency information when sufficient training data is available for every sense .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
It is considered to be a good feature that reflects the sense frequency information when sufficient training data is available for every sense .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
It is considered to be a good feature that reflects the sense frequency information when sufficient training data is available for every sense .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
It is considered to be a good feature that reflects the sense frequency information when sufficient training data is available for every sense .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
For this reason , we use this first sense feature instead of the ranking feature , for the supersense-based evaluation .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
For this reason , we use this first sense feature instead of the ranking feature , for the supersense-based evaluation .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
For this reason , we use this first sense feature instead of the ranking feature , for the supersense-based evaluation .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
introduces an unsupervised graph-based algorithm , and showed a significant superiority of the sequence labeling model over the individual label assignment .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
introduces an unsupervised graph-based algorithm , and showed a significant superiority of the sequence labeling model over the individual label assignment .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
introduces an unsupervised graph-based algorithm , and showed a significant superiority of the sequence labeling model over the individual label assignment .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
introduces an unsupervised graph-based algorithm , and showed a significant superiority of the sequence labeling model over the individual label assignment .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
built a model based on various word semantic similarity measures and graph centrality algorithms , which also used the graph structure incorporating the word-sense dependencies .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
On the other hand , the traditional approach to the supervised WSD is to solve an independent classification problem for each word .
#<struct ReadData::Alignment source_numbers="0", target_numbers="0", tag_name="wa">
On the other hand , the traditional approach to the supervised WSD is to solve an independent classification problem for each word .
#<struct ReadData::Alignment source_numbers="1", target_numbers="1", tag_name="wa">
On the other hand , the traditional approach to the supervised WSD is to solve an independent classification problem for each word .
#<struct ReadData::Alignment source_numbers="2,3", target_numbers="2", tag_name="wa">
However , as we described in Section 1 , this approach cannot deal with the interdependencies among word senses , and may output a semantically inconsistent assignment of senses .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
Recently , with the growing interest on the all-words task , a few supervised WSD systems have incorporated the sense dependencies .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
Recently , with the growing interest on the all-words task , a few supervised WSD systems have incorporated the sense dependencies .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
SenseLearner and SuperSenseLearner incorporate sequencial sense dependencies into the supervised WSD frameworks .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
SenseLearner and SuperSenseLearner incorporate sequencial sense dependencies into the supervised WSD frameworks .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
also took a sequencial tagging approach for the disambiguation of WordNet supersenses .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
also took a sequencial tagging approach for the disambiguation of WordNet supersenses .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
also took a sequencial tagging approach for the disambiguation of WordNet supersenses .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
also took a sequencial tagging approach for the disambiguation of WordNet supersenses .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
also took a sequencial tagging approach for the disambiguation of WordNet supersenses .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
also took a sequencial tagging approach for the disambiguation of WordNet supersenses .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
also took a sequencial tagging approach for the disambiguation of WordNet supersenses .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
also took a sequencial tagging approach for the disambiguation of WordNet supersenses .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
However , the dependencies they considered are rather simple ones between the adjacent words , and between either WordNet synsets or supersenses .
#<struct ReadData::Alignment source_numbers="1", target_numbers="5", tag_name="wa">
However , the dependencies they considered are rather simple ones between the adjacent words , and between either WordNet synsets or supersenses .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
However , the dependencies they considered are rather simple ones between the adjacent words , and between either WordNet synsets or supersenses .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
However , the dependencies they considered are rather simple ones between the adjacent words , and between either WordNet synsets or supersenses .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
However , the dependencies they considered are rather simple ones between the adjacent words , and between either WordNet synsets or supersenses .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
However , the dependencies they considered are rather simple ones between the adjacent words , and between either WordNet synsets or supersenses .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
However , the dependencies they considered are rather simple ones between the adjacent words , and between either WordNet synsets or supersenses .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Note additionally that they do not mention how and how much they contribute to the improvement of supervised WSD .
#<struct ReadData::Alignment source_numbers="7", target_numbers="8,9", tag_name="wa">
Note additionally that they do not mention how and how much they contribute to the improvement of supervised WSD .
#<struct ReadData::Alignment source_numbers="14", target_numbers="11", tag_name="wa">
Note additionally that they do not mention how and how much they contribute to the improvement of supervised WSD .
#<struct ReadData::Alignment source_numbers="16", target_numbers="13", tag_name="wa">
Note additionally that they do not mention how and how much they contribute to the improvement of supervised WSD .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Note additionally that they do not mention how and how much they contribute to the improvement of supervised WSD .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Note additionally that they do not mention how and how much they contribute to the improvement of supervised WSD .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Note additionally that they do not mention how and how much they contribute to the improvement of supervised WSD .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
Note additionally that they do not mention how and how much they contribute to the improvement of supervised WSD .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
Note additionally that they do not mention how and how much they contribute to the improvement of supervised WSD .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
Note additionally that they do not mention how and how much they contribute to the improvement of supervised WSD .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
Note additionally that they do not mention how and how much they contribute to the improvement of supervised WSD .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Note additionally that they do not mention how and how much they contribute to the improvement of supervised WSD .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Note additionally that they do not mention how and how much they contribute to the improvement of supervised WSD .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
Note additionally that they do not mention how and how much they contribute to the improvement of supervised WSD .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Note additionally that they do not mention how and how much they contribute to the improvement of supervised WSD .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
Note additionally that they do not mention how and how much they contribute to the improvement of supervised WSD .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
One interesting model related is the exponential family model proposed by , which captures the occurrences and co-occurrences of words and senses in a joint probability distribution .
#<struct ReadData::Alignment source_numbers="11", target_numbers="6", tag_name="wa">
One interesting model related is the exponential family model proposed by , which captures the occurrences and co-occurrences of words and senses in a joint probability distribution .
#<struct ReadData::Alignment source_numbers="27", target_numbers="21", tag_name="wa">
One interesting model related is the exponential family model proposed by , which captures the occurrences and co-occurrences of words and senses in a joint probability distribution .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
One interesting model related is the exponential family model proposed by , which captures the occurrences and co-occurrences of words and senses in a joint probability distribution .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
One interesting model related is the exponential family model proposed by , which captures the occurrences and co-occurrences of words and senses in a joint probability distribution .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
One interesting model related is the exponential family model proposed by , which captures the occurrences and co-occurrences of words and senses in a joint probability distribution .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
One interesting model related is the exponential family model proposed by , which captures the occurrences and co-occurrences of words and senses in a joint probability distribution .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
One interesting model related is the exponential family model proposed by , which captures the occurrences and co-occurrences of words and senses in a joint probability distribution .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
One interesting model related is the exponential family model proposed by , which captures the occurrences and co-occurrences of words and senses in a joint probability distribution .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Although they focused on the use of the co-occurrences of word senses rather than the dependencies , they clarified the contribution of sense co-occurrences to the supervised WSD .
#<struct ReadData::Alignment source_numbers="21", target_numbers="15", tag_name="wa">
Although they focused on the use of the co-occurrences of word senses rather than the dependencies , they clarified the contribution of sense co-occurrences to the supervised WSD .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Although they focused on the use of the co-occurrences of word senses rather than the dependencies , they clarified the contribution of sense co-occurrences to the supervised WSD .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
In this context , it is of an interest if the sense dependencies on a syntactic structure , rather than on a linear chain , works effectively or not .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
In this context , it is of an interest if the sense dependencies on a syntactic structure , rather than on a linear chain , works effectively or not .
#<struct ReadData::Alignment source_numbers="29", target_numbers="", tag_name="wa">
In this context , it is of an interest if the sense dependencies on a syntactic structure , rather than on a linear chain , works effectively or not .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
In this context , it is of an interest if the sense dependencies on a syntactic structure , rather than on a linear chain , works effectively or not .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
In this context , it is of an interest if the sense dependencies on a syntactic structure , rather than on a linear chain , works effectively or not .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
In this context , it is of an interest if the sense dependencies on a syntactic structure , rather than on a linear chain , works effectively or not .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
In this context , it is of an interest if the sense dependencies on a syntactic structure , rather than on a linear chain , works effectively or not .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
Also , despite the approaches described above , the contribution of sense dependencies for the supervised WSD has not explicitly examined thus far .
#<struct ReadData::Alignment source_numbers="17", target_numbers="17", tag_name="wa">
Also , despite the approaches described above , the contribution of sense dependencies for the supervised WSD has not explicitly examined thus far .
#<struct ReadData::Alignment source_numbers="18", target_numbers="18", tag_name="wa">
Also , despite the approaches described above , the contribution of sense dependencies for the supervised WSD has not explicitly examined thus far .
#<struct ReadData::Alignment source_numbers="20", target_numbers="21", tag_name="wa">
Also , despite the approaches described above , the contribution of sense dependencies for the supervised WSD has not explicitly examined thus far .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Also , despite the approaches described above , the contribution of sense dependencies for the supervised WSD has not explicitly examined thus far .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Also , despite the approaches described above , the contribution of sense dependencies for the supervised WSD has not explicitly examined thus far .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
In Section 1 , we presented one of the most significant problems in WSD - the data sparsity .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
This problem may even be magnified when we consider the interdependencies of word senses , since the number of features is roughly squared by the combination of two word senses .
#<struct ReadData::Alignment source_numbers="14", target_numbers="6", tag_name="wa">
This problem may even be magnified when we consider the interdependencies of word senses , since the number of features is roughly squared by the combination of two word senses .
#<struct ReadData::Alignment source_numbers="8", target_numbers="10", tag_name="wa">
This problem may even be magnified when we consider the interdependencies of word senses , since the number of features is roughly squared by the combination of two word senses .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
This problem may even be magnified when we consider the interdependencies of word senses , since the number of features is roughly squared by the combination of two word senses .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
This problem may even be magnified when we consider the interdependencies of word senses , since the number of features is roughly squared by the combination of two word senses .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
This problem may even be magnified when we consider the interdependencies of word senses , since the number of features is roughly squared by the combination of two word senses .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
In order to relieve this problem , we use the hierarchical information in the WordNet , including the superordinate words and supersenses , which we describe in Section 2 .1 and 2 .2 .
#<struct ReadData::Alignment source_numbers="25", target_numbers="24", tag_name="wa">
In order to relieve this problem , we use the hierarchical information in the WordNet , including the superordinate words and supersenses , which we describe in Section 2 .1 and 2 .2 .
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
In order to relieve this problem , we use the hierarchical information in the WordNet , including the superordinate words and supersenses , which we describe in Section 2 .1 and 2 .2 .
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
In order to relieve this problem , we use the hierarchical information in the WordNet , including the superordinate words and supersenses , which we describe in Section 2 .1 and 2 .2 .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
The use of the hierarchical information has been motivated by several researches .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
For example , a WSD system by , which was ranked second in the Senseval-3 , consists of two models : the first model applied to words seen in the training data , and the second model that performs a generalized disambiguation process for words unseen in the data by using the hierarchical information in the WordNet .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
For example , a WSD system by , which was ranked second in the Senseval-3 , consists of two models : the first model applied to words seen in the training data , and the second model that performs a generalized disambiguation process for words unseen in the data by using the hierarchical information in the WordNet .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
For example , a WSD system by , which was ranked second in the Senseval-3 , consists of two models : the first model applied to words seen in the training data , and the second model that performs a generalized disambiguation process for words unseen in the data by using the hierarchical information in the WordNet .
#<struct ReadData::Alignment source_numbers="37", target_numbers="", tag_name="wa">
For example , a WSD system by , which was ranked second in the Senseval-3 , consists of two models : the first model applied to words seen in the training data , and the second model that performs a generalized disambiguation process for words unseen in the data by using the hierarchical information in the WordNet .
#<struct ReadData::Alignment source_numbers="", target_numbers="46", tag_name="wa">
The fine granularity of the WordNet synsets is not just a major obstacle to high-performance WSD , but is sometimes too fine-grained even for a human to disambiguate .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
The fine granularity of the WordNet synsets is not just a major obstacle to high-performance WSD , but is sometimes too fine-grained even for a human to disambiguate .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
The fine granularity of the WordNet synsets is not just a major obstacle to high-performance WSD , but is sometimes too fine-grained even for a human to disambiguate .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
This is reflected in the low inter-annotator agreement of sense tagging ( typically around 70% ) , which implies that WSD models are unlikely to perform better than this accuracy .
#<struct ReadData::Alignment source_numbers="28", target_numbers="", tag_name="wa">
This is reflected in the low inter-annotator agreement of sense tagging ( typically around 70% ) , which implies that WSD models are unlikely to perform better than this accuracy .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
This is reflected in the low inter-annotator agreement of sense tagging ( typically around 70% ) , which implies that WSD models are unlikely to perform better than this accuracy .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
Also , this fine-grainedness is reported to be not appropriate for many NLP applications .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
Also , this fine-grainedness is reported to be not appropriate for many NLP applications .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Also , this fine-grainedness is reported to be not appropriate for many NLP applications .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Especially , the use of the supersenses has recently been investigated by , and receiving much attention in the WSD field .
#<struct ReadData::Alignment source_numbers="14", target_numbers="15", tag_name="wa">
Especially , the use of the supersenses has recently been investigated by , and receiving much attention in the WSD field .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Especially , the use of the supersenses has recently been investigated by , and receiving much attention in the WSD field .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Especially , the use of the supersenses has recently been investigated by , and receiving much attention in the WSD field .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Especially , the use of the supersenses has recently been investigated by , and receiving much attention in the WSD field .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
In this case , the inter-annotator agreements are turned out to reach around 90% .
#<struct ReadData::Alignment source_numbers="8,9,10", target_numbers="7", tag_name="wa">
In this case , the inter-annotator agreements are turned out to reach around 90% .
#<struct ReadData::Alignment source_numbers="11", target_numbers="8", tag_name="wa">
In this case , the inter-annotator agreements are turned out to reach around 90% .
#<struct ReadData::Alignment source_numbers="14", target_numbers="10", tag_name="wa">
In this case , the inter-annotator agreements are turned out to reach around 90% .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
In this case , the inter-annotator agreements are turned out to reach around 90% .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
In this case , the inter-annotator agreements are turned out to reach around 90% .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
In this case , the inter-annotator agreements are turned out to reach around 90% .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
For this reason , we use as our sense inventory the WordNet supersenses as well as the synsets .
#<struct ReadData::Alignment source_numbers="6", target_numbers="15", tag_name="wa">
For this reason , we use as our sense inventory the WordNet supersenses as well as the synsets .
#<struct ReadData::Alignment source_numbers="7", target_numbers="16", tag_name="wa">
For this reason , we use as our sense inventory the WordNet supersenses as well as the synsets .
#<struct ReadData::Alignment source_numbers="8", target_numbers="17", tag_name="wa">
For this reason , we use as our sense inventory the WordNet supersenses as well as the synsets .
#<struct ReadData::Alignment source_numbers="9", target_numbers="18", tag_name="wa">
For this reason , we use as our sense inventory the WordNet supersenses as well as the synsets .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
One is the independent classification of each word 's sense regardless of the sense dependencies among words .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
One is the independent classification of each word 's sense regardless of the sense dependencies among words .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
The other is the scarcity of the training data arose from the fine granularity of the sense distinction .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
The other is the scarcity of the training data arose from the fine granularity of the sense distinction .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
The first is the use of the syntactic dependencies of word senses on a dependency tree .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
The first is the use of the syntactic dependencies of word senses on a dependency tree .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Particularly , we assume that there exist strong dependencies of word senses between a head and its dependents in the dependency tree , rather than between neighboring words in the sentence .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Particularly , we assume that there exist strong dependencies of word senses between a head and its dependents in the dependency tree , rather than between neighboring words in the sentence .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Particularly , we assume that there exist strong dependencies of word senses between a head and its dependents in the dependency tree , rather than between neighboring words in the sentence .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
The second is the combination of various coarse-grained sense tag sets with the WordNet synsets .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
The second is the combination of various coarse-grained sense tag sets with the WordNet synsets .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
The second is the combination of various coarse-grained sense tag sets with the WordNet synsets .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
The second is the combination of various coarse-grained sense tag sets with the WordNet synsets .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
The second is the combination of various coarse-grained sense tag sets with the WordNet synsets .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
The second is the combination of various coarse-grained sense tag sets with the WordNet synsets .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
The second is the combination of various coarse-grained sense tag sets with the WordNet synsets .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
One way is to use them directly as the sense inventory instead of a finer sense inventory .
#<struct ReadData::Alignment source_numbers="4", target_numbers="3", tag_name="wa">
One way is to use them directly as the sense inventory instead of a finer sense inventory .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
One way is to use them directly as the sense inventory instead of a finer sense inventory .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
One way is to use them directly as the sense inventory instead of a finer sense inventory .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
One way is to use them directly as the sense inventory instead of a finer sense inventory .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
This method serves us much more training instances for each coarser sense , while we can no longer distinguish finer senses .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
This method serves us much more training instances for each coarser sense , while we can no longer distinguish finer senses .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
The other is to use them in combination with finer sense tag sets .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
The other is to use them in combination with finer sense tag sets .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
The other is to use them in combination with finer sense tag sets .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
The other is to use them in combination with finer sense tag sets .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
The other is to use them in combination with finer sense tag sets .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
The other is to use them in combination with finer sense tag sets .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
The other is to use them in combination with finer sense tag sets .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
The other is to use them in combination with finer sense tag sets .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
The other is to use them in combination with finer sense tag sets .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Although the sense disambiguation is still based on the finer senses , the coarser sense tags will help the discrimination of the finer senses , serving generalized information for each fine-grained sense .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
This approach has been taken in several hierarchical WSD methods , but never combined with the sense dependencies as we use .
#<struct ReadData::Alignment source_numbers="13", target_numbers="15", tag_name="wa">
This approach has been taken in several hierarchical WSD methods , but never combined with the sense dependencies as we use .
#<struct ReadData::Alignment source_numbers="20", target_numbers="24,25", tag_name="wa">
This approach has been taken in several hierarchical WSD methods , but never combined with the sense dependencies as we use .
#<struct ReadData::Alignment source_numbers="21", target_numbers="27", tag_name="wa">
This approach has been taken in several hierarchical WSD methods , but never combined with the sense dependencies as we use .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
This approach has been taken in several hierarchical WSD methods , but never combined with the sense dependencies as we use .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
This approach has been taken in several hierarchical WSD methods , but never combined with the sense dependencies as we use .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
This approach has been taken in several hierarchical WSD methods , but never combined with the sense dependencies as we use .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
This approach has been taken in several hierarchical WSD methods , but never combined with the sense dependencies as we use .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
This approach has been taken in several hierarchical WSD methods , but never combined with the sense dependencies as we use .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
This approach has been taken in several hierarchical WSD methods , but never combined with the sense dependencies as we use .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
This approach has been taken in several hierarchical WSD methods , but never combined with the sense dependencies as we use .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
This approach has been taken in several hierarchical WSD methods , but never combined with the sense dependencies as we use .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
The process of WSD is summarized as below .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
In the training phase , all vertex features and edge features are extracted using the gold-standard senses , and the weight vectors for them are optimized over the training data .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
In the training phase , all vertex features and edge features are extracted using the gold-standard senses , and the weight vectors for them are optimized over the training data .
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
The conditional probability of a label sequence / MATH conditioned on a data sequence / MATH is given by / MATH , where / MATH and / MATH are the feature vectors for an edge and a vertex , / MATH and / MATH are the weight vectors for them , / MATH and / MATH are the set of components of / MATH associated with an edge / MATH and a vertex / MATH , and / MATH is the partition function which constrains the sum of all the probabilities to be 1 .
#<struct ReadData::Alignment source_numbers="82,83", target_numbers="80,81", tag_name="wa">
The conditional probability of a label sequence / MATH conditioned on a data sequence / MATH is given by / MATH , where / MATH and / MATH are the feature vectors for an edge and a vertex , / MATH and / MATH are the weight vectors for them , / MATH and / MATH are the set of components of / MATH associated with an edge / MATH and a vertex / MATH , and / MATH is the partition function which constrains the sum of all the probabilities to be 1 .
#<struct ReadData::Alignment source_numbers="48", target_numbers="", tag_name="wa">
The conditional probability of a label sequence / MATH conditioned on a data sequence / MATH is given by / MATH , where / MATH and / MATH are the feature vectors for an edge and a vertex , / MATH and / MATH are the weight vectors for them , / MATH and / MATH are the set of components of / MATH associated with an edge / MATH and a vertex / MATH , and / MATH is the partition function which constrains the sum of all the probabilities to be 1 .
#<struct ReadData::Alignment source_numbers="49", target_numbers="", tag_name="wa">
Tree-structured CRFs ( T-CRFs ) are different from widely used linear-chain CRFs in that the random variables are organized in a tree structure ( acyclic graph ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
Hence , we can consider them appropriate for modeling the syntactic dependencies of word senses , which cannot be represented by linear structures .
#<struct ReadData::Alignment source_numbers="6", target_numbers="6", tag_name="wa">
Hence , we can consider them appropriate for modeling the syntactic dependencies of word senses , which cannot be represented by linear structures .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Hence , we can consider them appropriate for modeling the syntactic dependencies of word senses , which cannot be represented by linear structures .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
In this model , the optimal label assignment / MATH for an observation sequence / MATH is then calculated by / MATH , where / MATH denotes a vertex corresponding to a word while / MATH denotes the vertex corresponding to its parent in the dependency tree .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
If we interpret / MATH as the vertex associated with the preceding word in a sentence , it reduces to a linear-chain CRF .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
If we interpret / MATH as the vertex associated with the preceding word in a sentence , it reduces to a linear-chain CRF .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
If we interpret / MATH as the vertex associated with the preceding word in a sentence , it reduces to a linear-chain CRF .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
If we interpret / MATH as the vertex associated with the preceding word in a sentence , it reduces to a linear-chain CRF .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
In this section , we introduce a method to build graph structures on which CRFs are constructed .
#<struct ReadData::Alignment source_numbers="6,7", target_numbers="6,7", tag_name="wa">
At the beginning , we parse this sentence with the Sagae and Tsujii 's dependency parser , which outputs parsed trees in the CoNLL-X dependency format .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
At the beginning , we parse this sentence with the Sagae and Tsujii 's dependency parser , which outputs parsed trees in the CoNLL-X dependency format .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
For example , on the right-hand side of Figure 2 , the dependencies among confidence-in-bank are splitted into the two dependencies confidence-in and in-bank ; Hence our model cannot capture the direct dependency between confidence and bank .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
For example , on the right-hand side of Figure 2 , the dependencies among confidence-in-bank are splitted into the two dependencies confidence-in and in-bank ; Hence our model cannot capture the direct dependency between confidence and bank .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
For this reason , for the synset-based model , we convert the outputted dependency tree into a tree of content words , as exemplified on the right-hand side of Figure 2 .
#<struct ReadData::Alignment source_numbers="3", target_numbers="1", tag_name="wa">
For this reason , for the synset-based model , we convert the outputted dependency tree into a tree of content words , as exemplified on the right-hand side of Figure 2 .
#<struct ReadData::Alignment source_numbers="8", target_numbers="6", tag_name="wa">
For this reason , for the synset-based model , we convert the outputted dependency tree into a tree of content words , as exemplified on the right-hand side of Figure 2 .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
For this reason , for the synset-based model , we convert the outputted dependency tree into a tree of content words , as exemplified on the right-hand side of Figure 2 .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
For this reason , for the synset-based model , we convert the outputted dependency tree into a tree of content words , as exemplified on the right-hand side of Figure 2 .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
For this reason , for the synset-based model , we convert the outputted dependency tree into a tree of content words , as exemplified on the right-hand side of Figure 2 .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Then , on the right-hand side of Figure 2 , we can see that the dependency between confidence and bank is now described as a direct edge .
#<struct ReadData::Alignment source_numbers="27", target_numbers="23", tag_name="wa">
Then , on the right-hand side of Figure 2 , we can see that the dependency between confidence and bank is now described as a direct edge .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Then , on the right-hand side of Figure 2 , we can see that the dependency between confidence and bank is now described as a direct edge .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
Then , on the right-hand side of Figure 2 , we can see that the dependency between confidence and bank is now described as a direct edge .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
Then , on the right-hand side of Figure 2 , we can see that the dependency between confidence and bank is now described as a direct edge .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
Thus , by the compaction of the trees , our model can capture more useful dependencies among word senses .
#<struct ReadData::Alignment source_numbers="1", target_numbers="6", tag_name="wa">
Thus , by the compaction of the trees , our model can capture more useful dependencies among word senses .
#<struct ReadData::Alignment source_numbers="8", target_numbers="8", tag_name="wa">
Thus , by the compaction of the trees , our model can capture more useful dependencies among word senses .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Thus , by the compaction of the trees , our model can capture more useful dependencies among word senses .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Thus , by the compaction of the trees , our model can capture more useful dependencies among word senses .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Thus , by the compaction of the trees , our model can capture more useful dependencies among word senses .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Note that for the supersense-based model , we further convert the tree into a tree of nouns and verbs , because supersenses are defined for only these two parts of speech .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Note that for the supersense-based model , we further convert the tree into a tree of nouns and verbs , because supersenses are defined for only these two parts of speech .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Note that for the supersense-based model , we further convert the tree into a tree of nouns and verbs , because supersenses are defined for only these two parts of speech .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Note that for the supersense-based model , we further convert the tree into a tree of nouns and verbs , because supersenses are defined for only these two parts of speech .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
The inclusion of removed words and dependency relation labels are performed in the same manner as in the synset-based model , and the tree on the right hand side of Figure 2 in this case remains unchanged because the sentence does not contain any adjectives nor adverbs .
#<struct ReadData::Alignment source_numbers="20", target_numbers="36", tag_name="wa">
The inclusion of removed words and dependency relation labels are performed in the same manner as in the synset-based model , and the tree on the right hand side of Figure 2 in this case remains unchanged because the sentence does not contain any adjectives nor adverbs .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
The inclusion of removed words and dependency relation labels are performed in the same manner as in the synset-based model , and the tree on the right hand side of Figure 2 in this case remains unchanged because the sentence does not contain any adjectives nor adverbs .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
For the linear-chain models , we do not need to parse a sentence .
#<struct ReadData::Alignment source_numbers="10", target_numbers="5", tag_name="wa">
For the linear-chain models , we do not need to parse a sentence .
#<struct ReadData::Alignment source_numbers="6,7,8", target_numbers="8,9", tag_name="wa">
For the linear-chain models , we do not need to parse a sentence .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
For the linear-chain models , we do not need to parse a sentence .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Next , as the same reason for the tree-structured case , we remove from the graph those words that we do not need to disambiguate , in order to capture the direct dependencies between content words ( or nouns and verbs in the supersense-based model ) .
#<struct ReadData::Alignment source_numbers="20,21,22,23", target_numbers="17,18,19,20", tag_name="wa">
Next , as the same reason for the tree-structured case , we remove from the graph those words that we do not need to disambiguate , in order to capture the direct dependencies between content words ( or nouns and verbs in the supersense-based model ) .
#<struct ReadData::Alignment source_numbers="28", target_numbers="21", tag_name="wa">
Next , as the same reason for the tree-structured case , we remove from the graph those words that we do not need to disambiguate , in order to capture the direct dependencies between content words ( or nouns and verbs in the supersense-based model ) .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
Next , as the same reason for the tree-structured case , we remove from the graph those words that we do not need to disambiguate , in order to capture the direct dependencies between content words ( or nouns and verbs in the supersense-based model ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
Thus , the process of the tree compaction is performed in the same manner , as described in Figure 3 .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Thus , the process of the tree compaction is performed in the same manner , as described in Figure 3 .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Thus , the process of the tree compaction is performed in the same manner , as described in Figure 3 .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Thus , the process of the tree compaction is performed in the same manner , as described in Figure 3 .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Here , we focus on three words destroy , confidence , and bank in Sentence ( i ) , and for simplicity consider only two major senses for each word as described in Table 3 , so that the number of possible sense assignments is in this case / MATH .
#<struct ReadData::Alignment source_numbers="50", target_numbers="19", tag_name="wa">
Here , we focus on three words destroy , confidence , and bank in Sentence ( i ) , and for simplicity consider only two major senses for each word as described in Table 3 , so that the number of possible sense assignments is in this case / MATH .
#<struct ReadData::Alignment source_numbers="18", target_numbers="22", tag_name="wa">
Here , we focus on three words destroy , confidence , and bank in Sentence ( i ) , and for simplicity consider only two major senses for each word as described in Table 3 , so that the number of possible sense assignments is in this case / MATH .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
Here , we focus on three words destroy , confidence , and bank in Sentence ( i ) , and for simplicity consider only two major senses for each word as described in Table 3 , so that the number of possible sense assignments is in this case / MATH .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
Here , we focus on three words destroy , confidence , and bank in Sentence ( i ) , and for simplicity consider only two major senses for each word as described in Table 3 , so that the number of possible sense assignments is in this case / MATH .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
Here , we focus on three words destroy , confidence , and bank in Sentence ( i ) , and for simplicity consider only two major senses for each word as described in Table 3 , so that the number of possible sense assignments is in this case / MATH .
#<struct ReadData::Alignment source_numbers="45", target_numbers="", tag_name="wa">
Here , we focus on three words destroy , confidence , and bank in Sentence ( i ) , and for simplicity consider only two major senses for each word as described in Table 3 , so that the number of possible sense assignments is in this case / MATH .
#<struct ReadData::Alignment source_numbers="46", target_numbers="", tag_name="wa">
Here , we focus on three words destroy , confidence , and bank in Sentence ( i ) , and for simplicity consider only two major senses for each word as described in Table 3 , so that the number of possible sense assignments is in this case / MATH .
#<struct ReadData::Alignment source_numbers="47", target_numbers="", tag_name="wa">
Here , we focus on three words destroy , confidence , and bank in Sentence ( i ) , and for simplicity consider only two major senses for each word as described in Table 3 , so that the number of possible sense assignments is in this case / MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Here , we focus on three words destroy , confidence , and bank in Sentence ( i ) , and for simplicity consider only two major senses for each word as described in Table 3 , so that the number of possible sense assignments is in this case / MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Here , we focus on three words destroy , confidence , and bank in Sentence ( i ) , and for simplicity consider only two major senses for each word as described in Table 3 , so that the number of possible sense assignments is in this case / MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
Here , we focus on three words destroy , confidence , and bank in Sentence ( i ) , and for simplicity consider only two major senses for each word as described in Table 3 , so that the number of possible sense assignments is in this case / MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
Here , we focus on three words destroy , confidence , and bank in Sentence ( i ) , and for simplicity consider only two major senses for each word as described in Table 3 , so that the number of possible sense assignments is in this case / MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="49", tag_name="wa">
The first intuition would be that confidence( n )#2 is strongly related to a group or an institution ( financial bank ) but not related to natural landscape ( river bank ) , while confidence( n )#1 depends mostly on persons and not on other entities .
#<struct ReadData::Alignment source_numbers="32", target_numbers="22", tag_name="wa">
The first intuition would be that confidence( n )#2 is strongly related to a group or an institution ( financial bank ) but not related to natural landscape ( river bank ) , while confidence( n )#1 depends mostly on persons and not on other entities .
#<struct ReadData::Alignment source_numbers="23,24,25", target_numbers="25,26", tag_name="wa">
The first intuition would be that confidence( n )#2 is strongly related to a group or an institution ( financial bank ) but not related to natural landscape ( river bank ) , while confidence( n )#1 depends mostly on persons and not on other entities .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
The first intuition would be that confidence( n )#2 is strongly related to a group or an institution ( financial bank ) but not related to natural landscape ( river bank ) , while confidence( n )#1 depends mostly on persons and not on other entities .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
Given confidence does not have an " object " meaning , the weights of destroy( v )#2-confidence( n )#1 and destroy( v )#2-confidence( n )#2 would be the largest among others .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
Given confidence does not have an " object " meaning , the weights of destroy( v )#2-confidence( n )#1 and destroy( v )#2-confidence( n )#2 would be the largest among others .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
Given confidence does not have an " object " meaning , the weights of destroy( v )#2-confidence( n )#1 and destroy( v )#2-confidence( n )#2 would be the largest among others .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
The detailed description of sense bigrams are given in Section 4 .7 .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
The detailed description of sense bigrams are given in Section 4 .7 .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
These labels represent word senses at various levels , and to be combined with the vertex and edge features .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
We implement as vertex features a set of typical contextual features widely used in a lot of supervised WSD models .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
We implement as vertex features a set of typical contextual features widely used in a lot of supervised WSD models .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
We implement as vertex features a set of typical contextual features widely used in a lot of supervised WSD models .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
We implement as vertex features a set of typical contextual features widely used in a lot of supervised WSD models .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
In order to see whether the sense dependency features are certainly effective or not , we include as vertex features the word forms , lemmas , and parts of speech of both the parent and the child words in the dependency tree .
#<struct ReadData::Alignment source_numbers="5", target_numbers="4", tag_name="wa">
In order to see whether the sense dependency features are certainly effective or not , we include as vertex features the word forms , lemmas , and parts of speech of both the parent and the child words in the dependency tree .
#<struct ReadData::Alignment source_numbers="30", target_numbers="6", tag_name="wa">
In order to see whether the sense dependency features are certainly effective or not , we include as vertex features the word forms , lemmas , and parts of speech of both the parent and the child words in the dependency tree .
#<struct ReadData::Alignment source_numbers="14", target_numbers="10", tag_name="wa">
In order to see whether the sense dependency features are certainly effective or not , we include as vertex features the word forms , lemmas , and parts of speech of both the parent and the child words in the dependency tree .
#<struct ReadData::Alignment source_numbers="23", target_numbers="19", tag_name="wa">
In order to see whether the sense dependency features are certainly effective or not , we include as vertex features the word forms , lemmas , and parts of speech of both the parent and the child words in the dependency tree .
#<struct ReadData::Alignment source_numbers="25", target_numbers="21", tag_name="wa">
In order to see whether the sense dependency features are certainly effective or not , we include as vertex features the word forms , lemmas , and parts of speech of both the parent and the child words in the dependency tree .
#<struct ReadData::Alignment source_numbers="42", target_numbers="38", tag_name="wa">
In order to see whether the sense dependency features are certainly effective or not , we include as vertex features the word forms , lemmas , and parts of speech of both the parent and the child words in the dependency tree .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
In order to see whether the sense dependency features are certainly effective or not , we include as vertex features the word forms , lemmas , and parts of speech of both the parent and the child words in the dependency tree .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
In order to see whether the sense dependency features are certainly effective or not , we include as vertex features the word forms , lemmas , and parts of speech of both the parent and the child words in the dependency tree .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
In order to see whether the sense dependency features are certainly effective or not , we include as vertex features the word forms , lemmas , and parts of speech of both the parent and the child words in the dependency tree .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
In order to see whether the sense dependency features are certainly effective or not , we include as vertex features the word forms , lemmas , and parts of speech of both the parent and the child words in the dependency tree .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
In order to see whether the sense dependency features are certainly effective or not , we include as vertex features the word forms , lemmas , and parts of speech of both the parent and the child words in the dependency tree .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
In order to see whether the sense dependency features are certainly effective or not , we include as vertex features the word forms , lemmas , and parts of speech of both the parent and the child words in the dependency tree .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
In order to see whether the sense dependency features are certainly effective or not , we include as vertex features the word forms , lemmas , and parts of speech of both the parent and the child words in the dependency tree .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
Using this contextual information and the set of vertex labels / MATH , we construct a set of features on a vertex / MATH by / MATH .
#<struct ReadData::Alignment source_numbers="12", target_numbers="4", tag_name="wa">
Using this contextual information and the set of vertex labels / MATH , we construct a set of features on a vertex / MATH by / MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Note that this feature is not combined with any sense labels nor contextual information .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
For the supersense-based model , we use vertex features based on , which includes some features from the named entity recognition literature such as the word shape features along with the standard feature set for WSD .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
For the supersense-based model , we use vertex features based on , which includes some features from the named entity recognition literature such as the word shape features along with the standard feature set for WSD .
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
For the supersense-based model , we use vertex features based on , which includes some features from the named entity recognition literature such as the word shape features along with the standard feature set for WSD .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
For the supersense-based model , we use vertex features based on , which includes some features from the named entity recognition literature such as the word shape features along with the standard feature set for WSD .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
For the supersense-based model , we use vertex features based on , which includes some features from the named entity recognition literature such as the word shape features along with the standard feature set for WSD .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
Unlike in the synset-based model , we do not incorporate the syntactic information of the parent and child words , since it has been reported not to improve the performance .
#<struct ReadData::Alignment source_numbers="22,23", target_numbers="21,22,23,24", tag_name="wa">
Unlike in the synset-based model , we do not incorporate the syntactic information of the parent and child words , since it has been reported not to improve the performance .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
Unlike in the synset-based model , we do not incorporate the syntactic information of the parent and child words , since it has been reported not to improve the performance .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
In this section , we introduce corpora we use for the evaluation .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
SemCor is a corpus , in which all content words are annotated with the WordNet synsets , and consists of balanced 352 files from the Brown Corpus .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
Note that these data sets are different from the originals in that multi-word expressions are already segmented .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Note that these data sets are different from the originals in that multi-word expressions are already segmented .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Note that these data sets are different from the originals in that multi-word expressions are already segmented .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Note that these data sets are different from the originals in that multi-word expressions are already segmented .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Note that these data sets are different from the originals in that multi-word expressions are already segmented .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
Note that these data sets are different from the originals in that multi-word expressions are already segmented .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Note that these data sets are different from the originals in that multi-word expressions are already segmented .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
However , on the other hand , our model cannot output any answers to multi-word expressions that have no directly corresponding WordNet synsets , because we treat expression as one unit in the process of WSD .
#<struct ReadData::Alignment source_numbers="23", target_numbers="18", tag_name="wa">
However , on the other hand , our model cannot output any answers to multi-word expressions that have no directly corresponding WordNet synsets , because we treat expression as one unit in the process of WSD .
#<struct ReadData::Alignment source_numbers="36", target_numbers="31", tag_name="wa">
However , on the other hand , our model cannot output any answers to multi-word expressions that have no directly corresponding WordNet synsets , because we treat expression as one unit in the process of WSD .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
However , on the other hand , our model cannot output any answers to multi-word expressions that have no directly corresponding WordNet synsets , because we treat expression as one unit in the process of WSD .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
However , on the other hand , our model cannot output any answers to multi-word expressions that have no directly corresponding WordNet synsets , because we treat expression as one unit in the process of WSD .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
However , on the other hand , our model cannot output any answers to multi-word expressions that have no directly corresponding WordNet synsets , because we treat expression as one unit in the process of WSD .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
However , on the other hand , our model cannot output any answers to multi-word expressions that have no directly corresponding WordNet synsets , because we treat expression as one unit in the process of WSD .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
For example , the multi-word expression tear-filled is treated as one instance but not tagged with any WordNet synsets in the converted corpus , while in the original corpus it is tagged with two WordNet synsets for tear and filled .
#<struct ReadData::Alignment source_numbers="23", target_numbers="12", tag_name="wa">
For example , the multi-word expression tear-filled is treated as one instance but not tagged with any WordNet synsets in the converted corpus , while in the original corpus it is tagged with two WordNet synsets for tear and filled .
#<struct ReadData::Alignment source_numbers="30", target_numbers="35", tag_name="wa">
For example , the multi-word expression tear-filled is treated as one instance but not tagged with any WordNet synsets in the converted corpus , while in the original corpus it is tagged with two WordNet synsets for tear and filled .
#<struct ReadData::Alignment source_numbers="31", target_numbers="36", tag_name="wa">
For example , the multi-word expression tear-filled is treated as one instance but not tagged with any WordNet synsets in the converted corpus , while in the original corpus it is tagged with two WordNet synsets for tear and filled .
#<struct ReadData::Alignment source_numbers="32", target_numbers="37", tag_name="wa">
For example , the multi-word expression tear-filled is treated as one instance but not tagged with any WordNet synsets in the converted corpus , while in the original corpus it is tagged with two WordNet synsets for tear and filled .
#<struct ReadData::Alignment source_numbers="33", target_numbers="38", tag_name="wa">
For example , the multi-word expression tear-filled is treated as one instance but not tagged with any WordNet synsets in the converted corpus , while in the original corpus it is tagged with two WordNet synsets for tear and filled .
#<struct ReadData::Alignment source_numbers="34", target_numbers="39", tag_name="wa">
For example , the multi-word expression tear-filled is treated as one instance but not tagged with any WordNet synsets in the converted corpus , while in the original corpus it is tagged with two WordNet synsets for tear and filled .
#<struct ReadData::Alignment source_numbers="35", target_numbers="40", tag_name="wa">
For example , the multi-word expression tear-filled is treated as one instance but not tagged with any WordNet synsets in the converted corpus , while in the original corpus it is tagged with two WordNet synsets for tear and filled .
#<struct ReadData::Alignment source_numbers="36", target_numbers="41", tag_name="wa">
For example , the multi-word expression tear-filled is treated as one instance but not tagged with any WordNet synsets in the converted corpus , while in the original corpus it is tagged with two WordNet synsets for tear and filled .
#<struct ReadData::Alignment source_numbers="37", target_numbers="42", tag_name="wa">
For example , the multi-word expression tear-filled is treated as one instance but not tagged with any WordNet synsets in the converted corpus , while in the original corpus it is tagged with two WordNet synsets for tear and filled .
#<struct ReadData::Alignment source_numbers="38", target_numbers="43", tag_name="wa">
For example , the multi-word expression tear-filled is treated as one instance but not tagged with any WordNet synsets in the converted corpus , while in the original corpus it is tagged with two WordNet synsets for tear and filled .
#<struct ReadData::Alignment source_numbers="39", target_numbers="44", tag_name="wa">
For example , the multi-word expression tear-filled is treated as one instance but not tagged with any WordNet synsets in the converted corpus , while in the original corpus it is tagged with two WordNet synsets for tear and filled .
#<struct ReadData::Alignment source_numbers="40", target_numbers="45", tag_name="wa">
For example , the multi-word expression tear-filled is treated as one instance but not tagged with any WordNet synsets in the converted corpus , while in the original corpus it is tagged with two WordNet synsets for tear and filled .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
For example , the multi-word expression tear-filled is treated as one instance but not tagged with any WordNet synsets in the converted corpus , while in the original corpus it is tagged with two WordNet synsets for tear and filled .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
For example , the multi-word expression tear-filled is treated as one instance but not tagged with any WordNet synsets in the converted corpus , while in the original corpus it is tagged with two WordNet synsets for tear and filled .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
For example , the multi-word expression tear-filled is treated as one instance but not tagged with any WordNet synsets in the converted corpus , while in the original corpus it is tagged with two WordNet synsets for tear and filled .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
For example , the multi-word expression tear-filled is treated as one instance but not tagged with any WordNet synsets in the converted corpus , while in the original corpus it is tagged with two WordNet synsets for tear and filled .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
For example , the multi-word expression tear-filled is treated as one instance but not tagged with any WordNet synsets in the converted corpus , while in the original corpus it is tagged with two WordNet synsets for tear and filled .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
For example , the multi-word expression tear-filled is treated as one instance but not tagged with any WordNet synsets in the converted corpus , while in the original corpus it is tagged with two WordNet synsets for tear and filled .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
For example , the multi-word expression tear-filled is treated as one instance but not tagged with any WordNet synsets in the converted corpus , while in the original corpus it is tagged with two WordNet synsets for tear and filled .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
For example , the multi-word expression tear-filled is treated as one instance but not tagged with any WordNet synsets in the converted corpus , while in the original corpus it is tagged with two WordNet synsets for tear and filled .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
For the evaluation on the Senseval data sets , all instances of the rest ( e.g. SEM-E ) is used for development and one of the Senseval data sets ( SE2 or SE3 ) is used for evaluation .
#<struct ReadData::Alignment source_numbers="18,19", target_numbers="18,19", tag_name="wa">
For the evaluation on the Senseval data sets , all instances of the rest ( e.g. SEM-E ) is used for development and one of the Senseval data sets ( SE2 or SE3 ) is used for evaluation .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
As the evaluation measure , we use the standard recall measure , which is equivalent to the precision as we output answers to all instances .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
As the evaluation measure , we use the standard recall measure , which is equivalent to the precision as we output answers to all instances .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
As the evaluation measure , we use the standard recall measure , which is equivalent to the precision as we output answers to all instances .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
As the evaluation measure , we use the standard recall measure , which is equivalent to the precision as we output answers to all instances .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
As the evaluation measure , we use the standard recall measure , which is equivalent to the precision as we output answers to all instances .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
As the evaluation measure , we use the standard recall measure , which is equivalent to the precision as we output answers to all instances .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
As they noted , in the WordNet , there is semantically inconsistent labeling of supersenses such that top level synsets are tagged as the supersense noun .Tops rather than the specific supersense they govern .
#<struct ReadData::Alignment source_numbers="29", target_numbers="7", tag_name="wa">
As they noted , in the WordNet , there is semantically inconsistent labeling of supersenses such that top level synsets are tagged as the supersense noun .Tops rather than the specific supersense they govern .
#<struct ReadData::Alignment source_numbers="12", target_numbers="8", tag_name="wa">
As they noted , in the WordNet , there is semantically inconsistent labeling of supersenses such that top level synsets are tagged as the supersense noun .Tops rather than the specific supersense they govern .
#<struct ReadData::Alignment source_numbers="13", target_numbers="9", tag_name="wa">
As they noted , in the WordNet , there is semantically inconsistent labeling of supersenses such that top level synsets are tagged as the supersense noun .Tops rather than the specific supersense they govern .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
As they noted , in the WordNet , there is semantically inconsistent labeling of supersenses such that top level synsets are tagged as the supersense noun .Tops rather than the specific supersense they govern .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
As they noted , in the WordNet , there is semantically inconsistent labeling of supersenses such that top level synsets are tagged as the supersense noun .Tops rather than the specific supersense they govern .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
As they noted , in the WordNet , there is semantically inconsistent labeling of supersenses such that top level synsets are tagged as the supersense noun .Tops rather than the specific supersense they govern .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
As they noted , in the WordNet , there is semantically inconsistent labeling of supersenses such that top level synsets are tagged as the supersense noun .Tops rather than the specific supersense they govern .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
As they noted , in the WordNet , there is semantically inconsistent labeling of supersenses such that top level synsets are tagged as the supersense noun .Tops rather than the specific supersense they govern .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
As they noted , in the WordNet , there is semantically inconsistent labeling of supersenses such that top level synsets are tagged as the supersense noun .Tops rather than the specific supersense they govern .
#<struct ReadData::Alignment source_numbers="26", target_numbers="", tag_name="wa">
As they noted , in the WordNet , there is semantically inconsistent labeling of supersenses such that top level synsets are tagged as the supersense noun .Tops rather than the specific supersense they govern .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
As they noted , in the WordNet , there is semantically inconsistent labeling of supersenses such that top level synsets are tagged as the supersense noun .Tops rather than the specific supersense they govern .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
As they noted , in the WordNet , there is semantically inconsistent labeling of supersenses such that top level synsets are tagged as the supersense noun .Tops rather than the specific supersense they govern .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
As they noted , in the WordNet , there is semantically inconsistent labeling of supersenses such that top level synsets are tagged as the supersense noun .Tops rather than the specific supersense they govern .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
As they noted , in the WordNet , there is semantically inconsistent labeling of supersenses such that top level synsets are tagged as the supersense noun .Tops rather than the specific supersense they govern .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
As they noted , in the WordNet , there is semantically inconsistent labeling of supersenses such that top level synsets are tagged as the supersense noun .Tops rather than the specific supersense they govern .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
As they noted , in the WordNet , there is semantically inconsistent labeling of supersenses such that top level synsets are tagged as the supersense noun .Tops rather than the specific supersense they govern .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
For this reason , we adopted the modification of noun supersenses in the same way as , substituting noun .Tops labels with more specific supersense labels when possible , and left some general nouns with noun .TopsoteNouns which are left with noun .Tops are : entity , thing , anything , something , nothing , object , living thing , organism , benthos , heterotroph , life , and biont . .
#<struct ReadData::Alignment source_numbers="67", target_numbers="37", tag_name="wa">
For this reason , we adopted the modification of noun supersenses in the same way as , substituting noun .Tops labels with more specific supersense labels when possible , and left some general nouns with noun .TopsoteNouns which are left with noun .Tops are : entity , thing , anything , something , nothing , object , living thing , organism , benthos , heterotroph , life , and biont . .
#<struct ReadData::Alignment source_numbers="", target_numbers="68", tag_name="wa">
We ignore the adjective and adverb instances in the evaluation .
#<struct ReadData::Alignment source_numbers="10", target_numbers="16", tag_name="wa">
We ignore the adjective and adverb instances in the evaluation .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
We ignore the adjective and adverb instances in the evaluation .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
We ignore the adjective and adverb instances in the evaluation .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
We ignore the adjective and adverb instances in the evaluation .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
We ignore the adjective and adverb instances in the evaluation .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
We ignore the adjective and adverb instances in the evaluation .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
We ignore the adjective and adverb instances in the evaluation .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
We ignore the adjective and adverb instances in the evaluation .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
We ignore the adjective and adverb instances in the evaluation .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
We ignore the adjective and adverb instances in the evaluation .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
We ignore the adjective and adverb instances in the evaluation .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
We ignore the adjective and adverb instances in the evaluation .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
We ignore the adjective and adverb instances in the evaluation .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
We ignore the adjective and adverb instances in the evaluation .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
Table 6 is the list of models we use for the evaluation , where FS and SR correspond to the first sense and sense ranking features respectively , and non-dependency denotes models that do not incorporate sense dependency features ( i.e.
#<struct ReadData::Alignment source_numbers="32", target_numbers="7", tag_name="wa">
Table 6 is the list of models we use for the evaluation , where FS and SR correspond to the first sense and sense ranking features respectively , and non-dependency denotes models that do not incorporate sense dependency features ( i.e.
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
In this section , each figure shows the mean recall ( equivalent to the precisions ) averaged over the five trials of the cross validation , the " Diff . " rows show the differences between the dependency models and the non-dependency models , and / MATH and / MATH denote the statistical significance of / MATH and / MATH respectively .
#<struct ReadData::Alignment source_numbers="25", target_numbers="21", tag_name="wa">
In this section , each figure shows the mean recall ( equivalent to the precisions ) averaged over the five trials of the cross validation , the " Diff . " rows show the differences between the dependency models and the non-dependency models , and / MATH and / MATH denote the statistical significance of / MATH and / MATH respectively .
#<struct ReadData::Alignment source_numbers="29", target_numbers="25", tag_name="wa">
In this section , each figure shows the mean recall ( equivalent to the precisions ) averaged over the five trials of the cross validation , the " Diff . " rows show the differences between the dependency models and the non-dependency models , and / MATH and / MATH denote the statistical significance of / MATH and / MATH respectively .
#<struct ReadData::Alignment source_numbers="43", target_numbers="39", tag_name="wa">
In this section , each figure shows the mean recall ( equivalent to the precisions ) averaged over the five trials of the cross validation , the " Diff . " rows show the differences between the dependency models and the non-dependency models , and / MATH and / MATH denote the statistical significance of / MATH and / MATH respectively .
#<struct ReadData::Alignment source_numbers="50", target_numbers="46", tag_name="wa">
In this section , each figure shows the mean recall ( equivalent to the precisions ) averaged over the five trials of the cross validation , the " Diff . " rows show the differences between the dependency models and the non-dependency models , and / MATH and / MATH denote the statistical significance of / MATH and / MATH respectively .
#<struct ReadData::Alignment source_numbers="51", target_numbers="47", tag_name="wa">
In this section , each figure shows the mean recall ( equivalent to the precisions ) averaged over the five trials of the cross validation , the " Diff . " rows show the differences between the dependency models and the non-dependency models , and / MATH and / MATH denote the statistical significance of / MATH and / MATH respectively .
#<struct ReadData::Alignment source_numbers="52", target_numbers="48", tag_name="wa">
In this section , each figure shows the mean recall ( equivalent to the precisions ) averaged over the five trials of the cross validation , the " Diff . " rows show the differences between the dependency models and the non-dependency models , and / MATH and / MATH denote the statistical significance of / MATH and / MATH respectively .
#<struct ReadData::Alignment source_numbers="53", target_numbers="49", tag_name="wa">
In this section , each figure shows the mean recall ( equivalent to the precisions ) averaged over the five trials of the cross validation , the " Diff . " rows show the differences between the dependency models and the non-dependency models , and / MATH and / MATH denote the statistical significance of / MATH and / MATH respectively .
#<struct ReadData::Alignment source_numbers="54", target_numbers="50", tag_name="wa">
In this section , each figure shows the mean recall ( equivalent to the precisions ) averaged over the five trials of the cross validation , the " Diff . " rows show the differences between the dependency models and the non-dependency models , and / MATH and / MATH denote the statistical significance of / MATH and / MATH respectively .
#<struct ReadData::Alignment source_numbers="55", target_numbers="51", tag_name="wa">
In this section , each figure shows the mean recall ( equivalent to the precisions ) averaged over the five trials of the cross validation , the " Diff . " rows show the differences between the dependency models and the non-dependency models , and / MATH and / MATH denote the statistical significance of / MATH and / MATH respectively .
#<struct ReadData::Alignment source_numbers="56", target_numbers="52", tag_name="wa">
In this section , each figure shows the mean recall ( equivalent to the precisions ) averaged over the five trials of the cross validation , the " Diff . " rows show the differences between the dependency models and the non-dependency models , and / MATH and / MATH denote the statistical significance of / MATH and / MATH respectively .
#<struct ReadData::Alignment source_numbers="57", target_numbers="53", tag_name="wa">
In this section , each figure shows the mean recall ( equivalent to the precisions ) averaged over the five trials of the cross validation , the " Diff . " rows show the differences between the dependency models and the non-dependency models , and / MATH and / MATH denote the statistical significance of / MATH and / MATH respectively .
#<struct ReadData::Alignment source_numbers="58", target_numbers="54", tag_name="wa">
In this section , each figure shows the mean recall ( equivalent to the precisions ) averaged over the five trials of the cross validation , the " Diff . " rows show the differences between the dependency models and the non-dependency models , and / MATH and / MATH denote the statistical significance of / MATH and / MATH respectively .
#<struct ReadData::Alignment source_numbers="59", target_numbers="55", tag_name="wa">
In this section , each figure shows the mean recall ( equivalent to the precisions ) averaged over the five trials of the cross validation , the " Diff . " rows show the differences between the dependency models and the non-dependency models , and / MATH and / MATH denote the statistical significance of / MATH and / MATH respectively .
#<struct ReadData::Alignment source_numbers="60", target_numbers="56", tag_name="wa">
In this section , each figure shows the mean recall ( equivalent to the precisions ) averaged over the five trials of the cross validation , the " Diff . " rows show the differences between the dependency models and the non-dependency models , and / MATH and / MATH denote the statistical significance of / MATH and / MATH respectively .
#<struct ReadData::Alignment source_numbers="61", target_numbers="57", tag_name="wa">
In this section , each figure shows the mean recall ( equivalent to the precisions ) averaged over the five trials of the cross validation , the " Diff . " rows show the differences between the dependency models and the non-dependency models , and / MATH and / MATH denote the statistical significance of / MATH and / MATH respectively .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
In this section , each figure shows the mean recall ( equivalent to the precisions ) averaged over the five trials of the cross validation , the " Diff . " rows show the differences between the dependency models and the non-dependency models , and / MATH and / MATH denote the statistical significance of / MATH and / MATH respectively .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
In this section , each figure shows the mean recall ( equivalent to the precisions ) averaged over the five trials of the cross validation , the " Diff . " rows show the differences between the dependency models and the non-dependency models , and / MATH and / MATH denote the statistical significance of / MATH and / MATH respectively .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
In this section , each figure shows the mean recall ( equivalent to the precisions ) averaged over the five trials of the cross validation , the " Diff . " rows show the differences between the dependency models and the non-dependency models , and / MATH and / MATH denote the statistical significance of / MATH and / MATH respectively .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
In this section , each figure shows the mean recall ( equivalent to the precisions ) averaged over the five trials of the cross validation , the " Diff . " rows show the differences between the dependency models and the non-dependency models , and / MATH and / MATH denote the statistical significance of / MATH and / MATH respectively .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
In this section , each figure shows the mean recall ( equivalent to the precisions ) averaged over the five trials of the cross validation , the " Diff . " rows show the differences between the dependency models and the non-dependency models , and / MATH and / MATH denote the statistical significance of / MATH and / MATH respectively .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
We can see from Table 7 that with the sense frequency information , the tree-structured models ( statistically ) significantly outperformed the non-dependency models on all the data sets .
#<struct ReadData::Alignment source_numbers="1", target_numbers="5", tag_name="wa">
We can see from Table 7 that with the sense frequency information , the tree-structured models ( statistically ) significantly outperformed the non-dependency models on all the data sets .
#<struct ReadData::Alignment source_numbers="2", target_numbers="6,7", tag_name="wa">
We can see from Table 7 that with the sense frequency information , the tree-structured models ( statistically ) significantly outperformed the non-dependency models on all the data sets .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
We can see from Table 7 that with the sense frequency information , the tree-structured models ( statistically ) significantly outperformed the non-dependency models on all the data sets .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
We can see from Table 7 that with the sense frequency information , the tree-structured models ( statistically ) significantly outperformed the non-dependency models on all the data sets .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
We can see from Table 7 that with the sense frequency information , the tree-structured models ( statistically ) significantly outperformed the non-dependency models on all the data sets .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
We can see from Table 7 that with the sense frequency information , the tree-structured models ( statistically ) significantly outperformed the non-dependency models on all the data sets .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
These improvements seem small in terms of figures ; However , considering for instance the No-Dep-SS-FS model outperforms the Baseline-SS-FS model only by 0 .37% on SEM , the further improvement of 0 .21% is considerable because this means our dependency model could handle 57% more instances over the first sense baseline .
#<struct ReadData::Alignment source_numbers="3", target_numbers="3", tag_name="wa">
These improvements seem small in terms of figures ; However , considering for instance the No-Dep-SS-FS model outperforms the Baseline-SS-FS model only by 0 .37% on SEM , the further improvement of 0 .21% is considerable because this means our dependency model could handle 57% more instances over the first sense baseline .
#<struct ReadData::Alignment source_numbers="4", target_numbers="4", tag_name="wa">
These improvements seem small in terms of figures ; However , considering for instance the No-Dep-SS-FS model outperforms the Baseline-SS-FS model only by 0 .37% on SEM , the further improvement of 0 .21% is considerable because this means our dependency model could handle 57% more instances over the first sense baseline .
#<struct ReadData::Alignment source_numbers="36,37", target_numbers="36,37", tag_name="wa">
These improvements seem small in terms of figures ; However , considering for instance the No-Dep-SS-FS model outperforms the Baseline-SS-FS model only by 0 .37% on SEM , the further improvement of 0 .21% is considerable because this means our dependency model could handle 57% more instances over the first sense baseline .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
These improvements seem small in terms of figures ; However , considering for instance the No-Dep-SS-FS model outperforms the Baseline-SS-FS model only by 0 .37% on SEM , the further improvement of 0 .21% is considerable because this means our dependency model could handle 57% more instances over the first sense baseline .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
These improvements seem small in terms of figures ; However , considering for instance the No-Dep-SS-FS model outperforms the Baseline-SS-FS model only by 0 .37% on SEM , the further improvement of 0 .21% is considerable because this means our dependency model could handle 57% more instances over the first sense baseline .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
These improvements seem small in terms of figures ; However , considering for instance the No-Dep-SS-FS model outperforms the Baseline-SS-FS model only by 0 .37% on SEM , the further improvement of 0 .21% is considerable because this means our dependency model could handle 57% more instances over the first sense baseline .
#<struct ReadData::Alignment source_numbers="38", target_numbers="", tag_name="wa">
These improvements seem small in terms of figures ; However , considering for instance the No-Dep-SS-FS model outperforms the Baseline-SS-FS model only by 0 .37% on SEM , the further improvement of 0 .21% is considerable because this means our dependency model could handle 57% more instances over the first sense baseline .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
These improvements seem small in terms of figures ; However , considering for instance the No-Dep-SS-FS model outperforms the Baseline-SS-FS model only by 0 .37% on SEM , the further improvement of 0 .21% is considerable because this means our dependency model could handle 57% more instances over the first sense baseline .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
These improvements seem small in terms of figures ; However , considering for instance the No-Dep-SS-FS model outperforms the Baseline-SS-FS model only by 0 .37% on SEM , the further improvement of 0 .21% is considerable because this means our dependency model could handle 57% more instances over the first sense baseline .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
These improvements seem small in terms of figures ; However , considering for instance the No-Dep-SS-FS model outperforms the Baseline-SS-FS model only by 0 .37% on SEM , the further improvement of 0 .21% is considerable because this means our dependency model could handle 57% more instances over the first sense baseline .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
These improvements seem small in terms of figures ; However , considering for instance the No-Dep-SS-FS model outperforms the Baseline-SS-FS model only by 0 .37% on SEM , the further improvement of 0 .21% is considerable because this means our dependency model could handle 57% more instances over the first sense baseline .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
Note that , without the sense frequency information , the synset-based tree-structured model ( Tree-WS ) performed poorer than the non-dependency model ( NoDep-WS ) on all the data sets , whereas the supersense-based model ( Tree-SS ) exhibited the robustness regardless of the existence of the sense frequency information .
#<struct ReadData::Alignment source_numbers="17,18", target_numbers="17,18", tag_name="wa">
Note that , without the sense frequency information , the synset-based tree-structured model ( Tree-WS ) performed poorer than the non-dependency model ( NoDep-WS ) on all the data sets , whereas the supersense-based model ( Tree-SS ) exhibited the robustness regardless of the existence of the sense frequency information .
#<struct ReadData::Alignment source_numbers="", target_numbers="41", tag_name="wa">
Note that , without the sense frequency information , the synset-based tree-structured model ( Tree-WS ) performed poorer than the non-dependency model ( NoDep-WS ) on all the data sets , whereas the supersense-based model ( Tree-SS ) exhibited the robustness regardless of the existence of the sense frequency information .
#<struct ReadData::Alignment source_numbers="", target_numbers="42", tag_name="wa">
However , by the incorporation of the sense dependencies , the improvements with the sense ranking features are even smaller , and the deteriorations without them are even larger than in the tree-structured case .
#<struct ReadData::Alignment source_numbers="18,19", target_numbers="18,19", tag_name="wa">
However , by the incorporation of the sense dependencies , the improvements with the sense ranking features are even smaller , and the deteriorations without them are even larger than in the tree-structured case .
#<struct ReadData::Alignment source_numbers="26,27", target_numbers="30,31", tag_name="wa">
However , by the incorporation of the sense dependencies , the improvements with the sense ranking features are even smaller , and the deteriorations without them are even larger than in the tree-structured case .
#<struct ReadData::Alignment source_numbers="28,29", target_numbers="32,33", tag_name="wa">
However , by the incorporation of the sense dependencies , the improvements with the sense ranking features are even smaller , and the deteriorations without them are even larger than in the tree-structured case .
#<struct ReadData::Alignment source_numbers="30", target_numbers="34", tag_name="wa">
However , by the incorporation of the sense dependencies , the improvements with the sense ranking features are even smaller , and the deteriorations without them are even larger than in the tree-structured case .
#<struct ReadData::Alignment source_numbers="31", target_numbers="35", tag_name="wa">
However , by the incorporation of the sense dependencies , the improvements with the sense ranking features are even smaller , and the deteriorations without them are even larger than in the tree-structured case .
#<struct ReadData::Alignment source_numbers="32", target_numbers="36", tag_name="wa">
However , by the incorporation of the sense dependencies , the improvements with the sense ranking features are even smaller , and the deteriorations without them are even larger than in the tree-structured case .
#<struct ReadData::Alignment source_numbers="33", target_numbers="37", tag_name="wa">
However , by the incorporation of the sense dependencies , the improvements with the sense ranking features are even smaller , and the deteriorations without them are even larger than in the tree-structured case .
#<struct ReadData::Alignment source_numbers="34", target_numbers="38", tag_name="wa">
However , by the incorporation of the sense dependencies , the improvements with the sense ranking features are even smaller , and the deteriorations without them are even larger than in the tree-structured case .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
However , by the incorporation of the sense dependencies , the improvements with the sense ranking features are even smaller , and the deteriorations without them are even larger than in the tree-structured case .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
However , by the incorporation of the sense dependencies , the improvements with the sense ranking features are even smaller , and the deteriorations without them are even larger than in the tree-structured case .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
However , by the incorporation of the sense dependencies , the improvements with the sense ranking features are even smaller , and the deteriorations without them are even larger than in the tree-structured case .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
However , by the incorporation of the sense dependencies , the improvements with the sense ranking features are even smaller , and the deteriorations without them are even larger than in the tree-structured case .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
However , by the incorporation of the sense dependencies , the improvements with the sense ranking features are even smaller , and the deteriorations without them are even larger than in the tree-structured case .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
In the results shown in Table 9 , although some of the differences are marginal , we can see that the tree-structured models outperformed the linear-chain models , focusing on the statistically significant differences .
#<struct ReadData::Alignment source_numbers="34", target_numbers="", tag_name="wa">
In the results shown in Table 9 , although some of the differences are marginal , we can see that the tree-structured models outperformed the linear-chain models , focusing on the statistically significant differences .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
In the results shown in Table 9 , although some of the differences are marginal , we can see that the tree-structured models outperformed the linear-chain models , focusing on the statistically significant differences .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
In the results shown in Table 9 , although some of the differences are marginal , we can see that the tree-structured models outperformed the linear-chain models , focusing on the statistically significant differences .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
In the results shown in Table 9 , although some of the differences are marginal , we can see that the tree-structured models outperformed the linear-chain models , focusing on the statistically significant differences .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
In the results shown in Table 9 , although some of the differences are marginal , we can see that the tree-structured models outperformed the linear-chain models , focusing on the statistically significant differences .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
These results suggest that although both the dependency trees and the linear chains capture useful dependencies of word senses , the dependencies on the tree structures capture more important information .
#<struct ReadData::Alignment source_numbers="19", target_numbers="1", tag_name="wa">
These results suggest that although both the dependency trees and the linear chains capture useful dependencies of word senses , the dependencies on the tree structures capture more important information .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
These results suggest that although both the dependency trees and the linear chains capture useful dependencies of word senses , the dependencies on the tree structures capture more important information .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
These results suggest that although both the dependency trees and the linear chains capture useful dependencies of word senses , the dependencies on the tree structures capture more important information .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
These results suggest that although both the dependency trees and the linear chains capture useful dependencies of word senses , the dependencies on the tree structures capture more important information .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
These results suggest that although both the dependency trees and the linear chains capture useful dependencies of word senses , the dependencies on the tree structures capture more important information .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
These results suggest that although both the dependency trees and the linear chains capture useful dependencies of word senses , the dependencies on the tree structures capture more important information .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Whereas Tree-WS-SR and Tree-WS use all four sense labels for the edge features ( / MATH ) , Tree-WS-SR' and Tree-WS' only use the synset labels ( / MATH ) , so that we can see the contribution of the coarse-grained sense labels .
#<struct ReadData::Alignment source_numbers="43", target_numbers="30", tag_name="wa">
Whereas Tree-WS-SR and Tree-WS use all four sense labels for the edge features ( / MATH ) , Tree-WS-SR' and Tree-WS' only use the synset labels ( / MATH ) , so that we can see the contribution of the coarse-grained sense labels .
#<struct ReadData::Alignment source_numbers="31", target_numbers="", tag_name="wa">
Whereas Tree-WS-SR and Tree-WS use all four sense labels for the edge features ( / MATH ) , Tree-WS-SR' and Tree-WS' only use the synset labels ( / MATH ) , so that we can see the contribution of the coarse-grained sense labels .
#<struct ReadData::Alignment source_numbers="32", target_numbers="", tag_name="wa">
Whereas Tree-WS-SR and Tree-WS use all four sense labels for the edge features ( / MATH ) , Tree-WS-SR' and Tree-WS' only use the synset labels ( / MATH ) , so that we can see the contribution of the coarse-grained sense labels .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
Whereas Tree-WS-SR and Tree-WS use all four sense labels for the edge features ( / MATH ) , Tree-WS-SR' and Tree-WS' only use the synset labels ( / MATH ) , so that we can see the contribution of the coarse-grained sense labels .
#<struct ReadData::Alignment source_numbers="", target_numbers="43", tag_name="wa">
Interestingly , when evaluated at the supersense level , the synset-based models considerably outperformed the supersense-based models , with the overall improvements of 0 .69% with the sense frequency information and 1 .41% without it , as shown in Table fcomp-ws-ss-tree .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
Interestingly , when evaluated at the supersense level , the synset-based models considerably outperformed the supersense-based models , with the overall improvements of 0 .69% with the sense frequency information and 1 .41% without it , as shown in Table fcomp-ws-ss-tree .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
These results suggest that even though the granularity of the supersenses is sufficient for many NLP tasks , they are too coarse-grained to capture enough information for WSD models ; Therefore , even for the supersense-based disambiguation , we can improve the performance by considering finer-grained senses .
#<struct ReadData::Alignment source_numbers="31", target_numbers="1", tag_name="wa">
These results suggest that even though the granularity of the supersenses is sufficient for many NLP tasks , they are too coarse-grained to capture enough information for WSD models ; Therefore , even for the supersense-based disambiguation , we can improve the performance by considering finer-grained senses .
#<struct ReadData::Alignment source_numbers="37", target_numbers="29", tag_name="wa">
These results suggest that even though the granularity of the supersenses is sufficient for many NLP tasks , they are too coarse-grained to capture enough information for WSD models ; Therefore , even for the supersense-based disambiguation , we can improve the performance by considering finer-grained senses .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
These results suggest that even though the granularity of the supersenses is sufficient for many NLP tasks , they are too coarse-grained to capture enough information for WSD models ; Therefore , even for the supersense-based disambiguation , we can improve the performance by considering finer-grained senses .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
These results suggest that even though the granularity of the supersenses is sufficient for many NLP tasks , they are too coarse-grained to capture enough information for WSD models ; Therefore , even for the supersense-based disambiguation , we can improve the performance by considering finer-grained senses .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
These results suggest that even though the granularity of the supersenses is sufficient for many NLP tasks , they are too coarse-grained to capture enough information for WSD models ; Therefore , even for the supersense-based disambiguation , we can improve the performance by considering finer-grained senses .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
These results suggest that even though the granularity of the supersenses is sufficient for many NLP tasks , they are too coarse-grained to capture enough information for WSD models ; Therefore , even for the supersense-based disambiguation , we can improve the performance by considering finer-grained senses .
#<struct ReadData::Alignment source_numbers="30", target_numbers="", tag_name="wa">
These results suggest that even though the granularity of the supersenses is sufficient for many NLP tasks , they are too coarse-grained to capture enough information for WSD models ; Therefore , even for the supersense-based disambiguation , we can improve the performance by considering finer-grained senses .
#<struct ReadData::Alignment source_numbers="32", target_numbers="", tag_name="wa">
These results suggest that even though the granularity of the supersenses is sufficient for many NLP tasks , they are too coarse-grained to capture enough information for WSD models ; Therefore , even for the supersense-based disambiguation , we can improve the performance by considering finer-grained senses .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
These results suggest that even though the granularity of the supersenses is sufficient for many NLP tasks , they are too coarse-grained to capture enough information for WSD models ; Therefore , even for the supersense-based disambiguation , we can improve the performance by considering finer-grained senses .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
These results suggest that even though the granularity of the supersenses is sufficient for many NLP tasks , they are too coarse-grained to capture enough information for WSD models ; Therefore , even for the supersense-based disambiguation , we can improve the performance by considering finer-grained senses .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
However , considering that all systems in Table 12 except for Simil-Prime utilize other sense-annotated corpora in addition to SemCor , such as the Senseval data sets or example sentences in the WordNet , and our model cannot handle multi-word expressions that do not exist in the WordNet as noted in Section 5 .1 , we can conclude that the performance of our T-CRF model is comparable to that of state-of-the-art WSD systems .
#<struct ReadData::Alignment source_numbers="68", target_numbers="37", tag_name="wa">
However , considering that all systems in Table 12 except for Simil-Prime utilize other sense-annotated corpora in addition to SemCor , such as the Senseval data sets or example sentences in the WordNet , and our model cannot handle multi-word expressions that do not exist in the WordNet as noted in Section 5 .1 , we can conclude that the performance of our T-CRF model is comparable to that of state-of-the-art WSD systems .
#<struct ReadData::Alignment source_numbers="", target_numbers="71", tag_name="wa">
However , considering that all systems in Table 12 except for Simil-Prime utilize other sense-annotated corpora in addition to SemCor , such as the Senseval data sets or example sentences in the WordNet , and our model cannot handle multi-word expressions that do not exist in the WordNet as noted in Section 5 .1 , we can conclude that the performance of our T-CRF model is comparable to that of state-of-the-art WSD systems .
#<struct ReadData::Alignment source_numbers="", target_numbers="77", tag_name="wa">
However , considering that all systems in Table 12 except for Simil-Prime utilize other sense-annotated corpora in addition to SemCor , such as the Senseval data sets or example sentences in the WordNet , and our model cannot handle multi-word expressions that do not exist in the WordNet as noted in Section 5 .1 , we can conclude that the performance of our T-CRF model is comparable to that of state-of-the-art WSD systems .
#<struct ReadData::Alignment source_numbers="", target_numbers="78", tag_name="wa">
However , considering that all systems in Table 12 except for Simil-Prime utilize other sense-annotated corpora in addition to SemCor , such as the Senseval data sets or example sentences in the WordNet , and our model cannot handle multi-word expressions that do not exist in the WordNet as noted in Section 5 .1 , we can conclude that the performance of our T-CRF model is comparable to that of state-of-the-art WSD systems .
#<struct ReadData::Alignment source_numbers="", target_numbers="79", tag_name="wa">
However , considering that all systems in Table 12 except for Simil-Prime utilize other sense-annotated corpora in addition to SemCor , such as the Senseval data sets or example sentences in the WordNet , and our model cannot handle multi-word expressions that do not exist in the WordNet as noted in Section 5 .1 , we can conclude that the performance of our T-CRF model is comparable to that of state-of-the-art WSD systems .
#<struct ReadData::Alignment source_numbers="", target_numbers="80", tag_name="wa">
However , considering that all systems in Table 12 except for Simil-Prime utilize other sense-annotated corpora in addition to SemCor , such as the Senseval data sets or example sentences in the WordNet , and our model cannot handle multi-word expressions that do not exist in the WordNet as noted in Section 5 .1 , we can conclude that the performance of our T-CRF model is comparable to that of state-of-the-art WSD systems .
#<struct ReadData::Alignment source_numbers="", target_numbers="81", tag_name="wa">
However , considering that all systems in Table 12 except for Simil-Prime utilize other sense-annotated corpora in addition to SemCor , such as the Senseval data sets or example sentences in the WordNet , and our model cannot handle multi-word expressions that do not exist in the WordNet as noted in Section 5 .1 , we can conclude that the performance of our T-CRF model is comparable to that of state-of-the-art WSD systems .
#<struct ReadData::Alignment source_numbers="", target_numbers="82", tag_name="wa">
However , considering that all systems in Table 12 except for Simil-Prime utilize other sense-annotated corpora in addition to SemCor , such as the Senseval data sets or example sentences in the WordNet , and our model cannot handle multi-word expressions that do not exist in the WordNet as noted in Section 5 .1 , we can conclude that the performance of our T-CRF model is comparable to that of state-of-the-art WSD systems .
#<struct ReadData::Alignment source_numbers="", target_numbers="83", tag_name="wa">
We call a feature either with a positive lambda or with an alpha larger than 1 as an excitatory feature , while that either with a negative lambda or an alpha smaller than 1 as an inhibitory feature .
#<struct ReadData::Alignment source_numbers="24", target_numbers="24", tag_name="wa">
We call a feature either with a positive lambda or with an alpha larger than 1 as an excitatory feature , while that either with a negative lambda or an alpha smaller than 1 as an inhibitory feature .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
We call a feature either with a positive lambda or with an alpha larger than 1 as an excitatory feature , while that either with a negative lambda or an alpha smaller than 1 as an inhibitory feature .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
We call a feature either with a positive lambda or with an alpha larger than 1 as an excitatory feature , while that either with a negative lambda or an alpha smaller than 1 as an inhibitory feature .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
We call a feature either with a positive lambda or with an alpha larger than 1 as an excitatory feature , while that either with a negative lambda or an alpha smaller than 1 as an inhibitory feature .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
We call a feature either with a positive lambda or with an alpha larger than 1 as an excitatory feature , while that either with a negative lambda or an alpha smaller than 1 as an inhibitory feature .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
We call a feature either with a positive lambda or with an alpha larger than 1 as an excitatory feature , while that either with a negative lambda or an alpha smaller than 1 as an inhibitory feature .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
Thus , although the difference of the recalls is small , we can assume that the sense dependency features in the tree-structured model and those in the linear-chain model have different contributions to the results .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
The simultaneous use of both is of an interest from practical and semantical perspectives ; However , since it makes our model no longer a tree , the implementation is not straightforward .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
The simultaneous use of both is of an interest from practical and semantical perspectives ; However , since it makes our model no longer a tree , the implementation is not straightforward .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
One noteworthy point is that more number of noun-noun dependencies are found in the positive instances than in the negative instances , which might suggest that noun-noun dependencies are particularly likely to capture useful dependencies and contribute to positive instances .
#<struct ReadData::Alignment source_numbers="24", target_numbers="23", tag_name="wa">
One noteworthy point is that more number of noun-noun dependencies are found in the positive instances than in the negative instances , which might suggest that noun-noun dependencies are particularly likely to capture useful dependencies and contribute to positive instances .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
One noteworthy point is that more number of noun-noun dependencies are found in the positive instances than in the negative instances , which might suggest that noun-noun dependencies are particularly likely to capture useful dependencies and contribute to positive instances .
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
One noteworthy point is that more number of noun-noun dependencies are found in the positive instances than in the negative instances , which might suggest that noun-noun dependencies are particularly likely to capture useful dependencies and contribute to positive instances .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
The first sentence is
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
The verb take has surprisingly as many as 42 senses in the WordNet .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
The verb take has surprisingly as many as 42 senses in the WordNet .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
The verb take has surprisingly as many as 42 senses in the WordNet .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
The verb take has surprisingly as many as 42 senses in the WordNet .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
The verb take has surprisingly as many as 42 senses in the WordNet .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
But , fortunatelly , the first six senses belong to different supersenses , and our dependency model succeeded in outputting the correct sense take#4 ( SS :verb .contact , take physically ) by making use of the strong dependency SS :verb .contact-SS :noun .substance ( / MATH ) , given dust#1 belongs to noun .substance .
#<struct ReadData::Alignment source_numbers="3", target_numbers="2", tag_name="wa">
But , fortunatelly , the first six senses belong to different supersenses , and our dependency model succeeded in outputting the correct sense take#4 ( SS :verb .contact , take physically ) by making use of the strong dependency SS :verb .contact-SS :noun .substance ( / MATH ) , given dust#1 belongs to noun .substance .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
But , fortunatelly , the first six senses belong to different supersenses , and our dependency model succeeded in outputting the correct sense take#4 ( SS :verb .contact , take physically ) by making use of the strong dependency SS :verb .contact-SS :noun .substance ( / MATH ) , given dust#1 belongs to noun .substance .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
But , fortunatelly , the first six senses belong to different supersenses , and our dependency model succeeded in outputting the correct sense take#4 ( SS :verb .contact , take physically ) by making use of the strong dependency SS :verb .contact-SS :noun .substance ( / MATH ) , given dust#1 belongs to noun .substance .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
While this verb-object dependency had a large excitatory weight , the corresponding verb-subject dependency had an inhibitory weight ( G1 :have( v )#2-( SBJ )-SS :noun .attribute ( / MATH ) ) , which means the dependency relationlabel also contributed to the result .
#<struct ReadData::Alignment source_numbers="34", target_numbers="", tag_name="wa">
While this verb-object dependency had a large excitatory weight , the corresponding verb-subject dependency had an inhibitory weight ( G1 :have( v )#2-( SBJ )-SS :noun .attribute ( / MATH ) ) , which means the dependency relationlabel also contributed to the result .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
While this verb-object dependency had a large excitatory weight , the corresponding verb-subject dependency had an inhibitory weight ( G1 :have( v )#2-( SBJ )-SS :noun .attribute ( / MATH ) ) , which means the dependency relationlabel also contributed to the result .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
From the phrase career as a player , we can assume that the correct sense of career can be either of two senses , and possibly there is a preference for career#2 , as captured by the largest-weighted dependency WS :career%1%2-( NMOD )-SS :noun .person ( / MATH ) between career and player .
#<struct ReadData::Alignment source_numbers="25", target_numbers="24,25,26", tag_name="wa">
From the phrase career as a player , we can assume that the correct sense of career can be either of two senses , and possibly there is a preference for career#2 , as captured by the largest-weighted dependency WS :career%1%2-( NMOD )-SS :noun .person ( / MATH ) between career and player .
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
From the phrase career as a player , we can assume that the correct sense of career can be either of two senses , and possibly there is a preference for career#2 , as captured by the largest-weighted dependency WS :career%1%2-( NMOD )-SS :noun .person ( / MATH ) between career and player .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
Since dependencies of this type were not observed in the negative instances at all , they seem to particularly contribute to the positive instances .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
Since dependencies of this type were not observed in the negative instances at all , they seem to particularly contribute to the positive instances .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
Another interesting result observed is that the noun-noun dependencies in coordination relations work remarkably strongly .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Another interesting result observed is that the noun-noun dependencies in coordination relations work remarkably strongly .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Another interesting result observed is that the noun-noun dependencies in coordination relations work remarkably strongly .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
Another interesting result observed is that the noun-noun dependencies in coordination relations work remarkably strongly .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
Another interesting result observed is that the noun-noun dependencies in coordination relations work remarkably strongly .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Another interesting result observed is that the noun-noun dependencies in coordination relations work remarkably strongly .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Another interesting result observed is that the noun-noun dependencies in coordination relations work remarkably strongly .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Another interesting result observed is that the noun-noun dependencies in coordination relations work remarkably strongly .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Another interesting result observed is that the noun-noun dependencies in coordination relations work remarkably strongly .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
Here , the correct sense for nail is nail#2 ( noun .artifact , a thin pointed piece of metal ) and that for level is level#5 ( noun .artifact , indicator of the horizontal ) .
#<struct ReadData::Alignment source_numbers="29", target_numbers="20", tag_name="wa">
Here , the correct sense for nail is nail#2 ( noun .artifact , a thin pointed piece of metal ) and that for level is level#5 ( noun .artifact , indicator of the horizontal ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
In this paper , we proposed a novel approach to the all-words WSD , focusing on the use of syntactic dependencies of word senses , and investigated the contribution of these dependencies to WSD .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
In this paper , we proposed a novel approach to the all-words WSD , focusing on the use of syntactic dependencies of word senses , and investigated the contribution of these dependencies to WSD .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
In our experiments , the sense dependency features were shown to work effectively for WSD , with 0 .29% , 0 .64% , and 0 .30% improvements of recalls for SemCor , Senseval-2 , and Senseval-3 data sets respectively .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
In our experiments , the sense dependency features were shown to work effectively for WSD , with 0 .29% , 0 .64% , and 0 .30% improvements of recalls for SemCor , Senseval-2 , and Senseval-3 data sets respectively .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
Despite the small improvements in terms of overall figures , these improvements indeed correspond to 25%-57% improvements over the first sense baseline .
#<struct ReadData::Alignment source_numbers="4", target_numbers="4", tag_name="wa">
Despite the small improvements in terms of overall figures , these improvements indeed correspond to 25%-57% improvements over the first sense baseline .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Despite the small improvements in terms of overall figures , these improvements indeed correspond to 25%-57% improvements over the first sense baseline .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
The dependency tree structures was shown to be appropriate for modeling the dependencies of word senses , by the results that the tree-structured models outperformed the linear-chain models .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
The dependency tree structures was shown to be appropriate for modeling the dependencies of word senses , by the results that the tree-structured models outperformed the linear-chain models .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
The dependency tree structures was shown to be appropriate for modeling the dependencies of word senses , by the results that the tree-structured models outperformed the linear-chain models .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
The dependency tree structures was shown to be appropriate for modeling the dependencies of word senses , by the results that the tree-structured models outperformed the linear-chain models .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
The dependency tree structures was shown to be appropriate for modeling the dependencies of word senses , by the results that the tree-structured models outperformed the linear-chain models .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
The dependency tree structures was shown to be appropriate for modeling the dependencies of word senses , by the results that the tree-structured models outperformed the linear-chain models .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
The dependency tree structures was shown to be appropriate for modeling the dependencies of word senses , by the results that the tree-structured models outperformed the linear-chain models .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
The dependency tree structures was shown to be appropriate for modeling the dependencies of word senses , by the results that the tree-structured models outperformed the linear-chain models .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
The dependency tree structures was shown to be appropriate for modeling the dependencies of word senses , by the results that the tree-structured models outperformed the linear-chain models .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
In the analysis section , we presented an in-depth analysis of the observed instances , and saw that the noun-noun dependencies particularly contribute to the positive instances .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
In the analysis section , we presented an in-depth analysis of the observed instances , and saw that the noun-noun dependencies particularly contribute to the positive instances .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
Also , the combination of coarse-grained tag sets with the sense dependency features were proved to be effective .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Also , the combination of coarse-grained tag sets with the sense dependency features were proved to be effective .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Also , the combination of coarse-grained tag sets with the sense dependency features were proved to be effective .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
However , our experiments on the other hand showed that even when combined with the coarse-grained tag sets , the sense dependency features do not improve the performance unless combined with proper sense frequency information , due to the data sparseness problem .
#<struct ReadData::Alignment source_numbers="18", target_numbers="14", tag_name="wa">
However , our experiments on the other hand showed that even when combined with the coarse-grained tag sets , the sense dependency features do not improve the performance unless combined with proper sense frequency information , due to the data sparseness problem .
#<struct ReadData::Alignment source_numbers="35", target_numbers="24", tag_name="wa">
However , our experiments on the other hand showed that even when combined with the coarse-grained tag sets , the sense dependency features do not improve the performance unless combined with proper sense frequency information , due to the data sparseness problem .
#<struct ReadData::Alignment source_numbers="42", target_numbers="32", tag_name="wa">
However , our experiments on the other hand showed that even when combined with the coarse-grained tag sets , the sense dependency features do not improve the performance unless combined with proper sense frequency information , due to the data sparseness problem .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
However , our experiments on the other hand showed that even when combined with the coarse-grained tag sets , the sense dependency features do not improve the performance unless combined with proper sense frequency information , due to the data sparseness problem .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
However , our experiments on the other hand showed that even when combined with the coarse-grained tag sets , the sense dependency features do not improve the performance unless combined with proper sense frequency information , due to the data sparseness problem .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
However , our experiments on the other hand showed that even when combined with the coarse-grained tag sets , the sense dependency features do not improve the performance unless combined with proper sense frequency information , due to the data sparseness problem .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
However , our experiments on the other hand showed that even when combined with the coarse-grained tag sets , the sense dependency features do not improve the performance unless combined with proper sense frequency information , due to the data sparseness problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
However , our experiments on the other hand showed that even when combined with the coarse-grained tag sets , the sense dependency features do not improve the performance unless combined with proper sense frequency information , due to the data sparseness problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
However , our experiments on the other hand showed that even when combined with the coarse-grained tag sets , the sense dependency features do not improve the performance unless combined with proper sense frequency information , due to the data sparseness problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="41", tag_name="wa">
The supersense-based WSD models , on the contrary , exhibited the robustness regardless of the existence of the sense frequency information , while they are defeated by the synset-based models in recalls .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
The supersense-based WSD models , on the contrary , exhibited the robustness regardless of the existence of the sense frequency information , while they are defeated by the synset-based models in recalls .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
These results show the importance of fine-grained and coarse-grained sense information , and that the combination of both enables us to build a precise and robust WSD system .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
These results show the importance of fine-grained and coarse-grained sense information , and that the combination of both enables us to build a precise and robust WSD system .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
Although our model was based on a simple framework and trained only on the SemCor corpus , the results we gained were promising , suggesting that our model still has a great potential for improvement .
#<struct ReadData::Alignment source_numbers="23", target_numbers="9", tag_name="wa">
Although our model was based on a simple framework and trained only on the SemCor corpus , the results we gained were promising , suggesting that our model still has a great potential for improvement .
#<struct ReadData::Alignment source_numbers="24,25", target_numbers="28,29", tag_name="wa">
Although our model was based on a simple framework and trained only on the SemCor corpus , the results we gained were promising , suggesting that our model still has a great potential for improvement .
#<struct ReadData::Alignment source_numbers="35", target_numbers="39", tag_name="wa">
Although our model was based on a simple framework and trained only on the SemCor corpus , the results we gained were promising , suggesting that our model still has a great potential for improvement .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
Although our model was based on a simple framework and trained only on the SemCor corpus , the results we gained were promising , suggesting that our model still has a great potential for improvement .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
Although our model was based on a simple framework and trained only on the SemCor corpus , the results we gained were promising , suggesting that our model still has a great potential for improvement .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
Although our model was based on a simple framework and trained only on the SemCor corpus , the results we gained were promising , suggesting that our model still has a great potential for improvement .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
Generating short summary videos for rushes is a challenging task due to difficulty in redundancy elimination and determination of important objects and events being placed in the summary .
#<struct ReadData::Alignment source_numbers="26", target_numbers="12", tag_name="wa">
Generating short summary videos for rushes is a challenging task due to difficulty in redundancy elimination and determination of important objects and events being placed in the summary .
#<struct ReadData::Alignment source_numbers="17,18", target_numbers="18", tag_name="wa">
Generating short summary videos for rushes is a challenging task due to difficulty in redundancy elimination and determination of important objects and events being placed in the summary .
#<struct ReadData::Alignment source_numbers="23", target_numbers="25", tag_name="wa">
Generating short summary videos for rushes is a challenging task due to difficulty in redundancy elimination and determination of important objects and events being placed in the summary .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
Generating short summary videos for rushes is a challenging task due to difficulty in redundancy elimination and determination of important objects and events being placed in the summary .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
Generating short summary videos for rushes is a challenging task due to difficulty in redundancy elimination and determination of important objects and events being placed in the summary .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
Generating short summary videos for rushes is a challenging task due to difficulty in redundancy elimination and determination of important objects and events being placed in the summary .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
This makes approaches using one keyframe for shot representation failed in doing clustering .
#<struct ReadData::Alignment source_numbers="12", target_numbers="16", tag_name="wa">
This makes approaches using one keyframe for shot representation failed in doing clustering .
#<struct ReadData::Alignment source_numbers="13", target_numbers="17", tag_name="wa">
This makes approaches using one keyframe for shot representation failed in doing clustering .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
This makes approaches using one keyframe for shot representation failed in doing clustering .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
This makes approaches using one keyframe for shot representation failed in doing clustering .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
This makes approaches using one keyframe for shot representation failed in doing clustering .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
This makes approaches using one keyframe for shot representation failed in doing clustering .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
This makes approaches using one keyframe for shot representation failed in doing clustering .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
This makes approaches using one keyframe for shot representation failed in doing clustering .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
In addition , even repetitive segments can be determined precisely , the summary generated by concatenating together selected segments still has longer duration than the upper limit .
#<struct ReadData::Alignment source_numbers="20", target_numbers="22", tag_name="wa">
In addition , even repetitive segments can be determined precisely , the summary generated by concatenating together selected segments still has longer duration than the upper limit .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
In addition , even repetitive segments can be determined precisely , the summary generated by concatenating together selected segments still has longer duration than the upper limit .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
In addition , even repetitive segments can be determined precisely , the summary generated by concatenating together selected segments still has longer duration than the upper limit .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
In this paper , we introduce two approaches to these problems .
#<struct ReadData::Alignment source_numbers="8", target_numbers="4", tag_name="wa">
In this paper , we introduce two approaches to these problems .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
In this paper , we introduce two approaches to these problems .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
In this paper , we introduce two approaches to these problems .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
In this paper , we introduce two approaches to these problems .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
In this paper , we introduce two approaches to these problems .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
In this paper , we introduce two approaches to these problems .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
In this paper , we introduce two approaches to these problems .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
In the first approach , one keyframe is used for shot representation in doing clustering; and sub-segments are selected using motion information for generating the summary .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
In the first approach , one keyframe is used for shot representation in doing clustering; and sub-segments are selected using motion information for generating the summary .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
In the first approach , one keyframe is used for shot representation in doing clustering; and sub-segments are selected using motion information for generating the summary .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
In the first approach , one keyframe is used for shot representation in doing clustering; and sub-segments are selected using motion information for generating the summary .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
In the first approach , one keyframe is used for shot representation in doing clustering; and sub-segments are selected using motion information for generating the summary .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
In the first approach , one keyframe is used for shot representation in doing clustering; and sub-segments are selected using motion information for generating the summary .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
In the first approach , one keyframe is used for shot representation in doing clustering; and sub-segments are selected using motion information for generating the summary .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
In the first approach , one keyframe is used for shot representation in doing clustering; and sub-segments are selected using motion information for generating the summary .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
In the first approach , one keyframe is used for shot representation in doing clustering; and sub-segments are selected using motion information for generating the summary .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
Meanwhile , in the second approach , all frames of a shot are used for clustering; and a simple skimming method is used to select sub-segments .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
Experimental results on the TRECVID 2008 dataset and comparison between the two approaches are reported .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Experimental results on the TRECVID 2008 dataset and comparison between the two approaches are reported .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Experimental results on the TRECVID 2008 dataset and comparison between the two approaches are reported .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
Video summarization is a significant research that helps to meet these needs by developing a condensed version of a full length digital video with the most important contents \CITE .
#<struct ReadData::Alignment source_numbers="3,4", target_numbers="2", tag_name="wa">
Video summarization is a significant research that helps to meet these needs by developing a condensed version of a full length digital video with the most important contents \CITE .
#<struct ReadData::Alignment source_numbers="11", target_numbers="7", tag_name="wa">
Video summarization is a significant research that helps to meet these needs by developing a condensed version of a full length digital video with the most important contents \CITE .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Video summarization is a significant research that helps to meet these needs by developing a condensed version of a full length digital video with the most important contents \CITE .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Video summarization is a significant research that helps to meet these needs by developing a condensed version of a full length digital video with the most important contents \CITE .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
Video summarization is a significant research that helps to meet these needs by developing a condensed version of a full length digital video with the most important contents \CITE .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Video summarization is a significant research that helps to meet these needs by developing a condensed version of a full length digital video with the most important contents \CITE .
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
Video summarization is a significant research that helps to meet these needs by developing a condensed version of a full length digital video with the most important contents \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Video summarization is a significant research that helps to meet these needs by developing a condensed version of a full length digital video with the most important contents \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
Video summarization is a significant research that helps to meet these needs by developing a condensed version of a full length digital video with the most important contents \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
Summary videos can help users to browse and navigate large video archives efficiently and effectively .
#<struct ReadData::Alignment source_numbers="6", target_numbers="9", tag_name="wa">
Summary videos can help users to browse and navigate large video archives efficiently and effectively .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Summary videos can help users to browse and navigate large video archives efficiently and effectively .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Generating summary videos for BBC rushes \CITE is a challenging task due to difficulty in redundancy elimination and determination of important objects and events being placed in the summary .
#<struct ReadData::Alignment source_numbers="27", target_numbers="13", tag_name="wa">
Generating summary videos for BBC rushes \CITE is a challenging task due to difficulty in redundancy elimination and determination of important objects and events being placed in the summary .
#<struct ReadData::Alignment source_numbers="24", target_numbers="27", tag_name="wa">
Generating summary videos for BBC rushes \CITE is a challenging task due to difficulty in redundancy elimination and determination of important objects and events being placed in the summary .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
Generating summary videos for BBC rushes \CITE is a challenging task due to difficulty in redundancy elimination and determination of important objects and events being placed in the summary .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
Generating summary videos for BBC rushes \CITE is a challenging task due to difficulty in redundancy elimination and determination of important objects and events being placed in the summary .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
Generating summary videos for BBC rushes \CITE is a challenging task due to difficulty in redundancy elimination and determination of important objects and events being placed in the summary .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
Generating summary videos for BBC rushes \CITE is a challenging task due to difficulty in redundancy elimination and determination of important objects and events being placed in the summary .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
Since the length of the summary is limited to 2\% duration of the original video , there is a trade-off between recall and usability ( e.g user friendly through smooth presentation , being easy to understand ) .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
Since the length of the summary is limited to 2\% duration of the original video , there is a trade-off between recall and usability ( e.g user friendly through smooth presentation , being easy to understand ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
Since the length of the summary is limited to 2\% duration of the original video , there is a trade-off between recall and usability ( e.g user friendly through smooth presentation , being easy to understand ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
High recall , i.e many objects and events ( called scenes ) are included in the summary , usually reduce the number of frames for each scene .
#<struct ReadData::Alignment source_numbers="13", target_numbers="12", tag_name="wa">
High recall , i.e many objects and events ( called scenes ) are included in the summary , usually reduce the number of frames for each scene .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
High recall , i.e many objects and events ( called scenes ) are included in the summary , usually reduce the number of frames for each scene .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
High recall , i.e many objects and events ( called scenes ) are included in the summary , usually reduce the number of frames for each scene .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
For example , the maximum duration for the summary of a 30 minute length video is 36 seconds ( \MATH ) .
#<struct ReadData::Alignment source_numbers="7,8", target_numbers="7,8", tag_name="wa">
For example , the maximum duration for the summary of a 30 minute length video is 36 seconds ( \MATH ) .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
For the event such as " `Woman attacks man on bench on left and runs off with large bag .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
For the event such as " `Woman attacks man on bench on left and runs off with large bag .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
On the contrary , smooth presentation of events consumes a lot number of frames , that decrease the recall .
#<struct ReadData::Alignment source_numbers="0", target_numbers="0", tag_name="wa">
On the contrary , smooth presentation of events consumes a lot number of frames , that decrease the recall .
#<struct ReadData::Alignment source_numbers="1", target_numbers="1", tag_name="wa">
On the contrary , smooth presentation of events consumes a lot number of frames , that decrease the recall .
#<struct ReadData::Alignment source_numbers="2", target_numbers="2,3", tag_name="wa">
On the contrary , smooth presentation of events consumes a lot number of frames , that decrease the recall .
#<struct ReadData::Alignment source_numbers="9", target_numbers="5", tag_name="wa">
On the contrary , smooth presentation of events consumes a lot number of frames , that decrease the recall .
#<struct ReadData::Alignment source_numbers="10", target_numbers="14,15", tag_name="wa">
On the contrary , smooth presentation of events consumes a lot number of frames , that decrease the recall .
#<struct ReadData::Alignment source_numbers="14", target_numbers="18", tag_name="wa">
On the contrary , smooth presentation of events consumes a lot number of frames , that decrease the recall .
#<struct ReadData::Alignment source_numbers="16", target_numbers="21", tag_name="wa">
On the contrary , smooth presentation of events consumes a lot number of frames , that decrease the recall .
#<struct ReadData::Alignment source_numbers="19", target_numbers="24", tag_name="wa">
On the contrary , smooth presentation of events consumes a lot number of frames , that decrease the recall .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
On the contrary , smooth presentation of events consumes a lot number of frames , that decrease the recall .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
On the contrary , smooth presentation of events consumes a lot number of frames , that decrease the recall .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
On the contrary , smooth presentation of events consumes a lot number of frames , that decrease the recall .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
On the contrary , smooth presentation of events consumes a lot number of frames , that decrease the recall .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
On the contrary , smooth presentation of events consumes a lot number of frames , that decrease the recall .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
On the contrary , smooth presentation of events consumes a lot number of frames , that decrease the recall .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
On the contrary , smooth presentation of events consumes a lot number of frames , that decrease the recall .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
Video segmentation : This step decomposes the original video into segments , such shots or sub-shots .
#<struct ReadData::Alignment source_numbers="12", target_numbers="13", tag_name="wa">
Video segmentation : This step decomposes the original video into segments , such shots or sub-shots .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Video segmentation : This step decomposes the original video into segments , such shots or sub-shots .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Video segmentation : This step decomposes the original video into segments , such shots or sub-shots .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Video segmentation : This step decomposes the original video into segments , such shots or sub-shots .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Each segment should be aligned such that it is a part of a scene .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Each segment should be aligned such that it is a part of a scene .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Junk elimination : This step removes color bars , clapboards , all black or all white frames that are unnecessary for the final summary video .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
Junk elimination : This step removes color bars , clapboards , all black or all white frames that are unnecessary for the final summary video .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
Junk elimination : This step removes color bars , clapboards , all black or all white frames that are unnecessary for the final summary video .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
Summary generation : This step selects frames from representative segments of clusters and concatenate to form the final summary video .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
While the steps of video segmentation and junk elimination are easy to handle , the steps of redundancy elimination and summary generation are difficult .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
While the steps of video segmentation and junk elimination are easy to handle , the steps of redundancy elimination and summary generation are difficult .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
While the steps of video segmentation and junk elimination are easy to handle , the steps of redundancy elimination and summary generation are difficult .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
While the steps of video segmentation and junk elimination are easy to handle , the steps of redundancy elimination and summary generation are difficult .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
For example , as for redundancy elimination , the question is how to represent a segment into a feature vector and how to compute the similarity between two segments having different length and motion pattern .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
For example , as for redundancy elimination , the question is how to represent a segment into a feature vector and how to compute the similarity between two segments having different length and motion pattern .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
In the other case , assume that we have selected appropriate segments , the total length of these segments are usually larger than that of the final summary .
#<struct ReadData::Alignment source_numbers="5,6", target_numbers="5,6", tag_name="wa">
In the other case , assume that we have selected appropriate segments , the total length of these segments are usually larger than that of the final summary .
#<struct ReadData::Alignment source_numbers="25", target_numbers="10", tag_name="wa">
In the other case , assume that we have selected appropriate segments , the total length of these segments are usually larger than that of the final summary .
#<struct ReadData::Alignment source_numbers="19,20", target_numbers="20,21", tag_name="wa">
In the other case , assume that we have selected appropriate segments , the total length of these segments are usually larger than that of the final summary .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
The question is how to determine the important part of the selected segment such that it conveys information of the scene as much as possible .
#<struct ReadData::Alignment source_numbers="21", target_numbers="18", tag_name="wa">
The question is how to determine the important part of the selected segment such that it conveys information of the scene as much as possible .
#<struct ReadData::Alignment source_numbers="22", target_numbers="19", tag_name="wa">
The question is how to determine the important part of the selected segment such that it conveys information of the scene as much as possible .
#<struct ReadData::Alignment source_numbers="18", target_numbers="20", tag_name="wa">
The question is how to determine the important part of the selected segment such that it conveys information of the scene as much as possible .
#<struct ReadData::Alignment source_numbers="19", target_numbers="21", tag_name="wa">
The question is how to determine the important part of the selected segment such that it conveys information of the scene as much as possible .
#<struct ReadData::Alignment source_numbers="23", target_numbers="26", tag_name="wa">
The question is how to determine the important part of the selected segment such that it conveys information of the scene as much as possible .
#<struct ReadData::Alignment source_numbers="24", target_numbers="27", tag_name="wa">
The question is how to determine the important part of the selected segment such that it conveys information of the scene as much as possible .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
The question is how to determine the important part of the selected segment such that it conveys information of the scene as much as possible .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
The question is how to determine the important part of the selected segment such that it conveys information of the scene as much as possible .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
The question is how to determine the important part of the selected segment such that it conveys information of the scene as much as possible .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
The question is how to determine the important part of the selected segment such that it conveys information of the scene as much as possible .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
The question is how to determine the important part of the selected segment such that it conveys information of the scene as much as possible .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
The question is how to determine the important part of the selected segment such that it conveys information of the scene as much as possible .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
The question is how to determine the important part of the selected segment such that it conveys information of the scene as much as possible .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
The question is how to determine the important part of the selected segment such that it conveys information of the scene as much as possible .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
The first approach represents each segment by one key-frame and groups similar segments by doing clustering on these key-frames .
#<struct ReadData::Alignment source_numbers="15", target_numbers="15", tag_name="wa">
The first approach represents each segment by one key-frame and groups similar segments by doing clustering on these key-frames .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
The first approach represents each segment by one key-frame and groups similar segments by doing clustering on these key-frames .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
The first approach represents each segment by one key-frame and groups similar segments by doing clustering on these key-frames .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
Then the portion of each segment that has high motion is used to include into the final summary .
#<struct ReadData::Alignment source_numbers="8", target_numbers="9", tag_name="wa">
Then the portion of each segment that has high motion is used to include into the final summary .
#<struct ReadData::Alignment source_numbers="11,12,13", target_numbers="12", tag_name="wa">
Then the portion of each segment that has high motion is used to include into the final summary .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
Then the portion of each segment that has high motion is used to include into the final summary .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Then the portion of each segment that has high motion is used to include into the final summary .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Specifically , for each segment , a set of frames are extracted by sampling at a certain time interval ( e.g 5 frames ) .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
Specifically , for each segment , a set of frames are extracted by sampling at a certain time interval ( e.g 5 frames ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
In order to generate the final summary , with each representative segment , the middle part is selected with the skim rate of 2 frames .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
In order to generate the final summary , with each representative segment , the middle part is selected with the skim rate of 2 frames .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
From the definition , all rushes are unedited; therefore it must consist of hard cut only .
#<struct ReadData::Alignment source_numbers="2", target_numbers="1", tag_name="wa">
From the definition , all rushes are unedited; therefore it must consist of hard cut only .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
From the definition , all rushes are unedited; therefore it must consist of hard cut only .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
From the definition , all rushes are unedited; therefore it must consist of hard cut only .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
From the definition , all rushes are unedited; therefore it must consist of hard cut only .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
From the definition , all rushes are unedited; therefore it must consist of hard cut only .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
The shot boundary detection algorithm in \CITE is used to determine shot boundary and partition the input video into shots .
#<struct ReadData::Alignment source_numbers="14", target_numbers="16", tag_name="wa">
The shot boundary detection algorithm in \CITE is used to determine shot boundary and partition the input video into shots .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
The sum of the middle eight of these 16 values are used to define a cut between frames \MATH and \MATH if these values exceed a threshold \MATH .
#<struct ReadData::Alignment source_numbers="10,11", target_numbers="10,11", tag_name="wa">
The sum of the middle eight of these 16 values are used to define a cut between frames \MATH and \MATH if these values exceed a threshold \MATH .
#<struct ReadData::Alignment source_numbers="13,14", target_numbers="13,14", tag_name="wa">
The sum of the middle eight of these 16 values are used to define a cut between frames \MATH and \MATH if these values exceed a threshold \MATH .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
The sum of the middle eight of these 16 values are used to define a cut between frames \MATH and \MATH if these values exceed a threshold \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
Therefore , if the algorithm detected a cut between frames \MATH and \MATH , whose magnitude is larger than a threshold \MATH , these cuts are rejected since they are motions from large objects .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
Therefore , if the algorithm detected a cut between frames \MATH and \MATH , whose magnitude is larger than a threshold \MATH , these cuts are rejected since they are motions from large objects .
#<struct ReadData::Alignment source_numbers="31", target_numbers="", tag_name="wa">
Therefore , if the algorithm detected a cut between frames \MATH and \MATH , whose magnitude is larger than a threshold \MATH , these cuts are rejected since they are motions from large objects .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
Therefore , if the algorithm detected a cut between frames \MATH and \MATH , whose magnitude is larger than a threshold \MATH , these cuts are rejected since they are motions from large objects .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
Finally , the short shots with less than 25 frames ( 1 second ) are removed .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Finally , the short shots with less than 25 frames ( 1 second ) are removed .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
A first frame of the shot is chosen as the base frame \MATH and next frame \MATH for comparison .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
A first frame of the shot is chosen as the base frame \MATH and next frame \MATH for comparison .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
The \MATH distance used to compute the distance of frame sequence until the sum of the sorted value of lower eight is larger than a threshold \MATH .
#<struct ReadData::Alignment source_numbers="15", target_numbers="9", tag_name="wa">
The \MATH distance used to compute the distance of frame sequence until the sum of the sorted value of lower eight is larger than a threshold \MATH .
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
The \MATH distance used to compute the distance of frame sequence until the sum of the sorted value of lower eight is larger than a threshold \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
The \MATH distance used to compute the distance of frame sequence until the sum of the sorted value of lower eight is larger than a threshold \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
The \MATH distance used to compute the distance of frame sequence until the sum of the sorted value of lower eight is larger than a threshold \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
The \MATH distance used to compute the distance of frame sequence until the sum of the sorted value of lower eight is larger than a threshold \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
The \MATH distance used to compute the distance of frame sequence until the sum of the sorted value of lower eight is larger than a threshold \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
Finally , the short sub-shots with less than 25 frames are removed .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Finally , the short sub-shots with less than 25 frames are removed .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
We employ a keyframe extraction algorithm proposed in \CITE to extract the representative keyframes from each sub-shot .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
We employ a keyframe extraction algorithm proposed in \CITE to extract the representative keyframes from each sub-shot .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Next , we sort these values into an ascending order .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
If the value of the \MATH is smaller than threshold \MATH , then these sub-shot is defined as a color bar sub-shot .
#<struct ReadData::Alignment source_numbers="14", target_numbers="15", tag_name="wa">
If the value of the \MATH is smaller than threshold \MATH , then these sub-shot is defined as a color bar sub-shot .
#<struct ReadData::Alignment source_numbers="15,16", target_numbers="16,17", tag_name="wa">
From the properties of single color image , a dominant color in its global histogram is large .
#<struct ReadData::Alignment source_numbers="8", target_numbers="4", tag_name="wa">
From the properties of single color image , a dominant color in its global histogram is large .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
In rushes videos , there are many types of clapper boards , appearance but the same type of clapper boards is often used in the same movie .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
The clapper boards have many types , such as scale , rotation , and illumination changes .
#<struct ReadData::Alignment source_numbers="3", target_numbers="1", tag_name="wa">
The clapper boards have many types , such as scale , rotation , and illumination changes .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
The clapper boards have many types , such as scale , rotation , and illumination changes .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
A set of 80 example keyframes of clapper boards are extracted from the development set and used as a set of queries .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
If a result of the NDK algorithm returns a match between a keyframe with a query then we define the sub-shot is a clapper board sub-shot .
#<struct ReadData::Alignment source_numbers="19", target_numbers="1", tag_name="wa">
If a result of the NDK algorithm returns a match between a keyframe with a query then we define the sub-shot is a clapper board sub-shot .
#<struct ReadData::Alignment source_numbers="21", target_numbers="19", tag_name="wa">
If a result of the NDK algorithm returns a match between a keyframe with a query then we define the sub-shot is a clapper board sub-shot .
#<struct ReadData::Alignment source_numbers="17,18", target_numbers="20", tag_name="wa">
If a result of the NDK algorithm returns a match between a keyframe with a query then we define the sub-shot is a clapper board sub-shot .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
If a result of the NDK algorithm returns a match between a keyframe with a query then we define the sub-shot is a clapper board sub-shot .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
If a result of the NDK algorithm returns a match between a keyframe with a query then we define the sub-shot is a clapper board sub-shot .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
If a result of the NDK algorithm returns a match between a keyframe with a query then we define the sub-shot is a clapper board sub-shot .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
If a result of the NDK algorithm returns a match between a keyframe with a query then we define the sub-shot is a clapper board sub-shot .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
The unused keyframes containing of story units for generate video summary are removed .
#<struct ReadData::Alignment source_numbers="8", target_numbers="8", tag_name="wa">
The unused keyframes containing of story units for generate video summary are removed .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
However , rushes videos containing of repetitive story , such as retake scenes , are unedited .
#<struct ReadData::Alignment source_numbers="5", target_numbers="13", tag_name="wa">
From this characteristic , clustering technique can be used to separate the data into groups of similar contents .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
From this characteristic , clustering technique can be used to separate the data into groups of similar contents .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
From this characteristic , clustering technique can be used to separate the data into groups of similar contents .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
From this characteristic , clustering technique can be used to separate the data into groups of similar contents .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
GreedyRSC , proposed in \CITE , is used to find clusters with high precision and the number of clusters is automatically determined .
#<struct ReadData::Alignment source_numbers="11,12", target_numbers="11,12", tag_name="wa">
To do the clustering on keyframes , three different features , including mean , variance , and skewness , are extracted from local color histogram .
#<struct ReadData::Alignment source_numbers="2", target_numbers="11", tag_name="wa">
These values are used to represent the keyframes content and defined as follows :
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
So far , we completely remove the unused contents from rushes video and reduce repetition of the story contents .
#<struct ReadData::Alignment source_numbers="5", target_numbers="6", tag_name="wa">
So far , we completely remove the unused contents from rushes video and reduce repetition of the story contents .
#<struct ReadData::Alignment source_numbers="13", target_numbers="14", tag_name="wa">
So far , we completely remove the unused contents from rushes video and reduce repetition of the story contents .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
So far , we completely remove the unused contents from rushes video and reduce repetition of the story contents .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
The objective of rushes summarization at TRECVID 2008 is to generate short summaries ( the upper limit of the duration of summary is 2\% of the original video ) , less repetitive of content , and must have many objects and events as possible .
#<struct ReadData::Alignment source_numbers="42", target_numbers="38", tag_name="wa">
The objective of rushes summarization at TRECVID 2008 is to generate short summaries ( the upper limit of the duration of summary is 2\% of the original video ) , less repetitive of content , and must have many objects and events as possible .
#<struct ReadData::Alignment source_numbers="", target_numbers="43", tag_name="wa">
To reach this objective , the important keyframes should be selected to generate summary video .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
To reach this objective , the important keyframes should be selected to generate summary video .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Third , merge consecutive sub-shots in each cluster into shots and compute the priority of each shot based on priority of shot weighted duration and shot weighted average motion magnitude using the following equation : \MATH</p>
#<struct ReadData::Alignment source_numbers="31", target_numbers="3", tag_name="wa">
Third , merge consecutive sub-shots in each cluster into shots and compute the priority of each shot based on priority of shot weighted duration and shot weighted average motion magnitude using the following equation : \MATH</p>
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
Forth , sort sub-shots in the selected shot in descending order based on the average motion magnitude .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Forth , sort sub-shots in the selected shot in descending order based on the average motion magnitude .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Forth , sort sub-shots in the selected shot in descending order based on the average motion magnitude .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Forth , sort sub-shots in the selected shot in descending order based on the average motion magnitude .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Forth , sort sub-shots in the selected shot in descending order based on the average motion magnitude .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
Select sub-shots from top to bottom until the quota length for that shot is reached .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Select sub-shots from top to bottom until the quota length for that shot is reached .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Select sub-shots from top to bottom until the quota length for that shot is reached .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Fifth , for each selected sub-shot , extract 25 frames ( 1 second ) around the middle to generate the final summary .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Fifth , for each selected sub-shot , extract 25 frames ( 1 second ) around the middle to generate the final summary .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
Fifth , for each selected sub-shot , extract 25 frames ( 1 second ) around the middle to generate the final summary .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
This system is adopted with some modifications from the system developed for the same task last year \CITE .
#<struct ReadData::Alignment source_numbers="2", target_numbers="2", tag_name="wa">
This system is adopted with some modifications from the system developed for the same task last year \CITE .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
This system is adopted with some modifications from the system developed for the same task last year \CITE .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
Specifically , the original video is decomposed into segments , which are shots with hard cut transition .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
Specifically , the original video is decomposed into segments , which are shots with hard cut transition .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Specifically , the original video is decomposed into segments , which are shots with hard cut transition .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
These segments are further decomposed into fragments so that each fragment represents a portion of a scene .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
These segments are further decomposed into fragments so that each fragment represents a portion of a scene .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
These segments are further decomposed into fragments so that each fragment represents a portion of a scene .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
In order to reduce the computation time , we only extract a subset of frames from the original video by sampling at a five frame interval ( i.e extract frames 0th , 5th , 10th , and so on ) .
#<struct ReadData::Alignment source_numbers="16", target_numbers="14", tag_name="wa">
In order to reduce the computation time , we only extract a subset of frames from the original video by sampling at a five frame interval ( i.e extract frames 0th , 5th , 10th , and so on ) .
#<struct ReadData::Alignment source_numbers="27", target_numbers="", tag_name="wa">
In order to reduce the computation time , we only extract a subset of frames from the original video by sampling at a five frame interval ( i.e extract frames 0th , 5th , 10th , and so on ) .
#<struct ReadData::Alignment source_numbers="30", target_numbers="", tag_name="wa">
In order to reduce the computation time , we only extract a subset of frames from the original video by sampling at a five frame interval ( i.e extract frames 0th , 5th , 10th , and so on ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
In order to reduce the computation time , we only extract a subset of frames from the original video by sampling at a five frame interval ( i.e extract frames 0th , 5th , 10th , and so on ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
In order to reduce the computation time , we only extract a subset of frames from the original video by sampling at a five frame interval ( i.e extract frames 0th , 5th , 10th , and so on ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
In order to reduce the computation time , we only extract a subset of frames from the original video by sampling at a five frame interval ( i.e extract frames 0th , 5th , 10th , and so on ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
Meanwhile , the fragment boundary is determined by using a strict threshold to detect dramatic motion .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
The number of clusters is determined automatically by this method .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
The number of clusters is determined automatically by this method .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
We compute the similarity value between two fragments by counting the number of shared characters between two strings and being normalized to the size of each string .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
If this value is larger than a threshold , these two segments are merged into one cluster .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
If this value is larger than a threshold , these two segments are merged into one cluster .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
We found that this approach is more effective than the approach using one keyframe for one fragment since the more number of keyframes is used , the more information is available to make right decision .
#<struct ReadData::Alignment source_numbers="23,24", target_numbers="22,23", tag_name="wa">
We found that this approach is more effective than the approach using one keyframe for one fragment since the more number of keyframes is used , the more information is available to make right decision .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
We found that this approach is more effective than the approach using one keyframe for one fragment since the more number of keyframes is used , the more information is available to make right decision .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
We found that this approach is more effective than the approach using one keyframe for one fragment since the more number of keyframes is used , the more information is available to make right decision .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
We select junk frames such as color bar frames , single color ( black or white ) frames to form the reference junk frame set .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
If the similarity between one frame in the input fragment and one frame in the reference junk frame set is lower than the predefined thresholds, the input fragment is considered as junk and all fragments of the cluster containing junk fragment are eliminated .
#<struct ReadData::Alignment source_numbers="36", target_numbers="33", tag_name="wa">
If the similarity between one frame in the input fragment and one frame in the reference junk frame set is lower than the predefined thresholds, the input fragment is considered as junk and all fragments of the cluster containing junk fragment are eliminated .
#<struct ReadData::Alignment source_numbers="30", target_numbers="", tag_name="wa">
If the similarity between one frame in the input fragment and one frame in the reference junk frame set is lower than the predefined thresholds, the input fragment is considered as junk and all fragments of the cluster containing junk fragment are eliminated .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
Since the length of these fragments is still larger than the maximum length of the final summary, we employ a simple strategy to shrink these fragments as follows .
#<struct ReadData::Alignment source_numbers="26,27", target_numbers="19,20", tag_name="wa">
Since the length of these fragments is still larger than the maximum length of the final summary, we employ a simple strategy to shrink these fragments as follows .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
Second, for each fragment, we extract the portion which is expanded from the central of the fragment .
#<struct ReadData::Alignment source_numbers="8,9", target_numbers="8,9", tag_name="wa">
Second, for each fragment, we extract the portion which is expanded from the central of the fragment .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
This portion covers a duration twice as much as the fragment quota by selecting frames with sampling rate of 2 frames .
#<struct ReadData::Alignment source_numbers="5,6,7,8", target_numbers="5,6", tag_name="wa">
This portion covers a duration twice as much as the fragment quota by selecting frames with sampling rate of 2 frames .
#<struct ReadData::Alignment source_numbers="18", target_numbers="8", tag_name="wa">
This portion covers a duration twice as much as the fragment quota by selecting frames with sampling rate of 2 frames .
#<struct ReadData::Alignment source_numbers="19", target_numbers="20,21", tag_name="wa">
This portion covers a duration twice as much as the fragment quota by selecting frames with sampling rate of 2 frames .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Specifically, we select frames \MATH, \MATH, ..., \MATH, \MATH, ..., \MATH, \MATH, where \MATH is the middle frame of the fragment, and \MATH is half of number of frames computed from the quota\MATH and frame rate ( 25fps ) \MATH :
#<struct ReadData::Alignment source_numbers="24,25", target_numbers="24,25", tag_name="wa">
We have tested our approaches with 40 videos of TRECVID 2008 test set .
#<struct ReadData::Alignment source_numbers="7,8", target_numbers="7,8", tag_name="wa">
We have tested our approaches with 40 videos of TRECVID 2008 test set .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
We have tested our approaches with 40 videos of TRECVID 2008 test set .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
The system NII-2 achieves higher recall ( IN ) than the system NII-1 since NII-1 only uses one keyframe for each sub-shot and has shorter duration ( DU ) for summary videos .
#<struct ReadData::Alignment source_numbers="12", target_numbers="11", tag_name="wa">
The system NII-2 achieves higher recall ( IN ) than the system NII-1 since NII-1 only uses one keyframe for each sub-shot and has shorter duration ( DU ) for summary videos .
#<struct ReadData::Alignment source_numbers="1", target_numbers="12", tag_name="wa">
The system NII-2 achieves higher recall ( IN ) than the system NII-1 since NII-1 only uses one keyframe for each sub-shot and has shorter duration ( DU ) for summary videos .
#<struct ReadData::Alignment source_numbers="14", target_numbers="14", tag_name="wa">
The system NII-2 achieves higher recall ( IN ) than the system NII-1 since NII-1 only uses one keyframe for each sub-shot and has shorter duration ( DU ) for summary videos .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
The system NII-2 achieves higher recall ( IN ) than the system NII-1 since NII-1 only uses one keyframe for each sub-shot and has shorter duration ( DU ) for summary videos .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
The system NII-2 achieves higher recall ( IN ) than the system NII-1 since NII-1 only uses one keyframe for each sub-shot and has shorter duration ( DU ) for summary videos .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
The system NII-2 achieves higher recall ( IN ) than the system NII-1 since NII-1 only uses one keyframe for each sub-shot and has shorter duration ( DU ) for summary videos .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
The system NII-2 achieves higher recall ( IN ) than the system NII-1 since NII-1 only uses one keyframe for each sub-shot and has shorter duration ( DU ) for summary videos .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
The system NII-2 achieves higher recall ( IN ) than the system NII-1 since NII-1 only uses one keyframe for each sub-shot and has shorter duration ( DU ) for summary videos .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
However, NII-1 has a better score in quality .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
However, NII-1 has a better score in quality .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
However, NII-1 has a better score in quality .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
The summary videos generated by NII-1 have fewer duplications ( RE ), are presented in a smoother way ( TE ) and are easy to judge for inclusions ( TT ) .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
The summary videos generated by NII-1 have fewer duplications ( RE ), are presented in a smoother way ( TE ) and are easy to judge for inclusions ( TT ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
The clapper board detection process using NDK consumes around half of processing time of NII-1 but performance is low due to large variations of clapper boards in videos ( see Figure \REF ) .
#<struct ReadData::Alignment source_numbers="33", target_numbers="37", tag_name="wa">
The clapper board detection process using NDK consumes around half of processing time of NII-1 but performance is low due to large variations of clapper boards in videos ( see Figure \REF ) .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
The clapper board detection process using NDK consumes around half of processing time of NII-1 but performance is low due to large variations of clapper boards in videos ( see Figure \REF ) .
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
The clapper board detection process using NDK consumes around half of processing time of NII-1 but performance is low due to large variations of clapper boards in videos ( see Figure \REF ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
The clapper board detection process using NDK consumes around half of processing time of NII-1 but performance is low due to large variations of clapper boards in videos ( see Figure \REF ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
In addition, by using simple features and sampling frames in the original video, NII-2 significantly speeds up the processing time ( computed from the time taking the input video to the time picking the summary video ) to quasi real-time .
#<struct ReadData::Alignment source_numbers="25", target_numbers="28", tag_name="wa">
In addition, by using simple features and sampling frames in the original video, NII-2 significantly speeds up the processing time ( computed from the time taking the input video to the time picking the summary video ) to quasi real-time .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
In addition, by using simple features and sampling frames in the original video, NII-2 significantly speeds up the processing time ( computed from the time taking the input video to the time picking the summary video ) to quasi real-time .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
In addition, by using simple features and sampling frames in the original video, NII-2 significantly speeds up the processing time ( computed from the time taking the input video to the time picking the summary video ) to quasi real-time .
#<struct ReadData::Alignment source_numbers="32", target_numbers="", tag_name="wa">
In addition, by using simple features and sampling frames in the original video, NII-2 significantly speeds up the processing time ( computed from the time taking the input video to the time picking the summary video ) to quasi real-time .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
In addition, by using simple features and sampling frames in the original video, NII-2 significantly speeds up the processing time ( computed from the time taking the input video to the time picking the summary video ) to quasi real-time .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
In addition, by using simple features and sampling frames in the original video, NII-2 significantly speeds up the processing time ( computed from the time taking the input video to the time picking the summary video ) to quasi real-time .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
In addition, by using simple features and sampling frames in the original video, NII-2 significantly speeds up the processing time ( computed from the time taking the input video to the time picking the summary video ) to quasi real-time .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
The 14 systems listed in this table have IN score larger than the median ( 0.45 ); and other scores such as RE and TE larger than half of maximum score ( 2.5 ) .
#<struct ReadData::Alignment source_numbers="34", target_numbers="38", tag_name="wa">
The 14 systems listed in this table have IN score larger than the median ( 0.45 ); and other scores such as RE and TE larger than half of maximum score ( 2.5 ) .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
The 14 systems listed in this table have IN score larger than the median ( 0.45 ); and other scores such as RE and TE larger than half of maximum score ( 2.5 ) .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
The 14 systems listed in this table have IN score larger than the median ( 0.45 ); and other scores such as RE and TE larger than half of maximum score ( 2.5 ) .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
The 14 systems listed in this table have IN score larger than the median ( 0.45 ); and other scores such as RE and TE larger than half of maximum score ( 2.5 ) .
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
The 14 systems listed in this table have IN score larger than the median ( 0.45 ); and other scores such as RE and TE larger than half of maximum score ( 2.5 ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
The 14 systems listed in this table have IN score larger than the median ( 0.45 ); and other scores such as RE and TE larger than half of maximum score ( 2.5 ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
The 14 systems listed in this table have IN score larger than the median ( 0.45 ); and other scores such as RE and TE larger than half of maximum score ( 2.5 ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
The 14 systems listed in this table have IN score larger than the median ( 0.45 ); and other scores such as RE and TE larger than half of maximum score ( 2.5 ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
The 14 systems listed in this table have IN score larger than the median ( 0.45 ); and other scores such as RE and TE larger than half of maximum score ( 2.5 ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
The 14 systems listed in this table have IN score larger than the median ( 0.45 ); and other scores such as RE and TE larger than half of maximum score ( 2.5 ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
Compared to other systems listed in this list, our system NII-2 is one of the fastest systems .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Compared to other systems listed in this list, our system NII-2 is one of the fastest systems .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Compared to other systems listed in this list, our system NII-2 is one of the fastest systems .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Compared to other systems listed in this list, our system NII-2 is one of the fastest systems .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
Compared to other systems listed in this list, our system NII-2 is one of the fastest systems .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Compared to other systems listed in this list, our system NII-2 is one of the fastest systems .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Compared to the other systems participating in this task of TRECVID 2008, NII-1 has good performance in measures such as DU and TT ( see Figure \REF and Figure \REF; while NII-2 achieves good performance in measure IN ( see Figure \REF ) .
#<struct ReadData::Alignment source_numbers="13", target_numbers="13", tag_name="wa">
Compared to the other systems participating in this task of TRECVID 2008, NII-1 has good performance in measures such as DU and TT ( see Figure \REF and Figure \REF; while NII-2 achieves good performance in measure IN ( see Figure \REF ) .
#<struct ReadData::Alignment source_numbers="14", target_numbers="14", tag_name="wa">
Compared to the other systems participating in this task of TRECVID 2008, NII-1 has good performance in measures such as DU and TT ( see Figure \REF and Figure \REF; while NII-2 achieves good performance in measure IN ( see Figure \REF ) .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
Compared to the other systems participating in this task of TRECVID 2008, NII-1 has good performance in measures such as DU and TT ( see Figure \REF and Figure \REF; while NII-2 achieves good performance in measure IN ( see Figure \REF ) .
#<struct ReadData::Alignment source_numbers="32", target_numbers="", tag_name="wa">
Compared to the other systems participating in this task of TRECVID 2008, NII-1 has good performance in measures such as DU and TT ( see Figure \REF and Figure \REF; while NII-2 achieves good performance in measure IN ( see Figure \REF ) .
#<struct ReadData::Alignment source_numbers="33", target_numbers="", tag_name="wa">
Compared to the other systems participating in this task of TRECVID 2008, NII-1 has good performance in measures such as DU and TT ( see Figure \REF and Figure \REF; while NII-2 achieves good performance in measure IN ( see Figure \REF ) .
#<struct ReadData::Alignment source_numbers="34", target_numbers="", tag_name="wa">
Compared to the other systems participating in this task of TRECVID 2008, NII-1 has good performance in measures such as DU and TT ( see Figure \REF and Figure \REF; while NII-2 achieves good performance in measure IN ( see Figure \REF ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
Compared to the other systems participating in this task of TRECVID 2008, NII-1 has good performance in measures such as DU and TT ( see Figure \REF and Figure \REF; while NII-2 achieves good performance in measure IN ( see Figure \REF ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
Lack of discriminative representation of segments and robust clustering methods is the main reason \CITE .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Lack of discriminative representation of segments and robust clustering methods is the main reason \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Fragmentation is the case that samples of one cluster are put into several different clusters .
#<struct ReadData::Alignment source_numbers="2,3", target_numbers="2", tag_name="wa">
Fragmentation is the case that samples of one cluster are put into several different clusters .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
Therefore, it is necessary to develop robust methods for detection of repetitive segments .
#<struct ReadData::Alignment source_numbers="9", target_numbers="9", tag_name="wa">
Therefore, it is necessary to develop robust methods for detection of repetitive segments .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Using all frames of one segment instead of using one keyframe as proposed in NII-2 is one of the efforts toward this direction .
#<struct ReadData::Alignment source_numbers="21,22", target_numbers="25,26", tag_name="wa">
Using all frames of one segment instead of using one keyframe as proposed in NII-2 is one of the efforts toward this direction .
#<struct ReadData::Alignment source_numbers="23", target_numbers="27", tag_name="wa">
Using all frames of one segment instead of using one keyframe as proposed in NII-2 is one of the efforts toward this direction .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
Using all frames of one segment instead of using one keyframe as proposed in NII-2 is one of the efforts toward this direction .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
Using all frames of one segment instead of using one keyframe as proposed in NII-2 is one of the efforts toward this direction .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
Although the result is not very high as expected, we still believe that this approach is promising .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Although the result is not very high as expected, we still believe that this approach is promising .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
We have presented two different approaches for generating short summary for rushes video .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
In the first approach, NII-1, redundancy elimination is done by doing clustering on the set of keyframes extracted from sub-shots .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
In the first approach, NII-1, redundancy elimination is done by doing clustering on the set of keyframes extracted from sub-shots .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
In the first approach, NII-1, redundancy elimination is done by doing clustering on the set of keyframes extracted from sub-shots .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
In the first approach, NII-1, redundancy elimination is done by doing clustering on the set of keyframes extracted from sub-shots .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
In the first approach, NII-1, redundancy elimination is done by doing clustering on the set of keyframes extracted from sub-shots .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
In the first approach, NII-1, redundancy elimination is done by doing clustering on the set of keyframes extracted from sub-shots .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
In the first approach, NII-1, redundancy elimination is done by doing clustering on the set of keyframes extracted from sub-shots .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
In the first approach, NII-1, redundancy elimination is done by doing clustering on the set of keyframes extracted from sub-shots .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
With each representative segment of each cluster, the portion that has high degree of motion is selected to form the summary .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
With each representative segment of each cluster, the portion that has high degree of motion is selected to form the summary .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
With each representative segment of each cluster, the portion that has high degree of motion is selected to form the summary .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
With each representative segment of each cluster, the portion that has high degree of motion is selected to form the summary .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
This approach achieves good performance in usability score but low performance in recall .
#<struct ReadData::Alignment source_numbers="3", target_numbers="4", tag_name="wa">
This approach achieves good performance in usability score but low performance in recall .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
This approach achieves good performance in usability score but low performance in recall .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
This approach achieves good performance in usability score but low performance in recall .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
This approach achieves good performance in usability score but low performance in recall .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
This approach achieves good performance in usability score but low performance in recall .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
This approach achieves good performance in usability score but low performance in recall .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
This approach achieves good performance in usability score but low performance in recall .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
This approach achieves good performance in usability score but low performance in recall .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
This approach achieves good performance in usability score but low performance in recall .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
This approach achieves good performance in usability score but low performance in recall .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
This approach achieves good performance in usability score but low performance in recall .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
This approach achieves good performance in usability score but low performance in recall .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
This approach achieves good performance in usability score but low performance in recall .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
This approach achieves good performance in recall and reasonable performance in usability score .
#<struct ReadData::Alignment source_numbers="8", target_numbers="8,9", tag_name="wa">
This approach achieves good performance in recall and reasonable performance in usability score .
#<struct ReadData::Alignment source_numbers="3", target_numbers="10", tag_name="wa">
This approach achieves good performance in recall and reasonable performance in usability score .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
This approach achieves good performance in recall and reasonable performance in usability score .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
This approach achieves good performance in recall and reasonable performance in usability score .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
This approach achieves good performance in recall and reasonable performance in usability score .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
This approach achieves good performance in recall and reasonable performance in usability score .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
This approach achieves good performance in recall and reasonable performance in usability score .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
This approach achieves good performance in recall and reasonable performance in usability score .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
This approach achieves good performance in recall and reasonable performance in usability score .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
This approach achieves good performance in recall and reasonable performance in usability score .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Compared to other systems participating in TRECVID 2008 summarization task, NII-2 is among best systems that have good balance between recall and usability .
#<struct ReadData::Alignment source_numbers="16,17", target_numbers="18,19", tag_name="wa">
Compared to other systems participating in TRECVID 2008 summarization task, NII-2 is among best systems that have good balance between recall and usability .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
Compared to other systems participating in TRECVID 2008 summarization task, NII-2 is among best systems that have good balance between recall and usability .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Searching persons is one of the essential tasks required by users for image and video search engines .
#<struct ReadData::Alignment source_numbers="11", target_numbers="1", tag_name="wa">
Searching persons is one of the essential tasks required by users for image and video search engines .
#<struct ReadData::Alignment source_numbers="1,2", target_numbers="4,5", tag_name="wa">
Searching persons is one of the essential tasks required by users for image and video search engines .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Searching persons is one of the essential tasks required by users for image and video search engines .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Searching persons is one of the essential tasks required by users for image and video search engines .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
However , the current search engines have limited capabilities for this task since they usually rely on texts associated with image and video which are likely to return many irrelevant results .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
In this paper , we propose a method to effectively retrieve relevant faces for one person by learning visual consistency from results retrieved from text correlation based search engines .
#<struct ReadData::Alignment source_numbers="29", target_numbers="25", tag_name="wa">
In this paper , we propose a method to effectively retrieve relevant faces for one person by learning visual consistency from results retrieved from text correlation based search engines .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
In this paper , we propose a method to effectively retrieve relevant faces for one person by learning visual consistency from results retrieved from text correlation based search engines .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
In this paper , we propose a method to effectively retrieve relevant faces for one person by learning visual consistency from results retrieved from text correlation based search engines .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
In this paper , we propose a method to effectively retrieve relevant faces for one person by learning visual consistency from results retrieved from text correlation based search engines .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
In this paper , we propose a method to effectively retrieve relevant faces for one person by learning visual consistency from results retrieved from text correlation based search engines .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
In this paper , we propose a method to effectively retrieve relevant faces for one person by learning visual consistency from results retrieved from text correlation based search engines .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
This problem is challenging because ( i ) no any label is provided leading to be difficult to use supervised-based ranking methods .
#<struct ReadData::Alignment source_numbers="11", target_numbers="9", tag_name="wa">
This problem is challenging because ( i ) no any label is provided leading to be difficult to use supervised-based ranking methods .
#<struct ReadData::Alignment source_numbers="12", target_numbers="12", tag_name="wa">
This problem is challenging because ( i ) no any label is provided leading to be difficult to use supervised-based ranking methods .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
This problem is challenging because ( i ) no any label is provided leading to be difficult to use supervised-based ranking methods .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
This problem is challenging because ( i ) no any label is provided leading to be difficult to use supervised-based ranking methods .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
This problem is challenging because ( i ) no any label is provided leading to be difficult to use supervised-based ranking methods .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
This problem is challenging because ( i ) no any label is provided leading to be difficult to use supervised-based ranking methods .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
This problem is challenging because ( i ) no any label is provided leading to be difficult to use supervised-based ranking methods .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
This problem is challenging because ( i ) no any label is provided leading to be difficult to use supervised-based ranking methods .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
( ii ) current face recognition techniques are still unmatured with wild-face databases even with supervised learning methods .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
( ii ) current face recognition techniques are still unmatured with wild-face databases even with supervised learning methods .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
In the proposed method , we treat the problem as a classification problem which input faces are classified as 'personX' ( the queried person ) or 'non-personX' and the faces are ranked based on their relevant score that is inferred from the classifier 's probability output .
#<struct ReadData::Alignment source_numbers="7,8", target_numbers="7,8", tag_name="wa">
In the proposed method , we treat the problem as a classification problem which input faces are classified as 'personX' ( the queried person ) or 'non-personX' and the faces are ranked based on their relevant score that is inferred from the classifier 's probability output .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
In the proposed method , we treat the problem as a classification problem which input faces are classified as 'personX' ( the queried person ) or 'non-personX' and the faces are ranked based on their relevant score that is inferred from the classifier 's probability output .
#<struct ReadData::Alignment source_numbers="26", target_numbers="", tag_name="wa">
In the proposed method , we treat the problem as a classification problem which input faces are classified as 'personX' ( the queried person ) or 'non-personX' and the faces are ranked based on their relevant score that is inferred from the classifier 's probability output .
#<struct ReadData::Alignment source_numbers="37", target_numbers="", tag_name="wa">
In the proposed method , we treat the problem as a classification problem which input faces are classified as 'personX' ( the queried person ) or 'non-personX' and the faces are ranked based on their relevant score that is inferred from the classifier 's probability output .
#<struct ReadData::Alignment source_numbers="38", target_numbers="", tag_name="wa">
In the proposed method , we treat the problem as a classification problem which input faces are classified as 'personX' ( the queried person ) or 'non-personX' and the faces are ranked based on their relevant score that is inferred from the classifier 's probability output .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
In the proposed method , we treat the problem as a classification problem which input faces are classified as 'personX' ( the queried person ) or 'non-personX' and the faces are ranked based on their relevant score that is inferred from the classifier 's probability output .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
In the proposed method , we treat the problem as a classification problem which input faces are classified as 'personX' ( the queried person ) or 'non-personX' and the faces are ranked based on their relevant score that is inferred from the classifier 's probability output .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
In order to train this classifier , we use a bagging-based framework to combine results from multiple weak classifiers which are trained using different subsets .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
In order to train this classifier , we use a bagging-based framework to combine results from multiple weak classifiers which are trained using different subsets .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
In order to train this classifier , we use a bagging-based framework to combine results from multiple weak classifiers which are trained using different subsets .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
In order to train this classifier , we use a bagging-based framework to combine results from multiple weak classifiers which are trained using different subsets .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
In order to train this classifier , we use a bagging-based framework to combine results from multiple weak classifiers which are trained using different subsets .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Experimental results on various face sets retrieved from the caption of news photos show that the retrieval performance is improved after each iteration leading the final performance outperforms the baseline algorithms .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
Experimental results on various face sets retrieved from the caption of news photos show that the retrieval performance is improved after each iteration leading the final performance outperforms the baseline algorithms .
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
Experimental results on various face sets retrieved from the caption of news photos show that the retrieval performance is improved after each iteration leading the final performance outperforms the baseline algorithms .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
With the rapid growing of digital technology , large image and video databases are available easier than ever to users .
#<struct ReadData::Alignment source_numbers="3,4", target_numbers="3,4", tag_name="wa">
With the rapid growing of digital technology , large image and video databases are available easier than ever to users .
#<struct ReadData::Alignment source_numbers="14", target_numbers="15", tag_name="wa">
With the rapid growing of digital technology , large image and video databases are available easier than ever to users .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
With the rapid growing of digital technology , large image and video databases are available easier than ever to users .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Therefore , effective and efficient tools are strongly needed for indexing and retrieving based on visual contents .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
One of the typical examples for this application is to search a specific person by providing his or her name .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
One of the typical examples for this application is to search a specific person by providing his or her name .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
One of the typical examples for this application is to search a specific person by providing his or her name .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
One of the typical examples for this application is to search a specific person by providing his or her name .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
One of the typical examples for this application is to search a specific person by providing his or her name .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
One of the typical examples for this application is to search a specific person by providing his or her name .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
One of the typical examples for this application is to search a specific person by providing his or her name .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Usually , most of current search engines use text associated with images or videos as a significant clue to return the results .
#<struct ReadData::Alignment source_numbers="20", target_numbers="7", tag_name="wa">
Usually , most of current search engines use text associated with images or videos as a significant clue to return the results .
#<struct ReadData::Alignment source_numbers="19", target_numbers="18", tag_name="wa">
Usually , most of current search engines use text associated with images or videos as a significant clue to return the results .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
Usually , most of current search engines use text associated with images or videos as a significant clue to return the results .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
However , since it is not necessary faces and names appear simultaneously and are aligned ( as shown in Figure \REF ) , the main drawback of this approach is existence of many irrelevant results that makes the retrieval performance very low .
#<struct ReadData::Alignment source_numbers="42", target_numbers="25", tag_name="wa">
However , since it is not necessary faces and names appear simultaneously and are aligned ( as shown in Figure \REF ) , the main drawback of this approach is existence of many irrelevant results that makes the retrieval performance very low .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
However , since it is not necessary faces and names appear simultaneously and are aligned ( as shown in Figure \REF ) , the main drawback of this approach is existence of many irrelevant results that makes the retrieval performance very low .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
However , since it is not necessary faces and names appear simultaneously and are aligned ( as shown in Figure \REF ) , the main drawback of this approach is existence of many irrelevant results that makes the retrieval performance very low .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
However , since it is not necessary faces and names appear simultaneously and are aligned ( as shown in Figure \REF ) , the main drawback of this approach is existence of many irrelevant results that makes the retrieval performance very low .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
However , since it is not necessary faces and names appear simultaneously and are aligned ( as shown in Figure \REF ) , the main drawback of this approach is existence of many irrelevant results that makes the retrieval performance very low .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
However , since it is not necessary faces and names appear simultaneously and are aligned ( as shown in Figure \REF ) , the main drawback of this approach is existence of many irrelevant results that makes the retrieval performance very low .
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
However , since it is not necessary faces and names appear simultaneously and are aligned ( as shown in Figure \REF ) , the main drawback of this approach is existence of many irrelevant results that makes the retrieval performance very low .
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
However , since it is not necessary faces and names appear simultaneously and are aligned ( as shown in Figure \REF ) , the main drawback of this approach is existence of many irrelevant results that makes the retrieval performance very low .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
However , since it is not necessary faces and names appear simultaneously and are aligned ( as shown in Figure \REF ) , the main drawback of this approach is existence of many irrelevant results that makes the retrieval performance very low .
#<struct ReadData::Alignment source_numbers="26", target_numbers="", tag_name="wa">
However , since it is not necessary faces and names appear simultaneously and are aligned ( as shown in Figure \REF ) , the main drawback of this approach is existence of many irrelevant results that makes the retrieval performance very low .
#<struct ReadData::Alignment source_numbers="27", target_numbers="", tag_name="wa">
However , since it is not necessary faces and names appear simultaneously and are aligned ( as shown in Figure \REF ) , the main drawback of this approach is existence of many irrelevant results that makes the retrieval performance very low .
#<struct ReadData::Alignment source_numbers="28", target_numbers="", tag_name="wa">
However , since it is not necessary faces and names appear simultaneously and are aligned ( as shown in Figure \REF ) , the main drawback of this approach is existence of many irrelevant results that makes the retrieval performance very low .
#<struct ReadData::Alignment source_numbers="29", target_numbers="", tag_name="wa">
However , since it is not necessary faces and names appear simultaneously and are aligned ( as shown in Figure \REF ) , the main drawback of this approach is existence of many irrelevant results that makes the retrieval performance very low .
#<struct ReadData::Alignment source_numbers="30", target_numbers="", tag_name="wa">
However , since it is not necessary faces and names appear simultaneously and are aligned ( as shown in Figure \REF ) , the main drawback of this approach is existence of many irrelevant results that makes the retrieval performance very low .
#<struct ReadData::Alignment source_numbers="31", target_numbers="", tag_name="wa">
However , since it is not necessary faces and names appear simultaneously and are aligned ( as shown in Figure \REF ) , the main drawback of this approach is existence of many irrelevant results that makes the retrieval performance very low .
#<struct ReadData::Alignment source_numbers="32", target_numbers="", tag_name="wa">
However , since it is not necessary faces and names appear simultaneously and are aligned ( as shown in Figure \REF ) , the main drawback of this approach is existence of many irrelevant results that makes the retrieval performance very low .
#<struct ReadData::Alignment source_numbers="33", target_numbers="", tag_name="wa">
However , since it is not necessary faces and names appear simultaneously and are aligned ( as shown in Figure \REF ) , the main drawback of this approach is existence of many irrelevant results that makes the retrieval performance very low .
#<struct ReadData::Alignment source_numbers="34", target_numbers="", tag_name="wa">
However , since it is not necessary faces and names appear simultaneously and are aligned ( as shown in Figure \REF ) , the main drawback of this approach is existence of many irrelevant results that makes the retrieval performance very low .
#<struct ReadData::Alignment source_numbers="35", target_numbers="", tag_name="wa">
However , since it is not necessary faces and names appear simultaneously and are aligned ( as shown in Figure \REF ) , the main drawback of this approach is existence of many irrelevant results that makes the retrieval performance very low .
#<struct ReadData::Alignment source_numbers="36", target_numbers="", tag_name="wa">
However , since it is not necessary faces and names appear simultaneously and are aligned ( as shown in Figure \REF ) , the main drawback of this approach is existence of many irrelevant results that makes the retrieval performance very low .
#<struct ReadData::Alignment source_numbers="40", target_numbers="", tag_name="wa">
However , since it is not necessary faces and names appear simultaneously and are aligned ( as shown in Figure \REF ) , the main drawback of this approach is existence of many irrelevant results that makes the retrieval performance very low .
#<struct ReadData::Alignment source_numbers="41", target_numbers="", tag_name="wa">
However , since it is not necessary faces and names appear simultaneously and are aligned ( as shown in Figure \REF ) , the main drawback of this approach is existence of many irrelevant results that makes the retrieval performance very low .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
However , since it is not necessary faces and names appear simultaneously and are aligned ( as shown in Figure \REF ) , the main drawback of this approach is existence of many irrelevant results that makes the retrieval performance very low .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
However , since it is not necessary faces and names appear simultaneously and are aligned ( as shown in Figure \REF ) , the main drawback of this approach is existence of many irrelevant results that makes the retrieval performance very low .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
However , since it is not necessary faces and names appear simultaneously and are aligned ( as shown in Figure \REF ) , the main drawback of this approach is existence of many irrelevant results that makes the retrieval performance very low .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
However , since it is not necessary faces and names appear simultaneously and are aligned ( as shown in Figure \REF ) , the main drawback of this approach is existence of many irrelevant results that makes the retrieval performance very low .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
Therefore it is necessary to improve the retrieval performance by taking into account visual information from the retrieved faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
-Large variations in face appearance due to pose changes , illumination conditions , occlusions and facial expressions make face recognition difficult even with state of the art techniques \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
-The fact the retrieved face set consists of faces of several persons while no any label is given makes supervised learning methods as well as unsupervised learning methods such as \MATH -means inapplicable .
#<struct ReadData::Alignment source_numbers="11", target_numbers="11,12", tag_name="wa">
-The fact the retrieved face set consists of faces of several persons while no any label is given makes supervised learning methods as well as unsupervised learning methods such as \MATH -means inapplicable .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
-The fact the retrieved face set consists of faces of several persons while no any label is given makes supervised learning methods as well as unsupervised learning methods such as \MATH -means inapplicable .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
-The fact the retrieved face set consists of faces of several persons while no any label is given makes supervised learning methods as well as unsupervised learning methods such as \MATH -means inapplicable .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
-The fact the retrieved face set consists of faces of several persons while no any label is given makes supervised learning methods as well as unsupervised learning methods such as \MATH -means inapplicable .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
-The fact the retrieved face set consists of faces of several persons while no any label is given makes supervised learning methods as well as unsupervised learning methods such as \MATH -means inapplicable .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
-The fact the retrieved face set consists of faces of several persons while no any label is given makes supervised learning methods as well as unsupervised learning methods such as \MATH -means inapplicable .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
In this paper , we propose a method to solve the mentioned problem .
#<struct ReadData::Alignment source_numbers="13", target_numbers="9", tag_name="wa">
In this paper , we propose a method to solve the mentioned problem .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
In this paper , we propose a method to solve the mentioned problem .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
In this paper , we propose a method to solve the mentioned problem .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
In this paper , we propose a method to solve the mentioned problem .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
In this paper , we propose a method to solve the mentioned problem .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
In this paper , we propose a method to solve the mentioned problem .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
In this paper , we propose a method to solve the mentioned problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
In this paper , we propose a method to solve the mentioned problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
The main idea is to learn visual consistency assumed to exist among the results returned from current text-based search engines .
#<struct ReadData::Alignment source_numbers="10", target_numbers="7,8", tag_name="wa">
The main idea is to learn visual consistency assumed to exist among the results returned from current text-based search engines .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
The main idea is to learn visual consistency assumed to exist among the results returned from current text-based search engines .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
The main idea is to learn visual consistency assumed to exist among the results returned from current text-based search engines .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
The main idea is to learn visual consistency assumed to exist among the results returned from current text-based search engines .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
The main idea is to learn visual consistency assumed to exist among the results returned from current text-based search engines .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
The method consists of two stages .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
The method consists of two stages .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
This stage is stemmed from the observation that faces relevant to the queried person tend to form dense clusters while irrelevant faces are very sparse since they look different from each other .
#<struct ReadData::Alignment source_numbers="3", target_numbers="3", tag_name="wa">
This stage is stemmed from the observation that faces relevant to the queried person tend to form dense clusters while irrelevant faces are very sparse since they look different from each other .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
This stage is stemmed from the observation that faces relevant to the queried person tend to form dense clusters while irrelevant faces are very sparse since they look different from each other .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
This stage is stemmed from the observation that faces relevant to the queried person tend to form dense clusters while irrelevant faces are very sparse since they look different from each other .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
This stage is stemmed from the observation that faces relevant to the queried person tend to form dense clusters while irrelevant faces are very sparse since they look different from each other .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
This stage is stemmed from the observation that faces relevant to the queried person tend to form dense clusters while irrelevant faces are very sparse since they look different from each other .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
This stage is stemmed from the observation that faces relevant to the queried person tend to form dense clusters while irrelevant faces are very sparse since they look different from each other .
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
This stage is stemmed from the observation that faces relevant to the queried person tend to form dense clusters while irrelevant faces are very sparse since they look different from each other .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
This stage is stemmed from the observation that faces relevant to the queried person tend to form dense clusters while irrelevant faces are very sparse since they look different from each other .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
This stage is stemmed from the observation that faces relevant to the queried person tend to form dense clusters while irrelevant faces are very sparse since they look different from each other .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
This stage is stemmed from the observation that faces relevant to the queried person tend to form dense clusters while irrelevant faces are very sparse since they look different from each other .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
This stage is stemmed from the observation that faces relevant to the queried person tend to form dense clusters while irrelevant faces are very sparse since they look different from each other .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
This stage is stemmed from the observation that faces relevant to the queried person tend to form dense clusters while irrelevant faces are very sparse since they look different from each other .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
The output is a rank list in which faces having larger number of neighbors within a distance are predicted as relevant ones and therefore are put on the top .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
The output is a rank list in which faces having larger number of neighbors within a distance are predicted as relevant ones and therefore are put on the top .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
The output is a rank list in which faces having larger number of neighbors within a distance are predicted as relevant ones and therefore are put on the top .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
The output is a rank list in which faces having larger number of neighbors within a distance are predicted as relevant ones and therefore are put on the top .
#<struct ReadData::Alignment source_numbers="26", target_numbers="", tag_name="wa">
The output is a rank list in which faces having larger number of neighbors within a distance are predicted as relevant ones and therefore are put on the top .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
The output is a rank list in which faces having larger number of neighbors within a distance are predicted as relevant ones and therefore are put on the top .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
The output is a rank list in which faces having larger number of neighbors within a distance are predicted as relevant ones and therefore are put on the top .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
The output is a rank list in which faces having larger number of neighbors within a distance are predicted as relevant ones and therefore are put on the top .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
The output is a rank list in which faces having larger number of neighbors within a distance are predicted as relevant ones and therefore are put on the top .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
The output is a rank list in which faces having larger number of neighbors within a distance are predicted as relevant ones and therefore are put on the top .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
The output is a rank list in which faces having larger number of neighbors within a distance are predicted as relevant ones and therefore are put on the top .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
The output is a rank list in which faces having larger number of neighbors within a distance are predicted as relevant ones and therefore are put on the top .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
The output is a rank list in which faces having larger number of neighbors within a distance are predicted as relevant ones and therefore are put on the top .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
The output is a rank list in which faces having larger number of neighbors within a distance are predicted as relevant ones and therefore are put on the top .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
The output is a rank list in which faces having larger number of neighbors within a distance are predicted as relevant ones and therefore are put on the top .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
The output is a rank list in which faces having larger number of neighbors within a distance are predicted as relevant ones and therefore are put on the top .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
The output is a rank list in which faces having larger number of neighbors within a distance are predicted as relevant ones and therefore are put on the top .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
The output is a rank list in which faces having larger number of neighbors within a distance are predicted as relevant ones and therefore are put on the top .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
The output is a rank list in which faces having larger number of neighbors within a distance are predicted as relevant ones and therefore are put on the top .
#<struct ReadData::Alignment source_numbers="", target_numbers="40", tag_name="wa">
The output is a rank list in which faces having larger number of neighbors within a distance are predicted as relevant ones and therefore are put on the top .
#<struct ReadData::Alignment source_numbers="", target_numbers="41", tag_name="wa">
The output is a rank list in which faces having larger number of neighbors within a distance are predicted as relevant ones and therefore are put on the top .
#<struct ReadData::Alignment source_numbers="", target_numbers="42", tag_name="wa">
The output is a rank list in which faces having larger number of neighbors within a distance are predicted as relevant ones and therefore are put on the top .
#<struct ReadData::Alignment source_numbers="", target_numbers="43", tag_name="wa">
The output is a rank list in which faces having larger number of neighbors within a distance are predicted as relevant ones and therefore are put on the top .
#<struct ReadData::Alignment source_numbers="", target_numbers="44", tag_name="wa">
The output is a rank list in which faces having larger number of neighbors within a distance are predicted as relevant ones and therefore are put on the top .
#<struct ReadData::Alignment source_numbers="", target_numbers="45", tag_name="wa">
The output is a rank list in which faces having larger number of neighbors within a distance are predicted as relevant ones and therefore are put on the top .
#<struct ReadData::Alignment source_numbers="", target_numbers="46", tag_name="wa">
The output is a rank list in which faces having larger number of neighbors within a distance are predicted as relevant ones and therefore are put on the top .
#<struct ReadData::Alignment source_numbers="", target_numbers="47", tag_name="wa">
Since the above ranking method is based on the number of neighbors , it is sensitive to the chosen distance .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
Since the above ranking method is based on the number of neighbors , it is sensitive to the chosen distance .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
It is necessary to use the second stage to improve the rank list .
#<struct ReadData::Alignment source_numbers="1", target_numbers="3", tag_name="wa">
It is necessary to use the second stage to improve the rank list .
#<struct ReadData::Alignment source_numbers="3", target_numbers="5", tag_name="wa">
It is necessary to use the second stage to improve the rank list .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
It is necessary to use the second stage to improve the rank list .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
It is necessary to use the second stage to improve the rank list .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
It is necessary to use the second stage to improve the rank list .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
It is necessary to use the second stage to improve the rank list .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
It is necessary to use the second stage to improve the rank list .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
It is necessary to use the second stage to improve the rank list .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
We model this problem as a classification problem which input faces are classified as personX ( the queried person ) or non-personX ( the irrelevant person ) .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
We model this problem as a classification problem which input faces are classified as personX ( the queried person ) or non-personX ( the irrelevant person ) .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
We model this problem as a classification problem which input faces are classified as personX ( the queried person ) or non-personX ( the irrelevant person ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
We model this problem as a classification problem which input faces are classified as personX ( the queried person ) or non-personX ( the irrelevant person ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
We model this problem as a classification problem which input faces are classified as personX ( the queried person ) or non-personX ( the irrelevant person ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
This subset then is used to train a classifier using a supervised method such as support vector machines ( SVM ) .
#<struct ReadData::Alignment source_numbers="12", target_numbers="11", tag_name="wa">
This subset then is used to train a classifier using a supervised method such as support vector machines ( SVM ) .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
The trained classifier is used to re-rank faces in the original input set again .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
This stage is effective for improving the rank list due to the following reasons :
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
This stage is effective for improving the rank list due to the following reasons :
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
This stage is effective for improving the rank list due to the following reasons :
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
-Supervised learning methods such as SVM have strong theoretical background in finding optimal decision boundary even with existence of noisy data .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
-Supervised learning methods such as SVM have strong theoretical background in finding optimal decision boundary even with existence of noisy data .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
-Supervised learning methods such as SVM have strong theoretical background in finding optimal decision boundary even with existence of noisy data .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
-Supervised learning methods such as SVM have strong theoretical background in finding optimal decision boundary even with existence of noisy data .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
-Supervised learning methods such as SVM have strong theoretical background in finding optimal decision boundary even with existence of noisy data .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
-Supervised learning methods such as SVM have strong theoretical background in finding optimal decision boundary even with existence of noisy data .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Furthermore , with recent studies \CITE SVM classifiers can provide probability outputs that are suitable for ranking .
#<struct ReadData::Alignment source_numbers="9", target_numbers="9", tag_name="wa">
Furthermore , with recent studies \CITE SVM classifiers can provide probability outputs that are suitable for ranking .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Furthermore , with recent studies \CITE SVM classifiers can provide probability outputs that are suitable for ranking .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Furthermore , with recent studies \CITE SVM classifiers can provide probability outputs that are suitable for ranking .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Furthermore , with recent studies \CITE SVM classifiers can provide probability outputs that are suitable for ranking .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
-We propose a general framework to boost the face retrieval performance from the results retrieved from text correlation based search engines by learning visual consistency .
#<struct ReadData::Alignment source_numbers="12", target_numbers="20", tag_name="wa">
-We propose a general framework to boost the face retrieval performance from the results retrieved from text correlation based search engines by learning visual consistency .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
-We propose a general framework to boost the face retrieval performance from the results retrieved from text correlation based search engines by learning visual consistency .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
-We propose a general framework to boost the face retrieval performance from the results retrieved from text correlation based search engines by learning visual consistency .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
It integrates seamlessly current existing data mining methods such as outliers detection , supervised learning and unsupervised learning based on bagging for a practical problem .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
It integrates seamlessly current existing data mining methods such as outliers detection , supervised learning and unsupervised learning based on bagging for a practical problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
It integrates seamlessly current existing data mining methods such as outliers detection , supervised learning and unsupervised learning based on bagging for a practical problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
It integrates seamlessly current existing data mining methods such as outliers detection , supervised learning and unsupervised learning based on bagging for a practical problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
It integrates seamlessly current existing data mining methods such as outliers detection , supervised learning and unsupervised learning based on bagging for a practical problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
It integrates seamlessly current existing data mining methods such as outliers detection , supervised learning and unsupervised learning based on bagging for a practical problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
It integrates seamlessly current existing data mining methods such as outliers detection , supervised learning and unsupervised learning based on bagging for a practical problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
It integrates seamlessly current existing data mining methods such as outliers detection , supervised learning and unsupervised learning based on bagging for a practical problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
It integrates seamlessly current existing data mining methods such as outliers detection , supervised learning and unsupervised learning based on bagging for a practical problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
It integrates seamlessly current existing data mining methods such as outliers detection , supervised learning and unsupervised learning based on bagging for a practical problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
It integrates seamlessly current existing data mining methods such as outliers detection , supervised learning and unsupervised learning based on bagging for a practical problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
It integrates seamlessly current existing data mining methods such as outliers detection , supervised learning and unsupervised learning based on bagging for a practical problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
It integrates seamlessly current existing data mining methods such as outliers detection , supervised learning and unsupervised learning based on bagging for a practical problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
It integrates seamlessly current existing data mining methods such as outliers detection , supervised learning and unsupervised learning based on bagging for a practical problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
It integrates seamlessly current existing data mining methods such as outliers detection , supervised learning and unsupervised learning based on bagging for a practical problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
It integrates seamlessly current existing data mining methods such as outliers detection , supervised learning and unsupervised learning based on bagging for a practical problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
It integrates seamlessly current existing data mining methods such as outliers detection , supervised learning and unsupervised learning based on bagging for a practical problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="40", tag_name="wa">
There are several approaches proposed for general object classification rather than for face retrieval .
#<struct ReadData::Alignment source_numbers="10", target_numbers="10", tag_name="wa">
There are several approaches proposed for general object classification rather than for face retrieval .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
There are several approaches proposed for general object classification rather than for face retrieval .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
There are several approaches proposed for general object classification rather than for face retrieval .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
There are several approaches proposed for general object classification rather than for face retrieval .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Compared to the problem of face retrieval based recognition , the problem of object classification is easier since classification of different object types such as airplane and non-airplane only needs to handle inter-variations between different categories while discriminating personA and personB requires to handle both intra-variations and inter-variations of the same category .
#<struct ReadData::Alignment source_numbers="48", target_numbers="43", tag_name="wa">
Compared to the problem of face retrieval based recognition , the problem of object classification is easier since classification of different object types such as airplane and non-airplane only needs to handle inter-variations between different categories while discriminating personA and personB requires to handle both intra-variations and inter-variations of the same category .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Compared to the problem of face retrieval based recognition , the problem of object classification is easier since classification of different object types such as airplane and non-airplane only needs to handle inter-variations between different categories while discriminating personA and personB requires to handle both intra-variations and inter-variations of the same category .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
Compared to the problem of face retrieval based recognition , the problem of object classification is easier since classification of different object types such as airplane and non-airplane only needs to handle inter-variations between different categories while discriminating personA and personB requires to handle both intra-variations and inter-variations of the same category .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Compared to the problem of face retrieval based recognition , the problem of object classification is easier since classification of different object types such as airplane and non-airplane only needs to handle inter-variations between different categories while discriminating personA and personB requires to handle both intra-variations and inter-variations of the same category .
#<struct ReadData::Alignment source_numbers="38", target_numbers="", tag_name="wa">
Compared to the problem of face retrieval based recognition , the problem of object classification is easier since classification of different object types such as airplane and non-airplane only needs to handle inter-variations between different categories while discriminating personA and personB requires to handle both intra-variations and inter-variations of the same category .
#<struct ReadData::Alignment source_numbers="40", target_numbers="", tag_name="wa">
Compared to the problem of face retrieval based recognition , the problem of object classification is easier since classification of different object types such as airplane and non-airplane only needs to handle inter-variations between different categories while discriminating personA and personB requires to handle both intra-variations and inter-variations of the same category .
#<struct ReadData::Alignment source_numbers="42", target_numbers="", tag_name="wa">
Compared to the problem of face retrieval based recognition , the problem of object classification is easier since classification of different object types such as airplane and non-airplane only needs to handle inter-variations between different categories while discriminating personA and personB requires to handle both intra-variations and inter-variations of the same category .
#<struct ReadData::Alignment source_numbers="43", target_numbers="", tag_name="wa">
Compared to the problem of face retrieval based recognition , the problem of object classification is easier since classification of different object types such as airplane and non-airplane only needs to handle inter-variations between different categories while discriminating personA and personB requires to handle both intra-variations and inter-variations of the same category .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Compared to the problem of face retrieval based recognition , the problem of object classification is easier since classification of different object types such as airplane and non-airplane only needs to handle inter-variations between different categories while discriminating personA and personB requires to handle both intra-variations and inter-variations of the same category .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
Compared to the problem of face retrieval based recognition , the problem of object classification is easier since classification of different object types such as airplane and non-airplane only needs to handle inter-variations between different categories while discriminating personA and personB requires to handle both intra-variations and inter-variations of the same category .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
Compared to the problem of face retrieval based recognition , the problem of object classification is easier since classification of different object types such as airplane and non-airplane only needs to handle inter-variations between different categories while discriminating personA and personB requires to handle both intra-variations and inter-variations of the same category .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
Compared to the problem of face retrieval based recognition , the problem of object classification is easier since classification of different object types such as airplane and non-airplane only needs to handle inter-variations between different categories while discriminating personA and personB requires to handle both intra-variations and inter-variations of the same category .
#<struct ReadData::Alignment source_numbers="", target_numbers="40", tag_name="wa">
Compared to the problem of face retrieval based recognition , the problem of object classification is easier since classification of different object types such as airplane and non-airplane only needs to handle inter-variations between different categories while discriminating personA and personB requires to handle both intra-variations and inter-variations of the same category .
#<struct ReadData::Alignment source_numbers="", target_numbers="42", tag_name="wa">
Compared to the problem of face retrieval based recognition , the problem of object classification is easier since classification of different object types such as airplane and non-airplane only needs to handle inter-variations between different categories while discriminating personA and personB requires to handle both intra-variations and inter-variations of the same category .
#<struct ReadData::Alignment source_numbers="", target_numbers="48", tag_name="wa">
Furthermore , in order to work in unsupervised mode , these approaches need a method to collect negative samples ( e.g. non-airplane ) which are inapplicable in our problem .
#<struct ReadData::Alignment source_numbers="26", target_numbers="", tag_name="wa">
Furthermore , in order to work in unsupervised mode , these approaches need a method to collect negative samples ( e.g. non-airplane ) which are inapplicable in our problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
Furthermore , in order to work in unsupervised mode , these approaches need a method to collect negative samples ( e.g. non-airplane ) which are inapplicable in our problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
Working closely to our problem , in \cite{Ozkan06CVPR} , a graph based approach was proposed \CITEin which a graph is formed by faces as nodes and weights of edges linked between nodes are the similarity of faces .
#<struct ReadData::Alignment source_numbers="6", target_numbers="8", tag_name="wa">
Working closely to our problem , in \cite{Ozkan06CVPR} , a graph based approach was proposed \CITEin which a graph is formed by faces as nodes and weights of edges linked between nodes are the similarity of faces .
#<struct ReadData::Alignment source_numbers="8", target_numbers="18", tag_name="wa">
Working closely to our problem , in \cite{Ozkan06CVPR} , a graph based approach was proposed \CITEin which a graph is formed by faces as nodes and weights of edges linked between nodes are the similarity of faces .
#<struct ReadData::Alignment source_numbers="33", target_numbers="20", tag_name="wa">
Working closely to our problem , in \cite{Ozkan06CVPR} , a graph based approach was proposed \CITEin which a graph is formed by faces as nodes and weights of edges linked between nodes are the similarity of faces .
#<struct ReadData::Alignment source_numbers="1", target_numbers="34", tag_name="wa">
Working closely to our problem , in \cite{Ozkan06CVPR} , a graph based approach was proposed \CITEin which a graph is formed by faces as nodes and weights of edges linked between nodes are the similarity of faces .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Working closely to our problem , in \cite{Ozkan06CVPR} , a graph based approach was proposed \CITEin which a graph is formed by faces as nodes and weights of edges linked between nodes are the similarity of faces .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Working closely to our problem , in \cite{Ozkan06CVPR} , a graph based approach was proposed \CITEin which a graph is formed by faces as nodes and weights of edges linked between nodes are the similarity of faces .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Working closely to our problem , in \cite{Ozkan06CVPR} , a graph based approach was proposed \CITEin which a graph is formed by faces as nodes and weights of edges linked between nodes are the similarity of faces .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Working closely to our problem , in \cite{Ozkan06CVPR} , a graph based approach was proposed \CITEin which a graph is formed by faces as nodes and weights of edges linked between nodes are the similarity of faces .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
Working closely to our problem , in \cite{Ozkan06CVPR} , a graph based approach was proposed \CITEin which a graph is formed by faces as nodes and weights of edges linked between nodes are the similarity of faces .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
Working closely to our problem , in \cite{Ozkan06CVPR} , a graph based approach was proposed \CITEin which a graph is formed by faces as nodes and weights of edges linked between nodes are the similarity of faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Working closely to our problem , in \cite{Ozkan06CVPR} , a graph based approach was proposed \CITEin which a graph is formed by faces as nodes and weights of edges linked between nodes are the similarity of faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Working closely to our problem , in \cite{Ozkan06CVPR} , a graph based approach was proposed \CITEin which a graph is formed by faces as nodes and weights of edges linked between nodes are the similarity of faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Working closely to our problem , in \cite{Ozkan06CVPR} , a graph based approach was proposed \CITEin which a graph is formed by faces as nodes and weights of edges linked between nodes are the similarity of faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Working closely to our problem , in \cite{Ozkan06CVPR} , a graph based approach was proposed \CITEin which a graph is formed by faces as nodes and weights of edges linked between nodes are the similarity of faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
Working closely to our problem , in \cite{Ozkan06CVPR} , a graph based approach was proposed \CITEin which a graph is formed by faces as nodes and weights of edges linked between nodes are the similarity of faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
Working closely to our problem , in \cite{Ozkan06CVPR} , a graph based approach was proposed \CITEin which a graph is formed by faces as nodes and weights of edges linked between nodes are the similarity of faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
Working closely to our problem , in \cite{Ozkan06CVPR} , a graph based approach was proposed \CITEin which a graph is formed by faces as nodes and weights of edges linked between nodes are the similarity of faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
By assuming that the number of faces of the queried person are larger than that of other persons , and these faces tend to form the most similar subset among the set of retrieved faces , this problem is considered equal to the problem of finding the densest subgraph of a full graph whose solution is available .
#<struct ReadData::Alignment source_numbers="55", target_numbers="10", tag_name="wa">
By assuming that the number of faces of the queried person are larger than that of other persons , and these faces tend to form the most similar subset among the set of retrieved faces , this problem is considered equal to the problem of finding the densest subgraph of a full graph whose solution is available .
#<struct ReadData::Alignment source_numbers="49", target_numbers="14", tag_name="wa">
By assuming that the number of faces of the queried person are larger than that of other persons , and these faces tend to form the most similar subset among the set of retrieved faces , this problem is considered equal to the problem of finding the densest subgraph of a full graph whose solution is available .
#<struct ReadData::Alignment source_numbers="15,16", target_numbers="15", tag_name="wa">
By assuming that the number of faces of the queried person are larger than that of other persons , and these faces tend to form the most similar subset among the set of retrieved faces , this problem is considered equal to the problem of finding the densest subgraph of a full graph whose solution is available .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
By assuming that the number of faces of the queried person are larger than that of other persons , and these faces tend to form the most similar subset among the set of retrieved faces , this problem is considered equal to the problem of finding the densest subgraph of a full graph whose solution is available .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
By assuming that the number of faces of the queried person are larger than that of other persons , and these faces tend to form the most similar subset among the set of retrieved faces , this problem is considered equal to the problem of finding the densest subgraph of a full graph whose solution is available .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
By assuming that the number of faces of the queried person are larger than that of other persons , and these faces tend to form the most similar subset among the set of retrieved faces , this problem is considered equal to the problem of finding the densest subgraph of a full graph whose solution is available .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
By assuming that the number of faces of the queried person are larger than that of other persons , and these faces tend to form the most similar subset among the set of retrieved faces , this problem is considered equal to the problem of finding the densest subgraph of a full graph whose solution is available .
#<struct ReadData::Alignment source_numbers="53", target_numbers="", tag_name="wa">
By assuming that the number of faces of the queried person are larger than that of other persons , and these faces tend to form the most similar subset among the set of retrieved faces , this problem is considered equal to the problem of finding the densest subgraph of a full graph whose solution is available .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
By assuming that the number of faces of the queried person are larger than that of other persons , and these faces tend to form the most similar subset among the set of retrieved faces , this problem is considered equal to the problem of finding the densest subgraph of a full graph whose solution is available .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
By assuming that the number of faces of the queried person are larger than that of other persons , and these faces tend to form the most similar subset among the set of retrieved faces , this problem is considered equal to the problem of finding the densest subgraph of a full graph whose solution is available .
#<struct ReadData::Alignment source_numbers="", target_numbers="47", tag_name="wa">
By assuming that the number of faces of the queried person are larger than that of other persons , and these faces tend to form the most similar subset among the set of retrieved faces , this problem is considered equal to the problem of finding the densest subgraph of a full graph whose solution is available .
#<struct ReadData::Alignment source_numbers="", target_numbers="51", tag_name="wa">
By assuming that the number of faces of the queried person are larger than that of other persons , and these faces tend to form the most similar subset among the set of retrieved faces , this problem is considered equal to the problem of finding the densest subgraph of a full graph whose solution is available .
#<struct ReadData::Alignment source_numbers="", target_numbers="52", tag_name="wa">
By assuming that the number of faces of the queried person are larger than that of other persons , and these faces tend to form the most similar subset among the set of retrieved faces , this problem is considered equal to the problem of finding the densest subgraph of a full graph whose solution is available .
#<struct ReadData::Alignment source_numbers="", target_numbers="56", tag_name="wa">
By assuming that the number of faces of the queried person are larger than that of other persons , and these faces tend to form the most similar subset among the set of retrieved faces , this problem is considered equal to the problem of finding the densest subgraph of a full graph whose solution is available .
#<struct ReadData::Alignment source_numbers="", target_numbers="57", tag_name="wa">
By assuming that the number of faces of the queried person are larger than that of other persons , and these faces tend to form the most similar subset among the set of retrieved faces , this problem is considered equal to the problem of finding the densest subgraph of a full graph whose solution is available .
#<struct ReadData::Alignment source_numbers="", target_numbers="58", tag_name="wa">
By assuming that the number of faces of the queried person are larger than that of other persons , and these faces tend to form the most similar subset among the set of retrieved faces , this problem is considered equal to the problem of finding the densest subgraph of a full graph whose solution is available .
#<struct ReadData::Alignment source_numbers="", target_numbers="59", tag_name="wa">
By assuming that the number of faces of the queried person are larger than that of other persons , and these faces tend to form the most similar subset among the set of retrieved faces , this problem is considered equal to the problem of finding the densest subgraph of a full graph whose solution is available .
#<struct ReadData::Alignment source_numbers="", target_numbers="60", tag_name="wa">
By assuming that the number of faces of the queried person are larger than that of other persons , and these faces tend to form the most similar subset among the set of retrieved faces , this problem is considered equal to the problem of finding the densest subgraph of a full graph whose solution is available .
#<struct ReadData::Alignment source_numbers="", target_numbers="61", tag_name="wa">
By assuming that the number of faces of the queried person are larger than that of other persons , and these faces tend to form the most similar subset among the set of retrieved faces , this problem is considered equal to the problem of finding the densest subgraph of a full graph whose solution is available .
#<struct ReadData::Alignment source_numbers="", target_numbers="62", tag_name="wa">
By assuming that the number of faces of the queried person are larger than that of other persons , and these faces tend to form the most similar subset among the set of retrieved faces , this problem is considered equal to the problem of finding the densest subgraph of a full graph whose solution is available .
#<struct ReadData::Alignment source_numbers="", target_numbers="63", tag_name="wa">
By assuming that the number of faces of the queried person are larger than that of other persons , and these faces tend to form the most similar subset among the set of retrieved faces , this problem is considered equal to the problem of finding the densest subgraph of a full graph whose solution is available .
#<struct ReadData::Alignment source_numbers="", target_numbers="64", tag_name="wa">
By assuming that the number of faces of the queried person are larger than that of other persons , and these faces tend to form the most similar subset among the set of retrieved faces , this problem is considered equal to the problem of finding the densest subgraph of a full graph whose solution is available .
#<struct ReadData::Alignment source_numbers="", target_numbers="65", tag_name="wa">
Furthermore , choosing an optimal threshold to convert the initial graph into a binary graph is difficult and rather ad hoc due to the curse of dimensionality .
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
Furthermore , choosing an optimal threshold to convert the initial graph into a binary graph is difficult and rather ad hoc due to the curse of dimensionality .
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
Furthermore , choosing an optimal threshold to convert the initial graph into a binary graph is difficult and rather ad hoc due to the curse of dimensionality .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
In another work \CITE , a clustering-based approach was proposed to associate names and faces in news photos .
#<struct ReadData::Alignment source_numbers="9,10", target_numbers="9,10", tag_name="wa">
In another work \CITE , a clustering-based approach was proposed to associate names and faces in news photos .
#<struct ReadData::Alignment source_numbers="11", target_numbers="11", tag_name="wa">
Although the result was impressive , it is not easy to apply for our problem since a large number of irrelevant faces ( more than 12% ) are eliminated manually before doing clustering .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
Although the result was impressive , it is not easy to apply for our problem since a large number of irrelevant faces ( more than 12% ) are eliminated manually before doing clustering .
#<struct ReadData::Alignment source_numbers="31", target_numbers="", tag_name="wa">
Although the result was impressive , it is not easy to apply for our problem since a large number of irrelevant faces ( more than 12% ) are eliminated manually before doing clustering .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
Although the result was impressive , it is not easy to apply for our problem since a large number of irrelevant faces ( more than 12% ) are eliminated manually before doing clustering .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Although the result was impressive , it is not easy to apply for our problem since a large number of irrelevant faces ( more than 12% ) are eliminated manually before doing clustering .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
Section \REF introduce briefly typical outliers detection methods .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Section \REF introduce briefly typical outliers detection methods .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Given a set of faces returned by any text-based correlation search engine , our method performs a ranking process summarized as follows :
#<struct ReadData::Alignment source_numbers="15", target_numbers="18", tag_name="wa">
Given a set of faces returned by any text-based correlation search engine , our method performs a ranking process summarized as follows :
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
Given a set of faces returned by any text-based correlation search engine , our method performs a ranking process summarized as follows :
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
Given a set of faces returned by any text-based correlation search engine , our method performs a ranking process summarized as follows :
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
-Step 4 : Train a ensemble classifier \MATH using this rank list by Bag-Rank-SVM .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
-Step 4 : Train a ensemble classifier \MATH using this rank list by Bag-Rank-SVM .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Step 3 used to find initial ranks for faces is described in \REF .
#<struct ReadData::Alignment source_numbers="10", target_numbers="9", tag_name="wa">
Step 3 used to find initial ranks for faces is described in \REF .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Since it is not guaranteed top \MATH and bottom \MATH of faces in the rank list are correctly correspondent to faces of the queried person \MATH and faces of non person \MATH as shown in Figure \REF , selecting randomly subsets to train weak classifiers and then combining these classifiers might help to reduce risk of using noisy training sets .
#<struct ReadData::Alignment source_numbers="22", target_numbers="6", tag_name="wa">
Since it is not guaranteed top \MATH and bottom \MATH of faces in the rank list are correctly correspondent to faces of the queried person \MATH and faces of non person \MATH as shown in Figure \REF , selecting randomly subsets to train weak classifiers and then combining these classifiers might help to reduce risk of using noisy training sets .
#<struct ReadData::Alignment source_numbers="18", target_numbers="19", tag_name="wa">
Since it is not guaranteed top \MATH and bottom \MATH of faces in the rank list are correctly correspondent to faces of the queried person \MATH and faces of non person \MATH as shown in Figure \REF , selecting randomly subsets to train weak classifiers and then combining these classifiers might help to reduce risk of using noisy training sets .
#<struct ReadData::Alignment source_numbers="53", target_numbers="53", tag_name="wa">
Since it is not guaranteed top \MATH and bottom \MATH of faces in the rank list are correctly correspondent to faces of the queried person \MATH and faces of non person \MATH as shown in Figure \REF , selecting randomly subsets to train weak classifiers and then combining these classifiers might help to reduce risk of using noisy training sets .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
Since it is not guaranteed top \MATH and bottom \MATH of faces in the rank list are correctly correspondent to faces of the queried person \MATH and faces of non person \MATH as shown in Figure \REF , selecting randomly subsets to train weak classifiers and then combining these classifiers might help to reduce risk of using noisy training sets .
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
Since it is not guaranteed top \MATH and bottom \MATH of faces in the rank list are correctly correspondent to faces of the queried person \MATH and faces of non person \MATH as shown in Figure \REF , selecting randomly subsets to train weak classifiers and then combining these classifiers might help to reduce risk of using noisy training sets .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
Since it is not guaranteed top \MATH and bottom \MATH of faces in the rank list are correctly correspondent to faces of the queried person \MATH and faces of non person \MATH as shown in Figure \REF , selecting randomly subsets to train weak classifiers and then combining these classifiers might help to reduce risk of using noisy training sets .
#<struct ReadData::Alignment source_numbers="30", target_numbers="", tag_name="wa">
Since it is not guaranteed top \MATH and bottom \MATH of faces in the rank list are correctly correspondent to faces of the queried person \MATH and faces of non person \MATH as shown in Figure \REF , selecting randomly subsets to train weak classifiers and then combining these classifiers might help to reduce risk of using noisy training sets .
#<struct ReadData::Alignment source_numbers="31", target_numbers="", tag_name="wa">
Since it is not guaranteed top \MATH and bottom \MATH of faces in the rank list are correctly correspondent to faces of the queried person \MATH and faces of non person \MATH as shown in Figure \REF , selecting randomly subsets to train weak classifiers and then combining these classifiers might help to reduce risk of using noisy training sets .
#<struct ReadData::Alignment source_numbers="52", target_numbers="", tag_name="wa">
Since it is not guaranteed top \MATH and bottom \MATH of faces in the rank list are correctly correspondent to faces of the queried person \MATH and faces of non person \MATH as shown in Figure \REF , selecting randomly subsets to train weak classifiers and then combining these classifiers might help to reduce risk of using noisy training sets .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Since it is not guaranteed top \MATH and bottom \MATH of faces in the rank list are correctly correspondent to faces of the queried person \MATH and faces of non person \MATH as shown in Figure \REF , selecting randomly subsets to train weak classifiers and then combining these classifiers might help to reduce risk of using noisy training sets .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
Since it is not guaranteed top \MATH and bottom \MATH of faces in the rank list are correctly correspondent to faces of the queried person \MATH and faces of non person \MATH as shown in Figure \REF , selecting randomly subsets to train weak classifiers and then combining these classifiers might help to reduce risk of using noisy training sets .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
Since it is not guaranteed top \MATH and bottom \MATH of faces in the rank list are correctly correspondent to faces of the queried person \MATH and faces of non person \MATH as shown in Figure \REF , selecting randomly subsets to train weak classifiers and then combining these classifiers might help to reduce risk of using noisy training sets .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
Since it is not guaranteed top \MATH and bottom \MATH of faces in the rank list are correctly correspondent to faces of the queried person \MATH and faces of non person \MATH as shown in Figure \REF , selecting randomly subsets to train weak classifiers and then combining these classifiers might help to reduce risk of using noisy training sets .
#<struct ReadData::Alignment source_numbers="", target_numbers="45", tag_name="wa">
We introduce here two common outliers detection methods including distance-based outliers detection( DBO ) \CITE and local outliers factor based method ( LOF ) \CITE .
#<struct ReadData::Alignment source_numbers="21", target_numbers="11", tag_name="wa">
We introduce here two common outliers detection methods including distance-based outliers detection( DBO ) \CITE and local outliers factor based method ( LOF ) \CITE .
#<struct ReadData::Alignment source_numbers="12", target_numbers="12", tag_name="wa">
We introduce here two common outliers detection methods including distance-based outliers detection( DBO ) \CITE and local outliers factor based method ( LOF ) \CITE .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
We introduce here two common outliers detection methods including distance-based outliers detection( DBO ) \CITE and local outliers factor based method ( LOF ) \CITE .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
We introduce here two common outliers detection methods including distance-based outliers detection( DBO ) \CITE and local outliers factor based method ( LOF ) \CITE .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
We introduce here two common outliers detection methods including distance-based outliers detection( DBO ) \CITE and local outliers factor based method ( LOF ) \CITE .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
We introduce here two common outliers detection methods including distance-based outliers detection( DBO ) \CITE and local outliers factor based method ( LOF ) \CITE .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
We introduce here two common outliers detection methods including distance-based outliers detection( DBO ) \CITE and local outliers factor based method ( LOF ) \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
We introduce here two common outliers detection methods including distance-based outliers detection( DBO ) \CITE and local outliers factor based method ( LOF ) \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
We introduce here two common outliers detection methods including distance-based outliers detection( DBO ) \CITE and local outliers factor based method ( LOF ) \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
We introduce here two common outliers detection methods including distance-based outliers detection( DBO ) \CITE and local outliers factor based method ( LOF ) \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
Adapting the definition \CITE , given a set of objects \MATH , an object \MATH is considered as an outliers if there are fewer than \MATH neighboring objects in \MATH lying within a distance \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Adapting the definition \CITE , given a set of objects \MATH , an object \MATH is considered as an outliers if there are fewer than \MATH neighboring objects in \MATH lying within a distance \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
The outliers detection process is summarized as follows :
#<struct ReadData::Alignment source_numbers="1", target_numbers="1", tag_name="wa">
The outliers detection process is summarized as follows :
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
The outliers detection process is summarized as follows :
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
-Step 2 : For each object , compute \MATH which is the number of neighboring objects lying within a distance \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
In our experiments , the distance between two objects is Euclidean distance between two faces and is computed in the eigen-subspace ( described in section \REF ) .
#<struct ReadData::Alignment source_numbers="19", target_numbers="10", tag_name="wa">
In our experiments , the distance between two objects is Euclidean distance between two faces and is computed in the eigen-subspace ( described in section \REF ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
-Step 1 : For each data object \MATH compute \MATH ( the distance to the \MATH nearest neighbor ) and \MATH ( all points in a \MATH sphere ) .
#<struct ReadData::Alignment source_numbers="14", target_numbers="9", tag_name="wa">
-Step 1 : For each data object \MATH compute \MATH ( the distance to the \MATH nearest neighbor ) and \MATH ( all points in a \MATH sphere ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
-Step 3 : Compute local reachability density of data object \MATH as inverse of the average reachability distance based on the \MATH ( minimum number of data objects ) nearest neighbors of data object \MATH .
#<struct ReadData::Alignment source_numbers="31", target_numbers="29", tag_name="wa">
-Step 3 : Compute local reachability density of data object \MATH as inverse of the average reachability distance based on the \MATH ( minimum number of data objects ) nearest neighbors of data object \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
-Step 4 : Compute LOF of data object \MATH as average of the ratios of the local reachability density of data object \MATH and local reachability density of \MATH nearest neighbors .
#<struct ReadData::Alignment source_numbers="15", target_numbers="10", tag_name="wa">
-Step 4 : Compute LOF of data object \MATH as average of the ratios of the local reachability density of data object \MATH and local reachability density of \MATH nearest neighbors .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
This dataset consists of approximately half a million news pictures and captions from Yahoo News over a period of roughly two years .
#<struct ReadData::Alignment source_numbers="2,3", target_numbers="2,3", tag_name="wa">
After eliminating faces whose facial features are poorly detected by a rectification process and faces whose associated names are not extracted properly from corresponding captions , 30 , 281 faces were kept .
#<struct ReadData::Alignment source_numbers="6", target_numbers="6", tag_name="wa">
After eliminating faces whose facial features are poorly detected by a rectification process and faces whose associated names are not extracted properly from corresponding captions , 30 , 281 faces were kept .
#<struct ReadData::Alignment source_numbers="8", target_numbers="8", tag_name="wa">
After eliminating faces whose facial features are poorly detected by a rectification process and faces whose associated names are not extracted properly from corresponding captions , 30 , 281 faces were kept .
#<struct ReadData::Alignment source_numbers="30", target_numbers="18", tag_name="wa">
After eliminating faces whose facial features are poorly detected by a rectification process and faces whose associated names are not extracted properly from corresponding captions , 30 , 281 faces were kept .
#<struct ReadData::Alignment source_numbers="20", target_numbers="20", tag_name="wa">
After eliminating faces whose facial features are poorly detected by a rectification process and faces whose associated names are not extracted properly from corresponding captions , 30 , 281 faces were kept .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
After eliminating faces whose facial features are poorly detected by a rectification process and faces whose associated names are not extracted properly from corresponding captions , 30 , 281 faces were kept .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
We selected sixteen celebrities who are government leaders such as George W . Bush ( US ) , Vladimir Putin ( Russia ) , Ziang Jemin ( China ) , Tony Blair ( UK ) , Junichiro Koizumi ( Japan ) , Roh Moo-hyun ( Korea ) , Abdullah Gul ( Turkey ) , and other key persons such as John Paul II ( the Former Pope ) , Kofi Annan and Hans Blix ( UN ) . These persons are selected since their appearances are highly frequent in the dataset \CITE .
#<struct ReadData::Alignment source_numbers="57", target_numbers="53", tag_name="wa">
We selected sixteen celebrities who are government leaders such as George W . Bush ( US ) , Vladimir Putin ( Russia ) , Ziang Jemin ( China ) , Tony Blair ( UK ) , Junichiro Koizumi ( Japan ) , Roh Moo-hyun ( Korea ) , Abdullah Gul ( Turkey ) , and other key persons such as John Paul II ( the Former Pope ) , Kofi Annan and Hans Blix ( UN ) . These persons are selected since their appearances are highly frequent in the dataset \CITE .
#<struct ReadData::Alignment source_numbers="71", target_numbers="64", tag_name="wa">
We selected sixteen celebrities who are government leaders such as George W . Bush ( US ) , Vladimir Putin ( Russia ) , Ziang Jemin ( China ) , Tony Blair ( UK ) , Junichiro Koizumi ( Japan ) , Roh Moo-hyun ( Korea ) , Abdullah Gul ( Turkey ) , and other key persons such as John Paul II ( the Former Pope ) , Kofi Annan and Hans Blix ( UN ) . These persons are selected since their appearances are highly frequent in the dataset \CITE .
#<struct ReadData::Alignment source_numbers="83", target_numbers="74", tag_name="wa">
We selected sixteen celebrities who are government leaders such as George W . Bush ( US ) , Vladimir Putin ( Russia ) , Ziang Jemin ( China ) , Tony Blair ( UK ) , Junichiro Koizumi ( Japan ) , Roh Moo-hyun ( Korea ) , Abdullah Gul ( Turkey ) , and other key persons such as John Paul II ( the Former Pope ) , Kofi Annan and Hans Blix ( UN ) . These persons are selected since their appearances are highly frequent in the dataset \CITE .
#<struct ReadData::Alignment source_numbers="84", target_numbers="76", tag_name="wa">
We selected sixteen celebrities who are government leaders such as George W . Bush ( US ) , Vladimir Putin ( Russia ) , Ziang Jemin ( China ) , Tony Blair ( UK ) , Junichiro Koizumi ( Japan ) , Roh Moo-hyun ( Korea ) , Abdullah Gul ( Turkey ) , and other key persons such as John Paul II ( the Former Pope ) , Kofi Annan and Hans Blix ( UN ) . These persons are selected since their appearances are highly frequent in the dataset \CITE .
#<struct ReadData::Alignment source_numbers="87,88", target_numbers="77,78", tag_name="wa">
We selected sixteen celebrities who are government leaders such as George W . Bush ( US ) , Vladimir Putin ( Russia ) , Ziang Jemin ( China ) , Tony Blair ( UK ) , Junichiro Koizumi ( Japan ) , Roh Moo-hyun ( Korea ) , Abdullah Gul ( Turkey ) , and other key persons such as John Paul II ( the Former Pope ) , Kofi Annan and Hans Blix ( UN ) . These persons are selected since their appearances are highly frequent in the dataset \CITE .
#<struct ReadData::Alignment source_numbers="92", target_numbers="82", tag_name="wa">
We selected sixteen celebrities who are government leaders such as George W . Bush ( US ) , Vladimir Putin ( Russia ) , Ziang Jemin ( China ) , Tony Blair ( UK ) , Junichiro Koizumi ( Japan ) , Roh Moo-hyun ( Korea ) , Abdullah Gul ( Turkey ) , and other key persons such as John Paul II ( the Former Pope ) , Kofi Annan and Hans Blix ( UN ) . These persons are selected since their appearances are highly frequent in the dataset \CITE .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
We selected sixteen celebrities who are government leaders such as George W . Bush ( US ) , Vladimir Putin ( Russia ) , Ziang Jemin ( China ) , Tony Blair ( UK ) , Junichiro Koizumi ( Japan ) , Roh Moo-hyun ( Korea ) , Abdullah Gul ( Turkey ) , and other key persons such as John Paul II ( the Former Pope ) , Kofi Annan and Hans Blix ( UN ) . These persons are selected since their appearances are highly frequent in the dataset \CITE .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
We selected sixteen celebrities who are government leaders such as George W . Bush ( US ) , Vladimir Putin ( Russia ) , Ziang Jemin ( China ) , Tony Blair ( UK ) , Junichiro Koizumi ( Japan ) , Roh Moo-hyun ( Korea ) , Abdullah Gul ( Turkey ) , and other key persons such as John Paul II ( the Former Pope ) , Kofi Annan and Hans Blix ( UN ) . These persons are selected since their appearances are highly frequent in the dataset \CITE .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
We selected sixteen celebrities who are government leaders such as George W . Bush ( US ) , Vladimir Putin ( Russia ) , Ziang Jemin ( China ) , Tony Blair ( UK ) , Junichiro Koizumi ( Japan ) , Roh Moo-hyun ( Korea ) , Abdullah Gul ( Turkey ) , and other key persons such as John Paul II ( the Former Pope ) , Kofi Annan and Hans Blix ( UN ) . These persons are selected since their appearances are highly frequent in the dataset \CITE .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
We selected sixteen celebrities who are government leaders such as George W . Bush ( US ) , Vladimir Putin ( Russia ) , Ziang Jemin ( China ) , Tony Blair ( UK ) , Junichiro Koizumi ( Japan ) , Roh Moo-hyun ( Korea ) , Abdullah Gul ( Turkey ) , and other key persons such as John Paul II ( the Former Pope ) , Kofi Annan and Hans Blix ( UN ) . These persons are selected since their appearances are highly frequent in the dataset \CITE .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
We selected sixteen celebrities who are government leaders such as George W . Bush ( US ) , Vladimir Putin ( Russia ) , Ziang Jemin ( China ) , Tony Blair ( UK ) , Junichiro Koizumi ( Japan ) , Roh Moo-hyun ( Korea ) , Abdullah Gul ( Turkey ) , and other key persons such as John Paul II ( the Former Pope ) , Kofi Annan and Hans Blix ( UN ) . These persons are selected since their appearances are highly frequent in the dataset \CITE .
#<struct ReadData::Alignment source_numbers="68", target_numbers="", tag_name="wa">
We selected sixteen celebrities who are government leaders such as George W . Bush ( US ) , Vladimir Putin ( Russia ) , Ziang Jemin ( China ) , Tony Blair ( UK ) , Junichiro Koizumi ( Japan ) , Roh Moo-hyun ( Korea ) , Abdullah Gul ( Turkey ) , and other key persons such as John Paul II ( the Former Pope ) , Kofi Annan and Hans Blix ( UN ) . These persons are selected since their appearances are highly frequent in the dataset \CITE .
#<struct ReadData::Alignment source_numbers="77", target_numbers="", tag_name="wa">
We selected sixteen celebrities who are government leaders such as George W . Bush ( US ) , Vladimir Putin ( Russia ) , Ziang Jemin ( China ) , Tony Blair ( UK ) , Junichiro Koizumi ( Japan ) , Roh Moo-hyun ( Korea ) , Abdullah Gul ( Turkey ) , and other key persons such as John Paul II ( the Former Pope ) , Kofi Annan and Hans Blix ( UN ) . These persons are selected since their appearances are highly frequent in the dataset \CITE .
#<struct ReadData::Alignment source_numbers="78", target_numbers="", tag_name="wa">
We selected sixteen celebrities who are government leaders such as George W . Bush ( US ) , Vladimir Putin ( Russia ) , Ziang Jemin ( China ) , Tony Blair ( UK ) , Junichiro Koizumi ( Japan ) , Roh Moo-hyun ( Korea ) , Abdullah Gul ( Turkey ) , and other key persons such as John Paul II ( the Former Pope ) , Kofi Annan and Hans Blix ( UN ) . These persons are selected since their appearances are highly frequent in the dataset \CITE .
#<struct ReadData::Alignment source_numbers="79", target_numbers="", tag_name="wa">
We selected sixteen celebrities who are government leaders such as George W . Bush ( US ) , Vladimir Putin ( Russia ) , Ziang Jemin ( China ) , Tony Blair ( UK ) , Junichiro Koizumi ( Japan ) , Roh Moo-hyun ( Korea ) , Abdullah Gul ( Turkey ) , and other key persons such as John Paul II ( the Former Pope ) , Kofi Annan and Hans Blix ( UN ) . These persons are selected since their appearances are highly frequent in the dataset \CITE .
#<struct ReadData::Alignment source_numbers="80", target_numbers="", tag_name="wa">
We selected sixteen celebrities who are government leaders such as George W . Bush ( US ) , Vladimir Putin ( Russia ) , Ziang Jemin ( China ) , Tony Blair ( UK ) , Junichiro Koizumi ( Japan ) , Roh Moo-hyun ( Korea ) , Abdullah Gul ( Turkey ) , and other key persons such as John Paul II ( the Former Pope ) , Kofi Annan and Hans Blix ( UN ) . These persons are selected since their appearances are highly frequent in the dataset \CITE .
#<struct ReadData::Alignment source_numbers="81", target_numbers="", tag_name="wa">
We selected sixteen celebrities who are government leaders such as George W . Bush ( US ) , Vladimir Putin ( Russia ) , Ziang Jemin ( China ) , Tony Blair ( UK ) , Junichiro Koizumi ( Japan ) , Roh Moo-hyun ( Korea ) , Abdullah Gul ( Turkey ) , and other key persons such as John Paul II ( the Former Pope ) , Kofi Annan and Hans Blix ( UN ) . These persons are selected since their appearances are highly frequent in the dataset \CITE .
#<struct ReadData::Alignment source_numbers="85", target_numbers="", tag_name="wa">
We selected sixteen celebrities who are government leaders such as George W . Bush ( US ) , Vladimir Putin ( Russia ) , Ziang Jemin ( China ) , Tony Blair ( UK ) , Junichiro Koizumi ( Japan ) , Roh Moo-hyun ( Korea ) , Abdullah Gul ( Turkey ) , and other key persons such as John Paul II ( the Former Pope ) , Kofi Annan and Hans Blix ( UN ) . These persons are selected since their appearances are highly frequent in the dataset \CITE .
#<struct ReadData::Alignment source_numbers="86", target_numbers="", tag_name="wa">
We selected sixteen celebrities who are government leaders such as George W . Bush ( US ) , Vladimir Putin ( Russia ) , Ziang Jemin ( China ) , Tony Blair ( UK ) , Junichiro Koizumi ( Japan ) , Roh Moo-hyun ( Korea ) , Abdullah Gul ( Turkey ) , and other key persons such as John Paul II ( the Former Pope ) , Kofi Annan and Hans Blix ( UN ) . These persons are selected since their appearances are highly frequent in the dataset \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
We selected sixteen celebrities who are government leaders such as George W . Bush ( US ) , Vladimir Putin ( Russia ) , Ziang Jemin ( China ) , Tony Blair ( UK ) , Junichiro Koizumi ( Japan ) , Roh Moo-hyun ( Korea ) , Abdullah Gul ( Turkey ) , and other key persons such as John Paul II ( the Former Pope ) , Kofi Annan and Hans Blix ( UN ) . These persons are selected since their appearances are highly frequent in the dataset \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="67", tag_name="wa">
We selected sixteen celebrities who are government leaders such as George W . Bush ( US ) , Vladimir Putin ( Russia ) , Ziang Jemin ( China ) , Tony Blair ( UK ) , Junichiro Koizumi ( Japan ) , Roh Moo-hyun ( Korea ) , Abdullah Gul ( Turkey ) , and other key persons such as John Paul II ( the Former Pope ) , Kofi Annan and Hans Blix ( UN ) . These persons are selected since their appearances are highly frequent in the dataset \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="75", tag_name="wa">
For each person , variations of his name are collected . For example , George W . Bush , President Bush , U . S . President , etc are variations of U . S . President Bush .
#<struct ReadData::Alignment source_numbers="8,9", target_numbers="8,9", tag_name="wa">
On average , the precision is 52.49% .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
On average , the precision is 52.49% .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
On average , the precision is 52.49% .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
On average , the precision is 52.49% .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
On average , the precision is 52.49% .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
To compensate for illumination effects , the subtraction of the bestfit brightness plane followed by histogram equalization was applied .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
To compensate for illumination effects , the subtraction of the bestfit brightness plane followed by histogram equalization was applied .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
We then used PCA \CITE to reduce the number of dimensions of the feature vector for face representation .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
We then used PCA \CITE to reduce the number of dimensions of the feature vector for face representation .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
We then used PCA \CITE to reduce the number of dimensions of the feature vector for face representation .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
We then used PCA \CITE to reduce the number of dimensions of the feature vector for face representation .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Eigenfaces were computed from the original face set returned by the text based query method .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
Eigenfaces were computed from the original face set returned by the text based query method .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
Eigenfaces were computed from the original face set returned by the text based query method .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
The number of eigenfaces was selected so that 97% of the total energy are retained \CITE .
#<struct ReadData::Alignment source_numbers="13", target_numbers="13", tag_name="wa">
The number of eigenfaces was selected so that 97% of the total energy are retained \CITE .
#<struct ReadData::Alignment source_numbers="14", target_numbers="14", tag_name="wa">
The number of eigenfaces was selected so that 97% of the total energy are retained \CITE .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
The number of eigenfaces was selected so that 97% of the total energy are retained \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
The number of eigenfaces was selected so that 97% of the total energy are retained \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
The number of eigenfaces was selected so that 97% of the total energy are retained \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
The number of eigenfaces was selected so that 97% of the total energy are retained \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
The number of eigenfaces was selected so that 97% of the total energy are retained \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
The number of eigenfaces was selected so that 97% of the total energy are retained \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
The number of eigenfaces was selected so that 97% of the total energy are retained \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
We evaluated the retrieval performance with measures that are popularly used in information retrieval such as precision , recall and average precision .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
Given a queried person , assuming that \MATH is the total number of faces returned , \MATH is the number of relevant faces , \MATH is the number of relevant faces , we calculate recall and precision as follows :
#<struct ReadData::Alignment source_numbers="18,19,20", target_numbers="9,10,11,12", tag_name="wa">
Given a queried person , assuming that \MATH is the total number of faces returned , \MATH is the number of relevant faces , \MATH is the number of relevant faces , we calculate recall and precision as follows :
#<struct ReadData::Alignment source_numbers="9,10,11,12", target_numbers="18,19,20", tag_name="wa">
Given a queried person , assuming that \MATH is the total number of faces returned , \MATH is the number of relevant faces , \MATH is the number of relevant faces , we calculate recall and precision as follows :
#<struct ReadData::Alignment source_numbers="", target_numbers="40", tag_name="wa">
Given a queried person , assuming that \MATH is the total number of faces returned , \MATH is the number of relevant faces , \MATH is the number of relevant faces , we calculate recall and precision as follows :
#<struct ReadData::Alignment source_numbers="", target_numbers="41", tag_name="wa">
Given a queried person , assuming that \MATH is the total number of faces returned , \MATH is the number of relevant faces , \MATH is the number of relevant faces , we calculate recall and precision as follows :
#<struct ReadData::Alignment source_numbers="", target_numbers="42", tag_name="wa">
Given a queried person , assuming that \MATH is the total number of faces returned , \MATH is the number of relevant faces , \MATH is the number of relevant faces , we calculate recall and precision as follows :
#<struct ReadData::Alignment source_numbers="", target_numbers="43", tag_name="wa">
Given a queried person , assuming that \MATH is the total number of faces returned , \MATH is the number of relevant faces , \MATH is the number of relevant faces , we calculate recall and precision as follows :
#<struct ReadData::Alignment source_numbers="", target_numbers="44", tag_name="wa">
Given a queried person , assuming that \MATH is the total number of faces returned , \MATH is the number of relevant faces , \MATH is the number of relevant faces , we calculate recall and precision as follows :
#<struct ReadData::Alignment source_numbers="", target_numbers="45", tag_name="wa">
Given a queried person , assuming that \MATH is the total number of faces returned , \MATH is the number of relevant faces , \MATH is the number of relevant faces , we calculate recall and precision as follows :
#<struct ReadData::Alignment source_numbers="", target_numbers="46", tag_name="wa">
Given a queried person , assuming that \MATH is the total number of faces returned , \MATH is the number of relevant faces , \MATH is the number of relevant faces , we calculate recall and precision as follows :
#<struct ReadData::Alignment source_numbers="", target_numbers="47", tag_name="wa">
Given a queried person , assuming that \MATH is the total number of faces returned , \MATH is the number of relevant faces , \MATH is the number of relevant faces , we calculate recall and precision as follows :
#<struct ReadData::Alignment source_numbers="", target_numbers="48", tag_name="wa">
Given a queried person , assuming that \MATH is the total number of faces returned , \MATH is the number of relevant faces , \MATH is the number of relevant faces , we calculate recall and precision as follows :
#<struct ReadData::Alignment source_numbers="", target_numbers="49", tag_name="wa">
Given a queried person , assuming that \MATH is the total number of faces returned , \MATH is the number of relevant faces , \MATH is the number of relevant faces , we calculate recall and precision as follows :
#<struct ReadData::Alignment source_numbers="", target_numbers="50", tag_name="wa">
Given a queried person , assuming that \MATH is the total number of faces returned , \MATH is the number of relevant faces , \MATH is the number of relevant faces , we calculate recall and precision as follows :
#<struct ReadData::Alignment source_numbers="", target_numbers="51", tag_name="wa">
Given a queried person , assuming that \MATH is the total number of faces returned , \MATH is the number of relevant faces , \MATH is the number of relevant faces , we calculate recall and precision as follows :
#<struct ReadData::Alignment source_numbers="", target_numbers="52", tag_name="wa">
Given a queried person , assuming that \MATH is the total number of faces returned , \MATH is the number of relevant faces , \MATH is the number of relevant faces , we calculate recall and precision as follows :
#<struct ReadData::Alignment source_numbers="", target_numbers="53", tag_name="wa">
In addition , to evaluate performance of multiple queries , we used mean average precision that is the mean of average precisions computed from queries .
#<struct ReadData::Alignment source_numbers="17", target_numbers="5", tag_name="wa">
In addition , to evaluate performance of multiple queries , we used mean average precision that is the mean of average precisions computed from queries .
#<struct ReadData::Alignment source_numbers="15,16", target_numbers="17,18", tag_name="wa">
In addition , to evaluate performance of multiple queries , we used mean average precision that is the mean of average precisions computed from queries .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
In addition , to evaluate performance of multiple queries , we used mean average precision that is the mean of average precisions computed from queries .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
In the baseline method , faces are sorted by the time that the associated news article is published .
#<struct ReadData::Alignment source_numbers="6", target_numbers="6", tag_name="wa">
In the baseline method , faces are sorted by the time that the associated news article is published .
#<struct ReadData::Alignment source_numbers="7", target_numbers="7", tag_name="wa">
In the baseline method , faces are sorted by the time that the associated news article is published .
#<struct ReadData::Alignment source_numbers="16", target_numbers="15", tag_name="wa">
In the baseline method , faces are sorted by the time that the associated news article is published .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
It indicates that DBO-based method outperforms the others .
#<struct ReadData::Alignment source_numbers="1,2", target_numbers="1,2", tag_name="wa">
This suggests that the input face sets are quite dense .
#<struct ReadData::Alignment source_numbers="7,8", target_numbers="7,8", tag_name="wa">
We studied effect of choosing number of times \MATH in the Bag-Rank-SVM algorithm .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
The subsets \MATH and \MATH are generated by randomly selecting with replacement 70% samples of \MATH amd \MATH .
#<struct ReadData::Alignment source_numbers="18", target_numbers="25", tag_name="wa">
The subsets \MATH and \MATH are generated by randomly selecting with replacement 70% samples of \MATH amd \MATH .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
The subsets \MATH and \MATH are generated by randomly selecting with replacement 70% samples of \MATH amd \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
The subsets \MATH and \MATH are generated by randomly selecting with replacement 70% samples of \MATH amd \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
The subsets \MATH and \MATH are generated by randomly selecting with replacement 70% samples of \MATH amd \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
The subsets \MATH and \MATH are generated by randomly selecting with replacement 70% samples of \MATH amd \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
The subsets \MATH and \MATH are generated by randomly selecting with replacement 70% samples of \MATH amd \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
The subsets \MATH and \MATH are generated by randomly selecting with replacement 70% samples of \MATH amd \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
The subsets \MATH and \MATH are generated by randomly selecting with replacement 70% samples of \MATH amd \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
The subsets \MATH and \MATH are generated by randomly selecting with replacement 70% samples of \MATH amd \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
The subsets \MATH and \MATH are generated by randomly selecting with replacement 70% samples of \MATH amd \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
The subsets \MATH and \MATH are generated by randomly selecting with replacement 70% samples of \MATH amd \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
The subsets \MATH and \MATH are generated by randomly selecting with replacement 70% samples of \MATH amd \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
The subsets \MATH and \MATH are generated by randomly selecting with replacement 70% samples of \MATH amd \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
The subsets \MATH and \MATH are generated by randomly selecting with replacement 70% samples of \MATH amd \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
The subsets \MATH and \MATH are generated by randomly selecting with replacement 70% samples of \MATH amd \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
The subsets \MATH and \MATH are generated by randomly selecting with replacement 70% samples of \MATH amd \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
The subsets \MATH and \MATH are generated by randomly selecting with replacement 70% samples of \MATH amd \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
The subsets \MATH and \MATH are generated by randomly selecting with replacement 70% samples of \MATH amd \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
The subsets \MATH and \MATH are generated by randomly selecting with replacement 70% samples of \MATH amd \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
Figure \REF shows performance of single classifiers and ensemble classifiers .
#<struct ReadData::Alignment source_numbers="9", target_numbers="9", tag_name="wa">
Figure \REF shows performance of single classifiers and ensemble classifiers .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
In addition , the performance of the ranking process is improved when using the ensemble classifier .
#<struct ReadData::Alignment source_numbers="10", target_numbers="9", tag_name="wa">
In addition , the performance of the ranking process is improved when using the ensemble classifier .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
In addition , the performance of the ranking process is improved when using the ensemble classifier .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
In addition , the performance of the ranking process is improved when using the ensemble classifier .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
In addition , the performance of the ranking process is improved when using the ensemble classifier .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
We set the number of iterations for the Bag-Rank-SVM algorithm being 5 and set the number of iterations of the outer loop $T=30$ to see how much the final performance changes .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
We set the number of iterations for the Bag-Rank-SVM algorithm being 5 and set the number of iterations of the outer loop $T=30$ to see how much the final performance changes .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
As shown in Figure \REF , the performance does not change so much after 5 iterations .
#<struct ReadData::Alignment source_numbers="10", target_numbers="10", tag_name="wa">
As shown in Figure \REF , the performance does not change so much after 5 iterations .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
As shown in Figure \REF , the performance does not change so much after 5 iterations .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
As shown in Figure \REF , the performance does not change so much after 5 iterations .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
The performance of different methods shown in Figure \REF indicates that our proposed method outperforms the distance-based outliers detection method and has comparable performance with the supervised method using 5% annotation data .
#<struct ReadData::Alignment source_numbers="21", target_numbers="21", tag_name="wa">
The performance of different methods shown in Figure \REF indicates that our proposed method outperforms the distance-based outliers detection method and has comparable performance with the supervised method using 5% annotation data .
#<struct ReadData::Alignment source_numbers="22", target_numbers="22", tag_name="wa">
The performance of different methods shown in Figure \REF indicates that our proposed method outperforms the distance-based outliers detection method and has comparable performance with the supervised method using 5% annotation data .
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
The performance of different methods shown in Figure \REF indicates that our proposed method outperforms the distance-based outliers detection method and has comparable performance with the supervised method using 5% annotation data .
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
The performance of different methods shown in Figure \REF indicates that our proposed method outperforms the distance-based outliers detection method and has comparable performance with the supervised method using 5% annotation data .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
As shown in Figure \REF , \REF , \REF , our proposed method produces better results in terms of average precision in which relevant faces are put on the top of the returned list .
#<struct ReadData::Alignment source_numbers="25", target_numbers="25", tag_name="wa">
As shown in Figure \REF , \REF , \REF , our proposed method produces better results in terms of average precision in which relevant faces are put on the top of the returned list .
#<struct ReadData::Alignment source_numbers="26", target_numbers="26", tag_name="wa">
As shown in Figure \REF , \REF , \REF , our proposed method produces better results in terms of average precision in which relevant faces are put on the top of the returned list .
#<struct ReadData::Alignment source_numbers="27", target_numbers="", tag_name="wa">
As shown in Figure \REF , \REF , \REF , our proposed method produces better results in terms of average precision in which relevant faces are put on the top of the returned list .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
We present a method to effectively rank faces retrieved by text-based correlation methods when searching a specific person .
#<struct ReadData::Alignment source_numbers="3,4", target_numbers="3,4", tag_name="wa">
We present a method to effectively rank faces retrieved by text-based correlation methods when searching a specific person .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
We present a method to effectively rank faces retrieved by text-based correlation methods when searching a specific person .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Using the rank list estimated from the previous steps , we automatically select a subset of positive and negative samples to train a classifier using SVM with probability outputs .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
Using the rank list estimated from the previous steps , we automatically select a subset of positive and negative samples to train a classifier using SVM with probability outputs .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
Using the rank list estimated from the previous steps , we automatically select a subset of positive and negative samples to train a classifier using SVM with probability outputs .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
Using the rank list estimated from the previous steps , we automatically select a subset of positive and negative samples to train a classifier using SVM with probability outputs .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
Using the rank list estimated from the previous steps , we automatically select a subset of positive and negative samples to train a classifier using SVM with probability outputs .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
Using the rank list estimated from the previous steps , we automatically select a subset of positive and negative samples to train a classifier using SVM with probability outputs .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
Using the rank list estimated from the previous steps , we automatically select a subset of positive and negative samples to train a classifier using SVM with probability outputs .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
Using the rank list estimated from the previous steps , we automatically select a subset of positive and negative samples to train a classifier using SVM with probability outputs .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
Using the rank list estimated from the previous steps , we automatically select a subset of positive and negative samples to train a classifier using SVM with probability outputs .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
Using the rank list estimated from the previous steps , we automatically select a subset of positive and negative samples to train a classifier using SVM with probability outputs .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
Using the rank list estimated from the previous steps , we automatically select a subset of positive and negative samples to train a classifier using SVM with probability outputs .
#<struct ReadData::Alignment source_numbers="", target_numbers="40", tag_name="wa">
Using the rank list estimated from the previous steps , we automatically select a subset of positive and negative samples to train a classifier using SVM with probability outputs .
#<struct ReadData::Alignment source_numbers="", target_numbers="41", tag_name="wa">
Using the rank list estimated from the previous steps , we automatically select a subset of positive and negative samples to train a classifier using SVM with probability outputs .
#<struct ReadData::Alignment source_numbers="", target_numbers="42", tag_name="wa">
Using the rank list estimated from the previous steps , we automatically select a subset of positive and negative samples to train a classifier using SVM with probability outputs .
#<struct ReadData::Alignment source_numbers="", target_numbers="43", tag_name="wa">
Using the rank list estimated from the previous steps , we automatically select a subset of positive and negative samples to train a classifier using SVM with probability outputs .
#<struct ReadData::Alignment source_numbers="", target_numbers="44", tag_name="wa">
Using the rank list estimated from the previous steps , we automatically select a subset of positive and negative samples to train a classifier using SVM with probability outputs .
#<struct ReadData::Alignment source_numbers="", target_numbers="45", tag_name="wa">
Using the rank list estimated from the previous steps , we automatically select a subset of positive and negative samples to train a classifier using SVM with probability outputs .
#<struct ReadData::Alignment source_numbers="", target_numbers="46", tag_name="wa">
Using the rank list estimated from the previous steps , we automatically select a subset of positive and negative samples to train a classifier using SVM with probability outputs .
#<struct ReadData::Alignment source_numbers="", target_numbers="47", tag_name="wa">
Using the rank list estimated from the previous steps , we automatically select a subset of positive and negative samples to train a classifier using SVM with probability outputs .
#<struct ReadData::Alignment source_numbers="", target_numbers="48", tag_name="wa">
Using the rank list estimated from the previous steps , we automatically select a subset of positive and negative samples to train a classifier using SVM with probability outputs .
#<struct ReadData::Alignment source_numbers="", target_numbers="49", tag_name="wa">
Using the rank list estimated from the previous steps , we automatically select a subset of positive and negative samples to train a classifier using SVM with probability outputs .
#<struct ReadData::Alignment source_numbers="", target_numbers="50", tag_name="wa">
Since labels of training sets are still noisy , the classified trained by these datasets are weak .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
Since labels of training sets are still noisy , the classified trained by these datasets are weak .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
By combining multiple weak classifiers in a bagging framework , the final strong classifier is constructed and produce good results .
#<struct ReadData::Alignment source_numbers="15", target_numbers="11", tag_name="wa">
By combining multiple weak classifiers in a bagging framework , the final strong classifier is constructed and produce good results .
#<struct ReadData::Alignment source_numbers="17", target_numbers="18", tag_name="wa">
By combining multiple weak classifiers in a bagging framework , the final strong classifier is constructed and produce good results .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
By combining multiple weak classifiers in a bagging framework , the final strong classifier is constructed and produce good results .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
By combining multiple weak classifiers in a bagging framework , the final strong classifier is constructed and produce good results .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
By combining multiple weak classifiers in a bagging framework , the final strong classifier is constructed and produce good results .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
By combining multiple weak classifiers in a bagging framework , the final strong classifier is constructed and produce good results .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
To get initial rank for the first step , we propose to use common outliers detection method .
#<struct ReadData::Alignment source_numbers="10,11", target_numbers="11", tag_name="wa">
To get initial rank for the first step , we propose to use common outliers detection method .
#<struct ReadData::Alignment source_numbers="12", target_numbers="12", tag_name="wa">
Human face processing techniques for broadcast video including face detection , tracking and recognition have long been a topic that attracts much research interest due to its crucial value in various applications including video structuring , indexing , retrieval , summarization , etc.
#<struct ReadData::Alignment source_numbers="35", target_numbers="7", tag_name="wa">
Human face processing techniques for broadcast video including face detection , tracking and recognition have long been a topic that attracts much research interest due to its crucial value in various applications including video structuring , indexing , retrieval , summarization , etc.
#<struct ReadData::Alignment source_numbers="37", target_numbers="13", tag_name="wa">
Human face processing techniques for broadcast video including face detection , tracking and recognition have long been a topic that attracts much research interest due to its crucial value in various applications including video structuring , indexing , retrieval , summarization , etc.
#<struct ReadData::Alignment source_numbers="39", target_numbers="16", tag_name="wa">
Human face processing techniques for broadcast video including face detection , tracking and recognition have long been a topic that attracts much research interest due to its crucial value in various applications including video structuring , indexing , retrieval , summarization , etc.
#<struct ReadData::Alignment source_numbers="20", target_numbers="24", tag_name="wa">
Human face processing techniques for broadcast video including face detection , tracking and recognition have long been a topic that attracts much research interest due to its crucial value in various applications including video structuring , indexing , retrieval , summarization , etc.
#<struct ReadData::Alignment source_numbers="41", target_numbers="38", tag_name="wa">
Human face processing techniques for broadcast video including face detection , tracking and recognition have long been a topic that attracts much research interest due to its crucial value in various applications including video structuring , indexing , retrieval , summarization , etc.
#<struct ReadData::Alignment source_numbers="32", target_numbers="", tag_name="wa">
Human face processing techniques for broadcast video including face detection , tracking and recognition have long been a topic that attracts much research interest due to its crucial value in various applications including video structuring , indexing , retrieval , summarization , etc.
#<struct ReadData::Alignment source_numbers="42", target_numbers="", tag_name="wa">
Human face processing techniques for broadcast video including face detection , tracking and recognition have long been a topic that attracts much research interest due to its crucial value in various applications including video structuring , indexing , retrieval , summarization , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
Human face processing techniques for broadcast video including face detection , tracking and recognition have long been a topic that attracts much research interest due to its crucial value in various applications including video structuring , indexing , retrieval , summarization , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
Human face processing techniques for broadcast video including face detection , tracking and recognition have long been a topic that attracts much research interest due to its crucial value in various applications including video structuring , indexing , retrieval , summarization , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="40", tag_name="wa">
Human face processing techniques for broadcast video including face detection , tracking and recognition have long been a topic that attracts much research interest due to its crucial value in various applications including video structuring , indexing , retrieval , summarization , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="44", tag_name="wa">
Human face processing techniques for broadcast video including face detection , tracking and recognition have long been a topic that attracts much research interest due to its crucial value in various applications including video structuring , indexing , retrieval , summarization , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="46", tag_name="wa">
Human face processing techniques for broadcast video including face detection , tracking and recognition have long been a topic that attracts much research interest due to its crucial value in various applications including video structuring , indexing , retrieval , summarization , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="48", tag_name="wa">
Human face processing techniques for broadcast video including face detection , tracking and recognition have long been a topic that attracts much research interest due to its crucial value in various applications including video structuring , indexing , retrieval , summarization , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="49", tag_name="wa">
Human face processing techniques for broadcast video including face detection , tracking and recognition have long been a topic that attracts much research interest due to its crucial value in various applications including video structuring , indexing , retrieval , summarization , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="51", tag_name="wa">
The main reason is human face provides rich information for people 's appearance such as a government leader in a news video , a pitcher in a sport video or a hero in a movie , and is the basis for interpreting facts .
#<struct ReadData::Alignment source_numbers="40", target_numbers="3", tag_name="wa">
The main reason is human face provides rich information for people 's appearance such as a government leader in a news video , a pitcher in a sport video or a hero in a movie , and is the basis for interpreting facts .
#<struct ReadData::Alignment source_numbers="38", target_numbers="7", tag_name="wa">
The main reason is human face provides rich information for people 's appearance such as a government leader in a news video , a pitcher in a sport video or a hero in a movie , and is the basis for interpreting facts .
#<struct ReadData::Alignment source_numbers="35", target_numbers="17", tag_name="wa">
The main reason is human face provides rich information for people 's appearance such as a government leader in a news video , a pitcher in a sport video or a hero in a movie , and is the basis for interpreting facts .
#<struct ReadData::Alignment source_numbers="16", target_numbers="22", tag_name="wa">
The main reason is human face provides rich information for people 's appearance such as a government leader in a news video , a pitcher in a sport video or a hero in a movie , and is the basis for interpreting facts .
#<struct ReadData::Alignment source_numbers="17", target_numbers="23", tag_name="wa">
The main reason is human face provides rich information for people 's appearance such as a government leader in a news video , a pitcher in a sport video or a hero in a movie , and is the basis for interpreting facts .
#<struct ReadData::Alignment source_numbers="18", target_numbers="24", tag_name="wa">
The main reason is human face provides rich information for people 's appearance such as a government leader in a news video , a pitcher in a sport video or a hero in a movie , and is the basis for interpreting facts .
#<struct ReadData::Alignment source_numbers="19", target_numbers="25", tag_name="wa">
The main reason is human face provides rich information for people 's appearance such as a government leader in a news video , a pitcher in a sport video or a hero in a movie , and is the basis for interpreting facts .
#<struct ReadData::Alignment source_numbers="20", target_numbers="26", tag_name="wa">
The main reason is human face provides rich information for people 's appearance such as a government leader in a news video , a pitcher in a sport video or a hero in a movie , and is the basis for interpreting facts .
#<struct ReadData::Alignment source_numbers="21", target_numbers="27", tag_name="wa">
The main reason is human face provides rich information for people 's appearance such as a government leader in a news video , a pitcher in a sport video or a hero in a movie , and is the basis for interpreting facts .
#<struct ReadData::Alignment source_numbers="22", target_numbers="28", tag_name="wa">
The main reason is human face provides rich information for people 's appearance such as a government leader in a news video , a pitcher in a sport video or a hero in a movie , and is the basis for interpreting facts .
#<struct ReadData::Alignment source_numbers="23", target_numbers="29", tag_name="wa">
The main reason is human face provides rich information for people 's appearance such as a government leader in a news video , a pitcher in a sport video or a hero in a movie , and is the basis for interpreting facts .
#<struct ReadData::Alignment source_numbers="24", target_numbers="30", tag_name="wa">
The main reason is human face provides rich information for people 's appearance such as a government leader in a news video , a pitcher in a sport video or a hero in a movie , and is the basis for interpreting facts .
#<struct ReadData::Alignment source_numbers="25", target_numbers="31", tag_name="wa">
The main reason is human face provides rich information for people 's appearance such as a government leader in a news video , a pitcher in a sport video or a hero in a movie , and is the basis for interpreting facts .
#<struct ReadData::Alignment source_numbers="26", target_numbers="32", tag_name="wa">
The main reason is human face provides rich information for people 's appearance such as a government leader in a news video , a pitcher in a sport video or a hero in a movie , and is the basis for interpreting facts .
#<struct ReadData::Alignment source_numbers="27", target_numbers="33", tag_name="wa">
The main reason is human face provides rich information for people 's appearance such as a government leader in a news video , a pitcher in a sport video or a hero in a movie , and is the basis for interpreting facts .
#<struct ReadData::Alignment source_numbers="28", target_numbers="34", tag_name="wa">
The main reason is human face provides rich information for people 's appearance such as a government leader in a news video , a pitcher in a sport video or a hero in a movie , and is the basis for interpreting facts .
#<struct ReadData::Alignment source_numbers="29", target_numbers="35", tag_name="wa">
The main reason is human face provides rich information for people 's appearance such as a government leader in a news video , a pitcher in a sport video or a hero in a movie , and is the basis for interpreting facts .
#<struct ReadData::Alignment source_numbers="30", target_numbers="36", tag_name="wa">
The main reason is human face provides rich information for people 's appearance such as a government leader in a news video , a pitcher in a sport video or a hero in a movie , and is the basis for interpreting facts .
#<struct ReadData::Alignment source_numbers="31", target_numbers="37", tag_name="wa">
The main reason is human face provides rich information for people 's appearance such as a government leader in a news video , a pitcher in a sport video or a hero in a movie , and is the basis for interpreting facts .
#<struct ReadData::Alignment source_numbers="32", target_numbers="38", tag_name="wa">
The main reason is human face provides rich information for people 's appearance such as a government leader in a news video , a pitcher in a sport video or a hero in a movie , and is the basis for interpreting facts .
#<struct ReadData::Alignment source_numbers="33", target_numbers="39", tag_name="wa">
The main reason is human face provides rich information for people 's appearance such as a government leader in a news video , a pitcher in a sport video or a hero in a movie , and is the basis for interpreting facts .
#<struct ReadData::Alignment source_numbers="34", target_numbers="40", tag_name="wa">
The main reason is human face provides rich information for people 's appearance such as a government leader in a news video , a pitcher in a sport video or a hero in a movie , and is the basis for interpreting facts .
#<struct ReadData::Alignment source_numbers="36", target_numbers="42", tag_name="wa">
The main reason is human face provides rich information for people 's appearance such as a government leader in a news video , a pitcher in a sport video or a hero in a movie , and is the basis for interpreting facts .
#<struct ReadData::Alignment source_numbers="37", target_numbers="43", tag_name="wa">
The main reason is human face provides rich information for people 's appearance such as a government leader in a news video , a pitcher in a sport video or a hero in a movie , and is the basis for interpreting facts .
#<struct ReadData::Alignment source_numbers="39", target_numbers="45", tag_name="wa">
The main reason is human face provides rich information for people 's appearance such as a government leader in a news video , a pitcher in a sport video or a hero in a movie , and is the basis for interpreting facts .
#<struct ReadData::Alignment source_numbers="41", target_numbers="47", tag_name="wa">
The main reason is human face provides rich information for people 's appearance such as a government leader in a news video , a pitcher in a sport video or a hero in a movie , and is the basis for interpreting facts .
#<struct ReadData::Alignment source_numbers="42", target_numbers="48", tag_name="wa">
The main reason is human face provides rich information for people 's appearance such as a government leader in a news video , a pitcher in a sport video or a hero in a movie , and is the basis for interpreting facts .
#<struct ReadData::Alignment source_numbers="43", target_numbers="49", tag_name="wa">
The main reason is human face provides rich information for people 's appearance such as a government leader in a news video , a pitcher in a sport video or a hero in a movie , and is the basis for interpreting facts .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
The main reason is human face provides rich information for people 's appearance such as a government leader in a news video , a pitcher in a sport video or a hero in a movie , and is the basis for interpreting facts .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
The main reason is human face provides rich information for people 's appearance such as a government leader in a news video , a pitcher in a sport video or a hero in a movie , and is the basis for interpreting facts .
#<struct ReadData::Alignment source_numbers="", target_numbers="41", tag_name="wa">
The main reason is human face provides rich information for people 's appearance such as a government leader in a news video , a pitcher in a sport video or a hero in a movie , and is the basis for interpreting facts .
#<struct ReadData::Alignment source_numbers="", target_numbers="44", tag_name="wa">
The main reason is human face provides rich information for people 's appearance such as a government leader in a news video , a pitcher in a sport video or a hero in a movie , and is the basis for interpreting facts .
#<struct ReadData::Alignment source_numbers="", target_numbers="46", tag_name="wa">
This article describes state-of-the art techniques for face detection , tracking and recognition with application to broadcast video .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
This article describes state-of-the art techniques for face detection , tracking and recognition with application to broadcast video .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
Face detection which is the task of localizing faces in an input image is fundamental for any face processing system .
#<struct ReadData::Alignment source_numbers="20", target_numbers="24", tag_name="wa">
Face detection which is the task of localizing faces in an input image is fundamental for any face processing system .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
Face detection which is the task of localizing faces in an input image is fundamental for any face processing system .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Face detection which is the task of localizing faces in an input image is fundamental for any face processing system .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Face detection which is the task of localizing faces in an input image is fundamental for any face processing system .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
Face detection which is the task of localizing faces in an input image is fundamental for any face processing system .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
Face detection which is the task of localizing faces in an input image is fundamental for any face processing system .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
- Robustness : it should be capable of handling appearance variations of pose changes , size , illuminations , occlusions , complex background , facial expressions , low resolutions , etc.
#<struct ReadData::Alignment source_numbers="29", target_numbers="11", tag_name="wa">
- Robustness : it should be capable of handling appearance variations of pose changes , size , illuminations , occlusions , complex background , facial expressions , low resolutions , etc.
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
- Robustness : it should be capable of handling appearance variations of pose changes , size , illuminations , occlusions , complex background , facial expressions , low resolutions , etc.
#<struct ReadData::Alignment source_numbers="30", target_numbers="", tag_name="wa">
- Robustness : it should be capable of handling appearance variations of pose changes , size , illuminations , occlusions , complex background , facial expressions , low resolutions , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
- Robustness : it should be capable of handling appearance variations of pose changes , size , illuminations , occlusions , complex background , facial expressions , low resolutions , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
- Robustness : it should be capable of handling appearance variations of pose changes , size , illuminations , occlusions , complex background , facial expressions , low resolutions , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
- Robustness : it should be capable of handling appearance variations of pose changes , size , illuminations , occlusions , complex background , facial expressions , low resolutions , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
- Fastness : it should be fast for real-time processing which is an important factor in processing large video archives .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
- Fastness : it should be fast for real-time processing which is an important factor in processing large video archives .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
- Fastness : it should be fast for real-time processing which is an important factor in processing large video archives .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
- Fastness : it should be fast for real-time processing which is an important factor in processing large video archives .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
- Fastness : it should be fast for real-time processing which is an important factor in processing large video archives .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
- Fastness : it should be fast for real-time processing which is an important factor in processing large video archives .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
- Fastness : it should be fast for real-time processing which is an important factor in processing large video archives .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
- Fastness : it should be fast for real-time processing which is an important factor in processing large video archives .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
- Simplicity : The training process should be simple .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
- Simplicity : The training process should be simple .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
For example , the training time is short , the number of parameters is small and training samples are collected without costly .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
For example , the training time is short , the number of parameters is small and training samples are collected without costly .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
For example , the training time is short , the number of parameters is small and training samples are collected without costly .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
For example , the training time is short , the number of parameters is small and training samples are collected without costly .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
Many approaches have been proposed for building fast and robust face detectors \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Among them , those using advanced learning methods such as neural network , support vector machines and boosting are the best .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Among them , those using advanced learning methods such as neural network , support vector machines and boosting are the best .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
Typically , detecting faces in an image includes the following steps :
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Typically , detecting faces in an image includes the following steps :
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
- Window scanning : in order to detect faces at multiple locations and sizes , a fixed window size ( e.g. 24x24 pixels ) is used to extract image patterns at every location and scale .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
- Window scanning : in order to detect faces at multiple locations and sizes , a fixed window size ( e.g. 24x24 pixels ) is used to extract image patterns at every location and scale .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
- Window scanning : in order to detect faces at multiple locations and sizes , a fixed window size ( e.g. 24x24 pixels ) is used to extract image patterns at every location and scale .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
- Window scanning : in order to detect faces at multiple locations and sizes , a fixed window size ( e.g. 24x24 pixels ) is used to extract image patterns at every location and scale .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
The number of patterns extracted from one 320x240 frame image is large , approximately 160 ,000 in which only a small number of patterns containing face .
#<struct ReadData::Alignment source_numbers="26", target_numbers="30", tag_name="wa">
The number of patterns extracted from one 320x240 frame image is large , approximately 160 ,000 in which only a small number of patterns containing face .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
The number of patterns extracted from one 320x240 frame image is large , approximately 160 ,000 in which only a small number of patterns containing face .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
The number of patterns extracted from one 320x240 frame image is large , approximately 160 ,000 in which only a small number of patterns containing face .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
The number of patterns extracted from one 320x240 frame image is large , approximately 160 ,000 in which only a small number of patterns containing face .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
The number of patterns extracted from one 320x240 frame image is large , approximately 160 ,000 in which only a small number of patterns containing face .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
The number of patterns extracted from one 320x240 frame image is large , approximately 160 ,000 in which only a small number of patterns containing face .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
The number of patterns extracted from one 320x240 frame image is large , approximately 160 ,000 in which only a small number of patterns containing face .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
The most popular feature type is Haar wavelet since it is very fast to compute using the integral image \CITE .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
The most popular feature type is Haar wavelet since it is very fast to compute using the integral image \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Other feature types can be listed including pixel intensity \CITE , local binary patterns \CITE and edge orientation histogram \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
- Classification : the extracted features is passed through a classifier which is trained beforehand to classify the input pattern associated with these features as a face or a non-face .
#<struct ReadData::Alignment source_numbers="12", target_numbers="12,13", tag_name="wa">
- Classification : the extracted features is passed through a classifier which is trained beforehand to classify the input pattern associated with these features as a face or a non-face .
#<struct ReadData::Alignment source_numbers="13", target_numbers="15", tag_name="wa">
- Classification : the extracted features is passed through a classifier which is trained beforehand to classify the input pattern associated with these features as a face or a non-face .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
- Classification : the extracted features is passed through a classifier which is trained beforehand to classify the input pattern associated with these features as a face or a non-face .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
- Classification : the extracted features is passed through a classifier which is trained beforehand to classify the input pattern associated with these features as a face or a non-face .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
- Classification : the extracted features is passed through a classifier which is trained beforehand to classify the input pattern associated with these features as a face or a non-face .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
- Classification : the extracted features is passed through a classifier which is trained beforehand to classify the input pattern associated with these features as a face or a non-face .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
- Classification : the extracted features is passed through a classifier which is trained beforehand to classify the input pattern associated with these features as a face or a non-face .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
In order to return one final detection per face , it is necessary to combine overlapping detections into a single detection .
#<struct ReadData::Alignment source_numbers="4", target_numbers="5", tag_name="wa">
In order to return one final detection per face , it is necessary to combine overlapping detections into a single detection .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Since the number of processed patterns is large while the vast majority of them are non-face , a single classifier based systems such as neural network \CITE and support vector machines \CITE are usually slow .
#<struct ReadData::Alignment source_numbers="1", target_numbers="1", tag_name="wa">
Since the number of processed patterns is large while the vast majority of them are non-face , a single classifier based systems such as neural network \CITE and support vector machines \CITE are usually slow .
#<struct ReadData::Alignment source_numbers="3", target_numbers="4", tag_name="wa">
Since the number of processed patterns is large while the vast majority of them are non-face , a single classifier based systems such as neural network \CITE and support vector machines \CITE are usually slow .
#<struct ReadData::Alignment source_numbers="4", target_numbers="5", tag_name="wa">
Since the number of processed patterns is large while the vast majority of them are non-face , a single classifier based systems such as neural network \CITE and support vector machines \CITE are usually slow .
#<struct ReadData::Alignment source_numbers="5", target_numbers="6", tag_name="wa">
Since the number of processed patterns is large while the vast majority of them are non-face , a single classifier based systems such as neural network \CITE and support vector machines \CITE are usually slow .
#<struct ReadData::Alignment source_numbers="17,18", target_numbers="10,11", tag_name="wa">
Since the number of processed patterns is large while the vast majority of them are non-face , a single classifier based systems such as neural network \CITE and support vector machines \CITE are usually slow .
#<struct ReadData::Alignment source_numbers="9", target_numbers="18", tag_name="wa">
Since the number of processed patterns is large while the vast majority of them are non-face , a single classifier based systems such as neural network \CITE and support vector machines \CITE are usually slow .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Since the number of processed patterns is large while the vast majority of them are non-face , a single classifier based systems such as neural network \CITE and support vector machines \CITE are usually slow .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
Since the number of processed patterns is large while the vast majority of them are non-face , a single classifier based systems such as neural network \CITE and support vector machines \CITE are usually slow .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Since the number of processed patterns is large while the vast majority of them are non-face , a single classifier based systems such as neural network \CITE and support vector machines \CITE are usually slow .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Since the number of processed patterns is large while the vast majority of them are non-face , a single classifier based systems such as neural network \CITE and support vector machines \CITE are usually slow .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
Since the number of processed patterns is large while the vast majority of them are non-face , a single classifier based systems such as neural network \CITE and support vector machines \CITE are usually slow .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
Since the number of processed patterns is large while the vast majority of them are non-face , a single classifier based systems such as neural network \CITE and support vector machines \CITE are usually slow .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
In this structure , fast and simple classifiers are used as filters at the earliest stages to quickly reject a large number of non-face patterns and slower yet more accurate classifiers are then used for classifying face-like patterns .
#<struct ReadData::Alignment source_numbers="32", target_numbers="27", tag_name="wa">
In this structure , fast and simple classifiers are used as filters at the earliest stages to quickly reject a large number of non-face patterns and slower yet more accurate classifiers are then used for classifying face-like patterns .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
In this structure , fast and simple classifiers are used as filters at the earliest stages to quickly reject a large number of non-face patterns and slower yet more accurate classifiers are then used for classifying face-like patterns .
#<struct ReadData::Alignment source_numbers="27", target_numbers="", tag_name="wa">
In this structure , fast and simple classifiers are used as filters at the earliest stages to quickly reject a large number of non-face patterns and slower yet more accurate classifiers are then used for classifying face-like patterns .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
In this structure , fast and simple classifiers are used as filters at the earliest stages to quickly reject a large number of non-face patterns and slower yet more accurate classifiers are then used for classifying face-like patterns .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
In this way , the complexity of classifiers can be adapted corresponding to the increasing difficulty in the input patterns .
#<struct ReadData::Alignment source_numbers="11", target_numbers="12", tag_name="wa">
In this way , the complexity of classifiers can be adapted corresponding to the increasing difficulty in the input patterns .
#<struct ReadData::Alignment source_numbers="12", target_numbers="13", tag_name="wa">
In this way , the complexity of classifiers can be adapted corresponding to the increasing difficulty in the input patterns .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
In this way , the complexity of classifiers can be adapted corresponding to the increasing difficulty in the input patterns .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
In this way , the complexity of classifiers can be adapted corresponding to the increasing difficulty in the input patterns .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Training classifiers usually consists of several steps :
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Training classifiers usually consists of several steps :
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Training classifiers usually consists of several steps :
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Face patterns are manually collected in images containing faces and then are scaled to the same size and normalized to a canonical pose which eyes , mouth and nose are aligned .
#<struct ReadData::Alignment source_numbers="5", target_numbers="23", tag_name="wa">
Face patterns are manually collected in images containing faces and then are scaled to the same size and normalized to a canonical pose which eyes , mouth and nose are aligned .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Face patterns are manually collected in images containing faces and then are scaled to the same size and normalized to a canonical pose which eyes , mouth and nose are aligned .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
Then these face patterns can be used to generate other artificial faces by randomly rotating the images ( about their center points ) up to 10 degree , scaling between 90% and 110% , translating up to half a pixel , and mirroring to enlarge the number of positive samples \CITE .
#<struct ReadData::Alignment source_numbers="51", target_numbers="55", tag_name="wa">
Then these face patterns can be used to generate other artificial faces by randomly rotating the images ( about their center points ) up to 10 degree , scaling between 90% and 110% , translating up to half a pixel , and mirroring to enlarge the number of positive samples \CITE .
#<struct ReadData::Alignment source_numbers="30", target_numbers="", tag_name="wa">
Then these face patterns can be used to generate other artificial faces by randomly rotating the images ( about their center points ) up to 10 degree , scaling between 90% and 110% , translating up to half a pixel , and mirroring to enlarge the number of positive samples \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
Then these face patterns can be used to generate other artificial faces by randomly rotating the images ( about their center points ) up to 10 degree , scaling between 90% and 110% , translating up to half a pixel , and mirroring to enlarge the number of positive samples \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
Then these face patterns can be used to generate other artificial faces by randomly rotating the images ( about their center points ) up to 10 degree , scaling between 90% and 110% , translating up to half a pixel , and mirroring to enlarge the number of positive samples \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
Then these face patterns can be used to generate other artificial faces by randomly rotating the images ( about their center points ) up to 10 degree , scaling between 90% and 110% , translating up to half a pixel , and mirroring to enlarge the number of positive samples \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
Then these face patterns can be used to generate other artificial faces by randomly rotating the images ( about their center points ) up to 10 degree , scaling between 90% and 110% , translating up to half a pixel , and mirroring to enlarge the number of positive samples \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="46", tag_name="wa">
Collecting non-face patterns are usually done automatically by scanning through images which contain no faces .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Collecting non-face patterns are usually done automatically by scanning through images which contain no faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Collecting non-face patterns are usually done automatically by scanning through images which contain no faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Collecting non-face patterns are usually done automatically by scanning through images which contain no faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
In \CITE a smaller number of training samples can be used to build a robust face detector by using edge orientation histogram feature .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
- Learning method selection : Basically , in the ideal case with proper settings , advanced learning methods such as neural network , support vector machines and AdaBoost produce similar performance .
#<struct ReadData::Alignment source_numbers="8", target_numbers="12", tag_name="wa">
- Learning method selection : Basically , in the ideal case with proper settings , advanced learning methods such as neural network , support vector machines and AdaBoost produce similar performance .
#<struct ReadData::Alignment source_numbers="20", target_numbers="24", tag_name="wa">
- Learning method selection : Basically , in the ideal case with proper settings , advanced learning methods such as neural network , support vector machines and AdaBoost produce similar performance .
#<struct ReadData::Alignment source_numbers="21", target_numbers="25", tag_name="wa">
- Learning method selection : Basically , in the ideal case with proper settings , advanced learning methods such as neural network , support vector machines and AdaBoost produce similar performance .
#<struct ReadData::Alignment source_numbers="22", target_numbers="26", tag_name="wa">
- Learning method selection : Basically , in the ideal case with proper settings , advanced learning methods such as neural network , support vector machines and AdaBoost produce similar performance .
#<struct ReadData::Alignment source_numbers="23", target_numbers="27", tag_name="wa">
- Learning method selection : Basically , in the ideal case with proper settings , advanced learning methods such as neural network , support vector machines and AdaBoost produce similar performance .
#<struct ReadData::Alignment source_numbers="24", target_numbers="28", tag_name="wa">
- Learning method selection : Basically , in the ideal case with proper settings , advanced learning methods such as neural network , support vector machines and AdaBoost produce similar performance .
#<struct ReadData::Alignment source_numbers="25", target_numbers="29", tag_name="wa">
- Learning method selection : Basically , in the ideal case with proper settings , advanced learning methods such as neural network , support vector machines and AdaBoost produce similar performance .
#<struct ReadData::Alignment source_numbers="26", target_numbers="31", tag_name="wa">
- Learning method selection : Basically , in the ideal case with proper settings , advanced learning methods such as neural network , support vector machines and AdaBoost produce similar performance .
#<struct ReadData::Alignment source_numbers="27", target_numbers="32", tag_name="wa">
- Learning method selection : Basically , in the ideal case with proper settings , advanced learning methods such as neural network , support vector machines and AdaBoost produce similar performance .
#<struct ReadData::Alignment source_numbers="30", target_numbers="35", tag_name="wa">
- Learning method selection : Basically , in the ideal case with proper settings , advanced learning methods such as neural network , support vector machines and AdaBoost produce similar performance .
#<struct ReadData::Alignment source_numbers="29", target_numbers="36", tag_name="wa">
- Learning method selection : Basically , in the ideal case with proper settings , advanced learning methods such as neural network , support vector machines and AdaBoost produce similar performance .
#<struct ReadData::Alignment source_numbers="31", target_numbers="37", tag_name="wa">
- Learning method selection : Basically , in the ideal case with proper settings , advanced learning methods such as neural network , support vector machines and AdaBoost produce similar performance .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
- Learning method selection : Basically , in the ideal case with proper settings , advanced learning methods such as neural network , support vector machines and AdaBoost produce similar performance .
#<struct ReadData::Alignment source_numbers="28", target_numbers="", tag_name="wa">
- Learning method selection : Basically , in the ideal case with proper settings , advanced learning methods such as neural network , support vector machines and AdaBoost produce similar performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
- Learning method selection : Basically , in the ideal case with proper settings , advanced learning methods such as neural network , support vector machines and AdaBoost produce similar performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
- Learning method selection : Basically , in the ideal case with proper settings , advanced learning methods such as neural network , support vector machines and AdaBoost produce similar performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
- Learning method selection : Basically , in the ideal case with proper settings , advanced learning methods such as neural network , support vector machines and AdaBoost produce similar performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
- Learning method selection : Basically , in the ideal case with proper settings , advanced learning methods such as neural network , support vector machines and AdaBoost produce similar performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
Using neural network requires the design of layers , nodes , etc.hich is complicated .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
Using neural network requires the design of layers , nodes , etc.hich is complicated .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
Using neural network requires the design of layers , nodes , etc.hich is complicated .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Using neural network requires the design of layers , nodes , etc.hich is complicated .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Therefore , it is preferable to use support vector machines since the number of parameters is only two if using RBF kernel and many tools are available .
#<struct ReadData::Alignment source_numbers="16", target_numbers="11", tag_name="wa">
Therefore , it is preferable to use support vector machines since the number of parameters is only two if using RBF kernel and many tools are available .
#<struct ReadData::Alignment source_numbers="17", target_numbers="12", tag_name="wa">
Therefore , it is preferable to use support vector machines since the number of parameters is only two if using RBF kernel and many tools are available .
#<struct ReadData::Alignment source_numbers="15", target_numbers="20", tag_name="wa">
Therefore , it is preferable to use support vector machines since the number of parameters is only two if using RBF kernel and many tools are available .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Therefore , it is preferable to use support vector machines since the number of parameters is only two if using RBF kernel and many tools are available .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
Therefore , it is preferable to use support vector machines since the number of parameters is only two if using RBF kernel and many tools are available .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
Therefore , it is preferable to use support vector machines since the number of parameters is only two if using RBF kernel and many tools are available .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
Therefore , it is preferable to use support vector machines since the number of parameters is only two if using RBF kernel and many tools are available .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
Therefore , it is preferable to use support vector machines since the number of parameters is only two if using RBF kernel and many tools are available .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Therefore , it is preferable to use support vector machines since the number of parameters is only two if using RBF kernel and many tools are available .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Therefore , it is preferable to use support vector machines since the number of parameters is only two if using RBF kernel and many tools are available .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
Therefore , it is preferable to use support vector machines since the number of parameters is only two if using RBF kernel and many tools are available .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
Another learning method which has been used widely in many object detection systems is AdaBoost and its variants .
#<struct ReadData::Alignment source_numbers="3,4", target_numbers="3,4", tag_name="wa">
Face tracking is the process of locating a moving face or several ones in time using a camera , as illustrated in Figure 1 .
#<struct ReadData::Alignment source_numbers="14", target_numbers="18", tag_name="wa">
Face tracking is the process of locating a moving face or several ones in time using a camera , as illustrated in Figure 1 .
#<struct ReadData::Alignment source_numbers="24", target_numbers="28", tag_name="wa">
Face tracking is the process of locating a moving face or several ones in time using a camera , as illustrated in Figure 1 .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
Face tracking is the process of locating a moving face or several ones in time using a camera , as illustrated in Figure 1 .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
Face tracking is the process of locating a moving face or several ones in time using a camera , as illustrated in Figure 1 .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
Face tracking is the process of locating a moving face or several ones in time using a camera , as illustrated in Figure 1 .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
Face tracking is the process of locating a moving face or several ones in time using a camera , as illustrated in Figure 1 .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Face tracking is the process of locating a moving face or several ones in time using a camera , as illustrated in Figure 1 .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Face tracking is the process of locating a moving face or several ones in time using a camera , as illustrated in Figure 1 .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
Face tracking is the process of locating a moving face or several ones in time using a camera , as illustrated in Figure 1 .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
Face tracking is the process of locating a moving face or several ones in time using a camera , as illustrated in Figure 1 .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Face tracking is the process of locating a moving face or several ones in time using a camera , as illustrated in Figure 1 .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
Face is first initialized manually or by a face detector .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Face is first initialized manually or by a face detector .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Face is first initialized manually or by a face detector .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Face is first initialized manually or by a face detector .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Face tracker then analyses subsequent video frames and outputs the location of the initialized face within these frames by estimating the motion parameters of the moving face .
#<struct ReadData::Alignment source_numbers="26", target_numbers="1", tag_name="wa">
Face tracker then analyses subsequent video frames and outputs the location of the initialized face within these frames by estimating the motion parameters of the moving face .
#<struct ReadData::Alignment source_numbers="24", target_numbers="5", tag_name="wa">
Face tracker then analyses subsequent video frames and outputs the location of the initialized face within these frames by estimating the motion parameters of the moving face .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Face tracker then analyses subsequent video frames and outputs the location of the initialized face within these frames by estimating the motion parameters of the moving face .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
Face tracker then analyses subsequent video frames and outputs the location of the initialized face within these frames by estimating the motion parameters of the moving face .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Face tracker then analyses subsequent video frames and outputs the location of the initialized face within these frames by estimating the motion parameters of the moving face .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
Face tracker then analyses subsequent video frames and outputs the location of the initialized face within these frames by estimating the motion parameters of the moving face .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
Different from face detection , the outcome of which is the position and scale of one single face in one single frame , face tracking enables the information acquisition of multiple consecutive faces within consecutive video frames .
#<struct ReadData::Alignment source_numbers="9", target_numbers="1", tag_name="wa">
Different from face detection , the outcome of which is the position and scale of one single face in one single frame , face tracking enables the information acquisition of multiple consecutive faces within consecutive video frames .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Different from face detection , the outcome of which is the position and scale of one single face in one single frame , face tracking enables the information acquisition of multiple consecutive faces within consecutive video frames .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
Different from face detection , the outcome of which is the position and scale of one single face in one single frame , face tracking enables the information acquisition of multiple consecutive faces within consecutive video frames .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Different from face detection , the outcome of which is the position and scale of one single face in one single frame , face tracking enables the information acquisition of multiple consecutive faces within consecutive video frames .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Different from face detection , the outcome of which is the position and scale of one single face in one single frame , face tracking enables the information acquisition of multiple consecutive faces within consecutive video frames .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
Different from face detection , the outcome of which is the position and scale of one single face in one single frame , face tracking enables the information acquisition of multiple consecutive faces within consecutive video frames .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
Although frame-based face detection techniques have demonstrated success on real images , the current ability on detecting faces from video is still primitive .
#<struct ReadData::Alignment source_numbers="5", target_numbers="5", tag_name="wa">
Although frame-based face detection techniques have demonstrated success on real images , the current ability on detecting faces from video is still primitive .
#<struct ReadData::Alignment source_numbers="6", target_numbers="8", tag_name="wa">
Although frame-based face detection techniques have demonstrated success on real images , the current ability on detecting faces from video is still primitive .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Although frame-based face detection techniques have demonstrated success on real images , the current ability on detecting faces from video is still primitive .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
Although frame-based face detection techniques have demonstrated success on real images , the current ability on detecting faces from video is still primitive .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Although frame-based face detection techniques have demonstrated success on real images , the current ability on detecting faces from video is still primitive .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Although frame-based face detection techniques have demonstrated success on real images , the current ability on detecting faces from video is still primitive .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
The detector responses can decrease due to different reasons including occlusions , lighting conditions and face pose .
#<struct ReadData::Alignment source_numbers="0", target_numbers="0", tag_name="wa">
The detector responses can decrease due to different reasons including occlusions , lighting conditions and face pose .
#<struct ReadData::Alignment source_numbers="17", target_numbers="21", tag_name="wa">
The detector responses can decrease due to different reasons including occlusions , lighting conditions and face pose .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
The detector responses can decrease due to different reasons including occlusions , lighting conditions and face pose .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
The detector responses can decrease due to different reasons including occlusions , lighting conditions and face pose .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
The detector responses can decrease due to different reasons including occlusions , lighting conditions and face pose .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Without any additional information , these responses can easily be rejected even if they indicate the presence of a face .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
It is therefore important to incorporate the temporal information in a video sequence to provide more complete video segments displaying the person of interest , which is always named as face tracking .
#<struct ReadData::Alignment source_numbers="30", target_numbers="34", tag_name="wa">
It is therefore important to incorporate the temporal information in a video sequence to provide more complete video segments displaying the person of interest , which is always named as face tracking .
#<struct ReadData::Alignment source_numbers="31", target_numbers="35", tag_name="wa">
It is therefore important to incorporate the temporal information in a video sequence to provide more complete video segments displaying the person of interest , which is always named as face tracking .
#<struct ReadData::Alignment source_numbers="32", target_numbers="36", tag_name="wa">
It is therefore important to incorporate the temporal information in a video sequence to provide more complete video segments displaying the person of interest , which is always named as face tracking .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
It is therefore important to incorporate the temporal information in a video sequence to provide more complete video segments displaying the person of interest , which is always named as face tracking .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
It is therefore important to incorporate the temporal information in a video sequence to provide more complete video segments displaying the person of interest , which is always named as face tracking .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
It is therefore important to incorporate the temporal information in a video sequence to provide more complete video segments displaying the person of interest , which is always named as face tracking .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
One of the main applications of face tracking is person retrieval from broadcast video , for example : intelligent fast-forwards " , where the video jumps to the next scene containing a certain person / actor ; or retrieval of different TV interventions , e.g. interviews , shows , etc. , of a given person in a video or a large collection of TV broadcast videos .
#<struct ReadData::Alignment source_numbers="15", target_numbers="5", tag_name="wa">
One of the main applications of face tracking is person retrieval from broadcast video , for example : intelligent fast-forwards " , where the video jumps to the next scene containing a certain person / actor ; or retrieval of different TV interventions , e.g. interviews , shows , etc. , of a given person in a video or a large collection of TV broadcast videos .
#<struct ReadData::Alignment source_numbers="55", target_numbers="9", tag_name="wa">
One of the main applications of face tracking is person retrieval from broadcast video , for example : intelligent fast-forwards " , where the video jumps to the next scene containing a certain person / actor ; or retrieval of different TV interventions , e.g. interviews , shows , etc. , of a given person in a video or a large collection of TV broadcast videos .
#<struct ReadData::Alignment source_numbers="27", target_numbers="10", tag_name="wa">
One of the main applications of face tracking is person retrieval from broadcast video , for example : intelligent fast-forwards " , where the video jumps to the next scene containing a certain person / actor ; or retrieval of different TV interventions , e.g. interviews , shows , etc. , of a given person in a video or a large collection of TV broadcast videos .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
One of the main applications of face tracking is person retrieval from broadcast video , for example : intelligent fast-forwards " , where the video jumps to the next scene containing a certain person / actor ; or retrieval of different TV interventions , e.g. interviews , shows , etc. , of a given person in a video or a large collection of TV broadcast videos .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
One of the main applications of face tracking is person retrieval from broadcast video , for example : intelligent fast-forwards " , where the video jumps to the next scene containing a certain person / actor ; or retrieval of different TV interventions , e.g. interviews , shows , etc. , of a given person in a video or a large collection of TV broadcast videos .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
One of the main applications of face tracking is person retrieval from broadcast video , for example : intelligent fast-forwards " , where the video jumps to the next scene containing a certain person / actor ; or retrieval of different TV interventions , e.g. interviews , shows , etc. , of a given person in a video or a large collection of TV broadcast videos .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
One of the main applications of face tracking is person retrieval from broadcast video , for example : intelligent fast-forwards " , where the video jumps to the next scene containing a certain person / actor ; or retrieval of different TV interventions , e.g. interviews , shows , etc. , of a given person in a video or a large collection of TV broadcast videos .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
One of the main applications of face tracking is person retrieval from broadcast video , for example : intelligent fast-forwards " , where the video jumps to the next scene containing a certain person / actor ; or retrieval of different TV interventions , e.g. interviews , shows , etc. , of a given person in a video or a large collection of TV broadcast videos .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
One of the main applications of face tracking is person retrieval from broadcast video , for example : intelligent fast-forwards " , where the video jumps to the next scene containing a certain person / actor ; or retrieval of different TV interventions , e.g. interviews , shows , etc. , of a given person in a video or a large collection of TV broadcast videos .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
One of the main applications of face tracking is person retrieval from broadcast video , for example : intelligent fast-forwards " , where the video jumps to the next scene containing a certain person / actor ; or retrieval of different TV interventions , e.g. interviews , shows , etc. , of a given person in a video or a large collection of TV broadcast videos .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
One of the main applications of face tracking is person retrieval from broadcast video , for example : intelligent fast-forwards " , where the video jumps to the next scene containing a certain person / actor ; or retrieval of different TV interventions , e.g. interviews , shows , etc. , of a given person in a video or a large collection of TV broadcast videos .
#<struct ReadData::Alignment source_numbers="", target_numbers="56", tag_name="wa">
In [5] , a person retrieval system for feature-length movie video is proposed using straightforward face tracking .
#<struct ReadData::Alignment source_numbers="3", target_numbers="8", tag_name="wa">
In [5] , a person retrieval system for feature-length movie video is proposed using straightforward face tracking .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
At run time a user outlines a face in a frame of the video , and the face tracks within the movie are then ranked according to the similarity to the outlined query face in the manner of Google .
#<struct ReadData::Alignment source_numbers="16", target_numbers="14", tag_name="wa">
At run time a user outlines a face in a frame of the video , and the face tracks within the movie are then ranked according to the similarity to the outlined query face in the manner of Google .
#<struct ReadData::Alignment source_numbers="20", target_numbers="18", tag_name="wa">
At run time a user outlines a face in a frame of the video , and the face tracks within the movie are then ranked according to the similarity to the outlined query face in the manner of Google .
#<struct ReadData::Alignment source_numbers="36", target_numbers="35,36", tag_name="wa">
At run time a user outlines a face in a frame of the video , and the face tracks within the movie are then ranked according to the similarity to the outlined query face in the manner of Google .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
At run time a user outlines a face in a frame of the video , and the face tracks within the movie are then ranked according to the similarity to the outlined query face in the manner of Google .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
At run time a user outlines a face in a frame of the video , and the face tracks within the movie are then ranked according to the similarity to the outlined query face in the manner of Google .
#<struct ReadData::Alignment source_numbers="27", target_numbers="", tag_name="wa">
At run time a user outlines a face in a frame of the video , and the face tracks within the movie are then ranked according to the similarity to the outlined query face in the manner of Google .
#<struct ReadData::Alignment source_numbers="37", target_numbers="", tag_name="wa">
At run time a user outlines a face in a frame of the video , and the face tracks within the movie are then ranked according to the similarity to the outlined query face in the manner of Google .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
At run time a user outlines a face in a frame of the video , and the face tracks within the movie are then ranked according to the similarity to the outlined query face in the manner of Google .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
Face tracking also finds applications in the area of face-name association , the objective of which is to label television or movie footage with the identity of the person present in each frame of the video .
#<struct ReadData::Alignment source_numbers="16", target_numbers="2", tag_name="wa">
Face tracking also finds applications in the area of face-name association , the objective of which is to label television or movie footage with the identity of the person present in each frame of the video .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
Face tracking also finds applications in the area of face-name association , the objective of which is to label television or movie footage with the identity of the person present in each frame of the video .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
Face tracking also finds applications in the area of face-name association , the objective of which is to label television or movie footage with the identity of the person present in each frame of the video .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Face tracking also finds applications in the area of face-name association , the objective of which is to label television or movie footage with the identity of the person present in each frame of the video .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
Everingham et al [8] proposed an automatic face-name association system .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Everingham et al [8] proposed an automatic face-name association system .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
This system uses a face tracker similar with [5] to extract a few hundred tracks of a particular character each in a single shot .
#<struct ReadData::Alignment source_numbers="9", target_numbers="7", tag_name="wa">
This system uses a face tracker similar with [5] to extract a few hundred tracks of a particular character each in a single shot .
#<struct ReadData::Alignment source_numbers="10", target_numbers="14", tag_name="wa">
This system uses a face tracker similar with [5] to extract a few hundred tracks of a particular character each in a single shot .
#<struct ReadData::Alignment source_numbers="19", target_numbers="20", tag_name="wa">
This system uses a face tracker similar with [5] to extract a few hundred tracks of a particular character each in a single shot .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
This system uses a face tracker similar with [5] to extract a few hundred tracks of a particular character each in a single shot .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
This system uses a face tracker similar with [5] to extract a few hundred tracks of a particular character each in a single shot .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
This system uses a face tracker similar with [5] to extract a few hundred tracks of a particular character each in a single shot .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
This system uses a face tracker similar with [5] to extract a few hundred tracks of a particular character each in a single shot .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
This system uses a face tracker similar with [5] to extract a few hundred tracks of a particular character each in a single shot .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
This system uses a face tracker similar with [5] to extract a few hundred tracks of a particular character each in a single shot .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Based on the temporal information obtained from the face tracker , textual information for TV and movie footage including subtitles and transcripts is employed to assign the character 's name to each face track .
#<struct ReadData::Alignment source_numbers="26", target_numbers="11", tag_name="wa">
Based on the temporal information obtained from the face tracker , textual information for TV and movie footage including subtitles and transcripts is employed to assign the character 's name to each face track .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
For instance , shots containing a particular person can be retrieved by a keyword like " Bush " or " Julia Roberts " instead of an outlined query face as used in [5] .
#<struct ReadData::Alignment source_numbers="30,31", target_numbers="26", tag_name="wa">
For instance , shots containing a particular person can be retrieved by a keyword like " Bush " or " Julia Roberts " instead of an outlined query face as used in [5] .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
For instance , shots containing a particular person can be retrieved by a keyword like " Bush " or " Julia Roberts " instead of an outlined query face as used in [5] .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
For instance , shots containing a particular person can be retrieved by a keyword like " Bush " or " Julia Roberts " instead of an outlined query face as used in [5] .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
For instance , shots containing a particular person can be retrieved by a keyword like " Bush " or " Julia Roberts " instead of an outlined query face as used in [5] .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
Besides broadcast video , face tracker also has important applications in the video used in humanoid robotics , visual surveillance , human-computer interaction ( HCI ) , video conferencing , face-based biometric person authentication , etc.
#<struct ReadData::Alignment source_numbers="34", target_numbers="", tag_name="wa">
Besides broadcast video , face tracker also has important applications in the video used in humanoid robotics , visual surveillance , human-computer interaction ( HCI ) , video conferencing , face-based biometric person authentication , etc.
#<struct ReadData::Alignment source_numbers="35", target_numbers="", tag_name="wa">
Besides broadcast video , face tracker also has important applications in the video used in humanoid robotics , visual surveillance , human-computer interaction ( HCI ) , video conferencing , face-based biometric person authentication , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
Besides broadcast video , face tracker also has important applications in the video used in humanoid robotics , visual surveillance , human-computer interaction ( HCI ) , video conferencing , face-based biometric person authentication , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
Besides broadcast video , face tracker also has important applications in the video used in humanoid robotics , visual surveillance , human-computer interaction ( HCI ) , video conferencing , face-based biometric person authentication , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
Besides broadcast video , face tracker also has important applications in the video used in humanoid robotics , visual surveillance , human-computer interaction ( HCI ) , video conferencing , face-based biometric person authentication , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
Choosing a face tracker can be a difficult task due to the variety of face trackers available .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
Generally speaking , the important issues that should be addressed include speed , robustness and accuracy .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Can the system run in real time ? Similar with many other processing tools for broadcast video , speed is not the most critical issue because offline processing is permitted in most cases of video structuring and indexing .
#<struct ReadData::Alignment source_numbers="32", target_numbers="36", tag_name="wa">
Can the system run in real time ? Similar with many other processing tools for broadcast video , speed is not the most critical issue because offline processing is permitted in most cases of video structuring and indexing .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Can the system run in real time ? Similar with many other processing tools for broadcast video , speed is not the most critical issue because offline processing is permitted in most cases of video structuring and indexing .
#<struct ReadData::Alignment source_numbers="33", target_numbers="", tag_name="wa">
Can the system run in real time ? Similar with many other processing tools for broadcast video , speed is not the most critical issue because offline processing is permitted in most cases of video structuring and indexing .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
However , a real-time face tracker will become necessary if the target archive is established from too large quantities of videos , e.g. 24-hour continuous video recording that needs daily structuring .
#<struct ReadData::Alignment source_numbers="10,11", target_numbers="10,11", tag_name="wa">
However , a real-time face tracker will become necessary if the target archive is established from too large quantities of videos , e.g. 24-hour continuous video recording that needs daily structuring .
#<struct ReadData::Alignment source_numbers="18", target_numbers="19", tag_name="wa">
However , a real-time face tracker will become necessary if the target archive is established from too large quantities of videos , e.g. 24-hour continuous video recording that needs daily structuring .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
On the other hand , the speed of the tracker is critical in most cases of applications for non-broadcast video , e.g. HCI .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
On the other hand , the speed of the tracker is critical in most cases of applications for non-broadcast video , e.g. HCI .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
Can the system cope with varying illumination , facial expression , scale , pose , camerawork , occlusion and large head motion ? A number of illumination factors , e.g. light sources , background colors , luminance levels , and media , impact greatly on the change in appearance of a moving face , for instance , when tracking a person who are moving from indoor to outdoor environment .
#<struct ReadData::Alignment source_numbers="32", target_numbers="18", tag_name="wa">
Can the system cope with varying illumination , facial expression , scale , pose , camerawork , occlusion and large head motion ? A number of illumination factors , e.g. light sources , background colors , luminance levels , and media , impact greatly on the change in appearance of a moving face , for instance , when tracking a person who are moving from indoor to outdoor environment .
#<struct ReadData::Alignment source_numbers="41", target_numbers="33", tag_name="wa">
Can the system cope with varying illumination , facial expression , scale , pose , camerawork , occlusion and large head motion ? A number of illumination factors , e.g. light sources , background colors , luminance levels , and media , impact greatly on the change in appearance of a moving face , for instance , when tracking a person who are moving from indoor to outdoor environment .
#<struct ReadData::Alignment source_numbers="56", target_numbers="42", tag_name="wa">
Can the system cope with varying illumination , facial expression , scale , pose , camerawork , occlusion and large head motion ? A number of illumination factors , e.g. light sources , background colors , luminance levels , and media , impact greatly on the change in appearance of a moving face , for instance , when tracking a person who are moving from indoor to outdoor environment .
#<struct ReadData::Alignment source_numbers="62,63,64", target_numbers="63,64,65", tag_name="wa">
Can the system cope with varying illumination , facial expression , scale , pose , camerawork , occlusion and large head motion ? A number of illumination factors , e.g. light sources , background colors , luminance levels , and media , impact greatly on the change in appearance of a moving face , for instance , when tracking a person who are moving from indoor to outdoor environment .
#<struct ReadData::Alignment source_numbers="", target_numbers="57", tag_name="wa">
Different from non-broadcast video , e.g. video used for HCI , faces appearing in broadcast video varies from large close-up faces to small faces taken by a long-shot .
#<struct ReadData::Alignment source_numbers="16,17", target_numbers="16,17", tag_name="wa">
Small face scale always leads to low resolution and will reject most face trackers designed by computer vision researchers .
#<struct ReadData::Alignment source_numbers="1", target_numbers="2", tag_name="wa">
Small face scale always leads to low resolution and will reject most face trackers designed by computer vision researchers .
#<struct ReadData::Alignment source_numbers="2", target_numbers="3", tag_name="wa">
Small face scale always leads to low resolution and will reject most face trackers designed by computer vision researchers .
#<struct ReadData::Alignment source_numbers="6", target_numbers="8", tag_name="wa">
Small face scale always leads to low resolution and will reject most face trackers designed by computer vision researchers .
#<struct ReadData::Alignment source_numbers="7", target_numbers="9", tag_name="wa">
Small face scale always leads to low resolution and will reject most face trackers designed by computer vision researchers .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Small face scale always leads to low resolution and will reject most face trackers designed by computer vision researchers .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Small face scale always leads to low resolution and will reject most face trackers designed by computer vision researchers .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Small face scale always leads to low resolution and will reject most face trackers designed by computer vision researchers .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Pose variation , i.e. head rotations including pitch , roll and yaw , is another influencing factor , which can cause disappearance of part of the face .
#<struct ReadData::Alignment source_numbers="25", target_numbers="7", tag_name="wa">
Pose variation , i.e. head rotations including pitch , roll and yaw , is another influencing factor , which can cause disappearance of part of the face .
#<struct ReadData::Alignment source_numbers="17", target_numbers="11", tag_name="wa">
Pose variation , i.e. head rotations including pitch , roll and yaw , is another influencing factor , which can cause disappearance of part of the face .
#<struct ReadData::Alignment source_numbers="21,22", target_numbers="23,24", tag_name="wa">
Pose variation , i.e. head rotations including pitch , roll and yaw , is another influencing factor , which can cause disappearance of part of the face .
#<struct ReadData::Alignment source_numbers="23,24", target_numbers="25,26", tag_name="wa">
Pose variation , i.e. head rotations including pitch , roll and yaw , is another influencing factor , which can cause disappearance of part of the face .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
In some cases , the variation of scale and pose might be caused by camerawork change .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
In some cases , the variation of scale and pose might be caused by camerawork change .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Disappearance of part of the face is also apt to happen due to occlusion by other objects , and motion information may be distracted by alternate motion of them .
#<struct ReadData::Alignment source_numbers="2", target_numbers="1", tag_name="wa">
Disappearance of part of the face is also apt to happen due to occlusion by other objects , and motion information may be distracted by alternate motion of them .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Disappearance of part of the face is also apt to happen due to occlusion by other objects , and motion information may be distracted by alternate motion of them .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
Disappearance of part of the face is also apt to happen due to occlusion by other objects , and motion information may be distracted by alternate motion of them .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
Disappearance of part of the face is also apt to happen due to occlusion by other objects , and motion information may be distracted by alternate motion of them .
#<struct ReadData::Alignment source_numbers="27", target_numbers="", tag_name="wa">
Disappearance of part of the face is also apt to happen due to occlusion by other objects , and motion information may be distracted by alternate motion of them .
#<struct ReadData::Alignment source_numbers="28", target_numbers="", tag_name="wa">
Disappearance of part of the face is also apt to happen due to occlusion by other objects , and motion information may be distracted by alternate motion of them .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Disappearance of part of the face is also apt to happen due to occlusion by other objects , and motion information may be distracted by alternate motion of them .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Disappearance of part of the face is also apt to happen due to occlusion by other objects , and motion information may be distracted by alternate motion of them .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Moreover , the task of face tracking becomes even more difficult when the head are moving fast relative to the frame rate so that the tracker fails to arrive in time " .
#<struct ReadData::Alignment source_numbers="14", target_numbers="14", tag_name="wa">
Moreover , the task of face tracking becomes even more difficult when the head are moving fast relative to the frame rate so that the tracker fails to arrive in time " .
#<struct ReadData::Alignment source_numbers="15", target_numbers="15", tag_name="wa">
Moreover , the task of face tracking becomes even more difficult when the head are moving fast relative to the frame rate so that the tracker fails to arrive in time " .
#<struct ReadData::Alignment source_numbers="28", target_numbers="", tag_name="wa">
Moreover , the task of face tracking becomes even more difficult when the head are moving fast relative to the frame rate so that the tracker fails to arrive in time " .
#<struct ReadData::Alignment source_numbers="30", target_numbers="", tag_name="wa">
Moreover , the task of face tracking becomes even more difficult when the head are moving fast relative to the frame rate so that the tracker fails to arrive in time " .
#<struct ReadData::Alignment source_numbers="31", target_numbers="", tag_name="wa">
Moreover , the task of face tracking becomes even more difficult when the head are moving fast relative to the frame rate so that the tracker fails to arrive in time " .
#<struct ReadData::Alignment source_numbers="32", target_numbers="", tag_name="wa">
Moreover , the task of face tracking becomes even more difficult when the head are moving fast relative to the frame rate so that the tracker fails to arrive in time " .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
Moreover , the task of face tracking becomes even more difficult when the head are moving fast relative to the frame rate so that the tracker fails to arrive in time " .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
Moreover , the task of face tracking becomes even more difficult when the head are moving fast relative to the frame rate so that the tracker fails to arrive in time " .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
This problem is difficult to solve due to a fixed threshold .
#<struct ReadData::Alignment source_numbers="6,7", target_numbers="6", tag_name="wa">
This problem is difficult to solve due to a fixed threshold .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
This problem is difficult to solve due to a fixed threshold .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Lowering the threshold of the face detector reduces false rejections but increases the number of false detections , and vice versa .
#<struct ReadData::Alignment source_numbers="12", target_numbers="8", tag_name="wa">
Lowering the threshold of the face detector reduces false rejections but increases the number of false detections , and vice versa .
#<struct ReadData::Alignment source_numbers="13", target_numbers="9", tag_name="wa">
Lowering the threshold of the face detector reduces false rejections but increases the number of false detections , and vice versa .
#<struct ReadData::Alignment source_numbers="14", target_numbers="10", tag_name="wa">
Lowering the threshold of the face detector reduces false rejections but increases the number of false detections , and vice versa .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Lowering the threshold of the face detector reduces false rejections but increases the number of false detections , and vice versa .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
Lowering the threshold of the face detector reduces false rejections but increases the number of false detections , and vice versa .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Lowering the threshold of the face detector reduces false rejections but increases the number of false detections , and vice versa .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
A tracker might accumulate motion errors and eventually lose track of the face , for instance , when tracking faces that change from a frontal view to a profile position .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
A tracker might accumulate motion errors and eventually lose track of the face , for instance , when tracking faces that change from a frontal view to a profile position .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
Face tracking can be considered as an algorithm that analyses the video frames and outputs the location of moving faces within the video frame .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Face tracking can be considered as an algorithm that analyses the video frames and outputs the location of moving faces within the video frame .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Face tracking can be considered as an algorithm that analyses the video frames and outputs the location of moving faces within the video frame .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
For each tracked face , three steps are involved that are initialization , tracking and a stopping procedure , as illustrated in Figure 2 .
#<struct ReadData::Alignment source_numbers="18", target_numbers="9", tag_name="wa">
For each tracked face , three steps are involved that are initialization , tracking and a stopping procedure , as illustrated in Figure 2 .
#<struct ReadData::Alignment source_numbers="9,10", target_numbers="10,11,12", tag_name="wa">
For each tracked face , three steps are involved that are initialization , tracking and a stopping procedure , as illustrated in Figure 2 .
#<struct ReadData::Alignment source_numbers="17", target_numbers="19", tag_name="wa">
For each tracked face , three steps are involved that are initialization , tracking and a stopping procedure , as illustrated in Figure 2 .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
For each tracked face , three steps are involved that are initialization , tracking and a stopping procedure , as illustrated in Figure 2 .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
For each tracked face , three steps are involved that are initialization , tracking and a stopping procedure , as illustrated in Figure 2 .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
For each tracked face , three steps are involved that are initialization , tracking and a stopping procedure , as illustrated in Figure 2 .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
For each tracked face , three steps are involved that are initialization , tracking and a stopping procedure , as illustrated in Figure 2 .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
Most of the developed methods use a face detector as the initialization of their tracking process .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Most of the developed methods use a face detector as the initialization of their tracking process .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
An always ignored but existing difficulty of this step lies in the control of false face detections described above .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
An always ignored but existing difficulty of this step lies in the control of false face detections described above .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Although there have been literatures in profile or intermediate pose face detector , this kind of work suffers from the false-detection problem far more than frontal face detector .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Although there have been literatures in profile or intermediate pose face detector , this kind of work suffers from the false-detection problem far more than frontal face detector .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
To alleviate these two problems , Chaudhury et al [1] used two face probability maps instead of a fixed threshold to initialize face tracker , one for frontal views and one for profiles .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
To alleviate these two problems , Chaudhury et al [1] used two face probability maps instead of a fixed threshold to initialize face tracker , one for frontal views and one for profiles .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
After initialization , one should choose what features to track before tracking the face .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
After initialization , one should choose what features to track before tracking the face .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
The exploitation of color is one of the common choices in order to be invariant to facial expression , scale and pose change [4 , 9] .
#<struct ReadData::Alignment source_numbers="24", target_numbers="21", tag_name="wa">
The exploitation of color is one of the common choices in order to be invariant to facial expression , scale and pose change [4 , 9] .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
The exploitation of color is one of the common choices in order to be invariant to facial expression , scale and pose change [4 , 9] .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
Another two choices are key-point [5 , 8] and facial features [3 , 6 , 10] , e.g. eyes , nose , mouth , etc. , both of which are more robust to varying illumination and occlusion .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Another two choices are key-point [5 , 8] and facial features [3 , 6 , 10] , e.g. eyes , nose , mouth , etc. , both of which are more robust to varying illumination and occlusion .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Another two choices are key-point [5 , 8] and facial features [3 , 6 , 10] , e.g. eyes , nose , mouth , etc. , both of which are more robust to varying illumination and occlusion .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Another two choices are key-point [5 , 8] and facial features [3 , 6 , 10] , e.g. eyes , nose , mouth , etc. , both of which are more robust to varying illumination and occlusion .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Facial features enable to track higher-level information from a human face but are weak in low video quality .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
Facial features enable to track higher-level information from a human face but are weak in low video quality .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
Facial features enable to track higher-level information from a human face but are weak in low video quality .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Facial features enable to track higher-level information from a human face but are weak in low video quality .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Facial features enable to track higher-level information from a human face but are weak in low video quality .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Facial features enable to track higher-level information from a human face but are weak in low video quality .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
Most facial-feature-based face trackers [6 , 10] are only tested by using non-broadcast video , e.g. webcam video , and their application potentiality to broadcast video is questionable .
#<struct ReadData::Alignment source_numbers="7", target_numbers="7,8", tag_name="wa">
Most facial-feature-based face trackers [6 , 10] are only tested by using non-broadcast video , e.g. webcam video , and their application potentiality to broadcast video is questionable .
#<struct ReadData::Alignment source_numbers="9", target_numbers="9", tag_name="wa">
An appearance-based or featureless tracker matches an observation model of the entire facial appearance with the input image , instead of choosing a few features to track .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
One example of appearance-based face tracker is [1] that has been introduced above .
#<struct ReadData::Alignment source_numbers="8,9,10", target_numbers="10,11", tag_name="wa">
One example of appearance-based face tracker is [1] that has been introduced above .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Another example is proposed by Li et al [9] , which uses a multi-view face detector to detect and track faces of different poses .
#<struct ReadData::Alignment source_numbers="2", target_numbers="2", tag_name="wa">
Another example is proposed by Li et al [9] , which uses a multi-view face detector to detect and track faces of different poses .
#<struct ReadData::Alignment source_numbers="3", target_numbers="3", tag_name="wa">
Another example is proposed by Li et al [9] , which uses a multi-view face detector to detect and track faces of different poses .
#<struct ReadData::Alignment source_numbers="21,22", target_numbers="21,22", tag_name="wa">
Another example is proposed by Li et al [9] , which uses a multi-view face detector to detect and track faces of different poses .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Another example is proposed by Li et al [9] , which uses a multi-view face detector to detect and track faces of different poses .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
It is based on the idea that head can be considered as the object of interest instead of face because face is not always present in the tracking process .
#<struct ReadData::Alignment source_numbers="12", target_numbers="22", tag_name="wa">
It is based on the idea that head can be considered as the object of interest instead of face because face is not always present in the tracking process .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
It is based on the idea that head can be considered as the object of interest instead of face because face is not always present in the tracking process .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
It is based on the idea that head can be considered as the object of interest instead of face because face is not always present in the tracking process .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
An extended particle filter is proposed to fuse these two interrelated information so as to handle the occlusion due to out-of-plane head rotation ( yaw ) that is more than �90 degrees .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
During the tracking procedure , face tracking systems usually employ a motion model that describes how the image of the target might change for different possible motions of the face to track .
#<struct ReadData::Alignment source_numbers="9,10", target_numbers="9,10", tag_name="wa">
Examples of simple motion models are as follows .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Examples of simple motion models are as follows .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Examples of simple motion models are as follows .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Based on the assumption that face can be considered as a planar object , the corresponding motion model can be a 2D transformation , e.g. affine transformation or homography , of an image of the face , e.g. the initial frame [3 , 6] .
#<struct ReadData::Alignment source_numbers="20", target_numbers="5", tag_name="wa">
Based on the assumption that face can be considered as a planar object , the corresponding motion model can be a 2D transformation , e.g. affine transformation or homography , of an image of the face , e.g. the initial frame [3 , 6] .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Based on the assumption that face can be considered as a planar object , the corresponding motion model can be a 2D transformation , e.g. affine transformation or homography , of an image of the face , e.g. the initial frame [3 , 6] .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
Some researchers assume the face as a rigid 3D object , thus the motion model defines its aspect depending on its 3D position and orientation [10] .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Some researchers assume the face as a rigid 3D object , thus the motion model defines its aspect depending on its 3D position and orientation [10] .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
Some researchers assume the face as a rigid 3D object , thus the motion model defines its aspect depending on its 3D position and orientation [10] .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Some researchers assume the face as a rigid 3D object , thus the motion model defines its aspect depending on its 3D position and orientation [10] .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Some system try to model face in this sense , and the image of deformable faces can be covered with a mesh , i.e. a sophisticated geometry and texture face model [2 , 7] .
#<struct ReadData::Alignment source_numbers="15", target_numbers="5", tag_name="wa">
Some system try to model face in this sense , and the image of deformable faces can be covered with a mesh , i.e. a sophisticated geometry and texture face model [2 , 7] .
#<struct ReadData::Alignment source_numbers="5", target_numbers="15", tag_name="wa">
Generally if the quality of the video is high , more sophisticated motion model is used , more accurate result the face tracker generates .
#<struct ReadData::Alignment source_numbers="24", target_numbers="28", tag_name="wa">
Generally if the quality of the video is high , more sophisticated motion model is used , more accurate result the face tracker generates .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
Generally if the quality of the video is high , more sophisticated motion model is used , more accurate result the face tracker generates .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
Generally if the quality of the video is high , more sophisticated motion model is used , more accurate result the face tracker generates .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
For instance , a sophisticated geometry and texture model might suffer from false face detections and drifting less than a simple 2D transformation model .
#<struct ReadData::Alignment source_numbers="24", target_numbers="33", tag_name="wa">
For instance , a sophisticated geometry and texture model might suffer from false face detections and drifting less than a simple 2D transformation model .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
For instance , a sophisticated geometry and texture model might suffer from false face detections and drifting less than a simple 2D transformation model .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
For instance , a sophisticated geometry and texture model might suffer from false face detections and drifting less than a simple 2D transformation model .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
For instance , a sophisticated geometry and texture model might suffer from false face detections and drifting less than a simple 2D transformation model .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
For instance , a sophisticated geometry and texture model might suffer from false face detections and drifting less than a simple 2D transformation model .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
For instance , a sophisticated geometry and texture model might suffer from false face detections and drifting less than a simple 2D transformation model .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
For instance , a sophisticated geometry and texture model might suffer from false face detections and drifting less than a simple 2D transformation model .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
For instance , a sophisticated geometry and texture model might suffer from false face detections and drifting less than a simple 2D transformation model .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
For instance , a sophisticated geometry and texture model might suffer from false face detections and drifting less than a simple 2D transformation model .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
For instance , a sophisticated geometry and texture model might suffer from false face detections and drifting less than a simple 2D transformation model .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
For instance , a sophisticated geometry and texture model might suffer from false face detections and drifting less than a simple 2D transformation model .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
But note that most 3D-based and mesh-based face trackers require relatively clear appearance , high resolution , and limited pose variation of the face , e.g. out-of-plane head rotations ( roll and yaw ) that are far less than �90 degrees .
#<struct ReadData::Alignment source_numbers="24", target_numbers="1", tag_name="wa">
But note that most 3D-based and mesh-based face trackers require relatively clear appearance , high resolution , and limited pose variation of the face , e.g. out-of-plane head rotations ( roll and yaw ) that are far less than �90 degrees .
#<struct ReadData::Alignment source_numbers="1", target_numbers="4,5", tag_name="wa">
But note that most 3D-based and mesh-based face trackers require relatively clear appearance , high resolution , and limited pose variation of the face , e.g. out-of-plane head rotations ( roll and yaw ) that are far less than �90 degrees .
#<struct ReadData::Alignment source_numbers="41", target_numbers="47", tag_name="wa">
But note that most 3D-based and mesh-based face trackers require relatively clear appearance , high resolution , and limited pose variation of the face , e.g. out-of-plane head rotations ( roll and yaw ) that are far less than �90 degrees .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
But note that most 3D-based and mesh-based face trackers require relatively clear appearance , high resolution , and limited pose variation of the face , e.g. out-of-plane head rotations ( roll and yaw ) that are far less than �90 degrees .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
But note that most 3D-based and mesh-based face trackers require relatively clear appearance , high resolution , and limited pose variation of the face , e.g. out-of-plane head rotations ( roll and yaw ) that are far less than �90 degrees .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
But note that most 3D-based and mesh-based face trackers require relatively clear appearance , high resolution , and limited pose variation of the face , e.g. out-of-plane head rotations ( roll and yaw ) that are far less than �90 degrees .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
But note that most 3D-based and mesh-based face trackers require relatively clear appearance , high resolution , and limited pose variation of the face , e.g. out-of-plane head rotations ( roll and yaw ) that are far less than �90 degrees .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
This constitutes a major deficiency of face tracking algorithms that are generally not able to stop a face track in case of tracking error , i.e. drifting .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
This constitutes a major deficiency of face tracking algorithms that are generally not able to stop a face track in case of tracking error , i.e. drifting .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Arnaud et al [3] proposed an approach that uses a general object tracker for face tracking and a stopping criterion based on the addition of an eye tracker to alleviate drifting .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Arnaud et al [3] proposed an approach that uses a general object tracker for face tracking and a stopping criterion based on the addition of an eye tracker to alleviate drifting .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Two positions of tracked eyes are compared with tracked face position .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Two positions of tracked eyes are compared with tracked face position .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
If none of the two eyes are in the face region , it will be determined as drifting and the tracking process will be stopped .
#<struct ReadData::Alignment source_numbers="1,2", target_numbers="1,2", tag_name="wa">
If none of the two eyes are in the face region , it will be determined as drifting and the tracking process will be stopped .
#<struct ReadData::Alignment source_numbers="22,23", target_numbers="5", tag_name="wa">
If none of the two eyes are in the face region , it will be determined as drifting and the tracking process will be stopped .
#<struct ReadData::Alignment source_numbers="6", target_numbers="21,22", tag_name="wa">
If none of the two eyes are in the face region , it will be determined as drifting and the tracking process will be stopped .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
Besides , most mesh-based trackers and top-down trackers are considered to be able to avoid drifting .
#<struct ReadData::Alignment source_numbers="7", target_numbers="7", tag_name="wa">
Besides , most mesh-based trackers and top-down trackers are considered to be able to avoid drifting .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Besides , most mesh-based trackers and top-down trackers are considered to be able to avoid drifting .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
Besides , most mesh-based trackers and top-down trackers are considered to be able to avoid drifting .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Besides , most mesh-based trackers and top-down trackers are considered to be able to avoid drifting .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Besides , most mesh-based trackers and top-down trackers are considered to be able to avoid drifting .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Besides , most mesh-based trackers and top-down trackers are considered to be able to avoid drifting .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
However , while most attempts have been made on face tracking for videos with high quality by computer vision researchers , only a limited number of face trackers are designed for broadcast video .
#<struct ReadData::Alignment source_numbers="5", target_numbers="7", tag_name="wa">
However , while most attempts have been made on face tracking for videos with high quality by computer vision researchers , only a limited number of face trackers are designed for broadcast video .
#<struct ReadData::Alignment source_numbers="6", target_numbers="8", tag_name="wa">
However , while most attempts have been made on face tracking for videos with high quality by computer vision researchers , only a limited number of face trackers are designed for broadcast video .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
However , while most attempts have been made on face tracking for videos with high quality by computer vision researchers , only a limited number of face trackers are designed for broadcast video .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
However , while most attempts have been made on face tracking for videos with high quality by computer vision researchers , only a limited number of face trackers are designed for broadcast video .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
However , while most attempts have been made on face tracking for videos with high quality by computer vision researchers , only a limited number of face trackers are designed for broadcast video .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
However , while most attempts have been made on face tracking for videos with high quality by computer vision researchers , only a limited number of face trackers are designed for broadcast video .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
A general evaluation criterion , in terms of speed , robustness and accuracy , is needed for performance comparison between face trackers of different purposes .
#<struct ReadData::Alignment source_numbers="22,23", target_numbers="25,26", tag_name="wa">
A general evaluation criterion , in terms of speed , robustness and accuracy , is needed for performance comparison between face trackers of different purposes .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
We propose a method to retrieve relevant faces for one person by learning the visual consistency among results retrieved from text-correlation-based search engines .
#<struct ReadData::Alignment source_numbers="8", target_numbers="4", tag_name="wa">
We propose a method to retrieve relevant faces for one person by learning the visual consistency among results retrieved from text-correlation-based search engines .
#<struct ReadData::Alignment source_numbers="5", target_numbers="5", tag_name="wa">
We propose a method to retrieve relevant faces for one person by learning the visual consistency among results retrieved from text-correlation-based search engines .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
We propose a method to retrieve relevant faces for one person by learning the visual consistency among results retrieved from text-correlation-based search engines .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
In the first step , each candidate face obtained from a text-based search engine is ranked by a score that measures the distribution of visual similarities among the faces .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
In the first step , each candidate face obtained from a text-based search engine is ranked by a score that measures the distribution of visual similarities among the faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
Faces that are possibly very relevant or irrelevant are ranked at the top or bottom of the list .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
This trend has shown the need for effective and efficient tools for indexing and retrieving based on visual content .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
This trend has shown the need for effective and efficient tools for indexing and retrieving based on visual content .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
However , other un-queried faces and names may appear with the queried ones ( as shown in Figure xx ) , and this significantly lowers retrieval performance .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
However , other un-queried faces and names may appear with the queried ones ( as shown in Figure xx ) , and this significantly lowers retrieval performance .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
However , other un-queried faces and names may appear with the queried ones ( as shown in Figure xx ) , and this significantly lowers retrieval performance .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
-Large variations in facial appearance due to pose changes , illumination conditions , occlusions and facial expressions make face recognition difficult even with state-of-the-art techniques\CITE ( see an example in Figure xx ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
The main idea is to assume that there is visual consistency among the results returned from text-based search engines ; and then learn this visual consistency through an interactive process .
#<struct ReadData::Alignment source_numbers="22", target_numbers="25", tag_name="wa">
The main idea is to assume that there is visual consistency among the results returned from text-based search engines ; and then learn this visual consistency through an interactive process .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
The main idea is to assume that there is visual consistency among the results returned from text-based search engines ; and then learn this visual consistency through an interactive process .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
The main idea is to assume that there is visual consistency among the results returned from text-based search engines ; and then learn this visual consistency through an interactive process .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
The main idea is to assume that there is visual consistency among the results returned from text-based search engines ; and then learn this visual consistency through an interactive process .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
The main idea is to assume that there is visual consistency among the results returned from text-based search engines ; and then learn this visual consistency through an interactive process .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
The main idea is to assume that there is visual consistency among the results returned from text-based search engines ; and then learn this visual consistency through an interactive process .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
This score is used to form a ranked list , in which faces having high density scores are considered relevant and are put at the top of the list .
#<struct ReadData::Alignment source_numbers="29", target_numbers="25", tag_name="wa">
This score is used to form a ranked list , in which faces having high density scores are considered relevant and are put at the top of the list .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
This score is used to form a ranked list , in which faces having high density scores are considered relevant and are put at the top of the list .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
This score is used to form a ranked list , in which faces having high density scores are considered relevant and are put at the top of the list .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
This score is used to form a ranked list , in which faces having high density scores are considered relevant and are put at the top of the list .
#<struct ReadData::Alignment source_numbers="26", target_numbers="", tag_name="wa">
This score is used to form a ranked list , in which faces having high density scores are considered relevant and are put at the top of the list .
#<struct ReadData::Alignment source_numbers="27", target_numbers="", tag_name="wa">
This score is used to form a ranked list , in which faces having high density scores are considered relevant and are put at the top of the list .
#<struct ReadData::Alignment source_numbers="28", target_numbers="", tag_name="wa">
This score is used to form a ranked list , in which faces having high density scores are considered relevant and are put at the top of the list .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
This score is used to form a ranked list , in which faces having high density scores are considered relevant and are put at the top of the list .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
This subset is then used to train a classifier using supervised methods such as support vector machine ( SVM ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
To get the final strong classifier , we use the idea of ensemble learning \CITE in which weak classifiers trained on different subsets are combined to improve the stability and classification accuracy of single classifiers .
#<struct ReadData::Alignment source_numbers="1,2", target_numbers="1,2", tag_name="wa">
To get the final strong classifier , we use the idea of ensemble learning \CITE in which weak classifiers trained on different subsets are combined to improve the stability and classification accuracy of single classifiers .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
To get the final strong classifier , we use the idea of ensemble learning \CITE in which weak classifiers trained on different subsets are combined to improve the stability and classification accuracy of single classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
To get the final strong classifier , we use the idea of ensemble learning \CITE in which weak classifiers trained on different subsets are combined to improve the stability and classification accuracy of single classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
To get the final strong classifier , we use the idea of ensemble learning \CITE in which weak classifiers trained on different subsets are combined to improve the stability and classification accuracy of single classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
The framework seamlessly integrates data mining techniques such as supervised learning , and unsupervised learning based on bagging .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
We demonstrate its feasibility of a practical web mining application .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
We demonstrate its feasibility of a practical web mining application .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
A comprehensive evaluation on a large face dataset of many people was carried out and it confirmed that our approach is promising .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
For examples , as described in \CITE , [Reference numbers generally should not be grammatically part of the sentence .
#<struct ReadData::Alignment source_numbers="4,5", target_numbers="4,5", tag_name="wa">
For examples , as described in \CITE , [Reference numbers generally should not be grammatically part of the sentence .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
For examples , as described in \CITE , [Reference numbers generally should not be grammatically part of the sentence .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
For examples , as described in \CITE , [Reference numbers generally should not be grammatically part of the sentence .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
It is better to use the authors�f names .]objects retrieved by an image search engine are re-ranked by extending the constellation model .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
It is better to use the authors�f names .]objects retrieved by an image search engine are re-ranked by extending the constellation model .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
It is better to use the authors�f names .]objects retrieved by an image search engine are re-ranked by extending the constellation model .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
It is better to use the authors�f names .]objects retrieved by an image search engine are re-ranked by extending the constellation model .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
It is better to use the authors�f names .]objects retrieved by an image search engine are re-ranked by extending the constellation model .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
However , these models are complicated , since they require several hundred parameters for learning , and they are susceptible to over-fitting .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
However , these models are complicated , since they require several hundred parameters for learning , and they are susceptible to over-fitting .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
However , these models are complicated , since they require several hundred parameters for learning , and they are susceptible to over-fitting .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
Although the result was impressive , it is not easy to apply it to our problem since it is based on a strong assumption that requires a perfect alignment in the case that the news photo only has one face and its caption only has one name .
#<struct ReadData::Alignment source_numbers="29", target_numbers="", tag_name="wa">
Although the result was impressive , it is not easy to apply it to our problem since it is based on a strong assumption that requires a perfect alignment in the case that the news photo only has one face and its caption only has one name .
#<struct ReadData::Alignment source_numbers="30", target_numbers="", tag_name="wa">
Although the result was impressive , it is not easy to apply it to our problem since it is based on a strong assumption that requires a perfect alignment in the case that the news photo only has one face and its caption only has one name .
#<struct ReadData::Alignment source_numbers="31", target_numbers="", tag_name="wa">
Although the result was impressive , it is not easy to apply it to our problem since it is based on a strong assumption that requires a perfect alignment in the case that the news photo only has one face and its caption only has one name .
#<struct ReadData::Alignment source_numbers="32", target_numbers="", tag_name="wa">
Although the result was impressive , it is not easy to apply it to our problem since it is based on a strong assumption that requires a perfect alignment in the case that the news photo only has one face and its caption only has one name .
#<struct ReadData::Alignment source_numbers="33", target_numbers="", tag_name="wa">
Although the result was impressive , it is not easy to apply it to our problem since it is based on a strong assumption that requires a perfect alignment in the case that the news photo only has one face and its caption only has one name .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
A graph-based approach was proposed by \CITE , in which a graph is formed by faces as nodes , and the weights of edges linked between nodes are the similarity of faces , is closely related to our problem .
#<struct ReadData::Alignment source_numbers="19", target_numbers="7", tag_name="wa">
A graph-based approach was proposed by \CITE , in which a graph is formed by faces as nodes , and the weights of edges linked between nodes are the similarity of faces , is closely related to our problem .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
A graph-based approach was proposed by \CITE , in which a graph is formed by faces as nodes , and the weights of edges linked between nodes are the similarity of faces , is closely related to our problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
A graph-based approach was proposed by \CITE , in which a graph is formed by faces as nodes , and the weights of edges linked between nodes are the similarity of faces , is closely related to our problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
A graph-based approach was proposed by \CITE , in which a graph is formed by faces as nodes , and the weights of edges linked between nodes are the similarity of faces , is closely related to our problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
A graph-based approach was proposed by \CITE , in which a graph is formed by faces as nodes , and the weights of edges linked between nodes are the similarity of faces , is closely related to our problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
Assuming that the number of faces of the queried person is larger than that of others and that these faces tend to form the most similar subset among the set of retrieved faces , this problem is considered equal to the problem of finding the densest subgraph of a full graph ; and therefore can be solved by taking an available solution .[It might be unclear as to what " available solution " you are talking about .
#<struct ReadData::Alignment source_numbers="77", target_numbers="63", tag_name="wa">
Assuming that the number of faces of the queried person is larger than that of others and that these faces tend to form the most similar subset among the set of retrieved faces , this problem is considered equal to the problem of finding the densest subgraph of a full graph ; and therefore can be solved by taking an available solution .[It might be unclear as to what " available solution " you are talking about .
#<struct ReadData::Alignment source_numbers="62", target_numbers="", tag_name="wa">
Assuming that the number of faces of the queried person is larger than that of others and that these faces tend to form the most similar subset among the set of retrieved faces , this problem is considered equal to the problem of finding the densest subgraph of a full graph ; and therefore can be solved by taking an available solution .[It might be unclear as to what " available solution " you are talking about .
#<struct ReadData::Alignment source_numbers="", target_numbers="55", tag_name="wa">
Assuming that the number of faces of the queried person is larger than that of others and that these faces tend to form the most similar subset among the set of retrieved faces , this problem is considered equal to the problem of finding the densest subgraph of a full graph ; and therefore can be solved by taking an available solution .[It might be unclear as to what " available solution " you are talking about .
#<struct ReadData::Alignment source_numbers="", target_numbers="64", tag_name="wa">
Assuming that the number of faces of the queried person is larger than that of others and that these faces tend to form the most similar subset among the set of retrieved faces , this problem is considered equal to the problem of finding the densest subgraph of a full graph ; and therefore can be solved by taking an available solution .[It might be unclear as to what " available solution " you are talking about .
#<struct ReadData::Alignment source_numbers="", target_numbers="79", tag_name="wa">
Assuming that the number of faces of the queried person is larger than that of others and that these faces tend to form the most similar subset among the set of retrieved faces , this problem is considered equal to the problem of finding the densest subgraph of a full graph ; and therefore can be solved by taking an available solution .[It might be unclear as to what " available solution " you are talking about .
#<struct ReadData::Alignment source_numbers="", target_numbers="80", tag_name="wa">
Assuming that the number of faces of the queried person is larger than that of others and that these faces tend to form the most similar subset among the set of retrieved faces , this problem is considered equal to the problem of finding the densest subgraph of a full graph ; and therefore can be solved by taking an available solution .[It might be unclear as to what " available solution " you are talking about .
#<struct ReadData::Alignment source_numbers="", target_numbers="81", tag_name="wa">
Assuming that the number of faces of the queried person is larger than that of others and that these faces tend to form the most similar subset among the set of retrieved faces , this problem is considered equal to the problem of finding the densest subgraph of a full graph ; and therefore can be solved by taking an available solution .[It might be unclear as to what " available solution " you are talking about .
#<struct ReadData::Alignment source_numbers="", target_numbers="82", tag_name="wa">
Assuming that the number of faces of the queried person is larger than that of others and that these faces tend to form the most similar subset among the set of retrieved faces , this problem is considered equal to the problem of finding the densest subgraph of a full graph ; and therefore can be solved by taking an available solution .[It might be unclear as to what " available solution " you are talking about .
#<struct ReadData::Alignment source_numbers="", target_numbers="83", tag_name="wa">
Assuming that the number of faces of the queried person is larger than that of others and that these faces tend to form the most similar subset among the set of retrieved faces , this problem is considered equal to the problem of finding the densest subgraph of a full graph ; and therefore can be solved by taking an available solution .[It might be unclear as to what " available solution " you are talking about .
#<struct ReadData::Alignment source_numbers="", target_numbers="84", tag_name="wa">
Assuming that the number of faces of the queried person is larger than that of others and that these faces tend to form the most similar subset among the set of retrieved faces , this problem is considered equal to the problem of finding the densest subgraph of a full graph ; and therefore can be solved by taking an available solution .[It might be unclear as to what " available solution " you are talking about .
#<struct ReadData::Alignment source_numbers="", target_numbers="85", tag_name="wa">
Assuming that the number of faces of the queried person is larger than that of others and that these faces tend to form the most similar subset among the set of retrieved faces , this problem is considered equal to the problem of finding the densest subgraph of a full graph ; and therefore can be solved by taking an available solution .[It might be unclear as to what " available solution " you are talking about .
#<struct ReadData::Alignment source_numbers="", target_numbers="86", tag_name="wa">
Assuming that the number of faces of the queried person is larger than that of others and that these faces tend to form the most similar subset among the set of retrieved faces , this problem is considered equal to the problem of finding the densest subgraph of a full graph ; and therefore can be solved by taking an available solution .[It might be unclear as to what " available solution " you are talking about .
#<struct ReadData::Alignment source_numbers="", target_numbers="87", tag_name="wa">
Assuming that the number of faces of the queried person is larger than that of others and that these faces tend to form the most similar subset among the set of retrieved faces , this problem is considered equal to the problem of finding the densest subgraph of a full graph ; and therefore can be solved by taking an available solution .[It might be unclear as to what " available solution " you are talking about .
#<struct ReadData::Alignment source_numbers="", target_numbers="88", tag_name="wa">
You might want to give more detail here .] Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person and it is easy to extend for the ranking problem .
#<struct ReadData::Alignment source_numbers="9", target_numbers="0", tag_name="wa">
You might want to give more detail here .] Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person and it is easy to extend for the ranking problem .
#<struct ReadData::Alignment source_numbers="11", target_numbers="1", tag_name="wa">
You might want to give more detail here .] Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person and it is easy to extend for the ranking problem .
#<struct ReadData::Alignment source_numbers="12", target_numbers="2", tag_name="wa">
You might want to give more detail here .] Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person and it is easy to extend for the ranking problem .
#<struct ReadData::Alignment source_numbers="13", target_numbers="3", tag_name="wa">
You might want to give more detail here .] Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person and it is easy to extend for the ranking problem .
#<struct ReadData::Alignment source_numbers="14", target_numbers="4", tag_name="wa">
You might want to give more detail here .] Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person and it is easy to extend for the ranking problem .
#<struct ReadData::Alignment source_numbers="15", target_numbers="5", tag_name="wa">
You might want to give more detail here .] Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person and it is easy to extend for the ranking problem .
#<struct ReadData::Alignment source_numbers="16", target_numbers="6", tag_name="wa">
You might want to give more detail here .] Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person and it is easy to extend for the ranking problem .
#<struct ReadData::Alignment source_numbers="17", target_numbers="7", tag_name="wa">
You might want to give more detail here .] Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person and it is easy to extend for the ranking problem .
#<struct ReadData::Alignment source_numbers="18", target_numbers="8", tag_name="wa">
You might want to give more detail here .] Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person and it is easy to extend for the ranking problem .
#<struct ReadData::Alignment source_numbers="19", target_numbers="9", tag_name="wa">
You might want to give more detail here .] Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person and it is easy to extend for the ranking problem .
#<struct ReadData::Alignment source_numbers="20", target_numbers="10", tag_name="wa">
You might want to give more detail here .] Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person and it is easy to extend for the ranking problem .
#<struct ReadData::Alignment source_numbers="21", target_numbers="11", tag_name="wa">
You might want to give more detail here .] Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person and it is easy to extend for the ranking problem .
#<struct ReadData::Alignment source_numbers="22", target_numbers="12", tag_name="wa">
You might want to give more detail here .] Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person and it is easy to extend for the ranking problem .
#<struct ReadData::Alignment source_numbers="23", target_numbers="13", tag_name="wa">
You might want to give more detail here .] Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person and it is easy to extend for the ranking problem .
#<struct ReadData::Alignment source_numbers="24", target_numbers="14", tag_name="wa">
You might want to give more detail here .] Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person and it is easy to extend for the ranking problem .
#<struct ReadData::Alignment source_numbers="25", target_numbers="15", tag_name="wa">
You might want to give more detail here .] Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person and it is easy to extend for the ranking problem .
#<struct ReadData::Alignment source_numbers="26", target_numbers="16", tag_name="wa">
You might want to give more detail here .] Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person and it is easy to extend for the ranking problem .
#<struct ReadData::Alignment source_numbers="27", target_numbers="17", tag_name="wa">
You might want to give more detail here .] Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person and it is easy to extend for the ranking problem .
#<struct ReadData::Alignment source_numbers="28", target_numbers="18", tag_name="wa">
You might want to give more detail here .] Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person and it is easy to extend for the ranking problem .
#<struct ReadData::Alignment source_numbers="29", target_numbers="19", tag_name="wa">
You might want to give more detail here .] Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person and it is easy to extend for the ranking problem .
#<struct ReadData::Alignment source_numbers="30", target_numbers="20", tag_name="wa">
You might want to give more detail here .] Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person and it is easy to extend for the ranking problem .
#<struct ReadData::Alignment source_numbers="31", target_numbers="21", tag_name="wa">
You might want to give more detail here .] Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person and it is easy to extend for the ranking problem .
#<struct ReadData::Alignment source_numbers="45", target_numbers="22", tag_name="wa">
You might want to give more detail here .] Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person and it is easy to extend for the ranking problem .
#<struct ReadData::Alignment source_numbers="32", target_numbers="23", tag_name="wa">
You might want to give more detail here .] Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person and it is easy to extend for the ranking problem .
#<struct ReadData::Alignment source_numbers="33", target_numbers="24", tag_name="wa">
You might want to give more detail here .] Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person and it is easy to extend for the ranking problem .
#<struct ReadData::Alignment source_numbers="34", target_numbers="25", tag_name="wa">
You might want to give more detail here .] Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person and it is easy to extend for the ranking problem .
#<struct ReadData::Alignment source_numbers="35", target_numbers="26", tag_name="wa">
You might want to give more detail here .] Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person and it is easy to extend for the ranking problem .
#<struct ReadData::Alignment source_numbers="36", target_numbers="27", tag_name="wa">
You might want to give more detail here .] Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person and it is easy to extend for the ranking problem .
#<struct ReadData::Alignment source_numbers="37", target_numbers="28", tag_name="wa">
You might want to give more detail here .] Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person and it is easy to extend for the ranking problem .
#<struct ReadData::Alignment source_numbers="38", target_numbers="29", tag_name="wa">
You might want to give more detail here .] Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person and it is easy to extend for the ranking problem .
#<struct ReadData::Alignment source_numbers="39", target_numbers="30", tag_name="wa">
You might want to give more detail here .] Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person and it is easy to extend for the ranking problem .
#<struct ReadData::Alignment source_numbers="40", target_numbers="31", tag_name="wa">
You might want to give more detail here .] Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person and it is easy to extend for the ranking problem .
#<struct ReadData::Alignment source_numbers="41", target_numbers="32", tag_name="wa">
You might want to give more detail here .] Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person and it is easy to extend for the ranking problem .
#<struct ReadData::Alignment source_numbers="42", target_numbers="33", tag_name="wa">
You might want to give more detail here .] Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person and it is easy to extend for the ranking problem .
#<struct ReadData::Alignment source_numbers="43", target_numbers="34", tag_name="wa">
You might want to give more detail here .] Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person and it is easy to extend for the ranking problem .
#<struct ReadData::Alignment source_numbers="44", target_numbers="35", tag_name="wa">
You might want to give more detail here .] Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person and it is easy to extend for the ranking problem .
#<struct ReadData::Alignment source_numbers="46", target_numbers="37", tag_name="wa">
You might want to give more detail here .] Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person and it is easy to extend for the ranking problem .
#<struct ReadData::Alignment source_numbers="47", target_numbers="38", tag_name="wa">
You might want to give more detail here .] Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person and it is easy to extend for the ranking problem .
#<struct ReadData::Alignment source_numbers="48", target_numbers="39", tag_name="wa">
You might want to give more detail here .] Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person and it is easy to extend for the ranking problem .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
You might want to give more detail here .] Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person and it is easy to extend for the ranking problem .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
You might want to give more detail here .] Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person and it is easy to extend for the ranking problem .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
You might want to give more detail here .] Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person and it is easy to extend for the ranking problem .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
You might want to give more detail here .] Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person and it is easy to extend for the ranking problem .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
You might want to give more detail here .] Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person and it is easy to extend for the ranking problem .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
You might want to give more detail here .] Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person and it is easy to extend for the ranking problem .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
You might want to give more detail here .] Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person and it is easy to extend for the ranking problem .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
You might want to give more detail here .] Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person and it is easy to extend for the ranking problem .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
You might want to give more detail here .] Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person and it is easy to extend for the ranking problem .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
You might want to give more detail here .] Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person and it is easy to extend for the ranking problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
Furthermore , choosing an optimal threshold to convert the initial graph into a binary graph is difficult and rather ad hoc due to the curse of dimensionality .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
Furthermore , choosing an optimal threshold to convert the initial graph into a binary graph is difficult and rather ad hoc due to the curse of dimensionality .
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
Furthermore , choosing an optimal threshold to convert the initial graph into a binary graph is difficult and rather ad hoc due to the curse of dimensionality .
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
Furthermore , choosing an optimal threshold to convert the initial graph into a binary graph is difficult and rather ad hoc due to the curse of dimensionality .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
Furthermore , choosing an optimal threshold to convert the initial graph into a binary graph is difficult and rather ad hoc due to the curse of dimensionality .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
The good point of the methods \CITE is they are fully unsupervised .
#<struct ReadData::Alignment source_numbers="4,5", target_numbers="3,4", tag_name="wa">
The good point of the methods \CITE is they are fully unsupervised .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
The good point of the methods \CITE is they are fully unsupervised .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
The good point of the methods \CITE is they are fully unsupervised .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
The good point of the methods \CITE is they are fully unsupervised .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
The good point of the methods \CITE is they are fully unsupervised .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
However , the bad point is no model is learned to predict new images of the same category .
#<struct ReadData::Alignment source_numbers="10,11", target_numbers="11", tag_name="wa">
However , the bad point is no model is learned to predict new images of the same category .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
However , the bad point is no model is learned to predict new images of the same category .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
However , the bad point is no model is learned to predict new images of the same category .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
However , the bad point is no model is learned to predict new images of the same category .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
However , the bad point is no model is learned to predict new images of the same category .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
However , the bad point is no model is learned to predict new images of the same category .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
However , the bad point is no model is learned to predict new images of the same category .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Furthermore , they perform hard categorization on input images that is [It is not clear if " hard categorization " is inapplicable or if the " input images " are inapplicable .]in applicable for re-ranking .
#<struct ReadData::Alignment source_numbers="29", target_numbers="3", tag_name="wa">
Furthermore , they perform hard categorization on input images that is [It is not clear if " hard categorization " is inapplicable or if the " input images " are inapplicable .]in applicable for re-ranking .
#<struct ReadData::Alignment source_numbers="33", target_numbers="5", tag_name="wa">
Furthermore , they perform hard categorization on input images that is [It is not clear if " hard categorization " is inapplicable or if the " input images " are inapplicable .]in applicable for re-ranking .
#<struct ReadData::Alignment source_numbers="3", target_numbers="6", tag_name="wa">
Furthermore , they perform hard categorization on input images that is [It is not clear if " hard categorization " is inapplicable or if the " input images " are inapplicable .]in applicable for re-ranking .
#<struct ReadData::Alignment source_numbers="10", target_numbers="13", tag_name="wa">
Furthermore , they perform hard categorization on input images that is [It is not clear if " hard categorization " is inapplicable or if the " input images " are inapplicable .]in applicable for re-ranking .
#<struct ReadData::Alignment source_numbers="30", target_numbers="14", tag_name="wa">
Furthermore , they perform hard categorization on input images that is [It is not clear if " hard categorization " is inapplicable or if the " input images " are inapplicable .]in applicable for re-ranking .
#<struct ReadData::Alignment source_numbers="34", target_numbers="16", tag_name="wa">
Furthermore , they perform hard categorization on input images that is [It is not clear if " hard categorization " is inapplicable or if the " input images " are inapplicable .]in applicable for re-ranking .
#<struct ReadData::Alignment source_numbers="35", target_numbers="17", tag_name="wa">
Furthermore , they perform hard categorization on input images that is [It is not clear if " hard categorization " is inapplicable or if the " input images " are inapplicable .]in applicable for re-ranking .
#<struct ReadData::Alignment source_numbers="12", target_numbers="19", tag_name="wa">
Furthermore , they perform hard categorization on input images that is [It is not clear if " hard categorization " is inapplicable or if the " input images " are inapplicable .]in applicable for re-ranking .
#<struct ReadData::Alignment source_numbers="13", target_numbers="20", tag_name="wa">
Furthermore , they perform hard categorization on input images that is [It is not clear if " hard categorization " is inapplicable or if the " input images " are inapplicable .]in applicable for re-ranking .
#<struct ReadData::Alignment source_numbers="14", target_numbers="21", tag_name="wa">
Furthermore , they perform hard categorization on input images that is [It is not clear if " hard categorization " is inapplicable or if the " input images " are inapplicable .]in applicable for re-ranking .
#<struct ReadData::Alignment source_numbers="15", target_numbers="22", tag_name="wa">
Furthermore , they perform hard categorization on input images that is [It is not clear if " hard categorization " is inapplicable or if the " input images " are inapplicable .]in applicable for re-ranking .
#<struct ReadData::Alignment source_numbers="16", target_numbers="23", tag_name="wa">
Furthermore , they perform hard categorization on input images that is [It is not clear if " hard categorization " is inapplicable or if the " input images " are inapplicable .]in applicable for re-ranking .
#<struct ReadData::Alignment source_numbers="17", target_numbers="24", tag_name="wa">
Furthermore , they perform hard categorization on input images that is [It is not clear if " hard categorization " is inapplicable or if the " input images " are inapplicable .]in applicable for re-ranking .
#<struct ReadData::Alignment source_numbers="18", target_numbers="25", tag_name="wa">
Furthermore , they perform hard categorization on input images that is [It is not clear if " hard categorization " is inapplicable or if the " input images " are inapplicable .]in applicable for re-ranking .
#<struct ReadData::Alignment source_numbers="19", target_numbers="26", tag_name="wa">
Furthermore , they perform hard categorization on input images that is [It is not clear if " hard categorization " is inapplicable or if the " input images " are inapplicable .]in applicable for re-ranking .
#<struct ReadData::Alignment source_numbers="20", target_numbers="27", tag_name="wa">
Furthermore , they perform hard categorization on input images that is [It is not clear if " hard categorization " is inapplicable or if the " input images " are inapplicable .]in applicable for re-ranking .
#<struct ReadData::Alignment source_numbers="21", target_numbers="28", tag_name="wa">
Furthermore , they perform hard categorization on input images that is [It is not clear if " hard categorization " is inapplicable or if the " input images " are inapplicable .]in applicable for re-ranking .
#<struct ReadData::Alignment source_numbers="22", target_numbers="29", tag_name="wa">
Furthermore , they perform hard categorization on input images that is [It is not clear if " hard categorization " is inapplicable or if the " input images " are inapplicable .]in applicable for re-ranking .
#<struct ReadData::Alignment source_numbers="23", target_numbers="30", tag_name="wa">
Furthermore , they perform hard categorization on input images that is [It is not clear if " hard categorization " is inapplicable or if the " input images " are inapplicable .]in applicable for re-ranking .
#<struct ReadData::Alignment source_numbers="24", target_numbers="31", tag_name="wa">
Furthermore , they perform hard categorization on input images that is [It is not clear if " hard categorization " is inapplicable or if the " input images " are inapplicable .]in applicable for re-ranking .
#<struct ReadData::Alignment source_numbers="25", target_numbers="32", tag_name="wa">
Furthermore , they perform hard categorization on input images that is [It is not clear if " hard categorization " is inapplicable or if the " input images " are inapplicable .]in applicable for re-ranking .
#<struct ReadData::Alignment source_numbers="26", target_numbers="33", tag_name="wa">
Furthermore , they perform hard categorization on input images that is [It is not clear if " hard categorization " is inapplicable or if the " input images " are inapplicable .]in applicable for re-ranking .
#<struct ReadData::Alignment source_numbers="27", target_numbers="34", tag_name="wa">
Furthermore , they perform hard categorization on input images that is [It is not clear if " hard categorization " is inapplicable or if the " input images " are inapplicable .]in applicable for re-ranking .
#<struct ReadData::Alignment source_numbers="28", target_numbers="35", tag_name="wa">
Furthermore , they perform hard categorization on input images that is [It is not clear if " hard categorization " is inapplicable or if the " input images " are inapplicable .]in applicable for re-ranking .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
Furthermore , they perform hard categorization on input images that is [It is not clear if " hard categorization " is inapplicable or if the " input images " are inapplicable .]in applicable for re-ranking .
#<struct ReadData::Alignment source_numbers="31", target_numbers="", tag_name="wa">
Furthermore , they perform hard categorization on input images that is [It is not clear if " hard categorization " is inapplicable or if the " input images " are inapplicable .]in applicable for re-ranking .
#<struct ReadData::Alignment source_numbers="32", target_numbers="", tag_name="wa">
Furthermore , they perform hard categorization on input images that is [It is not clear if " hard categorization " is inapplicable or if the " input images " are inapplicable .]in applicable for re-ranking .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Furthermore , they perform hard categorization on input images that is [It is not clear if " hard categorization " is inapplicable or if the " input images " are inapplicable .]in applicable for re-ranking .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
Furthermore , they perform hard categorization on input images that is [It is not clear if " hard categorization " is inapplicable or if the " input images " are inapplicable .]in applicable for re-ranking .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
Furthermore , they perform hard categorization on input images that is [It is not clear if " hard categorization " is inapplicable or if the " input images " are inapplicable .]in applicable for re-ranking .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
Furthermore , they perform hard categorization on input images that is [It is not clear if " hard categorization " is inapplicable or if the " input images " are inapplicable .]in applicable for re-ranking .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
Furthermore , they perform hard categorization on input images that is [It is not clear if " hard categorization " is inapplicable or if the " input images " are inapplicable .]in applicable for re-ranking .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
This leads the number of collected images is reduced .
#<struct ReadData::Alignment source_numbers="8", target_numbers="3,4", tag_name="wa">
This leads the number of collected images is reduced .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
This leads the number of collected images is reduced .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
This leads the number of collected images is reduced .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
However , different from the methods in \cite{xx} , we used an unsupervised method to select training samples automaticallyCITE .
#<struct ReadData::Alignment source_numbers="9", target_numbers="2", tag_name="wa">
However , different from the methods in \cite{xx} , we used an unsupervised method to select training samples automaticallyCITE .
#<struct ReadData::Alignment source_numbers="10", target_numbers="3", tag_name="wa">
However , different from the methods in \cite{xx} , we used an unsupervised method to select training samples automaticallyCITE .
#<struct ReadData::Alignment source_numbers="11", target_numbers="4", tag_name="wa">
However , different from the methods in \cite{xx} , we used an unsupervised method to select training samples automaticallyCITE .
#<struct ReadData::Alignment source_numbers="12", target_numbers="5", tag_name="wa">
However , different from the methods in \cite{xx} , we used an unsupervised method to select training samples automaticallyCITE .
#<struct ReadData::Alignment source_numbers="13", target_numbers="6", tag_name="wa">
However , different from the methods in \cite{xx} , we used an unsupervised method to select training samples automaticallyCITE .
#<struct ReadData::Alignment source_numbers="14", target_numbers="7", tag_name="wa">
However , different from the methods in \cite{xx} , we used an unsupervised method to select training samples automaticallyCITE .
#<struct ReadData::Alignment source_numbers="15", target_numbers="8", tag_name="wa">
However , different from the methods in \cite{xx} , we used an unsupervised method to select training samples automaticallyCITE .
#<struct ReadData::Alignment source_numbers="16", target_numbers="9", tag_name="wa">
However , different from the methods in \cite{xx} , we used an unsupervised method to select training samples automaticallyCITE .
#<struct ReadData::Alignment source_numbers="17", target_numbers="10", tag_name="wa">
However , different from the methods in \cite{xx} , we used an unsupervised method to select training samples automaticallyCITE .
#<struct ReadData::Alignment source_numbers="8", target_numbers="12", tag_name="wa">
However , different from the methods in \cite{xx} , we used an unsupervised method to select training samples automaticallyCITE .
#<struct ReadData::Alignment source_numbers="2", target_numbers="15", tag_name="wa">
However , different from the methods in \cite{xx} , we used an unsupervised method to select training samples automaticallyCITE .
#<struct ReadData::Alignment source_numbers="3", target_numbers="16", tag_name="wa">
However , different from the methods in \cite{xx} , we used an unsupervised method to select training samples automaticallyCITE .
#<struct ReadData::Alignment source_numbers="4", target_numbers="17", tag_name="wa">
However , different from the methods in \cite{xx} , we used an unsupervised method to select training samples automaticallyCITE .
#<struct ReadData::Alignment source_numbers="5", target_numbers="18", tag_name="wa">
However , different from the methods in \cite{xx} , we used an unsupervised method to select training samples automaticallyCITE .
#<struct ReadData::Alignment source_numbers="19", target_numbers="29", tag_name="wa">
However , different from the methods in \cite{xx} , we used an unsupervised method to select training samples automaticallyCITE .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
However , different from the methods in \cite{xx} , we used an unsupervised method to select training samples automaticallyCITE .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
However , different from the methods in \cite{xx} , we used an unsupervised method to select training samples automaticallyCITE .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
However , different from the methods in \cite{xx} , we used an unsupervised method to select training samples automaticallyCITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
However , different from the methods in \cite{xx} , we used an unsupervised method to select training samples automaticallyCITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
However , different from the methods in \cite{xx} , we used an unsupervised method to select training samples automaticallyCITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
However , different from the methods in \cite{xx} , we used an unsupervised method to select training samples automaticallyCITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
However , different from the methods in \cite{xx} , we used an unsupervised method to select training samples automaticallyCITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
However , different from the methods in \cite{xx} , we used an unsupervised method to select training samples automaticallyCITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
However , different from the methods in \cite{xx} , we used an unsupervised method to select training samples automaticallyCITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
However , different from the methods in \cite{xx} , we used an unsupervised method to select training samples automaticallyCITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
However , different from the methods in \cite{xx} , we used an unsupervised method to select training samples automaticallyCITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
However , different from the methods in \cite{xx} , we used an unsupervised method to select training samples automaticallyCITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
However , different from the methods in \cite{xx} , we used an unsupervised method to select training samples automaticallyCITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
However , different from the methods in \cite{xx} , we used an unsupervised method to select training samples automaticallyCITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
However , different from the methods in \cite{xx} , we used an unsupervised method to select training samples automaticallyCITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
This unsupervised method is different from the one in \CITE in its way of modeling the distribution of relevant images .
#<struct ReadData::Alignment source_numbers="14", target_numbers="15", tag_name="wa">
This unsupervised method is different from the one in \CITE in its way of modeling the distribution of relevant images .
#<struct ReadData::Alignment source_numbers="13", target_numbers="16", tag_name="wa">
This unsupervised method is different from the one in \CITE in its way of modeling the distribution of relevant images .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
This unsupervised method is different from the one in \CITE in its way of modeling the distribution of relevant images .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
This unsupervised method is different from the one in \CITE in its way of modeling the distribution of relevant images .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
This unsupervised method is different from the one in \CITE in its way of modeling the distribution of relevant images .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
This unsupervised method is different from the one in \CITE in its way of modeling the distribution of relevant images .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
This unsupervised method is different from the one in \CITE in its way of modeling the distribution of relevant images .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
This unsupervised method is different from the one in \CITE in its way of modeling the distribution of relevant images .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
This unsupervised method is different from the one in \CITE in its way of modeling the distribution of relevant images .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
-Step 3 : Estimate the ranked list of these faces by Rank-By-Local-Density-Score .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
-Step 3 : Estimate the ranked list of these faces by Rank-By-Local-Density-Score .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
-Step 3 : Estimate the ranked list of these faces by Rank-By-Local-Density-Score .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
-Step 4 : Improve this ranked list by Rank-By-Bagging-ProbSVM . //I found not hits for " rank-by-bagging-probSVM " on the Internet . You might want to double check to see if this is a standard term . The same is true for " rank-by-local-density score " . If this is your own term , you might want to specify this at some point .
#<struct ReadData::Alignment source_numbers="16", target_numbers="8", tag_name="wa">
-Step 4 : Improve this ranked list by Rank-By-Bagging-ProbSVM . //I found not hits for " rank-by-bagging-probSVM " on the Internet . You might want to double check to see if this is a standard term . The same is true for " rank-by-local-density score " . If this is your own term , you might want to specify this at some point .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
-Step 4 : Improve this ranked list by Rank-By-Bagging-ProbSVM . //I found not hits for " rank-by-bagging-probSVM " on the Internet . You might want to double check to see if this is a standard term . The same is true for " rank-by-local-density score " . If this is your own term , you might want to specify this at some point .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
-Step 4 : Improve this ranked list by Rank-By-Bagging-ProbSVM . //I found not hits for " rank-by-bagging-probSVM " on the Internet . You might want to double check to see if this is a standard term . The same is true for " rank-by-local-density score " . If this is your own term , you might want to specify this at some point .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
-Step 4 : Improve this ranked list by Rank-By-Bagging-ProbSVM . //I found not hits for " rank-by-bagging-probSVM " on the Internet . You might want to double check to see if this is a standard term . The same is true for " rank-by-local-density score " . If this is your own term , you might want to specify this at some point .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
-Step 4 : Improve this ranked list by Rank-By-Bagging-ProbSVM . //I found not hits for " rank-by-bagging-probSVM " on the Internet . You might want to double check to see if this is a standard term . The same is true for " rank-by-local-density score " . If this is your own term , you might want to specify this at some point .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
-Step 4 : Improve this ranked list by Rank-By-Bagging-ProbSVM . //I found not hits for " rank-by-bagging-probSVM " on the Internet . You might want to double check to see if this is a standard term . The same is true for " rank-by-local-density score " . If this is your own term , you might want to specify this at some point .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
-Step 4 : Improve this ranked list by Rank-By-Bagging-ProbSVM . //I found not hits for " rank-by-bagging-probSVM " on the Internet . You might want to double check to see if this is a standard term . The same is true for " rank-by-local-density score " . If this is your own term , you might want to specify this at some point .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
The algorithms used in Step 3 and Step 4 are described in section \REF and section \REF .
#<struct ReadData::Alignment source_numbers="4", target_numbers="4", tag_name="wa">
The algorithms used in Step 3 and Step 4 are described in section \REF and section \REF .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
The algorithms used in Step 3 and Step 4 are described in section \REF and section \REF .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
The algorithms used in Step 3 and Step 4 are described in section \REF and section \REF .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Among the faces retrieved by the text-based search engines for a query of person-\MATH , as shown in Figure \REF , relevant faces usually look similar and can form the largest cluster .
#<struct ReadData::Alignment source_numbers="28", target_numbers="26", tag_name="wa">
Among the faces retrieved by the text-based search engines for a query of person-\MATH , as shown in Figure \REF , relevant faces usually look similar and can form the largest cluster .
#<struct ReadData::Alignment source_numbers="27", target_numbers="", tag_name="wa">
One approach to re-rank these faces is to do clustering based on visual similarity .
#<struct ReadData::Alignment source_numbers="1,2", target_numbers="1,2", tag_name="wa">
One approach to re-rank these faces is to do clustering based on visual similarity .
#<struct ReadData::Alignment source_numbers="3", target_numbers="3", tag_name="wa">
One approach to re-rank these faces is to do clustering based on visual similarity .
#<struct ReadData::Alignment source_numbers="9", target_numbers="8", tag_name="wa">
One approach to re-rank these faces is to do clustering based on visual similarity .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
However , to get ideal clustering result is impossible , since these faces are high dimensional data and the clusters are in different shapes , sizes and densities .
#<struct ReadData::Alignment source_numbers="9", target_numbers="25", tag_name="wa">
Instead , in \cite{xx} , a graph based approach was proposed CITEin which the nodes are faces and edge weights are the similarities between two faces .
#<struct ReadData::Alignment source_numbers="2", target_numbers="12", tag_name="wa">
Instead , in \cite{xx} , a graph based approach was proposed CITEin which the nodes are faces and edge weights are the similarities between two faces .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
Instead , in \cite{xx} , a graph based approach was proposed CITEin which the nodes are faces and edge weights are the similarities between two faces .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
Instead , in \cite{xx} , a graph based approach was proposed CITEin which the nodes are faces and edge weights are the similarities between two faces .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Instead , in \cite{xx} , a graph based approach was proposed CITEin which the nodes are faces and edge weights are the similarities between two faces .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
Instead , in \cite{xx} , a graph based approach was proposed CITEin which the nodes are faces and edge weights are the similarities between two faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Instead , in \cite{xx} , a graph based approach was proposed CITEin which the nodes are faces and edge weights are the similarities between two faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Instead , in \cite{xx} , a graph based approach was proposed CITEin which the nodes are faces and edge weights are the similarities between two faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Instead , in \cite{xx} , a graph based approach was proposed CITEin which the nodes are faces and edge weights are the similarities between two faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Instead , in \cite{xx} , a graph based approach was proposed CITEin which the nodes are faces and edge weights are the similarities between two faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Instead , in \cite{xx} , a graph based approach was proposed CITEin which the nodes are faces and edge weights are the similarities between two faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
We use the idea of density-based clustering described in \CITE to solve this problem .
#<struct ReadData::Alignment source_numbers="7,8", target_numbers="7,8", tag_name="wa">
We use the idea of density-based clustering described in \CITE to solve this problem .
#<struct ReadData::Alignment source_numbers="14", target_numbers="21", tag_name="wa">
We use the idea of density-based clustering described in \CITE to solve this problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
We use the idea of density-based clustering described in \CITE to solve this problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
We use the idea of density-based clustering described in \CITE to solve this problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
We use the idea of density-based clustering described in \CITE to solve this problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
We use the idea of density-based clustering described in \CITE to solve this problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
We use the idea of density-based clustering described in \CITE to solve this problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
We use the idea of density-based clustering described in \CITE to solve this problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
We use the idea of density-based clustering described in \CITE to solve this problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
We use the idea of density-based clustering described in \CITE to solve this problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
We use the idea of density-based clustering described in \CITE to solve this problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
Specifically , we define local density score ( LDS ) of a point \MATH( i.e. a face ) as the average distance to its k-nearest neighbors :
#<struct ReadData::Alignment source_numbers="26", target_numbers="", tag_name="wa">
Specifically , we define local density score ( LDS ) of a point \MATH( i.e. a face ) as the average distance to its k-nearest neighbors :
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
Since faces are represented in high dimensional feature space , and face clusters might have different sizes , shapes and densities ; we do not use directly the Euclidean distance between two points in this feature space for \MATH .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
Since faces are represented in high dimensional feature space , and face clusters might have different sizes , shapes and densities ; we do not use directly the Euclidean distance between two points in this feature space for \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
Since faces are represented in high dimensional feature space , and face clusters might have different sizes , shapes and densities ; we do not use directly the Euclidean distance between two points in this feature space for \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
The efficiency of this similarity measure for density-based clustering methods was described . //There is no period here , so it is not clear if there should be a period or there should be more to this sentence that is not here . If the sentence does end here , you might want to go into more detail about who or what " described " this .]
#<struct ReadData::Alignment source_numbers="66", target_numbers="", tag_name="wa">
The efficiency of this similarity measure for density-based clustering methods was described . //There is no period here , so it is not clear if there should be a period or there should be more to this sentence that is not here . If the sentence does end here , you might want to go into more detail about who or what " described " this .]
#<struct ReadData::Alignment source_numbers="", target_numbers="66", tag_name="wa">
Step 2 : Rank these faces using LDS( p , k ) ( The higher the more relevant ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
Step 2 : Rank these faces using LDS( p , k ) ( The higher the more relevant ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
One limitation of the local density score based ranking is it could not handle the case that faces of another person have strong association in \MATH-neighbor set ( for example , many duplicates ) .
#<struct ReadData::Alignment source_numbers="11,12", target_numbers="11", tag_name="wa">
One limitation of the local density score based ranking is it could not handle the case that faces of another person have strong association in \MATH-neighbor set ( for example , many duplicates ) .
#<struct ReadData::Alignment source_numbers="13", target_numbers="12", tag_name="wa">
One limitation of the local density score based ranking is it could not handle the case that faces of another person have strong association in \MATH-neighbor set ( for example , many duplicates ) .
#<struct ReadData::Alignment source_numbers="22", target_numbers="17", tag_name="wa">
One limitation of the local density score based ranking is it could not handle the case that faces of another person have strong association in \MATH-neighbor set ( for example , many duplicates ) .
#<struct ReadData::Alignment source_numbers="23", target_numbers="18", tag_name="wa">
One limitation of the local density score based ranking is it could not handle the case that faces of another person have strong association in \MATH-neighbor set ( for example , many duplicates ) .
#<struct ReadData::Alignment source_numbers="14", target_numbers="20", tag_name="wa">
One limitation of the local density score based ranking is it could not handle the case that faces of another person have strong association in \MATH-neighbor set ( for example , many duplicates ) .
#<struct ReadData::Alignment source_numbers="34", target_numbers="30", tag_name="wa">
One limitation of the local density score based ranking is it could not handle the case that faces of another person have strong association in \MATH-neighbor set ( for example , many duplicates ) .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
One limitation of the local density score based ranking is it could not handle the case that faces of another person have strong association in \MATH-neighbor set ( for example , many duplicates ) .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
One limitation of the local density score based ranking is it could not handle the case that faces of another person have strong association in \MATH-neighbor set ( for example , many duplicates ) .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
This model is applied to faces of the original set and the output probabilistic scores are used to re-rank these faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Since it is not guaranteed that faces lying at two ends of the input rank list correctly correspond to the faces of person-\MATH and faces of non person-\MATH , we adopt the idea of bagging framework \CITE in which randomly selecting subsets to train weak classifiers , and then combining these classifiers help reduce the risk of using noisy training sets .
#<struct ReadData::Alignment source_numbers="32", target_numbers="", tag_name="wa">
Since it is not guaranteed that faces lying at two ends of the input rank list correctly correspond to the faces of person-\MATH and faces of non person-\MATH , we adopt the idea of bagging framework \CITE in which randomly selecting subsets to train weak classifiers , and then combining these classifiers help reduce the risk of using noisy training sets .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
Since it is not guaranteed that faces lying at two ends of the input rank list correctly correspond to the faces of person-\MATH and faces of non person-\MATH , we adopt the idea of bagging framework \CITE in which randomly selecting subsets to train weak classifiers , and then combining these classifiers help reduce the risk of using noisy training sets .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
Since it is not guaranteed that faces lying at two ends of the input rank list correctly correspond to the faces of person-\MATH and faces of non person-\MATH , we adopt the idea of bagging framework \CITE in which randomly selecting subsets to train weak classifiers , and then combining these classifiers help reduce the risk of using noisy training sets .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
Since it is not guaranteed that faces lying at two ends of the input rank list correctly correspond to the faces of person-\MATH and faces of non person-\MATH , we adopt the idea of bagging framework \CITE in which randomly selecting subsets to train weak classifiers , and then combining these classifiers help reduce the risk of using noisy training sets .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
The details of Rank-By-Bagging-ProbSVM-InnerLoop method , improving an input rank list by combining weak classifiers trained from subsets annotated by that rank list are described in Algorithm 2 .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
Step 1 : Train a weak classifier hi .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Step 1 .3 : Use S?pos and S? neg to train a weak classifier hj using LibSVM [8] with probability outputs .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Step 1 .3 : Use S?pos and S? neg to train a weak classifier hj using LibSVM [8] with probability outputs .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
Step 3 : Apply Hi to the original face set and form the rank list Ranki by using the output probabilistic scores .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
Step 3 : Apply Hi to the original face set and form the rank list Ranki by using the output probabilistic scores .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Step 4 : Repeat steps from Step 1 to Step 3 until Dist2RankList( Ranki?1 ,Ranki ) <= ? .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Step 4 : Repeat steps from Step 1 to Step 3 until Dist2RankList( Ranki?1 ,Ranki ) <= ? .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
Step 4 : Repeat steps from Step 1 to Step 3 until Dist2RankList( Ranki?1 ,Ranki ) <= ? .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Step 1 : Rankcur = Rank-By-Bagging-ProbSVM-InnerLoop( Rankprev ) .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Step 1 : Rankcur = Rank-By-Bagging-ProbSVM-InnerLoop( Rankprev ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Step 1 : Rankcur = Rank-By-Bagging-ProbSVM-InnerLoop( Rankprev ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Step 2 : dist = Dist2RankList( Rankprev ,Rankcur ) .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Step 2 : dist = Dist2RankList( Rankprev ,Rankcur ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Step 2 : dist = Dist2RankList( Rankprev ,Rankcur ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Step 5 : Repeat steps from Step 1 to Step 4 until dist <= ? .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Step 5 : Repeat steps from Step 1 to Step 4 until dist <= ? .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
Step 5 : Repeat steps from Step 1 to Step 4 until dist <= ? .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Step 5 : Return Rankfinal .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Step 5 : Return Rankfinal .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Given an input ranked list , Rank-By-Bagging-ProbSVM-InnerLoop is used to improve this rank list .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
The \MATH distance between two list \MATH and \MATH is defined as follows :
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
The \MATH distance between two list \MATH and \MATH is defined as follows :
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Since the maximum value of \MATH is \MATH where \MATH is the number of members of the list , the normalized Kendall tau distance can be written as follows :
#<struct ReadData::Alignment source_numbers="18", target_numbers="8", tag_name="wa">
Since the maximum value of \MATH is \MATH where \MATH is the number of members of the list , the normalized Kendall tau distance can be written as follows :
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
We used the dataset described in \CITE for our experiments .
#<struct ReadData::Alignment source_numbers="4,5", target_numbers="4,5", tag_name="wa">
We used the dataset described in \CITE for our experiments .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
We used the dataset described in \CITE for our experiments .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
We used the dataset described in \CITE for our experiments .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
This dataset consists of approximately half a million news [pictures / photos?] and captions from Yahoo News collected over a period of roughly two years .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
This dataset consists of approximately half a million news [pictures / photos?] and captions from Yahoo News collected over a period of roughly two years .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
This dataset consists of approximately half a million news [pictures / photos?] and captions from Yahoo News collected over a period of roughly two years .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
This dataset consists of approximately half a million news [pictures / photos?] and captions from Yahoo News collected over a period of roughly two years .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Only frontal faces were considered since current frontal face detection systems \CITE can work in real time and have accuracies exceeding 95\% .
#<struct ReadData::Alignment source_numbers="13", target_numbers="14", tag_name="wa">
Only frontal faces were considered since current frontal face detection systems \CITE can work in real time and have accuracies exceeding 95\% .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Only frontal faces were considered since current frontal face detection systems \CITE can work in real time and have accuracies exceeding 95\% .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
Only frontal faces were considered since current frontal face detection systems \CITE can work in real time and have accuracies exceeding 95\% .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Only frontal faces were considered since current frontal face detection systems \CITE can work in real time and have accuracies exceeding 95\% .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Only frontal faces were considered since current frontal face detection systems \CITE can work in real time and have accuracies exceeding 95\% .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
44 ,773 faces were detected and normalized to the size of 86\MATH86 pixels .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
44 ,773 faces were detected and normalized to the size of 86\MATH86 pixels .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
44 ,773 faces were detected and normalized to the size of 86\MATH86 pixels .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
We selected fifteen government leaders , including George W. Bush ( US ) , Vladimir Putin ( Russia ) , Ziang Jemin ( China ) , Tony Blair ( UK ) , Junichiro Koizumi ( Japan ) , Roh Moo-hyun ( Korea ) , and Abdullah Gul ( Turkey ) , and other key individuals , such as John Paul II ( the Former Pope ) and Hans Blix ( UN ) , because their images frequently appear in the dataset \CITE .
#<struct ReadData::Alignment source_numbers="44", target_numbers="", tag_name="wa">
The variations in each person 's name were collected .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
The variations in each person 's name were collected .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
We used an eye detector to detect the positions of the eyes in the detected faces .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
We used an eye detector to detect the positions of the eyes in the detected faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
The eye detector , built with the same approach as in \CITE , had an accuracy of more than 95\% .
#<struct ReadData::Alignment source_numbers="12", target_numbers="16", tag_name="wa">
The eye detector , built with the same approach as in \CITE , had an accuracy of more than 95\% .
#<struct ReadData::Alignment source_numbers="20", target_numbers="24", tag_name="wa">
The eye detector , built with the same approach as in \CITE , had an accuracy of more than 95\% .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
The eye detector , built with the same approach as in \CITE , had an accuracy of more than 95\% .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
The eye detector , built with the same approach as in \CITE , had an accuracy of more than 95\% .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
The eye detector , built with the same approach as in \CITE , had an accuracy of more than 95\% .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
The eye detector , built with the same approach as in \CITE , had an accuracy of more than 95\% .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
The eye detector , built with the same approach as in \CITE , had an accuracy of more than 95\% .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
To compensate for illumination effects , the subtraction of the bestfit brightness plane followed by histogram equalization was applied .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
To compensate for illumination effects , the subtraction of the bestfit brightness plane followed by histogram equalization was applied .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Eigenfaces were computed from the original face set returned by the text-based query method .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Eigenfaces were computed from the original face set returned by the text-based query method .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
The number of eigenfaces used to form the eigen space was selected so that 97\% of the total energy was retained \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
The number of eigenfaces used to form the eigen space was selected so that 97\% of the total energy was retained \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
The number of eigenfaces used to form the eigen space was selected so that 97\% of the total energy was retained \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
The number of eigenfaces used to form the eigen space was selected so that 97\% of the total energy was retained \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
The number of eigenfaces used to form the eigen space was selected so that 97\% of the total energy was retained \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
The number of eigenfaces used to form the eigen space was selected so that 97\% of the total energy was retained \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
The number of eigenfaces used to form the eigen space was selected so that 97\% of the total energy was retained \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
The number of eigenfaces used to form the eigen space was selected so that 97\% of the total energy was retained \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
The number of eigenfaces used to form the eigen space was selected so that 97\% of the total energy was retained \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
The number of eigenfaces used to form the eigen space was selected so that 97\% of the total energy was retained \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
The number of eigenfaces used to form the eigen space was selected so that 97\% of the total energy was retained \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
The number of eigenfaces used to form the eigen space was selected so that 97\% of the total energy was retained \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
The number of eigenfaces used to form the eigen space was selected so that 97\% of the total energy was retained \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
The number of eigenfaces used to form the eigen space was selected so that 97\% of the total energy was retained \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
The number of eigenfaces used to form the eigen space was selected so that 97\% of the total energy was retained \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
The number of eigenfaces used to form the eigen space was selected so that 97\% of the total energy was retained \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
The number of eigenfaces used to form the eigen space was selected so that 97\% of the total energy was retained \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
The number of eigenfaces used to form the eigen space was selected so that 97\% of the total energy was retained \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="40", tag_name="wa">
The number of eigenfaces used to form the eigen space was selected so that 97\% of the total energy was retained \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="41", tag_name="wa">
The number of eigenfaces used to form the eigen space was selected so that 97\% of the total energy was retained \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="42", tag_name="wa">
The number of eigenfaces used to form the eigen space was selected so that 97\% of the total energy was retained \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="43", tag_name="wa">
The number of eigenfaces used to form the eigen space was selected so that 97\% of the total energy was retained \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="44", tag_name="wa">
The number of eigenfaces used to form the eigen space was selected so that 97\% of the total energy was retained \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="45", tag_name="wa">
The number of eigenfaces used to form the eigen space was selected so that 97\% of the total energy was retained \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="46", tag_name="wa">
The number of eigenfaces used to form the eigen space was selected so that 97\% of the total energy was retained \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="47", tag_name="wa">
The number of eigenfaces used to form the eigen space was selected so that 97\% of the total energy was retained \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="48", tag_name="wa">
The number of eigenfaces used to form the eigen space was selected so that 97\% of the total energy was retained \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="49", tag_name="wa">
The number of eigenfaces used to form the eigen space was selected so that 97\% of the total energy was retained \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="50", tag_name="wa">
The number of eigenfaces used to form the eigen space was selected so that 97\% of the total energy was retained \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="51", tag_name="wa">
The number of eigenfaces used to form the eigen space was selected so that 97\% of the total energy was retained \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="52", tag_name="wa">
The number of eigenfaces used to form the eigen space was selected so that 97\% of the total energy was retained \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="53", tag_name="wa">
The number of eigenfaces used to form the eigen space was selected so that 97\% of the total energy was retained \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="54", tag_name="wa">
The number of eigenfaces used to form the eigen space was selected so that 97\% of the total energy was retained \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="55", tag_name="wa">
The number of eigenfaces used to form the eigen space was selected so that 97\% of the total energy was retained \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="56", tag_name="wa">
The number of eigenfaces used to form the eigen space was selected so that 97\% of the total energy was retained \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="57", tag_name="wa">
The number of eigenfaces used to form the eigen space was selected so that 97\% of the total energy was retained \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="58", tag_name="wa">
The number of eigenfaces used to form the eigen space was selected so that 97\% of the total energy was retained \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="59", tag_name="wa">
The number of eigenfaces used to form the eigen space was selected so that 97\% of the total energy was retained \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="60", tag_name="wa">
The number of eigenfaces used to form the eigen space was selected so that 97\% of the total energy was retained \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="61", tag_name="wa">
Precision and recall only evaluate the quality of an unordered set of retrieved faces .
#<struct ReadData::Alignment source_numbers="4", target_numbers="7", tag_name="wa">
Precision and recall only evaluate the quality of an unordered set of retrieved faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Precision and recall only evaluate the quality of an unordered set of retrieved faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Precision and recall only evaluate the quality of an unordered set of retrieved faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
-\MATH : the fraction of faces lying at the top and bottom of the ranked list that are used to form a positive set \MATH and negative set \MATH for training weak classifiers in Rank-By-Bagging-ProbSVM-InnerLoop .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
We empirically selected \MATH ( i .e 40\% samples of the rank list were used ) since larger \MATH will increase the number of incorrect labels and smaller \MATH will cause over-fitting .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
This value is used to determine when the inner loop and the outer loop are stopped .
#<struct ReadData::Alignment source_numbers="15", target_numbers="14", tag_name="wa">
This value is used to determine when the inner loop and the outer loop are stopped .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
Note that smaller \MATH requires more number of iterations making the system 's speed slower .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
Note that smaller \MATH requires more number of iterations making the system 's speed slower .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Note that smaller \MATH requires more number of iterations making the system 's speed slower .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
We have tested other kernel types such as RBF or polynomial , the performance did not change so much .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
We have tested other kernel types such as RBF or polynomial , the performance did not change so much .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
We have tested other kernel types such as RBF or polynomial , the performance did not change so much .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
We performed a comparison between our proposed method with other existing approaches .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
We performed a comparison between our proposed method with other existing approaches .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
We performed a comparison between our proposed method with other existing approaches .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Text Based Baseline ( TBL ) : Once faces corresponding with images whose captions contain the query name are returned , they are ranked by the time order .
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
Text Based Baseline ( TBL ) : Once faces corresponding with images whose captions contain the query name are returned , they are ranked by the time order .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
This is very naive method in which no prior knowledge between names and faces is used .
#<struct ReadData::Alignment source_numbers="2", target_numbers="2,3", tag_name="wa">
Since we do not know the number of returned faces from text based search engines , we used another input value \MATH defined as the fraction of neighbors and estimated \MATH by the formula : \MATH , where \MATH is the number of returned faces .
#<struct ReadData::Alignment source_numbers="36", target_numbers="21", tag_name="wa">
Since we do not know the number of returned faces from text based search engines , we used another input value \MATH defined as the fraction of neighbors and estimated \MATH by the formula : \MATH , where \MATH is the number of returned faces .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
Since we do not know the number of returned faces from text based search engines , we used another input value \MATH defined as the fraction of neighbors and estimated \MATH by the formula : \MATH , where \MATH is the number of returned faces .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
Since we do not know the number of returned faces from text based search engines , we used another input value \MATH defined as the fraction of neighbors and estimated \MATH by the formula : \MATH , where \MATH is the number of returned faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
Since we do not know the number of returned faces from text based search engines , we used another input value \MATH defined as the fraction of neighbors and estimated \MATH by the formula : \MATH , where \MATH is the number of returned faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
Since we do not know the number of returned faces from text based search engines , we used another input value \MATH defined as the fraction of neighbors and estimated \MATH by the formula : \MATH , where \MATH is the number of returned faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
In the case of large number of returned faces , we set \MATH to the maximum value of 200 : \MATH .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
In the case of large number of returned faces , we set \MATH to the maximum value of 200 : \MATH .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
In the case of large number of returned faces , we set \MATH to the maximum value of 200 : \MATH .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
In the case of large number of returned faces , we set \MATH to the maximum value of 200 : \MATH .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
In the case of large number of returned faces , we set \MATH to the maximum value of 200 : \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Unsupervised Ensemble Learning Using Local Density Score ( UEL-LDS ) : This is a combination of ranking by local density scores and then the ranked list is used for training classifier [Singular or plural?]to boost the rank list .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
Unsupervised Ensemble Learning Using Local Density Score ( UEL-LDS ) : This is a combination of ranking by local density scores and then the ranked list is used for training classifier [Singular or plural?]to boost the rank list .
#<struct ReadData::Alignment source_numbers="31", target_numbers="", tag_name="wa">
Unsupervised Ensemble Learning Using Local Density Score ( UEL-LDS ) : This is a combination of ranking by local density scores and then the ranked list is used for training classifier [Singular or plural?]to boost the rank list .
#<struct ReadData::Alignment source_numbers="32", target_numbers="", tag_name="wa">
Unsupervised Ensemble Learning Using Local Density Score ( UEL-LDS ) : This is a combination of ranking by local density scores and then the ranked list is used for training classifier [Singular or plural?]to boost the rank list .
#<struct ReadData::Alignment source_numbers="33", target_numbers="", tag_name="wa">
Unsupervised Ensemble Learning Using Local Density Score ( UEL-LDS ) : This is a combination of ranking by local density scores and then the ranked list is used for training classifier [Singular or plural?]to boost the rank list .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
Unsupervised Ensemble Learning Using Local Density Score ( UEL-LDS ) : This is a combination of ranking by local density scores and then the ranked list is used for training classifier [Singular or plural?]to boost the rank list .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
Our proposed methods ( LDS and UEL-LDS ) outperform other unsupervised methods such as TBL , DBO and DSG .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Furthermore , the performance of methods DBO and DSG are sensitive to the distance threshold ; while the performance of our proposed method is less sensitive .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
Furthermore , the performance of methods DBO and DSG are sensitive to the distance threshold ; while the performance of our proposed method is less sensitive .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
Furthermore , the performance of methods DBO and DSG are sensitive to the distance threshold ; while the performance of our proposed method is less sensitive .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
Furthermore , the performance of methods DBO and DSG are sensitive to the distance threshold ; while the performance of our proposed method is less sensitive .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
It confirms that the similarity measure using shared nearest neighbors is relieable for estimation of the local density score .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
It confirms that the similarity measure using shared nearest neighbors is relieable for estimation of the local density score .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
However , UEL-LDS improves the performance significantly even when the performance of LDS is poor .
#<struct ReadData::Alignment source_numbers="9", target_numbers="7", tag_name="wa">
However , UEL-LDS improves the performance significantly even when the performance of LDS is poor .
#<struct ReadData::Alignment source_numbers="10", target_numbers="8", tag_name="wa">
However , UEL-LDS improves the performance significantly even when the performance of LDS is poor .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
However , UEL-LDS improves the performance significantly even when the performance of LDS is poor .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Figure \REF shows an examples of top 50 faces ranked by the methods TBL , DBO , DSG and LDS .
#<struct ReadData::Alignment source_numbers="11", target_numbers="6", tag_name="wa">
Figure \REF shows an examples of top 50 faces ranked by the methods TBL , DBO , DSG and LDS .
#<struct ReadData::Alignment source_numbers="12", target_numbers="21", tag_name="wa">
Figure \REF shows an examples of top 50 faces ranked by the methods TBL , DBO , DSG and LDS .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Figure \REF shows an examples of top 50 faces ranked by the methods TBL , DBO , DSG and LDS .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
Figure \REF shows an examples of top 50 faces ranked by the methods TBL , DBO , DSG and LDS .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
This makes irrelevant faces that are near duplicates ( row 2 and row 3 in Figure \REF( b ) ) ranked higher than relevant faces .
#<struct ReadData::Alignment source_numbers="9", target_numbers="9", tag_name="wa">
This makes irrelevant faces that are near duplicates ( row 2 and row 3 in Figure \REF( b ) ) ranked higher than relevant faces .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
This makes irrelevant faces that are near duplicates ( row 2 and row 3 in Figure \REF( b ) ) ranked higher than relevant faces .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
This makes irrelevant faces that are near duplicates ( row 2 and row 3 in Figure \REF( b ) ) ranked higher than relevant faces .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
This makes irrelevant faces that are near duplicates ( row 2 and row 3 in Figure \REF( b ) ) ranked higher than relevant faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
The ensemble classifier \MATH is formed by combination of single classifiers from \MATH to \MATH .
#<struct ReadData::Alignment source_numbers="7", target_numbers="7", tag_name="wa">
The ensemble classifier \MATH is formed by combination of single classifiers from \MATH to \MATH .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
It clearly indicates that the ensemble classifier is more stable that single weak classifiers .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
It clearly indicates that the ensemble classifier is more stable that single weak classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
It clearly indicates that the ensemble classifier is more stable that single weak classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
It clearly indicates that the ensemble classifier is more stable that single weak classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
It clearly indicates that the ensemble classifier is more stable that single weak classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
It clearly indicates that the ensemble classifier is more stable that single weak classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
It clearly indicates that the ensemble classifier is more stable that single weak classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
It clearly indicates that the ensemble classifier is more stable that single weak classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
It clearly indicates that the ensemble classifier is more stable that single weak classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
It clearly indicates that the ensemble classifier is more stable that single weak classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
It clearly indicates that the ensemble classifier is more stable that single weak classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
It clearly indicates that the ensemble classifier is more stable that single weak classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
It clearly indicates that the ensemble classifier is more stable that single weak classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
It clearly indicates that the ensemble classifier is more stable that single weak classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
It clearly indicates that the ensemble classifier is more stable that single weak classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
It clearly indicates that the ensemble classifier is more stable that single weak classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
It clearly indicates that the ensemble classifier is more stable that single weak classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
It clearly indicates that the ensemble classifier is more stable that single weak classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
It clearly indicates that the ensemble classifier is more stable that single weak classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
It clearly indicates that the ensemble classifier is more stable that single weak classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
It clearly indicates that the ensemble classifier is more stable that single weak classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
It clearly indicates that the ensemble classifier is more stable that single weak classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
It clearly indicates that the ensemble classifier is more stable that single weak classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
It clearly indicates that the ensemble classifier is more stable that single weak classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
It clearly indicates that the ensemble classifier is more stable that single weak classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
It clearly indicates that the ensemble classifier is more stable that single weak classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
It clearly indicates that the ensemble classifier is more stable that single weak classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
It clearly indicates that the ensemble classifier is more stable that single weak classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="40", tag_name="wa">
It clearly indicates that the ensemble classifier is more stable that single weak classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="41", tag_name="wa">
It clearly indicates that the ensemble classifier is more stable that single weak classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="42", tag_name="wa">
It clearly indicates that the ensemble classifier is more stable that single weak classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="43", tag_name="wa">
It clearly indicates that the ensemble classifier is more stable that single weak classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="44", tag_name="wa">
It clearly indicates that the ensemble classifier is more stable that single weak classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="45", tag_name="wa">
It clearly indicates that the ensemble classifier is more stable that single weak classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="46", tag_name="wa">
It clearly indicates that the ensemble classifier is more stable that single weak classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="47", tag_name="wa">
It clearly indicates that the ensemble classifier is more stable that single weak classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="48", tag_name="wa">
It clearly indicates that the ensemble classifier is more stable that single weak classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="49", tag_name="wa">
It clearly indicates that the ensemble classifier is more stable that single weak classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="50", tag_name="wa">
It clearly indicates that the ensemble classifier is more stable that single weak classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="51", tag_name="wa">
It clearly indicates that the ensemble classifier is more stable that single weak classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="52", tag_name="wa">
It clearly indicates that the ensemble classifier is more stable that single weak classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="53", tag_name="wa">
It clearly indicates that the ensemble classifier is more stable that single weak classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="54", tag_name="wa">
It clearly indicates that the ensemble classifier is more stable that single weak classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="55", tag_name="wa">
It clearly indicates that the ensemble classifier is more stable that single weak classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="56", tag_name="wa">
It clearly indicates that the ensemble classifier is more stable that single weak classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="57", tag_name="wa">
We conducted another experiment to show the effectiveness of our approach in which learned models can be used to annotate new faces of other databases .
#<struct ReadData::Alignment source_numbers="16", target_numbers="15", tag_name="wa">
We conducted another experiment to show the effectiveness of our approach in which learned models can be used to annotate new faces of other databases .
#<struct ReadData::Alignment source_numbers="17", target_numbers="16", tag_name="wa">
We conducted another experiment to show the effectiveness of our approach in which learned models can be used to annotate new faces of other databases .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
For each name in the list , we used it as the query to obtain top 500 images from Google Image Search Engine .
#<struct ReadData::Alignment source_numbers="8", target_numbers="1", tag_name="wa">
For each name in the list , we used it as the query to obtain top 500 images from Google Image Search Engine .
#<struct ReadData::Alignment source_numbers="11", target_numbers="12", tag_name="wa">
For each name in the list , we used it as the query to obtain top 500 images from Google Image Search Engine .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
For each name in the list , we used it as the query to obtain top 500 images from Google Image Search Engine .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
For each name in the list , we used it as the query to obtain top 500 images from Google Image Search Engine .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
For each name in the list , we used it as the query to obtain top 500 images from Google Image Search Engine .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
For each name in the list , we used it as the query to obtain top 500 images from Google Image Search Engine .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
For each name in the list , we used it as the query to obtain top 500 images from Google Image Search Engine .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
For each name in the list , we used it as the query to obtain top 500 images from Google Image Search Engine .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
For each name in the list , we used it as the query to obtain top 500 images from Google Image Search Engine .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
For each name in the list , we used it as the query to obtain top 500 images from Google Image Search Engine .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
Next , these images were processed as the steps described in section \REF : extracting faces , detecting eyes and doing normalization .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
Next , these images were processed as the steps described in section \REF : extracting faces , detecting eyes and doing normalization .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Next , these images were processed as the steps described in section \REF : extracting faces , detecting eyes and doing normalization .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
There were 4 ,103 faces ( including false positives - non-faces were detected as faces ) detected from 7 ,500 returned images .
#<struct ReadData::Alignment source_numbers="12", target_numbers="11", tag_name="wa">
There were 4 ,103 faces ( including false positives - non-faces were detected as faces ) detected from 7 ,500 returned images .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
On average , the accuracy of the Google Search Engine ( GoogleSE ) is 57 .08\% .
#<struct ReadData::Alignment source_numbers="16", target_numbers="11", tag_name="wa">
On average , the accuracy of the Google Search Engine ( GoogleSE ) is 57 .08\% .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
On average , the accuracy of the Google Search Engine ( GoogleSE ) is 57 .08\% .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
On average , the accuracy of the Google Search Engine ( GoogleSE ) is 57 .08\% .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
On average , the accuracy of the Google Search Engine ( GoogleSE ) is 57 .08\% .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
On average , the accuracy of the Google Search Engine ( GoogleSE ) is 57 .08\% .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
The performances of SVM-SUP-05 and SVM-SUP-10 correspond to the supervised systems ( cf . section \REF ) that used \MATH of the data set respectively .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
We evaluated the performance by calculating the precision at top 20 returned faces , which is popular for image search engines ; and recall and precision on all detected faces of the test set .
#<struct ReadData::Alignment source_numbers="30", target_numbers="8", tag_name="wa">
We evaluated the performance by calculating the precision at top 20 returned faces , which is popular for image search engines ; and recall and precision on all detected faces of the test set .
#<struct ReadData::Alignment source_numbers="31", target_numbers="9", tag_name="wa">
We evaluated the performance by calculating the precision at top 20 returned faces , which is popular for image search engines ; and recall and precision on all detected faces of the test set .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
We evaluated the performance by calculating the precision at top 20 returned faces , which is popular for image search engines ; and recall and precision on all detected faces of the test set .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
We evaluated the performance by calculating the precision at top 20 returned faces , which is popular for image search engines ; and recall and precision on all detected faces of the test set .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
We evaluated the performance by calculating the precision at top 20 returned faces , which is popular for image search engines ; and recall and precision on all detected faces of the test set .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
We evaluated the performance by calculating the precision at top 20 returned faces , which is popular for image search engines ; and recall and precision on all detected faces of the test set .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
We evaluated the performance by calculating the precision at top 20 returned faces , which is popular for image search engines ; and recall and precision on all detected faces of the test set .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
The precision at top 20 of SVM-SUP-05 is poorer than that of UEL-LDS is due to small number of training samples .
#<struct ReadData::Alignment source_numbers="18", target_numbers="2", tag_name="wa">
The precision at top 20 of SVM-SUP-05 is poorer than that of UEL-LDS is due to small number of training samples .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
The precision at top 20 of SVM-SUP-05 is poorer than that of UEL-LDS is due to small number of training samples .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
The precision at top 20 of SVM-SUP-05 is poorer than that of UEL-LDS is due to small number of training samples .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
Figure \REF shows top 20 faces ranked by these two methods .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Figure \REF shows top 20 faces ranked by these two methods .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Consequently , as shown in Figure \REF , the model learned by this set obtained poor performance in recognizing new faces returned by GoogleSE .
#<struct ReadData::Alignment source_numbers="16", target_numbers="14", tag_name="wa">
Consequently , as shown in Figure \REF , the model learned by this set obtained poor performance in recognizing new faces returned by GoogleSE .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
Consequently , as shown in Figure \REF , the model learned by this set obtained poor performance in recognizing new faces returned by GoogleSE .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
Consequently , as shown in Figure \REF , the model learned by this set obtained poor performance in recognizing new faces returned by GoogleSE .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
Our approach solely relies on the above assumption , therefore it is not affected by the ranking of text-based search engines .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Our future work is to study how to improve the quality of the training sets used in this iteration .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Our future work is to study how to improve the quality of the training sets used in this iteration .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Our future work is to study how to improve the quality of the training sets used in this iteration .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Our future work is to study how to improve the quality of the training sets used in this iteration .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Our future work is to study how to improve the quality of the training sets used in this iteration .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
In the first stage , a relative density score is used to form a ranked list in which faces ranked at the top or bottom of the list are likely relevant or irrelevant faces .
#<struct ReadData::Alignment source_numbers="34", target_numbers="38", tag_name="wa">
In the first stage , a relative density score is used to form a ranked list in which faces ranked at the top or bottom of the list are likely relevant or irrelevant faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
In the first stage , a relative density score is used to form a ranked list in which faces ranked at the top or bottom of the list are likely relevant or irrelevant faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
In the first stage , a relative density score is used to form a ranked list in which faces ranked at the top or bottom of the list are likely relevant or irrelevant faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
In the first stage , a relative density score is used to form a ranked list in which faces ranked at the top or bottom of the list are likely relevant or irrelevant faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
Our approach is beneficial in the case multiple faces residing in the returned image as shown in Figure \REF .
#<struct ReadData::Alignment source_numbers="4", target_numbers="9", tag_name="wa">
Our approach is beneficial in the case multiple faces residing in the returned image as shown in Figure \REF .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Our approach is beneficial in the case multiple faces residing in the returned image as shown in Figure \REF .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
Our approach is beneficial in the case multiple faces residing in the returned image as shown in Figure \REF .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Our approach is beneficial in the case multiple faces residing in the returned image as shown in Figure \REF .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Our approach is beneficial in the case multiple faces residing in the returned image as shown in Figure \REF .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
Our approach is beneficial in the case multiple faces residing in the returned image as shown in Figure \REF .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Our approach is beneficial in the case multiple faces residing in the returned image as shown in Figure \REF .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Our approach is beneficial in the case multiple faces residing in the returned image as shown in Figure \REF .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Our approach is beneficial in the case multiple faces residing in the returned image as shown in Figure \REF .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Our approach is beneficial in the case multiple faces residing in the returned image as shown in Figure \REF .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Although many methods have been proposed for this task , finding a general and robust shot boundary method that is able to handle various transition types caused by photo flashes , rapid camera movement and object movement is still challenging .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
In this paper , we present a novel approach for detecting video shot boundaries in which we cast the problem of shot boundary detection into the problem of text segmentation in natural language processing .
#<struct ReadData::Alignment source_numbers="5", target_numbers="1", tag_name="wa">
In this paper , we present a novel approach for detecting video shot boundaries in which we cast the problem of shot boundary detection into the problem of text segmentation in natural language processing .
#<struct ReadData::Alignment source_numbers="6", target_numbers="2", tag_name="wa">
In this paper , we present a novel approach for detecting video shot boundaries in which we cast the problem of shot boundary detection into the problem of text segmentation in natural language processing .
#<struct ReadData::Alignment source_numbers="7", target_numbers="3", tag_name="wa">
In this paper , we present a novel approach for detecting video shot boundaries in which we cast the problem of shot boundary detection into the problem of text segmentation in natural language processing .
#<struct ReadData::Alignment source_numbers="8", target_numbers="4", tag_name="wa">
In this paper , we present a novel approach for detecting video shot boundaries in which we cast the problem of shot boundary detection into the problem of text segmentation in natural language processing .
#<struct ReadData::Alignment source_numbers="9", target_numbers="5", tag_name="wa">
In this paper , we present a novel approach for detecting video shot boundaries in which we cast the problem of shot boundary detection into the problem of text segmentation in natural language processing .
#<struct ReadData::Alignment source_numbers="10", target_numbers="6", tag_name="wa">
In this paper , we present a novel approach for detecting video shot boundaries in which we cast the problem of shot boundary detection into the problem of text segmentation in natural language processing .
#<struct ReadData::Alignment source_numbers="11", target_numbers="7", tag_name="wa">
In this paper , we present a novel approach for detecting video shot boundaries in which we cast the problem of shot boundary detection into the problem of text segmentation in natural language processing .
#<struct ReadData::Alignment source_numbers="12", target_numbers="8", tag_name="wa">
In this paper , we present a novel approach for detecting video shot boundaries in which we cast the problem of shot boundary detection into the problem of text segmentation in natural language processing .
#<struct ReadData::Alignment source_numbers="13", target_numbers="9", tag_name="wa">
In this paper , we present a novel approach for detecting video shot boundaries in which we cast the problem of shot boundary detection into the problem of text segmentation in natural language processing .
#<struct ReadData::Alignment source_numbers="14", target_numbers="10", tag_name="wa">
In this paper , we present a novel approach for detecting video shot boundaries in which we cast the problem of shot boundary detection into the problem of text segmentation in natural language processing .
#<struct ReadData::Alignment source_numbers="15", target_numbers="11", tag_name="wa">
In this paper , we present a novel approach for detecting video shot boundaries in which we cast the problem of shot boundary detection into the problem of text segmentation in natural language processing .
#<struct ReadData::Alignment source_numbers="16", target_numbers="12", tag_name="wa">
In this paper , we present a novel approach for detecting video shot boundaries in which we cast the problem of shot boundary detection into the problem of text segmentation in natural language processing .
#<struct ReadData::Alignment source_numbers="17", target_numbers="13", tag_name="wa">
In this paper , we present a novel approach for detecting video shot boundaries in which we cast the problem of shot boundary detection into the problem of text segmentation in natural language processing .
#<struct ReadData::Alignment source_numbers="18", target_numbers="14", tag_name="wa">
In this paper , we present a novel approach for detecting video shot boundaries in which we cast the problem of shot boundary detection into the problem of text segmentation in natural language processing .
#<struct ReadData::Alignment source_numbers="19", target_numbers="15", tag_name="wa">
In this paper , we present a novel approach for detecting video shot boundaries in which we cast the problem of shot boundary detection into the problem of text segmentation in natural language processing .
#<struct ReadData::Alignment source_numbers="20", target_numbers="16", tag_name="wa">
In this paper , we present a novel approach for detecting video shot boundaries in which we cast the problem of shot boundary detection into the problem of text segmentation in natural language processing .
#<struct ReadData::Alignment source_numbers="21", target_numbers="17", tag_name="wa">
In this paper , we present a novel approach for detecting video shot boundaries in which we cast the problem of shot boundary detection into the problem of text segmentation in natural language processing .
#<struct ReadData::Alignment source_numbers="22", target_numbers="18", tag_name="wa">
In this paper , we present a novel approach for detecting video shot boundaries in which we cast the problem of shot boundary detection into the problem of text segmentation in natural language processing .
#<struct ReadData::Alignment source_numbers="23", target_numbers="19", tag_name="wa">
In this paper , we present a novel approach for detecting video shot boundaries in which we cast the problem of shot boundary detection into the problem of text segmentation in natural language processing .
#<struct ReadData::Alignment source_numbers="24", target_numbers="20", tag_name="wa">
In this paper , we present a novel approach for detecting video shot boundaries in which we cast the problem of shot boundary detection into the problem of text segmentation in natural language processing .
#<struct ReadData::Alignment source_numbers="25", target_numbers="21", tag_name="wa">
In this paper , we present a novel approach for detecting video shot boundaries in which we cast the problem of shot boundary detection into the problem of text segmentation in natural language processing .
#<struct ReadData::Alignment source_numbers="26", target_numbers="22", tag_name="wa">
In this paper , we present a novel approach for detecting video shot boundaries in which we cast the problem of shot boundary detection into the problem of text segmentation in natural language processing .
#<struct ReadData::Alignment source_numbers="27", target_numbers="23", tag_name="wa">
In this paper , we present a novel approach for detecting video shot boundaries in which we cast the problem of shot boundary detection into the problem of text segmentation in natural language processing .
#<struct ReadData::Alignment source_numbers="28", target_numbers="24", tag_name="wa">
In this paper , we present a novel approach for detecting video shot boundaries in which we cast the problem of shot boundary detection into the problem of text segmentation in natural language processing .
#<struct ReadData::Alignment source_numbers="29", target_numbers="25", tag_name="wa">
In this paper , we present a novel approach for detecting video shot boundaries in which we cast the problem of shot boundary detection into the problem of text segmentation in natural language processing .
#<struct ReadData::Alignment source_numbers="30", target_numbers="26", tag_name="wa">
In this paper , we present a novel approach for detecting video shot boundaries in which we cast the problem of shot boundary detection into the problem of text segmentation in natural language processing .
#<struct ReadData::Alignment source_numbers="31", target_numbers="27", tag_name="wa">
In this paper , we present a novel approach for detecting video shot boundaries in which we cast the problem of shot boundary detection into the problem of text segmentation in natural language processing .
#<struct ReadData::Alignment source_numbers="32", target_numbers="28", tag_name="wa">
In this paper , we present a novel approach for detecting video shot boundaries in which we cast the problem of shot boundary detection into the problem of text segmentation in natural language processing .
#<struct ReadData::Alignment source_numbers="33", target_numbers="29", tag_name="wa">
In this paper , we present a novel approach for detecting video shot boundaries in which we cast the problem of shot boundary detection into the problem of text segmentation in natural language processing .
#<struct ReadData::Alignment source_numbers="34", target_numbers="30", tag_name="wa">
In this paper , we present a novel approach for detecting video shot boundaries in which we cast the problem of shot boundary detection into the problem of text segmentation in natural language processing .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
In this paper , we present a novel approach for detecting video shot boundaries in which we cast the problem of shot boundary detection into the problem of text segmentation in natural language processing .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
In this paper , we present a novel approach for detecting video shot boundaries in which we cast the problem of shot boundary detection into the problem of text segmentation in natural language processing .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
In this paper , we present a novel approach for detecting video shot boundaries in which we cast the problem of shot boundary detection into the problem of text segmentation in natural language processing .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
In this paper , we present a novel approach for detecting video shot boundaries in which we cast the problem of shot boundary detection into the problem of text segmentation in natural language processing .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
In this paper , we present a novel approach for detecting video shot boundaries in which we cast the problem of shot boundary detection into the problem of text segmentation in natural language processing .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
In this paper , we present a novel approach for detecting video shot boundaries in which we cast the problem of shot boundary detection into the problem of text segmentation in natural language processing .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
In this paper , we present a novel approach for detecting video shot boundaries in which we cast the problem of shot boundary detection into the problem of text segmentation in natural language processing .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
In this paper , we present a novel approach for detecting video shot boundaries in which we cast the problem of shot boundary detection into the problem of text segmentation in natural language processing .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
By the formulation that each frame is considered as a word and shot boundaries are treated as boundaries of text segments ( e .g topics ) .
#<struct ReadData::Alignment source_numbers="1", target_numbers="13", tag_name="wa">
By the formulation that each frame is considered as a word and shot boundaries are treated as boundaries of text segments ( e .g topics ) .
#<struct ReadData::Alignment source_numbers="19", target_numbers="19", tag_name="wa">
By the formulation that each frame is considered as a word and shot boundaries are treated as boundaries of text segments ( e .g topics ) .
#<struct ReadData::Alignment source_numbers="20", target_numbers="20", tag_name="wa">
By the formulation that each frame is considered as a word and shot boundaries are treated as boundaries of text segments ( e .g topics ) .
#<struct ReadData::Alignment source_numbers="17", target_numbers="21", tag_name="wa">
By the formulation that each frame is considered as a word and shot boundaries are treated as boundaries of text segments ( e .g topics ) .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
By the formulation that each frame is considered as a word and shot boundaries are treated as boundaries of text segments ( e .g topics ) .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
By the formulation that each frame is considered as a word and shot boundaries are treated as boundaries of text segments ( e .g topics ) .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
By the formulation that each frame is considered as a word and shot boundaries are treated as boundaries of text segments ( e .g topics ) .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
By the formulation that each frame is considered as a word and shot boundaries are treated as boundaries of text segments ( e .g topics ) .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
By the formulation that each frame is considered as a word and shot boundaries are treated as boundaries of text segments ( e .g topics ) .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
By the formulation that each frame is considered as a word and shot boundaries are treated as boundaries of text segments ( e .g topics ) .
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
By the formulation that each frame is considered as a word and shot boundaries are treated as boundaries of text segments ( e .g topics ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
By the formulation that each frame is considered as a word and shot boundaries are treated as boundaries of text segments ( e .g topics ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
By the formulation that each frame is considered as a word and shot boundaries are treated as boundaries of text segments ( e .g topics ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
By the formulation that each frame is considered as a word and shot boundaries are treated as boundaries of text segments ( e .g topics ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
By the formulation that each frame is considered as a word and shot boundaries are treated as boundaries of text segments ( e .g topics ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
By the formulation that each frame is considered as a word and shot boundaries are treated as boundaries of text segments ( e .g topics ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
By the formulation that each frame is considered as a word and shot boundaries are treated as boundaries of text segments ( e .g topics ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
Text segmentation based approaches that have been well studied in natural language processing can be adopted .
#<struct ReadData::Alignment source_numbers="16", target_numbers="12", tag_name="wa">
Text segmentation based approaches that have been well studied in natural language processing can be adopted .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Text segmentation based approaches that have been well studied in natural language processing can be adopted .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
Text segmentation based approaches that have been well studied in natural language processing can be adopted .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Text segmentation based approaches that have been well studied in natural language processing can be adopted .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
Text segmentation based approaches that have been well studied in natural language processing can be adopted .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Text segmentation based approaches that have been well studied in natural language processing can be adopted .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Text segmentation based approaches that have been well studied in natural language processing can be adopted .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
Text segmentation based approaches that have been well studied in natural language processing can be adopted .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Text segmentation based approaches that have been well studied in natural language processing can be adopted .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
Experimental results on various long video sequences show the effectiveness of our approach .
#<struct ReadData::Alignment source_numbers="7", target_numbers="9", tag_name="wa">
Experimental results on various long video sequences show the effectiveness of our approach .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Experimental results on various long video sequences show the effectiveness of our approach .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Experimental results on various long video sequences show the effectiveness of our approach .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Experimental results on various long video sequences show the effectiveness of our approach .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Experimental results on various long video sequences show the effectiveness of our approach .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Recent advances in digital technology have made many video archives available .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Therefore scalable , efficient and effective tools for indexing and retrieving video are needed .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
With a large amount of information encoded in one video , typically the first step of any video processing tools is to segment the input video into elementary shots in which each shot is defined as continuous frames from a single camera at a time .
#<struct ReadData::Alignment source_numbers="43", target_numbers="36", tag_name="wa">
With a large amount of information encoded in one video , typically the first step of any video processing tools is to segment the input video into elementary shots in which each shot is defined as continuous frames from a single camera at a time .
#<struct ReadData::Alignment source_numbers="37", target_numbers="38", tag_name="wa">
With a large amount of information encoded in one video , typically the first step of any video processing tools is to segment the input video into elementary shots in which each shot is defined as continuous frames from a single camera at a time .
#<struct ReadData::Alignment source_numbers="44", target_numbers="46", tag_name="wa">
With a large amount of information encoded in one video , typically the first step of any video processing tools is to segment the input video into elementary shots in which each shot is defined as continuous frames from a single camera at a time .
#<struct ReadData::Alignment source_numbers="", target_numbers="44", tag_name="wa">
With a large amount of information encoded in one video , typically the first step of any video processing tools is to segment the input video into elementary shots in which each shot is defined as continuous frames from a single camera at a time .
#<struct ReadData::Alignment source_numbers="", target_numbers="45", tag_name="wa">
By decomposing a video into shots and then extracting keyframes from these shots , a 30-minute video with 54 ,000 frames can be represented by around 500 keyframes ( 108 times smaller ) which are easily manageable for many video applications in indexing , browsing , summarization , retrieval and so on .
#<struct ReadData::Alignment source_numbers="33,34", target_numbers="36,37", tag_name="wa">
By decomposing a video into shots and then extracting keyframes from these shots , a 30-minute video with 54 ,000 frames can be represented by around 500 keyframes ( 108 times smaller ) which are easily manageable for many video applications in indexing , browsing , summarization , retrieval and so on .
#<struct ReadData::Alignment source_numbers="42", target_numbers="50", tag_name="wa">
By decomposing a video into shots and then extracting keyframes from these shots , a 30-minute video with 54 ,000 frames can be represented by around 500 keyframes ( 108 times smaller ) which are easily manageable for many video applications in indexing , browsing , summarization , retrieval and so on .
#<struct ReadData::Alignment source_numbers="43", target_numbers="51", tag_name="wa">
By decomposing a video into shots and then extracting keyframes from these shots , a 30-minute video with 54 ,000 frames can be represented by around 500 keyframes ( 108 times smaller ) which are easily manageable for many video applications in indexing , browsing , summarization , retrieval and so on .
#<struct ReadData::Alignment source_numbers="44", target_numbers="52", tag_name="wa">
By decomposing a video into shots and then extracting keyframes from these shots , a 30-minute video with 54 ,000 frames can be represented by around 500 keyframes ( 108 times smaller ) which are easily manageable for many video applications in indexing , browsing , summarization , retrieval and so on .
#<struct ReadData::Alignment source_numbers="45", target_numbers="53", tag_name="wa">
By decomposing a video into shots and then extracting keyframes from these shots , a 30-minute video with 54 ,000 frames can be represented by around 500 keyframes ( 108 times smaller ) which are easily manageable for many video applications in indexing , browsing , summarization , retrieval and so on .
#<struct ReadData::Alignment source_numbers="46", target_numbers="54", tag_name="wa">
By decomposing a video into shots and then extracting keyframes from these shots , a 30-minute video with 54 ,000 frames can be represented by around 500 keyframes ( 108 times smaller ) which are easily manageable for many video applications in indexing , browsing , summarization , retrieval and so on .
#<struct ReadData::Alignment source_numbers="47", target_numbers="55", tag_name="wa">
By decomposing a video into shots and then extracting keyframes from these shots , a 30-minute video with 54 ,000 frames can be represented by around 500 keyframes ( 108 times smaller ) which are easily manageable for many video applications in indexing , browsing , summarization , retrieval and so on .
#<struct ReadData::Alignment source_numbers="49", target_numbers="56", tag_name="wa">
By decomposing a video into shots and then extracting keyframes from these shots , a 30-minute video with 54 ,000 frames can be represented by around 500 keyframes ( 108 times smaller ) which are easily manageable for many video applications in indexing , browsing , summarization , retrieval and so on .
#<struct ReadData::Alignment source_numbers="48", target_numbers="57", tag_name="wa">
By decomposing a video into shots and then extracting keyframes from these shots , a 30-minute video with 54 ,000 frames can be represented by around 500 keyframes ( 108 times smaller ) which are easily manageable for many video applications in indexing , browsing , summarization , retrieval and so on .
#<struct ReadData::Alignment source_numbers="52", target_numbers="58", tag_name="wa">
By decomposing a video into shots and then extracting keyframes from these shots , a 30-minute video with 54 ,000 frames can be represented by around 500 keyframes ( 108 times smaller ) which are easily manageable for many video applications in indexing , browsing , summarization , retrieval and so on .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
By decomposing a video into shots and then extracting keyframes from these shots , a 30-minute video with 54 ,000 frames can be represented by around 500 keyframes ( 108 times smaller ) which are easily manageable for many video applications in indexing , browsing , summarization , retrieval and so on .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
By decomposing a video into shots and then extracting keyframes from these shots , a 30-minute video with 54 ,000 frames can be represented by around 500 keyframes ( 108 times smaller ) which are easily manageable for many video applications in indexing , browsing , summarization , retrieval and so on .
#<struct ReadData::Alignment source_numbers="41", target_numbers="", tag_name="wa">
By decomposing a video into shots and then extracting keyframes from these shots , a 30-minute video with 54 ,000 frames can be represented by around 500 keyframes ( 108 times smaller ) which are easily manageable for many video applications in indexing , browsing , summarization , retrieval and so on .
#<struct ReadData::Alignment source_numbers="50", target_numbers="", tag_name="wa">
By decomposing a video into shots and then extracting keyframes from these shots , a 30-minute video with 54 ,000 frames can be represented by around 500 keyframes ( 108 times smaller ) which are easily manageable for many video applications in indexing , browsing , summarization , retrieval and so on .
#<struct ReadData::Alignment source_numbers="51", target_numbers="", tag_name="wa">
By decomposing a video into shots and then extracting keyframes from these shots , a 30-minute video with 54 ,000 frames can be represented by around 500 keyframes ( 108 times smaller ) which are easily manageable for many video applications in indexing , browsing , summarization , retrieval and so on .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
By decomposing a video into shots and then extracting keyframes from these shots , a 30-minute video with 54 ,000 frames can be represented by around 500 keyframes ( 108 times smaller ) which are easily manageable for many video applications in indexing , browsing , summarization , retrieval and so on .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
By decomposing a video into shots and then extracting keyframes from these shots , a 30-minute video with 54 ,000 frames can be represented by around 500 keyframes ( 108 times smaller ) which are easily manageable for many video applications in indexing , browsing , summarization , retrieval and so on .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
By decomposing a video into shots and then extracting keyframes from these shots , a 30-minute video with 54 ,000 frames can be represented by around 500 keyframes ( 108 times smaller ) which are easily manageable for many video applications in indexing , browsing , summarization , retrieval and so on .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
By decomposing a video into shots and then extracting keyframes from these shots , a 30-minute video with 54 ,000 frames can be represented by around 500 keyframes ( 108 times smaller ) which are easily manageable for many video applications in indexing , browsing , summarization , retrieval and so on .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
By decomposing a video into shots and then extracting keyframes from these shots , a 30-minute video with 54 ,000 frames can be represented by around 500 keyframes ( 108 times smaller ) which are easily manageable for many video applications in indexing , browsing , summarization , retrieval and so on .
#<struct ReadData::Alignment source_numbers="", target_numbers="44", tag_name="wa">
By decomposing a video into shots and then extracting keyframes from these shots , a 30-minute video with 54 ,000 frames can be represented by around 500 keyframes ( 108 times smaller ) which are easily manageable for many video applications in indexing , browsing , summarization , retrieval and so on .
#<struct ReadData::Alignment source_numbers="", target_numbers="45", tag_name="wa">
By decomposing a video into shots and then extracting keyframes from these shots , a 30-minute video with 54 ,000 frames can be represented by around 500 keyframes ( 108 times smaller ) which are easily manageable for many video applications in indexing , browsing , summarization , retrieval and so on .
#<struct ReadData::Alignment source_numbers="", target_numbers="46", tag_name="wa">
By decomposing a video into shots and then extracting keyframes from these shots , a 30-minute video with 54 ,000 frames can be represented by around 500 keyframes ( 108 times smaller ) which are easily manageable for many video applications in indexing , browsing , summarization , retrieval and so on .
#<struct ReadData::Alignment source_numbers="", target_numbers="47", tag_name="wa">
By decomposing a video into shots and then extracting keyframes from these shots , a 30-minute video with 54 ,000 frames can be represented by around 500 keyframes ( 108 times smaller ) which are easily manageable for many video applications in indexing , browsing , summarization , retrieval and so on .
#<struct ReadData::Alignment source_numbers="", target_numbers="48", tag_name="wa">
By decomposing a video into shots and then extracting keyframes from these shots , a 30-minute video with 54 ,000 frames can be represented by around 500 keyframes ( 108 times smaller ) which are easily manageable for many video applications in indexing , browsing , summarization , retrieval and so on .
#<struct ReadData::Alignment source_numbers="", target_numbers="49", tag_name="wa">
A cut is an abrupt shot change that occurs in a single frame while a gradual is a slow change that occurs in a number of consecutive frames .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
A cut is an abrupt shot change that occurs in a single frame while a gradual is a slow change that occurs in a number of consecutive frames .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
A fade is usually a change in brightness with one or several solid black frames in between , while a dissolve occurs when the images in the current shot get dimmer and the images of the next shot get brighter \CITE .
#<struct ReadData::Alignment source_numbers="35", target_numbers="17", tag_name="wa">
A fade is usually a change in brightness with one or several solid black frames in between , while a dissolve occurs when the images in the current shot get dimmer and the images of the next shot get brighter \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
A fade is usually a change in brightness with one or several solid black frames in between , while a dissolve occurs when the images in the current shot get dimmer and the images of the next shot get brighter \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
A fade is usually a change in brightness with one or several solid black frames in between , while a dissolve occurs when the images in the current shot get dimmer and the images of the next shot get brighter \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
Since these approaches use threshold-based models for detection , their advantage is fast speed .
#<struct ReadData::Alignment source_numbers="12", target_numbers="14", tag_name="wa">
Since these approaches use threshold-based models for detection , their advantage is fast speed .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
Since these approaches use threshold-based models for detection , their advantage is fast speed .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
Since these approaches use threshold-based models for detection , their advantage is fast speed .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Nevertheless , they are sensitive to changes of illumination and motion .
#<struct ReadData::Alignment source_numbers="6,7", target_numbers="6,7", tag_name="wa">
Recent works \CITE use machine learning methods for making decision and show impressive results on test videos of TRECVID \CITE which is a de-facto benchmark for evaluation of various techniques in shot boundary detection .
#<struct ReadData::Alignment source_numbers="9,10", target_numbers="9,10", tag_name="wa">
Recent works \CITE use machine learning methods for making decision and show impressive results on test videos of TRECVID \CITE which is a de-facto benchmark for evaluation of various techniques in shot boundary detection .
#<struct ReadData::Alignment source_numbers="34", target_numbers="38", tag_name="wa">
Recent works \CITE use machine learning methods for making decision and show impressive results on test videos of TRECVID \CITE which is a de-facto benchmark for evaluation of various techniques in shot boundary detection .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
Recent works \CITE use machine learning methods for making decision and show impressive results on test videos of TRECVID \CITE which is a de-facto benchmark for evaluation of various techniques in shot boundary detection .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
Recent works \CITE use machine learning methods for making decision and show impressive results on test videos of TRECVID \CITE which is a de-facto benchmark for evaluation of various techniques in shot boundary detection .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
Recent works \CITE use machine learning methods for making decision and show impressive results on test videos of TRECVID \CITE which is a de-facto benchmark for evaluation of various techniques in shot boundary detection .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
Recent works \CITE use machine learning methods for making decision and show impressive results on test videos of TRECVID \CITE which is a de-facto benchmark for evaluation of various techniques in shot boundary detection .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
In this study , we propose a new approach inspired from natural language processing text segmentation techniques in which the problem of shot boundary detection is treated similarly to the problem of text segmentation .
#<struct ReadData::Alignment source_numbers="29", target_numbers="13", tag_name="wa">
In this study , we propose a new approach inspired from natural language processing text segmentation techniques in which the problem of shot boundary detection is treated similarly to the problem of text segmentation .
#<struct ReadData::Alignment source_numbers="30,31", target_numbers="33,34", tag_name="wa">
In this study , we propose a new approach inspired from natural language processing text segmentation techniques in which the problem of shot boundary detection is treated similarly to the problem of text segmentation .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
In this study , we propose a new approach inspired from natural language processing text segmentation techniques in which the problem of shot boundary detection is treated similarly to the problem of text segmentation .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
In this study , we propose a new approach inspired from natural language processing text segmentation techniques in which the problem of shot boundary detection is treated similarly to the problem of text segmentation .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
In this study , we propose a new approach inspired from natural language processing text segmentation techniques in which the problem of shot boundary detection is treated similarly to the problem of text segmentation .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
In this study , we propose a new approach inspired from natural language processing text segmentation techniques in which the problem of shot boundary detection is treated similarly to the problem of text segmentation .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
Specifically , each frame is considered as a word and a set of consecutive frames , forming a shot , is considered as a text segment .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
Specifically , each frame is considered as a word and a set of consecutive frames , forming a shot , is considered as a text segment .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
Then , the text segmentation problem can be considered a sequential tagging problem in which each word is labeled by one of labels such as
#<struct ReadData::Alignment source_numbers="22", target_numbers="24", tag_name="wa">
Then , the text segmentation problem can be considered a sequential tagging problem in which each word is labeled by one of labels such as
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
Then , the text segmentation problem can be considered a sequential tagging problem in which each word is labeled by one of labels such as
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
Then , the text segmentation problem can be considered a sequential tagging problem in which each word is labeled by one of labels such as
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
Then , the text segmentation problem can be considered a sequential tagging problem in which each word is labeled by one of labels such as
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
Then , the text segmentation problem can be considered a sequential tagging problem in which each word is labeled by one of labels such as
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
PRESEG ( word beginning of a segment ) , INSEG ( word inside a segment ) and POSTSEG ( word outside a segment ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
The remaining of the paper is organized as follows .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
The remaining of the paper is organized as follows .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Given a video , the shot boundary detection process is carried out through two main stages .
#<struct ReadData::Alignment source_numbers="5", target_numbers="1", tag_name="wa">
Given a video , the shot boundary detection process is carried out through two main stages .
#<struct ReadData::Alignment source_numbers="6", target_numbers="2", tag_name="wa">
Given a video , the shot boundary detection process is carried out through two main stages .
#<struct ReadData::Alignment source_numbers="7", target_numbers="3", tag_name="wa">
Given a video , the shot boundary detection process is carried out through two main stages .
#<struct ReadData::Alignment source_numbers="8", target_numbers="4", tag_name="wa">
Given a video , the shot boundary detection process is carried out through two main stages .
#<struct ReadData::Alignment source_numbers="1", target_numbers="6", tag_name="wa">
Given a video , the shot boundary detection process is carried out through two main stages .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Given a video , the shot boundary detection process is carried out through two main stages .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
Given a video , the shot boundary detection process is carried out through two main stages .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
Given a video , the shot boundary detection process is carried out through two main stages .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Given a video , the shot boundary detection process is carried out through two main stages .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Given a video , the shot boundary detection process is carried out through two main stages .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
In the first stage , frames are extracted and labeled by pre-defined labels .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
In the first stage , frames are extracted and labeled by pre-defined labels .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
We use the following six labels to label frames in video : NORM -FRM ( frame of a normal shot ) , PRE -CUT ( pre-frame of a CUT transition ) , POST -CUT ( post-frame of a CUT transition ) , PRE -GRAD ( pre-frame of a GRADUAL transition ) , IN -GRAD ( frame inside a GRADUAL transition ) , POST -GRAD ( post-frame of a GRADUAL transition ) .
#<struct ReadData::Alignment source_numbers="67", target_numbers="10", tag_name="wa">
We use the following six labels to label frames in video : NORM -FRM ( frame of a normal shot ) , PRE -CUT ( pre-frame of a CUT transition ) , POST -CUT ( post-frame of a CUT transition ) , PRE -GRAD ( pre-frame of a GRADUAL transition ) , IN -GRAD ( frame inside a GRADUAL transition ) , POST -GRAD ( post-frame of a GRADUAL transition ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="63", tag_name="wa">
We use the following six labels to label frames in video : NORM -FRM ( frame of a normal shot ) , PRE -CUT ( pre-frame of a CUT transition ) , POST -CUT ( post-frame of a CUT transition ) , PRE -GRAD ( pre-frame of a GRADUAL transition ) , IN -GRAD ( frame inside a GRADUAL transition ) , POST -GRAD ( post-frame of a GRADUAL transition ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="69", tag_name="wa">
Given a sequence of labeled frames , shot boundaries and transition types are identified by looking up and processing frames marked by non NORM -FRM label .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
Given a sequence of labeled frames , shot boundaries and transition types are identified by looking up and processing frames marked by non NORM -FRM label .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Given a sequence of labeled frames , shot boundaries and transition types are identified by looking up and processing frames marked by non NORM -FRM label .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
Given a sequence of labeled frames , shot boundaries and transition types are identified by looking up and processing frames marked by non NORM -FRM label .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
In another case , if we encounter a number of frames marked by xxx-GRAD , we can declare a GRADUAL shot boundary occurs at these frames .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
To label a frame in video , firstly we extract features for that frame and then use a classifier , that has been trained by annotated frames in advance , to classify it into one of six categories mentioned above .
#<struct ReadData::Alignment source_numbers="17", target_numbers="5", tag_name="wa">
To label a frame in video , firstly we extract features for that frame and then use a classifier , that has been trained by annotated frames in advance , to classify it into one of six categories mentioned above .
#<struct ReadData::Alignment source_numbers="9", target_numbers="11", tag_name="wa">
To label a frame in video , firstly we extract features for that frame and then use a classifier , that has been trained by annotated frames in advance , to classify it into one of six categories mentioned above .
#<struct ReadData::Alignment source_numbers="20,21", target_numbers="23,24", tag_name="wa">
To label a frame in video , firstly we extract features for that frame and then use a classifier , that has been trained by annotated frames in advance , to classify it into one of six categories mentioned above .
#<struct ReadData::Alignment source_numbers="25", target_numbers="31", tag_name="wa">
To label a frame in video , firstly we extract features for that frame and then use a classifier , that has been trained by annotated frames in advance , to classify it into one of six categories mentioned above .
#<struct ReadData::Alignment source_numbers="26", target_numbers="32", tag_name="wa">
To label a frame in video , firstly we extract features for that frame and then use a classifier , that has been trained by annotated frames in advance , to classify it into one of six categories mentioned above .
#<struct ReadData::Alignment source_numbers="29", target_numbers="33", tag_name="wa">
To label a frame in video , firstly we extract features for that frame and then use a classifier , that has been trained by annotated frames in advance , to classify it into one of six categories mentioned above .
#<struct ReadData::Alignment source_numbers="40", target_numbers="45", tag_name="wa">
To label a frame in video , firstly we extract features for that frame and then use a classifier , that has been trained by annotated frames in advance , to classify it into one of six categories mentioned above .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
To label a frame in video , firstly we extract features for that frame and then use a classifier , that has been trained by annotated frames in advance , to classify it into one of six categories mentioned above .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
The feature extraction process and classifier learning using support vector machine ( SVM ) are described in details below .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
We use two typical features that are color moments , edge direction histogram for representing visual information of each frame .
#<struct ReadData::Alignment source_numbers="9", target_numbers="5", tag_name="wa">
We use two typical features that are color moments , edge direction histogram for representing visual information of each frame .
#<struct ReadData::Alignment source_numbers="5,6", target_numbers="6,7,8", tag_name="wa">
We use two typical features that are color moments , edge direction histogram for representing visual information of each frame .
#<struct ReadData::Alignment source_numbers="14", target_numbers="16,17", tag_name="wa">
We use two typical features that are color moments , edge direction histogram for representing visual information of each frame .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
We use two typical features that are color moments , edge direction histogram for representing visual information of each frame .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
We use two typical features that are color moments , edge direction histogram for representing visual information of each frame .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
However , using this representation is not discriminative enough for frame categorization since frames of a shot transition usually have strong relation to their neighbor frames .
#<struct ReadData::Alignment source_numbers="20", target_numbers="20", tag_name="wa">
However , using this representation is not discriminative enough for frame categorization since frames of a shot transition usually have strong relation to their neighbor frames .
#<struct ReadData::Alignment source_numbers="21", target_numbers="21", tag_name="wa">
However , using this representation is not discriminative enough for frame categorization since frames of a shot transition usually have strong relation to their neighbor frames .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
Specifically , for each frame , we compute \MATH distances between the current frame \MATH and neighbor frames ranging from \MATH .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Specifically , for each frame , we compute \MATH distances between the current frame \MATH and neighbor frames ranging from \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Specifically , for each frame , we compute \MATH distances between the current frame \MATH and neighbor frames ranging from \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
By this way , we can have a unified framework for shot boundary detection and consequently avoid to have special treatments for different shot boundary types as described in many works participated the TRECVID benchmark \CITE .
#<struct ReadData::Alignment source_numbers="32", target_numbers="11", tag_name="wa">
By this way , we can have a unified framework for shot boundary detection and consequently avoid to have special treatments for different shot boundary types as described in many works participated the TRECVID benchmark \CITE .
#<struct ReadData::Alignment source_numbers="17", target_numbers="19", tag_name="wa">
By this way , we can have a unified framework for shot boundary detection and consequently avoid to have special treatments for different shot boundary types as described in many works participated the TRECVID benchmark \CITE .
#<struct ReadData::Alignment source_numbers="18", target_numbers="20", tag_name="wa">
By this way , we can have a unified framework for shot boundary detection and consequently avoid to have special treatments for different shot boundary types as described in many works participated the TRECVID benchmark \CITE .
#<struct ReadData::Alignment source_numbers="36", target_numbers="42", tag_name="wa">
By this way , we can have a unified framework for shot boundary detection and consequently avoid to have special treatments for different shot boundary types as described in many works participated the TRECVID benchmark \CITE .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
By this way , we can have a unified framework for shot boundary detection and consequently avoid to have special treatments for different shot boundary types as described in many works participated the TRECVID benchmark \CITE .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
By this way , we can have a unified framework for shot boundary detection and consequently avoid to have special treatments for different shot boundary types as described in many works participated the TRECVID benchmark \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
By this way , we can have a unified framework for shot boundary detection and consequently avoid to have special treatments for different shot boundary types as described in many works participated the TRECVID benchmark \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
By this way , we can have a unified framework for shot boundary detection and consequently avoid to have special treatments for different shot boundary types as described in many works participated the TRECVID benchmark \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
By this way , we can have a unified framework for shot boundary detection and consequently avoid to have special treatments for different shot boundary types as described in many works participated the TRECVID benchmark \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
By this way , we can have a unified framework for shot boundary detection and consequently avoid to have special treatments for different shot boundary types as described in many works participated the TRECVID benchmark \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
The first order ( mean ) , the second order ( variance ) and the third order ( skewness ) color moments are defined as :
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
The basic steps to compute edge orientation histogram feature are as follows :
#<struct ReadData::Alignment source_numbers="2,3", target_numbers="2,3", tag_name="wa">
The basic steps to compute edge orientation histogram feature are as follows :
#<struct ReadData::Alignment source_numbers="4", target_numbers="4", tag_name="wa">
The histogram is normalized by the number of all pixels to compensate for different image sizes .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
We use color moments and edge orientation histogram to compute distances between the current frame \MATH and it neighbor frames as follows :
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Compute \MATH values which are the Euclidean distance between current frame \MATH and its neighbor frames ranging from \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
In other words , we compute \MATH where \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
It has been very efficiently proved in many pattern recognition applications \CITE .
#<struct ReadData::Alignment source_numbers="1,2", target_numbers="1,2", tag_name="wa">
It has been very efficiently proved in many pattern recognition applications \CITE .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
It has been very efficiently proved in many pattern recognition applications \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
It has been very efficiently proved in many pattern recognition applications \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
It has been very efficiently proved in many pattern recognition applications \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
It has been very efficiently proved in many pattern recognition applications \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
In the binary classification case , the objective of the SVM is to find a best separating hyperplane with a maximum margin .
#<struct ReadData::Alignment source_numbers="14,15", target_numbers="15,16", tag_name="wa">
where \MATH is the d-dimensional vector of an observation example , \MATH is a class label , \MATH is the vector of the \MATH training example , \MATH is the number of training examples , and \MATH is a kernel function , \MATH is learned through the learning process .
#<struct ReadData::Alignment source_numbers="46", target_numbers="13", tag_name="wa">
where \MATH is the d-dimensional vector of an observation example , \MATH is a class label , \MATH is the vector of the \MATH training example , \MATH is the number of training examples , and \MATH is a kernel function , \MATH is learned through the learning process .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
where \MATH is the d-dimensional vector of an observation example , \MATH is a class label , \MATH is the vector of the \MATH training example , \MATH is the number of training examples , and \MATH is a kernel function , \MATH is learned through the learning process .
#<struct ReadData::Alignment source_numbers="", target_numbers="46", tag_name="wa">
SVM were originally designed for binary classification .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
SVM were originally designed for binary classification .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
To handle the case of multi-class classification , there are two common approaches .
#<struct ReadData::Alignment source_numbers="13", target_numbers="9", tag_name="wa">
To handle the case of multi-class classification , there are two common approaches .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
To handle the case of multi-class classification , there are two common approaches .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
To handle the case of multi-class classification , there are two common approaches .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
To handle the case of multi-class classification , there are two common approaches .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
To handle the case of multi-class classification , there are two common approaches .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
To handle the case of multi-class classification , there are two common approaches .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
To handle the case of multi-class classification , there are two common approaches .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
To handle the case of multi-class classification , there are two common approaches .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
To handle the case of multi-class classification , there are two common approaches .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
To handle the case of multi-class classification , there are two common approaches .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
The first one is the one-against-all method that combines \MATH binary classifiers where \MATH is the number of classes .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
The \MATH SVM classifier is trained by positive samples being examples of the \MATH class and negative samples being examples of the other classes .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
The \MATH SVM classifier is trained by positive samples being examples of the \MATH class and negative samples being examples of the other classes .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
The \MATH SVM classifier is trained by positive samples being examples of the \MATH class and negative samples being examples of the other classes .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
The \MATH SVM classifier is trained by positive samples being examples of the \MATH class and negative samples being examples of the other classes .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
The \MATH SVM classifier is trained by positive samples being examples of the \MATH class and negative samples being examples of the other classes .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
The \MATH SVM classifier is trained by positive samples being examples of the \MATH class and negative samples being examples of the other classes .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
The second one is the one-against-one method that combines \MATH binary classifiers in which each classifier is trained on examples of two classes .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
The second one is the one-against-one method that combines \MATH binary classifiers in which each classifier is trained on examples of two classes .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
of a CUT transition ) , PRE GRAD ( pre-frame of a GRADUAL transition ) , IN GRAD ( frame inside a GRADUALtransition ) , POST GRAD ( post-frame of a GRADUAL transition ) and NORM-FRM ( normal frame which does not belong to any shot transitions ) .
#<struct ReadData::Alignment source_numbers="39,40,41,42", target_numbers="40,41,42,43", tag_name="wa">
of a CUT transition ) , PRE GRAD ( pre-frame of a GRADUAL transition ) , IN GRAD ( frame inside a GRADUALtransition ) , POST GRAD ( post-frame of a GRADUAL transition ) and NORM-FRM ( normal frame which does not belong to any shot transitions ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
To learn this classifier , we manually annotate frames in the training data .
#<struct ReadData::Alignment source_numbers="1", target_numbers="16", tag_name="wa">
To learn this classifier , we manually annotate frames in the training data .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
To learn this classifier , we manually annotate frames in the training data .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
To learn this classifier , we manually annotate frames in the training data .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
To learn this classifier , we manually annotate frames in the training data .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
To learn this classifier , we manually annotate frames in the training data .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
To learn this classifier , we manually annotate frames in the training data .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
To learn this classifier , we manually annotate frames in the training data .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
To learn this classifier , we manually annotate frames in the training data .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
To learn this classifier , we manually annotate frames in the training data .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
To learn this classifier , we manually annotate frames in the training data .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
To learn this classifier , we manually annotate frames in the training data .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
To learn this classifier , we manually annotate frames in the training data .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
A gradual transition usually has the pattern " ` . . . , PRE-GRAD , IN-GRAD , IN-GRAD , . . . , IN-GRAD , POS-GRAD , . . . " ' and a cut transition usually has the pattern " ` . . . , PRE-CUT , IN-CUT , . . . , IN-CUT , POST-CUT , . . . " ' .
#<struct ReadData::Alignment source_numbers="33", target_numbers="5", tag_name="wa">
A gradual transition usually has the pattern " ` . . . , PRE-GRAD , IN-GRAD , IN-GRAD , . . . , IN-GRAD , POS-GRAD , . . . " ' and a cut transition usually has the pattern " ` . . . , PRE-CUT , IN-CUT , . . . , IN-CUT , POST-CUT , . . . " ' .
#<struct ReadData::Alignment source_numbers="37,38", target_numbers="37,38", tag_name="wa">
A gradual transition usually has the pattern " ` . . . , PRE-GRAD , IN-GRAD , IN-GRAD , . . . , IN-GRAD , POS-GRAD , . . . " ' and a cut transition usually has the pattern " ` . . . , PRE-CUT , IN-CUT , . . . , IN-CUT , POST-CUT , . . . " ' .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
A gradual transition usually has the pattern " ` . . . , PRE-GRAD , IN-GRAD , IN-GRAD , . . . , IN-GRAD , POS-GRAD , . . . " ' and a cut transition usually has the pattern " ` . . . , PRE-CUT , IN-CUT , . . . , IN-CUT , POST-CUT , . . . " ' .
#<struct ReadData::Alignment source_numbers="39", target_numbers="", tag_name="wa">
A gradual transition usually has the pattern " ` . . . , PRE-GRAD , IN-GRAD , IN-GRAD , . . . , IN-GRAD , POS-GRAD , . . . " ' and a cut transition usually has the pattern " ` . . . , PRE-CUT , IN-CUT , . . . , IN-CUT , POST-CUT , . . . " ' .
#<struct ReadData::Alignment source_numbers="62", target_numbers="", tag_name="wa">
A gradual transition usually has the pattern " ` . . . , PRE-GRAD , IN-GRAD , IN-GRAD , . . . , IN-GRAD , POS-GRAD , . . . " ' and a cut transition usually has the pattern " ` . . . , PRE-CUT , IN-CUT , . . . , IN-CUT , POST-CUT , . . . " ' .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
A gradual transition usually has the pattern " ` . . . , PRE-GRAD , IN-GRAD , IN-GRAD , . . . , IN-GRAD , POS-GRAD , . . . " ' and a cut transition usually has the pattern " ` . . . , PRE-CUT , IN-CUT , . . . , IN-CUT , POST-CUT , . . . " ' .
#<struct ReadData::Alignment source_numbers="", target_numbers="61", tag_name="wa">
Since the classifier occasionally produce false predictions due to variations caused by photo flashes , rapid camera movement and object movement , only using the perfect match between the predefined patterns and sub-sequences usually skips many truth shot boundaries .
#<struct ReadData::Alignment source_numbers="28", target_numbers="9", tag_name="wa">
Since the classifier occasionally produce false predictions due to variations caused by photo flashes , rapid camera movement and object movement , only using the perfect match between the predefined patterns and sub-sequences usually skips many truth shot boundaries .
#<struct ReadData::Alignment source_numbers="21", target_numbers="19", tag_name="wa">
Since the classifier occasionally produce false predictions due to variations caused by photo flashes , rapid camera movement and object movement , only using the perfect match between the predefined patterns and sub-sequences usually skips many truth shot boundaries .
#<struct ReadData::Alignment source_numbers="36", target_numbers="40", tag_name="wa">
Since the classifier occasionally produce false predictions due to variations caused by photo flashes , rapid camera movement and object movement , only using the perfect match between the predefined patterns and sub-sequences usually skips many truth shot boundaries .
#<struct ReadData::Alignment source_numbers="39", target_numbers="43", tag_name="wa">
Since the classifier occasionally produce false predictions due to variations caused by photo flashes , rapid camera movement and object movement , only using the perfect match between the predefined patterns and sub-sequences usually skips many truth shot boundaries .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
Since the classifier occasionally produce false predictions due to variations caused by photo flashes , rapid camera movement and object movement , only using the perfect match between the predefined patterns and sub-sequences usually skips many truth shot boundaries .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
Since the classifier occasionally produce false predictions due to variations caused by photo flashes , rapid camera movement and object movement , only using the perfect match between the predefined patterns and sub-sequences usually skips many truth shot boundaries .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
Since the classifier occasionally produce false predictions due to variations caused by photo flashes , rapid camera movement and object movement , only using the perfect match between the predefined patterns and sub-sequences usually skips many truth shot boundaries .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
We divided 8 videos , each 30-minute length , into two sets : training set and testing set .
#<struct ReadData::Alignment source_numbers="16", target_numbers="17,18", tag_name="wa">
The number of frames , the number of shot boundaries and types of these sets are shown in Table \REF .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Note that , the number of shot boundaries is equal to the number of frames with PRE-CUT / GRAD label and the number of frames with PRE-CUT / GRAD label is equal to the number of frames with POST-CUT / GRAD label .
#<struct ReadData::Alignment source_numbers="37", target_numbers="", tag_name="wa">
Note that , the number of shot boundaries is equal to the number of frames with PRE-CUT / GRAD label and the number of frames with PRE-CUT / GRAD label is equal to the number of frames with POST-CUT / GRAD label .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
Note that , the number of shot boundaries is equal to the number of frames with PRE-CUT / GRAD label and the number of frames with PRE-CUT / GRAD label is equal to the number of frames with POST-CUT / GRAD label .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
We used \MATH grid for dividing the input image into sub-images .
#<struct ReadData::Alignment source_numbers="5", target_numbers="4,5", tag_name="wa">
We used \MATH grid for dividing the input image into sub-images .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
where \MATH is the \MATH-th element of the feature vectors \MATH respectively , \MATH is the number of dimensions .
#<struct ReadData::Alignment source_numbers="12", target_numbers="11", tag_name="wa">
where \MATH is the \MATH-th element of the feature vectors \MATH respectively , \MATH is the number of dimensions .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
where \MATH is the \MATH-th element of the feature vectors \MATH respectively , \MATH is the number of dimensions .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
In order to handle the problem of imbalanced training sets where the number of NORM-FRM frames is much larger than other frames , we randomly take \MATH of NORM-FRM frames and 100\% of the other frames to form the training set .
#<struct ReadData::Alignment source_numbers="38", target_numbers="26", tag_name="wa">
In order to handle the problem of imbalanced training sets where the number of NORM-FRM frames is much larger than other frames , we randomly take \MATH of NORM-FRM frames and 100\% of the other frames to form the training set .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
We use LibSVM \CITE to train SVM classifiers with RBF kernel .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
The results that were evaluated by a tool provided by TRECVID with standard measurement such as precision , recall and F1 score clearly show that our proposed method significantly outperforms the baseline method and the combination of GCM+EOH obtains the best result .
#<struct ReadData::Alignment source_numbers="17", target_numbers="15", tag_name="wa">
The results that were evaluated by a tool provided by TRECVID with standard measurement such as precision , recall and F1 score clearly show that our proposed method significantly outperforms the baseline method and the combination of GCM+EOH obtains the best result .
#<struct ReadData::Alignment source_numbers="39", target_numbers="18", tag_name="wa">
The results that were evaluated by a tool provided by TRECVID with standard measurement such as precision , recall and F1 score clearly show that our proposed method significantly outperforms the baseline method and the combination of GCM+EOH obtains the best result .
#<struct ReadData::Alignment source_numbers="42", target_numbers="47", tag_name="wa">
The results that were evaluated by a tool provided by TRECVID with standard measurement such as precision , recall and F1 score clearly show that our proposed method significantly outperforms the baseline method and the combination of GCM+EOH obtains the best result .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
The results that were evaluated by a tool provided by TRECVID with standard measurement such as precision , recall and F1 score clearly show that our proposed method significantly outperforms the baseline method and the combination of GCM+EOH obtains the best result .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
The results that were evaluated by a tool provided by TRECVID with standard measurement such as precision , recall and F1 score clearly show that our proposed method significantly outperforms the baseline method and the combination of GCM+EOH obtains the best result .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
The results that were evaluated by a tool provided by TRECVID with standard measurement such as precision , recall and F1 score clearly show that our proposed method significantly outperforms the baseline method and the combination of GCM+EOH obtains the best result .
#<struct ReadData::Alignment source_numbers="", target_numbers="44", tag_name="wa">
We evaluated the performance of our system with different choices for taking the number of NORM -FRM frames used in training process .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
We evaluated the performance of our system with different choices for taking the number of NORM -FRM frames used in training process .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
We evaluated the performance of our system with different choices for taking the number of NORM -FRM frames used in training process .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
Specifically , we selected three sampling rates \MATH which are \MATH and \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
As shown in Figure \REF , the best performance is obtained with the sampling rate of \MATH .
#<struct ReadData::Alignment source_numbers="9", target_numbers="9", tag_name="wa">
As shown in Figure \REF , the best performance is obtained with the sampling rate of \MATH .
#<struct ReadData::Alignment source_numbers="10", target_numbers="10", tag_name="wa">
As shown in Figure \REF , the best performance is obtained with the sampling rate of \MATH .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
As shown in Figure \REF , the best performance is obtained with the sampling rate of \MATH .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
As shown in Figure \REF , the best performance is obtained with the sampling rate of \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
As shown in Figure \REF , the best performance is obtained with the sampling rate of \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
In Table \REF we show the evaluation of using different features for forming the feature vector using distances between current frames and its neighbors .
#<struct ReadData::Alignment source_numbers="12", target_numbers="14", tag_name="wa">
In Table \REF we show the evaluation of using different features for forming the feature vector using distances between current frames and its neighbors .
#<struct ReadData::Alignment source_numbers="24", target_numbers="28", tag_name="wa">
In Table \REF we show the evaluation of using different features for forming the feature vector using distances between current frames and its neighbors .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
In Table \REF we show the evaluation of using different features for forming the feature vector using distances between current frames and its neighbors .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
In Table \REF we show the evaluation of using different features for forming the feature vector using distances between current frames and its neighbors .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
In Table \REF we show the evaluation of using different features for forming the feature vector using distances between current frames and its neighbors .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
In Table \REF we show the evaluation of using different features for forming the feature vector using distances between current frames and its neighbors .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
In Table \REF we show the evaluation of using different features for forming the feature vector using distances between current frames and its neighbors .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
In Table \REF we show the evaluation of using different features for forming the feature vector using distances between current frames and its neighbors .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
In Table \REF we show the evaluation of using different features for forming the feature vector using distances between current frames and its neighbors .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
The first one is GCM , the second one is EOH and the last one GCM+EOH is combination of distances using GCM and distances using EOH .
#<struct ReadData::Alignment source_numbers="26", target_numbers="30", tag_name="wa">
The first one is GCM , the second one is EOH and the last one GCM+EOH is combination of distances using GCM and distances using EOH .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
The number of dimensions of feature vectors using GCM and EOH is 20 while that of feature vectors using GCM+EOH is 40 .
#<struct ReadData::Alignment source_numbers="11,12", target_numbers="12,13", tag_name="wa">
The number of dimensions of feature vectors using GCM and EOH is 20 while that of feature vectors using GCM+EOH is 40 .
#<struct ReadData::Alignment source_numbers="20,21", target_numbers="22,23", tag_name="wa">
The number of dimensions of feature vectors using GCM and EOH is 20 while that of feature vectors using GCM+EOH is 40 .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
We also compare the proposed method with the baseline method that computes differences in color histograms between two consecutive frames and then decides a shot transitition by using a predefined threshold .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
We also compare the proposed method with the baseline method that computes differences in color histograms between two consecutive frames and then decides a shot transitition by using a predefined threshold .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
We also compare the proposed method with the baseline method that computes differences in color histograms between two consecutive frames and then decides a shot transitition by using a predefined threshold .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
Our system achieves high precision and recall for the CUT transition and the result is comparable with the third-ranked system .
#<struct ReadData::Alignment source_numbers="12,13", target_numbers="13,14", tag_name="wa">
Our system achieves high precision and recall for the CUT transition and the result is comparable with the third-ranked system .
#<struct ReadData::Alignment source_numbers="15,16", target_numbers="16,17", tag_name="wa">
Many previous shot boundary detectors usually divided the system into sub-systems in which special treatments were proposed to handle different types of shot transitions .
#<struct ReadData::Alignment source_numbers="6,7", target_numbers="6,7", tag_name="wa">
Many previous shot boundary detectors usually divided the system into sub-systems in which special treatments were proposed to handle different types of shot transitions .
#<struct ReadData::Alignment source_numbers="15", target_numbers="15", tag_name="wa">
Many previous shot boundary detectors usually divided the system into sub-systems in which special treatments were proposed to handle different types of shot transitions .
#<struct ReadData::Alignment source_numbers="16", target_numbers="16", tag_name="wa">
Therefore , it is difficult to generalize for new test sets .
#<struct ReadData::Alignment source_numbers="2", target_numbers="2", tag_name="wa">
Therefore , it is difficult to generalize for new test sets .
#<struct ReadData::Alignment source_numbers="3", target_numbers="3", tag_name="wa">
Therefore , it is difficult to generalize for new test sets .
#<struct ReadData::Alignment source_numbers="6", target_numbers="4", tag_name="wa">
Therefore , it is difficult to generalize for new test sets .
#<struct ReadData::Alignment source_numbers="4", target_numbers="6", tag_name="wa">
Therefore , it is difficult to generalize for new test sets .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Therefore , it is difficult to generalize for new test sets .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Different from these approaches , in this paper , we have proposed a unified and general framework for shot boundary detection using a text segmentation based approach .
#<struct ReadData::Alignment source_numbers="21", target_numbers="13", tag_name="wa">
Different from these approaches , in this paper , we have proposed a unified and general framework for shot boundary detection using a text segmentation based approach .
#<struct ReadData::Alignment source_numbers="27", target_numbers="19", tag_name="wa">
Different from these approaches , in this paper , we have proposed a unified and general framework for shot boundary detection using a text segmentation based approach .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Different from these approaches , in this paper , we have proposed a unified and general framework for shot boundary detection using a text segmentation based approach .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Different from these approaches , in this paper , we have proposed a unified and general framework for shot boundary detection using a text segmentation based approach .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Different from these approaches , in this paper , we have proposed a unified and general framework for shot boundary detection using a text segmentation based approach .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
Different from these approaches , in this paper , we have proposed a unified and general framework for shot boundary detection using a text segmentation based approach .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
Different from these approaches , in this paper , we have proposed a unified and general framework for shot boundary detection using a text segmentation based approach .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Different from these approaches , in this paper , we have proposed a unified and general framework for shot boundary detection using a text segmentation based approach .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
Different from these approaches , in this paper , we have proposed a unified and general framework for shot boundary detection using a text segmentation based approach .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Different from these approaches , in this paper , we have proposed a unified and general framework for shot boundary detection using a text segmentation based approach .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Different from these approaches , in this paper , we have proposed a unified and general framework for shot boundary detection using a text segmentation based approach .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Different from these approaches , in this paper , we have proposed a unified and general framework for shot boundary detection using a text segmentation based approach .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Different from these approaches , in this paper , we have proposed a unified and general framework for shot boundary detection using a text segmentation based approach .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
Firstly , we label frames by one of six labels defined for different types of frames : NORM -FRM , PRE -CUT , POST -CUT , PRE -GRAD , IN -GRAD and POST -GRAD .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Firstly , we label frames by one of six labels defined for different types of frames : NORM -FRM , PRE -CUT , POST -CUT , PRE -GRAD , IN -GRAD and POST -GRAD .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Firstly , we label frames by one of six labels defined for different types of frames : NORM -FRM , PRE -CUT , POST -CUT , PRE -GRAD , IN -GRAD and POST -GRAD .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
Experiments on various videos of TRECVID 2003 have shown that our approach is effective .
#<struct ReadData::Alignment source_numbers="3,4", target_numbers="6,7", tag_name="wa">
Experiments on various videos of TRECVID 2003 have shown that our approach is effective .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Experiments on various videos of TRECVID 2003 have shown that our approach is effective .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Experiments on various videos of TRECVID 2003 have shown that our approach is effective .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Experiments on various videos of TRECVID 2003 have shown that our approach is effective .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Recently , boosting is used widely in object detection applications because of its impressive performance in both speed and accuracy .
#<struct ReadData::Alignment source_numbers="4", target_numbers="7", tag_name="wa">
Recently , boosting is used widely in object detection applications because of its impressive performance in both speed and accuracy .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Recently , boosting is used widely in object detection applications because of its impressive performance in both speed and accuracy .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
However , learning weak classifiers which is one of the most significant tasks in using boosting is left for users .
#<struct ReadData::Alignment source_numbers="17,18", target_numbers="19,20", tag_name="wa">
However , learning weak classifiers which is one of the most significant tasks in using boosting is left for users .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
However , learning weak classifiers which is one of the most significant tasks in using boosting is left for users .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
However , learning weak classifiers which is one of the most significant tasks in using boosting is left for users .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
However , learning weak classifiers which is one of the most significant tasks in using boosting is left for users .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
However , learning weak classifiers which is one of the most significant tasks in using boosting is left for users .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
However , learning weak classifiers which is one of the most significant tasks in using boosting is left for users .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
However , learning weak classifiers which is one of the most significant tasks in using boosting is left for users .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
However , learning weak classifiers which is one of the most significant tasks in using boosting is left for users .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
However , learning weak classifiers which is one of the most significant tasks in using boosting is left for users .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
However , learning weak classifiers which is one of the most significant tasks in using boosting is left for users .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
However , learning weak classifiers which is one of the most significant tasks in using boosting is left for users .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
However , learning weak classifiers which is one of the most significant tasks in using boosting is left for users .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
However , learning weak classifiers which is one of the most significant tasks in using boosting is left for users .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
However , learning weak classifiers which is one of the most significant tasks in using boosting is left for users .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
However , learning weak classifiers which is one of the most significant tasks in using boosting is left for users .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
However , learning weak classifiers which is one of the most significant tasks in using boosting is left for users .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
However , learning weak classifiers which is one of the most significant tasks in using boosting is left for users .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
However , learning weak classifiers which is one of the most significant tasks in using boosting is left for users .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
However , learning weak classifiers which is one of the most significant tasks in using boosting is left for users .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
However , learning weak classifiers which is one of the most significant tasks in using boosting is left for users .
#<struct ReadData::Alignment source_numbers="", target_numbers="40", tag_name="wa">
However , learning weak classifiers which is one of the most significant tasks in using boosting is left for users .
#<struct ReadData::Alignment source_numbers="", target_numbers="41", tag_name="wa">
However , learning weak classifiers which is one of the most significant tasks in using boosting is left for users .
#<struct ReadData::Alignment source_numbers="", target_numbers="42", tag_name="wa">
However , learning weak classifiers which is one of the most significant tasks in using boosting is left for users .
#<struct ReadData::Alignment source_numbers="", target_numbers="43", tag_name="wa">
However , learning weak classifiers which is one of the most significant tasks in using boosting is left for users .
#<struct ReadData::Alignment source_numbers="", target_numbers="44", tag_name="wa">
However , learning weak classifiers which is one of the most significant tasks in using boosting is left for users .
#<struct ReadData::Alignment source_numbers="", target_numbers="45", tag_name="wa">
However , learning weak classifiers which is one of the most significant tasks in using boosting is left for users .
#<struct ReadData::Alignment source_numbers="", target_numbers="46", tag_name="wa">
However , learning weak classifiers which is one of the most significant tasks in using boosting is left for users .
#<struct ReadData::Alignment source_numbers="", target_numbers="47", tag_name="wa">
However , learning weak classifiers which is one of the most significant tasks in using boosting is left for users .
#<struct ReadData::Alignment source_numbers="", target_numbers="48", tag_name="wa">
However , learning weak classifiers which is one of the most significant tasks in using boosting is left for users .
#<struct ReadData::Alignment source_numbers="", target_numbers="49", tag_name="wa">
However , learning weak classifiers which is one of the most significant tasks in using boosting is left for users .
#<struct ReadData::Alignment source_numbers="", target_numbers="50", tag_name="wa">
However , learning weak classifiers which is one of the most significant tasks in using boosting is left for users .
#<struct ReadData::Alignment source_numbers="", target_numbers="51", tag_name="wa">
However , learning weak classifiers which is one of the most significant tasks in using boosting is left for users .
#<struct ReadData::Alignment source_numbers="", target_numbers="52", tag_name="wa">
However , learning weak classifiers which is one of the most significant tasks in using boosting is left for users .
#<struct ReadData::Alignment source_numbers="", target_numbers="53", tag_name="wa">
However , learning weak classifiers which is one of the most significant tasks in using boosting is left for users .
#<struct ReadData::Alignment source_numbers="", target_numbers="54", tag_name="wa">
However , learning weak classifiers which is one of the most significant tasks in using boosting is left for users .
#<struct ReadData::Alignment source_numbers="", target_numbers="55", tag_name="wa">
However , learning weak classifiers which is one of the most significant tasks in using boosting is left for users .
#<struct ReadData::Alignment source_numbers="", target_numbers="56", tag_name="wa">
However , learning weak classifiers which is one of the most significant tasks in using boosting is left for users .
#<struct ReadData::Alignment source_numbers="", target_numbers="57", tag_name="wa">
However , learning weak classifiers which is one of the most significant tasks in using boosting is left for users .
#<struct ReadData::Alignment source_numbers="", target_numbers="58", tag_name="wa">
Meanwhile , determining the appropriate number of bins for weak classifiers learned by Real AdaBoost is a challenging task because small one might not well approximate the real distribution while large one might cause over-fitting , increase computation time and waste storage space .
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
Meanwhile , determining the appropriate number of bins for weak classifiers learned by Real AdaBoost is a challenging task because small one might not well approximate the real distribution while large one might cause over-fitting , increase computation time and waste storage space .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
Meanwhile , determining the appropriate number of bins for weak classifiers learned by Real AdaBoost is a challenging task because small one might not well approximate the real distribution while large one might cause over-fitting , increase computation time and waste storage space .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
This paper describes a novel method for efficiently learning weak classifiers using entropy measures , called Ent-Boost .
#<struct ReadData::Alignment source_numbers="14", target_numbers="4", tag_name="wa">
This paper describes a novel method for efficiently learning weak classifiers using entropy measures , called Ent-Boost .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
This paper describes a novel method for efficiently learning weak classifiers using entropy measures , called Ent-Boost .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
This paper describes a novel method for efficiently learning weak classifiers using entropy measures , called Ent-Boost .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
This paper describes a novel method for efficiently learning weak classifiers using entropy measures , called Ent-Boost .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
This paper describes a novel method for efficiently learning weak classifiers using entropy measures , called Ent-Boost .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
This paper describes a novel method for efficiently learning weak classifiers using entropy measures , called Ent-Boost .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
This paper describes a novel method for efficiently learning weak classifiers using entropy measures , called Ent-Boost .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
This paper describes a novel method for efficiently learning weak classifiers using entropy measures , called Ent-Boost .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
This paper describes a novel method for efficiently learning weak classifiers using entropy measures , called Ent-Boost .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
This paper describes a novel method for efficiently learning weak classifiers using entropy measures , called Ent-Boost .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
This paper describes a novel method for efficiently learning weak classifiers using entropy measures , called Ent-Boost .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
The class entropy information is used to estimate the optimal number of bins automatically through discretization process .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
The class entropy information is used to estimate the optimal number of bins automatically through discretization process .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
The class entropy information is used to estimate the optimal number of bins automatically through discretization process .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Then Kullback-Leibler divergence which is the relative entropy between probability distributions of positive and negative samples is employed to select the best weak classifier in the weak classifier set .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Then Kullback-Leibler divergence which is the relative entropy between probability distributions of positive and negative samples is employed to select the best weak classifier in the weak classifier set .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Experiments have shown that strong classifiers learned by Ent-Boost can achieve good performance , and have compact storage space .
#<struct ReadData::Alignment source_numbers="16", target_numbers="22", tag_name="wa">
Experiments have shown that strong classifiers learned by Ent-Boost can achieve good performance , and have compact storage space .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
Experiments have shown that strong classifiers learned by Ent-Boost can achieve good performance , and have compact storage space .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
Experiments have shown that strong classifiers learned by Ent-Boost can achieve good performance , and have compact storage space .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
Experiments have shown that strong classifiers learned by Ent-Boost can achieve good performance , and have compact storage space .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
Experiments have shown that strong classifiers learned by Ent-Boost can achieve good performance , and have compact storage space .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Experiments have shown that strong classifiers learned by Ent-Boost can achieve good performance , and have compact storage space .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Experiments have shown that strong classifiers learned by Ent-Boost can achieve good performance , and have compact storage space .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
Experiments have shown that strong classifiers learned by Ent-Boost can achieve good performance , and have compact storage space .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Experiments have shown that strong classifiers learned by Ent-Boost can achieve good performance , and have compact storage space .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
Experiments have shown that strong classifiers learned by Ent-Boost can achieve good performance , and have compact storage space .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
Experiments have shown that strong classifiers learned by Ent-Boost can achieve good performance , and have compact storage space .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
Experiments have shown that strong classifiers learned by Ent-Boost can achieve good performance , and have compact storage space .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
Experiments have shown that strong classifiers learned by Ent-Boost can achieve good performance , and have compact storage space .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
Results on building a robust face detector are also reported .
#<struct ReadData::Alignment source_numbers="10", target_numbers="17", tag_name="wa">
Results on building a robust face detector are also reported .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Results on building a robust face detector are also reported .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Results on building a robust face detector are also reported .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Results on building a robust face detector are also reported .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Results on building a robust face detector are also reported .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Results on building a robust face detector are also reported .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Results on building a robust face detector are also reported .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Results on building a robust face detector are also reported .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Results on building a robust face detector are also reported .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Results on building a robust face detector are also reported .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Results on building a robust face detector are also reported .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
Results on building a robust face detector are also reported .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
Results on building a robust face detector are also reported .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Results on building a robust face detector are also reported .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Results on building a robust face detector are also reported .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
Results on building a robust face detector are also reported .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
Several kinds of classifiers , such as Neural Network [1] and Support Vector Machines [2] , have been proposed and applied successfully in many object-detection systems .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Several kinds of classifiers , such as Neural Network [1] and Support Vector Machines [2] , have been proposed and applied successfully in many object-detection systems .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Several kinds of classifiers , such as Neural Network [1] and Support Vector Machines [2] , have been proposed and applied successfully in many object-detection systems .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
Several kinds of classifiers , such as Neural Network [1] and Support Vector Machines [2] , have been proposed and applied successfully in many object-detection systems .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
Several kinds of classifiers , such as Neural Network [1] and Support Vector Machines [2] , have been proposed and applied successfully in many object-detection systems .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
Several kinds of classifiers , such as Neural Network [1] and Support Vector Machines [2] , have been proposed and applied successfully in many object-detection systems .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Several kinds of classifiers , such as Neural Network [1] and Support Vector Machines [2] , have been proposed and applied successfully in many object-detection systems .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Several kinds of classifiers , such as Neural Network [1] and Support Vector Machines [2] , have been proposed and applied successfully in many object-detection systems .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
Several kinds of classifiers , such as Neural Network [1] and Support Vector Machines [2] , have been proposed and applied successfully in many object-detection systems .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
Several kinds of classifiers , such as Neural Network [1] and Support Vector Machines [2] , have been proposed and applied successfully in many object-detection systems .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Boosting [3] and its variants [4] ,[5] ,[6] ,[7] ,[8] ,[9] ,[10] have recently gained a lot of attentions from researchers because of its excellent performance .
#<struct ReadData::Alignment source_numbers="15,16", target_numbers="11", tag_name="wa">
Boosting [3] and its variants [4] ,[5] ,[6] ,[7] ,[8] ,[9] ,[10] have recently gained a lot of attentions from researchers because of its excellent performance .
#<struct ReadData::Alignment source_numbers="18", target_numbers="12", tag_name="wa">
Boosting [3] and its variants [4] ,[5] ,[6] ,[7] ,[8] ,[9] ,[10] have recently gained a lot of attentions from researchers because of its excellent performance .
#<struct ReadData::Alignment source_numbers="17", target_numbers="16", tag_name="wa">
Boosting [3] and its variants [4] ,[5] ,[6] ,[7] ,[8] ,[9] ,[10] have recently gained a lot of attentions from researchers because of its excellent performance .
#<struct ReadData::Alignment source_numbers="22,23", target_numbers="17", tag_name="wa">
Boosting [3] and its variants [4] ,[5] ,[6] ,[7] ,[8] ,[9] ,[10] have recently gained a lot of attentions from researchers because of its excellent performance .
#<struct ReadData::Alignment source_numbers="26", target_numbers="20", tag_name="wa">
Boosting [3] and its variants [4] ,[5] ,[6] ,[7] ,[8] ,[9] ,[10] have recently gained a lot of attentions from researchers because of its excellent performance .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
Boosting [3] and its variants [4] ,[5] ,[6] ,[7] ,[8] ,[9] ,[10] have recently gained a lot of attentions from researchers because of its excellent performance .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Boosting [3] and its variants [4] ,[5] ,[6] ,[7] ,[8] ,[9] ,[10] have recently gained a lot of attentions from researchers because of its excellent performance .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Boosting [3] and its variants [4] ,[5] ,[6] ,[7] ,[8] ,[9] ,[10] have recently gained a lot of attentions from researchers because of its excellent performance .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Boosting [3] and its variants [4] ,[5] ,[6] ,[7] ,[8] ,[9] ,[10] have recently gained a lot of attentions from researchers because of its excellent performance .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Boosting [3] and its variants [4] ,[5] ,[6] ,[7] ,[8] ,[9] ,[10] have recently gained a lot of attentions from researchers because of its excellent performance .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
Boosting [3] and its variants [4] ,[5] ,[6] ,[7] ,[8] ,[9] ,[10] have recently gained a lot of attentions from researchers because of its excellent performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Boosting [3] and its variants [4] ,[5] ,[6] ,[7] ,[8] ,[9] ,[10] have recently gained a lot of attentions from researchers because of its excellent performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
In regards to face detection , for example , the methods described in works [4] ,[5] ,[10] represent the state of the art in terms of both high accuracy and running speed .
#<struct ReadData::Alignment source_numbers="29", target_numbers="17", tag_name="wa">
In regards to face detection , for example , the methods described in works [4] ,[5] ,[10] represent the state of the art in terms of both high accuracy and running speed .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
In regards to face detection , for example , the methods described in works [4] ,[5] ,[10] represent the state of the art in terms of both high accuracy and running speed .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
In regards to face detection , for example , the methods described in works [4] ,[5] ,[10] represent the state of the art in terms of both high accuracy and running speed .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
In regards to face detection , for example , the methods described in works [4] ,[5] ,[10] represent the state of the art in terms of both high accuracy and running speed .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
In regards to face detection , for example , the methods described in works [4] ,[5] ,[10] represent the state of the art in terms of both high accuracy and running speed .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
In regards to face detection , for example , the methods described in works [4] ,[5] ,[10] represent the state of the art in terms of both high accuracy and running speed .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
In regards to face detection , for example , the methods described in works [4] ,[5] ,[10] represent the state of the art in terms of both high accuracy and running speed .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
In regards to face detection , for example , the methods described in works [4] ,[5] ,[10] represent the state of the art in terms of both high accuracy and running speed .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
In regards to face detection , for example , the methods described in works [4] ,[5] ,[10] represent the state of the art in terms of both high accuracy and running speed .
#<struct ReadData::Alignment source_numbers="27", target_numbers="", tag_name="wa">
In regards to face detection , for example , the methods described in works [4] ,[5] ,[10] represent the state of the art in terms of both high accuracy and running speed .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
In regards to face detection , for example , the methods described in works [4] ,[5] ,[10] represent the state of the art in terms of both high accuracy and running speed .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
In regards to face detection , for example , the methods described in works [4] ,[5] ,[10] represent the state of the art in terms of both high accuracy and running speed .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
In regards to face detection , for example , the methods described in works [4] ,[5] ,[10] represent the state of the art in terms of both high accuracy and running speed .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
In regards to face detection , for example , the methods described in works [4] ,[5] ,[10] represent the state of the art in terms of both high accuracy and running speed .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
In regards to face detection , for example , the methods described in works [4] ,[5] ,[10] represent the state of the art in terms of both high accuracy and running speed .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
In regards to face detection , for example , the methods described in works [4] ,[5] ,[10] represent the state of the art in terms of both high accuracy and running speed .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
Typically , each weak classifier is any classifier whose performance is better than random guessing ( i.e. , error rate is less than 0 .5 ) .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Typically , each weak classifier is any classifier whose performance is better than random guessing ( i.e. , error rate is less than 0 .5 ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Performances of weak classifiers are integrated into the final form of the strong classifier through a learning process in which more accurate weak classifiers have larger weights in final voting .
#<struct ReadData::Alignment source_numbers="11,12", target_numbers="13,14", tag_name="wa">
Performances of weak classifiers are integrated into the final form of the strong classifier through a learning process in which more accurate weak classifiers have larger weights in final voting .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Performances of weak classifiers are integrated into the final form of the strong classifier through a learning process in which more accurate weak classifiers have larger weights in final voting .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
In practical problems , designing and learning weak classifiers are left for practitioners with two main challenges : computational evaluation and discriminant power .
#<struct ReadData::Alignment source_numbers="10", target_numbers="9", tag_name="wa">
In practical problems , designing and learning weak classifiers are left for practitioners with two main challenges : computational evaluation and discriminant power .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
In practical problems , designing and learning weak classifiers are left for practitioners with two main challenges : computational evaluation and discriminant power .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
Generally , for efficient computation , the dimension of the input space of weak classifiers is reduced to much lower than that of the strong classifier .
#<struct ReadData::Alignment source_numbers="7,8", target_numbers="7,8", tag_name="wa">
Generally , for efficient computation , the dimension of the input space of weak classifiers is reduced to much lower than that of the strong classifier .
#<struct ReadData::Alignment source_numbers="15", target_numbers="15", tag_name="wa">
Generally , for efficient computation , the dimension of the input space of weak classifiers is reduced to much lower than that of the strong classifier .
#<struct ReadData::Alignment source_numbers="16", target_numbers="16", tag_name="wa">
Generally , for efficient computation , the dimension of the input space of weak classifiers is reduced to much lower than that of the strong classifier .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
Generally , for efficient computation , the dimension of the input space of weak classifiers is reduced to much lower than that of the strong classifier .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
Generally , for efficient computation , the dimension of the input space of weak classifiers is reduced to much lower than that of the strong classifier .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
Generally , for efficient computation , the dimension of the input space of weak classifiers is reduced to much lower than that of the strong classifier .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
In object-detection frameworks [4] ,[5] ,[11] ,[12] ,[13] weak classifiers are usually constructed from one or several features .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
In object-detection frameworks [4] ,[5] ,[11] ,[12] ,[13] weak classifiers are usually constructed from one or several features .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
In object-detection frameworks [4] ,[5] ,[11] ,[12] ,[13] weak classifiers are usually constructed from one or several features .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
In object-detection frameworks [4] ,[5] ,[11] ,[12] ,[13] weak classifiers are usually constructed from one or several features .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
In object-detection frameworks [4] ,[5] ,[11] ,[12] ,[13] weak classifiers are usually constructed from one or several features .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
In object-detection frameworks [4] ,[5] ,[11] ,[12] ,[13] weak classifiers are usually constructed from one or several features .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
In object-detection frameworks [4] ,[5] ,[11] ,[12] ,[13] weak classifiers are usually constructed from one or several features .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
In object-detection frameworks [4] ,[5] ,[11] ,[12] ,[13] weak classifiers are usually constructed from one or several features .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
In object-detection frameworks [4] ,[5] ,[11] ,[12] ,[13] weak classifiers are usually constructed from one or several features .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
In object-detection frameworks [4] ,[5] ,[11] ,[12] ,[13] weak classifiers are usually constructed from one or several features .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
In object-detection frameworks [4] ,[5] ,[11] ,[12] ,[13] weak classifiers are usually constructed from one or several features .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Given a feature type , choosing the suitable way to form a weak classifier that balance efficiency and computation is still a open problem [14] .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
Given a feature type , choosing the suitable way to form a weak classifier that balance efficiency and computation is still a open problem [14] .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
There are two key trends for seeking the most discriminant weak classifier .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
There are two key trends for seeking the most discriminant weak classifier .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
There are two key trends for seeking the most discriminant weak classifier .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
There are two key trends for seeking the most discriminant weak classifier .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
There are two key trends for seeking the most discriminant weak classifier .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
The first trend is dealing with the problem of how to design features for best representation of the target object .
#<struct ReadData::Alignment source_numbers="15,16,17", target_numbers="15,16", tag_name="wa">
Besides Haar wavelet features [4] , Gabor wavelets [5] , edge orientation histogram ( EOH ) [11] , orientation dominants [12] , scale invariant feature transform ( SIFT )-based-high-level features [13] and local binary pattern ( LBP ) [15] have also been used .
#<struct ReadData::Alignment source_numbers="28", target_numbers="", tag_name="wa">
Besides Haar wavelet features [4] , Gabor wavelets [5] , edge orientation histogram ( EOH ) [11] , orientation dominants [12] , scale invariant feature transform ( SIFT )-based-high-level features [13] and local binary pattern ( LBP ) [15] have also been used .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
Besides Haar wavelet features [4] , Gabor wavelets [5] , edge orientation histogram ( EOH ) [11] , orientation dominants [12] , scale invariant feature transform ( SIFT )-based-high-level features [13] and local binary pattern ( LBP ) [15] have also been used .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
Besides Haar wavelet features [4] , Gabor wavelets [5] , edge orientation histogram ( EOH ) [11] , orientation dominants [12] , scale invariant feature transform ( SIFT )-based-high-level features [13] and local binary pattern ( LBP ) [15] have also been used .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
In Discrete AdaBoost [16] , weak classifiers are threshold-functions whose the output is restricted to binary .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
In Discrete AdaBoost [16] , weak classifiers are threshold-functions whose the output is restricted to binary .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
In Discrete AdaBoost [16] , weak classifiers are threshold-functions whose the output is restricted to binary .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
In Discrete AdaBoost [16] , weak classifiers are threshold-functions whose the output is restricted to binary .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
In Discrete AdaBoost [16] , weak classifiers are threshold-functions whose the output is restricted to binary .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
In Discrete AdaBoost [16] , weak classifiers are threshold-functions whose the output is restricted to binary .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
In Discrete AdaBoost [16] , weak classifiers are threshold-functions whose the output is restricted to binary .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
In Discrete AdaBoost [16] , weak classifiers are threshold-functions whose the output is restricted to binary .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
In Discrete AdaBoost [16] , weak classifiers are threshold-functions whose the output is restricted to binary .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
In Discrete AdaBoost [16] , weak classifiers are threshold-functions whose the output is restricted to binary .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
In Discrete AdaBoost [16] , weak classifiers are threshold-functions whose the output is restricted to binary .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
In Discrete AdaBoost [16] , weak classifiers are threshold-functions whose the output is restricted to binary .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
This leads weak classifiers are too weak to boost when handling complex data sets .
#<struct ReadData::Alignment source_numbers="4,5", target_numbers="4,5,6", tag_name="wa">
Typically , most current works [5] ,[17] ,[6] ,[8] ,[10] split the data into \MATH bins that are equal width which suffers from following limitations :
#<struct ReadData::Alignment source_numbers="25", target_numbers="33", tag_name="wa">
Typically , most current works [5] ,[17] ,[6] ,[8] ,[10] split the data into \MATH bins that are equal width which suffers from following limitations :
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
Typically , most current works [5] ,[17] ,[6] ,[8] ,[10] split the data into \MATH bins that are equal width which suffers from following limitations :
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Typically , most current works [5] ,[17] ,[6] ,[8] ,[10] split the data into \MATH bins that are equal width which suffers from following limitations :
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Typically , most current works [5] ,[17] ,[6] ,[8] ,[10] split the data into \MATH bins that are equal width which suffers from following limitations :
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Typically , most current works [5] ,[17] ,[6] ,[8] ,[10] split the data into \MATH bins that are equal width which suffers from following limitations :
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
Typically , most current works [5] ,[17] ,[6] ,[8] ,[10] split the data into \MATH bins that are equal width which suffers from following limitations :
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Typically , most current works [5] ,[17] ,[6] ,[8] ,[10] split the data into \MATH bins that are equal width which suffers from following limitations :
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Typically , most current works [5] ,[17] ,[6] ,[8] ,[10] split the data into \MATH bins that are equal width which suffers from following limitations :
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Typically , most current works [5] ,[17] ,[6] ,[8] ,[10] split the data into \MATH bins that are equal width which suffers from following limitations :
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Typically , most current works [5] ,[17] ,[6] ,[8] ,[10] split the data into \MATH bins that are equal width which suffers from following limitations :
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Typically , most current works [5] ,[17] ,[6] ,[8] ,[10] split the data into \MATH bins that are equal width which suffers from following limitations :
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
Typically , most current works [5] ,[17] ,[6] ,[8] ,[10] split the data into \MATH bins that are equal width which suffers from following limitations :
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
Typically , most current works [5] ,[17] ,[6] ,[8] ,[10] split the data into \MATH bins that are equal width which suffers from following limitations :
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Typically , most current works [5] ,[17] ,[6] ,[8] ,[10] split the data into \MATH bins that are equal width which suffers from following limitations :
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
Typically , most current works [5] ,[17] ,[6] ,[8] ,[10] split the data into \MATH bins that are equal width which suffers from following limitations :
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
Typically , most current works [5] ,[17] ,[6] ,[8] ,[10] split the data into \MATH bins that are equal width which suffers from following limitations :
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
Typically , most current works [5] ,[17] ,[6] ,[8] ,[10] split the data into \MATH bins that are equal width which suffers from following limitations :
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
Typically , most current works [5] ,[17] ,[6] ,[8] ,[10] split the data into \MATH bins that are equal width which suffers from following limitations :
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
Typically , most current works [5] ,[17] ,[6] ,[8] ,[10] split the data into \MATH bins that are equal width which suffers from following limitations :
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
-Choosing the appropriate number of bins is undetermined .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
-Choosing the appropriate number of bins is undetermined .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
-Choosing the appropriate number of bins is undetermined .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
-Choosing the appropriate number of bins is undetermined .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
-Choosing the appropriate number of bins is undetermined .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Normally , it has been done by trials and errors [6] ,[17] - a tedious task .
#<struct ReadData::Alignment source_numbers="7,8", target_numbers="7,8", tag_name="wa">
Normally , it has been done by trials and errors [6] ,[17] - a tedious task .
#<struct ReadData::Alignment source_numbers="9", target_numbers="9", tag_name="wa">
Normally , it has been done by trials and errors [6] ,[17] - a tedious task .
#<struct ReadData::Alignment source_numbers="10", target_numbers="10", tag_name="wa">
Normally , it has been done by trials and errors [6] ,[17] - a tedious task .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
Normally , it has been done by trials and errors [6] ,[17] - a tedious task .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
Normally , it has been done by trials and errors [6] ,[17] - a tedious task .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
Normally , it has been done by trials and errors [6] ,[17] - a tedious task .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
Normally , it has been done by trials and errors [6] ,[17] - a tedious task .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
In the training cascade of classifiers [6] ,[17] , when the complexity of the training data changes over time , using the same number of bins for training every layers is not optimal .
#<struct ReadData::Alignment source_numbers="19", target_numbers="7", tag_name="wa">
In the training cascade of classifiers [6] ,[17] , when the complexity of the training data changes over time , using the same number of bins for training every layers is not optimal .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
In the training cascade of classifiers [6] ,[17] , when the complexity of the training data changes over time , using the same number of bins for training every layers is not optimal .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
In the training cascade of classifiers [6] ,[17] , when the complexity of the training data changes over time , using the same number of bins for training every layers is not optimal .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
Furthermore it might increase computation and training time , waste storage space which is critical in applications with limited resources , for example , face detection on mobile phones .
#<struct ReadData::Alignment source_numbers="8", target_numbers="1", tag_name="wa">
Furthermore it might increase computation and training time , waste storage space which is critical in applications with limited resources , for example , face detection on mobile phones .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
Furthermore it might increase computation and training time , waste storage space which is critical in applications with limited resources , for example , face detection on mobile phones .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Furthermore it might increase computation and training time , waste storage space which is critical in applications with limited resources , for example , face detection on mobile phones .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Furthermore it might increase computation and training time , waste storage space which is critical in applications with limited resources , for example , face detection on mobile phones .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Meanwhile choosing a small number of bins might not well approximate the real densities of the data distribution and thus influence selection of the best weak classifier .
#<struct ReadData::Alignment source_numbers="20", target_numbers="22", tag_name="wa">
Meanwhile choosing a small number of bins might not well approximate the real densities of the data distribution and thus influence selection of the best weak classifier .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Meanwhile choosing a small number of bins might not well approximate the real densities of the data distribution and thus influence selection of the best weak classifier .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Meanwhile choosing a small number of bins might not well approximate the real densities of the data distribution and thus influence selection of the best weak classifier .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Meanwhile choosing a small number of bins might not well approximate the real densities of the data distribution and thus influence selection of the best weak classifier .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
Meanwhile choosing a small number of bins might not well approximate the real densities of the data distribution and thus influence selection of the best weak classifier .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Meanwhile choosing a small number of bins might not well approximate the real densities of the data distribution and thus influence selection of the best weak classifier .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Meanwhile choosing a small number of bins might not well approximate the real densities of the data distribution and thus influence selection of the best weak classifier .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Meanwhile choosing a small number of bins might not well approximate the real densities of the data distribution and thus influence selection of the best weak classifier .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Meanwhile choosing a small number of bins might not well approximate the real densities of the data distribution and thus influence selection of the best weak classifier .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
Meanwhile choosing a small number of bins might not well approximate the real densities of the data distribution and thus influence selection of the best weak classifier .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
It is therefore necessary to have a deterministic method to choose this number of bins automatically and optimally .
#<struct ReadData::Alignment source_numbers="1", target_numbers="3", tag_name="wa">
It is therefore necessary to have a deterministic method to choose this number of bins automatically and optimally .
#<struct ReadData::Alignment source_numbers="3,4", target_numbers="5", tag_name="wa">
It is therefore necessary to have a deterministic method to choose this number of bins automatically and optimally .
#<struct ReadData::Alignment source_numbers="11,12", target_numbers="11,12", tag_name="wa">
It is therefore necessary to have a deterministic method to choose this number of bins automatically and optimally .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
It is therefore necessary to have a deterministic method to choose this number of bins automatically and optimally .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
It is therefore necessary to have a deterministic method to choose this number of bins automatically and optimally .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
It is therefore necessary to have a deterministic method to choose this number of bins automatically and optimally .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
This problem can be formulated as a discretization problem in which subspace boundaries are found by some criteria .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
This problem can be formulated as a discretization problem in which subspace boundaries are found by some criteria .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
This problem can be formulated as a discretization problem in which subspace boundaries are found by some criteria .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
This problem can be formulated as a discretization problem in which subspace boundaries are found by some criteria .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
This problem can be formulated as a discretization problem in which subspace boundaries are found by some criteria .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
This problem can be formulated as a discretization problem in which subspace boundaries are found by some criteria .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
This problem can be formulated as a discretization problem in which subspace boundaries are found by some criteria .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
This problem can be formulated as a discretization problem in which subspace boundaries are found by some criteria .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
This problem can be formulated as a discretization problem in which subspace boundaries are found by some criteria .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
This problem can be formulated as a discretization problem in which subspace boundaries are found by some criteria .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
This problem can be formulated as a discretization problem in which subspace boundaries are found by some criteria .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
This problem can be formulated as a discretization problem in which subspace boundaries are found by some criteria .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
Among discretization methods , the entropy based method [19] has been proved most efficiently ; hence , we propose using it to solve the problem .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Among discretization methods , the entropy based method [19] has been proved most efficiently ; hence , we propose using it to solve the problem .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
Among discretization methods , the entropy based method [19] has been proved most efficiently ; hence , we propose using it to solve the problem .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
Among discretization methods , the entropy based method [19] has been proved most efficiently ; hence , we propose using it to solve the problem .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
Among discretization methods , the entropy based method [19] has been proved most efficiently ; hence , we propose using it to solve the problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Among discretization methods , the entropy based method [19] has been proved most efficiently ; hence , we propose using it to solve the problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Among discretization methods , the entropy based method [19] has been proved most efficiently ; hence , we propose using it to solve the problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
The entropy based discretization method is an algorithm that automatically selects appropriate thresholds to split feature values into optimal bins by using entropy measurement .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
The entropy based discretization method is an algorithm that automatically selects appropriate thresholds to split feature values into optimal bins by using entropy measurement .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
The entropy based discretization method is an algorithm that automatically selects appropriate thresholds to split feature values into optimal bins by using entropy measurement .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
It is a supervised discretization method which takes into account class information and data distribution , so it is generic and can be applied for any kinds of input data .
#<struct ReadData::Alignment source_numbers="6,7", target_numbers="6,7", tag_name="wa">
It is a supervised discretization method which takes into account class information and data distribution , so it is generic and can be applied for any kinds of input data .
#<struct ReadData::Alignment source_numbers="26,27", target_numbers="26,27", tag_name="wa">
It is a supervised discretization method which takes into account class information and data distribution , so it is generic and can be applied for any kinds of input data .
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
It is a supervised discretization method which takes into account class information and data distribution , so it is generic and can be applied for any kinds of input data .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
Furthermore , many studies have been shown that discretization process might help to improve performance in induction tasks [18] , it can also work with a weighted data distribution ; therefore , it is most appropriate for boosting-based methods .
#<struct ReadData::Alignment source_numbers="4", target_numbers="4", tag_name="wa">
Furthermore , many studies have been shown that discretization process might help to improve performance in induction tasks [18] , it can also work with a weighted data distribution ; therefore , it is most appropriate for boosting-based methods .
#<struct ReadData::Alignment source_numbers="6", target_numbers="5", tag_name="wa">
Furthermore , many studies have been shown that discretization process might help to improve performance in induction tasks [18] , it can also work with a weighted data distribution ; therefore , it is most appropriate for boosting-based methods .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Furthermore , many studies have been shown that discretization process might help to improve performance in induction tasks [18] , it can also work with a weighted data distribution ; therefore , it is most appropriate for boosting-based methods .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
Furthermore , many studies have been shown that discretization process might help to improve performance in induction tasks [18] , it can also work with a weighted data distribution ; therefore , it is most appropriate for boosting-based methods .
#<struct ReadData::Alignment source_numbers="29", target_numbers="", tag_name="wa">
Furthermore , many studies have been shown that discretization process might help to improve performance in induction tasks [18] , it can also work with a weighted data distribution ; therefore , it is most appropriate for boosting-based methods .
#<struct ReadData::Alignment source_numbers="30", target_numbers="", tag_name="wa">
Furthermore , many studies have been shown that discretization process might help to improve performance in induction tasks [18] , it can also work with a weighted data distribution ; therefore , it is most appropriate for boosting-based methods .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
Furthermore , many studies have been shown that discretization process might help to improve performance in induction tasks [18] , it can also work with a weighted data distribution ; therefore , it is most appropriate for boosting-based methods .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
Furthermore , many studies have been shown that discretization process might help to improve performance in induction tasks [18] , it can also work with a weighted data distribution ; therefore , it is most appropriate for boosting-based methods .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
Besides learning weak classifiers , selecting the best weak classifier in the large weak classifier set in each round of boosting is also important .
#<struct ReadData::Alignment source_numbers="19", target_numbers="14", tag_name="wa">
Besides learning weak classifiers , selecting the best weak classifier in the large weak classifier set in each round of boosting is also important .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
Adopting [5] , it is done by choosing the weak classifier that maximizes Kullback-Leibler ( KL ) divergence between two distributions of positive and negative samples .
#<struct ReadData::Alignment source_numbers="2", target_numbers="6", tag_name="wa">
Adopting [5] , it is done by choosing the weak classifier that maximizes Kullback-Leibler ( KL ) divergence between two distributions of positive and negative samples .
#<struct ReadData::Alignment source_numbers="26", target_numbers="30", tag_name="wa">
Adopting [5] , it is done by choosing the weak classifier that maximizes Kullback-Leibler ( KL ) divergence between two distributions of positive and negative samples .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Adopting [5] , it is done by choosing the weak classifier that maximizes Kullback-Leibler ( KL ) divergence between two distributions of positive and negative samples .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Adopting [5] , it is done by choosing the weak classifier that maximizes Kullback-Leibler ( KL ) divergence between two distributions of positive and negative samples .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Adopting [5] , it is done by choosing the weak classifier that maximizes Kullback-Leibler ( KL ) divergence between two distributions of positive and negative samples .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Adopting [5] , it is done by choosing the weak classifier that maximizes Kullback-Leibler ( KL ) divergence between two distributions of positive and negative samples .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Adopting [5] , it is done by choosing the weak classifier that maximizes Kullback-Leibler ( KL ) divergence between two distributions of positive and negative samples .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Adopting [5] , it is done by choosing the weak classifier that maximizes Kullback-Leibler ( KL ) divergence between two distributions of positive and negative samples .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
Adopting [5] , it is done by choosing the weak classifier that maximizes Kullback-Leibler ( KL ) divergence between two distributions of positive and negative samples .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
Adopting [5] , it is done by choosing the weak classifier that maximizes Kullback-Leibler ( KL ) divergence between two distributions of positive and negative samples .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
Adopting [5] , it is done by choosing the weak classifier that maximizes Kullback-Leibler ( KL ) divergence between two distributions of positive and negative samples .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
Originally , Discrete AdaBoost proposed by Freund and Schapire [16] is a learning method of combining weak classifiers to a strong classier .
#<struct ReadData::Alignment source_numbers="18", target_numbers="20", tag_name="wa">
Originally , Discrete AdaBoost proposed by Freund and Schapire [16] is a learning method of combining weak classifiers to a strong classier .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Originally , Discrete AdaBoost proposed by Freund and Schapire [16] is a learning method of combining weak classifiers to a strong classier .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
Originally , Discrete AdaBoost proposed by Freund and Schapire [16] is a learning method of combining weak classifiers to a strong classier .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
Given a training set \MATH where \MATH and \MATH , a weak classifier \MATH has the form \MATH .
#<struct ReadData::Alignment source_numbers="9", target_numbers="5", tag_name="wa">
Given a training set \MATH where \MATH and \MATH , a weak classifier \MATH has the form \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Therefore , in many applications [4] ,[5] ,[7] , it is simplified by associating to one feature \MATH .
#<struct ReadData::Alignment source_numbers="8", target_numbers="10", tag_name="wa">
Therefore , in many applications [4] ,[5] ,[7] , it is simplified by associating to one feature \MATH .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
Therefore , in many applications [4] ,[5] ,[7] , it is simplified by associating to one feature \MATH .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Therefore , in many applications [4] ,[5] ,[7] , it is simplified by associating to one feature \MATH .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
Therefore , in many applications [4] ,[5] ,[7] , it is simplified by associating to one feature \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Therefore , in many applications [4] ,[5] ,[7] , it is simplified by associating to one feature \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Therefore , in many applications [4] ,[5] ,[7] , it is simplified by associating to one feature \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Therefore , in many applications [4] ,[5] ,[7] , it is simplified by associating to one feature \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Therefore , in many applications [4] ,[5] ,[7] , it is simplified by associating to one feature \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
In boosting process , a distribution \MATH or set of weights over the training samples are maintained and updated so that subsequent weak classifiers focus on the hard classified samples .
#<struct ReadData::Alignment source_numbers="27", target_numbers="", tag_name="wa">
In boosting process , a distribution \MATH or set of weights over the training samples are maintained and updated so that subsequent weak classifiers focus on the hard classified samples .
#<struct ReadData::Alignment source_numbers="28", target_numbers="", tag_name="wa">
In boosting process , a distribution \MATH or set of weights over the training samples are maintained and updated so that subsequent weak classifiers focus on the hard classified samples .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
In boosting process , a distribution \MATH or set of weights over the training samples are maintained and updated so that subsequent weak classifiers focus on the hard classified samples .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
In boosting process , a distribution \MATH or set of weights over the training samples are maintained and updated so that subsequent weak classifiers focus on the hard classified samples .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
In boosting process , a distribution \MATH or set of weights over the training samples are maintained and updated so that subsequent weak classifiers focus on the hard classified samples .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
Real AdaBoost [3] is a generalized version of Discrete AdaBoost in that weak classifiers are real-valued functions instead of binary ones and \MATH is found numerically in general instead of predescription .
#<struct ReadData::Alignment source_numbers="26", target_numbers="", tag_name="wa">
Real AdaBoost [3] is a generalized version of Discrete AdaBoost in that weak classifiers are real-valued functions instead of binary ones and \MATH is found numerically in general instead of predescription .
#<struct ReadData::Alignment source_numbers="27", target_numbers="", tag_name="wa">
Real AdaBoost [3] is a generalized version of Discrete AdaBoost in that weak classifiers are real-valued functions instead of binary ones and \MATH is found numerically in general instead of predescription .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
Real AdaBoost [3] is a generalized version of Discrete AdaBoost in that weak classifiers are real-valued functions instead of binary ones and \MATH is found numerically in general instead of predescription .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
Real AdaBoost [3] is a generalized version of Discrete AdaBoost in that weak classifiers are real-valued functions instead of binary ones and \MATH is found numerically in general instead of predescription .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
Real AdaBoost [3] is a generalized version of Discrete AdaBoost in that weak classifiers are real-valued functions instead of binary ones and \MATH is found numerically in general instead of predescription .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
Real AdaBoost [3] is a generalized version of Discrete AdaBoost in that weak classifiers are real-valued functions instead of binary ones and \MATH is found numerically in general instead of predescription .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
Real AdaBoost [3] is a generalized version of Discrete AdaBoost in that weak classifiers are real-valued functions instead of binary ones and \MATH is found numerically in general instead of predescription .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
Real AdaBoost [3] is a generalized version of Discrete AdaBoost in that weak classifiers are real-valued functions instead of binary ones and \MATH is found numerically in general instead of predescription .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
Real AdaBoost [3] is a generalized version of Discrete AdaBoost in that weak classifiers are real-valued functions instead of binary ones and \MATH is found numerically in general instead of predescription .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
Real AdaBoost [3] is a generalized version of Discrete AdaBoost in that weak classifiers are real-valued functions instead of binary ones and \MATH is found numerically in general instead of predescription .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
Real AdaBoost [3] is a generalized version of Discrete AdaBoost in that weak classifiers are real-valued functions instead of binary ones and \MATH is found numerically in general instead of predescription .
#<struct ReadData::Alignment source_numbers="", target_numbers="40", tag_name="wa">
Real AdaBoost [3] is a generalized version of Discrete AdaBoost in that weak classifiers are real-valued functions instead of binary ones and \MATH is found numerically in general instead of predescription .
#<struct ReadData::Alignment source_numbers="", target_numbers="41", tag_name="wa">
This method also proposes designing weak classifiers that partition the input space into subspaces so that its predictions are unique in each subspace .
#<struct ReadData::Alignment source_numbers="4", target_numbers="11", tag_name="wa">
This method also proposes designing weak classifiers that partition the input space into subspaces so that its predictions are unique in each subspace .
#<struct ReadData::Alignment source_numbers="5", target_numbers="12", tag_name="wa">
This method also proposes designing weak classifiers that partition the input space into subspaces so that its predictions are unique in each subspace .
#<struct ReadData::Alignment source_numbers="6", target_numbers="13", tag_name="wa">
This method also proposes designing weak classifiers that partition the input space into subspaces so that its predictions are unique in each subspace .
#<struct ReadData::Alignment source_numbers="7", target_numbers="14", tag_name="wa">
This method also proposes designing weak classifiers that partition the input space into subspaces so that its predictions are unique in each subspace .
#<struct ReadData::Alignment source_numbers="8", target_numbers="15", tag_name="wa">
This method also proposes designing weak classifiers that partition the input space into subspaces so that its predictions are unique in each subspace .
#<struct ReadData::Alignment source_numbers="9", target_numbers="16", tag_name="wa">
This method also proposes designing weak classifiers that partition the input space into subspaces so that its predictions are unique in each subspace .
#<struct ReadData::Alignment source_numbers="10", target_numbers="17", tag_name="wa">
This method also proposes designing weak classifiers that partition the input space into subspaces so that its predictions are unique in each subspace .
#<struct ReadData::Alignment source_numbers="11", target_numbers="18", tag_name="wa">
This method also proposes designing weak classifiers that partition the input space into subspaces so that its predictions are unique in each subspace .
#<struct ReadData::Alignment source_numbers="12", target_numbers="19", tag_name="wa">
This method also proposes designing weak classifiers that partition the input space into subspaces so that its predictions are unique in each subspace .
#<struct ReadData::Alignment source_numbers="13", target_numbers="20", tag_name="wa">
This method also proposes designing weak classifiers that partition the input space into subspaces so that its predictions are unique in each subspace .
#<struct ReadData::Alignment source_numbers="14", target_numbers="21", tag_name="wa">
This method also proposes designing weak classifiers that partition the input space into subspaces so that its predictions are unique in each subspace .
#<struct ReadData::Alignment source_numbers="15", target_numbers="22", tag_name="wa">
This method also proposes designing weak classifiers that partition the input space into subspaces so that its predictions are unique in each subspace .
#<struct ReadData::Alignment source_numbers="16,17", target_numbers="23,24", tag_name="wa">
This method also proposes designing weak classifiers that partition the input space into subspaces so that its predictions are unique in each subspace .
#<struct ReadData::Alignment source_numbers="18", target_numbers="25", tag_name="wa">
This method also proposes designing weak classifiers that partition the input space into subspaces so that its predictions are unique in each subspace .
#<struct ReadData::Alignment source_numbers="19", target_numbers="26", tag_name="wa">
This method also proposes designing weak classifiers that partition the input space into subspaces so that its predictions are unique in each subspace .
#<struct ReadData::Alignment source_numbers="20", target_numbers="27", tag_name="wa">
This method also proposes designing weak classifiers that partition the input space into subspaces so that its predictions are unique in each subspace .
#<struct ReadData::Alignment source_numbers="21", target_numbers="28", tag_name="wa">
This method also proposes designing weak classifiers that partition the input space into subspaces so that its predictions are unique in each subspace .
#<struct ReadData::Alignment source_numbers="22", target_numbers="29", tag_name="wa">
This method also proposes designing weak classifiers that partition the input space into subspaces so that its predictions are unique in each subspace .
#<struct ReadData::Alignment source_numbers="23", target_numbers="30", tag_name="wa">
This method also proposes designing weak classifiers that partition the input space into subspaces so that its predictions are unique in each subspace .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
This method also proposes designing weak classifiers that partition the input space into subspaces so that its predictions are unique in each subspace .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
This method also proposes designing weak classifiers that partition the input space into subspaces so that its predictions are unique in each subspace .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
This method also proposes designing weak classifiers that partition the input space into subspaces so that its predictions are unique in each subspace .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
This method also proposes designing weak classifiers that partition the input space into subspaces so that its predictions are unique in each subspace .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
This method also proposes designing weak classifiers that partition the input space into subspaces so that its predictions are unique in each subspace .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
This method also proposes designing weak classifiers that partition the input space into subspaces so that its predictions are unique in each subspace .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
This method also proposes designing weak classifiers that partition the input space into subspaces so that its predictions are unique in each subspace .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
This method also proposes designing weak classifiers that partition the input space into subspaces so that its predictions are unique in each subspace .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
This method also proposes designing weak classifiers that partition the input space into subspaces so that its predictions are unique in each subspace .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
This method also proposes designing weak classifiers that partition the input space into subspaces so that its predictions are unique in each subspace .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
This method also proposes designing weak classifiers that partition the input space into subspaces so that its predictions are unique in each subspace .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
This method also proposes designing weak classifiers that partition the input space into subspaces so that its predictions are unique in each subspace .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
This method also proposes designing weak classifiers that partition the input space into subspaces so that its predictions are unique in each subspace .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
This method also proposes designing weak classifiers that partition the input space into subspaces so that its predictions are unique in each subspace .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Such weak classifiers are used widely in current state of the art object detection systems [5] ,[17] ,[8] .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Such weak classifiers are used widely in current state of the art object detection systems [5] ,[17] ,[8] .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Such weak classifiers are used widely in current state of the art object detection systems [5] ,[17] ,[8] .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Such weak classifiers are used widely in current state of the art object detection systems [5] ,[17] ,[8] .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
Such weak classifiers are used widely in current state of the art object detection systems [5] ,[17] ,[8] .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
Such weak classifiers are used widely in current state of the art object detection systems [5] ,[17] ,[8] .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
Such weak classifiers are used widely in current state of the art object detection systems [5] ,[17] ,[8] .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Such weak classifiers are used widely in current state of the art object detection systems [5] ,[17] ,[8] .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Such weak classifiers are used widely in current state of the art object detection systems [5] ,[17] ,[8] .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Such weak classifiers are used widely in current state of the art object detection systems [5] ,[17] ,[8] .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
Such weak classifiers are used widely in current state of the art object detection systems [5] ,[17] ,[8] .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
It is proved in [3] that the most appropriate choice for the prediction of the weak classifier on block \MATH to maximize the margin is \MATH where \MATH is a smoothed value in order to handle cases that \MATH is very small or even zero .
#<struct ReadData::Alignment source_numbers="37", target_numbers="", tag_name="wa">
It is proved in [3] that the most appropriate choice for the prediction of the weak classifier on block \MATH to maximize the margin is \MATH where \MATH is a smoothed value in order to handle cases that \MATH is very small or even zero .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
It is proved in [3] that the most appropriate choice for the prediction of the weak classifier on block \MATH to maximize the margin is \MATH where \MATH is a smoothed value in order to handle cases that \MATH is very small or even zero .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
Real AdaBoost is easy to implement ; however , in practical applications , designing and learning weak classifiers depend on specific applications .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
Real AdaBoost is easy to implement ; however , in practical applications , designing and learning weak classifiers depend on specific applications .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Real AdaBoost is easy to implement ; however , in practical applications , designing and learning weak classifiers depend on specific applications .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
In such face detection systems as [5] ,[6] ,[17] ,[8] , weak classifiers are usually associated with one feature .
#<struct ReadData::Alignment source_numbers="10", target_numbers="17", tag_name="wa">
In such face detection systems as [5] ,[6] ,[17] ,[8] , weak classifiers are usually associated with one feature .
#<struct ReadData::Alignment source_numbers="11", target_numbers="18", tag_name="wa">
In such face detection systems as [5] ,[6] ,[17] ,[8] , weak classifiers are usually associated with one feature .
#<struct ReadData::Alignment source_numbers="12", target_numbers="19", tag_name="wa">
In such face detection systems as [5] ,[6] ,[17] ,[8] , weak classifiers are usually associated with one feature .
#<struct ReadData::Alignment source_numbers="13", target_numbers="20", tag_name="wa">
In such face detection systems as [5] ,[6] ,[17] ,[8] , weak classifiers are usually associated with one feature .
#<struct ReadData::Alignment source_numbers="14", target_numbers="21", tag_name="wa">
In such face detection systems as [5] ,[6] ,[17] ,[8] , weak classifiers are usually associated with one feature .
#<struct ReadData::Alignment source_numbers="15", target_numbers="22", tag_name="wa">
In such face detection systems as [5] ,[6] ,[17] ,[8] , weak classifiers are usually associated with one feature .
#<struct ReadData::Alignment source_numbers="16", target_numbers="23", tag_name="wa">
In such face detection systems as [5] ,[6] ,[17] ,[8] , weak classifiers are usually associated with one feature .
#<struct ReadData::Alignment source_numbers="17", target_numbers="24", tag_name="wa">
In such face detection systems as [5] ,[6] ,[17] ,[8] , weak classifiers are usually associated with one feature .
#<struct ReadData::Alignment source_numbers="18", target_numbers="25", tag_name="wa">
In such face detection systems as [5] ,[6] ,[17] ,[8] , weak classifiers are usually associated with one feature .
#<struct ReadData::Alignment source_numbers="19", target_numbers="26", tag_name="wa">
In such face detection systems as [5] ,[6] ,[17] ,[8] , weak classifiers are usually associated with one feature .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
In such face detection systems as [5] ,[6] ,[17] ,[8] , weak classifiers are usually associated with one feature .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
In such face detection systems as [5] ,[6] ,[17] ,[8] , weak classifiers are usually associated with one feature .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
In such face detection systems as [5] ,[6] ,[17] ,[8] , weak classifiers are usually associated with one feature .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
In such face detection systems as [5] ,[6] ,[17] ,[8] , weak classifiers are usually associated with one feature .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
In such face detection systems as [5] ,[6] ,[17] ,[8] , weak classifiers are usually associated with one feature .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
In such face detection systems as [5] ,[6] ,[17] ,[8] , weak classifiers are usually associated with one feature .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
In such face detection systems as [5] ,[6] ,[17] ,[8] , weak classifiers are usually associated with one feature .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
In such face detection systems as [5] ,[6] ,[17] ,[8] , weak classifiers are usually associated with one feature .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
In such face detection systems as [5] ,[6] ,[17] ,[8] , weak classifiers are usually associated with one feature .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
In such face detection systems as [5] ,[6] ,[17] ,[8] , weak classifiers are usually associated with one feature .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
In such face detection systems as [5] ,[6] ,[17] ,[8] , weak classifiers are usually associated with one feature .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
In such face detection systems as [5] ,[6] ,[17] ,[8] , weak classifiers are usually associated with one feature .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
With a very large number of available features , hundreds of thousands , there are a lot of choices to choose one weak classifier for each round of boosting .
#<struct ReadData::Alignment source_numbers="18", target_numbers="22", tag_name="wa">
With a very large number of available features , hundreds of thousands , there are a lot of choices to choose one weak classifier for each round of boosting .
#<struct ReadData::Alignment source_numbers="20", target_numbers="27", tag_name="wa">
With a very large number of available features , hundreds of thousands , there are a lot of choices to choose one weak classifier for each round of boosting .
#<struct ReadData::Alignment source_numbers="21", target_numbers="28", tag_name="wa">
With a very large number of available features , hundreds of thousands , there are a lot of choices to choose one weak classifier for each round of boosting .
#<struct ReadData::Alignment source_numbers="22", target_numbers="29", tag_name="wa">
With a very large number of available features , hundreds of thousands , there are a lot of choices to choose one weak classifier for each round of boosting .
#<struct ReadData::Alignment source_numbers="23", target_numbers="30", tag_name="wa">
With a very large number of available features , hundreds of thousands , there are a lot of choices to choose one weak classifier for each round of boosting .
#<struct ReadData::Alignment source_numbers="24", target_numbers="31", tag_name="wa">
With a very large number of available features , hundreds of thousands , there are a lot of choices to choose one weak classifier for each round of boosting .
#<struct ReadData::Alignment source_numbers="25", target_numbers="32", tag_name="wa">
With a very large number of available features , hundreds of thousands , there are a lot of choices to choose one weak classifier for each round of boosting .
#<struct ReadData::Alignment source_numbers="26", target_numbers="33", tag_name="wa">
With a very large number of available features , hundreds of thousands , there are a lot of choices to choose one weak classifier for each round of boosting .
#<struct ReadData::Alignment source_numbers="27", target_numbers="34", tag_name="wa">
With a very large number of available features , hundreds of thousands , there are a lot of choices to choose one weak classifier for each round of boosting .
#<struct ReadData::Alignment source_numbers="28", target_numbers="35", tag_name="wa">
With a very large number of available features , hundreds of thousands , there are a lot of choices to choose one weak classifier for each round of boosting .
#<struct ReadData::Alignment source_numbers="29", target_numbers="36", tag_name="wa">
With a very large number of available features , hundreds of thousands , there are a lot of choices to choose one weak classifier for each round of boosting .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
With a very large number of available features , hundreds of thousands , there are a lot of choices to choose one weak classifier for each round of boosting .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
With a very large number of available features , hundreds of thousands , there are a lot of choices to choose one weak classifier for each round of boosting .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
With a very large number of available features , hundreds of thousands , there are a lot of choices to choose one weak classifier for each round of boosting .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
With a very large number of available features , hundreds of thousands , there are a lot of choices to choose one weak classifier for each round of boosting .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
With a very large number of available features , hundreds of thousands , there are a lot of choices to choose one weak classifier for each round of boosting .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
With a very large number of available features , hundreds of thousands , there are a lot of choices to choose one weak classifier for each round of boosting .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
With a very large number of available features , hundreds of thousands , there are a lot of choices to choose one weak classifier for each round of boosting .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
With a very large number of available features , hundreds of thousands , there are a lot of choices to choose one weak classifier for each round of boosting .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
With a very large number of available features , hundreds of thousands , there are a lot of choices to choose one weak classifier for each round of boosting .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
With a very large number of available features , hundreds of thousands , there are a lot of choices to choose one weak classifier for each round of boosting .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
With a very large number of available features , hundreds of thousands , there are a lot of choices to choose one weak classifier for each round of boosting .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
With a very large number of available features , hundreds of thousands , there are a lot of choices to choose one weak classifier for each round of boosting .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
With a very large number of available features , hundreds of thousands , there are a lot of choices to choose one weak classifier for each round of boosting .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
With a very large number of available features , hundreds of thousands , there are a lot of choices to choose one weak classifier for each round of boosting .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
With a very large number of available features , hundreds of thousands , there are a lot of choices to choose one weak classifier for each round of boosting .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
With a very large number of available features , hundreds of thousands , there are a lot of choices to choose one weak classifier for each round of boosting .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
With a very large number of available features , hundreds of thousands , there are a lot of choices to choose one weak classifier for each round of boosting .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
With a very large number of available features , hundreds of thousands , there are a lot of choices to choose one weak classifier for each round of boosting .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
Generally , optimally selecting the suitable weak classifier will make the final strong classifier more robust and efficient .
#<struct ReadData::Alignment source_numbers="9", target_numbers="6", tag_name="wa">
Generally , optimally selecting the suitable weak classifier will make the final strong classifier more robust and efficient .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Generally , optimally selecting the suitable weak classifier will make the final strong classifier more robust and efficient .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Generally , optimally selecting the suitable weak classifier will make the final strong classifier more robust and efficient .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Generally , optimally selecting the suitable weak classifier will make the final strong classifier more robust and efficient .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Generally , optimally selecting the suitable weak classifier will make the final strong classifier more robust and efficient .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Furthermore , it can reduce the number of boosting rounds that directly shorten training time .
#<struct ReadData::Alignment source_numbers="12", target_numbers="14", tag_name="wa">
Furthermore , it can reduce the number of boosting rounds that directly shorten training time .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Furthermore , it can reduce the number of boosting rounds that directly shorten training time .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Furthermore , it can reduce the number of boosting rounds that directly shorten training time .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Furthermore , it can reduce the number of boosting rounds that directly shorten training time .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Furthermore , it can reduce the number of boosting rounds that directly shorten training time .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
Furthermore , it can reduce the number of boosting rounds that directly shorten training time .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
So far , most current studies have been focused on how to measure the discriminant power of weak classifiers in order to select the best weak classifier .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
So far , most current studies have been focused on how to measure the discriminant power of weak classifiers in order to select the best weak classifier .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
So far , most current studies have been focused on how to measure the discriminant power of weak classifiers in order to select the best weak classifier .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
So far , most current studies have been focused on how to measure the discriminant power of weak classifiers in order to select the best weak classifier .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
So far , most current studies have been focused on how to measure the discriminant power of weak classifiers in order to select the best weak classifier .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
So far , most current studies have been focused on how to measure the discriminant power of weak classifiers in order to select the best weak classifier .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Many measurements have been proposed ; for example , Bhattacharyya distance [6] , Kullback-Leibler divergence [5] and , recently , Jensen-Shannon divergence [8] and mutual information [9] ( cf . Table 1 .
#<struct ReadData::Alignment source_numbers="17", target_numbers="5", tag_name="wa">
Many measurements have been proposed ; for example , Bhattacharyya distance [6] , Kullback-Leibler divergence [5] and , recently , Jensen-Shannon divergence [8] and mutual information [9] ( cf . Table 1 .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Many measurements have been proposed ; for example , Bhattacharyya distance [6] , Kullback-Leibler divergence [5] and , recently , Jensen-Shannon divergence [8] and mutual information [9] ( cf . Table 1 .
#<struct ReadData::Alignment source_numbers="28", target_numbers="", tag_name="wa">
Many measurements have been proposed ; for example , Bhattacharyya distance [6] , Kullback-Leibler divergence [5] and , recently , Jensen-Shannon divergence [8] and mutual information [9] ( cf . Table 1 .
#<struct ReadData::Alignment source_numbers="32", target_numbers="", tag_name="wa">
Many measurements have been proposed ; for example , Bhattacharyya distance [6] , Kullback-Leibler divergence [5] and , recently , Jensen-Shannon divergence [8] and mutual information [9] ( cf . Table 1 .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
Many measurements have been proposed ; for example , Bhattacharyya distance [6] , Kullback-Leibler divergence [5] and , recently , Jensen-Shannon divergence [8] and mutual information [9] ( cf . Table 1 .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
Meanwhile , few studies have been made for efficiently partitioning subspaces .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Meanwhile , few studies have been made for efficiently partitioning subspaces .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
As shown in Figure 1 , using a fixed number of bins , strong classifiers trained by above measurements give comparable performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
As shown in Figure 1 , using a fixed number of bins , strong classifiers trained by above measurements give comparable performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
As shown in Figure 1 , using a fixed number of bins , strong classifiers trained by above measurements give comparable performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
However , it will be shown in section 5 , these performances are affected seriously if different subspace splitting methods are used .
#<struct ReadData::Alignment source_numbers="3", target_numbers="5", tag_name="wa">
However , it will be shown in section 5 , these performances are affected seriously if different subspace splitting methods are used .
#<struct ReadData::Alignment source_numbers="4,5", target_numbers="6", tag_name="wa">
However , it will be shown in section 5 , these performances are affected seriously if different subspace splitting methods are used .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
However , it will be shown in section 5 , these performances are affected seriously if different subspace splitting methods are used .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
However , it will be shown in section 5 , these performances are affected seriously if different subspace splitting methods are used .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
However , it will be shown in section 5 , these performances are affected seriously if different subspace splitting methods are used .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
However , it will be shown in section 5 , these performances are affected seriously if different subspace splitting methods are used .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
The proposed boosting scheme Ent-Boost is an integration of adaptive entropy-based subspace splitting and the symmetric KL divergence-based weak classifier selection .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
The proposed boosting scheme Ent-Boost is an integration of adaptive entropy-based subspace splitting and the symmetric KL divergence-based weak classifier selection .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
In Ent-Boost , each weak classifier is constructed from one feature and trained on the weighted training samples similar to Real AdaBoost .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
In Ent-Boost , each weak classifier is constructed from one feature and trained on the weighted training samples similar to Real AdaBoost .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
In Ent-Boost , each weak classifier is constructed from one feature and trained on the weighted training samples similar to Real AdaBoost .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
However , instead of using equal-width binning method like Real AdaBoost [6] ,[17] which is hard to know the suitable number of bins in advance , we use entropy-based discretization method [19] to split the input space into subspaces .
#<struct ReadData::Alignment source_numbers="34", target_numbers="5", tag_name="wa">
However , instead of using equal-width binning method like Real AdaBoost [6] ,[17] which is hard to know the suitable number of bins in advance , we use entropy-based discretization method [19] to split the input space into subspaces .
#<struct ReadData::Alignment source_numbers="27", target_numbers="9", tag_name="wa">
However , instead of using equal-width binning method like Real AdaBoost [6] ,[17] which is hard to know the suitable number of bins in advance , we use entropy-based discretization method [19] to split the input space into subspaces .
#<struct ReadData::Alignment source_numbers="23", target_numbers="10", tag_name="wa">
However , instead of using equal-width binning method like Real AdaBoost [6] ,[17] which is hard to know the suitable number of bins in advance , we use entropy-based discretization method [19] to split the input space into subspaces .
#<struct ReadData::Alignment source_numbers="25", target_numbers="14", tag_name="wa">
However , instead of using equal-width binning method like Real AdaBoost [6] ,[17] which is hard to know the suitable number of bins in advance , we use entropy-based discretization method [19] to split the input space into subspaces .
#<struct ReadData::Alignment source_numbers="14", target_numbers="17,18", tag_name="wa">
However , instead of using equal-width binning method like Real AdaBoost [6] ,[17] which is hard to know the suitable number of bins in advance , we use entropy-based discretization method [19] to split the input space into subspaces .
#<struct ReadData::Alignment source_numbers="15", target_numbers="19", tag_name="wa">
However , instead of using equal-width binning method like Real AdaBoost [6] ,[17] which is hard to know the suitable number of bins in advance , we use entropy-based discretization method [19] to split the input space into subspaces .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
However , instead of using equal-width binning method like Real AdaBoost [6] ,[17] which is hard to know the suitable number of bins in advance , we use entropy-based discretization method [19] to split the input space into subspaces .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
However , instead of using equal-width binning method like Real AdaBoost [6] ,[17] which is hard to know the suitable number of bins in advance , we use entropy-based discretization method [19] to split the input space into subspaces .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
However , instead of using equal-width binning method like Real AdaBoost [6] ,[17] which is hard to know the suitable number of bins in advance , we use entropy-based discretization method [19] to split the input space into subspaces .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
However , instead of using equal-width binning method like Real AdaBoost [6] ,[17] which is hard to know the suitable number of bins in advance , we use entropy-based discretization method [19] to split the input space into subspaces .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
However , instead of using equal-width binning method like Real AdaBoost [6] ,[17] which is hard to know the suitable number of bins in advance , we use entropy-based discretization method [19] to split the input space into subspaces .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
However , instead of using equal-width binning method like Real AdaBoost [6] ,[17] which is hard to know the suitable number of bins in advance , we use entropy-based discretization method [19] to split the input space into subspaces .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
However , instead of using equal-width binning method like Real AdaBoost [6] ,[17] which is hard to know the suitable number of bins in advance , we use entropy-based discretization method [19] to split the input space into subspaces .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
However , instead of using equal-width binning method like Real AdaBoost [6] ,[17] which is hard to know the suitable number of bins in advance , we use entropy-based discretization method [19] to split the input space into subspaces .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
However , instead of using equal-width binning method like Real AdaBoost [6] ,[17] which is hard to know the suitable number of bins in advance , we use entropy-based discretization method [19] to split the input space into subspaces .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
However , instead of using equal-width binning method like Real AdaBoost [6] ,[17] which is hard to know the suitable number of bins in advance , we use entropy-based discretization method [19] to split the input space into subspaces .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
This subspace splitting process is totally automatically in which the stopping criteria of splitting process is determined through using Minimum Description Length Principles ( MDLP ) ( see the next section ) .
#<struct ReadData::Alignment source_numbers="28", target_numbers="12", tag_name="wa">
This subspace splitting process is totally automatically in which the stopping criteria of splitting process is determined through using Minimum Description Length Principles ( MDLP ) ( see the next section ) .
#<struct ReadData::Alignment source_numbers="16", target_numbers="16", tag_name="wa">
This subspace splitting process is totally automatically in which the stopping criteria of splitting process is determined through using Minimum Description Length Principles ( MDLP ) ( see the next section ) .
#<struct ReadData::Alignment source_numbers="32", target_numbers="25", tag_name="wa">
This subspace splitting process is totally automatically in which the stopping criteria of splitting process is determined through using Minimum Description Length Principles ( MDLP ) ( see the next section ) .
#<struct ReadData::Alignment source_numbers="15", target_numbers="28,29", tag_name="wa">
This subspace splitting process is totally automatically in which the stopping criteria of splitting process is determined through using Minimum Description Length Principles ( MDLP ) ( see the next section ) .
#<struct ReadData::Alignment source_numbers="7", target_numbers="31", tag_name="wa">
This subspace splitting process is totally automatically in which the stopping criteria of splitting process is determined through using Minimum Description Length Principles ( MDLP ) ( see the next section ) .
#<struct ReadData::Alignment source_numbers="29", target_numbers="36", tag_name="wa">
This subspace splitting process is totally automatically in which the stopping criteria of splitting process is determined through using Minimum Description Length Principles ( MDLP ) ( see the next section ) .
#<struct ReadData::Alignment source_numbers="30", target_numbers="37", tag_name="wa">
This subspace splitting process is totally automatically in which the stopping criteria of splitting process is determined through using Minimum Description Length Principles ( MDLP ) ( see the next section ) .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
This subspace splitting process is totally automatically in which the stopping criteria of splitting process is determined through using Minimum Description Length Principles ( MDLP ) ( see the next section ) .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
This subspace splitting process is totally automatically in which the stopping criteria of splitting process is determined through using Minimum Description Length Principles ( MDLP ) ( see the next section ) .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
This subspace splitting process is totally automatically in which the stopping criteria of splitting process is determined through using Minimum Description Length Principles ( MDLP ) ( see the next section ) .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
This subspace splitting process is totally automatically in which the stopping criteria of splitting process is determined through using Minimum Description Length Principles ( MDLP ) ( see the next section ) .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
This subspace splitting process is totally automatically in which the stopping criteria of splitting process is determined through using Minimum Description Length Principles ( MDLP ) ( see the next section ) .
#<struct ReadData::Alignment source_numbers="26", target_numbers="", tag_name="wa">
This subspace splitting process is totally automatically in which the stopping criteria of splitting process is determined through using Minimum Description Length Principles ( MDLP ) ( see the next section ) .
#<struct ReadData::Alignment source_numbers="27", target_numbers="", tag_name="wa">
This subspace splitting process is totally automatically in which the stopping criteria of splitting process is determined through using Minimum Description Length Principles ( MDLP ) ( see the next section ) .
#<struct ReadData::Alignment source_numbers="31", target_numbers="", tag_name="wa">
This subspace splitting process is totally automatically in which the stopping criteria of splitting process is determined through using Minimum Description Length Principles ( MDLP ) ( see the next section ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
This subspace splitting process is totally automatically in which the stopping criteria of splitting process is determined through using Minimum Description Length Principles ( MDLP ) ( see the next section ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
This subspace splitting process is totally automatically in which the stopping criteria of splitting process is determined through using Minimum Description Length Principles ( MDLP ) ( see the next section ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
This subspace splitting process is totally automatically in which the stopping criteria of splitting process is determined through using Minimum Description Length Principles ( MDLP ) ( see the next section ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
This subspace splitting process is totally automatically in which the stopping criteria of splitting process is determined through using Minimum Description Length Principles ( MDLP ) ( see the next section ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
This subspace splitting process is totally automatically in which the stopping criteria of splitting process is determined through using Minimum Description Length Principles ( MDLP ) ( see the next section ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
This subspace splitting process is totally automatically in which the stopping criteria of splitting process is determined through using Minimum Description Length Principles ( MDLP ) ( see the next section ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
This subspace splitting process is totally automatically in which the stopping criteria of splitting process is determined through using Minimum Description Length Principles ( MDLP ) ( see the next section ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
This subspace splitting process is totally automatically in which the stopping criteria of splitting process is determined through using Minimum Description Length Principles ( MDLP ) ( see the next section ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
This subspace splitting process is totally automatically in which the stopping criteria of splitting process is determined through using Minimum Description Length Principles ( MDLP ) ( see the next section ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
This subspace splitting process is totally automatically in which the stopping criteria of splitting process is determined through using Minimum Description Length Principles ( MDLP ) ( see the next section ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
This subspace splitting process is totally automatically in which the stopping criteria of splitting process is determined through using Minimum Description Length Principles ( MDLP ) ( see the next section ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
This subspace splitting process is totally automatically in which the stopping criteria of splitting process is determined through using Minimum Description Length Principles ( MDLP ) ( see the next section ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
This subspace splitting process is totally automatically in which the stopping criteria of splitting process is determined through using Minimum Description Length Principles ( MDLP ) ( see the next section ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
To select the best weak classifier from the input weak classifier set , we use symmetric KL divergence as in [5] which measures the distance between two distributions as follows : \MATH where \MATH and \MATH are probability distributions of a discrete random variable .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
This formula can be rewritten in entropy terms : \MATH or \MATH where \MATH and \MATH are entropy , and \MATH is cross entropy of \MATH and \MATH .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
As a result , the number of intervals of selected weak classifier varies .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
As a result , the number of intervals of selected weak classifier varies .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
As a result , the number of intervals of selected weak classifier varies .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
As a result , the number of intervals of selected weak classifier varies .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
As a result , the number of intervals of selected weak classifier varies .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
This is different from previous methods that fix the number of equal-width intervals in advance .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
This is different from previous methods that fix the number of equal-width intervals in advance .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
This is different from previous methods that fix the number of equal-width intervals in advance .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
This section gives a brief introduction on automatic subspace splitting using entropy-based discretization .
#<struct ReadData::Alignment source_numbers="3,4", target_numbers="2", tag_name="wa">
This section gives a brief introduction on automatic subspace splitting using entropy-based discretization .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
This section gives a brief introduction on automatic subspace splitting using entropy-based discretization .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
This section gives a brief introduction on automatic subspace splitting using entropy-based discretization .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
This section gives a brief introduction on automatic subspace splitting using entropy-based discretization .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Basically , discretization is a quantizing process that converts continuous values into discrete values ; it typically consists of four steps [18] :
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Basically , discretization is a quantizing process that converts continuous values into discrete values ; it typically consists of four steps [18] :
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Basically , discretization is a quantizing process that converts continuous values into discrete values ; it typically consists of four steps [18] :
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Basically , discretization is a quantizing process that converts continuous values into discrete values ; it typically consists of four steps [18] :
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
Basically , discretization is a quantizing process that converts continuous values into discrete values ; it typically consists of four steps [18] :
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
Basically , discretization is a quantizing process that converts continuous values into discrete values ; it typically consists of four steps [18] :
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
Basically , discretization is a quantizing process that converts continuous values into discrete values ; it typically consists of four steps [18] :
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Basically , discretization is a quantizing process that converts continuous values into discrete values ; it typically consists of four steps [18] :
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
Basically , discretization is a quantizing process that converts continuous values into discrete values ; it typically consists of four steps [18] :
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Basically , discretization is a quantizing process that converts continuous values into discrete values ; it typically consists of four steps [18] :
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
Step 2 : valuating candidate cut-points and selecting the best cut-point for splitting .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
Step 2 : valuating candidate cut-points and selecting the best cut-point for splitting .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
The stopping criteria are usually selected according to a trade-off between lower arity ( the number of intervals or the number of bins ) and its effect on the accuracy of classification tasks .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
The stopping criteria are usually selected according to a trade-off between lower arity ( the number of intervals or the number of bins ) and its effect on the accuracy of classification tasks .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
The stopping criteria are usually selected according to a trade-off between lower arity ( the number of intervals or the number of bins ) and its effect on the accuracy of classification tasks .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
The stopping criteria are usually selected according to a trade-off between lower arity ( the number of intervals or the number of bins ) and its effect on the accuracy of classification tasks .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
A higher arity can make the understanding of an attribute more difficult , while a very low arity may affect predictive accuracy negatively .
#<struct ReadData::Alignment source_numbers="5", target_numbers="5", tag_name="wa">
A higher arity can make the understanding of an attribute more difficult , while a very low arity may affect predictive accuracy negatively .
#<struct ReadData::Alignment source_numbers="11", target_numbers="6,7", tag_name="wa">
A higher arity can make the understanding of an attribute more difficult , while a very low arity may affect predictive accuracy negatively .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
A higher arity can make the understanding of an attribute more difficult , while a very low arity may affect predictive accuracy negatively .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
A higher arity can make the understanding of an attribute more difficult , while a very low arity may affect predictive accuracy negatively .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
A higher arity can make the understanding of an attribute more difficult , while a very low arity may affect predictive accuracy negatively .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
Given set S and a potential binary partition , \MATH , specified on S by the given cut-point \MATH , a stopping criteria is used to decide whether or not this partition should be accepted .
#<struct ReadData::Alignment source_numbers="10", target_numbers="9", tag_name="wa">
Given set S and a potential binary partition , \MATH , specified on S by the given cut-point \MATH , a stopping criteria is used to decide whether or not this partition should be accepted .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Suppose \MATH is the probability of a \MATH answer , and \MATH is the probability of the \MATH answer .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
Suppose \MATH is the probability of a \MATH answer , and \MATH is the probability of the \MATH answer .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
Originally , the minimum description length of an object is defined as the minimum number of bits required to uniquely specify that object out of the universe of all objects .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Originally , the minimum description length of an object is defined as the minimum number of bits required to uniquely specify that object out of the universe of all objects .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Originally , the minimum description length of an object is defined as the minimum number of bits required to uniquely specify that object out of the universe of all objects .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Originally , the minimum description length of an object is defined as the minimum number of bits required to uniquely specify that object out of the universe of all objects .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
The sender needs to convey to proper class labeling of the example set to the receiver .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
The sender needs to convey to proper class labeling of the example set to the receiver .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
The sender needs to convey to proper class labeling of the example set to the receiver .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
The sender needs to convey to proper class labeling of the example set to the receiver .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
It says that the partition induced by a cut-point is accepted if and only if the length of the message required to send before partition is more than the length of the message required to send after partition .
#<struct ReadData::Alignment source_numbers="21", target_numbers="21", tag_name="wa">
It says that the partition induced by a cut-point is accepted if and only if the length of the message required to send before partition is more than the length of the message required to send after partition .
#<struct ReadData::Alignment source_numbers="22", target_numbers="22,23", tag_name="wa">
It says that the partition induced by a cut-point is accepted if and only if the length of the message required to send before partition is more than the length of the message required to send after partition .
#<struct ReadData::Alignment source_numbers="31", target_numbers="25", tag_name="wa">
It says that the partition induced by a cut-point is accepted if and only if the length of the message required to send before partition is more than the length of the message required to send after partition .
#<struct ReadData::Alignment source_numbers="34", target_numbers="36", tag_name="wa">
It says that the partition induced by a cut-point is accepted if and only if the length of the message required to send before partition is more than the length of the message required to send after partition .
#<struct ReadData::Alignment source_numbers="35", target_numbers="37,38", tag_name="wa">
It says that the partition induced by a cut-point is accepted if and only if the length of the message required to send before partition is more than the length of the message required to send after partition .
#<struct ReadData::Alignment source_numbers="38", target_numbers="42", tag_name="wa">
It says that the partition induced by a cut-point is accepted if and only if the length of the message required to send before partition is more than the length of the message required to send after partition .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
where \MATH and \MATH \MATH is the number of classes in \MATH Extensive experiments [19] ,[18] recommended that this method should be the first choice for variable discretization because it gives small number of cut-points while maintaining consistency .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
where \MATH and \MATH \MATH is the number of classes in \MATH Extensive experiments [19] ,[18] recommended that this method should be the first choice for variable discretization because it gives small number of cut-points while maintaining consistency .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
where \MATH and \MATH \MATH is the number of classes in \MATH Extensive experiments [19] ,[18] recommended that this method should be the first choice for variable discretization because it gives small number of cut-points while maintaining consistency .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
where \MATH and \MATH \MATH is the number of classes in \MATH Extensive experiments [19] ,[18] recommended that this method should be the first choice for variable discretization because it gives small number of cut-points while maintaining consistency .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
where \MATH and \MATH \MATH is the number of classes in \MATH Extensive experiments [19] ,[18] recommended that this method should be the first choice for variable discretization because it gives small number of cut-points while maintaining consistency .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
For experiments , face and non-face patterns are of size 24x24 .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
For experiments , face and non-face patterns are of size 24x24 .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
For experiments , face and non-face patterns are of size 24x24 .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
For experiments , face and non-face patterns are of size 24x24 .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
For experiments , face and non-face patterns are of size 24x24 .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Haar wavelet feature that has been widely used in many face detection systems [4] ,[6] ,[14] is used in our experiments .
#<struct ReadData::Alignment source_numbers="2", target_numbers="2", tag_name="wa">
Haar wavelet feature that has been widely used in many face detection systems [4] ,[6] ,[14] is used in our experiments .
#<struct ReadData::Alignment source_numbers="4", target_numbers="5", tag_name="wa">
Haar wavelet feature that has been widely used in many face detection systems [4] ,[6] ,[14] is used in our experiments .
#<struct ReadData::Alignment source_numbers="5", target_numbers="6", tag_name="wa">
Haar wavelet feature that has been widely used in many face detection systems [4] ,[6] ,[14] is used in our experiments .
#<struct ReadData::Alignment source_numbers="7", target_numbers="7", tag_name="wa">
Haar wavelet feature that has been widely used in many face detection systems [4] ,[6] ,[14] is used in our experiments .
#<struct ReadData::Alignment source_numbers="16", target_numbers="19", tag_name="wa">
Haar wavelet feature that has been widely used in many face detection systems [4] ,[6] ,[14] is used in our experiments .
#<struct ReadData::Alignment source_numbers="17", target_numbers="20", tag_name="wa">
Haar wavelet feature that has been widely used in many face detection systems [4] ,[6] ,[14] is used in our experiments .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
Haar wavelet feature that has been widely used in many face detection systems [4] ,[6] ,[14] is used in our experiments .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
Haar wavelet feature that has been widely used in many face detection systems [4] ,[6] ,[14] is used in our experiments .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
Haar wavelet feature that has been widely used in many face detection systems [4] ,[6] ,[14] is used in our experiments .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
Haar wavelet feature that has been widely used in many face detection systems [4] ,[6] ,[14] is used in our experiments .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Haar wavelet feature that has been widely used in many face detection systems [4] ,[6] ,[14] is used in our experiments .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Haar wavelet feature that has been widely used in many face detection systems [4] ,[6] ,[14] is used in our experiments .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Haar wavelet feature that has been widely used in many face detection systems [4] ,[6] ,[14] is used in our experiments .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
Haar wavelet feature that has been widely used in many face detection systems [4] ,[6] ,[14] is used in our experiments .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
Haar wavelet feature that has been widely used in many face detection systems [4] ,[6] ,[14] is used in our experiments .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Haar wavelet feature that has been widely used in many face detection systems [4] ,[6] ,[14] is used in our experiments .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
It consists of four kinds of features modeled from adjacent basic rectangles with the same size and shape .
#<struct ReadData::Alignment source_numbers="1,2", target_numbers="1,2", tag_name="wa">
It consists of four kinds of features modeled from adjacent basic rectangles with the same size and shape .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
It consists of four kinds of features modeled from adjacent basic rectangles with the same size and shape .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
The feature value is defined as the difference of sum of the pixels within rectangles ( cf . Figure 3 ) .
#<struct ReadData::Alignment source_numbers="21", target_numbers="20", tag_name="wa">
The feature value is defined as the difference of sum of the pixels within rectangles ( cf . Figure 3 ) .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
The feature value is defined as the difference of sum of the pixels within rectangles ( cf . Figure 3 ) .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
Figure 4 shows a comparison of performances of strong classifiers trained by different boosting schemes that are AdaBoost [4] , Real AdaBoost [17] and Ent-Boost .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
Figure 4 shows a comparison of performances of strong classifiers trained by different boosting schemes that are AdaBoost [4] , Real AdaBoost [17] and Ent-Boost .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
Figure 4 shows a comparison of performances of strong classifiers trained by different boosting schemes that are AdaBoost [4] , Real AdaBoost [17] and Ent-Boost .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Figure 4 shows a comparison of performances of strong classifiers trained by different boosting schemes that are AdaBoost [4] , Real AdaBoost [17] and Ent-Boost .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
As for Real AdaBoost , the subspace splitting is done by equal width binning in which the number of bins is arbitrarily selected to be 64 and 128 .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
As for Real AdaBoost , the subspace splitting is done by equal width binning in which the number of bins is arbitrarily selected to be 64 and 128 .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
As for Real AdaBoost , the subspace splitting is done by equal width binning in which the number of bins is arbitrarily selected to be 64 and 128 .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
As for Real AdaBoost , the subspace splitting is done by equal width binning in which the number of bins is arbitrarily selected to be 64 and 128 .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
As for Real AdaBoost , the subspace splitting is done by equal width binning in which the number of bins is arbitrarily selected to be 64 and 128 .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
As for Real AdaBoost , the subspace splitting is done by equal width binning in which the number of bins is arbitrarily selected to be 64 and 128 .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
The curves indicate that the performances of Real AdaBoost and Ent-Boost are better than that of AdaBoost .
#<struct ReadData::Alignment source_numbers="11,12", target_numbers="11,12", tag_name="wa">
In addition , the performance of Real AdaBoost classifiers varies when using different number of bins .
#<struct ReadData::Alignment source_numbers="13,14", target_numbers="13,14", tag_name="wa">
Overall , Ent-Boost has the best result .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
Overall , Ent-Boost has the best result .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
As for storage space , the Ent-Boost based classifier only employs 6 .79 bins on average which is much smaller than that of Real AdaBoost-based classifiers .
#<struct ReadData::Alignment source_numbers="20,21", target_numbers="20,21,22", tag_name="wa">
As for storage space , the Ent-Boost based classifier only employs 6 .79 bins on average which is much smaller than that of Real AdaBoost-based classifiers .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
As for storage space , the Ent-Boost based classifier only employs 6 .79 bins on average which is much smaller than that of Real AdaBoost-based classifiers .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
As for storage space , the Ent-Boost based classifier only employs 6 .79 bins on average which is much smaller than that of Real AdaBoost-based classifiers .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
As for storage space , the Ent-Boost based classifier only employs 6 .79 bins on average which is much smaller than that of Real AdaBoost-based classifiers .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
As for storage space , the Ent-Boost based classifier only employs 6 .79 bins on average which is much smaller than that of Real AdaBoost-based classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
As for storage space , the Ent-Boost based classifier only employs 6 .79 bins on average which is much smaller than that of Real AdaBoost-based classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
As for storage space , the Ent-Boost based classifier only employs 6 .79 bins on average which is much smaller than that of Real AdaBoost-based classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
As for storage space , the Ent-Boost based classifier only employs 6 .79 bins on average which is much smaller than that of Real AdaBoost-based classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
As for storage space , the Ent-Boost based classifier only employs 6 .79 bins on average which is much smaller than that of Real AdaBoost-based classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
It was a cascade of Ent-Boost based classifiers that were trained similar to [4] .
#<struct ReadData::Alignment source_numbers="13", target_numbers="18", tag_name="wa">
It was a cascade of Ent-Boost based classifiers that were trained similar to [4] .
#<struct ReadData::Alignment source_numbers="14", target_numbers="19", tag_name="wa">
It was a cascade of Ent-Boost based classifiers that were trained similar to [4] .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
It was a cascade of Ent-Boost based classifiers that were trained similar to [4] .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
It was a cascade of Ent-Boost based classifiers that were trained similar to [4] .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
It was a cascade of Ent-Boost based classifiers that were trained similar to [4] .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
It was a cascade of Ent-Boost based classifiers that were trained similar to [4] .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
It was a cascade of Ent-Boost based classifiers that were trained similar to [4] .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
It was a cascade of Ent-Boost based classifiers that were trained similar to [4] .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
It was a cascade of Ent-Boost based classifiers that were trained similar to [4] .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
It was a cascade of Ent-Boost based classifiers that were trained similar to [4] .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Performances of AdaBoost-based face detector [4] and Ent-Boost based face detector on MIT+CMU test set [1] shown in Table 2 has confirmed the effectiveness of our proposed boosting scheme .
#<struct ReadData::Alignment source_numbers="22", target_numbers="3", tag_name="wa">
Performances of AdaBoost-based face detector [4] and Ent-Boost based face detector on MIT+CMU test set [1] shown in Table 2 has confirmed the effectiveness of our proposed boosting scheme .
#<struct ReadData::Alignment source_numbers="21", target_numbers="19", tag_name="wa">
Performances of AdaBoost-based face detector [4] and Ent-Boost based face detector on MIT+CMU test set [1] shown in Table 2 has confirmed the effectiveness of our proposed boosting scheme .
#<struct ReadData::Alignment source_numbers="18", target_numbers="28", tag_name="wa">
Performances of AdaBoost-based face detector [4] and Ent-Boost based face detector on MIT+CMU test set [1] shown in Table 2 has confirmed the effectiveness of our proposed boosting scheme .
#<struct ReadData::Alignment source_numbers="19", target_numbers="29", tag_name="wa">
Performances of AdaBoost-based face detector [4] and Ent-Boost based face detector on MIT+CMU test set [1] shown in Table 2 has confirmed the effectiveness of our proposed boosting scheme .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Performances of AdaBoost-based face detector [4] and Ent-Boost based face detector on MIT+CMU test set [1] shown in Table 2 has confirmed the effectiveness of our proposed boosting scheme .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Performances of AdaBoost-based face detector [4] and Ent-Boost based face detector on MIT+CMU test set [1] shown in Table 2 has confirmed the effectiveness of our proposed boosting scheme .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Performances of AdaBoost-based face detector [4] and Ent-Boost based face detector on MIT+CMU test set [1] shown in Table 2 has confirmed the effectiveness of our proposed boosting scheme .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
Performances of AdaBoost-based face detector [4] and Ent-Boost based face detector on MIT+CMU test set [1] shown in Table 2 has confirmed the effectiveness of our proposed boosting scheme .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
Performances of AdaBoost-based face detector [4] and Ent-Boost based face detector on MIT+CMU test set [1] shown in Table 2 has confirmed the effectiveness of our proposed boosting scheme .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
Performances of AdaBoost-based face detector [4] and Ent-Boost based face detector on MIT+CMU test set [1] shown in Table 2 has confirmed the effectiveness of our proposed boosting scheme .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Performances of AdaBoost-based face detector [4] and Ent-Boost based face detector on MIT+CMU test set [1] shown in Table 2 has confirmed the effectiveness of our proposed boosting scheme .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Performances of AdaBoost-based face detector [4] and Ent-Boost based face detector on MIT+CMU test set [1] shown in Table 2 has confirmed the effectiveness of our proposed boosting scheme .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
Performances of AdaBoost-based face detector [4] and Ent-Boost based face detector on MIT+CMU test set [1] shown in Table 2 has confirmed the effectiveness of our proposed boosting scheme .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
Performances of AdaBoost-based face detector [4] and Ent-Boost based face detector on MIT+CMU test set [1] shown in Table 2 has confirmed the effectiveness of our proposed boosting scheme .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
We have presented Ent-Boost , a variant of AdaBoost , which uses entropy measure for automatic subspace splitting and optimal weak classifier selection .
#<struct ReadData::Alignment source_numbers="13,14", target_numbers="13,14", tag_name="wa">
We have presented Ent-Boost , a variant of AdaBoost , which uses entropy measure for automatic subspace splitting and optimal weak classifier selection .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
We have presented Ent-Boost , a variant of AdaBoost , which uses entropy measure for automatic subspace splitting and optimal weak classifier selection .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
The resulted strong classifier has good performance and compact storage .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Furthermore , it overcomes the main limitation of Real AdaBoost which is hard to determine the suitable number of bins for subspace splitting .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Furthermore , it overcomes the main limitation of Real AdaBoost which is hard to determine the suitable number of bins for subspace splitting .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
Furthermore , it overcomes the main limitation of Real AdaBoost which is hard to determine the suitable number of bins for subspace splitting .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Furthermore , it overcomes the main limitation of Real AdaBoost which is hard to determine the suitable number of bins for subspace splitting .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Furthermore , it overcomes the main limitation of Real AdaBoost which is hard to determine the suitable number of bins for subspace splitting .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Furthermore , it overcomes the main limitation of Real AdaBoost which is hard to determine the suitable number of bins for subspace splitting .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Furthermore , it overcomes the main limitation of Real AdaBoost which is hard to determine the suitable number of bins for subspace splitting .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Furthermore , it overcomes the main limitation of Real AdaBoost which is hard to determine the suitable number of bins for subspace splitting .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
By considering the class information and the distribution of the input data in splitting process , this method is generic and can be applied to other applications .
#<struct ReadData::Alignment source_numbers="1", target_numbers="2", tag_name="wa">
By considering the class information and the distribution of the input data in splitting process , this method is generic and can be applied to other applications .
#<struct ReadData::Alignment source_numbers="23", target_numbers="25", tag_name="wa">
By considering the class information and the distribution of the input data in splitting process , this method is generic and can be applied to other applications .
#<struct ReadData::Alignment source_numbers="24,25", target_numbers="26,27", tag_name="wa">
By considering the class information and the distribution of the input data in splitting process , this method is generic and can be applied to other applications .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
By considering the class information and the distribution of the input data in splitting process , this method is generic and can be applied to other applications .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
By considering the class information and the distribution of the input data in splitting process , this method is generic and can be applied to other applications .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
This paper describes an efficient feature selection method which quickly selects a small subset out of a given huge feature set for building robust object detection systems .
#<struct ReadData::Alignment source_numbers="27", target_numbers="36", tag_name="wa">
This paper describes an efficient feature selection method which quickly selects a small subset out of a given huge feature set for building robust object detection systems .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
This paper describes an efficient feature selection method which quickly selects a small subset out of a given huge feature set for building robust object detection systems .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
This paper describes an efficient feature selection method which quickly selects a small subset out of a given huge feature set for building robust object detection systems .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
This paper describes an efficient feature selection method which quickly selects a small subset out of a given huge feature set for building robust object detection systems .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
This paper describes an efficient feature selection method which quickly selects a small subset out of a given huge feature set for building robust object detection systems .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
This paper describes an efficient feature selection method which quickly selects a small subset out of a given huge feature set for building robust object detection systems .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
This paper describes an efficient feature selection method which quickly selects a small subset out of a given huge feature set for building robust object detection systems .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
This paper describes an efficient feature selection method which quickly selects a small subset out of a given huge feature set for building robust object detection systems .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
This paper describes an efficient feature selection method which quickly selects a small subset out of a given huge feature set for building robust object detection systems .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
In this filter-based method , features are selected so that not only maximizing their relevance with the target class but also minimizing their mutual dependency .
#<struct ReadData::Alignment source_numbers="12", target_numbers="13", tag_name="wa">
In this filter-based method , features are selected so that not only maximizing their relevance with the target class but also minimizing their mutual dependency .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
As a result , the selected feature set only contains highly informative and non-redundant features which when combined together , significantly improve classification performance .
#<struct ReadData::Alignment source_numbers="19", target_numbers="25", tag_name="wa">
As a result , the selected feature set only contains highly informative and non-redundant features which when combined together , significantly improve classification performance .
#<struct ReadData::Alignment source_numbers="24", target_numbers="30", tag_name="wa">
As a result , the selected feature set only contains highly informative and non-redundant features which when combined together , significantly improve classification performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
As a result , the selected feature set only contains highly informative and non-redundant features which when combined together , significantly improve classification performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
As a result , the selected feature set only contains highly informative and non-redundant features which when combined together , significantly improve classification performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
As a result , the selected feature set only contains highly informative and non-redundant features which when combined together , significantly improve classification performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
As a result , the selected feature set only contains highly informative and non-redundant features which when combined together , significantly improve classification performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
As a result , the selected feature set only contains highly informative and non-redundant features which when combined together , significantly improve classification performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
The relevance and mutual dependency of features are measured by using conditional mutual information ( CMI ) in which features and classes are treated as discrete random variables .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
The relevance and mutual dependency of features are measured by using conditional mutual information ( CMI ) in which features and classes are treated as discrete random variables .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
The relevance and mutual dependency of features are measured by using conditional mutual information ( CMI ) in which features and classes are treated as discrete random variables .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
The relevance and mutual dependency of features are measured by using conditional mutual information ( CMI ) in which features and classes are treated as discrete random variables .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
The relevance and mutual dependency of features are measured by using conditional mutual information ( CMI ) in which features and classes are treated as discrete random variables .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
The relevance and mutual dependency of features are measured by using conditional mutual information ( CMI ) in which features and classes are treated as discrete random variables .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
The relevance and mutual dependency of features are measured by using conditional mutual information ( CMI ) in which features and classes are treated as discrete random variables .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
The relevance and mutual dependency of features are measured by using conditional mutual information ( CMI ) in which features and classes are treated as discrete random variables .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
The relevance and mutual dependency of features are measured by using conditional mutual information ( CMI ) in which features and classes are treated as discrete random variables .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
The relevance and mutual dependency of features are measured by using conditional mutual information ( CMI ) in which features and classes are treated as discrete random variables .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
The relevance and mutual dependency of features are measured by using conditional mutual information ( CMI ) in which features and classes are treated as discrete random variables .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
The relevance and mutual dependency of features are measured by using conditional mutual information ( CMI ) in which features and classes are treated as discrete random variables .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
The relevance and mutual dependency of features are measured by using conditional mutual information ( CMI ) in which features and classes are treated as discrete random variables .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
The relevance and mutual dependency of features are measured by using conditional mutual information ( CMI ) in which features and classes are treated as discrete random variables .
#<struct ReadData::Alignment source_numbers="", target_numbers="40", tag_name="wa">
The relevance and mutual dependency of features are measured by using conditional mutual information ( CMI ) in which features and classes are treated as discrete random variables .
#<struct ReadData::Alignment source_numbers="", target_numbers="41", tag_name="wa">
The relevance and mutual dependency of features are measured by using conditional mutual information ( CMI ) in which features and classes are treated as discrete random variables .
#<struct ReadData::Alignment source_numbers="", target_numbers="42", tag_name="wa">
The relevance and mutual dependency of features are measured by using conditional mutual information ( CMI ) in which features and classes are treated as discrete random variables .
#<struct ReadData::Alignment source_numbers="", target_numbers="43", tag_name="wa">
One of the fundamental research issues in pattern recognition is feature selection which is the task of finding a small subset out of a given large set of features .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
It is significant due to the following three reasons .
#<struct ReadData::Alignment source_numbers="1", target_numbers="7", tag_name="wa">
It is significant due to the following three reasons .
#<struct ReadData::Alignment source_numbers="9", target_numbers="15", tag_name="wa">
It is significant due to the following three reasons .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
It is significant due to the following three reasons .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
It is significant due to the following three reasons .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
It is significant due to the following three reasons .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
It is significant due to the following three reasons .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
It is significant due to the following three reasons .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
It is significant due to the following three reasons .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
It is significant due to the following three reasons .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
First , there are many ways to represent a target object , leading to a huge feature set .
#<struct ReadData::Alignment source_numbers="18", target_numbers="24", tag_name="wa">
First , there are many ways to represent a target object , leading to a huge feature set .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
First , there are many ways to represent a target object , leading to a huge feature set .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
First , there are many ways to represent a target object , leading to a huge feature set .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
First , there are many ways to represent a target object , leading to a huge feature set .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
First , there are many ways to represent a target object , leading to a huge feature set .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
First , there are many ways to represent a target object , leading to a huge feature set .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
First , there are many ways to represent a target object , leading to a huge feature set .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
First , there are many ways to represent a target object , leading to a huge feature set .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
Second , a huge feature set usually includes many irrelevant and redundant features that can degrade the generalization performance of classifiers , waste storage space and increase training time [2 , 3] .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
Furthermore , less complex model is easier to understand and verify .
#<struct ReadData::Alignment source_numbers="4", target_numbers="4", tag_name="wa">
Furthermore , less complex model is easier to understand and verify .
#<struct ReadData::Alignment source_numbers="5", target_numbers="5", tag_name="wa">
Furthermore , less complex model is easier to understand and verify .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="23", target_numbers="38", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="", target_numbers="40", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="", target_numbers="41", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="", target_numbers="42", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="", target_numbers="43", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="", target_numbers="44", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="", target_numbers="45", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="", target_numbers="46", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="", target_numbers="47", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="", target_numbers="48", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="", target_numbers="49", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="", target_numbers="50", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="", target_numbers="51", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="", target_numbers="52", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="", target_numbers="53", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="", target_numbers="54", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="", target_numbers="55", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="", target_numbers="56", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="", target_numbers="57", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="", target_numbers="58", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="", target_numbers="59", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="", target_numbers="60", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="", target_numbers="61", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="", target_numbers="62", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="", target_numbers="63", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="", target_numbers="64", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="", target_numbers="65", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="", target_numbers="66", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="", target_numbers="67", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="", target_numbers="68", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="", target_numbers="69", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="", target_numbers="70", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="", target_numbers="71", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="", target_numbers="72", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="", target_numbers="73", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="", target_numbers="74", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="", target_numbers="75", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="", target_numbers="76", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="", target_numbers="77", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="", target_numbers="78", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="", target_numbers="79", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="", target_numbers="80", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="", target_numbers="81", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="", target_numbers="82", tag_name="wa">
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
#<struct ReadData::Alignment source_numbers="", target_numbers="83", tag_name="wa">
In the filter-based approach , features are normally selected based on their individual predictive power which is measured by Fisher scores , Pearson correlation [6] or mutual information [7] .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
In the filter-based approach , features are normally selected based on their individual predictive power which is measured by Fisher scores , Pearson correlation [6] or mutual information [7] .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
In the filter-based approach , features are normally selected based on their individual predictive power which is measured by Fisher scores , Pearson correlation [6] or mutual information [7] .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
In the filter-based approach , features are normally selected based on their individual predictive power which is measured by Fisher scores , Pearson correlation [6] or mutual information [7] .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
In the filter-based approach , features are normally selected based on their individual predictive power which is measured by Fisher scores , Pearson correlation [6] or mutual information [7] .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
The major advantage of these methods is their speed and ability to scale to huge feature sets .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
However , the mutual relationships between features is often not taken into account , leading selected features might be highly redundant and less informative because two features with high individual predict power when combined together might not bring significant performance improvement compared with two features which one of them has low predictive power but is useful when combined with others .
#<struct ReadData::Alignment source_numbers="24", target_numbers="2", tag_name="wa">
However , the mutual relationships between features is often not taken into account , leading selected features might be highly redundant and less informative because two features with high individual predict power when combined together might not bring significant performance improvement compared with two features which one of them has low predictive power but is useful when combined with others .
#<struct ReadData::Alignment source_numbers="54", target_numbers="9", tag_name="wa">
However , the mutual relationships between features is often not taken into account , leading selected features might be highly redundant and less informative because two features with high individual predict power when combined together might not bring significant performance improvement compared with two features which one of them has low predictive power but is useful when combined with others .
#<struct ReadData::Alignment source_numbers="51", target_numbers="33", tag_name="wa">
However , the mutual relationships between features is often not taken into account , leading selected features might be highly redundant and less informative because two features with high individual predict power when combined together might not bring significant performance improvement compared with two features which one of them has low predictive power but is useful when combined with others .
#<struct ReadData::Alignment source_numbers="52", target_numbers="34", tag_name="wa">
However , the mutual relationships between features is often not taken into account , leading selected features might be highly redundant and less informative because two features with high individual predict power when combined together might not bring significant performance improvement compared with two features which one of them has low predictive power but is useful when combined with others .
#<struct ReadData::Alignment source_numbers="60", target_numbers="46", tag_name="wa">
However , the mutual relationships between features is often not taken into account , leading selected features might be highly redundant and less informative because two features with high individual predict power when combined together might not bring significant performance improvement compared with two features which one of them has low predictive power but is useful when combined with others .
#<struct ReadData::Alignment source_numbers="47", target_numbers="52", tag_name="wa">
However , the mutual relationships between features is often not taken into account , leading selected features might be highly redundant and less informative because two features with high individual predict power when combined together might not bring significant performance improvement compared with two features which one of them has low predictive power but is useful when combined with others .
#<struct ReadData::Alignment source_numbers="30", target_numbers="59", tag_name="wa">
However , the mutual relationships between features is often not taken into account , leading selected features might be highly redundant and less informative because two features with high individual predict power when combined together might not bring significant performance improvement compared with two features which one of them has low predictive power but is useful when combined with others .
#<struct ReadData::Alignment source_numbers="31", target_numbers="60", tag_name="wa">
However , the mutual relationships between features is often not taken into account , leading selected features might be highly redundant and less informative because two features with high individual predict power when combined together might not bring significant performance improvement compared with two features which one of them has low predictive power but is useful when combined with others .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
However , the mutual relationships between features is often not taken into account , leading selected features might be highly redundant and less informative because two features with high individual predict power when combined together might not bring significant performance improvement compared with two features which one of them has low predictive power but is useful when combined with others .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
However , the mutual relationships between features is often not taken into account , leading selected features might be highly redundant and less informative because two features with high individual predict power when combined together might not bring significant performance improvement compared with two features which one of them has low predictive power but is useful when combined with others .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
However , the mutual relationships between features is often not taken into account , leading selected features might be highly redundant and less informative because two features with high individual predict power when combined together might not bring significant performance improvement compared with two features which one of them has low predictive power but is useful when combined with others .
#<struct ReadData::Alignment source_numbers="", target_numbers="47", tag_name="wa">
However , the mutual relationships between features is often not taken into account , leading selected features might be highly redundant and less informative because two features with high individual predict power when combined together might not bring significant performance improvement compared with two features which one of them has low predictive power but is useful when combined with others .
#<struct ReadData::Alignment source_numbers="", target_numbers="55", tag_name="wa">
However , the mutual relationships between features is often not taken into account , leading selected features might be highly redundant and less informative because two features with high individual predict power when combined together might not bring significant performance improvement compared with two features which one of them has low predictive power but is useful when combined with others .
#<struct ReadData::Alignment source_numbers="", target_numbers="62", tag_name="wa">
However , the mutual relationships between features is often not taken into account , leading selected features might be highly redundant and less informative because two features with high individual predict power when combined together might not bring significant performance improvement compared with two features which one of them has low predictive power but is useful when combined with others .
#<struct ReadData::Alignment source_numbers="", target_numbers="68", tag_name="wa">
However , the mutual relationships between features is often not taken into account , leading selected features might be highly redundant and less informative because two features with high individual predict power when combined together might not bring significant performance improvement compared with two features which one of them has low predictive power but is useful when combined with others .
#<struct ReadData::Alignment source_numbers="", target_numbers="69", tag_name="wa">
However , the mutual relationships between features is often not taken into account , leading selected features might be highly redundant and less informative because two features with high individual predict power when combined together might not bring significant performance improvement compared with two features which one of them has low predictive power but is useful when combined with others .
#<struct ReadData::Alignment source_numbers="", target_numbers="70", tag_name="wa">
However , the mutual relationships between features is often not taken into account , leading selected features might be highly redundant and less informative because two features with high individual predict power when combined together might not bring significant performance improvement compared with two features which one of them has low predictive power but is useful when combined with others .
#<struct ReadData::Alignment source_numbers="", target_numbers="71", tag_name="wa">
However , the mutual relationships between features is often not taken into account , leading selected features might be highly redundant and less informative because two features with high individual predict power when combined together might not bring significant performance improvement compared with two features which one of them has low predictive power but is useful when combined with others .
#<struct ReadData::Alignment source_numbers="", target_numbers="72", tag_name="wa">
However , the mutual relationships between features is often not taken into account , leading selected features might be highly redundant and less informative because two features with high individual predict power when combined together might not bring significant performance improvement compared with two features which one of them has low predictive power but is useful when combined with others .
#<struct ReadData::Alignment source_numbers="", target_numbers="73", tag_name="wa">
However , the mutual relationships between features is often not taken into account , leading selected features might be highly redundant and less informative because two features with high individual predict power when combined together might not bring significant performance improvement compared with two features which one of them has low predictive power but is useful when combined with others .
#<struct ReadData::Alignment source_numbers="", target_numbers="74", tag_name="wa">
However , the mutual relationships between features is often not taken into account , leading selected features might be highly redundant and less informative because two features with high individual predict power when combined together might not bring significant performance improvement compared with two features which one of them has low predictive power but is useful when combined with others .
#<struct ReadData::Alignment source_numbers="", target_numbers="75", tag_name="wa">
However , the mutual relationships between features is often not taken into account , leading selected features might be highly redundant and less informative because two features with high individual predict power when combined together might not bring significant performance improvement compared with two features which one of them has low predictive power but is useful when combined with others .
#<struct ReadData::Alignment source_numbers="", target_numbers="76", tag_name="wa">
Since wrapper-based feature selection methods use machine learning algorithms as a black box in selection process , they can suffer from over-fitting in situations of small training sets .
#<struct ReadData::Alignment source_numbers="24", target_numbers="25", tag_name="wa">
Since wrapper-based feature selection methods use machine learning algorithms as a black box in selection process , they can suffer from over-fitting in situations of small training sets .
#<struct ReadData::Alignment source_numbers="28", target_numbers="32", tag_name="wa">
Since wrapper-based feature selection methods use machine learning algorithms as a black box in selection process , they can suffer from over-fitting in situations of small training sets .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Since wrapper-based feature selection methods use machine learning algorithms as a black box in selection process , they can suffer from over-fitting in situations of small training sets .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
Since wrapper-based feature selection methods use machine learning algorithms as a black box in selection process , they can suffer from over-fitting in situations of small training sets .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
Since wrapper-based feature selection methods use machine learning algorithms as a black box in selection process , they can suffer from over-fitting in situations of small training sets .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
Since wrapper-based feature selection methods use machine learning algorithms as a black box in selection process , they can suffer from over-fitting in situations of small training sets .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
Since wrapper-based feature selection methods use machine learning algorithms as a black box in selection process , they can suffer from over-fitting in situations of small training sets .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
Since wrapper-based feature selection methods use machine learning algorithms as a black box in selection process , they can suffer from over-fitting in situations of small training sets .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
Since wrapper-based feature selection methods use machine learning algorithms as a black box in selection process , they can suffer from over-fitting in situations of small training sets .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
Since wrapper-based feature selection methods use machine learning algorithms as a black box in selection process , they can suffer from over-fitting in situations of small training sets .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
Since wrapper-based feature selection methods use machine learning algorithms as a black box in selection process , they can suffer from over-fitting in situations of small training sets .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
Since wrapper-based feature selection methods use machine learning algorithms as a black box in selection process , they can suffer from over-fitting in situations of small training sets .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
Furthermore , in practical object detection systems as in [1 , 8] , the feature sets usually have hundreds of thousands features , using wrapper-based methods is obviously inefficient because of very high computation cost .
#<struct ReadData::Alignment source_numbers="35", target_numbers="40", tag_name="wa">
Furthermore , in practical object detection systems as in [1 , 8] , the feature sets usually have hundreds of thousands features , using wrapper-based methods is obviously inefficient because of very high computation cost .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
Furthermore , in practical object detection systems as in [1 , 8] , the feature sets usually have hundreds of thousands features , using wrapper-based methods is obviously inefficient because of very high computation cost .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
Furthermore , in practical object detection systems as in [1 , 8] , the feature sets usually have hundreds of thousands features , using wrapper-based methods is obviously inefficient because of very high computation cost .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
For example , in the state of the art face detection system [1] , choosing a 6 ,061- feature set out of a 180 ,000-feature set by AdaBoost has taken several weeks .
#<struct ReadData::Alignment source_numbers="8", target_numbers="8", tag_name="wa">
For example , in the state of the art face detection system [1] , choosing a 6 ,061- feature set out of a 180 ,000-feature set by AdaBoost has taken several weeks .
#<struct ReadData::Alignment source_numbers="26", target_numbers="27", tag_name="wa">
For example , in the state of the art face detection system [1] , choosing a 6 ,061- feature set out of a 180 ,000-feature set by AdaBoost has taken several weeks .
#<struct ReadData::Alignment source_numbers="28", target_numbers="30", tag_name="wa">
For example , in the state of the art face detection system [1] , choosing a 6 ,061- feature set out of a 180 ,000-feature set by AdaBoost has taken several weeks .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
For example , in the state of the art face detection system [1] , choosing a 6 ,061- feature set out of a 180 ,000-feature set by AdaBoost has taken several weeks .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
For example , in the state of the art face detection system [1] , choosing a 6 ,061- feature set out of a 180 ,000-feature set by AdaBoost has taken several weeks .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
For example , in the state of the art face detection system [1] , choosing a 6 ,061- feature set out of a 180 ,000-feature set by AdaBoost has taken several weeks .
#<struct ReadData::Alignment source_numbers="29", target_numbers="", tag_name="wa">
For example , in the state of the art face detection system [1] , choosing a 6 ,061- feature set out of a 180 ,000-feature set by AdaBoost has taken several weeks .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
For example , in the state of the art face detection system [1] , choosing a 6 ,061- feature set out of a 180 ,000-feature set by AdaBoost has taken several weeks .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
For example , in the state of the art face detection system [1] , choosing a 6 ,061- feature set out of a 180 ,000-feature set by AdaBoost has taken several weeks .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
For example , in the state of the art face detection system [1] , choosing a 6 ,061- feature set out of a 180 ,000-feature set by AdaBoost has taken several weeks .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
For example , in the state of the art face detection system [1] , choosing a 6 ,061- feature set out of a 180 ,000-feature set by AdaBoost has taken several weeks .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
For example , in the state of the art face detection system [1] , choosing a 6 ,061- feature set out of a 180 ,000-feature set by AdaBoost has taken several weeks .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
For example , in the state of the art face detection system [1] , choosing a 6 ,061- feature set out of a 180 ,000-feature set by AdaBoost has taken several weeks .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
For example , in the state of the art face detection system [1] , choosing a 6 ,061- feature set out of a 180 ,000-feature set by AdaBoost has taken several weeks .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
For example , in the state of the art face detection system [1] , choosing a 6 ,061- feature set out of a 180 ,000-feature set by AdaBoost has taken several weeks .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
For example , in the state of the art face detection system [1] , choosing a 6 ,061- feature set out of a 180 ,000-feature set by AdaBoost has taken several weeks .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
For example , in the state of the art face detection system [1] , choosing a 6 ,061- feature set out of a 180 ,000-feature set by AdaBoost has taken several weeks .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
Consequently , conditional mutual information ( CMI ) based feature selection methods have been proposed [9 , 8 , 7 , 10] to take full advantage of above approaches for handling large scale feature sets .
#<struct ReadData::Alignment source_numbers="9", target_numbers="2", tag_name="wa">
Consequently , conditional mutual information ( CMI ) based feature selection methods have been proposed [9 , 8 , 7 , 10] to take full advantage of above approaches for handling large scale feature sets .
#<struct ReadData::Alignment source_numbers="10", target_numbers="3", tag_name="wa">
Consequently , conditional mutual information ( CMI ) based feature selection methods have been proposed [9 , 8 , 7 , 10] to take full advantage of above approaches for handling large scale feature sets .
#<struct ReadData::Alignment source_numbers="11", target_numbers="4", tag_name="wa">
Consequently , conditional mutual information ( CMI ) based feature selection methods have been proposed [9 , 8 , 7 , 10] to take full advantage of above approaches for handling large scale feature sets .
#<struct ReadData::Alignment source_numbers="33", target_numbers="14", tag_name="wa">
Consequently , conditional mutual information ( CMI ) based feature selection methods have been proposed [9 , 8 , 7 , 10] to take full advantage of above approaches for handling large scale feature sets .
#<struct ReadData::Alignment source_numbers="35", target_numbers="41", tag_name="wa">
Consequently , conditional mutual information ( CMI ) based feature selection methods have been proposed [9 , 8 , 7 , 10] to take full advantage of above approaches for handling large scale feature sets .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Consequently , conditional mutual information ( CMI ) based feature selection methods have been proposed [9 , 8 , 7 , 10] to take full advantage of above approaches for handling large scale feature sets .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Consequently , conditional mutual information ( CMI ) based feature selection methods have been proposed [9 , 8 , 7 , 10] to take full advantage of above approaches for handling large scale feature sets .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
Consequently , conditional mutual information ( CMI ) based feature selection methods have been proposed [9 , 8 , 7 , 10] to take full advantage of above approaches for handling large scale feature sets .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
Consequently , conditional mutual information ( CMI ) based feature selection methods have been proposed [9 , 8 , 7 , 10] to take full advantage of above approaches for handling large scale feature sets .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
The main idea of CMI-based methods is to select features which maximize their relevance with the target class and simultaneously minimize mutual dependency between selected ones .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
The main idea of CMI-based methods is to select features which maximize their relevance with the target class and simultaneously minimize mutual dependency between selected ones .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
The main idea of CMI-based methods is to select features which maximize their relevance with the target class and simultaneously minimize mutual dependency between selected ones .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
The main idea of CMI-based methods is to select features which maximize their relevance with the target class and simultaneously minimize mutual dependency between selected ones .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
The main idea of CMI-based methods is to select features which maximize their relevance with the target class and simultaneously minimize mutual dependency between selected ones .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
The main idea of CMI-based methods is to select features which maximize their relevance with the target class and simultaneously minimize mutual dependency between selected ones .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
The main idea of CMI-based methods is to select features which maximize their relevance with the target class and simultaneously minimize mutual dependency between selected ones .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
It does not select a feature similar to already selected ones , even if it is individual powerful , as selecting it might not increase much information about the target class [7] .
#<struct ReadData::Alignment source_numbers="1,2", target_numbers="3,4", tag_name="wa">
It does not select a feature similar to already selected ones , even if it is individual powerful , as selecting it might not increase much information about the target class [7] .
#<struct ReadData::Alignment source_numbers="15", target_numbers="19", tag_name="wa">
It does not select a feature similar to already selected ones , even if it is individual powerful , as selecting it might not increase much information about the target class [7] .
#<struct ReadData::Alignment source_numbers="16", target_numbers="20", tag_name="wa">
It does not select a feature similar to already selected ones , even if it is individual powerful , as selecting it might not increase much information about the target class [7] .
#<struct ReadData::Alignment source_numbers="17", target_numbers="21", tag_name="wa">
It does not select a feature similar to already selected ones , even if it is individual powerful , as selecting it might not increase much information about the target class [7] .
#<struct ReadData::Alignment source_numbers="18", target_numbers="22", tag_name="wa">
It does not select a feature similar to already selected ones , even if it is individual powerful , as selecting it might not increase much information about the target class [7] .
#<struct ReadData::Alignment source_numbers="19", target_numbers="23", tag_name="wa">
It does not select a feature similar to already selected ones , even if it is individual powerful , as selecting it might not increase much information about the target class [7] .
#<struct ReadData::Alignment source_numbers="20", target_numbers="25", tag_name="wa">
It does not select a feature similar to already selected ones , even if it is individual powerful , as selecting it might not increase much information about the target class [7] .
#<struct ReadData::Alignment source_numbers="21", target_numbers="26", tag_name="wa">
It does not select a feature similar to already selected ones , even if it is individual powerful , as selecting it might not increase much information about the target class [7] .
#<struct ReadData::Alignment source_numbers="22", target_numbers="27", tag_name="wa">
It does not select a feature similar to already selected ones , even if it is individual powerful , as selecting it might not increase much information about the target class [7] .
#<struct ReadData::Alignment source_numbers="23", target_numbers="28", tag_name="wa">
It does not select a feature similar to already selected ones , even if it is individual powerful , as selecting it might not increase much information about the target class [7] .
#<struct ReadData::Alignment source_numbers="25", target_numbers="30", tag_name="wa">
It does not select a feature similar to already selected ones , even if it is individual powerful , as selecting it might not increase much information about the target class [7] .
#<struct ReadData::Alignment source_numbers="24", target_numbers="32", tag_name="wa">
It does not select a feature similar to already selected ones , even if it is individual powerful , as selecting it might not increase much information about the target class [7] .
#<struct ReadData::Alignment source_numbers="26", target_numbers="34", tag_name="wa">
It does not select a feature similar to already selected ones , even if it is individual powerful , as selecting it might not increase much information about the target class [7] .
#<struct ReadData::Alignment source_numbers="27", target_numbers="35", tag_name="wa">
It does not select a feature similar to already selected ones , even if it is individual powerful , as selecting it might not increase much information about the target class [7] .
#<struct ReadData::Alignment source_numbers="28", target_numbers="36", tag_name="wa">
It does not select a feature similar to already selected ones , even if it is individual powerful , as selecting it might not increase much information about the target class [7] .
#<struct ReadData::Alignment source_numbers="29", target_numbers="37", tag_name="wa">
It does not select a feature similar to already selected ones , even if it is individual powerful , as selecting it might not increase much information about the target class [7] .
#<struct ReadData::Alignment source_numbers="30", target_numbers="38", tag_name="wa">
It does not select a feature similar to already selected ones , even if it is individual powerful , as selecting it might not increase much information about the target class [7] .
#<struct ReadData::Alignment source_numbers="31", target_numbers="39", tag_name="wa">
It does not select a feature similar to already selected ones , even if it is individual powerful , as selecting it might not increase much information about the target class [7] .
#<struct ReadData::Alignment source_numbers="32", target_numbers="40", tag_name="wa">
It does not select a feature similar to already selected ones , even if it is individual powerful , as selecting it might not increase much information about the target class [7] .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
It does not select a feature similar to already selected ones , even if it is individual powerful , as selecting it might not increase much information about the target class [7] .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
It does not select a feature similar to already selected ones , even if it is individual powerful , as selecting it might not increase much information about the target class [7] .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
It does not select a feature similar to already selected ones , even if it is individual powerful , as selecting it might not increase much information about the target class [7] .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
It does not select a feature similar to already selected ones , even if it is individual powerful , as selecting it might not increase much information about the target class [7] .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
It does not select a feature similar to already selected ones , even if it is individual powerful , as selecting it might not increase much information about the target class [7] .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
It does not select a feature similar to already selected ones , even if it is individual powerful , as selecting it might not increase much information about the target class [7] .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
It does not select a feature similar to already selected ones , even if it is individual powerful , as selecting it might not increase much information about the target class [7] .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
It does not select a feature similar to already selected ones , even if it is individual powerful , as selecting it might not increase much information about the target class [7] .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
It does not select a feature similar to already selected ones , even if it is individual powerful , as selecting it might not increase much information about the target class [7] .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
One of the important tasks in using CMI-based methods is mutual information estimation which involves to compute probability densities of continuous random variables .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
One of the important tasks in using CMI-based methods is mutual information estimation which involves to compute probability densities of continuous random variables .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
One of the important tasks in using CMI-based methods is mutual information estimation which involves to compute probability densities of continuous random variables .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
One of the important tasks in using CMI-based methods is mutual information estimation which involves to compute probability densities of continuous random variables .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
In [9] , Kwak and Choi used Parzen windows based density estimation method in which many parameters such as kernel function and window width are complicated to determine .
#<struct ReadData::Alignment source_numbers="8", target_numbers="9", tag_name="wa">
In [9] , Kwak and Choi used Parzen windows based density estimation method in which many parameters such as kernel function and window width are complicated to determine .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
In [9] , Kwak and Choi used Parzen windows based density estimation method in which many parameters such as kernel function and window width are complicated to determine .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
In [9] , Kwak and Choi used Parzen windows based density estimation method in which many parameters such as kernel function and window width are complicated to determine .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
For simplification , discretizing features is often used .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
For simplification , discretizing features is often used .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
For simplification , discretizing features is often used .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
For simplification , discretizing features is often used .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
For simplification , discretizing features is often used .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
For simplification , discretizing features is often used .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
For simplification , discretizing features is often used .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
For simplification , discretizing features is often used .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
For simplification , discretizing features is often used .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
For simplification , discretizing features is often used .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
For simplification , discretizing features is often used .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
For simplification , discretizing features is often used .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
For simplification , discretizing features is often used .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
For simplification , discretizing features is often used .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
For simplification , discretizing features is often used .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
For simplification , discretizing features is often used .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
For simplification , discretizing features is often used .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
So far , in object detection systems like [8 , 7] , features are treated as binary random variables by choosing appropriate thresholds .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
However , binarizing features is not a suitable way to handle highly complex data for which it is hard to find the best threshold .
#<struct ReadData::Alignment source_numbers="20,21", target_numbers="20,21", tag_name="wa">
However , binarizing features is not a suitable way to handle highly complex data for which it is hard to find the best threshold .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
However , binarizing features is not a suitable way to handle highly complex data for which it is hard to find the best threshold .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
It is better if multiple thresholds are used to discretize data .
#<struct ReadData::Alignment source_numbers="1", target_numbers="6", tag_name="wa">
It is better if multiple thresholds are used to discretize data .
#<struct ReadData::Alignment source_numbers="2", target_numbers="7", tag_name="wa">
It is better if multiple thresholds are used to discretize data .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
It is better if multiple thresholds are used to discretize data .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
It is better if multiple thresholds are used to discretize data .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
It is better if multiple thresholds are used to discretize data .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
It is better if multiple thresholds are used to discretize data .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
It is better if multiple thresholds are used to discretize data .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
It is better if multiple thresholds are used to discretize data .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
It is better if multiple thresholds are used to discretize data .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
It is better if multiple thresholds are used to discretize data .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
It is better if multiple thresholds are used to discretize data .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
Such a simple method is equal-width binning which divides the range of feature values into m equal sized bins , where m must be known in advance .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
However , the main distinguished point is that it employs the entropy-based discretization method [11] to discretize features .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
However , the main distinguished point is that it employs the entropy-based discretization method [11] to discretize features .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
However , the main distinguished point is that it employs the entropy-based discretization method [11] to discretize features .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
However , the main distinguished point is that it employs the entropy-based discretization method [11] to discretize features .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
This discretization method is simpler than Parzen windows based density estimation method and more efficient than binary discretization .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
This discretization method is simpler than Parzen windows based density estimation method and more efficient than binary discretization .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
This discretization method is simpler than Parzen windows based density estimation method and more efficient than binary discretization .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Furthermore , contrary to equal-width binning , it can automatically evaluate the optimal number of bins based on data distribution .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
Furthermore , contrary to equal-width binning , it can automatically evaluate the optimal number of bins based on data distribution .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
Furthermore , contrary to equal-width binning , it can automatically evaluate the optimal number of bins based on data distribution .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
Experiments show that the proposed method can well handle huge feature sets for face detection such as Haar wavelets [1] and Gabor wavelets [12] , significantly reduce the training time while maintaining high classification performance .
#<struct ReadData::Alignment source_numbers="26", target_numbers="", tag_name="wa">
Experiments show that the proposed method can well handle huge feature sets for face detection such as Haar wavelets [1] and Gabor wavelets [12] , significantly reduce the training time while maintaining high classification performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Experiments show that the proposed method can well handle huge feature sets for face detection such as Haar wavelets [1] and Gabor wavelets [12] , significantly reduce the training time while maintaining high classification performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Experiments show that the proposed method can well handle huge feature sets for face detection such as Haar wavelets [1] and Gabor wavelets [12] , significantly reduce the training time while maintaining high classification performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Experiments show that the proposed method can well handle huge feature sets for face detection such as Haar wavelets [1] and Gabor wavelets [12] , significantly reduce the training time while maintaining high classification performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
Huge feature sets usually contain four kinds of features : ( i ) irrelevant features , ( ii ) weakly relevant and redundant features , ( iii ) weakly relevant but non-redundant features and ( iv ) strongly relevant features in which ( iii ) and ( iv ) are the objective of feature selection methods [13] .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
Huge feature sets usually contain four kinds of features : ( i ) irrelevant features , ( ii ) weakly relevant and redundant features , ( iii ) weakly relevant but non-redundant features and ( iv ) strongly relevant features in which ( iii ) and ( iv ) are the objective of feature selection methods [13] .
#<struct ReadData::Alignment source_numbers="", target_numbers="41", tag_name="wa">
To measure relevance of a feature , the entropy-based measure which quantifies the uncertainty of random variables is normally used .
#<struct ReadData::Alignment source_numbers="7", target_numbers="2", tag_name="wa">
To measure relevance of a feature , the entropy-based measure which quantifies the uncertainty of random variables is normally used .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
To measure relevance of a feature , the entropy-based measure which quantifies the uncertainty of random variables is normally used .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
To measure relevance of a feature , the entropy-based measure which quantifies the uncertainty of random variables is normally used .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
The mutual dependence between two random variables is measured by mutual information \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
The conditional mutual information is defined as : \MATH
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
In the first step , the most relevant feature F1 which has the highest mutual information is selected .
#<struct ReadData::Alignment source_numbers="14", target_numbers="18", tag_name="wa">
In the first step , the most relevant feature F1 which has the highest mutual information is selected .
#<struct ReadData::Alignment source_numbers="15", target_numbers="19", tag_name="wa">
In the first step , the most relevant feature F1 which has the highest mutual information is selected .
#<struct ReadData::Alignment source_numbers="18", target_numbers="23", tag_name="wa">
In the first step , the most relevant feature F1 which has the highest mutual information is selected .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
In the first step , the most relevant feature F1 which has the highest mutual information is selected .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
In the first step , the most relevant feature F1 which has the highest mutual information is selected .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
In the first step , the most relevant feature F1 which has the highest mutual information is selected .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
In the first step , the most relevant feature F1 which has the highest mutual information is selected .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
However , in the second step , the condition to select feature F2 is not its mutual information alone , but how much information of F2 can add with respect to the already existing F1 .
#<struct ReadData::Alignment source_numbers="19", target_numbers="8", tag_name="wa">
However , in the second step , the condition to select feature F2 is not its mutual information alone , but how much information of F2 can add with respect to the already existing F1 .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
However , in the second step , the condition to select feature F2 is not its mutual information alone , but how much information of F2 can add with respect to the already existing F1 .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
However , in the second step , the condition to select feature F2 is not its mutual information alone , but how much information of F2 can add with respect to the already existing F1 .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
However , in the second step , the condition to select feature F2 is not its mutual information alone , but how much information of F2 can add with respect to the already existing F1 .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
Therefore , F2 is selected so that maximizing :\MATH .
#<struct ReadData::Alignment source_numbers="8", target_numbers="15", tag_name="wa">
Therefore , F2 is selected so that maximizing :\MATH .
#<struct ReadData::Alignment source_numbers="9", target_numbers="16", tag_name="wa">
Therefore , F2 is selected so that maximizing :\MATH .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Therefore , F2 is selected so that maximizing :\MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Therefore , F2 is selected so that maximizing :\MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Therefore , F2 is selected so that maximizing :\MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Therefore , F2 is selected so that maximizing :\MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Therefore , F2 is selected so that maximizing :\MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
Therefore , F2 is selected so that maximizing :\MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
Therefore , F2 is selected so that maximizing :\MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Therefore , F2 is selected so that maximizing :\MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Following the same scheme , we iteratively add the feature that brings the highest increase of information content contained in current selected feature set .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
Following the same scheme , we iteratively add the feature that brings the highest increase of information content contained in current selected feature set .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
Following the same scheme , we iteratively add the feature that brings the highest increase of information content contained in current selected feature set .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Following the same scheme , we iteratively add the feature that brings the highest increase of information content contained in current selected feature set .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
Following the same scheme , we iteratively add the feature that brings the highest increase of information content contained in current selected feature set .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
Following the same scheme , we iteratively add the feature that brings the highest increase of information content contained in current selected feature set .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
Following the same scheme , we iteratively add the feature that brings the highest increase of information content contained in current selected feature set .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
Following the same scheme , we iteratively add the feature that brings the highest increase of information content contained in current selected feature set .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
Following the same scheme , we iteratively add the feature that brings the highest increase of information content contained in current selected feature set .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
Following the same scheme , we iteratively add the feature that brings the highest increase of information content contained in current selected feature set .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
Following the same scheme , we iteratively add the feature that brings the highest increase of information content contained in current selected feature set .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
Following the same scheme , we iteratively add the feature that brings the highest increase of information content contained in current selected feature set .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
Following the same scheme , we iteratively add the feature that brings the highest increase of information content contained in current selected feature set .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
Following the same scheme , we iteratively add the feature that brings the highest increase of information content contained in current selected feature set .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
Following the same scheme , we iteratively add the feature that brings the highest increase of information content contained in current selected feature set .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
Following the same scheme , we iteratively add the feature that brings the highest increase of information content contained in current selected feature set .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
Following the same scheme , we iteratively add the feature that brings the highest increase of information content contained in current selected feature set .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
Following the same scheme , we iteratively add the feature that brings the highest increase of information content contained in current selected feature set .
#<struct ReadData::Alignment source_numbers="", target_numbers="40", tag_name="wa">
Following the same scheme , we iteratively add the feature that brings the highest increase of information content contained in current selected feature set .
#<struct ReadData::Alignment source_numbers="", target_numbers="41", tag_name="wa">
Following the same scheme , we iteratively add the feature that brings the highest increase of information content contained in current selected feature set .
#<struct ReadData::Alignment source_numbers="", target_numbers="42", tag_name="wa">
In order to simply estimate mutual information , the easiest way is features are discretized in binary values by specifying thresholds [8 , 7] .
#<struct ReadData::Alignment source_numbers="2", target_numbers="10", tag_name="wa">
In order to simply estimate mutual information , the easiest way is features are discretized in binary values by specifying thresholds [8 , 7] .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
In order to simply estimate mutual information , the easiest way is features are discretized in binary values by specifying thresholds [8 , 7] .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
In order to simply estimate mutual information , the easiest way is features are discretized in binary values by specifying thresholds [8 , 7] .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
In order to simply estimate mutual information , the easiest way is features are discretized in binary values by specifying thresholds [8 , 7] .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
However , for complex data , it is not efficient ; therefore , we use entropy-based method proposed by Fayyad and Irani [11] for discretization .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
However , for complex data , it is not efficient ; therefore , we use entropy-based method proposed by Fayyad and Irani [11] for discretization .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
However , for complex data , it is not efficient ; therefore , we use entropy-based method proposed by Fayyad and Irani [11] for discretization .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
This method is a supervised method , thus it is generic and can adapt very well to any kind of data distributions .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Basically , discretization is a quantizing process that converts continuous values into discrete values .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Basically , discretization is a quantizing process that converts continuous values into discrete values .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Basically , discretization is a quantizing process that converts continuous values into discrete values .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Basically , discretization is a quantizing process that converts continuous values into discrete values .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Basically , discretization is a quantizing process that converts continuous values into discrete values .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Suppose that we are given a set of instances S , a feature A and a cut-point T ( a cutpoint is a threshold value that divides the range of continuous values into two intervals ; one interval is less than or equal to the threshold , and the other interval is greater than the threshold ) .
#<struct ReadData::Alignment source_numbers="46", target_numbers="14", tag_name="wa">
Suppose that we are given a set of instances S , a feature A and a cut-point T ( a cutpoint is a threshold value that divides the range of continuous values into two intervals ; one interval is less than or equal to the threshold , and the other interval is greater than the threshold ) .
#<struct ReadData::Alignment source_numbers="57", target_numbers="19", tag_name="wa">
Suppose that we are given a set of instances S , a feature A and a cut-point T ( a cutpoint is a threshold value that divides the range of continuous values into two intervals ; one interval is less than or equal to the threshold , and the other interval is greater than the threshold ) .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
Suppose that we are given a set of instances S , a feature A and a cut-point T ( a cutpoint is a threshold value that divides the range of continuous values into two intervals ; one interval is less than or equal to the threshold , and the other interval is greater than the threshold ) .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
Suppose that we are given a set of instances S , a feature A and a cut-point T ( a cutpoint is a threshold value that divides the range of continuous values into two intervals ; one interval is less than or equal to the threshold , and the other interval is greater than the threshold ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
Suppose that we are given a set of instances S , a feature A and a cut-point T ( a cutpoint is a threshold value that divides the range of continuous values into two intervals ; one interval is less than or equal to the threshold , and the other interval is greater than the threshold ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
Suppose that we are given a set of instances S , a feature A and a cut-point T ( a cutpoint is a threshold value that divides the range of continuous values into two intervals ; one interval is less than or equal to the threshold , and the other interval is greater than the threshold ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="48", tag_name="wa">
Suppose that we are given a set of instances S , a feature A and a cut-point T ( a cutpoint is a threshold value that divides the range of continuous values into two intervals ; one interval is less than or equal to the threshold , and the other interval is greater than the threshold ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="58", tag_name="wa">
Suppose that we are given a set of instances S , a feature A and a cut-point T ( a cutpoint is a threshold value that divides the range of continuous values into two intervals ; one interval is less than or equal to the threshold , and the other interval is greater than the threshold ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="60", tag_name="wa">
Among candidate cut-points , the best candidate cut-point Tmin which minimizes the entropy function \MATH is selected to split \MATH into two partitions \MATH and \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Among candidate cut-points , the best candidate cut-point Tmin which minimizes the entropy function \MATH is selected to split \MATH into two partitions \MATH and \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
This process can then be repeated recursively to \MATH and \MATH until some stopping condition is satisfied , thus creating multiple intervals on the feature \MATH .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
This process can then be repeated recursively to \MATH and \MATH until some stopping condition is satisfied , thus creating multiple intervals on the feature \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Using MDLP , the stopping criteria is proposed by Fayyad and Irani [11] as follows :
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
MDLP Criteria : A partition induced by cut-point T for a set S of N examples is accepted if : \MATH Where \MATH ,where \MATH , \MATH , \MATH is the number of classes in \MATH , \MATH , \MATH .
#<struct ReadData::Alignment source_numbers="40", target_numbers="45", tag_name="wa">
MDLP Criteria : A partition induced by cut-point T for a set S of N examples is accepted if : \MATH Where \MATH ,where \MATH , \MATH , \MATH is the number of classes in \MATH , \MATH , \MATH .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
MDLP Criteria : A partition induced by cut-point T for a set S of N examples is accepted if : \MATH Where \MATH ,where \MATH , \MATH , \MATH is the number of classes in \MATH , \MATH , \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
MDLP Criteria : A partition induced by cut-point T for a set S of N examples is accepted if : \MATH Where \MATH ,where \MATH , \MATH , \MATH is the number of classes in \MATH , \MATH , \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
MDLP Criteria : A partition induced by cut-point T for a set S of N examples is accepted if : \MATH Where \MATH ,where \MATH , \MATH , \MATH is the number of classes in \MATH , \MATH , \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
MDLP Criteria : A partition induced by cut-point T for a set S of N examples is accepted if : \MATH Where \MATH ,where \MATH , \MATH , \MATH is the number of classes in \MATH , \MATH , \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="41", tag_name="wa">
MDLP Criteria : A partition induced by cut-point T for a set S of N examples is accepted if : \MATH Where \MATH ,where \MATH , \MATH , \MATH is the number of classes in \MATH , \MATH , \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="43", tag_name="wa">
MDLP Criteria : A partition induced by cut-point T for a set S of N examples is accepted if : \MATH Where \MATH ,where \MATH , \MATH , \MATH is the number of classes in \MATH , \MATH , \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="44", tag_name="wa">
Extensive experiments [11 , 14] have shown that this method is one of the best variable discretization one because it gives small number of cut-points while maintaining consistency .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
Another set of 10 ,000 complex non-face patterns were false positives collected by running a face detector based on a cascade of 17 AdaBoost classifiers at different locations and scales on 8 ,440 images with various subjects , such as rocks , trees , buildings , scenery , and flowers , containing no faces .
#<struct ReadData::Alignment source_numbers="51", target_numbers="34,35", tag_name="wa">
Another set of 10 ,000 complex non-face patterns were false positives collected by running a face detector based on a cascade of 17 AdaBoost classifiers at different locations and scales on 8 ,440 images with various subjects , such as rocks , trees , buildings , scenery , and flowers , containing no faces .
#<struct ReadData::Alignment source_numbers="52", target_numbers="36", tag_name="wa">
Another set of 10 ,000 complex non-face patterns were false positives collected by running a face detector based on a cascade of 17 AdaBoost classifiers at different locations and scales on 8 ,440 images with various subjects , such as rocks , trees , buildings , scenery , and flowers , containing no faces .
#<struct ReadData::Alignment source_numbers="53", target_numbers="37", tag_name="wa">
Another set of 10 ,000 complex non-face patterns were false positives collected by running a face detector based on a cascade of 17 AdaBoost classifiers at different locations and scales on 8 ,440 images with various subjects , such as rocks , trees , buildings , scenery , and flowers , containing no faces .
#<struct ReadData::Alignment source_numbers="34", target_numbers="41", tag_name="wa">
Another set of 10 ,000 complex non-face patterns were false positives collected by running a face detector based on a cascade of 17 AdaBoost classifiers at different locations and scales on 8 ,440 images with various subjects , such as rocks , trees , buildings , scenery , and flowers , containing no faces .
#<struct ReadData::Alignment source_numbers="37", target_numbers="45", tag_name="wa">
Another set of 10 ,000 complex non-face patterns were false positives collected by running a face detector based on a cascade of 17 AdaBoost classifiers at different locations and scales on 8 ,440 images with various subjects , such as rocks , trees , buildings , scenery , and flowers , containing no faces .
#<struct ReadData::Alignment source_numbers="41", target_numbers="49", tag_name="wa">
Another set of 10 ,000 complex non-face patterns were false positives collected by running a face detector based on a cascade of 17 AdaBoost classifiers at different locations and scales on 8 ,440 images with various subjects , such as rocks , trees , buildings , scenery , and flowers , containing no faces .
#<struct ReadData::Alignment source_numbers="43", target_numbers="51", tag_name="wa">
Another set of 10 ,000 complex non-face patterns were false positives collected by running a face detector based on a cascade of 17 AdaBoost classifiers at different locations and scales on 8 ,440 images with various subjects , such as rocks , trees , buildings , scenery , and flowers , containing no faces .
#<struct ReadData::Alignment source_numbers="45", target_numbers="53", tag_name="wa">
Another set of 10 ,000 complex non-face patterns were false positives collected by running a face detector based on a cascade of 17 AdaBoost classifiers at different locations and scales on 8 ,440 images with various subjects , such as rocks , trees , buildings , scenery , and flowers , containing no faces .
#<struct ReadData::Alignment source_numbers="47", target_numbers="55", tag_name="wa">
Another set of 10 ,000 complex non-face patterns were false positives collected by running a face detector based on a cascade of 17 AdaBoost classifiers at different locations and scales on 8 ,440 images with various subjects , such as rocks , trees , buildings , scenery , and flowers , containing no faces .
#<struct ReadData::Alignment source_numbers="50", target_numbers="58", tag_name="wa">
Another set of 10 ,000 complex non-face patterns were false positives collected by running a face detector based on a cascade of 17 AdaBoost classifiers at different locations and scales on 8 ,440 images with various subjects , such as rocks , trees , buildings , scenery , and flowers , containing no faces .
#<struct ReadData::Alignment source_numbers="54", target_numbers="62", tag_name="wa">
Another set of 10 ,000 complex non-face patterns were false positives collected by running a face detector based on a cascade of 17 AdaBoost classifiers at different locations and scales on 8 ,440 images with various subjects , such as rocks , trees , buildings , scenery , and flowers , containing no faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
Another set of 10 ,000 complex non-face patterns were false positives collected by running a face detector based on a cascade of 17 AdaBoost classifiers at different locations and scales on 8 ,440 images with various subjects , such as rocks , trees , buildings , scenery , and flowers , containing no faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
Another set of 10 ,000 complex non-face patterns were false positives collected by running a face detector based on a cascade of 17 AdaBoost classifiers at different locations and scales on 8 ,440 images with various subjects , such as rocks , trees , buildings , scenery , and flowers , containing no faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="40", tag_name="wa">
Another set of 10 ,000 complex non-face patterns were false positives collected by running a face detector based on a cascade of 17 AdaBoost classifiers at different locations and scales on 8 ,440 images with various subjects , such as rocks , trees , buildings , scenery , and flowers , containing no faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="42", tag_name="wa">
Another set of 10 ,000 complex non-face patterns were false positives collected by running a face detector based on a cascade of 17 AdaBoost classifiers at different locations and scales on 8 ,440 images with various subjects , such as rocks , trees , buildings , scenery , and flowers , containing no faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="59", tag_name="wa">
Another set of 10 ,000 complex non-face patterns were false positives collected by running a face detector based on a cascade of 17 AdaBoost classifiers at different locations and scales on 8 ,440 images with various subjects , such as rocks , trees , buildings , scenery , and flowers , containing no faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="60", tag_name="wa">
Another set of 10 ,000 complex non-face patterns were false positives collected by running a face detector based on a cascade of 17 AdaBoost classifiers at different locations and scales on 8 ,440 images with various subjects , such as rocks , trees , buildings , scenery , and flowers , containing no faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="61", tag_name="wa">
Two types of features that are Haar wavelet feature and Gabor wavelet feature were used in experiments .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
Two types of features that are Haar wavelet feature and Gabor wavelet feature were used in experiments .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Two types of features that are Haar wavelet feature and Gabor wavelet feature were used in experiments .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
It consists of four kinds of features modeled from adjacent basic rectangles with the same size and shape .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
It consists of four kinds of features modeled from adjacent basic rectangles with the same size and shape .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
It consists of four kinds of features modeled from adjacent basic rectangles with the same size and shape .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
It consists of four kinds of features modeled from adjacent basic rectangles with the same size and shape .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
It consists of four kinds of features modeled from adjacent basic rectangles with the same size and shape .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
It consists of four kinds of features modeled from adjacent basic rectangles with the same size and shape .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
It consists of four kinds of features modeled from adjacent basic rectangles with the same size and shape .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
It consists of four kinds of features modeled from adjacent basic rectangles with the same size and shape .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
It consists of four kinds of features modeled from adjacent basic rectangles with the same size and shape .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
It consists of four kinds of features modeled from adjacent basic rectangles with the same size and shape .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
It consists of four kinds of features modeled from adjacent basic rectangles with the same size and shape .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
It consists of four kinds of features modeled from adjacent basic rectangles with the same size and shape .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
It consists of four kinds of features modeled from adjacent basic rectangles with the same size and shape .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
It consists of four kinds of features modeled from adjacent basic rectangles with the same size and shape .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
It consists of four kinds of features modeled from adjacent basic rectangles with the same size and shape .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
It consists of four kinds of features modeled from adjacent basic rectangles with the same size and shape .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
It consists of four kinds of features modeled from adjacent basic rectangles with the same size and shape .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
It consists of four kinds of features modeled from adjacent basic rectangles with the same size and shape .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
It consists of four kinds of features modeled from adjacent basic rectangles with the same size and shape .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
It consists of four kinds of features modeled from adjacent basic rectangles with the same size and shape .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
It consists of four kinds of features modeled from adjacent basic rectangles with the same size and shape .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
It consists of four kinds of features modeled from adjacent basic rectangles with the same size and shape .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
It consists of four kinds of features modeled from adjacent basic rectangles with the same size and shape .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
It consists of four kinds of features modeled from adjacent basic rectangles with the same size and shape .
#<struct ReadData::Alignment source_numbers="", target_numbers="40", tag_name="wa">
It consists of four kinds of features modeled from adjacent basic rectangles with the same size and shape .
#<struct ReadData::Alignment source_numbers="", target_numbers="41", tag_name="wa">
It consists of four kinds of features modeled from adjacent basic rectangles with the same size and shape .
#<struct ReadData::Alignment source_numbers="", target_numbers="42", tag_name="wa">
It consists of four kinds of features modeled from adjacent basic rectangles with the same size and shape .
#<struct ReadData::Alignment source_numbers="", target_numbers="43", tag_name="wa">
It consists of four kinds of features modeled from adjacent basic rectangles with the same size and shape .
#<struct ReadData::Alignment source_numbers="", target_numbers="44", tag_name="wa">
It consists of four kinds of features modeled from adjacent basic rectangles with the same size and shape .
#<struct ReadData::Alignment source_numbers="", target_numbers="45", tag_name="wa">
It consists of four kinds of features modeled from adjacent basic rectangles with the same size and shape .
#<struct ReadData::Alignment source_numbers="", target_numbers="46", tag_name="wa">
It consists of four kinds of features modeled from adjacent basic rectangles with the same size and shape .
#<struct ReadData::Alignment source_numbers="", target_numbers="47", tag_name="wa">
It consists of four kinds of features modeled from adjacent basic rectangles with the same size and shape .
#<struct ReadData::Alignment source_numbers="", target_numbers="48", tag_name="wa">
It consists of four kinds of features modeled from adjacent basic rectangles with the same size and shape .
#<struct ReadData::Alignment source_numbers="", target_numbers="49", tag_name="wa">
It consists of four kinds of features modeled from adjacent basic rectangles with the same size and shape .
#<struct ReadData::Alignment source_numbers="", target_numbers="50", tag_name="wa">
It consists of four kinds of features modeled from adjacent basic rectangles with the same size and shape .
#<struct ReadData::Alignment source_numbers="", target_numbers="51", tag_name="wa">
It consists of four kinds of features modeled from adjacent basic rectangles with the same size and shape .
#<struct ReadData::Alignment source_numbers="", target_numbers="52", tag_name="wa">
It consists of four kinds of features modeled from adjacent basic rectangles with the same size and shape .
#<struct ReadData::Alignment source_numbers="", target_numbers="53", tag_name="wa">
It consists of four kinds of features modeled from adjacent basic rectangles with the same size and shape .
#<struct ReadData::Alignment source_numbers="", target_numbers="54", tag_name="wa">
It consists of four kinds of features modeled from adjacent basic rectangles with the same size and shape .
#<struct ReadData::Alignment source_numbers="", target_numbers="55", tag_name="wa">
It consists of four kinds of features modeled from adjacent basic rectangles with the same size and shape .
#<struct ReadData::Alignment source_numbers="", target_numbers="56", tag_name="wa">
Gabor wavelet features have also often been used in face recognition systems [12] and are defined as : \MATH where \MATH and \MATH define the orientation and scale of the Gabor kernels respectively , \MATH , and the wave vector \MATH , is defined as : \MATH where \MATH , \MATH \MATH .
#<struct ReadData::Alignment source_numbers="49", target_numbers="20", tag_name="wa">
Gabor wavelet features have also often been used in face recognition systems [12] and are defined as : \MATH where \MATH and \MATH define the orientation and scale of the Gabor kernels respectively , \MATH , and the wave vector \MATH , is defined as : \MATH where \MATH , \MATH \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Gabor wavelet features have also often been used in face recognition systems [12] and are defined as : \MATH where \MATH and \MATH define the orientation and scale of the Gabor kernels respectively , \MATH , and the wave vector \MATH , is defined as : \MATH where \MATH , \MATH \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="51", tag_name="wa">
Gabor wavelet features have also often been used in face recognition systems [12] and are defined as : \MATH where \MATH and \MATH define the orientation and scale of the Gabor kernels respectively , \MATH , and the wave vector \MATH , is defined as : \MATH where \MATH , \MATH \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="53", tag_name="wa">
Let \MATH be the face image , its convolution with a Gabor filter �� ,_( z ) is defined as : \MATH where \MATH denotes the convolution operator .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Similar to [12] , Gabor kernels at five scales \MATH and eight orientations \MATH were used .
#<struct ReadData::Alignment source_numbers="16", target_numbers="20", tag_name="wa">
Similar to [12] , Gabor kernels at five scales \MATH and eight orientations \MATH were used .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Similar to [12] , Gabor kernels at five scales \MATH and eight orientations \MATH were used .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
Similar to [12] , Gabor kernels at five scales \MATH and eight orientations \MATH were used .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
Similar to [12] , Gabor kernels at five scales \MATH and eight orientations \MATH were used .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
As a result , \MATH there are \MATH Gabor features for one 24x24 training sample .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
As a result , \MATH there are \MATH Gabor features for one 24x24 training sample .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
As a result , \MATH there are \MATH Gabor features for one 24x24 training sample .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
As a result , \MATH there are \MATH Gabor features for one 24x24 training sample .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
As a result , \MATH there are \MATH Gabor features for one 24x24 training sample .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
In order to show effectiveness of the proposed feature selection method ( CMI-Multi ) , we compared it with two other feature selection methods that are forward feature selection ( FFS ) [16] and CMI-basedmethod using binary features ( CMIBinary ) [8 , 7] on the data set and feature setsmentioned above .
#<struct ReadData::Alignment source_numbers="45", target_numbers="2", tag_name="wa">
In order to show effectiveness of the proposed feature selection method ( CMI-Multi ) , we compared it with two other feature selection methods that are forward feature selection ( FFS ) [16] and CMI-basedmethod using binary features ( CMIBinary ) [8 , 7] on the data set and feature setsmentioned above .
#<struct ReadData::Alignment source_numbers="51", target_numbers="55", tag_name="wa">
In order to show effectiveness of the proposed feature selection method ( CMI-Multi ) , we compared it with two other feature selection methods that are forward feature selection ( FFS ) [16] and CMI-basedmethod using binary features ( CMIBinary ) [8 , 7] on the data set and feature setsmentioned above .
#<struct ReadData::Alignment source_numbers="52", target_numbers="56", tag_name="wa">
In order to show effectiveness of the proposed feature selection method ( CMI-Multi ) , we compared it with two other feature selection methods that are forward feature selection ( FFS ) [16] and CMI-basedmethod using binary features ( CMIBinary ) [8 , 7] on the data set and feature setsmentioned above .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
In order to show effectiveness of the proposed feature selection method ( CMI-Multi ) , we compared it with two other feature selection methods that are forward feature selection ( FFS ) [16] and CMI-basedmethod using binary features ( CMIBinary ) [8 , 7] on the data set and feature setsmentioned above .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
In order to show effectiveness of the proposed feature selection method ( CMI-Multi ) , we compared it with two other feature selection methods that are forward feature selection ( FFS ) [16] and CMI-basedmethod using binary features ( CMIBinary ) [8 , 7] on the data set and feature setsmentioned above .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
In order to show effectiveness of the proposed feature selection method ( CMI-Multi ) , we compared it with two other feature selection methods that are forward feature selection ( FFS ) [16] and CMI-basedmethod using binary features ( CMIBinary ) [8 , 7] on the data set and feature setsmentioned above .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
In order to show effectiveness of the proposed feature selection method ( CMI-Multi ) , we compared it with two other feature selection methods that are forward feature selection ( FFS ) [16] and CMI-basedmethod using binary features ( CMIBinary ) [8 , 7] on the data set and feature setsmentioned above .
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
In order to show effectiveness of the proposed feature selection method ( CMI-Multi ) , we compared it with two other feature selection methods that are forward feature selection ( FFS ) [16] and CMI-basedmethod using binary features ( CMIBinary ) [8 , 7] on the data set and feature setsmentioned above .
#<struct ReadData::Alignment source_numbers="34", target_numbers="", tag_name="wa">
In order to show effectiveness of the proposed feature selection method ( CMI-Multi ) , we compared it with two other feature selection methods that are forward feature selection ( FFS ) [16] and CMI-basedmethod using binary features ( CMIBinary ) [8 , 7] on the data set and feature setsmentioned above .
#<struct ReadData::Alignment source_numbers="39", target_numbers="", tag_name="wa">
In order to show effectiveness of the proposed feature selection method ( CMI-Multi ) , we compared it with two other feature selection methods that are forward feature selection ( FFS ) [16] and CMI-basedmethod using binary features ( CMIBinary ) [8 , 7] on the data set and feature setsmentioned above .
#<struct ReadData::Alignment source_numbers="50", target_numbers="", tag_name="wa">
In order to show effectiveness of the proposed feature selection method ( CMI-Multi ) , we compared it with two other feature selection methods that are forward feature selection ( FFS ) [16] and CMI-basedmethod using binary features ( CMIBinary ) [8 , 7] on the data set and feature setsmentioned above .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
In order to show effectiveness of the proposed feature selection method ( CMI-Multi ) , we compared it with two other feature selection methods that are forward feature selection ( FFS ) [16] and CMI-basedmethod using binary features ( CMIBinary ) [8 , 7] on the data set and feature setsmentioned above .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
In order to show effectiveness of the proposed feature selection method ( CMI-Multi ) , we compared it with two other feature selection methods that are forward feature selection ( FFS ) [16] and CMI-basedmethod using binary features ( CMIBinary ) [8 , 7] on the data set and feature setsmentioned above .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
In order to show effectiveness of the proposed feature selection method ( CMI-Multi ) , we compared it with two other feature selection methods that are forward feature selection ( FFS ) [16] and CMI-basedmethod using binary features ( CMIBinary ) [8 , 7] on the data set and feature setsmentioned above .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
In order to show effectiveness of the proposed feature selection method ( CMI-Multi ) , we compared it with two other feature selection methods that are forward feature selection ( FFS ) [16] and CMI-basedmethod using binary features ( CMIBinary ) [8 , 7] on the data set and feature setsmentioned above .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
In order to show effectiveness of the proposed feature selection method ( CMI-Multi ) , we compared it with two other feature selection methods that are forward feature selection ( FFS ) [16] and CMI-basedmethod using binary features ( CMIBinary ) [8 , 7] on the data set and feature setsmentioned above .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
In order to show effectiveness of the proposed feature selection method ( CMI-Multi ) , we compared it with two other feature selection methods that are forward feature selection ( FFS ) [16] and CMI-basedmethod using binary features ( CMIBinary ) [8 , 7] on the data set and feature setsmentioned above .
#<struct ReadData::Alignment source_numbers="", target_numbers="40", tag_name="wa">
In order to show effectiveness of the proposed feature selection method ( CMI-Multi ) , we compared it with two other feature selection methods that are forward feature selection ( FFS ) [16] and CMI-basedmethod using binary features ( CMIBinary ) [8 , 7] on the data set and feature setsmentioned above .
#<struct ReadData::Alignment source_numbers="", target_numbers="45", tag_name="wa">
In order to show effectiveness of the proposed feature selection method ( CMI-Multi ) , we compared it with two other feature selection methods that are forward feature selection ( FFS ) [16] and CMI-basedmethod using binary features ( CMIBinary ) [8 , 7] on the data set and feature setsmentioned above .
#<struct ReadData::Alignment source_numbers="", target_numbers="47", tag_name="wa">
In order to show effectiveness of the proposed feature selection method ( CMI-Multi ) , we compared it with two other feature selection methods that are forward feature selection ( FFS ) [16] and CMI-basedmethod using binary features ( CMIBinary ) [8 , 7] on the data set and feature setsmentioned above .
#<struct ReadData::Alignment source_numbers="", target_numbers="52", tag_name="wa">
In order to show effectiveness of the proposed feature selection method ( CMI-Multi ) , we compared it with two other feature selection methods that are forward feature selection ( FFS ) [16] and CMI-basedmethod using binary features ( CMIBinary ) [8 , 7] on the data set and feature setsmentioned above .
#<struct ReadData::Alignment source_numbers="", target_numbers="53", tag_name="wa">
In order to show effectiveness of the proposed feature selection method ( CMI-Multi ) , we compared it with two other feature selection methods that are forward feature selection ( FFS ) [16] and CMI-basedmethod using binary features ( CMIBinary ) [8 , 7] on the data set and feature setsmentioned above .
#<struct ReadData::Alignment source_numbers="", target_numbers="54", tag_name="wa">
We chose the forward feature selection proposed by Wu et. al. [16] because it has very impressive results when not only reducing significantly the training time of AdaBoost-based face detection system [1] ( about 100 times ) but also maintaining comparable performance .
#<struct ReadData::Alignment source_numbers="30", target_numbers="32", tag_name="wa">
We chose the forward feature selection proposed by Wu et. al. [16] because it has very impressive results when not only reducing significantly the training time of AdaBoost-based face detection system [1] ( about 100 times ) but also maintaining comparable performance .
#<struct ReadData::Alignment source_numbers="36", target_numbers="40", tag_name="wa">
We chose the forward feature selection proposed by Wu et. al. [16] because it has very impressive results when not only reducing significantly the training time of AdaBoost-based face detection system [1] ( about 100 times ) but also maintaining comparable performance .
#<struct ReadData::Alignment source_numbers="37", target_numbers="41", tag_name="wa">
We chose the forward feature selection proposed by Wu et. al. [16] because it has very impressive results when not only reducing significantly the training time of AdaBoost-based face detection system [1] ( about 100 times ) but also maintaining comparable performance .
#<struct ReadData::Alignment source_numbers="38", target_numbers="42", tag_name="wa">
We chose the forward feature selection proposed by Wu et. al. [16] because it has very impressive results when not only reducing significantly the training time of AdaBoost-based face detection system [1] ( about 100 times ) but also maintaining comparable performance .
#<struct ReadData::Alignment source_numbers="39", target_numbers="43", tag_name="wa">
We chose the forward feature selection proposed by Wu et. al. [16] because it has very impressive results when not only reducing significantly the training time of AdaBoost-based face detection system [1] ( about 100 times ) but also maintaining comparable performance .
#<struct ReadData::Alignment source_numbers="40", target_numbers="44", tag_name="wa">
We chose the forward feature selection proposed by Wu et. al. [16] because it has very impressive results when not only reducing significantly the training time of AdaBoost-based face detection system [1] ( about 100 times ) but also maintaining comparable performance .
#<struct ReadData::Alignment source_numbers="41", target_numbers="45", tag_name="wa">
We chose the forward feature selection proposed by Wu et. al. [16] because it has very impressive results when not only reducing significantly the training time of AdaBoost-based face detection system [1] ( about 100 times ) but also maintaining comparable performance .
#<struct ReadData::Alignment source_numbers="42", target_numbers="46", tag_name="wa">
We chose the forward feature selection proposed by Wu et. al. [16] because it has very impressive results when not only reducing significantly the training time of AdaBoost-based face detection system [1] ( about 100 times ) but also maintaining comparable performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
We chose the forward feature selection proposed by Wu et. al. [16] because it has very impressive results when not only reducing significantly the training time of AdaBoost-based face detection system [1] ( about 100 times ) but also maintaining comparable performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
We chose the forward feature selection proposed by Wu et. al. [16] because it has very impressive results when not only reducing significantly the training time of AdaBoost-based face detection system [1] ( about 100 times ) but also maintaining comparable performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
We chose the forward feature selection proposed by Wu et. al. [16] because it has very impressive results when not only reducing significantly the training time of AdaBoost-based face detection system [1] ( about 100 times ) but also maintaining comparable performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
It indicates that , the proposed method CMI-Multi outperforms the others while FFS and CMI-Binary have comparable performance .
#<struct ReadData::Alignment source_numbers="15", target_numbers="21", tag_name="wa">
It indicates that , the proposed method CMI-Multi outperforms the others while FFS and CMI-Binary have comparable performance .
#<struct ReadData::Alignment source_numbers="18", target_numbers="27", tag_name="wa">
It indicates that , the proposed method CMI-Multi outperforms the others while FFS and CMI-Binary have comparable performance .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
It indicates that , the proposed method CMI-Multi outperforms the others while FFS and CMI-Binary have comparable performance .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
It indicates that , the proposed method CMI-Multi outperforms the others while FFS and CMI-Binary have comparable performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
It indicates that , the proposed method CMI-Multi outperforms the others while FFS and CMI-Binary have comparable performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
It indicates that , the proposed method CMI-Multi outperforms the others while FFS and CMI-Binary have comparable performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
It indicates that , the proposed method CMI-Multi outperforms the others while FFS and CMI-Binary have comparable performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
It indicates that , the proposed method CMI-Multi outperforms the others while FFS and CMI-Binary have comparable performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
It indicates that , the proposed method CMI-Multi outperforms the others while FFS and CMI-Binary have comparable performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
It indicates that , the proposed method CMI-Multi outperforms the others while FFS and CMI-Binary have comparable performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
It indicates that , the proposed method CMI-Multi outperforms the others while FFS and CMI-Binary have comparable performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
It indicates that , the proposed method CMI-Multi outperforms the others while FFS and CMI-Binary have comparable performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
It indicates that , the proposed method CMI-Multi outperforms the others while FFS and CMI-Binary have comparable performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
It indicates that , the proposed method CMI-Multi outperforms the others while FFS and CMI-Binary have comparable performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
The similar result is also shown when tested on Gabor wavelet features .
#<struct ReadData::Alignment source_numbers="7", target_numbers="15", tag_name="wa">
The similar result is also shown when tested on Gabor wavelet features .
#<struct ReadData::Alignment source_numbers="8", target_numbers="16", tag_name="wa">
The similar result is also shown when tested on Gabor wavelet features .
#<struct ReadData::Alignment source_numbers="12", target_numbers="20", tag_name="wa">
The similar result is also shown when tested on Gabor wavelet features .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
The similar result is also shown when tested on Gabor wavelet features .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
The similar result is also shown when tested on Gabor wavelet features .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
The similar result is also shown when tested on Gabor wavelet features .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
The similar result is also shown when tested on Gabor wavelet features .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
The similar result is also shown when tested on Gabor wavelet features .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
The similar result is also shown when tested on Gabor wavelet features .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
The similar result is also shown when tested on Gabor wavelet features .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
In this case , CMI-based feature selection methods obviously outperform FFS and CMI-Multi is confirmed to be more efficient than CMI-Binary .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
In this case , CMI-based feature selection methods obviously outperform FFS and CMI-Multi is confirmed to be more efficient than CMI-Binary .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
In this case , CMI-based feature selection methods obviously outperform FFS and CMI-Multi is confirmed to be more efficient than CMI-Binary .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
Because our proposed method uses same principle as FFS which only trains weak classifiers once , it is extremely fast compared with AdaBoost [1] .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Testing on the standard benchmark MIT+CMU test set , they have comparable performance .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Testing on the standard benchmark MIT+CMU test set , they have comparable performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
However , CMI-Multi is trained faster than AdaBoost approximately 70 times .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
However , CMI-Multi is trained faster than AdaBoost approximately 70 times .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
However , CMI-Multi is trained faster than AdaBoost approximately 70 times .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
However , CMI-Multi is trained faster than AdaBoost approximately 70 times .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
The estimation of mutual information is simplified by using MDLP based discretization method .
#<struct ReadData::Alignment source_numbers="10", target_numbers="11", tag_name="wa">
The estimation of mutual information is simplified by using MDLP based discretization method .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
The estimation of mutual information is simplified by using MDLP based discretization method .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Integrated into AdaBoost-based object detection systems , it can not only reduce the training time significantly but also achieve high classification performance .
#<struct ReadData::Alignment source_numbers="11", target_numbers="13", tag_name="wa">
Integrated into AdaBoost-based object detection systems , it can not only reduce the training time significantly but also achieve high classification performance .
#<struct ReadData::Alignment source_numbers="18", target_numbers="21", tag_name="wa">
Integrated into AdaBoost-based object detection systems , it can not only reduce the training time significantly but also achieve high classification performance .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Integrated into AdaBoost-based object detection systems , it can not only reduce the training time significantly but also achieve high classification performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Integrated into AdaBoost-based object detection systems , it can not only reduce the training time significantly but also achieve high classification performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Integrated into AdaBoost-based object detection systems , it can not only reduce the training time significantly but also achieve high classification performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Integrated into AdaBoost-based object detection systems , it can not only reduce the training time significantly but also achieve high classification performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
Experiments on two popular feature sets such as Haar wavelets and Gabor wavelets have demonstrated the effectiveness of the proposed method .
#<struct ReadData::Alignment source_numbers="21", target_numbers="14", tag_name="wa">
Experiments on two popular feature sets such as Haar wavelets and Gabor wavelets have demonstrated the effectiveness of the proposed method .
#<struct ReadData::Alignment source_numbers="6", target_numbers="32", tag_name="wa">
Experiments on two popular feature sets such as Haar wavelets and Gabor wavelets have demonstrated the effectiveness of the proposed method .
#<struct ReadData::Alignment source_numbers="7", target_numbers="33", tag_name="wa">
Experiments on two popular feature sets such as Haar wavelets and Gabor wavelets have demonstrated the effectiveness of the proposed method .
#<struct ReadData::Alignment source_numbers="8", target_numbers="34", tag_name="wa">
Experiments on two popular feature sets such as Haar wavelets and Gabor wavelets have demonstrated the effectiveness of the proposed method .
#<struct ReadData::Alignment source_numbers="9", target_numbers="35", tag_name="wa">
Experiments on two popular feature sets such as Haar wavelets and Gabor wavelets have demonstrated the effectiveness of the proposed method .
#<struct ReadData::Alignment source_numbers="10", target_numbers="36", tag_name="wa">
Experiments on two popular feature sets such as Haar wavelets and Gabor wavelets have demonstrated the effectiveness of the proposed method .
#<struct ReadData::Alignment source_numbers="11", target_numbers="41", tag_name="wa">
Experiments on two popular feature sets such as Haar wavelets and Gabor wavelets have demonstrated the effectiveness of the proposed method .
#<struct ReadData::Alignment source_numbers="12", target_numbers="42", tag_name="wa">
Experiments on two popular feature sets such as Haar wavelets and Gabor wavelets have demonstrated the effectiveness of the proposed method .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
Experiments on two popular feature sets such as Haar wavelets and Gabor wavelets have demonstrated the effectiveness of the proposed method .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
Experiments on two popular feature sets such as Haar wavelets and Gabor wavelets have demonstrated the effectiveness of the proposed method .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Experiments on two popular feature sets such as Haar wavelets and Gabor wavelets have demonstrated the effectiveness of the proposed method .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
Experiments on two popular feature sets such as Haar wavelets and Gabor wavelets have demonstrated the effectiveness of the proposed method .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
Experiments on two popular feature sets such as Haar wavelets and Gabor wavelets have demonstrated the effectiveness of the proposed method .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
Experiments on two popular feature sets such as Haar wavelets and Gabor wavelets have demonstrated the effectiveness of the proposed method .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
Experiments on two popular feature sets such as Haar wavelets and Gabor wavelets have demonstrated the effectiveness of the proposed method .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
Experiments on two popular feature sets such as Haar wavelets and Gabor wavelets have demonstrated the effectiveness of the proposed method .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
Experiments on two popular feature sets such as Haar wavelets and Gabor wavelets have demonstrated the effectiveness of the proposed method .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
Experiments on two popular feature sets such as Haar wavelets and Gabor wavelets have demonstrated the effectiveness of the proposed method .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
Experiments on two popular feature sets such as Haar wavelets and Gabor wavelets have demonstrated the effectiveness of the proposed method .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
Experiments on two popular feature sets such as Haar wavelets and Gabor wavelets have demonstrated the effectiveness of the proposed method .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
Experiments on two popular feature sets such as Haar wavelets and Gabor wavelets have demonstrated the effectiveness of the proposed method .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
Experiments on two popular feature sets such as Haar wavelets and Gabor wavelets have demonstrated the effectiveness of the proposed method .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
Experiments on two popular feature sets such as Haar wavelets and Gabor wavelets have demonstrated the effectiveness of the proposed method .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
Experiments on two popular feature sets such as Haar wavelets and Gabor wavelets have demonstrated the effectiveness of the proposed method .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
Experiments on two popular feature sets such as Haar wavelets and Gabor wavelets have demonstrated the effectiveness of the proposed method .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
Experiments on two popular feature sets such as Haar wavelets and Gabor wavelets have demonstrated the effectiveness of the proposed method .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
Experiments on two popular feature sets such as Haar wavelets and Gabor wavelets have demonstrated the effectiveness of the proposed method .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
Experiments on two popular feature sets such as Haar wavelets and Gabor wavelets have demonstrated the effectiveness of the proposed method .
#<struct ReadData::Alignment source_numbers="", target_numbers="40", tag_name="wa">
Experiments on two popular feature sets such as Haar wavelets and Gabor wavelets have demonstrated the effectiveness of the proposed method .
#<struct ReadData::Alignment source_numbers="", target_numbers="43", tag_name="wa">
Experiments on two popular feature sets such as Haar wavelets and Gabor wavelets have demonstrated the effectiveness of the proposed method .
#<struct ReadData::Alignment source_numbers="", target_numbers="44", tag_name="wa">
Experiments on two popular feature sets such as Haar wavelets and Gabor wavelets have demonstrated the effectiveness of the proposed method .
#<struct ReadData::Alignment source_numbers="", target_numbers="45", tag_name="wa">
Experiments on two popular feature sets such as Haar wavelets and Gabor wavelets have demonstrated the effectiveness of the proposed method .
#<struct ReadData::Alignment source_numbers="", target_numbers="46", tag_name="wa">
Experiments on two popular feature sets such as Haar wavelets and Gabor wavelets have demonstrated the effectiveness of the proposed method .
#<struct ReadData::Alignment source_numbers="", target_numbers="47", tag_name="wa">
Experiments on two popular feature sets such as Haar wavelets and Gabor wavelets have demonstrated the effectiveness of the proposed method .
#<struct ReadData::Alignment source_numbers="", target_numbers="48", tag_name="wa">
Experiments on two popular feature sets such as Haar wavelets and Gabor wavelets have demonstrated the effectiveness of the proposed method .
#<struct ReadData::Alignment source_numbers="", target_numbers="49", tag_name="wa">
Experiments on two popular feature sets such as Haar wavelets and Gabor wavelets have demonstrated the effectiveness of the proposed method .
#<struct ReadData::Alignment source_numbers="", target_numbers="50", tag_name="wa">
A multi-stage approach --- which is fast , robust and easy to train --- for a face-detection system is proposed .
#<struct ReadData::Alignment source_numbers="4,5", target_numbers="3,4", tag_name="wa">
A multi-stage approach --- which is fast , robust and easy to train --- for a face-detection system is proposed .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
A multi-stage approach --- which is fast , robust and easy to train --- for a face-detection system is proposed .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
A multi-stage approach --- which is fast , robust and easy to train --- for a face-detection system is proposed .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
However , it is distinguished from previous work by two features .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
However , it is distinguished from previous work by two features .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
However , it is distinguished from previous work by two features .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
However , it is distinguished from previous work by two features .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
However , it is distinguished from previous work by two features .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
First , a new stage is added to detect face candidate regions more quickly by using a larger window size and larger moving step size .
#<struct ReadData::Alignment source_numbers="5", target_numbers="5,6", tag_name="wa">
First , a new stage is added to detect face candidate regions more quickly by using a larger window size and larger moving step size .
#<struct ReadData::Alignment source_numbers="6", target_numbers="7", tag_name="wa">
Second , SVM classifiers are used instead of AdaBoost classifiers in the last stage , and Haar wavelet features selected by the previous stage are reused for the SVM classifier robustly and efficiently .
#<struct ReadData::Alignment source_numbers="2", target_numbers="6", tag_name="wa">
Second , SVM classifiers are used instead of AdaBoost classifiers in the last stage , and Haar wavelet features selected by the previous stage are reused for the SVM classifier robustly and efficiently .
#<struct ReadData::Alignment source_numbers="14", target_numbers="19", tag_name="wa">
Second , SVM classifiers are used instead of AdaBoost classifiers in the last stage , and Haar wavelet features selected by the previous stage are reused for the SVM classifier robustly and efficiently .
#<struct ReadData::Alignment source_numbers="33", target_numbers="38", tag_name="wa">
Second , SVM classifiers are used instead of AdaBoost classifiers in the last stage , and Haar wavelet features selected by the previous stage are reused for the SVM classifier robustly and efficiently .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Second , SVM classifiers are used instead of AdaBoost classifiers in the last stage , and Haar wavelet features selected by the previous stage are reused for the SVM classifier robustly and efficiently .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Second , SVM classifiers are used instead of AdaBoost classifiers in the last stage , and Haar wavelet features selected by the previous stage are reused for the SVM classifier robustly and efficiently .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Second , SVM classifiers are used instead of AdaBoost classifiers in the last stage , and Haar wavelet features selected by the previous stage are reused for the SVM classifier robustly and efficiently .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Second , SVM classifiers are used instead of AdaBoost classifiers in the last stage , and Haar wavelet features selected by the previous stage are reused for the SVM classifier robustly and efficiently .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
The proposed multi-stage-based system is shown to run faster than the original AdaBoost-based system while maintaining comparable accuracy .
#<struct ReadData::Alignment source_numbers="4", target_numbers="4,5", tag_name="wa">
The proposed multi-stage-based system is shown to run faster than the original AdaBoost-based system while maintaining comparable accuracy .
#<struct ReadData::Alignment source_numbers="5", target_numbers="6", tag_name="wa">
For example , face detection is combined with other modules to identify who a person in a video sequence is [2] .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
For example , face detection is combined with other modules to identify who a person in a video sequence is [2] .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
Although it has been studied for more than 30 years , developing a fast and robust face detection system that can handle the variations found in different faces in real applications , such as facial expressions , pose changes , illumination changes , complex backgrounds , and low resolutions , is still a challenging research target [4] .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Although it has been studied for more than 30 years , developing a fast and robust face detection system that can handle the variations found in different faces in real applications , such as facial expressions , pose changes , illumination changes , complex backgrounds , and low resolutions , is still a challenging research target [4] .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Although it has been studied for more than 30 years , developing a fast and robust face detection system that can handle the variations found in different faces in real applications , such as facial expressions , pose changes , illumination changes , complex backgrounds , and low resolutions , is still a challenging research target [4] .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Recently , with advances in machine learning research , Neural Network [5] ,[6] , Support Vector Machines ( SVM ) [7] ,[8] ,[9] and AdaBoost [1] ,[10] ,[11] ,[12] ,[13] are typical choices for building robust face detectors .
#<struct ReadData::Alignment source_numbers="38", target_numbers="45", tag_name="wa">
Recently , with advances in machine learning research , Neural Network [5] ,[6] , Support Vector Machines ( SVM ) [7] ,[8] ,[9] and AdaBoost [1] ,[10] ,[11] ,[12] ,[13] are typical choices for building robust face detectors .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Recently , with advances in machine learning research , Neural Network [5] ,[6] , Support Vector Machines ( SVM ) [7] ,[8] ,[9] and AdaBoost [1] ,[10] ,[11] ,[12] ,[13] are typical choices for building robust face detectors .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Recently , with advances in machine learning research , Neural Network [5] ,[6] , Support Vector Machines ( SVM ) [7] ,[8] ,[9] and AdaBoost [1] ,[10] ,[11] ,[12] ,[13] are typical choices for building robust face detectors .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
Recently , with advances in machine learning research , Neural Network [5] ,[6] , Support Vector Machines ( SVM ) [7] ,[8] ,[9] and AdaBoost [1] ,[10] ,[11] ,[12] ,[13] are typical choices for building robust face detectors .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
Recently , with advances in machine learning research , Neural Network [5] ,[6] , Support Vector Machines ( SVM ) [7] ,[8] ,[9] and AdaBoost [1] ,[10] ,[11] ,[12] ,[13] are typical choices for building robust face detectors .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
Recently , with advances in machine learning research , Neural Network [5] ,[6] , Support Vector Machines ( SVM ) [7] ,[8] ,[9] and AdaBoost [1] ,[10] ,[11] ,[12] ,[13] are typical choices for building robust face detectors .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
Recently , with advances in machine learning research , Neural Network [5] ,[6] , Support Vector Machines ( SVM ) [7] ,[8] ,[9] and AdaBoost [1] ,[10] ,[11] ,[12] ,[13] are typical choices for building robust face detectors .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
Recently , with advances in machine learning research , Neural Network [5] ,[6] , Support Vector Machines ( SVM ) [7] ,[8] ,[9] and AdaBoost [1] ,[10] ,[11] ,[12] ,[13] are typical choices for building robust face detectors .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
Recently , with advances in machine learning research , Neural Network [5] ,[6] , Support Vector Machines ( SVM ) [7] ,[8] ,[9] and AdaBoost [1] ,[10] ,[11] ,[12] ,[13] are typical choices for building robust face detectors .
#<struct ReadData::Alignment source_numbers="26", target_numbers="", tag_name="wa">
Recently , with advances in machine learning research , Neural Network [5] ,[6] , Support Vector Machines ( SVM ) [7] ,[8] ,[9] and AdaBoost [1] ,[10] ,[11] ,[12] ,[13] are typical choices for building robust face detectors .
#<struct ReadData::Alignment source_numbers="27", target_numbers="", tag_name="wa">
Recently , with advances in machine learning research , Neural Network [5] ,[6] , Support Vector Machines ( SVM ) [7] ,[8] ,[9] and AdaBoost [1] ,[10] ,[11] ,[12] ,[13] are typical choices for building robust face detectors .
#<struct ReadData::Alignment source_numbers="28", target_numbers="", tag_name="wa">
Recently , with advances in machine learning research , Neural Network [5] ,[6] , Support Vector Machines ( SVM ) [7] ,[8] ,[9] and AdaBoost [1] ,[10] ,[11] ,[12] ,[13] are typical choices for building robust face detectors .
#<struct ReadData::Alignment source_numbers="29", target_numbers="", tag_name="wa">
Recently , with advances in machine learning research , Neural Network [5] ,[6] , Support Vector Machines ( SVM ) [7] ,[8] ,[9] and AdaBoost [1] ,[10] ,[11] ,[12] ,[13] are typical choices for building robust face detectors .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Recently , with advances in machine learning research , Neural Network [5] ,[6] , Support Vector Machines ( SVM ) [7] ,[8] ,[9] and AdaBoost [1] ,[10] ,[11] ,[12] ,[13] are typical choices for building robust face detectors .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Recently , with advances in machine learning research , Neural Network [5] ,[6] , Support Vector Machines ( SVM ) [7] ,[8] ,[9] and AdaBoost [1] ,[10] ,[11] ,[12] ,[13] are typical choices for building robust face detectors .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Recently , with advances in machine learning research , Neural Network [5] ,[6] , Support Vector Machines ( SVM ) [7] ,[8] ,[9] and AdaBoost [1] ,[10] ,[11] ,[12] ,[13] are typical choices for building robust face detectors .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Recently , with advances in machine learning research , Neural Network [5] ,[6] , Support Vector Machines ( SVM ) [7] ,[8] ,[9] and AdaBoost [1] ,[10] ,[11] ,[12] ,[13] are typical choices for building robust face detectors .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
Recently , with advances in machine learning research , Neural Network [5] ,[6] , Support Vector Machines ( SVM ) [7] ,[8] ,[9] and AdaBoost [1] ,[10] ,[11] ,[12] ,[13] are typical choices for building robust face detectors .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
Recently , with advances in machine learning research , Neural Network [5] ,[6] , Support Vector Machines ( SVM ) [7] ,[8] ,[9] and AdaBoost [1] ,[10] ,[11] ,[12] ,[13] are typical choices for building robust face detectors .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Recently , with advances in machine learning research , Neural Network [5] ,[6] , Support Vector Machines ( SVM ) [7] ,[8] ,[9] and AdaBoost [1] ,[10] ,[11] ,[12] ,[13] are typical choices for building robust face detectors .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
Recently , with advances in machine learning research , Neural Network [5] ,[6] , Support Vector Machines ( SVM ) [7] ,[8] ,[9] and AdaBoost [1] ,[10] ,[11] ,[12] ,[13] are typical choices for building robust face detectors .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
Recently , with advances in machine learning research , Neural Network [5] ,[6] , Support Vector Machines ( SVM ) [7] ,[8] ,[9] and AdaBoost [1] ,[10] ,[11] ,[12] ,[13] are typical choices for building robust face detectors .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
Recently , with advances in machine learning research , Neural Network [5] ,[6] , Support Vector Machines ( SVM ) [7] ,[8] ,[9] and AdaBoost [1] ,[10] ,[11] ,[12] ,[13] are typical choices for building robust face detectors .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
Recently , with advances in machine learning research , Neural Network [5] ,[6] , Support Vector Machines ( SVM ) [7] ,[8] ,[9] and AdaBoost [1] ,[10] ,[11] ,[12] ,[13] are typical choices for building robust face detectors .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
Recently , with advances in machine learning research , Neural Network [5] ,[6] , Support Vector Machines ( SVM ) [7] ,[8] ,[9] and AdaBoost [1] ,[10] ,[11] ,[12] ,[13] are typical choices for building robust face detectors .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
Recently , with advances in machine learning research , Neural Network [5] ,[6] , Support Vector Machines ( SVM ) [7] ,[8] ,[9] and AdaBoost [1] ,[10] ,[11] ,[12] ,[13] are typical choices for building robust face detectors .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
Recently , with advances in machine learning research , Neural Network [5] ,[6] , Support Vector Machines ( SVM ) [7] ,[8] ,[9] and AdaBoost [1] ,[10] ,[11] ,[12] ,[13] are typical choices for building robust face detectors .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
Recently , with advances in machine learning research , Neural Network [5] ,[6] , Support Vector Machines ( SVM ) [7] ,[8] ,[9] and AdaBoost [1] ,[10] ,[11] ,[12] ,[13] are typical choices for building robust face detectors .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
Recently , with advances in machine learning research , Neural Network [5] ,[6] , Support Vector Machines ( SVM ) [7] ,[8] ,[9] and AdaBoost [1] ,[10] ,[11] ,[12] ,[13] are typical choices for building robust face detectors .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
Recently , with advances in machine learning research , Neural Network [5] ,[6] , Support Vector Machines ( SVM ) [7] ,[8] ,[9] and AdaBoost [1] ,[10] ,[11] ,[12] ,[13] are typical choices for building robust face detectors .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
Recently , with advances in machine learning research , Neural Network [5] ,[6] , Support Vector Machines ( SVM ) [7] ,[8] ,[9] and AdaBoost [1] ,[10] ,[11] ,[12] ,[13] are typical choices for building robust face detectors .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
Generally , to classify an input pattern of intensities as a face or non-face , features must be extracted and normalized before passing to a classifier [14] .
#<struct ReadData::Alignment source_numbers="23", target_numbers="31", tag_name="wa">
Generally , to classify an input pattern of intensities as a face or non-face , features must be extracted and normalized before passing to a classifier [14] .
#<struct ReadData::Alignment source_numbers="24", target_numbers="32", tag_name="wa">
Generally , to classify an input pattern of intensities as a face or non-face , features must be extracted and normalized before passing to a classifier [14] .
#<struct ReadData::Alignment source_numbers="25", target_numbers="33", tag_name="wa">
Generally , to classify an input pattern of intensities as a face or non-face , features must be extracted and normalized before passing to a classifier [14] .
#<struct ReadData::Alignment source_numbers="26", target_numbers="34", tag_name="wa">
Generally , to classify an input pattern of intensities as a face or non-face , features must be extracted and normalized before passing to a classifier [14] .
#<struct ReadData::Alignment source_numbers="27", target_numbers="35", tag_name="wa">
Generally , to classify an input pattern of intensities as a face or non-face , features must be extracted and normalized before passing to a classifier [14] .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
Generally , to classify an input pattern of intensities as a face or non-face , features must be extracted and normalized before passing to a classifier [14] .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
Generally , to classify an input pattern of intensities as a face or non-face , features must be extracted and normalized before passing to a classifier [14] .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
Generally , to classify an input pattern of intensities as a face or non-face , features must be extracted and normalized before passing to a classifier [14] .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
Generally , to classify an input pattern of intensities as a face or non-face , features must be extracted and normalized before passing to a classifier [14] .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
Generally , to classify an input pattern of intensities as a face or non-face , features must be extracted and normalized before passing to a classifier [14] .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
Generally , to classify an input pattern of intensities as a face or non-face , features must be extracted and normalized before passing to a classifier [14] .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
Generally , to classify an input pattern of intensities as a face or non-face , features must be extracted and normalized before passing to a classifier [14] .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
There are many kinds of features that have been used ranging from simple features such as intensity values [7] ,[5] and eigenspace [15] to complex features such as wavelets [16] ,[1] ,[12] , edge orientation histograms [17] ,[18] and Bayesian discriminating features ( BDF ) [19] .
#<struct ReadData::Alignment source_numbers="32", target_numbers="7", tag_name="wa">
There are many kinds of features that have been used ranging from simple features such as intensity values [7] ,[5] and eigenspace [15] to complex features such as wavelets [16] ,[1] ,[12] , edge orientation histograms [17] ,[18] and Bayesian discriminating features ( BDF ) [19] .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
There are many kinds of features that have been used ranging from simple features such as intensity values [7] ,[5] and eigenspace [15] to complex features such as wavelets [16] ,[1] ,[12] , edge orientation histograms [17] ,[18] and Bayesian discriminating features ( BDF ) [19] .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
There are many kinds of features that have been used ranging from simple features such as intensity values [7] ,[5] and eigenspace [15] to complex features such as wavelets [16] ,[1] ,[12] , edge orientation histograms [17] ,[18] and Bayesian discriminating features ( BDF ) [19] .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
There are many kinds of features that have been used ranging from simple features such as intensity values [7] ,[5] and eigenspace [15] to complex features such as wavelets [16] ,[1] ,[12] , edge orientation histograms [17] ,[18] and Bayesian discriminating features ( BDF ) [19] .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
There are many kinds of features that have been used ranging from simple features such as intensity values [7] ,[5] and eigenspace [15] to complex features such as wavelets [16] ,[1] ,[12] , edge orientation histograms [17] ,[18] and Bayesian discriminating features ( BDF ) [19] .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
There are many kinds of features that have been used ranging from simple features such as intensity values [7] ,[5] and eigenspace [15] to complex features such as wavelets [16] ,[1] ,[12] , edge orientation histograms [17] ,[18] and Bayesian discriminating features ( BDF ) [19] .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
There are many kinds of features that have been used ranging from simple features such as intensity values [7] ,[5] and eigenspace [15] to complex features such as wavelets [16] ,[1] ,[12] , edge orientation histograms [17] ,[18] and Bayesian discriminating features ( BDF ) [19] .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
There are many kinds of features that have been used ranging from simple features such as intensity values [7] ,[5] and eigenspace [15] to complex features such as wavelets [16] ,[1] ,[12] , edge orientation histograms [17] ,[18] and Bayesian discriminating features ( BDF ) [19] .
#<struct ReadData::Alignment source_numbers="30", target_numbers="", tag_name="wa">
There are many kinds of features that have been used ranging from simple features such as intensity values [7] ,[5] and eigenspace [15] to complex features such as wavelets [16] ,[1] ,[12] , edge orientation histograms [17] ,[18] and Bayesian discriminating features ( BDF ) [19] .
#<struct ReadData::Alignment source_numbers="31", target_numbers="", tag_name="wa">
There are many kinds of features that have been used ranging from simple features such as intensity values [7] ,[5] and eigenspace [15] to complex features such as wavelets [16] ,[1] ,[12] , edge orientation histograms [17] ,[18] and Bayesian discriminating features ( BDF ) [19] .
#<struct ReadData::Alignment source_numbers="37", target_numbers="", tag_name="wa">
There are many kinds of features that have been used ranging from simple features such as intensity values [7] ,[5] and eigenspace [15] to complex features such as wavelets [16] ,[1] ,[12] , edge orientation histograms [17] ,[18] and Bayesian discriminating features ( BDF ) [19] .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
There are many kinds of features that have been used ranging from simple features such as intensity values [7] ,[5] and eigenspace [15] to complex features such as wavelets [16] ,[1] ,[12] , edge orientation histograms [17] ,[18] and Bayesian discriminating features ( BDF ) [19] .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
There are many kinds of features that have been used ranging from simple features such as intensity values [7] ,[5] and eigenspace [15] to complex features such as wavelets [16] ,[1] ,[12] , edge orientation histograms [17] ,[18] and Bayesian discriminating features ( BDF ) [19] .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
There are many kinds of features that have been used ranging from simple features such as intensity values [7] ,[5] and eigenspace [15] to complex features such as wavelets [16] ,[1] ,[12] , edge orientation histograms [17] ,[18] and Bayesian discriminating features ( BDF ) [19] .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
There are many kinds of features that have been used ranging from simple features such as intensity values [7] ,[5] and eigenspace [15] to complex features such as wavelets [16] ,[1] ,[12] , edge orientation histograms [17] ,[18] and Bayesian discriminating features ( BDF ) [19] .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
There are many kinds of features that have been used ranging from simple features such as intensity values [7] ,[5] and eigenspace [15] to complex features such as wavelets [16] ,[1] ,[12] , edge orientation histograms [17] ,[18] and Bayesian discriminating features ( BDF ) [19] .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
There are many kinds of features that have been used ranging from simple features such as intensity values [7] ,[5] and eigenspace [15] to complex features such as wavelets [16] ,[1] ,[12] , edge orientation histograms [17] ,[18] and Bayesian discriminating features ( BDF ) [19] .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
There are many kinds of features that have been used ranging from simple features such as intensity values [7] ,[5] and eigenspace [15] to complex features such as wavelets [16] ,[1] ,[12] , edge orientation histograms [17] ,[18] and Bayesian discriminating features ( BDF ) [19] .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
There are many kinds of features that have been used ranging from simple features such as intensity values [7] ,[5] and eigenspace [15] to complex features such as wavelets [16] ,[1] ,[12] , edge orientation histograms [17] ,[18] and Bayesian discriminating features ( BDF ) [19] .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
There are many kinds of features that have been used ranging from simple features such as intensity values [7] ,[5] and eigenspace [15] to complex features such as wavelets [16] ,[1] ,[12] , edge orientation histograms [17] ,[18] and Bayesian discriminating features ( BDF ) [19] .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
There are many kinds of features that have been used ranging from simple features such as intensity values [7] ,[5] and eigenspace [15] to complex features such as wavelets [16] ,[1] ,[12] , edge orientation histograms [17] ,[18] and Bayesian discriminating features ( BDF ) [19] .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
There are many kinds of features that have been used ranging from simple features such as intensity values [7] ,[5] and eigenspace [15] to complex features such as wavelets [16] ,[1] ,[12] , edge orientation histograms [17] ,[18] and Bayesian discriminating features ( BDF ) [19] .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
There are many kinds of features that have been used ranging from simple features such as intensity values [7] ,[5] and eigenspace [15] to complex features such as wavelets [16] ,[1] ,[12] , edge orientation histograms [17] ,[18] and Bayesian discriminating features ( BDF ) [19] .
#<struct ReadData::Alignment source_numbers="", target_numbers="40", tag_name="wa">
Discriminative and informative features usually increase detection rate and reduce complexity of the training procedure [17] .
#<struct ReadData::Alignment source_numbers="7,8", target_numbers="7,8", tag_name="wa">
In a typical face detector which is scale-free and location-free , the number of analyzed patterns is usually very large ( 160 ,000 patterns for a 320x240 pixel image ) because the face classifier has to scan over the input image at every location and every scale .
#<struct ReadData::Alignment source_numbers="5,6", target_numbers="5,6", tag_name="wa">
In a typical face detector which is scale-free and location-free , the number of analyzed patterns is usually very large ( 160 ,000 patterns for a 320x240 pixel image ) because the face classifier has to scan over the input image at every location and every scale .
#<struct ReadData::Alignment source_numbers="8", target_numbers="8", tag_name="wa">
In a typical face detector which is scale-free and location-free , the number of analyzed patterns is usually very large ( 160 ,000 patterns for a 320x240 pixel image ) because the face classifier has to scan over the input image at every location and every scale .
#<struct ReadData::Alignment source_numbers="9", target_numbers="9", tag_name="wa">
In a typical face detector which is scale-free and location-free , the number of analyzed patterns is usually very large ( 160 ,000 patterns for a 320x240 pixel image ) because the face classifier has to scan over the input image at every location and every scale .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
In a typical face detector which is scale-free and location-free , the number of analyzed patterns is usually very large ( 160 ,000 patterns for a 320x240 pixel image ) because the face classifier has to scan over the input image at every location and every scale .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Face detectors based on single classifiers such as SVM [7] ,[8] ,[9] and Neural Network [6] ,[5] are usually slow because they process non-face regions and face regions in the input image equally .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Face detectors based on single classifiers such as SVM [7] ,[8] ,[9] and Neural Network [6] ,[5] are usually slow because they process non-face regions and face regions in the input image equally .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
Face detectors based on single classifiers such as SVM [7] ,[8] ,[9] and Neural Network [6] ,[5] are usually slow because they process non-face regions and face regions in the input image equally .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
Face detectors based on single classifiers such as SVM [7] ,[8] ,[9] and Neural Network [6] ,[5] are usually slow because they process non-face regions and face regions in the input image equally .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
Face detectors based on single classifiers such as SVM [7] ,[8] ,[9] and Neural Network [6] ,[5] are usually slow because they process non-face regions and face regions in the input image equally .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
Face detectors based on single classifiers such as SVM [7] ,[8] ,[9] and Neural Network [6] ,[5] are usually slow because they process non-face regions and face regions in the input image equally .
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
Face detectors based on single classifiers such as SVM [7] ,[8] ,[9] and Neural Network [6] ,[5] are usually slow because they process non-face regions and face regions in the input image equally .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Face detectors based on single classifiers such as SVM [7] ,[8] ,[9] and Neural Network [6] ,[5] are usually slow because they process non-face regions and face regions in the input image equally .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
Face detectors based on single classifiers such as SVM [7] ,[8] ,[9] and Neural Network [6] ,[5] are usually slow because they process non-face regions and face regions in the input image equally .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
Face detectors based on single classifiers such as SVM [7] ,[8] ,[9] and Neural Network [6] ,[5] are usually slow because they process non-face regions and face regions in the input image equally .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Face detectors based on single classifiers such as SVM [7] ,[8] ,[9] and Neural Network [6] ,[5] are usually slow because they process non-face regions and face regions in the input image equally .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
Face detectors based on single classifiers such as SVM [7] ,[8] ,[9] and Neural Network [6] ,[5] are usually slow because they process non-face regions and face regions in the input image equally .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
Face detectors based on single classifiers such as SVM [7] ,[8] ,[9] and Neural Network [6] ,[5] are usually slow because they process non-face regions and face regions in the input image equally .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
Face detectors based on single classifiers such as SVM [7] ,[8] ,[9] and Neural Network [6] ,[5] are usually slow because they process non-face regions and face regions in the input image equally .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
To deal with the problem of processing a large number of patterns , a combination of simple-to-complex classifiers is proposed [8] ,[1] ,[9] ,[20] ,[21] ,[11] .
#<struct ReadData::Alignment source_numbers="18", target_numbers="18,19", tag_name="wa">
To deal with the problem of processing a large number of patterns , a combination of simple-to-complex classifiers is proposed [8] ,[1] ,[9] ,[20] ,[21] ,[11] .
#<struct ReadData::Alignment source_numbers="19", target_numbers="20", tag_name="wa">
To deal with the problem of processing a large number of patterns , a combination of simple-to-complex classifiers is proposed [8] ,[1] ,[9] ,[20] ,[21] ,[11] .
#<struct ReadData::Alignment source_numbers="26", target_numbers="32", tag_name="wa">
To deal with the problem of processing a large number of patterns , a combination of simple-to-complex classifiers is proposed [8] ,[1] ,[9] ,[20] ,[21] ,[11] .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
To deal with the problem of processing a large number of patterns , a combination of simple-to-complex classifiers is proposed [8] ,[1] ,[9] ,[20] ,[21] ,[11] .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
To deal with the problem of processing a large number of patterns , a combination of simple-to-complex classifiers is proposed [8] ,[1] ,[9] ,[20] ,[21] ,[11] .
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
To deal with the problem of processing a large number of patterns , a combination of simple-to-complex classifiers is proposed [8] ,[1] ,[9] ,[20] ,[21] ,[11] .
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
To deal with the problem of processing a large number of patterns , a combination of simple-to-complex classifiers is proposed [8] ,[1] ,[9] ,[20] ,[21] ,[11] .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
To deal with the problem of processing a large number of patterns , a combination of simple-to-complex classifiers is proposed [8] ,[1] ,[9] ,[20] ,[21] ,[11] .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
To deal with the problem of processing a large number of patterns , a combination of simple-to-complex classifiers is proposed [8] ,[1] ,[9] ,[20] ,[21] ,[11] .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
To deal with the problem of processing a large number of patterns , a combination of simple-to-complex classifiers is proposed [8] ,[1] ,[9] ,[20] ,[21] ,[11] .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
To deal with the problem of processing a large number of patterns , a combination of simple-to-complex classifiers is proposed [8] ,[1] ,[9] ,[20] ,[21] ,[11] .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
To deal with the problem of processing a large number of patterns , a combination of simple-to-complex classifiers is proposed [8] ,[1] ,[9] ,[20] ,[21] ,[11] .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
To deal with the problem of processing a large number of patterns , a combination of simple-to-complex classifiers is proposed [8] ,[1] ,[9] ,[20] ,[21] ,[11] .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
To deal with the problem of processing a large number of patterns , a combination of simple-to-complex classifiers is proposed [8] ,[1] ,[9] ,[20] ,[21] ,[11] .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
To deal with the problem of processing a large number of patterns , a combination of simple-to-complex classifiers is proposed [8] ,[1] ,[9] ,[20] ,[21] ,[11] .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
To deal with the problem of processing a large number of patterns , a combination of simple-to-complex classifiers is proposed [8] ,[1] ,[9] ,[20] ,[21] ,[11] .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
To deal with the problem of processing a large number of patterns , a combination of simple-to-complex classifiers is proposed [8] ,[1] ,[9] ,[20] ,[21] ,[11] .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
In particular , fast and simple classifiers are used as filters at the earliest stages to quickly reject a large number of non-face patterns and a slower yet more accurate classifier is then used for classifying face-like patterns .
#<struct ReadData::Alignment source_numbers="33", target_numbers="39", tag_name="wa">
In particular , fast and simple classifiers are used as filters at the earliest stages to quickly reject a large number of non-face patterns and a slower yet more accurate classifier is then used for classifying face-like patterns .
#<struct ReadData::Alignment source_numbers="34", target_numbers="40", tag_name="wa">
In particular , fast and simple classifiers are used as filters at the earliest stages to quickly reject a large number of non-face patterns and a slower yet more accurate classifier is then used for classifying face-like patterns .
#<struct ReadData::Alignment source_numbers="35", target_numbers="41", tag_name="wa">
In particular , fast and simple classifiers are used as filters at the earliest stages to quickly reject a large number of non-face patterns and a slower yet more accurate classifier is then used for classifying face-like patterns .
#<struct ReadData::Alignment source_numbers="36", target_numbers="42", tag_name="wa">
In particular , fast and simple classifiers are used as filters at the earliest stages to quickly reject a large number of non-face patterns and a slower yet more accurate classifier is then used for classifying face-like patterns .
#<struct ReadData::Alignment source_numbers="37", target_numbers="43", tag_name="wa">
In particular , fast and simple classifiers are used as filters at the earliest stages to quickly reject a large number of non-face patterns and a slower yet more accurate classifier is then used for classifying face-like patterns .
#<struct ReadData::Alignment source_numbers="38", target_numbers="44", tag_name="wa">
In particular , fast and simple classifiers are used as filters at the earliest stages to quickly reject a large number of non-face patterns and a slower yet more accurate classifier is then used for classifying face-like patterns .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
In particular , fast and simple classifiers are used as filters at the earliest stages to quickly reject a large number of non-face patterns and a slower yet more accurate classifier is then used for classifying face-like patterns .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
In particular , fast and simple classifiers are used as filters at the earliest stages to quickly reject a large number of non-face patterns and a slower yet more accurate classifier is then used for classifying face-like patterns .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
In particular , fast and simple classifiers are used as filters at the earliest stages to quickly reject a large number of non-face patterns and a slower yet more accurate classifier is then used for classifying face-like patterns .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
In particular , fast and simple classifiers are used as filters at the earliest stages to quickly reject a large number of non-face patterns and a slower yet more accurate classifier is then used for classifying face-like patterns .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
In particular , fast and simple classifiers are used as filters at the earliest stages to quickly reject a large number of non-face patterns and a slower yet more accurate classifier is then used for classifying face-like patterns .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
By this way , the complexity of classifiers is adapted corresponding to the difficulty in the input patterns .
#<struct ReadData::Alignment source_numbers="8", target_numbers="8,9", tag_name="wa">
By this way , the complexity of classifiers is adapted corresponding to the difficulty in the input patterns .
#<struct ReadData::Alignment source_numbers="9", target_numbers="10", tag_name="wa">
By this way , the complexity of classifiers is adapted corresponding to the difficulty in the input patterns .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
By this way , the complexity of classifiers is adapted corresponding to the difficulty in the input patterns .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
By this way , the complexity of classifiers is adapted corresponding to the difficulty in the input patterns .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
By this way , the complexity of classifiers is adapted corresponding to the difficulty in the input patterns .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
By this way , the complexity of classifiers is adapted corresponding to the difficulty in the input patterns .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
By this way , the complexity of classifiers is adapted corresponding to the difficulty in the input patterns .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
By this way , the complexity of classifiers is adapted corresponding to the difficulty in the input patterns .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
By this way , the complexity of classifiers is adapted corresponding to the difficulty in the input patterns .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
In [8] , non linear SVM classifiers using pixel-based features are arranged into a sequence with increasing number of support vectors , or in [9] , linear SVM classifiers trained at different resolutions are used for rejection and a reduced set of principle component analysis ( PCA )-based features are used with the non linear SVM at the classification stage in order to reduce computation time .
#<struct ReadData::Alignment source_numbers="10", target_numbers="9", tag_name="wa">
In [8] , non linear SVM classifiers using pixel-based features are arranged into a sequence with increasing number of support vectors , or in [9] , linear SVM classifiers trained at different resolutions are used for rejection and a reduced set of principle component analysis ( PCA )-based features are used with the non linear SVM at the classification stage in order to reduce computation time .
#<struct ReadData::Alignment source_numbers="11", target_numbers="10", tag_name="wa">
In [8] , non linear SVM classifiers using pixel-based features are arranged into a sequence with increasing number of support vectors , or in [9] , linear SVM classifiers trained at different resolutions are used for rejection and a reduced set of principle component analysis ( PCA )-based features are used with the non linear SVM at the classification stage in order to reduce computation time .
#<struct ReadData::Alignment source_numbers="57", target_numbers="16", tag_name="wa">
In [8] , non linear SVM classifiers using pixel-based features are arranged into a sequence with increasing number of support vectors , or in [9] , linear SVM classifiers trained at different resolutions are used for rejection and a reduced set of principle component analysis ( PCA )-based features are used with the non linear SVM at the classification stage in order to reduce computation time .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
In [8] , non linear SVM classifiers using pixel-based features are arranged into a sequence with increasing number of support vectors , or in [9] , linear SVM classifiers trained at different resolutions are used for rejection and a reduced set of principle component analysis ( PCA )-based features are used with the non linear SVM at the classification stage in order to reduce computation time .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
In [8] , non linear SVM classifiers using pixel-based features are arranged into a sequence with increasing number of support vectors , or in [9] , linear SVM classifiers trained at different resolutions are used for rejection and a reduced set of principle component analysis ( PCA )-based features are used with the non linear SVM at the classification stage in order to reduce computation time .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
In [8] , non linear SVM classifiers using pixel-based features are arranged into a sequence with increasing number of support vectors , or in [9] , linear SVM classifiers trained at different resolutions are used for rejection and a reduced set of principle component analysis ( PCA )-based features are used with the non linear SVM at the classification stage in order to reduce computation time .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
In [8] , non linear SVM classifiers using pixel-based features are arranged into a sequence with increasing number of support vectors , or in [9] , linear SVM classifiers trained at different resolutions are used for rejection and a reduced set of principle component analysis ( PCA )-based features are used with the non linear SVM at the classification stage in order to reduce computation time .
#<struct ReadData::Alignment source_numbers="53", target_numbers="", tag_name="wa">
In [8] , non linear SVM classifiers using pixel-based features are arranged into a sequence with increasing number of support vectors , or in [9] , linear SVM classifiers trained at different resolutions are used for rejection and a reduced set of principle component analysis ( PCA )-based features are used with the non linear SVM at the classification stage in order to reduce computation time .
#<struct ReadData::Alignment source_numbers="54", target_numbers="", tag_name="wa">
In [8] , non linear SVM classifiers using pixel-based features are arranged into a sequence with increasing number of support vectors , or in [9] , linear SVM classifiers trained at different resolutions are used for rejection and a reduced set of principle component analysis ( PCA )-based features are used with the non linear SVM at the classification stage in order to reduce computation time .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
In [8] , non linear SVM classifiers using pixel-based features are arranged into a sequence with increasing number of support vectors , or in [9] , linear SVM classifiers trained at different resolutions are used for rejection and a reduced set of principle component analysis ( PCA )-based features are used with the non linear SVM at the classification stage in order to reduce computation time .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
In [8] , non linear SVM classifiers using pixel-based features are arranged into a sequence with increasing number of support vectors , or in [9] , linear SVM classifiers trained at different resolutions are used for rejection and a reduced set of principle component analysis ( PCA )-based features are used with the non linear SVM at the classification stage in order to reduce computation time .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
In [8] , non linear SVM classifiers using pixel-based features are arranged into a sequence with increasing number of support vectors , or in [9] , linear SVM classifiers trained at different resolutions are used for rejection and a reduced set of principle component analysis ( PCA )-based features are used with the non linear SVM at the classification stage in order to reduce computation time .
#<struct ReadData::Alignment source_numbers="", target_numbers="53", tag_name="wa">
In [8] , non linear SVM classifiers using pixel-based features are arranged into a sequence with increasing number of support vectors , or in [9] , linear SVM classifiers trained at different resolutions are used for rejection and a reduced set of principle component analysis ( PCA )-based features are used with the non linear SVM at the classification stage in order to reduce computation time .
#<struct ReadData::Alignment source_numbers="", target_numbers="56", tag_name="wa">
In [1] , AdaBoost based classifiers are arranged in a degeneration decision tree or a cascade .
#<struct ReadData::Alignment source_numbers="6", target_numbers="5", tag_name="wa">
In [1] , AdaBoost based classifiers are arranged in a degeneration decision tree or a cascade .
#<struct ReadData::Alignment source_numbers="7", target_numbers="6", tag_name="wa">
In [1] , AdaBoost based classifiers are arranged in a degeneration decision tree or a cascade .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
In [1] , AdaBoost based classifiers are arranged in a degeneration decision tree or a cascade .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
In [1] , AdaBoost based classifiers are arranged in a degeneration decision tree or a cascade .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
It is believed that the cascade structure of classifiers is the key factor in enhancement of current real-time face detectors .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
It is believed that the cascade structure of classifiers is the key factor in enhancement of current real-time face detectors .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
It is believed that the cascade structure of classifiers is the key factor in enhancement of current real-time face detectors .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
It is believed that the cascade structure of classifiers is the key factor in enhancement of current real-time face detectors .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
It is believed that the cascade structure of classifiers is the key factor in enhancement of current real-time face detectors .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
It is believed that the cascade structure of classifiers is the key factor in enhancement of current real-time face detectors .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
It is believed that the cascade structure of classifiers is the key factor in enhancement of current real-time face detectors .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
It is believed that the cascade structure of classifiers is the key factor in enhancement of current real-time face detectors .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
It is believed that the cascade structure of classifiers is the key factor in enhancement of current real-time face detectors .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
It is believed that the cascade structure of classifiers is the key factor in enhancement of current real-time face detectors .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
It is believed that the cascade structure of classifiers is the key factor in enhancement of current real-time face detectors .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
It is believed that the cascade structure of classifiers is the key factor in enhancement of current real-time face detectors .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
It is believed that the cascade structure of classifiers is the key factor in enhancement of current real-time face detectors .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
It is believed that the cascade structure of classifiers is the key factor in enhancement of current real-time face detectors .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
It is believed that the cascade structure of classifiers is the key factor in enhancement of current real-time face detectors .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
It is believed that the cascade structure of classifiers is the key factor in enhancement of current real-time face detectors .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
It is believed that the cascade structure of classifiers is the key factor in enhancement of current real-time face detectors .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
It is believed that the cascade structure of classifiers is the key factor in enhancement of current real-time face detectors .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
It is believed that the cascade structure of classifiers is the key factor in enhancement of current real-time face detectors .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
It is believed that the cascade structure of classifiers is the key factor in enhancement of current real-time face detectors .
#<struct ReadData::Alignment source_numbers="", target_numbers="40", tag_name="wa">
It is believed that the cascade structure of classifiers is the key factor in enhancement of current real-time face detectors .
#<struct ReadData::Alignment source_numbers="", target_numbers="41", tag_name="wa">
It is believed that the cascade structure of classifiers is the key factor in enhancement of current real-time face detectors .
#<struct ReadData::Alignment source_numbers="", target_numbers="42", tag_name="wa">
It is believed that the cascade structure of classifiers is the key factor in enhancement of current real-time face detectors .
#<struct ReadData::Alignment source_numbers="", target_numbers="43", tag_name="wa">
It is believed that the cascade structure of classifiers is the key factor in enhancement of current real-time face detectors .
#<struct ReadData::Alignment source_numbers="", target_numbers="44", tag_name="wa">
It is believed that the cascade structure of classifiers is the key factor in enhancement of current real-time face detectors .
#<struct ReadData::Alignment source_numbers="", target_numbers="45", tag_name="wa">
It is believed that the cascade structure of classifiers is the key factor in enhancement of current real-time face detectors .
#<struct ReadData::Alignment source_numbers="", target_numbers="46", tag_name="wa">
This work is motivated by Viola and Jones [1] who proposed a framework for fast and robust face detection .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
-Firstly , the cascaded structure of simple-to-complex classifiers reduces computation time dramatically ( as mentioned above ) .
#<struct ReadData::Alignment source_numbers="17", target_numbers="10", tag_name="wa">
-Firstly , the cascaded structure of simple-to-complex classifiers reduces computation time dramatically ( as mentioned above ) .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
-Firstly , the cascaded structure of simple-to-complex classifiers reduces computation time dramatically ( as mentioned above ) .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
-Firstly , the cascaded structure of simple-to-complex classifiers reduces computation time dramatically ( as mentioned above ) .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
-Firstly , the cascaded structure of simple-to-complex classifiers reduces computation time dramatically ( as mentioned above ) .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
-Firstly , the cascaded structure of simple-to-complex classifiers reduces computation time dramatically ( as mentioned above ) .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
-Firstly , the cascaded structure of simple-to-complex classifiers reduces computation time dramatically ( as mentioned above ) .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
-Firstly , the cascaded structure of simple-to-complex classifiers reduces computation time dramatically ( as mentioned above ) .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
-Secondly , AdaBoost is used to select discriminative and significant features from a pool of a very large number of features and then construct the classifier .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
-Secondly , AdaBoost is used to select discriminative and significant features from a pool of a very large number of features and then construct the classifier .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
-Secondly , AdaBoost is used to select discriminative and significant features from a pool of a very large number of features and then construct the classifier .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
-Secondly , AdaBoost is used to select discriminative and significant features from a pool of a very large number of features and then construct the classifier .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Compared to SVM-based classifiers or neural network-based classifiers , AdaBoost based classifiers are hundreds of times faster .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Compared to SVM-based classifiers or neural network-based classifiers , AdaBoost based classifiers are hundreds of times faster .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Compared to SVM-based classifiers or neural network-based classifiers , AdaBoost based classifiers are hundreds of times faster .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
-Thirdly , Haar-wavelet features used for all stages are informative [22] and evaluated extremely fast due to the introduction of the integral image .
#<struct ReadData::Alignment source_numbers="12", target_numbers="13", tag_name="wa">
-Thirdly , Haar-wavelet features used for all stages are informative [22] and evaluated extremely fast due to the introduction of the integral image .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
-Thirdly , Haar-wavelet features used for all stages are informative [22] and evaluated extremely fast due to the introduction of the integral image .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
-Thirdly , Haar-wavelet features used for all stages are informative [22] and evaluated extremely fast due to the introduction of the integral image .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
-Thirdly , Haar-wavelet features used for all stages are informative [22] and evaluated extremely fast due to the introduction of the integral image .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
-Thirdly , Haar-wavelet features used for all stages are informative [22] and evaluated extremely fast due to the introduction of the integral image .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
-Thirdly , Haar-wavelet features used for all stages are informative [22] and evaluated extremely fast due to the introduction of the integral image .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
-Thirdly , Haar-wavelet features used for all stages are informative [22] and evaluated extremely fast due to the introduction of the integral image .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
This need is apparent when face and non-face patterns become hard to distinguish , weak classifiers are too weak to boost [22] .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
With the first several layers in our experiment ( cf. Figure 1 ) , using some 800 weak classifiers , more than \MATH of non-face patterns are rejected .
#<struct ReadData::Alignment source_numbers="9", target_numbers="9", tag_name="wa">
With the first several layers in our experiment ( cf. Figure 1 ) , using some 800 weak classifiers , more than \MATH of non-face patterns are rejected .
#<struct ReadData::Alignment source_numbers="26", target_numbers="27", tag_name="wa">
With the first several layers in our experiment ( cf. Figure 1 ) , using some 800 weak classifiers , more than \MATH of non-face patterns are rejected .
#<struct ReadData::Alignment source_numbers="27", target_numbers="28", tag_name="wa">
With the first several layers in our experiment ( cf. Figure 1 ) , using some 800 weak classifiers , more than \MATH of non-face patterns are rejected .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
However , turning the later layers into robustly classifying a smaller number of remaining patterns , it requires a lot more , e.g. , 5 ,660 , weak classifiers , thus making the training task much more complicated .
#<struct ReadData::Alignment source_numbers="29", target_numbers="25", tag_name="wa">
However , turning the later layers into robustly classifying a smaller number of remaining patterns , it requires a lot more , e.g. , 5 ,660 , weak classifiers , thus making the training task much more complicated .
#<struct ReadData::Alignment source_numbers="38", target_numbers="34", tag_name="wa">
However , turning the later layers into robustly classifying a smaller number of remaining patterns , it requires a lot more , e.g. , 5 ,660 , weak classifiers , thus making the training task much more complicated .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
However , turning the later layers into robustly classifying a smaller number of remaining patterns , it requires a lot more , e.g. , 5 ,660 , weak classifiers , thus making the training task much more complicated .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
However , turning the later layers into robustly classifying a smaller number of remaining patterns , it requires a lot more , e.g. , 5 ,660 , weak classifiers , thus making the training task much more complicated .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
However , turning the later layers into robustly classifying a smaller number of remaining patterns , it requires a lot more , e.g. , 5 ,660 , weak classifiers , thus making the training task much more complicated .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
However , turning the later layers into robustly classifying a smaller number of remaining patterns , it requires a lot more , e.g. , 5 ,660 , weak classifiers , thus making the training task much more complicated .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
However , turning the later layers into robustly classifying a smaller number of remaining patterns , it requires a lot more , e.g. , 5 ,660 , weak classifiers , thus making the training task much more complicated .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
However , turning the later layers into robustly classifying a smaller number of remaining patterns , it requires a lot more , e.g. , 5 ,660 , weak classifiers , thus making the training task much more complicated .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
However , turning the later layers into robustly classifying a smaller number of remaining patterns , it requires a lot more , e.g. , 5 ,660 , weak classifiers , thus making the training task much more complicated .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
However , turning the later layers into robustly classifying a smaller number of remaining patterns , it requires a lot more , e.g. , 5 ,660 , weak classifiers , thus making the training task much more complicated .
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
However , turning the later layers into robustly classifying a smaller number of remaining patterns , it requires a lot more , e.g. , 5 ,660 , weak classifiers , thus making the training task much more complicated .
#<struct ReadData::Alignment source_numbers="26", target_numbers="", tag_name="wa">
However , turning the later layers into robustly classifying a smaller number of remaining patterns , it requires a lot more , e.g. , 5 ,660 , weak classifiers , thus making the training task much more complicated .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
However , turning the later layers into robustly classifying a smaller number of remaining patterns , it requires a lot more , e.g. , 5 ,660 , weak classifiers , thus making the training task much more complicated .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
However , turning the later layers into robustly classifying a smaller number of remaining patterns , it requires a lot more , e.g. , 5 ,660 , weak classifiers , thus making the training task much more complicated .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
However , turning the later layers into robustly classifying a smaller number of remaining patterns , it requires a lot more , e.g. , 5 ,660 , weak classifiers , thus making the training task much more complicated .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
However , turning the later layers into robustly classifying a smaller number of remaining patterns , it requires a lot more , e.g. , 5 ,660 , weak classifiers , thus making the training task much more complicated .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
However , turning the later layers into robustly classifying a smaller number of remaining patterns , it requires a lot more , e.g. , 5 ,660 , weak classifiers , thus making the training task much more complicated .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
Firstly , it requires a long training time because the training time is proportional to the number of features in the input feature set ( which is normally hundreds of thousands ) and the number of training samples ( which is generally tens of thousands ) .
#<struct ReadData::Alignment source_numbers="10", target_numbers="7", tag_name="wa">
Firstly , it requires a long training time because the training time is proportional to the number of features in the input feature set ( which is normally hundreds of thousands ) and the number of training samples ( which is generally tens of thousands ) .
#<struct ReadData::Alignment source_numbers="11", target_numbers="8", tag_name="wa">
Firstly , it requires a long training time because the training time is proportional to the number of features in the input feature set ( which is normally hundreds of thousands ) and the number of training samples ( which is generally tens of thousands ) .
#<struct ReadData::Alignment source_numbers="15", target_numbers="12", tag_name="wa">
Firstly , it requires a long training time because the training time is proportional to the number of features in the input feature set ( which is normally hundreds of thousands ) and the number of training samples ( which is generally tens of thousands ) .
#<struct ReadData::Alignment source_numbers="20", target_numbers="17", tag_name="wa">
Firstly , it requires a long training time because the training time is proportional to the number of features in the input feature set ( which is normally hundreds of thousands ) and the number of training samples ( which is generally tens of thousands ) .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Firstly , it requires a long training time because the training time is proportional to the number of features in the input feature set ( which is normally hundreds of thousands ) and the number of training samples ( which is generally tens of thousands ) .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Firstly , it requires a long training time because the training time is proportional to the number of features in the input feature set ( which is normally hundreds of thousands ) and the number of training samples ( which is generally tens of thousands ) .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Firstly , it requires a long training time because the training time is proportional to the number of features in the input feature set ( which is normally hundreds of thousands ) and the number of training samples ( which is generally tens of thousands ) .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
Firstly , it requires a long training time because the training time is proportional to the number of features in the input feature set ( which is normally hundreds of thousands ) and the number of training samples ( which is generally tens of thousands ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
In our experiment , with 20 ,000 training samples and 134 ,736 features , the average training time for choosing one feature associated with the weak classifier is about 30 minutes on a PC ( Pentium 4 , 2 .8 MHz , 512-MB RAM ) .
#<struct ReadData::Alignment source_numbers="27,28", target_numbers="27,28", tag_name="wa">
Therefore , training a cascade of classifiers with around 6 ,060 features [1] might take in order of several weeks .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
Therefore , training a cascade of classifiers with around 6 ,060 features [1] might take in order of several weeks .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
Secondly , AdaBoost-based classifiers are constructed by adding features after each round of boosting , so several training parameters must be tuned manually while training .
#<struct ReadData::Alignment source_numbers="14", target_numbers="21", tag_name="wa">
Secondly , AdaBoost-based classifiers are constructed by adding features after each round of boosting , so several training parameters must be tuned manually while training .
#<struct ReadData::Alignment source_numbers="25", target_numbers="32", tag_name="wa">
Secondly , AdaBoost-based classifiers are constructed by adding features after each round of boosting , so several training parameters must be tuned manually while training .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Secondly , AdaBoost-based classifiers are constructed by adding features after each round of boosting , so several training parameters must be tuned manually while training .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Secondly , AdaBoost-based classifiers are constructed by adding features after each round of boosting , so several training parameters must be tuned manually while training .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Secondly , AdaBoost-based classifiers are constructed by adding features after each round of boosting , so several training parameters must be tuned manually while training .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Secondly , AdaBoost-based classifiers are constructed by adding features after each round of boosting , so several training parameters must be tuned manually while training .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Secondly , AdaBoost-based classifiers are constructed by adding features after each round of boosting , so several training parameters must be tuned manually while training .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Secondly , AdaBoost-based classifiers are constructed by adding features after each round of boosting , so several training parameters must be tuned manually while training .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Secondly , AdaBoost-based classifiers are constructed by adding features after each round of boosting , so several training parameters must be tuned manually while training .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Secondly , AdaBoost-based classifiers are constructed by adding features after each round of boosting , so several training parameters must be tuned manually while training .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Secondly , AdaBoost-based classifiers are constructed by adding features after each round of boosting , so several training parameters must be tuned manually while training .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Secondly , AdaBoost-based classifiers are constructed by adding features after each round of boosting , so several training parameters must be tuned manually while training .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Because the complexity of the training sets varies through layers in the cascade , it is undetermined how to choose these parameters automatically and optimally .
#<struct ReadData::Alignment source_numbers="17,18", target_numbers="15,16,17", tag_name="wa">
Because the complexity of the training sets varies through layers in the cascade , it is undetermined how to choose these parameters automatically and optimally .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
Because the complexity of the training sets varies through layers in the cascade , it is undetermined how to choose these parameters automatically and optimally .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
Because the complexity of the training sets varies through layers in the cascade , it is undetermined how to choose these parameters automatically and optimally .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
Because the complexity of the training sets varies through layers in the cascade , it is undetermined how to choose these parameters automatically and optimally .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
Because the complexity of the training sets varies through layers in the cascade , it is undetermined how to choose these parameters automatically and optimally .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
Because the complexity of the training sets varies through layers in the cascade , it is undetermined how to choose these parameters automatically and optimally .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
Because the complexity of the training sets varies through layers in the cascade , it is undetermined how to choose these parameters automatically and optimally .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
Specifically , for quick rejection of non-face patterns , we reuse two key ingredients of Viola and Jones' system , that is , the cascaded structure of simple-to-complex classifiers and AdaBoost trained with Haar-wavelet features .
#<struct ReadData::Alignment source_numbers="10", target_numbers="11", tag_name="wa">
Specifically , for quick rejection of non-face patterns , we reuse two key ingredients of Viola and Jones' system , that is , the cascaded structure of simple-to-complex classifiers and AdaBoost trained with Haar-wavelet features .
#<struct ReadData::Alignment source_numbers="33", target_numbers="", tag_name="wa">
Specifically , for quick rejection of non-face patterns , we reuse two key ingredients of Viola and Jones' system , that is , the cascaded structure of simple-to-complex classifiers and AdaBoost trained with Haar-wavelet features .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Specifically , for quick rejection of non-face patterns , we reuse two key ingredients of Viola and Jones' system , that is , the cascaded structure of simple-to-complex classifiers and AdaBoost trained with Haar-wavelet features .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
Specifically , for quick rejection of non-face patterns , we reuse two key ingredients of Viola and Jones' system , that is , the cascaded structure of simple-to-complex classifiers and AdaBoost trained with Haar-wavelet features .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
The contribution of this approach is three fold :
#<struct ReadData::Alignment source_numbers="6", target_numbers="6", tag_name="wa">
The contribution of this approach is three fold :
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
-First , to detect the face candidate regions , a new stage ( using a larger window size and a larger moving step size ) is added .
#<struct ReadData::Alignment source_numbers="25", target_numbers="25,26", tag_name="wa">
-First , to detect the face candidate regions , a new stage ( using a larger window size and a larger moving step size ) is added .
#<struct ReadData::Alignment source_numbers="26", target_numbers="27", tag_name="wa">
We use 36 x 36-pixel window-based classifiers with a moving step size of 12 pixels , to quickly estimate the candidate face regions .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
To improve speed while maintaining high accuracy , our approach takes advantage of the combination of the Haar wavelet features and the AdaBoost learning for fast and robust evaluation
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
Second , how to efficiently reuse the features selected by AdaBoost in the previous stage , for the SVM classifiers of the last stage , is investigated .
#<struct ReadData::Alignment source_numbers="26", target_numbers="4", tag_name="wa">
Second , how to efficiently reuse the features selected by AdaBoost in the previous stage , for the SVM classifiers of the last stage , is investigated .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
Second , how to efficiently reuse the features selected by AdaBoost in the previous stage , for the SVM classifiers of the last stage , is investigated .
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
Second , how to efficiently reuse the features selected by AdaBoost in the previous stage , for the SVM classifiers of the last stage , is investigated .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
Second , how to efficiently reuse the features selected by AdaBoost in the previous stage , for the SVM classifiers of the last stage , is investigated .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Second , how to efficiently reuse the features selected by AdaBoost in the previous stage , for the SVM classifiers of the last stage , is investigated .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Reusing these features brings to two advantages : ( i ) Haar wavelet features are very fast in evaluating and normalizing [1] .
#<struct ReadData::Alignment source_numbers="18", target_numbers="18", tag_name="wa">
Reusing these features brings to two advantages : ( i ) Haar wavelet features are very fast in evaluating and normalizing [1] .
#<struct ReadData::Alignment source_numbers="20", target_numbers="20", tag_name="wa">
Reusing these features brings to two advantages : ( i ) Haar wavelet features are very fast in evaluating and normalizing [1] .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Furthermore , it is unnecessary to re-evaluate these features because they have been previously evaluated .
#<struct ReadData::Alignment source_numbers="3,4", target_numbers="4,5,6", tag_name="wa">
Furthermore , it is unnecessary to re-evaluate these features because they have been previously evaluated .
#<struct ReadData::Alignment source_numbers="5", target_numbers="7", tag_name="wa">
Furthermore , it is unnecessary to re-evaluate these features because they have been previously evaluated .
#<struct ReadData::Alignment source_numbers="6", target_numbers="9", tag_name="wa">
Furthermore , it is unnecessary to re-evaluate these features because they have been previously evaluated .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Furthermore , it is unnecessary to re-evaluate these features because they have been previously evaluated .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
Furthermore , it is unnecessary to re-evaluate these features because they have been previously evaluated .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Furthermore , it is unnecessary to re-evaluate these features because they have been previously evaluated .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
( ii ) By using SVM classifiers with powerful generalization , using too many features in the cascade is avoided , therefore importantly training time is saved and over-fitting is avoided .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
( ii ) By using SVM classifiers with powerful generalization , using too many features in the cascade is avoided , therefore importantly training time is saved and over-fitting is avoided .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
( ii ) By using SVM classifiers with powerful generalization , using too many features in the cascade is avoided , therefore importantly training time is saved and over-fitting is avoided .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
( ii ) By using SVM classifiers with powerful generalization , using too many features in the cascade is avoided , therefore importantly training time is saved and over-fitting is avoided .
#<struct ReadData::Alignment source_numbers="26", target_numbers="", tag_name="wa">
( ii ) By using SVM classifiers with powerful generalization , using too many features in the cascade is avoided , therefore importantly training time is saved and over-fitting is avoided .
#<struct ReadData::Alignment source_numbers="29", target_numbers="", tag_name="wa">
( ii ) By using SVM classifiers with powerful generalization , using too many features in the cascade is avoided , therefore importantly training time is saved and over-fitting is avoided .
#<struct ReadData::Alignment source_numbers="30", target_numbers="", tag_name="wa">
( ii ) By using SVM classifiers with powerful generalization , using too many features in the cascade is avoided , therefore importantly training time is saved and over-fitting is avoided .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
( ii ) By using SVM classifiers with powerful generalization , using too many features in the cascade is avoided , therefore importantly training time is saved and over-fitting is avoided .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
( ii ) By using SVM classifiers with powerful generalization , using too many features in the cascade is avoided , therefore importantly training time is saved and over-fitting is avoided .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
( ii ) By using SVM classifiers with powerful generalization , using too many features in the cascade is avoided , therefore importantly training time is saved and over-fitting is avoided .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
( ii ) By using SVM classifiers with powerful generalization , using too many features in the cascade is avoided , therefore importantly training time is saved and over-fitting is avoided .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
( ii ) By using SVM classifiers with powerful generalization , using too many features in the cascade is avoided , therefore importantly training time is saved and over-fitting is avoided .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
( ii ) By using SVM classifiers with powerful generalization , using too many features in the cascade is avoided , therefore importantly training time is saved and over-fitting is avoided .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
Third , the training time of AdaBoost classifiers is shortened by using simple sampling techniques to reduce the number of features in the feature set .
#<struct ReadData::Alignment source_numbers="8", target_numbers="8,9", tag_name="wa">
Third , the training time of AdaBoost classifiers is shortened by using simple sampling techniques to reduce the number of features in the feature set .
#<struct ReadData::Alignment source_numbers="9", target_numbers="10", tag_name="wa">
Experiments will show that for rejection , using a full feature set and a sampled feature set gives the comparable performance .
#<struct ReadData::Alignment source_numbers="2", target_numbers="1", tag_name="wa">
Experiments will show that for rejection , using a full feature set and a sampled feature set gives the comparable performance .
#<struct ReadData::Alignment source_numbers="18", target_numbers="6", tag_name="wa">
Experiments will show that for rejection , using a full feature set and a sampled feature set gives the comparable performance .
#<struct ReadData::Alignment source_numbers="20", target_numbers="7", tag_name="wa">
Experiments will show that for rejection , using a full feature set and a sampled feature set gives the comparable performance .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Experiments will show that for rejection , using a full feature set and a sampled feature set gives the comparable performance .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
Experiments will show that for rejection , using a full feature set and a sampled feature set gives the comparable performance .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
Experiments will show that for rejection , using a full feature set and a sampled feature set gives the comparable performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Experiments will show that for rejection , using a full feature set and a sampled feature set gives the comparable performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Experiments will show that for rejection , using a full feature set and a sampled feature set gives the comparable performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
Experiments will show that for rejection , using a full feature set and a sampled feature set gives the comparable performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Experiments will show that for rejection , using a full feature set and a sampled feature set gives the comparable performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
Experiments will show that for rejection , using a full feature set and a sampled feature set gives the comparable performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
Along with using several SVM classifiers instead of many AdaBoost classifiers in later layers , the total training time is reduced significantly .
#<struct ReadData::Alignment source_numbers="19", target_numbers="19,20", tag_name="wa">
Along with using several SVM classifiers instead of many AdaBoost classifiers in later layers , the total training time is reduced significantly .
#<struct ReadData::Alignment source_numbers="20", target_numbers="22", tag_name="wa">
There have been several studies working on how to handle the drawbacks of Viola and Jones' system .
#<struct ReadData::Alignment source_numbers="1", target_numbers="2", tag_name="wa">
There have been several studies working on how to handle the drawbacks of Viola and Jones' system .
#<struct ReadData::Alignment source_numbers="5", target_numbers="3", tag_name="wa">
There have been several studies working on how to handle the drawbacks of Viola and Jones' system .
#<struct ReadData::Alignment source_numbers="9", target_numbers="5", tag_name="wa">
There have been several studies working on how to handle the drawbacks of Viola and Jones' system .
#<struct ReadData::Alignment source_numbers="17", target_numbers="13", tag_name="wa">
There have been several studies working on how to handle the drawbacks of Viola and Jones' system .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
There have been several studies working on how to handle the drawbacks of Viola and Jones' system .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
There have been several studies working on how to handle the drawbacks of Viola and Jones' system .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
There have been several studies working on how to handle the drawbacks of Viola and Jones' system .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
There have been several studies working on how to handle the drawbacks of Viola and Jones' system .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
There have been several studies working on how to handle the drawbacks of Viola and Jones' system .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
It is therefore very time consuming because all weak classifiers must be trained every time one feature is selected .
#<struct ReadData::Alignment source_numbers="1", target_numbers="2", tag_name="wa">
It is therefore very time consuming because all weak classifiers must be trained every time one feature is selected .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
It is therefore very time consuming because all weak classifiers must be trained every time one feature is selected .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
It is therefore very time consuming because all weak classifiers must be trained every time one feature is selected .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
It is therefore very time consuming because all weak classifiers must be trained every time one feature is selected .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
With their new proposal , weak classifiers are trained only once and features are selected by the direct feature selection method that directly maximizes the learning objective of the output classifier .
#<struct ReadData::Alignment source_numbers="28", target_numbers="1", tag_name="wa">
With their new proposal , weak classifiers are trained only once and features are selected by the direct feature selection method that directly maximizes the learning objective of the output classifier .
#<struct ReadData::Alignment source_numbers="4", target_numbers="8", tag_name="wa">
With their new proposal , weak classifiers are trained only once and features are selected by the direct feature selection method that directly maximizes the learning objective of the output classifier .
#<struct ReadData::Alignment source_numbers="21,22", target_numbers="26,27", tag_name="wa">
With their new proposal , weak classifiers are trained only once and features are selected by the direct feature selection method that directly maximizes the learning objective of the output classifier .
#<struct ReadData::Alignment source_numbers="31", target_numbers="36", tag_name="wa">
With their new proposal , weak classifiers are trained only once and features are selected by the direct feature selection method that directly maximizes the learning objective of the output classifier .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
With their new proposal , weak classifiers are trained only once and features are selected by the direct feature selection method that directly maximizes the learning objective of the output classifier .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
With their new proposal , weak classifiers are trained only once and features are selected by the direct feature selection method that directly maximizes the learning objective of the output classifier .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
With their new proposal , weak classifiers are trained only once and features are selected by the direct feature selection method that directly maximizes the learning objective of the output classifier .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
With their new proposal , weak classifiers are trained only once and features are selected by the direct feature selection method that directly maximizes the learning objective of the output classifier .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
With their new proposal , weak classifiers are trained only once and features are selected by the direct feature selection method that directly maximizes the learning objective of the output classifier .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
With their new proposal , weak classifiers are trained only once and features are selected by the direct feature selection method that directly maximizes the learning objective of the output classifier .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
Another direction is to optimally build the cascade to improve the overall performance of the cascade .
#<struct ReadData::Alignment source_numbers="9,10", target_numbers="9,10", tag_name="wa">
Another direction is to optimally build the cascade to improve the overall performance of the cascade .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
Another direction is to optimally build the cascade to improve the overall performance of the cascade .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
Another direction is to optimally build the cascade to improve the overall performance of the cascade .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
Xiao et al. [20] and Huang et al. [11] propose the boosting chain structure in which subsequent layers utilize historical information of previous layers .
#<struct ReadData::Alignment source_numbers="10", target_numbers="19", tag_name="wa">
Xiao et al. [20] and Huang et al. [11] propose the boosting chain structure in which subsequent layers utilize historical information of previous layers .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Discrete AdaBoost uses a binary weak classifier that is too weak to boost in the case of the hard distinguished dataset .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
Discrete AdaBoost uses a binary weak classifier that is too weak to boost in the case of the hard distinguished dataset .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Studies based on RealBoost [26] , such as [12] ,[10] ,[27] ,[11] , introduced new kinds of weak classifiers that are stronger than binary weak classifiers .
#<struct ReadData::Alignment source_numbers="12", target_numbers="16", tag_name="wa">
Studies based on RealBoost [26] , such as [12] ,[10] ,[27] ,[11] , introduced new kinds of weak classifiers that are stronger than binary weak classifiers .
#<struct ReadData::Alignment source_numbers="17", target_numbers="21", tag_name="wa">
Studies based on RealBoost [26] , such as [12] ,[10] ,[27] ,[11] , introduced new kinds of weak classifiers that are stronger than binary weak classifiers .
#<struct ReadData::Alignment source_numbers="18", target_numbers="22", tag_name="wa">
Studies based on RealBoost [26] , such as [12] ,[10] ,[27] ,[11] , introduced new kinds of weak classifiers that are stronger than binary weak classifiers .
#<struct ReadData::Alignment source_numbers="24", target_numbers="28", tag_name="wa">
Studies based on RealBoost [26] , such as [12] ,[10] ,[27] ,[11] , introduced new kinds of weak classifiers that are stronger than binary weak classifiers .
#<struct ReadData::Alignment source_numbers="25", target_numbers="29", tag_name="wa">
Studies based on RealBoost [26] , such as [12] ,[10] ,[27] ,[11] , introduced new kinds of weak classifiers that are stronger than binary weak classifiers .
#<struct ReadData::Alignment source_numbers="26", target_numbers="30", tag_name="wa">
Studies based on RealBoost [26] , such as [12] ,[10] ,[27] ,[11] , introduced new kinds of weak classifiers that are stronger than binary weak classifiers .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Studies based on RealBoost [26] , such as [12] ,[10] ,[27] ,[11] , introduced new kinds of weak classifiers that are stronger than binary weak classifiers .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Studies based on RealBoost [26] , such as [12] ,[10] ,[27] ,[11] , introduced new kinds of weak classifiers that are stronger than binary weak classifiers .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
Studies based on RealBoost [26] , such as [12] ,[10] ,[27] ,[11] , introduced new kinds of weak classifiers that are stronger than binary weak classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Studies based on RealBoost [26] , such as [12] ,[10] ,[27] ,[11] , introduced new kinds of weak classifiers that are stronger than binary weak classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Studies based on RealBoost [26] , such as [12] ,[10] ,[27] ,[11] , introduced new kinds of weak classifiers that are stronger than binary weak classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
Studies based on RealBoost [26] , such as [12] ,[10] ,[27] ,[11] , introduced new kinds of weak classifiers that are stronger than binary weak classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
Studies based on RealBoost [26] , such as [12] ,[10] ,[27] ,[11] , introduced new kinds of weak classifiers that are stronger than binary weak classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Studies based on RealBoost [26] , such as [12] ,[10] ,[27] ,[11] , introduced new kinds of weak classifiers that are stronger than binary weak classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Studies based on RealBoost [26] , such as [12] ,[10] ,[27] ,[11] , introduced new kinds of weak classifiers that are stronger than binary weak classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
New real-valued weak classifiers can effectively discriminate face and non-face distributions and , in consequence , the total number of features used also reduces dramatically .
#<struct ReadData::Alignment source_numbers="23", target_numbers="22", tag_name="wa">
New real-valued weak classifiers can effectively discriminate face and non-face distributions and , in consequence , the total number of features used also reduces dramatically .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
New real-valued weak classifiers can effectively discriminate face and non-face distributions and , in consequence , the total number of features used also reduces dramatically .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
New real-valued weak classifiers can effectively discriminate face and non-face distributions and , in consequence , the total number of features used also reduces dramatically .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
New real-valued weak classifiers can effectively discriminate face and non-face distributions and , in consequence , the total number of features used also reduces dramatically .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
New real-valued weak classifiers can effectively discriminate face and non-face distributions and , in consequence , the total number of features used also reduces dramatically .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
New real-valued weak classifiers can effectively discriminate face and non-face distributions and , in consequence , the total number of features used also reduces dramatically .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
New real-valued weak classifiers can effectively discriminate face and non-face distributions and , in consequence , the total number of features used also reduces dramatically .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
New real-valued weak classifiers can effectively discriminate face and non-face distributions and , in consequence , the total number of features used also reduces dramatically .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
Face detection systems such as [27] ,[11] only use around 800 features .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
Face detection systems such as [27] ,[11] only use around 800 features .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Face detection systems such as [27] ,[11] only use around 800 features .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Small number of bins might not well approximate the real distribution while large number of bins might cause over-fitting , increase computation time and waste storage space .
#<struct ReadData::Alignment source_numbers="27", target_numbers="31", tag_name="wa">
Small number of bins might not well approximate the real distribution while large number of bins might cause over-fitting , increase computation time and waste storage space .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Small number of bins might not well approximate the real distribution while large number of bins might cause over-fitting , increase computation time and waste storage space .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
Small number of bins might not well approximate the real distribution while large number of bins might cause over-fitting , increase computation time and waste storage space .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Small number of bins might not well approximate the real distribution while large number of bins might cause over-fitting , increase computation time and waste storage space .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Small number of bins might not well approximate the real distribution while large number of bins might cause over-fitting , increase computation time and waste storage space .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
Small number of bins might not well approximate the real distribution while large number of bins might cause over-fitting , increase computation time and waste storage space .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
Actually , our system can benefit from this approach when building the rejection stage and thus also reduce the training time much more .
#<struct ReadData::Alignment source_numbers="17", target_numbers="17", tag_name="wa">
Actually , our system can benefit from this approach when building the rejection stage and thus also reduce the training time much more .
#<struct ReadData::Alignment source_numbers="16", target_numbers="22", tag_name="wa">
Actually , our system can benefit from this approach when building the rejection stage and thus also reduce the training time much more .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Actually , our system can benefit from this approach when building the rejection stage and thus also reduce the training time much more .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
Actually , our system can benefit from this approach when building the rejection stage and thus also reduce the training time much more .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
Actually , our system can benefit from this approach when building the rejection stage and thus also reduce the training time much more .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Actually , our system can benefit from this approach when building the rejection stage and thus also reduce the training time much more .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
Actually , our system can benefit from this approach when building the rejection stage and thus also reduce the training time much more .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
The proposed face detection system consists of three stages that classify a 24x24 pixel window as either a face or a non-face .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
The proposed face detection system consists of three stages that classify a 24x24 pixel window as either a face or a non-face .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
The proposed face detection system consists of three stages that classify a 24x24 pixel window as either a face or a non-face .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
To detect faces of different sizes and locations , the detector is applied at every location and scale in the input image with a scale factor of 1 .2 , which is similar to the other approaches [5] ,[6] ,[9] .
#<struct ReadData::Alignment source_numbers="38", target_numbers="", tag_name="wa">
To detect faces of different sizes and locations , the detector is applied at every location and scale in the input image with a scale factor of 1 .2 , which is similar to the other approaches [5] ,[6] ,[9] .
#<struct ReadData::Alignment source_numbers="39", target_numbers="", tag_name="wa">
To detect faces of different sizes and locations , the detector is applied at every location and scale in the input image with a scale factor of 1 .2 , which is similar to the other approaches [5] ,[6] ,[9] .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
To detect faces of different sizes and locations , the detector is applied at every location and scale in the input image with a scale factor of 1 .2 , which is similar to the other approaches [5] ,[6] ,[9] .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
To detect faces of different sizes and locations , the detector is applied at every location and scale in the input image with a scale factor of 1 .2 , which is similar to the other approaches [5] ,[6] ,[9] .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
To detect faces of different sizes and locations , the detector is applied at every location and scale in the input image with a scale factor of 1 .2 , which is similar to the other approaches [5] ,[6] ,[9] .
#<struct ReadData::Alignment source_numbers="", target_numbers="40", tag_name="wa">
If a 36x36 window is detected as the existence of a face , 144 ( i.e. 12x12 ) likely face positions are collected and passed to the next stage .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
If a 36x36 window is detected as the existence of a face , 144 ( i.e. 12x12 ) likely face positions are collected and passed to the next stage .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
If a 36x36 window is detected as the existence of a face , 144 ( i.e. 12x12 ) likely face positions are collected and passed to the next stage .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
This is done by taking advantages of Viola and Jones' approach [1] , in which Haar wavelet features and the cascaded AdaBoost classifiers are extremely fast in computation .
#<struct ReadData::Alignment source_numbers="5,6", target_numbers="5,6", tag_name="wa">
This is done by taking advantages of Viola and Jones' approach [1] , in which Haar wavelet features and the cascaded AdaBoost classifiers are extremely fast in computation .
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
This is done by taking advantages of Viola and Jones' approach [1] , in which Haar wavelet features and the cascaded AdaBoost classifiers are extremely fast in computation .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
The reason why the fist stage , which is a cascade of \MATH classifiers , is added is to decrease the number of analyzed patterns .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
The reason why the fist stage , which is a cascade of \MATH classifiers , is added is to decrease the number of analyzed patterns .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
The reason why the fist stage , which is a cascade of \MATH classifiers , is added is to decrease the number of analyzed patterns .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
The reason why the fist stage , which is a cascade of \MATH classifiers , is added is to decrease the number of analyzed patterns .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
The reason why the fist stage , which is a cascade of \MATH classifiers , is added is to decrease the number of analyzed patterns .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
The reason why the fist stage , which is a cascade of \MATH classifiers , is added is to decrease the number of analyzed patterns .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
The \MATH window is chosen in accordance with the idea from [5] stated that the classifier can be trained to be invariant to translation by up to \MATH of original window size .
#<struct ReadData::Alignment source_numbers="9,10", target_numbers="9,10", tag_name="wa">
The \MATH window is chosen in accordance with the idea from [5] stated that the classifier can be trained to be invariant to translation by up to \MATH of original window size .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
With this flexible classifier , the moving step size can be increased up to 12 pixels that reduce dramatically number of analyzed patterns .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
With this flexible classifier , the moving step size can be increased up to 12 pixels that reduce dramatically number of analyzed patterns .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
Efficiency of this stage will be discussed further in section 6 .3 .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Efficiency of this stage will be discussed further in section 6 .3 .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
The last stage is a cascade of non-linear SVM classifiers that reuses features that have been selected by AdaBoost in the second stage classifier .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
The last stage is a cascade of non-linear SVM classifiers that reuses features that have been selected by AdaBoost in the second stage classifier .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
In our experiments , only 100 features are used and hence it is faster than using any pixel-based SVM classifiers [8] ,[9] .
#<struct ReadData::Alignment source_numbers="8", target_numbers="8", tag_name="wa">
In our experiments , only 100 features are used and hence it is faster than using any pixel-based SVM classifiers [8] ,[9] .
#<struct ReadData::Alignment source_numbers="11", target_numbers="14", tag_name="wa">
In our experiments , only 100 features are used and hence it is faster than using any pixel-based SVM classifiers [8] ,[9] .
#<struct ReadData::Alignment source_numbers="7", target_numbers="16,17", tag_name="wa">
In our experiments , only 100 features are used and hence it is faster than using any pixel-based SVM classifiers [8] ,[9] .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
In our experiments , only 100 features are used and hence it is faster than using any pixel-based SVM classifiers [8] ,[9] .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
In our experiments , only 100 features are used and hence it is faster than using any pixel-based SVM classifiers [8] ,[9] .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
In our experiments , only 100 features are used and hence it is faster than using any pixel-based SVM classifiers [8] ,[9] .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
In our experiments , only 100 features are used and hence it is faster than using any pixel-based SVM classifiers [8] ,[9] .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
In our experiments , only 100 features are used and hence it is faster than using any pixel-based SVM classifiers [8] ,[9] .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
In our experiments , only 100 features are used and hence it is faster than using any pixel-based SVM classifiers [8] ,[9] .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
In our experiments , only 100 features are used and hence it is faster than using any pixel-based SVM classifiers [8] ,[9] .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
In our experiments , only 100 features are used and hence it is faster than using any pixel-based SVM classifiers [8] ,[9] .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
In our experiments , only 100 features are used and hence it is faster than using any pixel-based SVM classifiers [8] ,[9] .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
In our experiments , only 100 features are used and hence it is faster than using any pixel-based SVM classifiers [8] ,[9] .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
In our experiments , only 100 features are used and hence it is faster than using any pixel-based SVM classifiers [8] ,[9] .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
The same feature set as proposed in [1] is used ( cf. Figure 4 ) .
#<struct ReadData::Alignment source_numbers="8", target_numbers="7", tag_name="wa">
The same feature set as proposed in [1] is used ( cf. Figure 4 ) .
#<struct ReadData::Alignment source_numbers="9", target_numbers="8", tag_name="wa">
The same feature set as proposed in [1] is used ( cf. Figure 4 ) .
#<struct ReadData::Alignment source_numbers="11", target_numbers="10", tag_name="wa">
The same feature set as proposed in [1] is used ( cf. Figure 4 ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
It consists of four kinds of features modeled from adjacent basic rectangles with the same size and shape .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
It consists of four kinds of features modeled from adjacent basic rectangles with the same size and shape .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
Each feature is parameterized by four parameters : the position within the window \MATH , width \MATH and height \MATH ( cf. Figure 5 ) .
#<struct ReadData::Alignment source_numbers="21", target_numbers="24", tag_name="wa">
Each feature is parameterized by four parameters : the position within the window \MATH , width \MATH and height \MATH ( cf. Figure 5 ) .
#<struct ReadData::Alignment source_numbers="22", target_numbers="26", tag_name="wa">
Each feature is parameterized by four parameters : the position within the window \MATH , width \MATH and height \MATH ( cf. Figure 5 ) .
#<struct ReadData::Alignment source_numbers="23", target_numbers="27", tag_name="wa">
Each feature is parameterized by four parameters : the position within the window \MATH , width \MATH and height \MATH ( cf. Figure 5 ) .
#<struct ReadData::Alignment source_numbers="24", target_numbers="28", tag_name="wa">
Each feature is parameterized by four parameters : the position within the window \MATH , width \MATH and height \MATH ( cf. Figure 5 ) .
#<struct ReadData::Alignment source_numbers="25", target_numbers="29", tag_name="wa">
Each feature is parameterized by four parameters : the position within the window \MATH , width \MATH and height \MATH ( cf. Figure 5 ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
Each feature is parameterized by four parameters : the position within the window \MATH , width \MATH and height \MATH ( cf. Figure 5 ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
By using integral image definition [1] , these rectangle feature values can be computed extremely quickly .
#<struct ReadData::Alignment source_numbers="9", target_numbers="8", tag_name="wa">
By using integral image definition [1] , these rectangle feature values can be computed extremely quickly .
#<struct ReadData::Alignment source_numbers="10", target_numbers="9", tag_name="wa">
By using integral image definition [1] , these rectangle feature values can be computed extremely quickly .
#<struct ReadData::Alignment source_numbers="7", target_numbers="11", tag_name="wa">
By using integral image definition [1] , these rectangle feature values can be computed extremely quickly .
#<struct ReadData::Alignment source_numbers="8", target_numbers="12", tag_name="wa">
By using integral image definition [1] , these rectangle feature values can be computed extremely quickly .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
By using integral image definition [1] , these rectangle feature values can be computed extremely quickly .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Given \MATH weak classifiers \MATH learned through \MATH rounds of boosting , the strong classifier is formed by a linear combination : \MATH where \MATH are coefficients found in the boosting process .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
Each weak classifier \MATH is associated with a feature \MATH and a threshold \MATH such that the number of incorrect classified examples corresponding to this weak classifier is minimized : \MATH , where polarity \MATH indicates the direction of the inequality sign .
#<struct ReadData::Alignment source_numbers="39", target_numbers="24", tag_name="wa">
Each weak classifier \MATH is associated with a feature \MATH and a threshold \MATH such that the number of incorrect classified examples corresponding to this weak classifier is minimized : \MATH , where polarity \MATH indicates the direction of the inequality sign .
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
Each weak classifier \MATH is associated with a feature \MATH and a threshold \MATH such that the number of incorrect classified examples corresponding to this weak classifier is minimized : \MATH , where polarity \MATH indicates the direction of the inequality sign .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
The error of each weak classifier is measured with respect to the set of weights over each example of the training set \MATH , where \MATH and \MATH are the weight and the label of the training example \MATH , respectively .
#<struct ReadData::Alignment source_numbers="39", target_numbers="", tag_name="wa">
The error of each weak classifier is measured with respect to the set of weights over each example of the training set \MATH , where \MATH and \MATH are the weight and the label of the training example \MATH , respectively .
#<struct ReadData::Alignment source_numbers="40", target_numbers="", tag_name="wa">
The error of each weak classifier is measured with respect to the set of weights over each example of the training set \MATH , where \MATH and \MATH are the weight and the label of the training example \MATH , respectively .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
Training cascaded classifiers that can achieve both good detection rate and less computation time is quite complex , because a higher detection rate requires more features , but more features are correspondent to more time for evaluation .
#<struct ReadData::Alignment source_numbers="31", target_numbers="29", tag_name="wa">
Training cascaded classifiers that can achieve both good detection rate and less computation time is quite complex , because a higher detection rate requires more features , but more features are correspondent to more time for evaluation .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
Training cascaded classifiers that can achieve both good detection rate and less computation time is quite complex , because a higher detection rate requires more features , but more features are correspondent to more time for evaluation .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
Training cascaded classifiers that can achieve both good detection rate and less computation time is quite complex , because a higher detection rate requires more features , but more features are correspondent to more time for evaluation .
#<struct ReadData::Alignment source_numbers="30", target_numbers="", tag_name="wa">
Training cascaded classifiers that can achieve both good detection rate and less computation time is quite complex , because a higher detection rate requires more features , but more features are correspondent to more time for evaluation .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Training cascaded classifiers that can achieve both good detection rate and less computation time is quite complex , because a higher detection rate requires more features , but more features are correspondent to more time for evaluation .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
Viola and Jones [1] stated that , if the layer classifier could achieve the predefined target goals after 200 features are used , the training process will stop and a new layer will be added .
#<struct ReadData::Alignment source_numbers="12", target_numbers="12", tag_name="wa">
Viola and Jones [1] stated that , if the layer classifier could achieve the predefined target goals after 200 features are used , the training process will stop and a new layer will be added .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
Viola and Jones [1] stated that , if the layer classifier could achieve the predefined target goals after 200 features are used , the training process will stop and a new layer will be added .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
1 . <section label= " SVM Classifier " >
#<struct ReadData::Alignment source_numbers="8", target_numbers="8", tag_name="wa">
It has been very efficiently proved in many pattern recognition applications [29] ,[8] ,[9] .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
It has been very efficiently proved in many pattern recognition applications [29] ,[8] ,[9] .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
It has been very efficiently proved in many pattern recognition applications [29] ,[8] ,[9] .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
It has been very efficiently proved in many pattern recognition applications [29] ,[8] ,[9] .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
It has been very efficiently proved in many pattern recognition applications [29] ,[8] ,[9] .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
It has been very efficiently proved in many pattern recognition applications [29] ,[8] ,[9] .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
The form of SVM classifiers is : \MATH where : \MATH is the d-dimensional vector of an observation example , \MATH is a class label , and \MATH is the vector of the \MATH training example .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
It is important to choose the appropriate kernel and parameter \MATH in order to to obtain the robust SVM classifier .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
Although many kernels have been introduced by researchers , the following four kernels are commonly used : \MATH where \MATH and \MATH are kernel parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
Compared to AdaBoost classifiers , SVM classifiers run much slower in running because of the large number of support vectors and heavy kernel computation .
#<struct ReadData::Alignment source_numbers="9", target_numbers="9,10", tag_name="wa">
Compared to AdaBoost classifiers , SVM classifiers run much slower in running because of the large number of support vectors and heavy kernel computation .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Compared to AdaBoost classifiers , SVM classifiers run much slower in running because of the large number of support vectors and heavy kernel computation .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
For training , we collected 7 ,500 , 24x24-size face patterns from the Internet .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
For training , we collected 7 ,500 , 24x24-size face patterns from the Internet .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
For training , we collected 7 ,500 , 24x24-size face patterns from the Internet .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
For training , we collected 7 ,500 , 24x24-size face patterns from the Internet .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
For training , we collected 7 ,500 , 24x24-size face patterns from the Internet .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
To compare the performance of classifiers , we have implemented a fully cascade of classifiers trained by AdaBoost , similar to that used by Viola and Jones [1] .
#<struct ReadData::Alignment source_numbers="9", target_numbers="8", tag_name="wa">
To compare the performance of classifiers , we have implemented a fully cascade of classifiers trained by AdaBoost , similar to that used by Viola and Jones [1] .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
The minimum of the detection rate is \MATH , the maximum of the false positive rate is \MATH and the maximum of the number of features in each layer is 200 .
#<struct ReadData::Alignment source_numbers="15,16", target_numbers="6", tag_name="wa">
The minimum of the detection rate is \MATH , the maximum of the false positive rate is \MATH and the maximum of the number of features in each layer is 200 .
#<struct ReadData::Alignment source_numbers="17", target_numbers="7", tag_name="wa">
The minimum of the detection rate is \MATH , the maximum of the false positive rate is \MATH and the maximum of the number of features in each layer is 200 .
#<struct ReadData::Alignment source_numbers="6", target_numbers="15,16", tag_name="wa">
The minimum of the detection rate is \MATH , the maximum of the false positive rate is \MATH and the maximum of the number of features in each layer is 200 .
#<struct ReadData::Alignment source_numbers="7", target_numbers="17", tag_name="wa">
The minimum of the detection rate is \MATH , the maximum of the false positive rate is \MATH and the maximum of the number of features in each layer is 200 .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
If \MATH is the number of Haar wavelet features and \MATH is the number of training patterns , the learning time of AdaBoost to train \MATH weak classifiers is roughly[1] .
#<struct ReadData::Alignment source_numbers="29", target_numbers="", tag_name="wa">
If \MATH is the number of Haar wavelet features and \MATH is the number of training patterns , the learning time of AdaBoost to train \MATH weak classifiers is roughly[1] .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
If \MATH is the number of Haar wavelet features and \MATH is the number of training patterns , the learning time of AdaBoost to train \MATH weak classifiers is roughly[1] .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
As mentioned in section 4 .1 , each feature is parameterized by a tuple of four parameters \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
As mentioned in section 4 .1 , each feature is parameterized by a tuple of four parameters \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
As mentioned in section 4 .1 , each feature is parameterized by a tuple of four parameters \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
As mentioned in section 4 .1 , each feature is parameterized by a tuple of four parameters \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
As mentioned in section 4 .1 , each feature is parameterized by a tuple of four parameters \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
As mentioned in section 4 .1 , each feature is parameterized by a tuple of four parameters \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
As mentioned in section 4 .1 , each feature is parameterized by a tuple of four parameters \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
As mentioned in section 4 .1 , each feature is parameterized by a tuple of four parameters \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
As mentioned in section 4 .1 , each feature is parameterized by a tuple of four parameters \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
As mentioned in section 4 .1 , each feature is parameterized by a tuple of four parameters \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
As mentioned in section 4 .1 , each feature is parameterized by a tuple of four parameters \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
As mentioned in section 4 .1 , each feature is parameterized by a tuple of four parameters \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
As mentioned in section 4 .1 , each feature is parameterized by a tuple of four parameters \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
As mentioned in section 4 .1 , each feature is parameterized by a tuple of four parameters \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
As mentioned in section 4 .1 , each feature is parameterized by a tuple of four parameters \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
As mentioned in section 4 .1 , each feature is parameterized by a tuple of four parameters \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
As mentioned in section 4 .1 , each feature is parameterized by a tuple of four parameters \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
As mentioned in section 4 .1 , each feature is parameterized by a tuple of four parameters \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
As mentioned in section 4 .1 , each feature is parameterized by a tuple of four parameters \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
As mentioned in section 4 .1 , each feature is parameterized by a tuple of four parameters \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
As mentioned in section 4 .1 , each feature is parameterized by a tuple of four parameters \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
As mentioned in section 4 .1 , each feature is parameterized by a tuple of four parameters \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="40", tag_name="wa">
As mentioned in section 4 .1 , each feature is parameterized by a tuple of four parameters \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="41", tag_name="wa">
As mentioned in section 4 .1 , each feature is parameterized by a tuple of four parameters \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="42", tag_name="wa">
As mentioned in section 4 .1 , each feature is parameterized by a tuple of four parameters \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="43", tag_name="wa">
As mentioned in section 4 .1 , each feature is parameterized by a tuple of four parameters \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="44", tag_name="wa">
As mentioned in section 4 .1 , each feature is parameterized by a tuple of four parameters \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="45", tag_name="wa">
As mentioned in section 4 .1 , each feature is parameterized by a tuple of four parameters \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="46", tag_name="wa">
As mentioned in section 4 .1 , each feature is parameterized by a tuple of four parameters \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="47", tag_name="wa">
As mentioned in section 4 .1 , each feature is parameterized by a tuple of four parameters \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="48", tag_name="wa">
As mentioned in section 4 .1 , each feature is parameterized by a tuple of four parameters \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="49", tag_name="wa">
As mentioned in section 4 .1 , each feature is parameterized by a tuple of four parameters \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="50", tag_name="wa">
As mentioned in section 4 .1 , each feature is parameterized by a tuple of four parameters \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="51", tag_name="wa">
As mentioned in section 4 .1 , each feature is parameterized by a tuple of four parameters \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="52", tag_name="wa">
As mentioned in section 4 .1 , each feature is parameterized by a tuple of four parameters \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="53", tag_name="wa">
As mentioned in section 4 .1 , each feature is parameterized by a tuple of four parameters \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="54", tag_name="wa">
As mentioned in section 4 .1 , each feature is parameterized by a tuple of four parameters \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="55", tag_name="wa">
As mentioned in section 4 .1 , each feature is parameterized by a tuple of four parameters \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="56", tag_name="wa">
As mentioned in section 4 .1 , each feature is parameterized by a tuple of four parameters \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="57", tag_name="wa">
As mentioned in section 4 .1 , each feature is parameterized by a tuple of four parameters \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="58", tag_name="wa">
In the other hand , a feature set is parameterized by \MATH .
#<struct ReadData::Alignment source_numbers="4", target_numbers="8", tag_name="wa">
In the other hand , a feature set is parameterized by \MATH .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
In the other hand , a feature set is parameterized by \MATH .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
In the other hand , a feature set is parameterized by \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
In the other hand , a feature set is parameterized by \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
In the other hand , a feature set is parameterized by \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
We carried out experiments to compare the performance of classifiers trained on these two feature sets : the full feature set \MATH containing 134 ,736 features and the reduced feature set \MATH containing 14 ,807 features ( excluding features with the small size ) .
#<struct ReadData::Alignment source_numbers="40,41", target_numbers="41,42", tag_name="wa">
We carried out experiments to compare the performance of classifiers trained on these two feature sets : the full feature set \MATH containing 134 ,736 features and the reduced feature set \MATH containing 14 ,807 features ( excluding features with the small size ) .
#<struct ReadData::Alignment source_numbers="39", target_numbers="", tag_name="wa">
We carried out experiments to compare the performance of classifiers trained on these two feature sets : the full feature set \MATH containing 134 ,736 features and the reduced feature set \MATH containing 14 ,807 features ( excluding features with the small size ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
We carried out experiments to compare the performance of classifiers trained on these two feature sets : the full feature set \MATH containing 134 ,736 features and the reduced feature set \MATH containing 14 ,807 features ( excluding features with the small size ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
The classifier 's threshold is changed to meet the detection rate of \MATH .
#<struct ReadData::Alignment source_numbers="4", target_numbers="4", tag_name="wa">
The classifier 's threshold is changed to meet the detection rate of \MATH .
#<struct ReadData::Alignment source_numbers="5", target_numbers="5", tag_name="wa">
Rejection performance is evaluated through the false positive rate on a validation test set which contains 500 ,000 non-face patterns .
#<struct ReadData::Alignment source_numbers="2", target_numbers="2", tag_name="wa">
Rejection performance is evaluated through the false positive rate on a validation test set which contains 500 ,000 non-face patterns .
#<struct ReadData::Alignment source_numbers="3", target_numbers="3", tag_name="wa">
Rejection performance is evaluated through the false positive rate on a validation test set which contains 500 ,000 non-face patterns .
#<struct ReadData::Alignment source_numbers="14,15", target_numbers="14,15", tag_name="wa">
The result shown in Figure 10 indicates that the performances of these two classifiers are no different , especially when the number of features is large enough , for example , more than 50 .
#<struct ReadData::Alignment source_numbers="1", target_numbers="1", tag_name="wa">
The result shown in Figure 10 indicates that the performances of these two classifiers are no different , especially when the number of features is large enough , for example , more than 50 .
#<struct ReadData::Alignment source_numbers="6,7", target_numbers="6,7", tag_name="wa">
The result shown in Figure 10 indicates that the performances of these two classifiers are no different , especially when the number of features is large enough , for example , more than 50 .
#<struct ReadData::Alignment source_numbers="14,15", target_numbers="14,15", tag_name="wa">
As a result , by using the reduced feature set , the training time can be shortened approximately to one ninth .
#<struct ReadData::Alignment source_numbers="20", target_numbers="19", tag_name="wa">
As a result , by using the reduced feature set , the training time can be shortened approximately to one ninth .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
Our another experiment has shown that , for similar performance , the AdaBoost classifier trained on the reduced feature set that uses larger sampling step sizes requires more features than that trained on the full feature set .
#<struct ReadData::Alignment source_numbers="3,4", target_numbers="4", tag_name="wa">
Our another experiment has shown that , for similar performance , the AdaBoost classifier trained on the reduced feature set that uses larger sampling step sizes requires more features than that trained on the full feature set .
#<struct ReadData::Alignment source_numbers="11", target_numbers="53", tag_name="wa">
Our another experiment has shown that , for similar performance , the AdaBoost classifier trained on the reduced feature set that uses larger sampling step sizes requires more features than that trained on the full feature set .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Our another experiment has shown that , for similar performance , the AdaBoost classifier trained on the reduced feature set that uses larger sampling step sizes requires more features than that trained on the full feature set .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Our another experiment has shown that , for similar performance , the AdaBoost classifier trained on the reduced feature set that uses larger sampling step sizes requires more features than that trained on the full feature set .
#<struct ReadData::Alignment source_numbers="30", target_numbers="", tag_name="wa">
Our another experiment has shown that , for similar performance , the AdaBoost classifier trained on the reduced feature set that uses larger sampling step sizes requires more features than that trained on the full feature set .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Our another experiment has shown that , for similar performance , the AdaBoost classifier trained on the reduced feature set that uses larger sampling step sizes requires more features than that trained on the full feature set .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Our another experiment has shown that , for similar performance , the AdaBoost classifier trained on the reduced feature set that uses larger sampling step sizes requires more features than that trained on the full feature set .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Our another experiment has shown that , for similar performance , the AdaBoost classifier trained on the reduced feature set that uses larger sampling step sizes requires more features than that trained on the full feature set .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
Our another experiment has shown that , for similar performance , the AdaBoost classifier trained on the reduced feature set that uses larger sampling step sizes requires more features than that trained on the full feature set .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
Our another experiment has shown that , for similar performance , the AdaBoost classifier trained on the reduced feature set that uses larger sampling step sizes requires more features than that trained on the full feature set .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
Our another experiment has shown that , for similar performance , the AdaBoost classifier trained on the reduced feature set that uses larger sampling step sizes requires more features than that trained on the full feature set .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
Our another experiment has shown that , for similar performance , the AdaBoost classifier trained on the reduced feature set that uses larger sampling step sizes requires more features than that trained on the full feature set .
#<struct ReadData::Alignment source_numbers="", target_numbers="40", tag_name="wa">
Our another experiment has shown that , for similar performance , the AdaBoost classifier trained on the reduced feature set that uses larger sampling step sizes requires more features than that trained on the full feature set .
#<struct ReadData::Alignment source_numbers="", target_numbers="41", tag_name="wa">
Our another experiment has shown that , for similar performance , the AdaBoost classifier trained on the reduced feature set that uses larger sampling step sizes requires more features than that trained on the full feature set .
#<struct ReadData::Alignment source_numbers="", target_numbers="42", tag_name="wa">
Our another experiment has shown that , for similar performance , the AdaBoost classifier trained on the reduced feature set that uses larger sampling step sizes requires more features than that trained on the full feature set .
#<struct ReadData::Alignment source_numbers="", target_numbers="43", tag_name="wa">
Our another experiment has shown that , for similar performance , the AdaBoost classifier trained on the reduced feature set that uses larger sampling step sizes requires more features than that trained on the full feature set .
#<struct ReadData::Alignment source_numbers="", target_numbers="44", tag_name="wa">
Our another experiment has shown that , for similar performance , the AdaBoost classifier trained on the reduced feature set that uses larger sampling step sizes requires more features than that trained on the full feature set .
#<struct ReadData::Alignment source_numbers="", target_numbers="45", tag_name="wa">
Our another experiment has shown that , for similar performance , the AdaBoost classifier trained on the reduced feature set that uses larger sampling step sizes requires more features than that trained on the full feature set .
#<struct ReadData::Alignment source_numbers="", target_numbers="46", tag_name="wa">
Our another experiment has shown that , for similar performance , the AdaBoost classifier trained on the reduced feature set that uses larger sampling step sizes requires more features than that trained on the full feature set .
#<struct ReadData::Alignment source_numbers="", target_numbers="47", tag_name="wa">
Our another experiment has shown that , for similar performance , the AdaBoost classifier trained on the reduced feature set that uses larger sampling step sizes requires more features than that trained on the full feature set .
#<struct ReadData::Alignment source_numbers="", target_numbers="48", tag_name="wa">
Our another experiment has shown that , for similar performance , the AdaBoost classifier trained on the reduced feature set that uses larger sampling step sizes requires more features than that trained on the full feature set .
#<struct ReadData::Alignment source_numbers="", target_numbers="49", tag_name="wa">
Our another experiment has shown that , for similar performance , the AdaBoost classifier trained on the reduced feature set that uses larger sampling step sizes requires more features than that trained on the full feature set .
#<struct ReadData::Alignment source_numbers="", target_numbers="50", tag_name="wa">
Our another experiment has shown that , for similar performance , the AdaBoost classifier trained on the reduced feature set that uses larger sampling step sizes requires more features than that trained on the full feature set .
#<struct ReadData::Alignment source_numbers="", target_numbers="51", tag_name="wa">
Our another experiment has shown that , for similar performance , the AdaBoost classifier trained on the reduced feature set that uses larger sampling step sizes requires more features than that trained on the full feature set .
#<struct ReadData::Alignment source_numbers="", target_numbers="52", tag_name="wa">
Our another experiment has shown that , for similar performance , the AdaBoost classifier trained on the reduced feature set that uses larger sampling step sizes requires more features than that trained on the full feature set .
#<struct ReadData::Alignment source_numbers="", target_numbers="54", tag_name="wa">
Our another experiment has shown that , for similar performance , the AdaBoost classifier trained on the reduced feature set that uses larger sampling step sizes requires more features than that trained on the full feature set .
#<struct ReadData::Alignment source_numbers="", target_numbers="55", tag_name="wa">
Our another experiment has shown that , for similar performance , the AdaBoost classifier trained on the reduced feature set that uses larger sampling step sizes requires more features than that trained on the full feature set .
#<struct ReadData::Alignment source_numbers="", target_numbers="56", tag_name="wa">
Our another experiment has shown that , for similar performance , the AdaBoost classifier trained on the reduced feature set that uses larger sampling step sizes requires more features than that trained on the full feature set .
#<struct ReadData::Alignment source_numbers="", target_numbers="57", tag_name="wa">
Our another experiment has shown that , for similar performance , the AdaBoost classifier trained on the reduced feature set that uses larger sampling step sizes requires more features than that trained on the full feature set .
#<struct ReadData::Alignment source_numbers="", target_numbers="58", tag_name="wa">
Our another experiment has shown that , for similar performance , the AdaBoost classifier trained on the reduced feature set that uses larger sampling step sizes requires more features than that trained on the full feature set .
#<struct ReadData::Alignment source_numbers="", target_numbers="59", tag_name="wa">
By taking advantage of simplification in training classifiers only for rejection demonstrated in section 6 .2 , training this cascade only uses the feature set generated from a 36x36 window with sampling parameters \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
Since a 36x36 face sample contains a lot of background outside the 24x24 face region while the classifier is required to be fast and to keep all possible face regions , training parameters are set as follows : the minimum detection rate of \MATH and maximum of false positive rate of \MATH .
#<struct ReadData::Alignment source_numbers="6", target_numbers="6", tag_name="wa">
Since a 36x36 face sample contains a lot of background outside the 24x24 face region while the classifier is required to be fast and to keep all possible face regions , training parameters are set as follows : the minimum detection rate of \MATH and maximum of false positive rate of \MATH .
#<struct ReadData::Alignment source_numbers="7,8", target_numbers="7,8", tag_name="wa">
Since a 36x36 face sample contains a lot of background outside the 24x24 face region while the classifier is required to be fast and to keep all possible face regions , training parameters are set as follows : the minimum detection rate of \MATH and maximum of false positive rate of \MATH .
#<struct ReadData::Alignment source_numbers="50", target_numbers="9", tag_name="wa">
Since a 36x36 face sample contains a lot of background outside the 24x24 face region while the classifier is required to be fast and to keep all possible face regions , training parameters are set as follows : the minimum detection rate of \MATH and maximum of false positive rate of \MATH .
#<struct ReadData::Alignment source_numbers="44", target_numbers="16", tag_name="wa">
Since a 36x36 face sample contains a lot of background outside the 24x24 face region while the classifier is required to be fast and to keep all possible face regions , training parameters are set as follows : the minimum detection rate of \MATH and maximum of false positive rate of \MATH .
#<struct ReadData::Alignment source_numbers="38,39", target_numbers="32,33", tag_name="wa">
Since a 36x36 face sample contains a lot of background outside the 24x24 face region while the classifier is required to be fast and to keep all possible face regions , training parameters are set as follows : the minimum detection rate of \MATH and maximum of false positive rate of \MATH .
#<struct ReadData::Alignment source_numbers="35,36", target_numbers="47", tag_name="wa">
Since a 36x36 face sample contains a lot of background outside the 24x24 face region while the classifier is required to be fast and to keep all possible face regions , training parameters are set as follows : the minimum detection rate of \MATH and maximum of false positive rate of \MATH .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
Since a 36x36 face sample contains a lot of background outside the 24x24 face region while the classifier is required to be fast and to keep all possible face regions , training parameters are set as follows : the minimum detection rate of \MATH and maximum of false positive rate of \MATH .
#<struct ReadData::Alignment source_numbers="33", target_numbers="", tag_name="wa">
Since a 36x36 face sample contains a lot of background outside the 24x24 face region while the classifier is required to be fast and to keep all possible face regions , training parameters are set as follows : the minimum detection rate of \MATH and maximum of false positive rate of \MATH .
#<struct ReadData::Alignment source_numbers="37", target_numbers="", tag_name="wa">
Since a 36x36 face sample contains a lot of background outside the 24x24 face region while the classifier is required to be fast and to keep all possible face regions , training parameters are set as follows : the minimum detection rate of \MATH and maximum of false positive rate of \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
Since a 36x36 face sample contains a lot of background outside the 24x24 face region while the classifier is required to be fast and to keep all possible face regions , training parameters are set as follows : the minimum detection rate of \MATH and maximum of false positive rate of \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="45", tag_name="wa">
In our experiments , after reaching 50 features , the classifier 's performance does not significantly increase anymore , so the maximum number of features for each layer is set to 50 .
#<struct ReadData::Alignment source_numbers="16", target_numbers="16", tag_name="wa">
In our experiments , after reaching 50 features , the classifier 's performance does not significantly increase anymore , so the maximum number of features for each layer is set to 50 .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
In our experiments , after reaching 50 features , the classifier 's performance does not significantly increase anymore , so the maximum number of features for each layer is set to 50 .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
In our experiments , after reaching 50 features , the classifier 's performance does not significantly increase anymore , so the maximum number of features for each layer is set to 50 .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
It is somehow similar to features of the first 24x24 layer classifier as shown in Figure 11( b ) .
#<struct ReadData::Alignment source_numbers="1", target_numbers="28,29", tag_name="wa">
It is somehow similar to features of the first 24x24 layer classifier as shown in Figure 11( b ) .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
It is somehow similar to features of the first 24x24 layer classifier as shown in Figure 11( b ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
It is somehow similar to features of the first 24x24 layer classifier as shown in Figure 11( b ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
It is somehow similar to features of the first 24x24 layer classifier as shown in Figure 11( b ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
It is somehow similar to features of the first 24x24 layer classifier as shown in Figure 11( b ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
It is somehow similar to features of the first 24x24 layer classifier as shown in Figure 11( b ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
It is somehow similar to features of the first 24x24 layer classifier as shown in Figure 11( b ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
It is somehow similar to features of the first 24x24 layer classifier as shown in Figure 11( b ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
It is somehow similar to features of the first 24x24 layer classifier as shown in Figure 11( b ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
It is somehow similar to features of the first 24x24 layer classifier as shown in Figure 11( b ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
It is somehow similar to features of the first 24x24 layer classifier as shown in Figure 11( b ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
Two main issues surrounding the reuse of features selected by AdaBoost are : ( i ) which layer whose features will be reused for SVM is the best? and ( ii ) How many features should be used?
#<struct ReadData::Alignment source_numbers="35", target_numbers="19", tag_name="wa">
Two main issues surrounding the reuse of features selected by AdaBoost are : ( i ) which layer whose features will be reused for SVM is the best? and ( ii ) How many features should be used?
#<struct ReadData::Alignment source_numbers="21", target_numbers="20", tag_name="wa">
Two main issues surrounding the reuse of features selected by AdaBoost are : ( i ) which layer whose features will be reused for SVM is the best? and ( ii ) How many features should be used?
#<struct ReadData::Alignment source_numbers="22", target_numbers="21", tag_name="wa">
Two main issues surrounding the reuse of features selected by AdaBoost are : ( i ) which layer whose features will be reused for SVM is the best? and ( ii ) How many features should be used?
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
Two main issues surrounding the reuse of features selected by AdaBoost are : ( i ) which layer whose features will be reused for SVM is the best? and ( ii ) How many features should be used?
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
Two main issues surrounding the reuse of features selected by AdaBoost are : ( i ) which layer whose features will be reused for SVM is the best? and ( ii ) How many features should be used?
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
Two main issues surrounding the reuse of features selected by AdaBoost are : ( i ) which layer whose features will be reused for SVM is the best? and ( ii ) How many features should be used?
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
Two main issues surrounding the reuse of features selected by AdaBoost are : ( i ) which layer whose features will be reused for SVM is the best? and ( ii ) How many features should be used?
#<struct ReadData::Alignment source_numbers="26", target_numbers="", tag_name="wa">
Two main issues surrounding the reuse of features selected by AdaBoost are : ( i ) which layer whose features will be reused for SVM is the best? and ( ii ) How many features should be used?
#<struct ReadData::Alignment source_numbers="27", target_numbers="", tag_name="wa">
Two main issues surrounding the reuse of features selected by AdaBoost are : ( i ) which layer whose features will be reused for SVM is the best? and ( ii ) How many features should be used?
#<struct ReadData::Alignment source_numbers="32", target_numbers="", tag_name="wa">
Two main issues surrounding the reuse of features selected by AdaBoost are : ( i ) which layer whose features will be reused for SVM is the best? and ( ii ) How many features should be used?
#<struct ReadData::Alignment source_numbers="37", target_numbers="", tag_name="wa">
Two main issues surrounding the reuse of features selected by AdaBoost are : ( i ) which layer whose features will be reused for SVM is the best? and ( ii ) How many features should be used?
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Two main issues surrounding the reuse of features selected by AdaBoost are : ( i ) which layer whose features will be reused for SVM is the best? and ( ii ) How many features should be used?
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
Two main issues surrounding the reuse of features selected by AdaBoost are : ( i ) which layer whose features will be reused for SVM is the best? and ( ii ) How many features should be used?
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
Two main issues surrounding the reuse of features selected by AdaBoost are : ( i ) which layer whose features will be reused for SVM is the best? and ( ii ) How many features should be used?
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
Two main issues surrounding the reuse of features selected by AdaBoost are : ( i ) which layer whose features will be reused for SVM is the best? and ( ii ) How many features should be used?
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
For comparison of the performance of SVM classifiers , 2 ,450 face patterns and 7 ,500 non-face patterns which are separated from the training set ( section 6 .1 ) were used .
#<struct ReadData::Alignment source_numbers="18,19", target_numbers="18,19", tag_name="wa">
For comparison of the performance of SVM classifiers , 2 ,450 face patterns and 7 ,500 non-face patterns which are separated from the training set ( section 6 .1 ) were used .
#<struct ReadData::Alignment source_numbers="20", target_numbers="20", tag_name="wa">
The parameter \MATH is set to \MATH .
#<struct ReadData::Alignment source_numbers="3", target_numbers="3", tag_name="wa">
The parameter \MATH is set to \MATH .
#<struct ReadData::Alignment source_numbers="4", target_numbers="4", tag_name="wa">
To determine how many features is robust enough , we used the 200-feature set selected in layer 17 to generate different subsets of features with different number of features .
#<struct ReadData::Alignment source_numbers="2,3", target_numbers="2,3", tag_name="wa">
To determine how many features is robust enough , we used the 200-feature set selected in layer 17 to generate different subsets of features with different number of features .
#<struct ReadData::Alignment source_numbers="27", target_numbers="4", tag_name="wa">
To determine how many features is robust enough , we used the 200-feature set selected in layer 17 to generate different subsets of features with different number of features .
#<struct ReadData::Alignment source_numbers="7", target_numbers="10", tag_name="wa">
To determine how many features is robust enough , we used the 200-feature set selected in layer 17 to generate different subsets of features with different number of features .
#<struct ReadData::Alignment source_numbers="8", target_numbers="12", tag_name="wa">
To determine how many features is robust enough , we used the 200-feature set selected in layer 17 to generate different subsets of features with different number of features .
#<struct ReadData::Alignment source_numbers="26", target_numbers="30,31", tag_name="wa">
To determine how many features is robust enough , we used the 200-feature set selected in layer 17 to generate different subsets of features with different number of features .
#<struct ReadData::Alignment source_numbers="29", target_numbers="33", tag_name="wa">
To determine how many features is robust enough , we used the 200-feature set selected in layer 17 to generate different subsets of features with different number of features .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
To determine how many features is robust enough , we used the 200-feature set selected in layer 17 to generate different subsets of features with different number of features .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
To determine how many features is robust enough , we used the 200-feature set selected in layer 17 to generate different subsets of features with different number of features .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Features in each set were selected in the order that they were added in the training process .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Features in each set were selected in the order that they were added in the training process .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Features in each set were selected in the order that they were added in the training process .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
The results shown in Figure 14 indicate that with more than 100 features , the performance of classifiers is comparable .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
The results shown in Figure 14 indicate that with more than 100 features , the performance of classifiers is comparable .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
The results shown in Figure 14 indicate that with more than 100 features , the performance of classifiers is comparable .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
The results shown in Figure 14 indicate that with more than 100 features , the performance of classifiers is comparable .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
Basically , the speed of a SVM classifier is proportional to the number of features used , so the greater number of features used , the slower the classifier will be .
#<struct ReadData::Alignment source_numbers="27", target_numbers="20", tag_name="wa">
Basically , the speed of a SVM classifier is proportional to the number of features used , so the greater number of features used , the slower the classifier will be .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
Figure 15 shows the processing speed of SVM classifiers that uses different subsets of features .
#<struct ReadData::Alignment source_numbers="10", target_numbers="9", tag_name="wa">
Figure 15 shows the processing speed of SVM classifiers that uses different subsets of features .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
The SVM classifier using 25 features run fastest while the SVM classifier using 200 features run slowest .
#<struct ReadData::Alignment source_numbers="9", target_numbers="7", tag_name="wa">
The SVM classifier using 25 features run fastest while the SVM classifier using 200 features run slowest .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
The SVM classifier using 25 features run fastest while the SVM classifier using 200 features run slowest .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
The SVM classifier using 25 features run fastest while the SVM classifier using 200 features run slowest .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
The SVM classifier using 25 features run fastest while the SVM classifier using 200 features run slowest .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
The speeds of SVM classifiers using 100 , 125 and 175 features are not importantly different because their difference in terms of number of features and number of support vectors is inconsiderable .
#<struct ReadData::Alignment source_numbers="12,13", target_numbers="13,14", tag_name="wa">
The speeds of SVM classifiers using 100 , 125 and 175 features are not importantly different because their difference in terms of number of features and number of support vectors is inconsiderable .
#<struct ReadData::Alignment source_numbers="30", target_numbers="31", tag_name="wa">
The speeds of SVM classifiers using 100 , 125 and 175 features are not importantly different because their difference in terms of number of features and number of support vectors is inconsiderable .
#<struct ReadData::Alignment source_numbers="32", target_numbers="40", tag_name="wa">
The speeds of SVM classifiers using 100 , 125 and 175 features are not importantly different because their difference in terms of number of features and number of support vectors is inconsiderable .
#<struct ReadData::Alignment source_numbers="31", target_numbers="", tag_name="wa">
The speeds of SVM classifiers using 100 , 125 and 175 features are not importantly different because their difference in terms of number of features and number of support vectors is inconsiderable .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
The speeds of SVM classifiers using 100 , 125 and 175 features are not importantly different because their difference in terms of number of features and number of support vectors is inconsiderable .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
The speeds of SVM classifiers using 100 , 125 and 175 features are not importantly different because their difference in terms of number of features and number of support vectors is inconsiderable .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
The speeds of SVM classifiers using 100 , 125 and 175 features are not importantly different because their difference in terms of number of features and number of support vectors is inconsiderable .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
The speeds of SVM classifiers using 100 , 125 and 175 features are not importantly different because their difference in terms of number of features and number of support vectors is inconsiderable .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
The speeds of SVM classifiers using 100 , 125 and 175 features are not importantly different because their difference in terms of number of features and number of support vectors is inconsiderable .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
The speeds of SVM classifiers using 100 , 125 and 175 features are not importantly different because their difference in terms of number of features and number of support vectors is inconsiderable .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
The speeds of SVM classifiers using 100 , 125 and 175 features are not importantly different because their difference in terms of number of features and number of support vectors is inconsiderable .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
The speeds of SVM classifiers using 100 , 125 and 175 features are not importantly different because their difference in terms of number of features and number of support vectors is inconsiderable .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
The remaining 34 ,000 non-face patterns and other 2 ,450 face patterns were used to compare the accuracy .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
The remaining 34 ,000 non-face patterns and other 2 ,450 face patterns were used to compare the accuracy .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
The remaining 34 ,000 non-face patterns and other 2 ,450 face patterns were used to compare the accuracy .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
The RBF SVM classifier reused 100 features selected by the last layer of CAB17 as the feature vector and was trained by a RBF kernel whose parameter \MATH is \MATH .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
The RBF SVM classifier reused 100 features selected by the last layer of CAB17 as the feature vector and was trained by a RBF kernel whose parameter \MATH is \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
The parameter \MATH is set to \MATH .
#<struct ReadData::Alignment source_numbers="3", target_numbers="3", tag_name="wa">
The parameter \MATH is set to \MATH .
#<struct ReadData::Alignment source_numbers="4", target_numbers="4", tag_name="wa">
These parameters are found by using cross-validation test .
#<struct ReadData::Alignment source_numbers="2", target_numbers="2", tag_name="wa">
These parameters are found by using cross-validation test .
#<struct ReadData::Alignment source_numbers="3", target_numbers="3", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="42", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="43", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="44", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="45", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="46", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="47", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="48", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="49", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="50", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="51", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="52", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="53", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="54", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="55", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="56", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="57", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="58", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="59", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="60", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="61", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="62", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="63", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="64", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="65", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="66", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="67", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="68", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="69", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="70", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="71", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="72", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="73", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="74", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="75", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="76", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="77", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="78", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="79", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="80", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="81", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="82", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="83", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="84", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="85", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="86", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="87", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="88", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="89", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="90", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="91", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="92", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="93", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="94", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="95", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="96", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="97", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="98", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="99", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="100", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="101", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="102", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="103", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="104", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="105", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="106", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="107", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="108", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="109", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="110", tag_name="wa">
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
#<struct ReadData::Alignment source_numbers="", target_numbers="111", tag_name="wa">
Furthermore , the training time of a single SVM ( which takes several hours ) is much smaller than that of a cascade of AdaBoost classifiers ( which might take everal weeks ) .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
Furthermore , the training time of a single SVM ( which takes several hours ) is much smaller than that of a cascade of AdaBoost classifiers ( which might take everal weeks ) .
#<struct ReadData::Alignment source_numbers="30", target_numbers="", tag_name="wa">
Furthermore , the training time of a single SVM ( which takes several hours ) is much smaller than that of a cascade of AdaBoost classifiers ( which might take everal weeks ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Furthermore , the training time of a single SVM ( which takes several hours ) is much smaller than that of a cascade of AdaBoost classifiers ( which might take everal weeks ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
In the first stage , the cascaded 36x36 classifiers consist of three layers , making a total number of features used of 120 .
#<struct ReadData::Alignment source_numbers="21", target_numbers="18", tag_name="wa">
In the first stage , the cascaded 36x36 classifiers consist of three layers , making a total number of features used of 120 .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
In the first stage , the cascaded 36x36 classifiers consist of three layers , making a total number of features used of 120 .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
In the first stage , the cascaded 36x36 classifiers consist of three layers , making a total number of features used of 120 .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and , thus , can save significant training time ( which is approximate 27 times in total ) .
#<struct ReadData::Alignment source_numbers="31,32", target_numbers="27", tag_name="wa">
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and , thus , can save significant training time ( which is approximate 27 times in total ) .
#<struct ReadData::Alignment source_numbers="28", target_numbers="33", tag_name="wa">
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and , thus , can save significant training time ( which is approximate 27 times in total ) .
#<struct ReadData::Alignment source_numbers="29", target_numbers="34", tag_name="wa">
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and , thus , can save significant training time ( which is approximate 27 times in total ) .
#<struct ReadData::Alignment source_numbers="30", target_numbers="35", tag_name="wa">
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and , thus , can save significant training time ( which is approximate 27 times in total ) .
#<struct ReadData::Alignment source_numbers="35", target_numbers="50", tag_name="wa">
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and , thus , can save significant training time ( which is approximate 27 times in total ) .
#<struct ReadData::Alignment source_numbers="18", target_numbers="64", tag_name="wa">
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and , thus , can save significant training time ( which is approximate 27 times in total ) .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and , thus , can save significant training time ( which is approximate 27 times in total ) .
#<struct ReadData::Alignment source_numbers="26", target_numbers="", tag_name="wa">
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and , thus , can save significant training time ( which is approximate 27 times in total ) .
#<struct ReadData::Alignment source_numbers="27", target_numbers="", tag_name="wa">
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and , thus , can save significant training time ( which is approximate 27 times in total ) .
#<struct ReadData::Alignment source_numbers="33", target_numbers="", tag_name="wa">
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and , thus , can save significant training time ( which is approximate 27 times in total ) .
#<struct ReadData::Alignment source_numbers="34", target_numbers="", tag_name="wa">
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and , thus , can save significant training time ( which is approximate 27 times in total ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and , thus , can save significant training time ( which is approximate 27 times in total ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and , thus , can save significant training time ( which is approximate 27 times in total ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and , thus , can save significant training time ( which is approximate 27 times in total ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and , thus , can save significant training time ( which is approximate 27 times in total ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and , thus , can save significant training time ( which is approximate 27 times in total ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and , thus , can save significant training time ( which is approximate 27 times in total ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and , thus , can save significant training time ( which is approximate 27 times in total ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and , thus , can save significant training time ( which is approximate 27 times in total ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and , thus , can save significant training time ( which is approximate 27 times in total ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and , thus , can save significant training time ( which is approximate 27 times in total ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and , thus , can save significant training time ( which is approximate 27 times in total ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and , thus , can save significant training time ( which is approximate 27 times in total ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="40", tag_name="wa">
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and , thus , can save significant training time ( which is approximate 27 times in total ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="41", tag_name="wa">
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and , thus , can save significant training time ( which is approximate 27 times in total ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="42", tag_name="wa">
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and , thus , can save significant training time ( which is approximate 27 times in total ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="43", tag_name="wa">
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and , thus , can save significant training time ( which is approximate 27 times in total ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="44", tag_name="wa">
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and , thus , can save significant training time ( which is approximate 27 times in total ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="45", tag_name="wa">
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and , thus , can save significant training time ( which is approximate 27 times in total ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="46", tag_name="wa">
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and , thus , can save significant training time ( which is approximate 27 times in total ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="47", tag_name="wa">
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and , thus , can save significant training time ( which is approximate 27 times in total ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="48", tag_name="wa">
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and , thus , can save significant training time ( which is approximate 27 times in total ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="49", tag_name="wa">
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and , thus , can save significant training time ( which is approximate 27 times in total ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="51", tag_name="wa">
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and , thus , can save significant training time ( which is approximate 27 times in total ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="52", tag_name="wa">
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and , thus , can save significant training time ( which is approximate 27 times in total ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="53", tag_name="wa">
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and , thus , can save significant training time ( which is approximate 27 times in total ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="54", tag_name="wa">
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and , thus , can save significant training time ( which is approximate 27 times in total ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="55", tag_name="wa">
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and , thus , can save significant training time ( which is approximate 27 times in total ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="56", tag_name="wa">
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and , thus , can save significant training time ( which is approximate 27 times in total ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="57", tag_name="wa">
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and , thus , can save significant training time ( which is approximate 27 times in total ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="58", tag_name="wa">
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and , thus , can save significant training time ( which is approximate 27 times in total ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="59", tag_name="wa">
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and , thus , can save significant training time ( which is approximate 27 times in total ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="60", tag_name="wa">
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and , thus , can save significant training time ( which is approximate 27 times in total ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="61", tag_name="wa">
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and , thus , can save significant training time ( which is approximate 27 times in total ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="62", tag_name="wa">
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and , thus , can save significant training time ( which is approximate 27 times in total ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="63", tag_name="wa">
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and , thus , can save significant training time ( which is approximate 27 times in total ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="65", tag_name="wa">
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and , thus , can save significant training time ( which is approximate 27 times in total ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="66", tag_name="wa">
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and , thus , can save significant training time ( which is approximate 27 times in total ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="67", tag_name="wa">
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and , thus , can save significant training time ( which is approximate 27 times in total ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="68", tag_name="wa">
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and , thus , can save significant training time ( which is approximate 27 times in total ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="69", tag_name="wa">
All these parameters were found by using cross-validation test tool provided by LibSVM [31]} .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
All these parameters were found by using cross-validation test tool provided by LibSVM [31]} .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
All these parameters were found by using cross-validation test tool provided by LibSVM [31]} .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
All these parameters were found by using cross-validation test tool provided by LibSVM [31]} .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
All these parameters were found by using cross-validation test tool provided by LibSVM [31]} .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
All these parameters were found by using cross-validation test tool provided by LibSVM [31]} .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
All these parameters were found by using cross-validation test tool provided by LibSVM [31]} .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
All these parameters were found by using cross-validation test tool provided by LibSVM [31]} .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
All these parameters were found by using cross-validation test tool provided by LibSVM [31]} .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
All these parameters were found by using cross-validation test tool provided by LibSVM [31]} .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
All these parameters were found by using cross-validation test tool provided by LibSVM [31]} .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
All these parameters were found by using cross-validation test tool provided by LibSVM [31]} .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
All these parameters were found by using cross-validation test tool provided by LibSVM [31]} .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
All these parameters were found by using cross-validation test tool provided by LibSVM [31]} .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
All these parameters were found by using cross-validation test tool provided by LibSVM [31]} .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
All these parameters were found by using cross-validation test tool provided by LibSVM [31]} .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
All these parameters were found by using cross-validation test tool provided by LibSVM [31]} .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
All these parameters were found by using cross-validation test tool provided by LibSVM [31]} .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
All these parameters were found by using cross-validation test tool provided by LibSVM [31]} .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
All these parameters were found by using cross-validation test tool provided by LibSVM [31]} .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
All these parameters were found by using cross-validation test tool provided by LibSVM [31]} .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
All these parameters were found by using cross-validation test tool provided by LibSVM [31]} .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
All these parameters were found by using cross-validation test tool provided by LibSVM [31]} .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
All these parameters were found by using cross-validation test tool provided by LibSVM [31]} .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
All these parameters were found by using cross-validation test tool provided by LibSVM [31]} .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
All these parameters were found by using cross-validation test tool provided by LibSVM [31]} .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
All these parameters were found by using cross-validation test tool provided by LibSVM [31]} .
#<struct ReadData::Alignment source_numbers="", target_numbers="40", tag_name="wa">
All these parameters were found by using cross-validation test tool provided by LibSVM [31]} .
#<struct ReadData::Alignment source_numbers="", target_numbers="41", tag_name="wa">
All these parameters were found by using cross-validation test tool provided by LibSVM [31]} .
#<struct ReadData::Alignment source_numbers="", target_numbers="42", tag_name="wa">
All these parameters were found by using cross-validation test tool provided by LibSVM [31]} .
#<struct ReadData::Alignment source_numbers="", target_numbers="43", tag_name="wa">
All these parameters were found by using cross-validation test tool provided by LibSVM [31]} .
#<struct ReadData::Alignment source_numbers="", target_numbers="44", tag_name="wa">
All these parameters were found by using cross-validation test tool provided by LibSVM [31]} .
#<struct ReadData::Alignment source_numbers="", target_numbers="45", tag_name="wa">
All these parameters were found by using cross-validation test tool provided by LibSVM [31]} .
#<struct ReadData::Alignment source_numbers="", target_numbers="46", tag_name="wa">
All these parameters were found by using cross-validation test tool provided by LibSVM [31]} .
#<struct ReadData::Alignment source_numbers="", target_numbers="47", tag_name="wa">
All these parameters were found by using cross-validation test tool provided by LibSVM [31]} .
#<struct ReadData::Alignment source_numbers="", target_numbers="48", tag_name="wa">
All these parameters were found by using cross-validation test tool provided by LibSVM [31]} .
#<struct ReadData::Alignment source_numbers="", target_numbers="49", tag_name="wa">
This training procedure resulted three SVM classifiers whose the numbers of support vectors are 4 ,725 , 5 ,043 , and 4 ,847 respectively .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
This training procedure resulted three SVM classifiers whose the numbers of support vectors are 4 ,725 , 5 ,043 , and 4 ,847 respectively .
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
This training procedure resulted three SVM classifiers whose the numbers of support vectors are 4 ,725 , 5 ,043 , and 4 ,847 respectively .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
We tested our system on the MIT+CMU frontal-face standard test set [5] which consists of 124 images with 480 frontal faces ( excluding images containing hand-drawn , cartoon and small faces ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
We tested our system on the MIT+CMU frontal-face standard test set [5] which consists of 124 images with 480 frontal faces ( excluding images containing hand-drawn , cartoon and small faces ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
The first row presents the number of features of each layer , and the second row shows the fraction of the remaining patterns after each layer processing .
#<struct ReadData::Alignment source_numbers="26", target_numbers="26", tag_name="wa">
The first row presents the number of features of each layer , and the second row shows the fraction of the remaining patterns after each layer processing .
#<struct ReadData::Alignment source_numbers="11", target_numbers="35", tag_name="wa">
The first row presents the number of features of each layer , and the second row shows the fraction of the remaining patterns after each layer processing .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
The first row presents the number of features of each layer , and the second row shows the fraction of the remaining patterns after each layer processing .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
The first row presents the number of features of each layer , and the second row shows the fraction of the remaining patterns after each layer processing .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
The first row presents the number of features of each layer , and the second row shows the fraction of the remaining patterns after each layer processing .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
The first row presents the number of features of each layer , and the second row shows the fraction of the remaining patterns after each layer processing .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
The first row presents the number of features of each layer , and the second row shows the fraction of the remaining patterns after each layer processing .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
The first row presents the number of features of each layer , and the second row shows the fraction of the remaining patterns after each layer processing .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
The first row presents the number of features of each layer , and the second row shows the fraction of the remaining patterns after each layer processing .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
The first row presents the number of features of each layer , and the second row shows the fraction of the remaining patterns after each layer processing .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
The first row presents the number of features of each layer , and the second row shows the fraction of the remaining patterns after each layer processing .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
The first row presents the number of features of each layer , and the second row shows the fraction of the remaining patterns after each layer processing .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
The first row presents the number of features of each layer , and the second row shows the fraction of the remaining patterns after each layer processing .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
The first row presents the number of features of each layer , and the second row shows the fraction of the remaining patterns after each layer processing .
#<struct ReadData::Alignment source_numbers="", target_numbers="40", tag_name="wa">
The first row presents the number of features of each layer , and the second row shows the fraction of the remaining patterns after each layer processing .
#<struct ReadData::Alignment source_numbers="", target_numbers="41", tag_name="wa">
The first row presents the number of features of each layer , and the second row shows the fraction of the remaining patterns after each layer processing .
#<struct ReadData::Alignment source_numbers="", target_numbers="42", tag_name="wa">
The first row presents the number of features of each layer , and the second row shows the fraction of the remaining patterns after each layer processing .
#<struct ReadData::Alignment source_numbers="", target_numbers="43", tag_name="wa">
The first row presents the number of features of each layer , and the second row shows the fraction of the remaining patterns after each layer processing .
#<struct ReadData::Alignment source_numbers="", target_numbers="44", tag_name="wa">
The first row presents the number of features of each layer , and the second row shows the fraction of the remaining patterns after each layer processing .
#<struct ReadData::Alignment source_numbers="", target_numbers="45", tag_name="wa">
The first row presents the number of features of each layer , and the second row shows the fraction of the remaining patterns after each layer processing .
#<struct ReadData::Alignment source_numbers="", target_numbers="46", tag_name="wa">
The first row presents the number of features of each layer , and the second row shows the fraction of the remaining patterns after each layer processing .
#<struct ReadData::Alignment source_numbers="", target_numbers="47", tag_name="wa">
The first row presents the number of features of each layer , and the second row shows the fraction of the remaining patterns after each layer processing .
#<struct ReadData::Alignment source_numbers="", target_numbers="48", tag_name="wa">
The first row presents the number of features of each layer , and the second row shows the fraction of the remaining patterns after each layer processing .
#<struct ReadData::Alignment source_numbers="", target_numbers="49", tag_name="wa">
The first row presents the number of features of each layer , and the second row shows the fraction of the remaining patterns after each layer processing .
#<struct ReadData::Alignment source_numbers="", target_numbers="50", tag_name="wa">
The first row presents the number of features of each layer , and the second row shows the fraction of the remaining patterns after each layer processing .
#<struct ReadData::Alignment source_numbers="", target_numbers="51", tag_name="wa">
The first row presents the number of features of each layer , and the second row shows the fraction of the remaining patterns after each layer processing .
#<struct ReadData::Alignment source_numbers="", target_numbers="52", tag_name="wa">
The first row presents the number of features of each layer , and the second row shows the fraction of the remaining patterns after each layer processing .
#<struct ReadData::Alignment source_numbers="", target_numbers="53", tag_name="wa">
The first row presents the number of features of each layer , and the second row shows the fraction of the remaining patterns after each layer processing .
#<struct ReadData::Alignment source_numbers="", target_numbers="54", tag_name="wa">
The first row presents the number of features of each layer , and the second row shows the fraction of the remaining patterns after each layer processing .
#<struct ReadData::Alignment source_numbers="", target_numbers="55", tag_name="wa">
The last row indicates the fraction of time that each layer consumes .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
The last row indicates the fraction of time that each layer consumes .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
The last row indicates the fraction of time that each layer consumes .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
The last row indicates the fraction of time that each layer consumes .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
The last row indicates the fraction of time that each layer consumes .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
All these statistics are extracted from running the classifiers on the MIT+CMU test set .
#<struct ReadData::Alignment source_numbers="3", target_numbers="3", tag_name="wa">
All these statistics are extracted from running the classifiers on the MIT+CMU test set .
#<struct ReadData::Alignment source_numbers="4", target_numbers="4", tag_name="wa">
All these statistics are extracted from running the classifiers on the MIT+CMU test set .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
All these statistics are extracted from running the classifiers on the MIT+CMU test set .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
If the first 24x24 layer classifier is added to the cascade of 36x36 classifiers , this combination rejects 85 .91\% of analyzed patterns compared to \MATH of using only the first layer of the single cascade 24x24 classifiers .
#<struct ReadData::Alignment source_numbers="6", target_numbers="6", tag_name="wa">
If the first 24x24 layer classifier is added to the cascade of 36x36 classifiers , this combination rejects 85 .91\% of analyzed patterns compared to \MATH of using only the first layer of the single cascade 24x24 classifiers .
#<struct ReadData::Alignment source_numbers="7", target_numbers="7", tag_name="wa">
If the first 24x24 layer classifier is added to the cascade of 36x36 classifiers , this combination rejects 85 .91\% of analyzed patterns compared to \MATH of using only the first layer of the single cascade 24x24 classifiers .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
If the first 24x24 layer classifier is added to the cascade of 36x36 classifiers , this combination rejects 85 .91\% of analyzed patterns compared to \MATH of using only the first layer of the single cascade 24x24 classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Furthermore , the rejection of this very large number of patterns is done extremely quickly , only using \MATH of processing time .
#<struct ReadData::Alignment source_numbers="11", target_numbers="11", tag_name="wa">
Furthermore , the rejection of this very large number of patterns is done extremely quickly , only using \MATH of processing time .
#<struct ReadData::Alignment source_numbers="12", target_numbers="12", tag_name="wa">
Furthermore , the rejection of this very large number of patterns is done extremely quickly , only using \MATH of processing time .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
Furthermore , the rejection of this very large number of patterns is done extremely quickly , only using \MATH of processing time .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
Furthermore , the rejection of this very large number of patterns is done extremely quickly , only using \MATH of processing time .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
Furthermore , the rejection of this very large number of patterns is done extremely quickly , only using \MATH of processing time .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
Furthermore , the rejection of this very large number of patterns is done extremely quickly , only using \MATH of processing time .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
Furthermore , the rejection of this very large number of patterns is done extremely quickly , only using \MATH of processing time .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
Furthermore , the rejection of this very large number of patterns is done extremely quickly , only using \MATH of processing time .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
Furthermore , the rejection of this very large number of patterns is done extremely quickly , only using \MATH of processing time .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
Furthermore , the rejection of this very large number of patterns is done extremely quickly , only using \MATH of processing time .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
Detection rate and speed of classifiers with ten false positives are listed in Table 3 .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Detection rate and speed of classifiers with ten false positives are listed in Table 3 .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
It is clear that our multi-stage system runs faster than the single cascade of 24x24 AdaBoost classifiers while detection rates are comparable .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
It is clear that our multi-stage system runs faster than the single cascade of 24x24 AdaBoost classifiers while detection rates are comparable .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
This performance is possible because of the three following reasons :
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
This performance is possible because of the three following reasons :
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
This performance is possible because of the three following reasons :
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
This performance is possible because of the three following reasons :
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
This performance is possible because of the three following reasons :
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
This performance is possible because of the three following reasons :
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
First , the cascade of 36x36 AdaBoost classifiers rejects a lot of non-face patterns extremely fast while slow SVM classifiers only process a very small number of the remaining patterns .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
First , the cascade of 36x36 AdaBoost classifiers rejects a lot of non-face patterns extremely fast while slow SVM classifiers only process a very small number of the remaining patterns .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
First , the cascade of 36x36 AdaBoost classifiers rejects a lot of non-face patterns extremely fast while slow SVM classifiers only process a very small number of the remaining patterns .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
First , the cascade of 36x36 AdaBoost classifiers rejects a lot of non-face patterns extremely fast while slow SVM classifiers only process a very small number of the remaining patterns .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
Second , many images in the MIT+CMU test set contain large portion of background which was mentioned in [9] which said the ratio of non-face to face patterns is about 50 ,000 to 1 .
#<struct ReadData::Alignment source_numbers="28", target_numbers="18,19", tag_name="wa">
Second , many images in the MIT+CMU test set contain large portion of background which was mentioned in [9] which said the ratio of non-face to face patterns is about 50 ,000 to 1 .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
Second , many images in the MIT+CMU test set contain large portion of background which was mentioned in [9] which said the ratio of non-face to face patterns is about 50 ,000 to 1 .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
Second , many images in the MIT+CMU test set contain large portion of background which was mentioned in [9] which said the ratio of non-face to face patterns is about 50 ,000 to 1 .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
Second , many images in the MIT+CMU test set contain large portion of background which was mentioned in [9] which said the ratio of non-face to face patterns is about 50 ,000 to 1 .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
Second , many images in the MIT+CMU test set contain large portion of background which was mentioned in [9] which said the ratio of non-face to face patterns is about 50 ,000 to 1 .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
Second , many images in the MIT+CMU test set contain large portion of background which was mentioned in [9] which said the ratio of non-face to face patterns is about 50 ,000 to 1 .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Second , many images in the MIT+CMU test set contain large portion of background which was mentioned in [9] which said the ratio of non-face to face patterns is about 50 ,000 to 1 .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
Experimental results showed that the AdaBoost+SVM system runs faster than that of the original AdaBoost on \MATH of total number of images in this test set .
#<struct ReadData::Alignment source_numbers="17,18", target_numbers="17,18,19,20", tag_name="wa">
Experimental results showed that the AdaBoost+SVM system runs faster than that of the original AdaBoost on \MATH of total number of images in this test set .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
Third , at a small number of false positives , some true face candidate regions rejected by 36x36 classifiers do not affect so much in final performance because it might also be rejected by 24x24 classifiers in later layers .
#<struct ReadData::Alignment source_numbers="19,20", target_numbers="19,20", tag_name="wa">
Third , at a small number of false positives , some true face candidate regions rejected by 36x36 classifiers do not affect so much in final performance because it might also be rejected by 24x24 classifiers in later layers .
#<struct ReadData::Alignment source_numbers="21", target_numbers="22", tag_name="wa">
Third , at a small number of false positives , some true face candidate regions rejected by 36x36 classifiers do not affect so much in final performance because it might also be rejected by 24x24 classifiers in later layers .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
Third , at a small number of false positives , some true face candidate regions rejected by 36x36 classifiers do not affect so much in final performance because it might also be rejected by 24x24 classifiers in later layers .
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
Third , at a small number of false positives , some true face candidate regions rejected by 36x36 classifiers do not affect so much in final performance because it might also be rejected by 24x24 classifiers in later layers .
#<struct ReadData::Alignment source_numbers="28", target_numbers="", tag_name="wa">
Third , at a small number of false positives , some true face candidate regions rejected by 36x36 classifiers do not affect so much in final performance because it might also be rejected by 24x24 classifiers in later layers .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
Third , at a small number of false positives , some true face candidate regions rejected by 36x36 classifiers do not affect so much in final performance because it might also be rejected by 24x24 classifiers in later layers .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
The cascaded structure of AdaBoost-based classifiers in two first stages allows to best adapt to various complexities of input patterns ,while non linear SVM classifiers at the final stage are robust enough to achieve good results .
#<struct ReadData::Alignment source_numbers="26", target_numbers="7", tag_name="wa">
The cascaded structure of AdaBoost-based classifiers in two first stages allows to best adapt to various complexities of input patterns ,while non linear SVM classifiers at the final stage are robust enough to achieve good results .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
The cascaded structure of AdaBoost-based classifiers in two first stages allows to best adapt to various complexities of input patterns ,while non linear SVM classifiers at the final stage are robust enough to achieve good results .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
The cascaded structure of AdaBoost-based classifiers in two first stages allows to best adapt to various complexities of input patterns ,while non linear SVM classifiers at the final stage are robust enough to achieve good results .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
The cascaded structure of AdaBoost-based classifiers in two first stages allows to best adapt to various complexities of input patterns ,while non linear SVM classifiers at the final stage are robust enough to achieve good results .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
The cascaded structure of AdaBoost-based classifiers in two first stages allows to best adapt to various complexities of input patterns ,while non linear SVM classifiers at the final stage are robust enough to achieve good results .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
The cascaded structure of AdaBoost-based classifiers in two first stages allows to best adapt to various complexities of input patterns ,while non linear SVM classifiers at the final stage are robust enough to achieve good results .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
The cascaded structure of AdaBoost-based classifiers in two first stages allows to best adapt to various complexities of input patterns ,while non linear SVM classifiers at the final stage are robust enough to achieve good results .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
The cascaded structure of AdaBoost-based classifiers in two first stages allows to best adapt to various complexities of input patterns ,while non linear SVM classifiers at the final stage are robust enough to achieve good results .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
The cascaded structure of AdaBoost-based classifiers in two first stages allows to best adapt to various complexities of input patterns ,while non linear SVM classifiers at the final stage are robust enough to achieve good results .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
Extensive experiments demonstrated that a significant computation time is devoted to potential face regions because almost all non-face patterns are rejected quickly by the two first stages , and only a very small number of face-like patterns is processed by the slow SVM classifiers .
#<struct ReadData::Alignment source_numbers="37", target_numbers="37", tag_name="wa">
Extensive experiments demonstrated that a significant computation time is devoted to potential face regions because almost all non-face patterns are rejected quickly by the two first stages , and only a very small number of face-like patterns is processed by the slow SVM classifiers .
#<struct ReadData::Alignment source_numbers="38", target_numbers="38", tag_name="wa">
Extensive experiments demonstrated that a significant computation time is devoted to potential face regions because almost all non-face patterns are rejected quickly by the two first stages , and only a very small number of face-like patterns is processed by the slow SVM classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="45", tag_name="wa">
Extensive experiments demonstrated that a significant computation time is devoted to potential face regions because almost all non-face patterns are rejected quickly by the two first stages , and only a very small number of face-like patterns is processed by the slow SVM classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="46", tag_name="wa">
Extensive experiments demonstrated that a significant computation time is devoted to potential face regions because almost all non-face patterns are rejected quickly by the two first stages , and only a very small number of face-like patterns is processed by the slow SVM classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="47", tag_name="wa">
Extensive experiments demonstrated that a significant computation time is devoted to potential face regions because almost all non-face patterns are rejected quickly by the two first stages , and only a very small number of face-like patterns is processed by the slow SVM classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="48", tag_name="wa">
Extensive experiments demonstrated that a significant computation time is devoted to potential face regions because almost all non-face patterns are rejected quickly by the two first stages , and only a very small number of face-like patterns is processed by the slow SVM classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="49", tag_name="wa">
Extensive experiments demonstrated that a significant computation time is devoted to potential face regions because almost all non-face patterns are rejected quickly by the two first stages , and only a very small number of face-like patterns is processed by the slow SVM classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="50", tag_name="wa">
Extensive experiments demonstrated that a significant computation time is devoted to potential face regions because almost all non-face patterns are rejected quickly by the two first stages , and only a very small number of face-like patterns is processed by the slow SVM classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="51", tag_name="wa">
Discriminant Haar wavelet features selected from AdaBoost are used for all stage classifier to take advantages from their efficient representation and fast evaluation .
#<struct ReadData::Alignment source_numbers="16,17", target_numbers="16,17", tag_name="wa">
to improve the retrieval performance of image search engines that use textual information for indexing , it is necessary to utilize visual information .
#<struct ReadData::Alignment source_numbers="17", target_numbers="1", tag_name="wa">
to improve the retrieval performance of image search engines that use textual information for indexing , it is necessary to utilize visual information .
#<struct ReadData::Alignment source_numbers="18", target_numbers="2", tag_name="wa">
to improve the retrieval performance of image search engines that use textual information for indexing , it is necessary to utilize visual information .
#<struct ReadData::Alignment source_numbers="19", target_numbers="3", tag_name="wa">
to improve the retrieval performance of image search engines that use textual information for indexing , it is necessary to utilize visual information .
#<struct ReadData::Alignment source_numbers="20", target_numbers="4", tag_name="wa">
to improve the retrieval performance of image search engines that use textual information for indexing , it is necessary to utilize visual information .
#<struct ReadData::Alignment source_numbers="21", target_numbers="5", tag_name="wa">
to improve the retrieval performance of image search engines that use textual information for indexing , it is necessary to utilize visual information .
#<struct ReadData::Alignment source_numbers="22", target_numbers="6", tag_name="wa">
to improve the retrieval performance of image search engines that use textual information for indexing , it is necessary to utilize visual information .
#<struct ReadData::Alignment source_numbers="2", target_numbers="9", tag_name="wa">
to improve the retrieval performance of image search engines that use textual information for indexing , it is necessary to utilize visual information .
#<struct ReadData::Alignment source_numbers="4,5", target_numbers="10,11", tag_name="wa">
to improve the retrieval performance of image search engines that use textual information for indexing , it is necessary to utilize visual information .
#<struct ReadData::Alignment source_numbers="3", target_numbers="12", tag_name="wa">
to improve the retrieval performance of image search engines that use textual information for indexing , it is necessary to utilize visual information .
#<struct ReadData::Alignment source_numbers="8", target_numbers="15", tag_name="wa">
to improve the retrieval performance of image search engines that use textual information for indexing , it is necessary to utilize visual information .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
to improve the retrieval performance of image search engines that use textual information for indexing , it is necessary to utilize visual information .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
to improve the retrieval performance of image search engines that use textual information for indexing , it is necessary to utilize visual information .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
to improve the retrieval performance of image search engines that use textual information for indexing , it is necessary to utilize visual information .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
to improve the retrieval performance of image search engines that use textual information for indexing , it is necessary to utilize visual information .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
to improve the retrieval performance of image search engines that use textual information for indexing , it is necessary to utilize visual information .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
to improve the retrieval performance of image search engines that use textual information for indexing , it is necessary to utilize visual information .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
One popular approach is to learn visual consistency among the images returned by these search engines .
#<struct ReadData::Alignment source_numbers="8,9", target_numbers="9", tag_name="wa">
Most of the state of the art methods for learning the visual consistency usually learn one specific classifier for each query for re-ranking the returned images .
#<struct ReadData::Alignment source_numbers="0", target_numbers="0", tag_name="wa">
Most of the state of the art methods for learning the visual consistency usually learn one specific classifier for each query for re-ranking the returned images .
#<struct ReadData::Alignment source_numbers="1", target_numbers="3", tag_name="wa">
Most of the state of the art methods for learning the visual consistency usually learn one specific classifier for each query for re-ranking the returned images .
#<struct ReadData::Alignment source_numbers="22", target_numbers="16", tag_name="wa">
Most of the state of the art methods for learning the visual consistency usually learn one specific classifier for each query for re-ranking the returned images .
#<struct ReadData::Alignment source_numbers="26", target_numbers="20", tag_name="wa">
Most of the state of the art methods for learning the visual consistency usually learn one specific classifier for each query for re-ranking the returned images .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
Most of the state of the art methods for learning the visual consistency usually learn one specific classifier for each query for re-ranking the returned images .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
Most of the state of the art methods for learning the visual consistency usually learn one specific classifier for each query for re-ranking the returned images .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Most of the state of the art methods for learning the visual consistency usually learn one specific classifier for each query for re-ranking the returned images .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
Most of the state of the art methods for learning the visual consistency usually learn one specific classifier for each query for re-ranking the returned images .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Most of the state of the art methods for learning the visual consistency usually learn one specific classifier for each query for re-ranking the returned images .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
Most of the state of the art methods for learning the visual consistency usually learn one specific classifier for each query for re-ranking the returned images .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Most of the state of the art methods for learning the visual consistency usually learn one specific classifier for each query for re-ranking the returned images .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
The drawback of these methods is it requires computational cost and processing time that are unsuitable for handling a large number of queries .
#<struct ReadData::Alignment source_numbers="0", target_numbers="0", tag_name="wa">
The drawback of these methods is it requires computational cost and processing time that are unsuitable for handling a large number of queries .
#<struct ReadData::Alignment source_numbers="1", target_numbers="2", tag_name="wa">
The drawback of these methods is it requires computational cost and processing time that are unsuitable for handling a large number of queries .
#<struct ReadData::Alignment source_numbers="7", target_numbers="9", tag_name="wa">
The drawback of these methods is it requires computational cost and processing time that are unsuitable for handling a large number of queries .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
The drawback of these methods is it requires computational cost and processing time that are unsuitable for handling a large number of queries .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
The drawback of these methods is it requires computational cost and processing time that are unsuitable for handling a large number of queries .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
The drawback of these methods is it requires computational cost and processing time that are unsuitable for handling a large number of queries .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
The drawback of these methods is it requires computational cost and processing time that are unsuitable for handling a large number of queries .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Different from query-specific based methods that learn classifiers for recognition concepts encoded in each query , the generic classifier of our method learns relevancy between images and the query for re-ranking purpose .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
Different from query-specific based methods that learn classifiers for recognition concepts encoded in each query , the generic classifier of our method learns relevancy between images and the query for re-ranking purpose .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
The key contribution of this paper is to introduce a query-dependent feature to represent this relevancy and an unsupervised method to collect training samples for learning the generic classifier .
#<struct ReadData::Alignment source_numbers="25", target_numbers="24,25", tag_name="wa">
The key contribution of this paper is to introduce a query-dependent feature to represent this relevancy and an unsupervised method to collect training samples for learning the generic classifier .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
The key contribution of this paper is to introduce a query-dependent feature to represent this relevancy and an unsupervised method to collect training samples for learning the generic classifier .
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
The key contribution of this paper is to introduce a query-dependent feature to represent this relevancy and an unsupervised method to collect training samples for learning the generic classifier .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
The generic classifier is built automatically and independent with existing ranking algorithms of input search engines .
#<struct ReadData::Alignment source_numbers="12", target_numbers="9", tag_name="wa">
The generic classifier is built automatically and independent with existing ranking algorithms of input search engines .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
The generic classifier is built automatically and independent with existing ranking algorithms of input search engines .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
experimental results show that the proposed method achieves good performance in various datasets .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
experimental results show that the proposed method achieves good performance in various datasets .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
experimental results show that the proposed method achieves good performance in various datasets .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
experimental results show that the proposed method achieves good performance in various datasets .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
experimental results show that the proposed method achieves good performance in various datasets .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
experimental results show that the proposed method achieves good performance in various datasets .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Image search is essential for many search engines .
#<struct ReadData::Alignment source_numbers="2,3", target_numbers="2,3", tag_name="wa">
Most of existing image search engines usually use text information for judging relevancy , resulting low precision performance .
#<struct ReadData::Alignment source_numbers="14", target_numbers="12", tag_name="wa">
Most of existing image search engines usually use text information for judging relevancy , resulting low precision performance .
#<struct ReadData::Alignment source_numbers="16", target_numbers="15", tag_name="wa">
Most of existing image search engines usually use text information for judging relevancy , resulting low precision performance .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
Most of existing image search engines usually use text information for judging relevancy , resulting low precision performance .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
Most of existing image search engines usually use text information for judging relevancy , resulting low precision performance .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
Most of existing image search engines usually use text information for judging relevancy , resulting low precision performance .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
Most of existing image search engines usually use text information for judging relevancy , resulting low precision performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Most of existing image search engines usually use text information for judging relevancy , resulting low precision performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Most of existing image search engines usually use text information for judging relevancy , resulting low precision performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
To improve the retrieval performance , it is necessary to use visual information of images for re-ranking .
#<struct ReadData::Alignment source_numbers="2", target_numbers="2", tag_name="wa">
To improve the retrieval performance , it is necessary to use visual information of images for re-ranking .
#<struct ReadData::Alignment source_numbers="13", target_numbers="4", tag_name="wa">
To improve the retrieval performance , it is necessary to use visual information of images for re-ranking .
#<struct ReadData::Alignment source_numbers="3", target_numbers="5", tag_name="wa">
To improve the retrieval performance , it is necessary to use visual information of images for re-ranking .
#<struct ReadData::Alignment source_numbers="16", target_numbers="17", tag_name="wa">
To improve the retrieval performance , it is necessary to use visual information of images for re-ranking .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
To improve the retrieval performance , it is necessary to use visual information of images for re-ranking .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
To improve the retrieval performance , it is necessary to use visual information of images for re-ranking .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
To improve the retrieval performance , it is necessary to use visual information of images for re-ranking .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
To improve the retrieval performance , it is necessary to use visual information of images for re-ranking .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
However , content-based image understanding is a challenging and unsolved problem .
#<struct ReadData::Alignment source_numbers="4", target_numbers="2", tag_name="wa">
However , content-based image understanding is a challenging and unsolved problem .
#<struct ReadData::Alignment source_numbers="2", target_numbers="3", tag_name="wa">
However , content-based image understanding is a challenging and unsolved problem .
#<struct ReadData::Alignment source_numbers="3", target_numbers="4", tag_name="wa">
In addition , using visual information requires huge computational cost compared with using text .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
In addition , using visual information requires huge computational cost compared with using text .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
In addition , using visual information requires huge computational cost compared with using text .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
In addition , using visual information requires huge computational cost compared with using text .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
In addition , using visual information requires huge computational cost compared with using text .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
In addition , using visual information requires huge computational cost compared with using text .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
One popular approach \CITE combining both text and visual information is to use text information to quickly retrieve a set of candidates and then do post-processing (i . e . re-rank) on this set to improve the precision .
#<struct ReadData::Alignment source_numbers="27", target_numbers="29", tag_name="wa">
One popular approach \CITE combining both text and visual information is to use text information to quickly retrieve a set of candidates and then do post-processing (i . e . re-rank) on this set to improve the precision .
#<struct ReadData::Alignment source_numbers="28", target_numbers="30", tag_name="wa">
One popular approach \CITE combining both text and visual information is to use text information to quickly retrieve a set of candidates and then do post-processing (i . e . re-rank) on this set to improve the precision .
#<struct ReadData::Alignment source_numbers="29", target_numbers="31", tag_name="wa">
One popular approach \CITE combining both text and visual information is to use text information to quickly retrieve a set of candidates and then do post-processing (i . e . re-rank) on this set to improve the precision .
#<struct ReadData::Alignment source_numbers="31", target_numbers="35", tag_name="wa">
One popular approach \CITE combining both text and visual information is to use text information to quickly retrieve a set of candidates and then do post-processing (i . e . re-rank) on this set to improve the precision .
#<struct ReadData::Alignment source_numbers="32", target_numbers="36", tag_name="wa">
One popular approach \CITE combining both text and visual information is to use text information to quickly retrieve a set of candidates and then do post-processing (i . e . re-rank) on this set to improve the precision .
#<struct ReadData::Alignment source_numbers="33", target_numbers="37", tag_name="wa">
One popular approach \CITE combining both text and visual information is to use text information to quickly retrieve a set of candidates and then do post-processing (i . e . re-rank) on this set to improve the precision .
#<struct ReadData::Alignment source_numbers="34", target_numbers="38", tag_name="wa">
One popular approach \CITE combining both text and visual information is to use text information to quickly retrieve a set of candidates and then do post-processing (i . e . re-rank) on this set to improve the precision .
#<struct ReadData::Alignment source_numbers="35", target_numbers="39", tag_name="wa">
One popular approach \CITE combining both text and visual information is to use text information to quickly retrieve a set of candidates and then do post-processing (i . e . re-rank) on this set to improve the precision .
#<struct ReadData::Alignment source_numbers="26", target_numbers="", tag_name="wa">
One popular approach \CITE combining both text and visual information is to use text information to quickly retrieve a set of candidates and then do post-processing (i . e . re-rank) on this set to improve the precision .
#<struct ReadData::Alignment source_numbers="30", target_numbers="", tag_name="wa">
One popular approach \CITE combining both text and visual information is to use text information to quickly retrieve a set of candidates and then do post-processing (i . e . re-rank) on this set to improve the precision .
#<struct ReadData::Alignment source_numbers="36", target_numbers="", tag_name="wa">
One popular approach \CITE combining both text and visual information is to use text information to quickly retrieve a set of candidates and then do post-processing (i . e . re-rank) on this set to improve the precision .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
One popular approach \CITE combining both text and visual information is to use text information to quickly retrieve a set of candidates and then do post-processing (i . e . re-rank) on this set to improve the precision .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
One popular approach \CITE combining both text and visual information is to use text information to quickly retrieve a set of candidates and then do post-processing (i . e . re-rank) on this set to improve the precision .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
One popular approach \CITE combining both text and visual information is to use text information to quickly retrieve a set of candidates and then do post-processing (i . e . re-rank) on this set to improve the precision .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
One popular approach \CITE combining both text and visual information is to use text information to quickly retrieve a set of candidates and then do post-processing (i . e . re-rank) on this set to improve the precision .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
There are two ways for post-processing : The first way \CITE is to build a ranker or a classifier specific to the given query using the returned images .
#<struct ReadData::Alignment source_numbers="5", target_numbers="6", tag_name="wa">
There are two ways for post-processing : The first way \CITE is to build a ranker or a classifier specific to the given query using the returned images .
#<struct ReadData::Alignment source_numbers="7", target_numbers="8", tag_name="wa">
There are two ways for post-processing : The first way \CITE is to build a ranker or a classifier specific to the given query using the returned images .
#<struct ReadData::Alignment source_numbers="8", target_numbers="9", tag_name="wa">
There are two ways for post-processing : The first way \CITE is to build a ranker or a classifier specific to the given query using the returned images .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
There are two ways for post-processing : The first way \CITE is to build a ranker or a classifier specific to the given query using the returned images .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
There are two ways for post-processing : The first way \CITE is to build a ranker or a classifier specific to the given query using the returned images .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
There are two ways for post-processing : The first way \CITE is to build a ranker or a classifier specific to the given query using the returned images .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
As a result , this way is not scalable for applications processing very large number of queries .
#<struct ReadData::Alignment source_numbers="11", target_numbers="12", tag_name="wa">
As a result , this way is not scalable for applications processing very large number of queries .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
This way is more scalable and can be used for practical applications such as meta search engines .
#<struct ReadData::Alignment source_numbers="0", target_numbers="0", tag_name="wa">
This way is more scalable and can be used for practical applications such as meta search engines .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
This way is more scalable and can be used for practical applications such as meta search engines .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
This way is more scalable and can be used for practical applications such as meta search engines .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
This way is more scalable and can be used for practical applications such as meta search engines .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
We follow the latter way for the problem of face retrieval in which the system enables users to search persons's appearance by their names .
#<struct ReadData::Alignment source_numbers="4,5", target_numbers="4,5", tag_name="wa">
We follow the latter way for the problem of face retrieval in which the system enables users to search persons's appearance by their names .
#<struct ReadData::Alignment source_numbers="7,8", target_numbers="8,9", tag_name="wa">
We follow the latter way for the problem of face retrieval in which the system enables users to search persons's appearance by their names .
#<struct ReadData::Alignment source_numbers="20", target_numbers="21", tag_name="wa">
We follow the latter way for the problem of face retrieval in which the system enables users to search persons's appearance by their names .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
We follow the latter way for the problem of face retrieval in which the system enables users to search persons's appearance by their names .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
We follow the latter way for the problem of face retrieval in which the system enables users to search persons's appearance by their names .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
Our system re-ranks the faces returned by text-based search engines by a generic classifier that is trained in advance using visual information before returning to the user .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Our system re-ranks the faces returned by text-based search engines by a generic classifier that is trained in advance using visual information before returning to the user .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Building such generic classifiers requires solving two problems : finding good query-relative representation of faces and collecting a large labeled dataset for training the classifier .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Building such generic classifiers requires solving two problems : finding good query-relative representation of faces and collecting a large labeled dataset for training the classifier .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Building such generic classifiers requires solving two problems : finding good query-relative representation of faces and collecting a large labeled dataset for training the classifier .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Building such generic classifiers requires solving two problems : finding good query-relative representation of faces and collecting a large labeled dataset for training the classifier .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
By addressing these problems , Our contribution is two-fold :
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
By addressing these problems , Our contribution is two-fold :
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
By addressing these problems , Our contribution is two-fold :
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
In this framework , We learn a relevance classifier that classifies whether an input face is relevant to the associated query or not .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
In this framework , We learn a relevance classifier that classifies whether an input face is relevant to the associated query or not .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
In this framework , We learn a relevance classifier that classifies whether an input face is relevant to the associated query or not .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
This approach is different from existing approaches such as \CITE that learn a classifier to recognize the identity of the returned faces .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
This approach is different from existing approaches such as \CITE that learn a classifier to recognize the identity of the returned faces .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
This approach is different from existing approaches such as \CITE that learn a classifier to recognize the identity of the returned faces .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
This approach is different from existing approaches such as \CITE that learn a classifier to recognize the identity of the returned faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
this classifier is independent with the identity of faces , so it can be shared for multiple queries (cf . Figure \REF) .
#<struct ReadData::Alignment source_numbers="3,4", target_numbers="4,5", tag_name="wa">
this classifier is independent with the identity of faces , so it can be shared for multiple queries (cf . Figure \REF) .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
this classifier is independent with the identity of faces , so it can be shared for multiple queries (cf . Figure \REF) .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
this classifier is independent with the identity of faces , so it can be shared for multiple queries (cf . Figure \REF) .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
this classifier is independent with the identity of faces , so it can be shared for multiple queries (cf . Figure \REF) .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
this classifier is independent with the identity of faces , so it can be shared for multiple queries (cf . Figure \REF) .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
this classifier is independent with the identity of faces , so it can be shared for multiple queries (cf . Figure \REF) .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
experimental results show that the relevance classifier that is independent with underlying ranking algorithm of existing search engines can significantly boost the performance .
#<struct ReadData::Alignment source_numbers="9,10", target_numbers="10,11", tag_name="wa">
experimental results show that the relevance classifier that is independent with underlying ranking algorithm of existing search engines can significantly boost the performance .
#<struct ReadData::Alignment source_numbers="21", target_numbers="12", tag_name="wa">
-We propose a simple yet efficient mining technique for automatically collecting labeled data for training the generic classifier .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
-We propose a simple yet efficient mining technique for automatically collecting labeled data for training the generic classifier .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Specifically , We detect and group faces of persons appearing in video programs in face tracks in which each face track contains of the faces of one person .
#<struct ReadData::Alignment source_numbers="22", target_numbers="6", tag_name="wa">
Specifically , We detect and group faces of persons appearing in video programs in face tracks in which each face track contains of the faces of one person .
#<struct ReadData::Alignment source_numbers="7,8", target_numbers="7", tag_name="wa">
Specifically , We detect and group faces of persons appearing in video programs in face tracks in which each face track contains of the faces of one person .
#<struct ReadData::Alignment source_numbers="21", target_numbers="20", tag_name="wa">
Specifically , We detect and group faces of persons appearing in video programs in face tracks in which each face track contains of the faces of one person .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Specifically , We detect and group faces of persons appearing in video programs in face tracks in which each face track contains of the faces of one person .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Specifically , We detect and group faces of persons appearing in video programs in face tracks in which each face track contains of the faces of one person .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
To distinguish face tracks of different persons , we assume that if multiple faces are detected at different locations in one frame , they are of different persons (cf . Figure \REF) .
#<struct ReadData::Alignment source_numbers="9,10", target_numbers="10,11", tag_name="wa">
To distinguish face tracks of different persons , we assume that if multiple faces are detected at different locations in one frame , they are of different persons (cf . Figure \REF) .
#<struct ReadData::Alignment source_numbers="24,25", target_numbers="15", tag_name="wa">
To distinguish face tracks of different persons , we assume that if multiple faces are detected at different locations in one frame , they are of different persons (cf . Figure \REF) .
#<struct ReadData::Alignment source_numbers="14", target_numbers="25,26", tag_name="wa">
To distinguish face tracks of different persons , we assume that if multiple faces are detected at different locations in one frame , they are of different persons (cf . Figure \REF) .
#<struct ReadData::Alignment source_numbers="29", target_numbers="32", tag_name="wa">
To distinguish face tracks of different persons , we assume that if multiple faces are detected at different locations in one frame , they are of different persons (cf . Figure \REF) .
#<struct ReadData::Alignment source_numbers="28", target_numbers="", tag_name="wa">
To distinguish face tracks of different persons , we assume that if multiple faces are detected at different locations in one frame , they are of different persons (cf . Figure \REF) .
#<struct ReadData::Alignment source_numbers="30", target_numbers="", tag_name="wa">
To distinguish face tracks of different persons , we assume that if multiple faces are detected at different locations in one frame , they are of different persons (cf . Figure \REF) .
#<struct ReadData::Alignment source_numbers="31", target_numbers="", tag_name="wa">
To distinguish face tracks of different persons , we assume that if multiple faces are detected at different locations in one frame , they are of different persons (cf . Figure \REF) .
#<struct ReadData::Alignment source_numbers="32", target_numbers="", tag_name="wa">
To distinguish face tracks of different persons , we assume that if multiple faces are detected at different locations in one frame , they are of different persons (cf . Figure \REF) .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
To distinguish face tracks of different persons , we assume that if multiple faces are detected at different locations in one frame , they are of different persons (cf . Figure \REF) .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
To distinguish face tracks of different persons , we assume that if multiple faces are detected at different locations in one frame , they are of different persons (cf . Figure \REF) .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
Using this assumption , we collect the face tracks whose faces are detected in the same frames to guarantee that each face track is associated to one unique person .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
Using this assumption , we collect the face tracks whose faces are detected in the same frames to guarantee that each face track is associated to one unique person .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
To enlarge the number of such face tracks , We use video programs of multiple genres and channels .
#<struct ReadData::Alignment source_numbers="1", target_numbers="10", tag_name="wa">
To enlarge the number of such face tracks , We use video programs of multiple genres and channels .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
To enlarge the number of such face tracks , We use video programs of multiple genres and channels .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
To enlarge the number of such face tracks , We use video programs of multiple genres and channels .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
To enlarge the number of such face tracks , We use video programs of multiple genres and channels .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
To enlarge the number of such face tracks , We use video programs of multiple genres and channels .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
From these faces , We can artificially generate face sets similar to the sets returned by search engines given person names .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
From these faces , We can artificially generate face sets similar to the sets returned by search engines given person names .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
From these faces , We can artificially generate face sets similar to the sets returned by search engines given person names .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
From these faces , We can artificially generate face sets similar to the sets returned by search engines given person names .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
From these faces , We can artificially generate face sets similar to the sets returned by search engines given person names .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
Since we know the relevance of these faces to the artificial sets , the labels of each face can be easily generated and no human intervention is needed for this process .
#<struct ReadData::Alignment source_numbers="28", target_numbers="15", tag_name="wa">
Since we know the relevance of these faces to the artificial sets , the labels of each face can be easily generated and no human intervention is needed for this process .
#<struct ReadData::Alignment source_numbers="18,19", target_numbers="18,19", tag_name="wa">
Since we know the relevance of these faces to the artificial sets , the labels of each face can be easily generated and no human intervention is needed for this process .
#<struct ReadData::Alignment source_numbers="26,27", target_numbers="26,27", tag_name="wa">
Since we know the relevance of these faces to the artificial sets , the labels of each face can be easily generated and no human intervention is needed for this process .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
Since we know the relevance of these faces to the artificial sets , the labels of each face can be easily generated and no human intervention is needed for this process .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
Note that the label of faces in our approach is not identity of that face . It is the relevance between the face and the associated query .
#<struct ReadData::Alignment source_numbers="18", target_numbers="2", tag_name="wa">
Note that the label of faces in our approach is not identity of that face . It is the relevance between the face and the associated query .
#<struct ReadData::Alignment source_numbers="2,3", target_numbers="3", tag_name="wa">
Note that the label of faces in our approach is not identity of that face . It is the relevance between the face and the associated query .
#<struct ReadData::Alignment source_numbers="9", target_numbers="9", tag_name="wa">
Note that the label of faces in our approach is not identity of that face . It is the relevance between the face and the associated query .
#<struct ReadData::Alignment source_numbers="24", target_numbers="15", tag_name="wa">
Note that the label of faces in our approach is not identity of that face . It is the relevance between the face and the associated query .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
Note that the label of faces in our approach is not identity of that face . It is the relevance between the face and the associated query .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
Note that the label of faces in our approach is not identity of that face . It is the relevance between the face and the associated query .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
Note that the label of faces in our approach is not identity of that face . It is the relevance between the face and the associated query .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
Note that the label of faces in our approach is not identity of that face . It is the relevance between the face and the associated query .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
Note that the label of faces in our approach is not identity of that face . It is the relevance between the face and the associated query .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
Note that the label of faces in our approach is not identity of that face . It is the relevance between the face and the associated query .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
Note that the label of faces in our approach is not identity of that face . It is the relevance between the face and the associated query .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Note that the label of faces in our approach is not identity of that face . It is the relevance between the face and the associated query .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Note that the label of faces in our approach is not identity of that face . It is the relevance between the face and the associated query .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
Collecting training sets from such external sources as video archives is easy and efficient because : firstly , a large number of videos can be easy to obtain .
#<struct ReadData::Alignment source_numbers="17", target_numbers="17", tag_name="wa">
Collecting training sets from such external sources as video archives is easy and efficient because : firstly , a large number of videos can be easy to obtain .
#<struct ReadData::Alignment source_numbers="25,26", target_numbers="25", tag_name="wa">
Collecting training sets from such external sources as video archives is easy and efficient because : firstly , a large number of videos can be easy to obtain .
#<struct ReadData::Alignment source_numbers="27", target_numbers="26", tag_name="wa">
Collecting training sets from such external sources as video archives is easy and efficient because : firstly , a large number of videos can be easy to obtain .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
Collecting training sets from such external sources as video archives is easy and efficient because : firstly , a large number of videos can be easy to obtain .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
For example , people can record broadcast videos of different channels in a certain period .
#<struct ReadData::Alignment source_numbers="8,9", target_numbers="8,9", tag_name="wa">
For example , people can record broadcast videos of different channels in a certain period .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
For example , people can record broadcast videos of different channels in a certain period .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
Secondly , a huge number of faces can be obtained by applying the face detector in every frame .
#<struct ReadData::Alignment source_numbers="17", target_numbers="17", tag_name="wa">
Secondly , a huge number of faces can be obtained by applying the face detector in every frame .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
Secondly , a huge number of faces can be obtained by applying the face detector in every frame .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
Secondly , a huge number of faces can be obtained by applying the face detector in every frame .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
Secondly , a huge number of faces can be obtained by applying the face detector in every frame .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
Secondly , a huge number of faces can be obtained by applying the face detector in every frame .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
Secondly , a huge number of faces can be obtained by applying the face detector in every frame .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
In addition , using temporal information , faces of one person appearing in consecutive frames can be automatically grouped with high accuracy .
#<struct ReadData::Alignment source_numbers="20", target_numbers="18", tag_name="wa">
In addition , using temporal information , faces of one person appearing in consecutive frames can be automatically grouped with high accuracy .
#<struct ReadData::Alignment source_numbers="21", target_numbers="21", tag_name="wa">
In addition , using temporal information , faces of one person appearing in consecutive frames can be automatically grouped with high accuracy .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
In addition , using temporal information , faces of one person appearing in consecutive frames can be automatically grouped with high accuracy .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
In addition , using temporal information , faces of one person appearing in consecutive frames can be automatically grouped with high accuracy .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
In addition , using temporal information , faces of one person appearing in consecutive frames can be automatically grouped with high accuracy .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
given a query described by text , for example , 'airplane' or 'George Bush' , finding relevant images with high precision is essential for image search engines .
#<struct ReadData::Alignment source_numbers="21", target_numbers="1", tag_name="wa">
given a query described by text , for example , 'airplane' or 'George Bush' , finding relevant images with high precision is essential for image search engines .
#<struct ReadData::Alignment source_numbers="22", target_numbers="2", tag_name="wa">
given a query described by text , for example , 'airplane' or 'George Bush' , finding relevant images with high precision is essential for image search engines .
#<struct ReadData::Alignment source_numbers="23", target_numbers="3", tag_name="wa">
given a query described by text , for example , 'airplane' or 'George Bush' , finding relevant images with high precision is essential for image search engines .
#<struct ReadData::Alignment source_numbers="26", target_numbers="5", tag_name="wa">
given a query described by text , for example , 'airplane' or 'George Bush' , finding relevant images with high precision is essential for image search engines .
#<struct ReadData::Alignment source_numbers="1", target_numbers="11", tag_name="wa">
given a query described by text , for example , 'airplane' or 'George Bush' , finding relevant images with high precision is essential for image search engines .
#<struct ReadData::Alignment source_numbers="19", target_numbers="12", tag_name="wa">
given a query described by text , for example , 'airplane' or 'George Bush' , finding relevant images with high precision is essential for image search engines .
#<struct ReadData::Alignment source_numbers="20", target_numbers="15", tag_name="wa">
given a query described by text , for example , 'airplane' or 'George Bush' , finding relevant images with high precision is essential for image search engines .
#<struct ReadData::Alignment source_numbers="2", target_numbers="17", tag_name="wa">
given a query described by text , for example , 'airplane' or 'George Bush' , finding relevant images with high precision is essential for image search engines .
#<struct ReadData::Alignment source_numbers="6", target_numbers="21", tag_name="wa">
given a query described by text , for example , 'airplane' or 'George Bush' , finding relevant images with high precision is essential for image search engines .
#<struct ReadData::Alignment source_numbers="9", target_numbers="23", tag_name="wa">
given a query described by text , for example , 'airplane' or 'George Bush' , finding relevant images with high precision is essential for image search engines .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
given a query described by text , for example , 'airplane' or 'George Bush' , finding relevant images with high precision is essential for image search engines .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
given a query described by text , for example , 'airplane' or 'George Bush' , finding relevant images with high precision is essential for image search engines .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
given a query described by text , for example , 'airplane' or 'George Bush' , finding relevant images with high precision is essential for image search engines .
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
given a query described by text , for example , 'airplane' or 'George Bush' , finding relevant images with high precision is essential for image search engines .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
given a query described by text , for example , 'airplane' or 'George Bush' , finding relevant images with high precision is essential for image search engines .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
given a query described by text , for example , 'airplane' or 'George Bush' , finding relevant images with high precision is essential for image search engines .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
given a query described by text , for example , 'airplane' or 'George Bush' , finding relevant images with high precision is essential for image search engines .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
given a query described by text , for example , 'airplane' or 'George Bush' , finding relevant images with high precision is essential for image search engines .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
given a query described by text , for example , 'airplane' or 'George Bush' , finding relevant images with high precision is essential for image search engines .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
Existing image search engines usually use textual information associated with the images such as filename , image caption , and surrounding text for ranking that leads to poor precision .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Existing image search engines usually use textual information associated with the images such as filename , image caption , and surrounding text for ranking that leads to poor precision .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Existing image search engines usually use textual information associated with the images such as filename , image caption , and surrounding text for ranking that leads to poor precision .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
The idea is to rely on the visual consistency among these images to learn visual classifiers that measure the relevancy between an image and the input query .
#<struct ReadData::Alignment source_numbers="20", target_numbers="9", tag_name="wa">
The idea is to rely on the visual consistency among these images to learn visual classifiers that measure the relevancy between an image and the input query .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
The idea is to rely on the visual consistency among these images to learn visual classifiers that measure the relevancy between an image and the input query .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
There are different approaches described in \CITE for re-ranking images containing general objects and faces returned from text-based search engines .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
There are different approaches described in \CITE for re-ranking images containing general objects and faces returned from text-based search engines .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
There are different approaches described in \CITE for re-ranking images containing general objects and faces returned from text-based search engines .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
There are different approaches described in \CITE for re-ranking images containing general objects and faces returned from text-based search engines .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Work such as \CITE extend topics models using probabilistic Late Semantic Analysis , Latent Dirichlet Allocation , or Hierarchical Dirichlet Process to learn generative model based classifiers .
#<struct ReadData::Alignment source_numbers="0", target_numbers="0", tag_name="wa">
Work such as \CITE extend topics models using probabilistic Late Semantic Analysis , Latent Dirichlet Allocation , or Hierarchical Dirichlet Process to learn generative model based classifiers .
#<struct ReadData::Alignment source_numbers="3", target_numbers="1", tag_name="wa">
Work such as \CITE extend topics models using probabilistic Late Semantic Analysis , Latent Dirichlet Allocation , or Hierarchical Dirichlet Process to learn generative model based classifiers .
#<struct ReadData::Alignment source_numbers="4", target_numbers="3,4", tag_name="wa">
Work such as \CITE extend topics models using probabilistic Late Semantic Analysis , Latent Dirichlet Allocation , or Hierarchical Dirichlet Process to learn generative model based classifiers .
#<struct ReadData::Alignment source_numbers="5", target_numbers="5", tag_name="wa">
Work such as \CITE extend topics models using probabilistic Late Semantic Analysis , Latent Dirichlet Allocation , or Hierarchical Dirichlet Process to learn generative model based classifiers .
#<struct ReadData::Alignment source_numbers="6", target_numbers="7", tag_name="wa">
Work such as \CITE extend topics models using probabilistic Late Semantic Analysis , Latent Dirichlet Allocation , or Hierarchical Dirichlet Process to learn generative model based classifiers .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Work such as \CITE extend topics models using probabilistic Late Semantic Analysis , Latent Dirichlet Allocation , or Hierarchical Dirichlet Process to learn generative model based classifiers .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Work such as \CITE extend topics models using probabilistic Late Semantic Analysis , Latent Dirichlet Allocation , or Hierarchical Dirichlet Process to learn generative model based classifiers .
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
Work such as \CITE extend topics models using probabilistic Late Semantic Analysis , Latent Dirichlet Allocation , or Hierarchical Dirichlet Process to learn generative model based classifiers .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
Work such as \CITE extend topics models using probabilistic Late Semantic Analysis , Latent Dirichlet Allocation , or Hierarchical Dirichlet Process to learn generative model based classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Work such as \CITE extend topics models using probabilistic Late Semantic Analysis , Latent Dirichlet Allocation , or Hierarchical Dirichlet Process to learn generative model based classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Work such as \CITE extend topics models using probabilistic Late Semantic Analysis , Latent Dirichlet Allocation , or Hierarchical Dirichlet Process to learn generative model based classifiers .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
These models can handle noisy image data in some degree .
#<struct ReadData::Alignment source_numbers="6,7", target_numbers="6,7", tag_name="wa">
However , they have many parameters needed to be tuned such as number of topics and feature configurations .
#<struct ReadData::Alignment source_numbers="6", target_numbers="7", tag_name="wa">
However , they have many parameters needed to be tuned such as number of topics and feature configurations .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
In addition , how to select the best topic associated with the input query for identifying target label is still challenging \CITE .
#<struct ReadData::Alignment source_numbers="3", target_numbers="3", tag_name="wa">
In addition , how to select the best topic associated with the input query for identifying target label is still challenging \CITE .
#<struct ReadData::Alignment source_numbers="6", target_numbers="4", tag_name="wa">
In addition , how to select the best topic associated with the input query for identifying target label is still challenging \CITE .
#<struct ReadData::Alignment source_numbers="7", target_numbers="5", tag_name="wa">
In addition , how to select the best topic associated with the input query for identifying target label is still challenging \CITE .
#<struct ReadData::Alignment source_numbers="8", target_numbers="6", tag_name="wa">
In addition , how to select the best topic associated with the input query for identifying target label is still challenging \CITE .
#<struct ReadData::Alignment source_numbers="18", target_numbers="7", tag_name="wa">
In addition , how to select the best topic associated with the input query for identifying target label is still challenging \CITE .
#<struct ReadData::Alignment source_numbers="4", target_numbers="14", tag_name="wa">
In addition , how to select the best topic associated with the input query for identifying target label is still challenging \CITE .
#<struct ReadData::Alignment source_numbers="15", target_numbers="15,16", tag_name="wa">
In addition , how to select the best topic associated with the input query for identifying target label is still challenging \CITE .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
In addition , how to select the best topic associated with the input query for identifying target label is still challenging \CITE .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
In addition , how to select the best topic associated with the input query for identifying target label is still challenging \CITE .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
In addition , how to select the best topic associated with the input query for identifying target label is still challenging \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
In addition , how to select the best topic associated with the input query for identifying target label is still challenging \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
In addition , how to select the best topic associated with the input query for identifying target label is still challenging \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
In addition , how to select the best topic associated with the input query for identifying target label is still challenging \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
In addition , how to select the best topic associated with the input query for identifying target label is still challenging \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
In \CITE , Textual information is used to build a text ranker to re-rank the returned images \CITE .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
In \CITE , Textual information is used to build a text ranker to re-rank the returned images \CITE .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
In \CITE , Textual information is used to build a text ranker to re-rank the returned images \CITE .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
The top images in this ranked list are used as positive samples to train visual classifiers using SVM (Support vector machines) .
#<struct ReadData::Alignment source_numbers="7,8", target_numbers="7,8", tag_name="wa">
The top images in this ranked list are used as positive samples to train visual classifiers using SVM (Support vector machines) .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
The top images in this ranked list are used as positive samples to train visual classifiers using SVM (Support vector machines) .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
The top images in this ranked list are used as positive samples to train visual classifiers using SVM (Support vector machines) .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
The top images in this ranked list are used as positive samples to train visual classifiers using SVM (Support vector machines) .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
The top images in this ranked list are used as positive samples to train visual classifiers using SVM (Support vector machines) .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
The top images in this ranked list are used as positive samples to train visual classifiers using SVM (Support vector machines) .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
This method makes the training data cleaner that leads to performance improvement .
#<struct ReadData::Alignment source_numbers="8,9", target_numbers="8,9", tag_name="wa">
This method makes the training data cleaner that leads to performance improvement .
#<struct ReadData::Alignment source_numbers="10", target_numbers="11", tag_name="wa">
This method makes the training data cleaner that leads to performance improvement .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
This method makes the training data cleaner that leads to performance improvement .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
This method makes the training data cleaner that leads to performance improvement .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
This method makes the training data cleaner that leads to performance improvement .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
In \CITE , A multiple instance learning framework is used to learn category models from images associated with keywords \CITE .
#<struct ReadData::Alignment source_numbers="20", target_numbers="17", tag_name="wa">
In \CITE , A multiple instance learning framework is used to learn category models from images associated with keywords \CITE .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
In \CITE , A multiple instance learning framework is used to learn category models from images associated with keywords \CITE .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
In \CITE , A multiple instance learning framework is used to learn category models from images associated with keywords \CITE .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
In \CITE , A multiple instance learning framework is used to learn category models from images associated with keywords \CITE .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
In \CITE , A multiple instance learning framework is used to learn category models from images associated with keywords \CITE .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
In \CITE , A multiple instance learning framework is used to learn category models from images associated with keywords \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
The work mentioned above are for re-ranking images containing general objects .
#<struct ReadData::Alignment source_numbers="6", target_numbers="2", tag_name="wa">
The work mentioned above are for re-ranking images containing general objects .
#<struct ReadData::Alignment source_numbers="11", target_numbers="7", tag_name="wa">
The work mentioned above are for re-ranking images containing general objects .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
The work mentioned above are for re-ranking images containing general objects .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
The work mentioned above are for re-ranking images containing general objects .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
The work mentioned above are for re-ranking images containing general objects .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
The work mentioned above are for re-ranking images containing general objects .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
The work mentioned above are for re-ranking images containing general objects .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
The work mentioned above are for re-ranking images containing general objects .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
The work mentioned above are for re-ranking images containing general objects .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
For re-ranking faces , work described in \CITE use Gaussian mixture models to build face recognizers and apply these recognizers back to the input faces for re-ranking \CITE .
#<struct ReadData::Alignment source_numbers="8", target_numbers="4,5", tag_name="wa">
For re-ranking faces , work described in \CITE use Gaussian mixture models to build face recognizers and apply these recognizers back to the input faces for re-ranking \CITE .
#<struct ReadData::Alignment source_numbers="25", target_numbers="6", tag_name="wa">
For re-ranking faces , work described in \CITE use Gaussian mixture models to build face recognizers and apply these recognizers back to the input faces for re-ranking \CITE .
#<struct ReadData::Alignment source_numbers="27", target_numbers="24", tag_name="wa">
For re-ranking faces , work described in \CITE use Gaussian mixture models to build face recognizers and apply these recognizers back to the input faces for re-ranking \CITE .
#<struct ReadData::Alignment source_numbers="28", target_numbers="25", tag_name="wa">
For re-ranking faces , work described in \CITE use Gaussian mixture models to build face recognizers and apply these recognizers back to the input faces for re-ranking \CITE .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
For re-ranking faces , work described in \CITE use Gaussian mixture models to build face recognizers and apply these recognizers back to the input faces for re-ranking \CITE .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
For re-ranking faces , work described in \CITE use Gaussian mixture models to build face recognizers and apply these recognizers back to the input faces for re-ranking \CITE .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
For re-ranking faces , work described in \CITE use Gaussian mixture models to build face recognizers and apply these recognizers back to the input faces for re-ranking \CITE .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
For re-ranking faces , work described in \CITE use Gaussian mixture models to build face recognizers and apply these recognizers back to the input faces for re-ranking \CITE .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
For re-ranking faces , work described in \CITE use Gaussian mixture models to build face recognizers and apply these recognizers back to the input faces for re-ranking \CITE .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
For re-ranking faces , work described in \CITE use Gaussian mixture models to build face recognizers and apply these recognizers back to the input faces for re-ranking \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
For re-ranking faces , work described in \CITE use Gaussian mixture models to build face recognizers and apply these recognizers back to the input faces for re-ranking \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
In \CITE , Discriminative approach based models such as SVM and linear discriminant analysis are used instead of Gaussian mixture models \CITE .
#<struct ReadData::Alignment source_numbers="14", target_numbers="9,10", tag_name="wa">
In \CITE , Discriminative approach based models such as SVM and linear discriminant analysis are used instead of Gaussian mixture models \CITE .
#<struct ReadData::Alignment source_numbers="15", target_numbers="11", tag_name="wa">
In \CITE , Discriminative approach based models such as SVM and linear discriminant analysis are used instead of Gaussian mixture models \CITE .
#<struct ReadData::Alignment source_numbers="21", target_numbers="17", tag_name="wa">
In \CITE , Discriminative approach based models such as SVM and linear discriminant analysis are used instead of Gaussian mixture models \CITE .
#<struct ReadData::Alignment source_numbers="22", target_numbers="18", tag_name="wa">
In \CITE , Discriminative approach based models such as SVM and linear discriminant analysis are used instead of Gaussian mixture models \CITE .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
In \CITE , Discriminative approach based models such as SVM and linear discriminant analysis are used instead of Gaussian mixture models \CITE .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
In \CITE , Discriminative approach based models such as SVM and linear discriminant analysis are used instead of Gaussian mixture models \CITE .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
In \CITE , Discriminative approach based models such as SVM and linear discriminant analysis are used instead of Gaussian mixture models \CITE .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
In \CITE , Discriminative approach based models such as SVM and linear discriminant analysis are used instead of Gaussian mixture models \CITE .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
In \CITE , Discriminative approach based models such as SVM and linear discriminant analysis are used instead of Gaussian mixture models \CITE .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
In \CITE , Discriminative approach based models such as SVM and linear discriminant analysis are used instead of Gaussian mixture models \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
In \CITE , A densest graph based method is used for finding the face group relevant to the query \CITE .
#<struct ReadData::Alignment source_numbers="8", target_numbers="3,4", tag_name="wa">
In \CITE , A densest graph based method is used for finding the face group relevant to the query \CITE .
#<struct ReadData::Alignment source_numbers="9", target_numbers="5", tag_name="wa">
In \CITE , A densest graph based method is used for finding the face group relevant to the query \CITE .
#<struct ReadData::Alignment source_numbers="20", target_numbers="16", tag_name="wa">
In \CITE , A densest graph based method is used for finding the face group relevant to the query \CITE .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
In \CITE , A densest graph based method is used for finding the face group relevant to the query \CITE .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
In \CITE , A densest graph based method is used for finding the face group relevant to the query \CITE .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
In \CITE , A densest graph based method is used for finding the face group relevant to the query \CITE .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
In \CITE , A densest graph based method is used for finding the face group relevant to the query \CITE .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
In \CITE , A densest graph based method is used for finding the face group relevant to the query \CITE .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
In \CITE , A densest graph based method is used for finding the face group relevant to the query \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
As for these approaches , One specific classifier is built for each query .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
As for these approaches , One specific classifier is built for each query .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
As for these approaches , One specific classifier is built for each query .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
As for these approaches , One specific classifier is built for each query .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Therefore , to handle a large number of queries , many classifiers must be built which are not suitable in practice .
#<struct ReadData::Alignment source_numbers="9", target_numbers="1", tag_name="wa">
Therefore , to handle a large number of queries , many classifiers must be built which are not suitable in practice .
#<struct ReadData::Alignment source_numbers="1", target_numbers="14", tag_name="wa">
Therefore , to handle a large number of queries , many classifiers must be built which are not suitable in practice .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
In \CITE{Krapac10CVPR} , Only one generic classifier is built in advance \CITE and then used for all queries .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
In \CITE{Krapac10CVPR} , Only one generic classifier is built in advance \CITE and then used for all queries .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
This generic classifier is a relevance classifier that learns relevancy between an image and the query .
#<struct ReadData::Alignment source_numbers="3,4", target_numbers="3,4", tag_name="wa">
As for specific classifiers , Each image is classified as 'class-A' or 'non-class-A' , where 'class-A' is the category associated with the query , for example , 'airplane' .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
As for specific classifiers , Each image is classified as 'class-A' or 'non-class-A' , where 'class-A' is the category associated with the query , for example , 'airplane' .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
As for specific classifiers , Each image is classified as 'class-A' or 'non-class-A' , where 'class-A' is the category associated with the query , for example , 'airplane' .
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
As for specific classifiers , Each image is classified as 'class-A' or 'non-class-A' , where 'class-A' is the category associated with the query , for example , 'airplane' .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
As for specific classifiers , Each image is classified as 'class-A' or 'non-class-A' , where 'class-A' is the category associated with the query , for example , 'airplane' .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
In generic classifier , Each image is classified as relevant or irrelevant to the query .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
In generic classifier , Each image is classified as relevant or irrelevant to the query .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
In generic classifier , Each image is classified as relevant or irrelevant to the query .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Therefore , it is independent to class labels and can be used for any query .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Therefore , it is independent to class labels and can be used for any query .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
This method works well for objects such as car , flag , but fails to handle faces .
#<struct ReadData::Alignment source_numbers="11", target_numbers="11", tag_name="wa">
This method works well for objects such as car , flag , but fails to handle faces .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
This method works well for objects such as car , flag , but fails to handle faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Our method is inspired by the generic classifier based approach .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
Our method is inspired by the generic classifier based approach .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Our method is inspired by the generic classifier based approach .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Our method is inspired by the generic classifier based approach .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
We extend it by two means : first , query-dependent features specific for faces are proposed , and second , the training data for learning the generic classifier is collected automatically by mining video archives .
#<struct ReadData::Alignment source_numbers="3,4", target_numbers="3,4", tag_name="wa">
We extend it by two means : first , query-dependent features specific for faces are proposed , and second , the training data for learning the generic classifier is collected automatically by mining video archives .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
We extend it by two means : first , query-dependent features specific for faces are proposed , and second , the training data for learning the generic classifier is collected automatically by mining video archives .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
Given a set of faces returned by any search engine for a queried person ( e .g . 'George Bush' ) , our task is to re-rank these faces to improve the precision .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
Given a set of faces returned by any search engine for a queried person ( e .g . 'George Bush' ) , our task is to re-rank these faces to improve the precision .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
Given a set of faces returned by any search engine for a queried person ( e .g . 'George Bush' ) , our task is to re-rank these faces to improve the precision .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
Given a set of faces returned by any search engine for a queried person ( e .g . 'George Bush' ) , our task is to re-rank these faces to improve the precision .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
Given a set of faces returned by any search engine for a queried person ( e .g . 'George Bush' ) , our task is to re-rank these faces to improve the precision .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
The ranked list is then return to users as shown in Figure \REF( b ) .
#<struct ReadData::Alignment source_numbers="5,6", target_numbers="5,6", tag_name="wa">
This approach is different from existing approaches such as \CITE as shown in Figure \REF( a ) in which one specific classifier is built for each query .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
This approach is different from existing approaches such as \CITE as shown in Figure \REF( a ) in which one specific classifier is built for each query .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
This approach is different from existing approaches such as \CITE as shown in Figure \REF( a ) in which one specific classifier is built for each query .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
To build the specific classifier for re-ranking faces returned by the query of 'personX' , each face is represented by the query-independent feature such as pixel intensity around facial features such as eyes , nose , and mouth \CITE .
#<struct ReadData::Alignment source_numbers="2", target_numbers="32", tag_name="wa">
To build the specific classifier for re-ranking faces returned by the query of 'personX' , each face is represented by the query-independent feature such as pixel intensity around facial features such as eyes , nose , and mouth \CITE .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
To build the specific classifier for re-ranking faces returned by the query of 'personX' , each face is represented by the query-independent feature such as pixel intensity around facial features such as eyes , nose , and mouth \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
To build the specific classifier for re-ranking faces returned by the query of 'personX' , each face is represented by the query-independent feature such as pixel intensity around facial features such as eyes , nose , and mouth \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
Meanwhile , to build the generic classifier which is independent with any \textit{'personX'} , each face is represented by the query-dependent feature .
#<struct ReadData::Alignment source_numbers="13", target_numbers="1", tag_name="wa">
Meanwhile , to build the generic classifier which is independent with any \textit{'personX'} , each face is represented by the query-dependent feature .
#<struct ReadData::Alignment source_numbers="7,8", target_numbers="15,16", tag_name="wa">
Meanwhile , to build the generic classifier which is independent with any \textit{'personX'} , each face is represented by the query-dependent feature .
#<struct ReadData::Alignment source_numbers="9,10", target_numbers="17,18", tag_name="wa">
Meanwhile , to build the generic classifier which is independent with any \textit{'personX'} , each face is represented by the query-dependent feature .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Meanwhile , to build the generic classifier which is independent with any \textit{'personX'} , each face is represented by the query-dependent feature .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Meanwhile , to build the generic classifier which is independent with any \textit{'personX'} , each face is represented by the query-dependent feature .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
Meanwhile , to build the generic classifier which is independent with any \textit{'personX'} , each face is represented by the query-dependent feature .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
Meanwhile , to build the generic classifier which is independent with any \textit{'personX'} , each face is represented by the query-dependent feature .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Meanwhile , to build the generic classifier which is independent with any \textit{'personX'} , each face is represented by the query-dependent feature .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
Meanwhile , to build the generic classifier which is independent with any \textit{'personX'} , each face is represented by the query-dependent feature .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
In \CITE , the Query-dependent features using textual information are proposed \CITE .
#<struct ReadData::Alignment source_numbers="9", target_numbers="6", tag_name="wa">
In \CITE , the Query-dependent features using textual information are proposed \CITE .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
In \CITE , the Query-dependent features using textual information are proposed \CITE .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
In \CITE , the Query-dependent features using textual information are proposed \CITE .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
In \CITE , the Query-dependent features using textual information are proposed \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Each feature is treated as binary indicating the presence or absence of the query terms in textual data associated with the input image , for example , filename , image title , and nearby text .
#<struct ReadData::Alignment source_numbers="2,3", target_numbers="2,3", tag_name="wa">
Each feature is treated as binary indicating the presence or absence of the query terms in textual data associated with the input image , for example , filename , image title , and nearby text .
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
Each feature is treated as binary indicating the presence or absence of the query terms in textual data associated with the input image , for example , filename , image title , and nearby text .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
Each feature is treated as binary indicating the presence or absence of the query terms in textual data associated with the input image , for example , filename , image title , and nearby text .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
Extending this query-dependent feature for using visual information is not trivial since we can not compute the presence and absence of the query term such as 'George Bush' in each face .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
Extending this query-dependent feature for using visual information is not trivial since we can not compute the presence and absence of the query term such as 'George Bush' in each face .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
In \CITE , Each image \CITE is represented as a set of visual words .
#<struct ReadData::Alignment source_numbers="5", target_numbers="3", tag_name="wa">
In \CITE , Each image \CITE is represented as a set of visual words .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
In \CITE , Each image \CITE is represented as a set of visual words .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
In \CITE , Each image \CITE is represented as a set of visual words .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
In \CITE , Each image \CITE is represented as a set of visual words .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Since this method is suitable for general objects rather than faces , we proposed another method described below for extracting query-dependent features to train the generic classifier .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
Since this method is suitable for general objects rather than faces , we proposed another method described below for extracting query-dependent features to train the generic classifier .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
Since this method is suitable for general objects rather than faces , we proposed another method described below for extracting query-dependent features to train the generic classifier .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
Since this method is suitable for general objects rather than faces , we proposed another method described below for extracting query-dependent features to train the generic classifier .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
To be able to model the relevance between a face and the given query , We assume that there is visual consistency among faces returned by search engines for that query .
#<struct ReadData::Alignment source_numbers="7", target_numbers="8", tag_name="wa">
To be able to model the relevance between a face and the given query , We assume that there is visual consistency among faces returned by search engines for that query .
#<struct ReadData::Alignment source_numbers="8", target_numbers="15", tag_name="wa">
To be able to model the relevance between a face and the given query , We assume that there is visual consistency among faces returned by search engines for that query .
#<struct ReadData::Alignment source_numbers="13", target_numbers="16", tag_name="wa">
To be able to model the relevance between a face and the given query , We assume that there is visual consistency among faces returned by search engines for that query .
#<struct ReadData::Alignment source_numbers="3", target_numbers="17", tag_name="wa">
To be able to model the relevance between a face and the given query , We assume that there is visual consistency among faces returned by search engines for that query .
#<struct ReadData::Alignment source_numbers="29", target_numbers="28", tag_name="wa">
To be able to model the relevance between a face and the given query , We assume that there is visual consistency among faces returned by search engines for that query .
#<struct ReadData::Alignment source_numbers="30", target_numbers="30", tag_name="wa">
To be able to model the relevance between a face and the given query , We assume that there is visual consistency among faces returned by search engines for that query .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
To be able to model the relevance between a face and the given query , We assume that there is visual consistency among faces returned by search engines for that query .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
To be able to model the relevance between a face and the given query , We assume that there is visual consistency among faces returned by search engines for that query .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
To be able to model the relevance between a face and the given query , We assume that there is visual consistency among faces returned by search engines for that query .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
To be able to model the relevance between a face and the given query , We assume that there is visual consistency among faces returned by search engines for that query .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
To be able to model the relevance between a face and the given query , We assume that there is visual consistency among faces returned by search engines for that query .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
To be able to model the relevance between a face and the given query , We assume that there is visual consistency among faces returned by search engines for that query .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
In the other word , we assume faces that are relevant to the query form the largest cluster .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
This assumption is widely accepted in most of the work of this field \CITE .
#<struct ReadData::Alignment source_numbers="9,10", target_numbers="9,10", tag_name="wa">
We consider the problem of finding relevant and irrelevant faces in the input set as the problem of outlier detection \CITE that is popular in data mining community .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
We consider the problem of finding relevant and irrelevant faces in the input set as the problem of outlier detection \CITE that is popular in data mining community .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
We consider the problem of finding relevant and irrelevant faces in the input set as the problem of outlier detection \CITE that is popular in data mining community .
#<struct ReadData::Alignment source_numbers="26", target_numbers="", tag_name="wa">
We consider the problem of finding relevant and irrelevant faces in the input set as the problem of outlier detection \CITE that is popular in data mining community .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
We consider the problem of finding relevant and irrelevant faces in the input set as the problem of outlier detection \CITE that is popular in data mining community .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
We consider the problem of finding relevant and irrelevant faces in the input set as the problem of outlier detection \CITE that is popular in data mining community .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
We first describe several distance based outlier detection methods that use the distance to the \MATH -nearest neighbors to determine observations as outliers or non-outliers .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
We first describe several distance based outlier detection methods that use the distance to the \MATH -nearest neighbors to determine observations as outliers or non-outliers .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
We first describe several distance based outlier detection methods that use the distance to the \MATH -nearest neighbors to determine observations as outliers or non-outliers .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Then the adaptation is proposed to form the query-dependent feature .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Then the adaptation is proposed to form the query-dependent feature .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Then the adaptation is proposed to form the query-dependent feature .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Given a threshold \MATH , for each point \MATH , we examine number of points \MATH so that \MATH , where \MATH is the distance ( e .g . Euclidean distance ) between \MATH and \MATH in the feature space .
#<struct ReadData::Alignment source_numbers="37", target_numbers="11", tag_name="wa">
Given a threshold \MATH , for each point \MATH , we examine number of points \MATH so that \MATH , where \MATH is the distance ( e .g . Euclidean distance ) between \MATH and \MATH in the feature space .
#<struct ReadData::Alignment source_numbers="26", target_numbers="", tag_name="wa">
Given a threshold \MATH , for each point \MATH , we examine number of points \MATH so that \MATH , where \MATH is the distance ( e .g . Euclidean distance ) between \MATH and \MATH in the feature space .
#<struct ReadData::Alignment source_numbers="27", target_numbers="", tag_name="wa">
Given a threshold \MATH , for each point \MATH , we examine number of points \MATH so that \MATH , where \MATH is the distance ( e .g . Euclidean distance ) between \MATH and \MATH in the feature space .
#<struct ReadData::Alignment source_numbers="28", target_numbers="", tag_name="wa">
Given a threshold \MATH , for each point \MATH , we examine number of points \MATH so that \MATH , where \MATH is the distance ( e .g . Euclidean distance ) between \MATH and \MATH in the feature space .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
Given a threshold \MATH , for each point \MATH , we examine number of points \MATH so that \MATH , where \MATH is the distance ( e .g . Euclidean distance ) between \MATH and \MATH in the feature space .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
Given a threshold \MATH , for each point \MATH , we examine number of points \MATH so that \MATH , where \MATH is the distance ( e .g . Euclidean distance ) between \MATH and \MATH in the feature space .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
This number of points \MATH is called the neighborhood score of \MATH and is defined as follows : \MATH where \MATH is the total number of points of the input dataset .
#<struct ReadData::Alignment source_numbers="26,27", target_numbers="25,26", tag_name="wa">
This number of points \MATH is called the neighborhood score of \MATH and is defined as follows : \MATH where \MATH is the total number of points of the input dataset .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
A low value of \MATH indicates \MATH is a candidate of outliers , while a high value of \MATH indicates \MATH is a member of one strong association cluster .
#<struct ReadData::Alignment source_numbers="2,3", target_numbers="2,3", tag_name="wa">
A low value of \MATH indicates \MATH is a candidate of outliers , while a high value of \MATH indicates \MATH is a member of one strong association cluster .
#<struct ReadData::Alignment source_numbers="16,17", target_numbers="16,17", tag_name="wa">
In practice , it is difficult to know \MATH because it depends on underlying distribution of the input dataset .
#<struct ReadData::Alignment source_numbers="9,10", target_numbers="9,10", tag_name="wa">
For each point \MATH , find its \MATH -nearest neighbors \MATH , the distance score of \MATH is the sum of the distances between \MATH and its \MATH -nearest neighbors \MATH and is defined as follows : \MATH
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
For each point \MATH , find its \MATH -nearest neighbors \MATH , the distance score of \MATH is the sum of the distances between \MATH and its \MATH -nearest neighbors \MATH and is defined as follows : \MATH
#<struct ReadData::Alignment source_numbers="35", target_numbers="", tag_name="wa">
For each point \MATH , find its \MATH -nearest neighbors \MATH , the distance score of \MATH is the sum of the distances between \MATH and its \MATH -nearest neighbors \MATH and is defined as follows : \MATH
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
Points with larger values for \MATH have more sparse neighborhoods and are likely outliers than points belonging to dense clusters which usually have lower values of \MATH .
#<struct ReadData::Alignment source_numbers="8", target_numbers="7", tag_name="wa">
Points with larger values for \MATH have more sparse neighborhoods and are likely outliers than points belonging to dense clusters which usually have lower values of \MATH .
#<struct ReadData::Alignment source_numbers="7", target_numbers="11", tag_name="wa">
Points with larger values for \MATH have more sparse neighborhoods and are likely outliers than points belonging to dense clusters which usually have lower values of \MATH .
#<struct ReadData::Alignment source_numbers="24,25", target_numbers="25,26", tag_name="wa">
Points with larger values for \MATH have more sparse neighborhoods and are likely outliers than points belonging to dense clusters which usually have lower values of \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
In our framework , Each face is an sample , and non-outliers / outliers mean faces relevant / irrelevant to the query ( i .e . target person ) .
#<struct ReadData::Alignment source_numbers="6,7", target_numbers="5,6", tag_name="wa">
In our framework , Each face is an sample , and non-outliers / outliers mean faces relevant / irrelevant to the query ( i .e . target person ) .
#<struct ReadData::Alignment source_numbers="3", target_numbers="24", tag_name="wa">
In our framework , Each face is an sample , and non-outliers / outliers mean faces relevant / irrelevant to the query ( i .e . target person ) .
#<struct ReadData::Alignment source_numbers="29", target_numbers="28", tag_name="wa">
In our framework , Each face is an sample , and non-outliers / outliers mean faces relevant / irrelevant to the query ( i .e . target person ) .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
In our framework , Each face is an sample , and non-outliers / outliers mean faces relevant / irrelevant to the query ( i .e . target person ) .
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
In our framework , Each face is an sample , and non-outliers / outliers mean faces relevant / irrelevant to the query ( i .e . target person ) .
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
In our framework , Each face is an sample , and non-outliers / outliers mean faces relevant / irrelevant to the query ( i .e . target person ) .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
In our framework , Each face is an sample , and non-outliers / outliers mean faces relevant / irrelevant to the query ( i .e . target person ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
In our framework , Each face is an sample , and non-outliers / outliers mean faces relevant / irrelevant to the query ( i .e . target person ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
In our framework , Each face is an sample , and non-outliers / outliers mean faces relevant / irrelevant to the query ( i .e . target person ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
As described above , \MATH and \MATH of outliers and non-outliers might have distributions shown in Figure \REF , these scores can be used as feature values to discriminate non-outliers and outliers .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
As described above , \MATH and \MATH of outliers and non-outliers might have distributions shown in Figure \REF , these scores can be used as feature values to discriminate non-outliers and outliers .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
As described above , \MATH and \MATH of outliers and non-outliers might have distributions shown in Figure \REF , these scores can be used as feature values to discriminate non-outliers and outliers .
#<struct ReadData::Alignment source_numbers="30", target_numbers="", tag_name="wa">
As described above , \MATH and \MATH of outliers and non-outliers might have distributions shown in Figure \REF , these scores can be used as feature values to discriminate non-outliers and outliers .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
In order to train the relevance classifier using supervised learning methods such as SVM , it requires a sufficient number of training samples .
#<struct ReadData::Alignment source_numbers="2", target_numbers="8", tag_name="wa">
In order to train the relevance classifier using supervised learning methods such as SVM , it requires a sufficient number of training samples .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
In order to train the relevance classifier using supervised learning methods such as SVM , it requires a sufficient number of training samples .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
In order to train the relevance classifier using supervised learning methods such as SVM , it requires a sufficient number of training samples .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
In order to train the relevance classifier using supervised learning methods such as SVM , it requires a sufficient number of training samples .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
In order to train the relevance classifier using supervised learning methods such as SVM , it requires a sufficient number of training samples .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
To collect training samples , The simplest way \CITE is we pick many names , and pass them to search engines .
#<struct ReadData::Alignment source_numbers="1", target_numbers="5", tag_name="wa">
To collect training samples , The simplest way \CITE is we pick many names , and pass them to search engines .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
To collect training samples , The simplest way \CITE is we pick many names , and pass them to search engines .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
To collect training samples , The simplest way \CITE is we pick many names , and pass them to search engines .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
To collect training samples , The simplest way \CITE is we pick many names , and pass them to search engines .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
After collecting the returned faces , we manually label each face whether it is relevant to the input query or not .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
After collecting the returned faces , we manually label each face whether it is relevant to the input query or not .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
It is a tedious task and requires human labor cost .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
It is a tedious task and requires human labor cost .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
It is a tedious task and requires human labor cost .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
It is a tedious task and requires human labor cost .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
It is a tedious task and requires human labor cost .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
This approach consists of two steps :
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
This approach consists of two steps :
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
First , by mining video archives , we automatically collect a set of faces of \MATH different persons \MATH , where \MATH is the set of faces of person \MATH , and \MATH is the number of persons; and
#<struct ReadData::Alignment source_numbers="37", target_numbers="", tag_name="wa">
First , by mining video archives , we automatically collect a set of faces of \MATH different persons \MATH , where \MATH is the set of faces of person \MATH , and \MATH is the number of persons; and
#<struct ReadData::Alignment source_numbers="38", target_numbers="", tag_name="wa">
First , by mining video archives , we automatically collect a set of faces of \MATH different persons \MATH , where \MATH is the set of faces of person \MATH , and \MATH is the number of persons; and
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
First , by mining video archives , we automatically collect a set of faces of \MATH different persons \MATH , where \MATH is the set of faces of person \MATH , and \MATH is the number of persons; and
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
In other words , as shown in Figure \REF , \MATH might have several face clusters and the largest cluster is equivalent to the faces relevant to the query if returning by a search engine .
#<struct ReadData::Alignment source_numbers="30", target_numbers="32", tag_name="wa">
In other words , as shown in Figure \REF , \MATH might have several face clusters and the largest cluster is equivalent to the faces relevant to the query if returning by a search engine .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
In other words , as shown in Figure \REF , \MATH might have several face clusters and the largest cluster is equivalent to the faces relevant to the query if returning by a search engine .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
In other words , as shown in Figure \REF , \MATH might have several face clusters and the largest cluster is equivalent to the faces relevant to the query if returning by a search engine .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
In other words , as shown in Figure \REF , \MATH might have several face clusters and the largest cluster is equivalent to the faces relevant to the query if returning by a search engine .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
As a result , this method can stimulate face sets returned by search engines using many names mentioned above .
#<struct ReadData::Alignment source_numbers="19", target_numbers="23", tag_name="wa">
As a result , this method can stimulate face sets returned by search engines using many names mentioned above .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
As a result , this method can stimulate face sets returned by search engines using many names mentioned above .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
As a result , this method can stimulate face sets returned by search engines using many names mentioned above .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
As a result , this method can stimulate face sets returned by search engines using many names mentioned above .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
Specifically , We use the following heuristics to pick a set of different persons appearing in video archives :
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Specifically , We use the following heuristics to pick a set of different persons appearing in video archives :
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Specifically , We use the following heuristics to pick a set of different persons appearing in video archives :
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
-If there are more than one face appearing in different locations in one frame , they likely belong to different persons .
#<struct ReadData::Alignment source_numbers="2", target_numbers="16", tag_name="wa">
-If there are more than one face appearing in different locations in one frame , they likely belong to different persons .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
-If there are more than one face appearing in different locations in one frame , they likely belong to different persons .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
Figure \REF shows an example of this case .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Figure \REF shows an example of this case .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Figure \REF shows an example of this case .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Figure \REF shows an example of this case .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Figure \REF shows an example of this case .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
-If two persons appear in video programs broadcast by different broadcast stations ( e .g . , CNN , MSNBC , and CCTV ) , they are likely different .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
-If two persons appear in video programs broadcast by different broadcast stations ( e .g . , CNN , MSNBC , and CCTV ) , they are likely different .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
-If two persons appear in video programs broadcast by different broadcast stations ( e .g . , CNN , MSNBC , and CCTV ) , they are likely different .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
-If two persons appear in video programs broadcast by different broadcast stations ( e .g . , CNN , MSNBC , and CCTV ) , they are likely different .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
-If two persons appear in video programs broadcast by different broadcast stations ( e .g . , CNN , MSNBC , and CCTV ) , they are likely different .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
-If two persons appear in video programs broadcast by different broadcast stations ( e .g . , CNN , MSNBC , and CCTV ) , they are likely different .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
If we have large video archives , using these heuristics we can collect a sufficient number of training samples for learning the relevance classifier .
#<struct ReadData::Alignment source_numbers="20", target_numbers="16,17", tag_name="wa">
If we have large video archives , using these heuristics we can collect a sufficient number of training samples for learning the relevance classifier .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
If we have large video archives , using these heuristics we can collect a sufficient number of training samples for learning the relevance classifier .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
We form a face set Generating \MATH by picking a subset of faces of Generating \MATH and adding randomly faces from other sets Generating \MATH .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
To keep the assumption of visual consistency satisfied , the number of faces selected in each set Generating \MATH must be smaller than the number of faces in set Generating \MATH .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
To keep the assumption of visual consistency satisfied , the number of faces selected in each set Generating \MATH must be smaller than the number of faces in set Generating \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
TRECVID dataset : We collected all video programs of TRECVID 2006 dataset \CITE .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
TRECVID dataset : We collected all video programs of TRECVID 2006 dataset \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
There are 527 video programs broadcast on 7 channels in 3 languages including English , Chinese and Arabic .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
We extracted faces from these video programs and grouped faces belonging to one person in each shot in one face track using a similar method described in \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
We extracted faces from these video programs and grouped faces belonging to one person in each shot in one face track using a similar method described in \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
For each channel , We scanned all face tracks extracted from the videos broadcast by this channel , and picked face tracks extracted from keyframes that several faces were detected at different locations .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
For each channel , We scanned all face tracks extracted from the videos broadcast by this channel , and picked face tracks extracted from keyframes that several faces were detected at different locations .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
For each channel , We scanned all face tracks extracted from the videos broadcast by this channel , and picked face tracks extracted from keyframes that several faces were detected at different locations .
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
For each channel , We scanned all face tracks extracted from the videos broadcast by this channel , and picked face tracks extracted from keyframes that several faces were detected at different locations .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
For each channel , We scanned all face tracks extracted from the videos broadcast by this channel , and picked face tracks extracted from keyframes that several faces were detected at different locations .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
For each channel , We scanned all face tracks extracted from the videos broadcast by this channel , and picked face tracks extracted from keyframes that several faces were detected at different locations .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
For each channel , We scanned all face tracks extracted from the videos broadcast by this channel , and picked face tracks extracted from keyframes that several faces were detected at different locations .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
For each channel , We scanned all face tracks extracted from the videos broadcast by this channel , and picked face tracks extracted from keyframes that several faces were detected at different locations .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
To guarantee selected face tracks representing different persons , for one channel , only face tracks of one shot was picked .
#<struct ReadData::Alignment source_numbers="19", target_numbers="16,17", tag_name="wa">
To guarantee selected face tracks representing different persons , for one channel , only face tracks of one shot was picked .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
To guarantee selected face tracks representing different persons , for one channel , only face tracks of one shot was picked .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
To guarantee selected face tracks representing different persons , for one channel , only face tracks of one shot was picked .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
To guarantee selected face tracks representing different persons , for one channel , only face tracks of one shot was picked .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Note that , the system does not know the identity of these faces .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Note that , the system does not know the identity of these faces .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Note that , the system does not know the identity of these faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
The number of faces of these face tracks is shown in Figure \REF .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
The number of faces of these face tracks is shown in Figure \REF .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Using these face tracks , We generated 133 labeled sets described in Section \REF and used them for training the relevance classifier .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Using these face tracks , We generated 133 labeled sets described in Section \REF and used them for training the relevance classifier .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
Using these face tracks , We generated 133 labeled sets described in Section \REF and used them for training the relevance classifier .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Using person names as queries , we applied simple string search to the captions this dataset to return a list of faces for each queried name .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Using person names as queries , we applied simple string search to the captions this dataset to return a list of faces for each queried name .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Using person names as queries , we applied simple string search to the captions this dataset to return a list of faces for each queried name .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Using person names as queries , we applied simple string search to the captions this dataset to return a list of faces for each queried name .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
These names are widely used in experiments such as \CITE .
#<struct ReadData::Alignment source_numbers="2", target_numbers="2", tag_name="wa">
These names are widely used in experiments such as \CITE .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
These names are widely used in experiments such as \CITE .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
These names are widely used in experiments such as \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
In total , 9 ,136 faces were retrieved in which 3 ,909 faces were relevant .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
On average , The accuracy was \MATH .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
On average , The accuracy was \MATH .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
On average , The accuracy was \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Google Images : We used the same set of person names used in Yahoo News Images dataset and put to Google Image Search Engine .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Google Images : We used the same set of person names used in Yahoo News Images dataset and put to Google Image Search Engine .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
Google Images : We used the same set of person names used in Yahoo News Images dataset and put to Google Image Search Engine .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
Google Images : We used the same set of person names used in Yahoo News Images dataset and put to Google Image Search Engine .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Google Images : We used the same set of person names used in Yahoo News Images dataset and put to Google Image Search Engine .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
Google Images : We used the same set of person names used in Yahoo News Images dataset and put to Google Image Search Engine .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
Google Images : We used the same set of person names used in Yahoo News Images dataset and put to Google Image Search Engine .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
For each query , We crawled a maximum of 500 images from URLs returned by Google .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
For each query , We crawled a maximum of 500 images from URLs returned by Google .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
For each query , We crawled a maximum of 500 images from URLs returned by Google .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
In total , 9 ,516 faces were extracted in which 5 ,816 faces were relevant .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
On average , The accuracy was \MATH .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
On average , The accuracy was \MATH .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
On average , The accuracy was \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
The datasets , Yahoo News Images and Google Images as shown in Figure \REF , were used for testing .
#<struct ReadData::Alignment source_numbers="2", target_numbers="9", tag_name="wa">
To group faces belonging to one person in one video shot , We simply used a similar technique described in \CITE .
#<struct ReadData::Alignment source_numbers="18", target_numbers="8", tag_name="wa">
To group faces belonging to one person in one video shot , We simply used a similar technique described in \CITE .
#<struct ReadData::Alignment source_numbers="19", target_numbers="9", tag_name="wa">
To group faces belonging to one person in one video shot , We simply used a similar technique described in \CITE .
#<struct ReadData::Alignment source_numbers="20", target_numbers="10", tag_name="wa">
To group faces belonging to one person in one video shot , We simply used a similar technique described in \CITE .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
To group faces belonging to one person in one video shot , We simply used a similar technique described in \CITE .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
To group faces belonging to one person in one video shot , We simply used a similar technique described in \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
To group faces belonging to one person in one video shot , We simply used a similar technique described in \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
Using the prior knowledge that faces of the same person in consecutive frames do not change much in locations and appearance , the technique used tracked points to robustly associate these faces into face tracks with the precision of \MATH .
#<struct ReadData::Alignment source_numbers="32", target_numbers="", tag_name="wa">
Using the prior knowledge that faces of the same person in consecutive frames do not change much in locations and appearance , the technique used tracked points to robustly associate these faces into face tracks with the precision of \MATH .
#<struct ReadData::Alignment source_numbers="36", target_numbers="", tag_name="wa">
Using the prior knowledge that faces of the same person in consecutive frames do not change much in locations and appearance , the technique used tracked points to robustly associate these faces into face tracks with the precision of \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
Using the prior knowledge that faces of the same person in consecutive frames do not change much in locations and appearance , the technique used tracked points to robustly associate these faces into face tracks with the precision of \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
Specifically , for each face , 9 facial feature points were detected , and 4 more facial feature points were inferred from these 9 points .
#<struct ReadData::Alignment source_numbers="5", target_numbers="9", tag_name="wa">
Specifically , for each face , 9 facial feature points were detected , and 4 more facial feature points were inferred from these 9 points .
#<struct ReadData::Alignment source_numbers="23,24", target_numbers="20,21", tag_name="wa">
Specifically , for each face , 9 facial feature points were detected , and 4 more facial feature points were inferred from these 9 points .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Specifically , for each face , 9 facial feature points were detected , and 4 more facial feature points were inferred from these 9 points .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Specifically , for each face , 9 facial feature points were detected , and 4 more facial feature points were inferred from these 9 points .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
Specifically , for each face , 9 facial feature points were detected , and 4 more facial feature points were inferred from these 9 points .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Specifically , for each face , 9 facial feature points were detected , and 4 more facial feature points were inferred from these 9 points .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Specifically , for each face , 9 facial feature points were detected , and 4 more facial feature points were inferred from these 9 points .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
Specifically , for each face , 9 facial feature points were detected , and 4 more facial feature points were inferred from these 9 points .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Specifically , for each face , 9 facial feature points were detected , and 4 more facial feature points were inferred from these 9 points .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Specifically , for each face , 9 facial feature points were detected , and 4 more facial feature points were inferred from these 9 points .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
In total , There were 13 feature points from which features are extracted .
#<struct ReadData::Alignment source_numbers="11", target_numbers="1,2", tag_name="wa">
In total , There were 13 feature points from which features are extracted .
#<struct ReadData::Alignment source_numbers="4", target_numbers="11", tag_name="wa">
In total , There were 13 feature points from which features are extracted .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
The features are intensity values lying within the circle with radius of 15 pixels .
#<struct ReadData::Alignment source_numbers="7,8", target_numbers="7,8", tag_name="wa">
Figure \REF shows illustration of this feature .
#<struct ReadData::Alignment source_numbers="2", target_numbers="2", tag_name="wa">
Figure \REF shows illustration of this feature .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
Figure \REF shows illustration of this feature .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
We evaluated the retrieval performance with measures that are commonly used in information retrieval , such as precision , recall , and average precision .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
We evaluated the retrieval performance with measures that are commonly used in information retrieval , such as precision , recall , and average precision .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
We evaluated the retrieval performance with measures that are commonly used in information retrieval , such as precision , recall , and average precision .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Given a queried person and letting \MATH be the total number of faces returned , \MATH the number of relevant faces , and \MATH the total number of relevant faces , recall and precision can be calculated as follows : \MATH .
#<struct ReadData::Alignment source_numbers="38", target_numbers="", tag_name="wa">
Precision and recall only evaluate the quality of an unordered set of retrieved faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Precision and recall only evaluate the quality of an unordered set of retrieved faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Precision and recall only evaluate the quality of an unordered set of retrieved faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
To evaluate ranked lists in which both recall and precision are taken into account , the average precision is usually used .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
To evaluate ranked lists in which both recall and precision are taken into account , the average precision is usually used .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
To evaluate ranked lists in which both recall and precision are taken into account , the average precision is usually used .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
To evaluate ranked lists in which both recall and precision are taken into account , the average precision is usually used .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
To evaluate ranked lists in which both recall and precision are taken into account , the average precision is usually used .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
The interpolated precision \MATH at a certain recall level \MATH is defined as the highest precision found for any recall level \MATH :
#<struct ReadData::Alignment source_numbers="22", target_numbers="26", tag_name="wa">
The interpolated precision \MATH at a certain recall level \MATH is defined as the highest precision found for any recall level \MATH :
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
The interpolated precision \MATH at a certain recall level \MATH is defined as the highest precision found for any recall level \MATH :
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
The interpolated precision \MATH at a certain recall level \MATH is defined as the highest precision found for any recall level \MATH :
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
The interpolated precision \MATH at a certain recall level \MATH is defined as the highest precision found for any recall level \MATH :
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
In addition , to evaluate the performance of multiple queries , we used mean average precision , which is the mean of average precisions computed from queries .
#<struct ReadData::Alignment source_numbers="19", target_numbers="5", tag_name="wa">
In addition , to evaluate the performance of multiple queries , we used mean average precision , which is the mean of average precisions computed from queries .
#<struct ReadData::Alignment source_numbers="10", target_numbers="16", tag_name="wa">
In addition , to evaluate the performance of multiple queries , we used mean average precision , which is the mean of average precisions computed from queries .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
In addition , to evaluate the performance of multiple queries , we used mean average precision , which is the mean of average precisions computed from queries .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
In this experiment , We compare the MAP performance of the following systems testing on YahooNews Images :
#<struct ReadData::Alignment source_numbers="7", target_numbers="9", tag_name="wa">
In this experiment , We compare the MAP performance of the following systems testing on YahooNews Images :
#<struct ReadData::Alignment source_numbers="13", target_numbers="19", tag_name="wa">
In this experiment , We compare the MAP performance of the following systems testing on YahooNews Images :
#<struct ReadData::Alignment source_numbers="14", target_numbers="21", tag_name="wa">
In this experiment , We compare the MAP performance of the following systems testing on YahooNews Images :
#<struct ReadData::Alignment source_numbers="17", target_numbers="24", tag_name="wa">
In this experiment , We compare the MAP performance of the following systems testing on YahooNews Images :
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
In this experiment , We compare the MAP performance of the following systems testing on YahooNews Images :
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
In this experiment , We compare the MAP performance of the following systems testing on YahooNews Images :
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
In this experiment , We compare the MAP performance of the following systems testing on YahooNews Images :
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
In this experiment , We compare the MAP performance of the following systems testing on YahooNews Images :
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
In this experiment , We compare the MAP performance of the following systems testing on YahooNews Images :
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
In this experiment , We compare the MAP performance of the following systems testing on YahooNews Images :
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
In this experiment , We compare the MAP performance of the following systems testing on YahooNews Images :
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
In this experiment , We compare the MAP performance of the following systems testing on YahooNews Images :
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
In this experiment , We compare the MAP performance of the following systems testing on YahooNews Images :
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
In this experiment , We compare the MAP performance of the following systems testing on YahooNews Images :
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
In this experiment , We compare the MAP performance of the following systems testing on YahooNews Images :
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
In this experiment , We compare the MAP performance of the following systems testing on YahooNews Images :
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
-DistScore-TrainGoogleImages : The training set is the set of annotated faces returned by Google Images Search for 23 person names .
#<struct ReadData::Alignment source_numbers="5,6", target_numbers="5,6", tag_name="wa">
-DistScore-TrainGoogleImages : The training set is the set of annotated faces returned by Google Images Search for 23 person names .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
-DistScore-TrainGoogleImages : The training set is the set of annotated faces returned by Google Images Search for 23 person names .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
-NNScore-TrainGoogleImages : The training set is the same as DistScore-TrainGoogleImages .
#<struct ReadData::Alignment source_numbers="5,6", target_numbers="5,6", tag_name="wa">
The training set is the set of annotated faces artificially generated by our method described in Section \REF .
#<struct ReadData::Alignment source_numbers="3,4", target_numbers="3,4", tag_name="wa">
The training set is the set of annotated faces artificially generated by our method described in Section \REF .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
The training set is the set of annotated faces artificially generated by our method described in Section \REF .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
-NNScore-TrainTRECVID : The training set is the same as DistScore-TrainTRECVID .
#<struct ReadData::Alignment source_numbers="5,6", target_numbers="5,6", tag_name="wa">
-Krapac[11]-TrainGoogleImages : The training set is the same as DistScore-TrainGoogleImages .
#<struct ReadData::Alignment source_numbers="5,6", target_numbers="5,6", tag_name="wa">
We re-implemented the method proposed by Krapac et al . \CITE for extracting query-dependent feature .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
We re-implemented the method proposed by Krapac et al . \CITE for extracting query-dependent feature .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
We re-implemented the method proposed by Krapac et al . \CITE for extracting query-dependent feature .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
We re-implemented the method proposed by Krapac et al . \CITE for extracting query-dependent feature .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
We re-implemented the method proposed by Krapac et al . \CITE for extracting query-dependent feature .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Specifically , Each face is represented as a bag of visual words .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Specifically , Each face is represented as a bag of visual words .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Specifically , Each face is represented as a bag of visual words .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
We used 13 facial feature points detected in each face and their descriptors using pixel intensity as visual words .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
We used 13 facial feature points detected in each face and their descriptors using pixel intensity as visual words .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
We used 13 facial feature points detected in each face and their descriptors using pixel intensity as visual words .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
-Mensink[15]-GaussianModels : This method proposed by Mensink et al . \CITE models the returned faces by using two Gaussians , one for the faces relevant to the target person and one for the remaining faces .
#<struct ReadData::Alignment source_numbers="32", target_numbers="19", tag_name="wa">
-Mensink[15]-GaussianModels : This method proposed by Mensink et al . \CITE models the returned faces by using two Gaussians , one for the faces relevant to the target person and one for the remaining faces .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
-Mensink[15]-GaussianModels : This method proposed by Mensink et al . \CITE models the returned faces by using two Gaussians , one for the faces relevant to the target person and one for the remaining faces .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
-Mensink[15]-GaussianModels : This method proposed by Mensink et al . \CITE models the returned faces by using two Gaussians , one for the faces relevant to the target person and one for the remaining faces .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
-Mensink[15]-GaussianModels : This method proposed by Mensink et al . \CITE models the returned faces by using two Gaussians , one for the faces relevant to the target person and one for the remaining faces .
#<struct ReadData::Alignment source_numbers="30", target_numbers="", tag_name="wa">
-Mensink[15]-GaussianModels : This method proposed by Mensink et al . \CITE models the returned faces by using two Gaussians , one for the faces relevant to the target person and one for the remaining faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
-Mensink[15]-GaussianModels : This method proposed by Mensink et al . \CITE models the returned faces by using two Gaussians , one for the faces relevant to the target person and one for the remaining faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
-Mensink[15]-GaussianModels : This method proposed by Mensink et al . \CITE models the returned faces by using two Gaussians , one for the faces relevant to the target person and one for the remaining faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
-Mensink[15]-GaussianModels : This method proposed by Mensink et al . \CITE models the returned faces by using two Gaussians , one for the faces relevant to the target person and one for the remaining faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
-Mensink[15]-GaussianModels : This method proposed by Mensink et al . \CITE models the returned faces by using two Gaussians , one for the faces relevant to the target person and one for the remaining faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
-Mensink[15]-Friends : This method proposed by Mensink et al . \CITE uses linear discriminant analysis to train a specific classifier for each query .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
-Mensink[15]-Friends : This method proposed by Mensink et al . \CITE uses linear discriminant analysis to train a specific classifier for each query .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
-Mensink[15]-Friends : This method proposed by Mensink et al . \CITE uses linear discriminant analysis to train a specific classifier for each query .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
This method uses detected person names in captions associated with faces for query expansion to model faces of the target person 's friends .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
This method uses detected person names in captions associated with faces for query expansion to model faces of the target person 's friends .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
The Methods such as Mensink[15]-GaussianModels and Mensink[15]-Friends are the state of the art methods that learn a specific classifier for each query .
#<struct ReadData::Alignment source_numbers="22", target_numbers="16", tag_name="wa">
The Methods such as Mensink[15]-GaussianModels and Mensink[15]-Friends are the state of the art methods that learn a specific classifier for each query .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
The Methods such as Mensink[15]-GaussianModels and Mensink[15]-Friends are the state of the art methods that learn a specific classifier for each query .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
The Methods such as Mensink[15]-GaussianModels and Mensink[15]-Friends are the state of the art methods that learn a specific classifier for each query .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
The Methods such as Mensink[15]-GaussianModels and Mensink[15]-Friends are the state of the art methods that learn a specific classifier for each query .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
The Methods such as Mensink[15]-GaussianModels and Mensink[15]-Friends are the state of the art methods that learn a specific classifier for each query .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
The Methods such as Mensink[15]-GaussianModels and Mensink[15]-Friends are the state of the art methods that learn a specific classifier for each query .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
The Methods such as Mensink[15]-GaussianModels and Mensink[15]-Friends are the state of the art methods that learn a specific classifier for each query .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
The method Krapac[11]-TrainGoogleImages is similar to our method in which one generic classifier is trained in advance and then is used for new queries .
#<struct ReadData::Alignment source_numbers="20", target_numbers="17", tag_name="wa">
The method Krapac[11]-TrainGoogleImages is similar to our method in which one generic classifier is trained in advance and then is used for new queries .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
The method Krapac[11]-TrainGoogleImages is similar to our method in which one generic classifier is trained in advance and then is used for new queries .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
The method Krapac[11]-TrainGoogleImages is similar to our method in which one generic classifier is trained in advance and then is used for new queries .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
Figure \REF shows the performance comparison of these systems when testing on YahooNews Images dataset .
#<struct ReadData::Alignment source_numbers="10", target_numbers="11", tag_name="wa">
Figure \REF shows the performance comparison of these systems when testing on YahooNews Images dataset .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Figure \REF shows the performance comparison of these systems when testing on YahooNews Images dataset .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Figure \REF shows the performance comparison of these systems when testing on YahooNews Images dataset .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Figure \REF shows the performance comparison of these systems when testing on YahooNews Images dataset .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Figure \REF shows the performance comparison of these systems when testing on YahooNews Images dataset .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
As for systems such as DistScore-TrainGoogleImages , NNScore-TrainGoogleImages , DistScore-TrainTRECVID , and NNScore-TrainTRECVID , the curves show the correlation between the performance and the number of features .
#<struct ReadData::Alignment source_numbers="6", target_numbers="17", tag_name="wa">
As for systems such as DistScore-TrainGoogleImages , NNScore-TrainGoogleImages , DistScore-TrainTRECVID , and NNScore-TrainTRECVID , the curves show the correlation between the performance and the number of features .
#<struct ReadData::Alignment source_numbers="8", target_numbers="19", tag_name="wa">
As for systems such as DistScore-TrainGoogleImages , NNScore-TrainGoogleImages , DistScore-TrainTRECVID , and NNScore-TrainTRECVID , the curves show the correlation between the performance and the number of features .
#<struct ReadData::Alignment source_numbers="10", target_numbers="21", tag_name="wa">
As for systems such as DistScore-TrainGoogleImages , NNScore-TrainGoogleImages , DistScore-TrainTRECVID , and NNScore-TrainTRECVID , the curves show the correlation between the performance and the number of features .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
As for systems such as DistScore-TrainGoogleImages , NNScore-TrainGoogleImages , DistScore-TrainTRECVID , and NNScore-TrainTRECVID , the curves show the correlation between the performance and the number of features .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
As for systems such as DistScore-TrainGoogleImages , NNScore-TrainGoogleImages , DistScore-TrainTRECVID , and NNScore-TrainTRECVID , the curves show the correlation between the performance and the number of features .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
As for systems such as DistScore-TrainGoogleImages , NNScore-TrainGoogleImages , DistScore-TrainTRECVID , and NNScore-TrainTRECVID , the curves show the correlation between the performance and the number of features .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
As for systems such as DistScore-TrainGoogleImages , NNScore-TrainGoogleImages , DistScore-TrainTRECVID , and NNScore-TrainTRECVID , the curves show the correlation between the performance and the number of features .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
As for systems such as DistScore-TrainGoogleImages , NNScore-TrainGoogleImages , DistScore-TrainTRECVID , and NNScore-TrainTRECVID , the curves show the correlation between the performance and the number of features .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
-DistScore is significantly better than that of NNScore .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
-DistScore is significantly better than that of NNScore .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
-DistScore is significantly better than that of NNScore .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
-DistScore is significantly better than that of NNScore .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Therefore , we can use small number of features for reducing the computational cost .
#<struct ReadData::Alignment source_numbers="3,4", target_numbers="3,4", tag_name="wa">
Therefore , we can use small number of features for reducing the computational cost .
#<struct ReadData::Alignment source_numbers="6,7", target_numbers="6,7", tag_name="wa">
-The performance of the system using the training data generated artificially by our method is comparable with that of the system using the training data returned by search engines .
#<struct ReadData::Alignment source_numbers="16", target_numbers="10", tag_name="wa">
-The performance of the system using the training data generated artificially by our method is comparable with that of the system using the training data returned by search engines .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
-The performance of the system using the training data generated artificially by our method is comparable with that of the system using the training data returned by search engines .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
-The performance of the system using the training data generated artificially by our method is comparable with that of the system using the training data returned by search engines .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
-Our proposed method DistScore-TrainTRECVID has comparable performance to the state of the art method in specific classifier-based approach Mensink[15]-Friends .
#<struct ReadData::Alignment source_numbers="10", target_numbers="2", tag_name="wa">
-Our proposed method DistScore-TrainTRECVID has comparable performance to the state of the art method in specific classifier-based approach Mensink[15]-Friends .
#<struct ReadData::Alignment source_numbers="1", target_numbers="4,5", tag_name="wa">
-Our proposed method DistScore-TrainTRECVID has comparable performance to the state of the art method in specific classifier-based approach Mensink[15]-Friends .
#<struct ReadData::Alignment source_numbers="4", target_numbers="6", tag_name="wa">
-Our proposed method DistScore-TrainTRECVID has comparable performance to the state of the art method in specific classifier-based approach Mensink[15]-Friends .
#<struct ReadData::Alignment source_numbers="11", target_numbers="13", tag_name="wa">
-Our proposed method DistScore-TrainTRECVID has comparable performance to the state of the art method in specific classifier-based approach Mensink[15]-Friends .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
-Our proposed method DistScore-TrainTRECVID has comparable performance to the state of the art method in specific classifier-based approach Mensink[15]-Friends .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
-Our proposed method DistScore-TrainTRECVID has comparable performance to the state of the art method in specific classifier-based approach Mensink[15]-Friends .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
-Our proposed method DistScore-TrainTRECVID has comparable performance to the state of the art method in specific classifier-based approach Mensink[15]-Friends .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
-Our proposed method DistScore-TrainTRECVID has comparable performance to the state of the art method in specific classifier-based approach Mensink[15]-Friends .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
It outperforms the method using only visual information Mensink[15]-GaussianModels .
#<struct ReadData::Alignment source_numbers="9", target_numbers="14", tag_name="wa">
It outperforms the method using only visual information Mensink[15]-GaussianModels .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
It outperforms the method using only visual information Mensink[15]-GaussianModels .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
It outperforms the method using only visual information Mensink[15]-GaussianModels .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
It outperforms the method using only visual information Mensink[15]-GaussianModels .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
It outperforms the method using only visual information Mensink[15]-GaussianModels .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
It outperforms the method using only visual information Mensink[15]-GaussianModels .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
It outperforms the method using only visual information Mensink[15]-GaussianModels .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
-Our proposed method DistScore-TrainTRECVID outperforms the method proposed by Krapac et al . customized for handling faces .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
-Our proposed method DistScore-TrainTRECVID outperforms the method proposed by Krapac et al . customized for handling faces .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
-Our proposed method DistScore-TrainTRECVID outperforms the method proposed by Krapac et al . customized for handling faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
-Our proposed method DistScore-TrainTRECVID outperforms the method proposed by Krapac et al . customized for handling faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
-Our proposed method DistScore-TrainTRECVID outperforms the method proposed by Krapac et al . customized for handling faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
-Our proposed method DistScore-TrainTRECVID outperforms the method proposed by Krapac et al . customized for handling faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
As shown in Figure \REF , DistScore-TrainTRECVID outperforms original ranking of Google Images Search Engine if using from 20 to 50 features .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
As shown in Figure \REF , DistScore-TrainTRECVID outperforms original ranking of Google Images Search Engine if using from 20 to 50 features .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
As shown in Figure \REF , DistScore-TrainTRECVID outperforms original ranking of Google Images Search Engine if using from 20 to 50 features .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
As shown in Figure \REF , DistScore-TrainTRECVID outperforms original ranking of Google Images Search Engine if using from 20 to 50 features .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
As shown in Figure \REF , DistScore-TrainTRECVID outperforms original ranking of Google Images Search Engine if using from 20 to 50 features .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
The result of DistScore-TrainTRECVID on YahooNews Images set and Google Images set indicates that the relevance classifier of our proposed method is able to generalize well on different queries and independent with underlying ranking algorithms of search engines .
#<struct ReadData::Alignment source_numbers="14", target_numbers="5", tag_name="wa">
The result of DistScore-TrainTRECVID on YahooNews Images set and Google Images set indicates that the relevance classifier of our proposed method is able to generalize well on different queries and independent with underlying ranking algorithms of search engines .
#<struct ReadData::Alignment source_numbers="12,13", target_numbers="13,14", tag_name="wa">
The result of DistScore-TrainTRECVID on YahooNews Images set and Google Images set indicates that the relevance classifier of our proposed method is able to generalize well on different queries and independent with underlying ranking algorithms of search engines .
#<struct ReadData::Alignment source_numbers="31", target_numbers="18", tag_name="wa">
The result of DistScore-TrainTRECVID on YahooNews Images set and Google Images set indicates that the relevance classifier of our proposed method is able to generalize well on different queries and independent with underlying ranking algorithms of search engines .
#<struct ReadData::Alignment source_numbers="2", target_numbers="33", tag_name="wa">
The result of DistScore-TrainTRECVID on YahooNews Images set and Google Images set indicates that the relevance classifier of our proposed method is able to generalize well on different queries and independent with underlying ranking algorithms of search engines .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
The result of DistScore-TrainTRECVID on YahooNews Images set and Google Images set indicates that the relevance classifier of our proposed method is able to generalize well on different queries and independent with underlying ranking algorithms of search engines .
#<struct ReadData::Alignment source_numbers="35", target_numbers="", tag_name="wa">
The result of DistScore-TrainTRECVID on YahooNews Images set and Google Images set indicates that the relevance classifier of our proposed method is able to generalize well on different queries and independent with underlying ranking algorithms of search engines .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
The result of DistScore-TrainTRECVID on YahooNews Images set and Google Images set indicates that the relevance classifier of our proposed method is able to generalize well on different queries and independent with underlying ranking algorithms of search engines .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
The result of DistScore-TrainTRECVID on YahooNews Images set and Google Images set indicates that the relevance classifier of our proposed method is able to generalize well on different queries and independent with underlying ranking algorithms of search engines .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
The result of DistScore-TrainTRECVID on YahooNews Images set and Google Images set indicates that the relevance classifier of our proposed method is able to generalize well on different queries and independent with underlying ranking algorithms of search engines .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
The result of DistScore-TrainTRECVID on YahooNews Images set and Google Images set indicates that the relevance classifier of our proposed method is able to generalize well on different queries and independent with underlying ranking algorithms of search engines .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
Figure \REF shows an example of re-ranking result of top-30 faces for the query John Paul that is one of the most difficult cases of the YahooNews Images set .
#<struct ReadData::Alignment source_numbers="11", target_numbers="8", tag_name="wa">
Figure \REF shows an example of re-ranking result of top-30 faces for the query John Paul that is one of the most difficult cases of the YahooNews Images set .
#<struct ReadData::Alignment source_numbers="12", target_numbers="9", tag_name="wa">
Figure \REF shows an example of re-ranking result of top-30 faces for the query John Paul that is one of the most difficult cases of the YahooNews Images set .
#<struct ReadData::Alignment source_numbers="25", target_numbers="13", tag_name="wa">
Figure \REF shows an example of re-ranking result of top-30 faces for the query John Paul that is one of the most difficult cases of the YahooNews Images set .
#<struct ReadData::Alignment source_numbers="16,17,18,19", target_numbers="18,19,20,21", tag_name="wa">
Figure \REF shows an example of re-ranking result of top-30 faces for the query John Paul that is one of the most difficult cases of the YahooNews Images set .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Figure \REF shows an example of re-ranking result of top-30 faces for the query John Paul that is one of the most difficult cases of the YahooNews Images set .
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
Figure \REF shows an example of re-ranking result of top-30 faces for the query John Paul that is one of the most difficult cases of the YahooNews Images set .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
Figure \REF shows an example of re-ranking result of top-30 faces for the query John Paul that is one of the most difficult cases of the YahooNews Images set .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Figure \REF shows an example of re-ranking result of top-30 faces for the query John Paul that is one of the most difficult cases of the YahooNews Images set .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
Figure \REF shows an example of re-ranking result of top-30 faces for the query John Paul that is one of the most difficult cases of the YahooNews Images set .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
The result clearly shows that our proposed method outperforms the other state of the art methods .
#<struct ReadData::Alignment source_numbers="3,4", target_numbers="3,4", tag_name="wa">
The result clearly shows that our proposed method outperforms the other state of the art methods .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
The result clearly shows that our proposed method outperforms the other state of the art methods .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
The result clearly shows that our proposed method outperforms the other state of the art methods .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
The result clearly shows that our proposed method outperforms the other state of the art methods .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
The result clearly shows that our proposed method outperforms the other state of the art methods .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
Our query-dependent feature is based on nearest neighbors of the images in the returned image set that usually have complexity of \MATH , where \MATH is the total number of images in the set .
#<struct ReadData::Alignment source_numbers="9", target_numbers="6", tag_name="wa">
However , recent studies on indexing techniques such as \MATH -d tree , locality sensitive hashing ( LSH ) , and SASH \CITE can speed up the nearest neighbor search significantly .
#<struct ReadData::Alignment source_numbers="21", target_numbers="28", tag_name="wa">
However , recent studies on indexing techniques such as \MATH -d tree , locality sensitive hashing ( LSH ) , and SASH \CITE can speed up the nearest neighbor search significantly .
#<struct ReadData::Alignment source_numbers="31", target_numbers="39", tag_name="wa">
However , recent studies on indexing techniques such as \MATH -d tree , locality sensitive hashing ( LSH ) , and SASH \CITE can speed up the nearest neighbor search significantly .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
However , recent studies on indexing techniques such as \MATH -d tree , locality sensitive hashing ( LSH ) , and SASH \CITE can speed up the nearest neighbor search significantly .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
However , recent studies on indexing techniques such as \MATH -d tree , locality sensitive hashing ( LSH ) , and SASH \CITE can speed up the nearest neighbor search significantly .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
However , recent studies on indexing techniques such as \MATH -d tree , locality sensitive hashing ( LSH ) , and SASH \CITE can speed up the nearest neighbor search significantly .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
However , recent studies on indexing techniques such as \MATH -d tree , locality sensitive hashing ( LSH ) , and SASH \CITE can speed up the nearest neighbor search significantly .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
However , recent studies on indexing techniques such as \MATH -d tree , locality sensitive hashing ( LSH ) , and SASH \CITE can speed up the nearest neighbor search significantly .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
However , recent studies on indexing techniques such as \MATH -d tree , locality sensitive hashing ( LSH ) , and SASH \CITE can speed up the nearest neighbor search significantly .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
For example , as described in \CITE , the complexity of fast lookup of $k$ approximate nearest neighbors is \MATH \CITE .
#<struct ReadData::Alignment source_numbers="21", target_numbers="17", tag_name="wa">
For example , as described in \CITE , the complexity of fast lookup of $k$ approximate nearest neighbors is \MATH \CITE .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
For example , as described in \CITE , the complexity of fast lookup of $k$ approximate nearest neighbors is \MATH \CITE .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
For example , as described in \CITE , the complexity of fast lookup of $k$ approximate nearest neighbors is \MATH \CITE .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
For example , as described in \CITE , the complexity of fast lookup of $k$ approximate nearest neighbors is \MATH \CITE .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
For example , as described in \CITE , the complexity of fast lookup of $k$ approximate nearest neighbors is \MATH \CITE .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Studying other techniques to speedup the query-feature extraction process is our next step in future work .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
Studying other techniques to speedup the query-feature extraction process is our next step in future work .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Studying other techniques to speedup the query-feature extraction process is our next step in future work .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
We have presented a novel method for re-ranking face images returned by existing search engines .
#<struct ReadData::Alignment source_numbers="5,6", target_numbers="5,6", tag_name="wa">
Instead of training a specific classifier for each new query , we train only one generic classifier and use it for ranking new queries .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
Instead of training a specific classifier for each new query , we train only one generic classifier and use it for ranking new queries .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
To train the generic classifier , We propose a simple unsupervised method to obtain a large number of labeled faces from video archives .
#<struct ReadData::Alignment source_numbers="12", target_numbers="6", tag_name="wa">
To train the generic classifier , We propose a simple unsupervised method to obtain a large number of labeled faces from video archives .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
To train the generic classifier , We propose a simple unsupervised method to obtain a large number of labeled faces from video archives .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
To train the generic classifier , We propose a simple unsupervised method to obtain a large number of labeled faces from video archives .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
Experiments shown that although our method is unsupervised and independent with underlying algorithms of existing search engines but successfully learns visual consistency among returned faces to boosts retrieval performance .
#<struct ReadData::Alignment source_numbers="1,2", target_numbers="1,2", tag_name="wa">
Experiments shown that although our method is unsupervised and independent with underlying algorithms of existing search engines but successfully learns visual consistency among returned faces to boosts retrieval performance .
#<struct ReadData::Alignment source_numbers="13", target_numbers="10", tag_name="wa">
Experiments shown that although our method is unsupervised and independent with underlying algorithms of existing search engines but successfully learns visual consistency among returned faces to boosts retrieval performance .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Experiments shown that although our method is unsupervised and independent with underlying algorithms of existing search engines but successfully learns visual consistency among returned faces to boosts retrieval performance .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
Experiments shown that although our method is unsupervised and independent with underlying algorithms of existing search engines but successfully learns visual consistency among returned faces to boosts retrieval performance .
#<struct ReadData::Alignment source_numbers="28", target_numbers="", tag_name="wa">
Experiments shown that although our method is unsupervised and independent with underlying algorithms of existing search engines but successfully learns visual consistency among returned faces to boosts retrieval performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Experiments shown that although our method is unsupervised and independent with underlying algorithms of existing search engines but successfully learns visual consistency among returned faces to boosts retrieval performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Experiments shown that although our method is unsupervised and independent with underlying algorithms of existing search engines but successfully learns visual consistency among returned faces to boosts retrieval performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
Experiments shown that although our method is unsupervised and independent with underlying algorithms of existing search engines but successfully learns visual consistency among returned faces to boosts retrieval performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
Experiments shown that although our method is unsupervised and independent with underlying algorithms of existing search engines but successfully learns visual consistency among returned faces to boosts retrieval performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
We present a method to enhance the performance of a mathematical search system in this paper .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
We present a method to enhance the performance of a mathematical search system in this paper .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
We present a method to enhance the performance of a mathematical search system in this paper .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
Targeting to mathematical formulas that appear in natural language documents , we collect the names of formulas from the surrounding text , and incorpo-rate the correspondence to the search system 's database .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Targeting to mathematical formulas that appear in natural language documents , we collect the names of formulas from the surrounding text , and incorpo-rate the correspondence to the search system 's database .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
Targeting to mathematical formulas that appear in natural language documents , we collect the names of formulas from the surrounding text , and incorpo-rate the correspondence to the search system 's database .
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
Targeting to mathematical formulas that appear in natural language documents , we collect the names of formulas from the surrounding text , and incorpo-rate the correspondence to the search system 's database .
#<struct ReadData::Alignment source_numbers="26", target_numbers="", tag_name="wa">
Targeting to mathematical formulas that appear in natural language documents , we collect the names of formulas from the surrounding text , and incorpo-rate the correspondence to the search system 's database .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Targeting to mathematical formulas that appear in natural language documents , we collect the names of formulas from the surrounding text , and incorpo-rate the correspondence to the search system 's database .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
Targeting to mathematical formulas that appear in natural language documents , we collect the names of formulas from the surrounding text , and incorpo-rate the correspondence to the search system 's database .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
E ectiveness of the proposed approach is shown through experiments using Wikipedia mathematical articles and Wolfram Functions Site data sets .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
E ectiveness of the proposed approach is shown through experiments using Wikipedia mathematical articles and Wolfram Functions Site data sets .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
E ectiveness of the proposed approach is shown through experiments using Wikipedia mathematical articles and Wolfram Functions Site data sets .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
E ectiveness of the proposed approach is shown through experiments using Wikipedia mathematical articles and Wolfram Functions Site data sets .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
In the current digital environment , the mathematical content being published on the Web is increasing day by day . While more and more mathematical contents being available on the Web , retrieving mathematical contents becomes an important issue for many users .
#<struct ReadData::Alignment source_numbers="7", target_numbers="1", tag_name="wa">
In the current digital environment , the mathematical content being published on the Web is increasing day by day . While more and more mathematical contents being available on the Web , retrieving mathematical contents becomes an important issue for many users .
#<struct ReadData::Alignment source_numbers="8", target_numbers="2", tag_name="wa">
In the current digital environment , the mathematical content being published on the Web is increasing day by day . While more and more mathematical contents being available on the Web , retrieving mathematical contents becomes an important issue for many users .
#<struct ReadData::Alignment source_numbers="9", target_numbers="3", tag_name="wa">
In the current digital environment , the mathematical content being published on the Web is increasing day by day . While more and more mathematical contents being available on the Web , retrieving mathematical contents becomes an important issue for many users .
#<struct ReadData::Alignment source_numbers="10", target_numbers="4", tag_name="wa">
In the current digital environment , the mathematical content being published on the Web is increasing day by day . While more and more mathematical contents being available on the Web , retrieving mathematical contents becomes an important issue for many users .
#<struct ReadData::Alignment source_numbers="11", target_numbers="5", tag_name="wa">
In the current digital environment , the mathematical content being published on the Web is increasing day by day . While more and more mathematical contents being available on the Web , retrieving mathematical contents becomes an important issue for many users .
#<struct ReadData::Alignment source_numbers="12", target_numbers="6", tag_name="wa">
In the current digital environment , the mathematical content being published on the Web is increasing day by day . While more and more mathematical contents being available on the Web , retrieving mathematical contents becomes an important issue for many users .
#<struct ReadData::Alignment source_numbers="13", target_numbers="7", tag_name="wa">
In the current digital environment , the mathematical content being published on the Web is increasing day by day . While more and more mathematical contents being available on the Web , retrieving mathematical contents becomes an important issue for many users .
#<struct ReadData::Alignment source_numbers="5", target_numbers="13", tag_name="wa">
In the current digital environment , the mathematical content being published on the Web is increasing day by day . While more and more mathematical contents being available on the Web , retrieving mathematical contents becomes an important issue for many users .
#<struct ReadData::Alignment source_numbers="22", target_numbers="14", tag_name="wa">
In the current digital environment , the mathematical content being published on the Web is increasing day by day . While more and more mathematical contents being available on the Web , retrieving mathematical contents becomes an important issue for many users .
#<struct ReadData::Alignment source_numbers="34", target_numbers="17,18", tag_name="wa">
In the current digital environment , the mathematical content being published on the Web is increasing day by day . While more and more mathematical contents being available on the Web , retrieving mathematical contents becomes an important issue for many users .
#<struct ReadData::Alignment source_numbers="35", target_numbers="19", tag_name="wa">
In the current digital environment , the mathematical content being published on the Web is increasing day by day . While more and more mathematical contents being available on the Web , retrieving mathematical contents becomes an important issue for many users .
#<struct ReadData::Alignment source_numbers="42", target_numbers="26", tag_name="wa">
In the current digital environment , the mathematical content being published on the Web is increasing day by day . While more and more mathematical contents being available on the Web , retrieving mathematical contents becomes an important issue for many users .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
In the current digital environment , the mathematical content being published on the Web is increasing day by day . While more and more mathematical contents being available on the Web , retrieving mathematical contents becomes an important issue for many users .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
In the current digital environment , the mathematical content being published on the Web is increasing day by day . While more and more mathematical contents being available on the Web , retrieving mathematical contents becomes an important issue for many users .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
In the current digital environment , the mathematical content being published on the Web is increasing day by day . While more and more mathematical contents being available on the Web , retrieving mathematical contents becomes an important issue for many users .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
In the current digital environment , the mathematical content being published on the Web is increasing day by day . While more and more mathematical contents being available on the Web , retrieving mathematical contents becomes an important issue for many users .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
In the current digital environment , the mathematical content being published on the Web is increasing day by day . While more and more mathematical contents being available on the Web , retrieving mathematical contents becomes an important issue for many users .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
In the current digital environment , the mathematical content being published on the Web is increasing day by day . While more and more mathematical contents being available on the Web , retrieving mathematical contents becomes an important issue for many users .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
In the current digital environment , the mathematical content being published on the Web is increasing day by day . While more and more mathematical contents being available on the Web , retrieving mathematical contents becomes an important issue for many users .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
In the current digital environment , the mathematical content being published on the Web is increasing day by day . While more and more mathematical contents being available on the Web , retrieving mathematical contents becomes an important issue for many users .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
In the current digital environment , the mathematical content being published on the Web is increasing day by day . While more and more mathematical contents being available on the Web , retrieving mathematical contents becomes an important issue for many users .
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
In the current digital environment , the mathematical content being published on the Web is increasing day by day . While more and more mathematical contents being available on the Web , retrieving mathematical contents becomes an important issue for many users .
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
In the current digital environment , the mathematical content being published on the Web is increasing day by day . While more and more mathematical contents being available on the Web , retrieving mathematical contents becomes an important issue for many users .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
In the current digital environment , the mathematical content being published on the Web is increasing day by day . While more and more mathematical contents being available on the Web , retrieving mathematical contents becomes an important issue for many users .
#<struct ReadData::Alignment source_numbers="26", target_numbers="", tag_name="wa">
In the current digital environment , the mathematical content being published on the Web is increasing day by day . While more and more mathematical contents being available on the Web , retrieving mathematical contents becomes an important issue for many users .
#<struct ReadData::Alignment source_numbers="27", target_numbers="", tag_name="wa">
In the current digital environment , the mathematical content being published on the Web is increasing day by day . While more and more mathematical contents being available on the Web , retrieving mathematical contents becomes an important issue for many users .
#<struct ReadData::Alignment source_numbers="28", target_numbers="", tag_name="wa">
In the current digital environment , the mathematical content being published on the Web is increasing day by day . While more and more mathematical contents being available on the Web , retrieving mathematical contents becomes an important issue for many users .
#<struct ReadData::Alignment source_numbers="29", target_numbers="", tag_name="wa">
In the current digital environment , the mathematical content being published on the Web is increasing day by day . While more and more mathematical contents being available on the Web , retrieving mathematical contents becomes an important issue for many users .
#<struct ReadData::Alignment source_numbers="30", target_numbers="", tag_name="wa">
In the current digital environment , the mathematical content being published on the Web is increasing day by day . While more and more mathematical contents being available on the Web , retrieving mathematical contents becomes an important issue for many users .
#<struct ReadData::Alignment source_numbers="31", target_numbers="", tag_name="wa">
Teach-ers , students , researchers do need to gain access to mathematical resources for teaching , studying , or obtaining updated information for research and development .
#<struct ReadData::Alignment source_numbers="24", target_numbers="4", tag_name="wa">
Teach-ers , students , researchers do need to gain access to mathematical resources for teaching , studying , or obtaining updated information for research and development .
#<struct ReadData::Alignment source_numbers="6", target_numbers="6", tag_name="wa">
Teach-ers , students , researchers do need to gain access to mathematical resources for teaching , studying , or obtaining updated information for research and development .
#<struct ReadData::Alignment source_numbers="9", target_numbers="8", tag_name="wa">
Teach-ers , students , researchers do need to gain access to mathematical resources for teaching , studying , or obtaining updated information for research and development .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Teach-ers , students , researchers do need to gain access to mathematical resources for teaching , studying , or obtaining updated information for research and development .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Teach-ers , students , researchers do need to gain access to mathematical resources for teaching , studying , or obtaining updated information for research and development .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Teach-ers , students , researchers do need to gain access to mathematical resources for teaching , studying , or obtaining updated information for research and development .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Teach-ers , students , researchers do need to gain access to mathematical resources for teaching , studying , or obtaining updated information for research and development .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
Teach-ers , students , researchers do need to gain access to mathematical resources for teaching , studying , or obtaining updated information for research and development .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
Teach-ers , students , researchers do need to gain access to mathematical resources for teaching , studying , or obtaining updated information for research and development .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Teach-ers , students , researchers do need to gain access to mathematical resources for teaching , studying , or obtaining updated information for research and development .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Teach-ers , students , researchers do need to gain access to mathematical resources for teaching , studying , or obtaining updated information for research and development .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Teach-ers , students , researchers do need to gain access to mathematical resources for teaching , studying , or obtaining updated information for research and development .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
Therefore , users need specialized search systems to nd the formula that is relevant to their requirements .
#<struct ReadData::Alignment source_numbers="10", target_numbers="9", tag_name="wa">
Therefore , users need specialized search systems to nd the formula that is relevant to their requirements .
#<struct ReadData::Alignment source_numbers="12", target_numbers="11", tag_name="wa">
Therefore , users need specialized search systems to nd the formula that is relevant to their requirements .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Therefore , users need specialized search systems to nd the formula that is relevant to their requirements .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Therefore , users need specialized search systems to nd the formula that is relevant to their requirements .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Therefore , users need specialized search systems to nd the formula that is relevant to their requirements .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Internet search engines are able to detect some particular keywords in mathematical formula but they mostly fail to recognize mathematical symbols and constructs such as integral sym-bols , square root symbols , fractions , or matrices .
#<struct ReadData::Alignment source_numbers="18", target_numbers="15", tag_name="wa">
Internet search engines are able to detect some particular keywords in mathematical formula but they mostly fail to recognize mathematical symbols and constructs such as integral sym-bols , square root symbols , fractions , or matrices .
#<struct ReadData::Alignment source_numbers="30", target_numbers="26", tag_name="wa">
Internet search engines are able to detect some particular keywords in mathematical formula but they mostly fail to recognize mathematical symbols and constructs such as integral sym-bols , square root symbols , fractions , or matrices .
#<struct ReadData::Alignment source_numbers="31", target_numbers="27", tag_name="wa">
Internet search engines are able to detect some particular keywords in mathematical formula but they mostly fail to recognize mathematical symbols and constructs such as integral sym-bols , square root symbols , fractions , or matrices .
#<struct ReadData::Alignment source_numbers="33", target_numbers="29", tag_name="wa">
Internet search engines are able to detect some particular keywords in mathematical formula but they mostly fail to recognize mathematical symbols and constructs such as integral sym-bols , square root symbols , fractions , or matrices .
#<struct ReadData::Alignment source_numbers="36", target_numbers="32", tag_name="wa">
Internet search engines are able to detect some particular keywords in mathematical formula but they mostly fail to recognize mathematical symbols and constructs such as integral sym-bols , square root symbols , fractions , or matrices .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Internet search engines are able to detect some particular keywords in mathematical formula but they mostly fail to recognize mathematical symbols and constructs such as integral sym-bols , square root symbols , fractions , or matrices .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
Internet search engines are able to detect some particular keywords in mathematical formula but they mostly fail to recognize mathematical symbols and constructs such as integral sym-bols , square root symbols , fractions , or matrices .
#<struct ReadData::Alignment source_numbers="26", target_numbers="", tag_name="wa">
Internet search engines are able to detect some particular keywords in mathematical formula but they mostly fail to recognize mathematical symbols and constructs such as integral sym-bols , square root symbols , fractions , or matrices .
#<struct ReadData::Alignment source_numbers="27", target_numbers="", tag_name="wa">
Internet search engines are able to detect some particular keywords in mathematical formula but they mostly fail to recognize mathematical symbols and constructs such as integral sym-bols , square root symbols , fractions , or matrices .
#<struct ReadData::Alignment source_numbers="34", target_numbers="", tag_name="wa">
Internet search engines are able to detect some particular keywords in mathematical formula but they mostly fail to recognize mathematical symbols and constructs such as integral sym-bols , square root symbols , fractions , or matrices .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Internet search engines are able to detect some particular keywords in mathematical formula but they mostly fail to recognize mathematical symbols and constructs such as integral sym-bols , square root symbols , fractions , or matrices .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
Internet search engines are able to detect some particular keywords in mathematical formula but they mostly fail to recognize mathematical symbols and constructs such as integral sym-bols , square root symbols , fractions , or matrices .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
There exist some mathematical-dedicated search engines available on the Internet .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
There exist some mathematical-dedicated search engines available on the Internet .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
There exist some mathematical-dedicated search engines available on the Internet .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
There exist some mathematical-dedicated search engines available on the Internet .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Furthermore , these systems do not take into account the semantics of mathematical formulas revealed by surrounding natural language text , like the name of the formula and its variables' descrip-tion .
#<struct ReadData::Alignment source_numbers="22", target_numbers="17", tag_name="wa">
Furthermore , these systems do not take into account the semantics of mathematical formulas revealed by surrounding natural language text , like the name of the formula and its variables' descrip-tion .
#<struct ReadData::Alignment source_numbers="23", target_numbers="27", tag_name="wa">
Furthermore , these systems do not take into account the semantics of mathematical formulas revealed by surrounding natural language text , like the name of the formula and its variables' descrip-tion .
#<struct ReadData::Alignment source_numbers="25", target_numbers="29", tag_name="wa">
Furthermore , these systems do not take into account the semantics of mathematical formulas revealed by surrounding natural language text , like the name of the formula and its variables' descrip-tion .
#<struct ReadData::Alignment source_numbers="24", target_numbers="31", tag_name="wa">
Furthermore , these systems do not take into account the semantics of mathematical formulas revealed by surrounding natural language text , like the name of the formula and its variables' descrip-tion .
#<struct ReadData::Alignment source_numbers="28", target_numbers="32", tag_name="wa">
Furthermore , these systems do not take into account the semantics of mathematical formulas revealed by surrounding natural language text , like the name of the formula and its variables' descrip-tion .
#<struct ReadData::Alignment source_numbers="29", target_numbers="33", tag_name="wa">
Furthermore , these systems do not take into account the semantics of mathematical formulas revealed by surrounding natural language text , like the name of the formula and its variables' descrip-tion .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
Furthermore , these systems do not take into account the semantics of mathematical formulas revealed by surrounding natural language text , like the name of the formula and its variables' descrip-tion .
#<struct ReadData::Alignment source_numbers="26", target_numbers="", tag_name="wa">
Furthermore , these systems do not take into account the semantics of mathematical formulas revealed by surrounding natural language text , like the name of the formula and its variables' descrip-tion .
#<struct ReadData::Alignment source_numbers="27", target_numbers="", tag_name="wa">
Furthermore , these systems do not take into account the semantics of mathematical formulas revealed by surrounding natural language text , like the name of the formula and its variables' descrip-tion .
#<struct ReadData::Alignment source_numbers="30", target_numbers="", tag_name="wa">
Furthermore , these systems do not take into account the semantics of mathematical formulas revealed by surrounding natural language text , like the name of the formula and its variables' descrip-tion .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Furthermore , these systems do not take into account the semantics of mathematical formulas revealed by surrounding natural language text , like the name of the formula and its variables' descrip-tion .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
Furthermore , these systems do not take into account the semantics of mathematical formulas revealed by surrounding natural language text , like the name of the formula and its variables' descrip-tion .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
Furthermore , these systems do not take into account the semantics of mathematical formulas revealed by surrounding natural language text , like the name of the formula and its variables' descrip-tion .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
Furthermore , these systems do not take into account the semantics of mathematical formulas revealed by surrounding natural language text , like the name of the formula and its variables' descrip-tion .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
Furthermore , these systems do not take into account the semantics of mathematical formulas revealed by surrounding natural language text , like the name of the formula and its variables' descrip-tion .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
Furthermore , these systems do not take into account the semantics of mathematical formulas revealed by surrounding natural language text , like the name of the formula and its variables' descrip-tion .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
The Digital Library of Mathematical functions ( DLMF ) project is a mathematical database available on the Web [8] .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
The Digital Library of Mathematical functions ( DLMF ) project is a mathematical database available on the Web [8] .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
But full mathematical search is still not available .
#<struct ReadData::Alignment source_numbers="5", target_numbers="1", tag_name="wa">
But full mathematical search is still not available .
#<struct ReadData::Alignment source_numbers="4", target_numbers="4", tag_name="wa">
But full mathematical search is still not available .
#<struct ReadData::Alignment source_numbers="6", target_numbers="5", tag_name="wa">
But full mathematical search is still not available .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
But full mathematical search is still not available .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
But full mathematical search is still not available .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
But full mathematical search is still not available .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
These systems , however , provide neither similarity structures nor semantic meanings of the formulas .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
These systems , however , provide neither similarity structures nor semantic meanings of the formulas .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
The Wolfram Functions Site [7] contains large mathe-matical formulas and also provides a semantics search for mathematical formulas .
#<struct ReadData::Alignment source_numbers="6", target_numbers="7", tag_name="wa">
The Wolfram Functions Site [7] contains large mathe-matical formulas and also provides a semantics search for mathematical formulas .
#<struct ReadData::Alignment source_numbers="16", target_numbers="10", tag_name="wa">
The Wolfram Functions Site [7] contains large mathe-matical formulas and also provides a semantics search for mathematical formulas .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
The Wolfram Functions Site [7] contains large mathe-matical formulas and also provides a semantics search for mathematical formulas .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
The Wolfram Functions Site [7] contains large mathe-matical formulas and also provides a semantics search for mathematical formulas .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
The Wolfram Functions Site [7] contains large mathe-matical formulas and also provides a semantics search for mathematical formulas .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
The Wolfram Functions Site [7] contains large mathe-matical formulas and also provides a semantics search for mathematical formulas .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
The Wolfram Functions Site [7] contains large mathe-matical formulas and also provides a semantics search for mathematical formulas .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
This site and some recent works done by Adeel et al. [2] and Yokoi and Aizawa [1] propose similarity search methods based on MathML but these works do not make use of the semantics of the formulas' surrounding text , which is considered to be important information sources .
#<struct ReadData::Alignment source_numbers="30,31", target_numbers="17", tag_name="wa">
This site and some recent works done by Adeel et al. [2] and Yokoi and Aizawa [1] propose similarity search methods based on MathML but these works do not make use of the semantics of the formulas' surrounding text , which is considered to be important information sources .
#<struct ReadData::Alignment source_numbers="48", target_numbers="38", tag_name="wa">
This site and some recent works done by Adeel et al. [2] and Yokoi and Aizawa [1] propose similarity search methods based on MathML but these works do not make use of the semantics of the formulas' surrounding text , which is considered to be important information sources .
#<struct ReadData::Alignment source_numbers="17", target_numbers="42", tag_name="wa">
This site and some recent works done by Adeel et al. [2] and Yokoi and Aizawa [1] propose similarity search methods based on MathML but these works do not make use of the semantics of the formulas' surrounding text , which is considered to be important information sources .
#<struct ReadData::Alignment source_numbers="41", target_numbers="43", tag_name="wa">
This site and some recent works done by Adeel et al. [2] and Yokoi and Aizawa [1] propose similarity search methods based on MathML but these works do not make use of the semantics of the formulas' surrounding text , which is considered to be important information sources .
#<struct ReadData::Alignment source_numbers="40", target_numbers="47,48,49", tag_name="wa">
This site and some recent works done by Adeel et al. [2] and Yokoi and Aizawa [1] propose similarity search methods based on MathML but these works do not make use of the semantics of the formulas' surrounding text , which is considered to be important information sources .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
This site and some recent works done by Adeel et al. [2] and Yokoi and Aizawa [1] propose similarity search methods based on MathML but these works do not make use of the semantics of the formulas' surrounding text , which is considered to be important information sources .
#<struct ReadData::Alignment source_numbers="26", target_numbers="", tag_name="wa">
This site and some recent works done by Adeel et al. [2] and Yokoi and Aizawa [1] propose similarity search methods based on MathML but these works do not make use of the semantics of the formulas' surrounding text , which is considered to be important information sources .
#<struct ReadData::Alignment source_numbers="39", target_numbers="", tag_name="wa">
This site and some recent works done by Adeel et al. [2] and Yokoi and Aizawa [1] propose similarity search methods based on MathML but these works do not make use of the semantics of the formulas' surrounding text , which is considered to be important information sources .
#<struct ReadData::Alignment source_numbers="42", target_numbers="", tag_name="wa">
This site and some recent works done by Adeel et al. [2] and Yokoi and Aizawa [1] propose similarity search methods based on MathML but these works do not make use of the semantics of the formulas' surrounding text , which is considered to be important information sources .
#<struct ReadData::Alignment source_numbers="43", target_numbers="", tag_name="wa">
This site and some recent works done by Adeel et al. [2] and Yokoi and Aizawa [1] propose similarity search methods based on MathML but these works do not make use of the semantics of the formulas' surrounding text , which is considered to be important information sources .
#<struct ReadData::Alignment source_numbers="44", target_numbers="", tag_name="wa">
This site and some recent works done by Adeel et al. [2] and Yokoi and Aizawa [1] propose similarity search methods based on MathML but these works do not make use of the semantics of the formulas' surrounding text , which is considered to be important information sources .
#<struct ReadData::Alignment source_numbers="45", target_numbers="", tag_name="wa">
This site and some recent works done by Adeel et al. [2] and Yokoi and Aizawa [1] propose similarity search methods based on MathML but these works do not make use of the semantics of the formulas' surrounding text , which is considered to be important information sources .
#<struct ReadData::Alignment source_numbers="46", target_numbers="", tag_name="wa">
This site and some recent works done by Adeel et al. [2] and Yokoi and Aizawa [1] propose similarity search methods based on MathML but these works do not make use of the semantics of the formulas' surrounding text , which is considered to be important information sources .
#<struct ReadData::Alignment source_numbers="47", target_numbers="", tag_name="wa">
This site and some recent works done by Adeel et al. [2] and Yokoi and Aizawa [1] propose similarity search methods based on MathML but these works do not make use of the semantics of the formulas' surrounding text , which is considered to be important information sources .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
This site and some recent works done by Adeel et al. [2] and Yokoi and Aizawa [1] propose similarity search methods based on MathML but these works do not make use of the semantics of the formulas' surrounding text , which is considered to be important information sources .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
This site and some recent works done by Adeel et al. [2] and Yokoi and Aizawa [1] propose similarity search methods based on MathML but these works do not make use of the semantics of the formulas' surrounding text , which is considered to be important information sources .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
This site and some recent works done by Adeel et al. [2] and Yokoi and Aizawa [1] propose similarity search methods based on MathML but these works do not make use of the semantics of the formulas' surrounding text , which is considered to be important information sources .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
This site and some recent works done by Adeel et al. [2] and Yokoi and Aizawa [1] propose similarity search methods based on MathML but these works do not make use of the semantics of the formulas' surrounding text , which is considered to be important information sources .
#<struct ReadData::Alignment source_numbers="", target_numbers="40", tag_name="wa">
This site and some recent works done by Adeel et al. [2] and Yokoi and Aizawa [1] propose similarity search methods based on MathML but these works do not make use of the semantics of the formulas' surrounding text , which is considered to be important information sources .
#<struct ReadData::Alignment source_numbers="", target_numbers="41", tag_name="wa">
This site and some recent works done by Adeel et al. [2] and Yokoi and Aizawa [1] propose similarity search methods based on MathML but these works do not make use of the semantics of the formulas' surrounding text , which is considered to be important information sources .
#<struct ReadData::Alignment source_numbers="", target_numbers="44", tag_name="wa">
This site and some recent works done by Adeel et al. [2] and Yokoi and Aizawa [1] propose similarity search methods based on MathML but these works do not make use of the semantics of the formulas' surrounding text , which is considered to be important information sources .
#<struct ReadData::Alignment source_numbers="", target_numbers="45", tag_name="wa">
This site and some recent works done by Adeel et al. [2] and Yokoi and Aizawa [1] propose similarity search methods based on MathML but these works do not make use of the semantics of the formulas' surrounding text , which is considered to be important information sources .
#<struct ReadData::Alignment source_numbers="", target_numbers="46", tag_name="wa">
This site and some recent works done by Adeel et al. [2] and Yokoi and Aizawa [1] propose similarity search methods based on MathML but these works do not make use of the semantics of the formulas' surrounding text , which is considered to be important information sources .
#<struct ReadData::Alignment source_numbers="", target_numbers="50", tag_name="wa">
This site and some recent works done by Adeel et al. [2] and Yokoi and Aizawa [1] propose similarity search methods based on MathML but these works do not make use of the semantics of the formulas' surrounding text , which is considered to be important information sources .
#<struct ReadData::Alignment source_numbers="", target_numbers="51", tag_name="wa">
We describe here in detail our work toward creating a mathematical database that contains for-mulas , their names , their variables' descriptions and other related information .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
We describe here in detail our work toward creating a mathematical database that contains for-mulas , their names , their variables' descriptions and other related information .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
We describe here in detail our work toward creating a mathematical database that contains for-mulas , their names , their variables' descriptions and other related information .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
We describe here in detail our work toward creating a mathematical database that contains for-mulas , their names , their variables' descriptions and other related information .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
We describe here in detail our work toward creating a mathematical database that contains for-mulas , their names , their variables' descriptions and other related information .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
We describe here in detail our work toward creating a mathematical database that contains for-mulas , their names , their variables' descriptions and other related information .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
We also implement a mathematical search system that use this information as its base knowledge .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
This information is very helpful when performing mathematical search by reducing the need for formula input and solving the notational variation problem where mathematically equivalent formulas follow di erent notations .
#<struct ReadData::Alignment source_numbers="27", target_numbers="", tag_name="wa">
This information is very helpful when performing mathematical search by reducing the need for formula input and solving the notational variation problem where mathematically equivalent formulas follow di erent notations .
#<struct ReadData::Alignment source_numbers="28", target_numbers="", tag_name="wa">
This information is very helpful when performing mathematical search by reducing the need for formula input and solving the notational variation problem where mathematically equivalent formulas follow di erent notations .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
Relations between formulas and their name could also be used to correct errors in mathematical OCR systems , such as Infty [5] .
#<struct ReadData::Alignment source_numbers="6,7", target_numbers="7,8", tag_name="wa">
Relations between formulas and their name could also be used to correct errors in mathematical OCR systems , such as Infty [5] .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Relations between formulas and their name could also be used to correct errors in mathematical OCR systems , such as Infty [5] .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Relations between formulas and their name could also be used to correct errors in mathematical OCR systems , such as Infty [5] .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
It also provides opportunities to make mathematical better understandable and usable for di erent groups of people with disabilities .
#<struct ReadData::Alignment source_numbers="19", target_numbers="15", tag_name="wa">
It also provides opportunities to make mathematical better understandable and usable for di erent groups of people with disabilities .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
It also provides opportunities to make mathematical better understandable and usable for di erent groups of people with disabilities .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
It also provides opportunities to make mathematical better understandable and usable for di erent groups of people with disabilities .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
It also provides opportunities to make mathematical better understandable and usable for di erent groups of people with disabilities .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
The remainder of this paper is organized as follow : In section 2 , we present an overview of the proposed framework .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
The remainder of this paper is organized as follow : In section 2 , we present an overview of the proposed framework .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
The remainder of this paper is organized as follow : In section 2 , we present an overview of the proposed framework .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
The remainder of this paper is organized as follow : In section 2 , we present an overview of the proposed framework .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
The remainder of this paper is organized as follow : In section 2 , we present an overview of the proposed framework .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
The remainder of this paper is organized as follow : In section 2 , we present an overview of the proposed framework .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Section 4 concludes the paper and gives avenues for future works .
#<struct ReadData::Alignment source_numbers="8,9", target_numbers="8,9", tag_name="wa">
Mathematical formulas on the Web has many di erent formats , some of them are LaTeX , and the Mathematical Markup Language ( MathML ) [6] .
#<struct ReadData::Alignment source_numbers="16", target_numbers="11", tag_name="wa">
Mathematical formulas on the Web has many di erent formats , some of them are LaTeX , and the Mathematical Markup Language ( MathML ) [6] .
#<struct ReadData::Alignment source_numbers="26", target_numbers="21", tag_name="wa">
Mathematical formulas on the Web has many di erent formats , some of them are LaTeX , and the Mathematical Markup Language ( MathML ) [6] .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Mathematical formulas on the Web has many di erent formats , some of them are LaTeX , and the Mathematical Markup Language ( MathML ) [6] .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Mathematical formulas on the Web has many di erent formats , some of them are LaTeX , and the Mathematical Markup Language ( MathML ) [6] .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
Mathematical formulas on the Web has many di erent formats , some of them are LaTeX , and the Mathematical Markup Language ( MathML ) [6] .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
Mathematical formulas on the Web has many di erent formats , some of them are LaTeX , and the Mathematical Markup Language ( MathML ) [6] .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
Mathematical formulas on the Web has many di erent formats , some of them are LaTeX , and the Mathematical Markup Language ( MathML ) [6] .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
Mathematical formulas on the Web has many di erent formats , some of them are LaTeX , and the Mathematical Markup Language ( MathML ) [6] .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Mathematical formulas on the Web has many di erent formats , some of them are LaTeX , and the Mathematical Markup Language ( MathML ) [6] .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
This makes the search more dif-cult .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
This makes the search more dif-cult .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
This makes the search more dif-cult .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
In this paper , we use the presentation MathML format for mathematical formulas .
#<struct ReadData::Alignment source_numbers="5", target_numbers="6", tag_name="wa">
In this paper , we use the presentation MathML format for mathematical formulas .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
In this paper , we use the presentation MathML format for mathematical formulas .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Formulas with other formats can be easily converted to MathML format using existing freely available tools .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
For our works , we use LaTeXML Converter which is freely available at \URL .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Figure 1 shows a page on mathematical section on Wikipedia and the information we retrieved on this site besides the mathematical formulas .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Figure 1 shows a page on mathematical section on Wikipedia and the information we retrieved on this site besides the mathematical formulas .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Figure 1 shows a page on mathematical section on Wikipedia and the information we retrieved on this site besides the mathematical formulas .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
At this point , we use some heuristics to provide an adequate solution for matching mathematical formulas with their names .
#<struct ReadData::Alignment source_numbers="5,6", target_numbers="1", tag_name="wa">
At this point , we use some heuristics to provide an adequate solution for matching mathematical formulas with their names .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
At this point , we use some heuristics to provide an adequate solution for matching mathematical formulas with their names .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
At this point , we use some heuristics to provide an adequate solution for matching mathematical formulas with their names .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
At this point , we use some heuristics to provide an adequate solution for matching mathematical formulas with their names .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
At this point , we use some heuristics to provide an adequate solution for matching mathematical formulas with their names .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
At this point , we use some heuristics to provide an adequate solution for matching mathematical formulas with their names .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
At this point , we use some heuristics to provide an adequate solution for matching mathematical formulas with their names .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
At this point , we use some heuristics to provide an adequate solution for matching mathematical formulas with their names .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
At this point , we use some heuristics to provide an adequate solution for matching mathematical formulas with their names .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
At this point , we use some heuristics to provide an adequate solution for matching mathematical formulas with their names .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
At this point , we use some heuristics to provide an adequate solution for matching mathematical formulas with their names .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
These heuristics are based on the type settings and distances between the name strings and formulas in the same page .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
These heuristics are based on the type settings and distances between the name strings and formulas in the same page .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
Our system allows two ways of searching : text content search and formula content search .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Our system allows two ways of searching : text content search and formula content search .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
In the rst case , users can use the extracted keywords for search , for example : " sin " , " Pythagorean " or " trigonometric functions " .
#<struct ReadData::Alignment source_numbers="12", target_numbers="4", tag_name="wa">
In the rst case , users can use the extracted keywords for search , for example : " sin " , " Pythagorean " or " trigonometric functions " .
#<struct ReadData::Alignment source_numbers="20", target_numbers="13", tag_name="wa">
In the rst case , users can use the extracted keywords for search , for example : " sin " , " Pythagorean " or " trigonometric functions " .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
In the rst case , users can use the extracted keywords for search , for example : " sin " , " Pythagorean " or " trigonometric functions " .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
In the rst case , users can use the extracted keywords for search , for example : " sin " , " Pythagorean " or " trigonometric functions " .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
In the rst case , users can use the extracted keywords for search , for example : " sin " , " Pythagorean " or " trigonometric functions " .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
In the rst case , users can use the extracted keywords for search , for example : " sin " , " Pythagorean " or " trigonometric functions " .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
In the rst case , users can use the extracted keywords for search , for example : " sin " , " Pythagorean " or " trigonometric functions " .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
In the rst case , users can use the extracted keywords for search , for example : " sin " , " Pythagorean " or " trigonometric functions " .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
In the rst case , users can use the extracted keywords for search , for example : " sin " , " Pythagorean " or " trigonometric functions " .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
In the rst case , users can use the extracted keywords for search , for example : " sin " , " Pythagorean " or " trigonometric functions " .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
In the rst case , users can use the extracted keywords for search , for example : " sin " , " Pythagorean " or " trigonometric functions " .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
In the rst case , users can use the extracted keywords for search , for example : " sin " , " Pythagorean " or " trigonometric functions " .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
In the rst case , users can use the extracted keywords for search , for example : " sin " , " Pythagorean " or " trigonometric functions " .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
In the rst case , users can use the extracted keywords for search , for example : " sin " , " Pythagorean " or " trigonometric functions " .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
In the rst case , users can use the extracted keywords for search , for example : " sin " , " Pythagorean " or " trigonometric functions " .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
In the rst case , users can use the extracted keywords for search , for example : " sin " , " Pythagorean " or " trigonometric functions " .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
In the second case , users can input the mathematical formulas directly , for example : \MATH .
#<struct ReadData::Alignment source_numbers="7", target_numbers="8", tag_name="wa">
In the second case , users can input the mathematical formulas directly , for example : \MATH .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
In the second case , users can input the mathematical formulas directly , for example : \MATH .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
In the second case , users can input the mathematical formulas directly , for example : \MATH .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
In the second case , users can input the mathematical formulas directly , for example : \MATH .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
In the second case , users can input the mathematical formulas directly , for example : \MATH .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
In the second case , users can input the mathematical formulas directly , for example : \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
In the second case , users can input the mathematical formulas directly , for example : \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
In the second case , users can input the mathematical formulas directly , for example : \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
In the second case , users can input the mathematical formulas directly , for example : \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
If found , it will return other information related with that formula .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
If found , it will return other information related with that formula .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Else , it just looks for mathematical formulas which are similar to the input ( including formulas with similar structure ) .
#<struct ReadData::Alignment source_numbers="1", target_numbers="5", tag_name="wa">
Else , it just looks for mathematical formulas which are similar to the input ( including formulas with similar structure ) .
#<struct ReadData::Alignment source_numbers="21", target_numbers="25", tag_name="wa">
Else , it just looks for mathematical formulas which are similar to the input ( including formulas with similar structure ) .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Else , it just looks for mathematical formulas which are similar to the input ( including formulas with similar structure ) .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
Else , it just looks for mathematical formulas which are similar to the input ( including formulas with similar structure ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Else , it just looks for mathematical formulas which are similar to the input ( including formulas with similar structure ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Else , it just looks for mathematical formulas which are similar to the input ( including formulas with similar structure ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Else , it just looks for mathematical formulas which are similar to the input ( including formulas with similar structure ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Else , it just looks for mathematical formulas which are similar to the input ( including formulas with similar structure ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
In our work , we manually consider formulas with the same semantic meaning are relevant .
#<struct ReadData::Alignment source_numbers="6", target_numbers="1", tag_name="wa">
In our work , we manually consider formulas with the same semantic meaning are relevant .
#<struct ReadData::Alignment source_numbers="7", target_numbers="3", tag_name="wa">
In our work , we manually consider formulas with the same semantic meaning are relevant .
#<struct ReadData::Alignment source_numbers="8", target_numbers="4", tag_name="wa">
In our work , we manually consider formulas with the same semantic meaning are relevant .
#<struct ReadData::Alignment source_numbers="9", target_numbers="5", tag_name="wa">
In our work , we manually consider formulas with the same semantic meaning are relevant .
#<struct ReadData::Alignment source_numbers="10", target_numbers="6", tag_name="wa">
In our work , we manually consider formulas with the same semantic meaning are relevant .
#<struct ReadData::Alignment source_numbers="11", target_numbers="7", tag_name="wa">
In our work , we manually consider formulas with the same semantic meaning are relevant .
#<struct ReadData::Alignment source_numbers="12", target_numbers="8", tag_name="wa">
In our work , we manually consider formulas with the same semantic meaning are relevant .
#<struct ReadData::Alignment source_numbers="13", target_numbers="9", tag_name="wa">
In our work , we manually consider formulas with the same semantic meaning are relevant .
#<struct ReadData::Alignment source_numbers="14", target_numbers="10", tag_name="wa">
In our work , we manually consider formulas with the same semantic meaning are relevant .
#<struct ReadData::Alignment source_numbers="15", target_numbers="11", tag_name="wa">
In our work , we manually consider formulas with the same semantic meaning are relevant .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
In our work , we manually consider formulas with the same semantic meaning are relevant .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
In our work , we manually consider formulas with the same semantic meaning are relevant .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
In our work , we manually consider formulas with the same semantic meaning are relevant .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
In our work , we manually consider formulas with the same semantic meaning are relevant .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
In our work , we manually consider formulas with the same semantic meaning are relevant .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
In our work , we manually consider formulas with the same semantic meaning are relevant .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
In our work , we manually consider formulas with the same semantic meaning are relevant .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
In our work , we manually consider formulas with the same semantic meaning are relevant .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
In our work , we manually consider formulas with the same semantic meaning are relevant .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
In our work , we manually consider formulas with the same semantic meaning are relevant .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
In our work , we manually consider formulas with the same semantic meaning are relevant .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
In our work , we manually consider formulas with the same semantic meaning are relevant .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
In our work , we manually consider formulas with the same semantic meaning are relevant .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
In our work , we manually consider formulas with the same semantic meaning are relevant .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
In our work , we manually consider formulas with the same semantic meaning are relevant .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
In our work , we manually consider formulas with the same semantic meaning are relevant .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
In our work , we manually consider formulas with the same semantic meaning are relevant .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
In our work , we manually consider formulas with the same semantic meaning are relevant .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
In our work , we manually consider formulas with the same semantic meaning are relevant .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
In our work , we manually consider formulas with the same semantic meaning are relevant .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
In order to show the e ect of linking the formula with its name , we also set up an experimental search system without using the formula 's names .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
In order to show the e ect of linking the formula with its name , we also set up an experimental search system without using the formula 's names .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
In order to show the e ect of linking the formula with its name , we also set up an experimental search system without using the formula 's names .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
In order to show the e ect of linking the formula with its name , we also set up an experimental search system without using the formula 's names .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
In order to show the e ect of linking the formula with its name , we also set up an experimental search system without using the formula 's names .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
In order to show the e ect of linking the formula with its name , we also set up an experimental search system without using the formula 's names .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
In order to show the e ect of linking the formula with its name , we also set up an experimental search system without using the formula 's names .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Table 1 shows top 5 of the searching results for the query \MATH .
#<struct ReadData::Alignment source_numbers="6", target_numbers="3", tag_name="wa">
Table 1 shows top 5 of the searching results for the query \MATH .
#<struct ReadData::Alignment source_numbers="10", target_numbers="9", tag_name="wa">
Table 1 shows top 5 of the searching results for the query \MATH .
#<struct ReadData::Alignment source_numbers="13", target_numbers="18", tag_name="wa">
Table 1 shows top 5 of the searching results for the query \MATH .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
Table 1 shows top 5 of the searching results for the query \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
Table 1 shows top 5 of the searching results for the query \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
Table 1 shows top 5 of the searching results for the query \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Table 1 shows top 5 of the searching results for the query \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Table 1 shows top 5 of the searching results for the query \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
Table 1 shows top 5 of the searching results for the query \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
Table 1 shows top 5 of the searching results for the query \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
As can be seen from the table , when the system associates the formulas with their names , it can provide more useful information to the user .
#<struct ReadData::Alignment source_numbers="9", target_numbers="6", tag_name="wa">
As can be seen from the table , when the system associates the formulas with their names , it can provide more useful information to the user .
#<struct ReadData::Alignment source_numbers="12", target_numbers="9", tag_name="wa">
As can be seen from the table , when the system associates the formulas with their names , it can provide more useful information to the user .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
As can be seen from the table , when the system associates the formulas with their names , it can provide more useful information to the user .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
Table 2 shows top 10 results with the query " Pythagorean " .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
Table 2 shows top 10 results with the query " Pythagorean " .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
In this paper , we presented a new framework for mathematical search where links between formulas and their names are automatically detected from the target documents and then utilized in the search .
#<struct ReadData::Alignment source_numbers="32", target_numbers="28", tag_name="wa">
In this paper , we presented a new framework for mathematical search where links between formulas and their names are automatically detected from the target documents and then utilized in the search .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
In this paper , we presented a new framework for mathematical search where links between formulas and their names are automatically detected from the target documents and then utilized in the search .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
In this paper , we presented a new framework for mathematical search where links between formulas and their names are automatically detected from the target documents and then utilized in the search .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
In this paper , we presented a new framework for mathematical search where links between formulas and their names are automatically detected from the target documents and then utilized in the search .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
In this paper , we presented a new framework for mathematical search where links between formulas and their names are automatically detected from the target documents and then utilized in the search .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
In this paper , we presented a new framework for mathematical search where links between formulas and their names are automatically detected from the target documents and then utilized in the search .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
In this paper , we presented a new framework for mathematical search where links between formulas and their names are automatically detected from the target documents and then utilized in the search .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
In this paper , we presented a new framework for mathematical search where links between formulas and their names are automatically detected from the target documents and then utilized in the search .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
Due to unavailability of the standard corpora to evaluate mathemat-ical search systems , our evaluation at this moment still remained subjective and limited .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
Due to unavailability of the standard corpora to evaluate mathemat-ical search systems , our evaluation at this moment still remained subjective and limited .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Due to unavailability of the standard corpora to evaluate mathemat-ical search systems , our evaluation at this moment still remained subjective and limited .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
Due to unavailability of the standard corpora to evaluate mathemat-ical search systems , our evaluation at this moment still remained subjective and limited .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Due to unavailability of the standard corpora to evaluate mathemat-ical search systems , our evaluation at this moment still remained subjective and limited .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
We believe that our approach , by incorporating information other than the mathematical formulas themselves , showed promising results .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
We believe that our approach , by incorporating information other than the mathematical formulas themselves , showed promising results .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
We believe that our approach , by incorporating information other than the mathematical formulas themselves , showed promising results .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
We believe that our approach , by incorporating information other than the mathematical formulas themselves , showed promising results .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
However , this is only a rst step , some important issues are left for future study .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
However , this is only a rst step , some important issues are left for future study .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
However , this is only a rst step , some important issues are left for future study .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
However , this is only a rst step , some important issues are left for future study .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
However , this is only a rst step , some important issues are left for future study .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
However , this is only a rst step , some important issues are left for future study .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Using formula 's name is one way of taking into account the semantic meaning of the formula , we are considering other information such as formula 's description and variable 's description .
#<struct ReadData::Alignment source_numbers="32", target_numbers="36", tag_name="wa">
Using formula 's name is one way of taking into account the semantic meaning of the formula , we are considering other information such as formula 's description and variable 's description .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
Using formula 's name is one way of taking into account the semantic meaning of the formula , we are considering other information such as formula 's description and variable 's description .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Using formula 's name is one way of taking into account the semantic meaning of the formula , we are considering other information such as formula 's description and variable 's description .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
Therefore , linking formulas across articles should be taken into account .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
This paper explores the use of MathML Pallel Markup Corpora for mathematical expression understanding , the task of which is formulated as a translation from Presentation to Content MathML Markups in our approach .
#<struct ReadData::Alignment source_numbers="30", target_numbers="", tag_name="wa">
This paper explores the use of MathML Pallel Markup Corpora for mathematical expression understanding , the task of which is formulated as a translation from Presentation to Content MathML Markups in our approach .
#<struct ReadData::Alignment source_numbers="31", target_numbers="", tag_name="wa">
This paper explores the use of MathML Pallel Markup Corpora for mathematical expression understanding , the task of which is formulated as a translation from Presentation to Content MathML Markups in our approach .
#<struct ReadData::Alignment source_numbers="32", target_numbers="", tag_name="wa">
This paper explores the use of MathML Pallel Markup Corpora for mathematical expression understanding , the task of which is formulated as a translation from Presentation to Content MathML Markups in our approach .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
This paper explores the use of MathML Pallel Markup Corpora for mathematical expression understanding , the task of which is formulated as a translation from Presentation to Content MathML Markups in our approach .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
This paper explores the use of MathML Pallel Markup Corpora for mathematical expression understanding , the task of which is formulated as a translation from Presentation to Content MathML Markups in our approach .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
This paper explores the use of MathML Pallel Markup Corpora for mathematical expression understanding , the task of which is formulated as a translation from Presentation to Content MathML Markups in our approach .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
This paper explores the use of MathML Pallel Markup Corpora for mathematical expression understanding , the task of which is formulated as a translation from Presentation to Content MathML Markups in our approach .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
This paper explores the use of MathML Pallel Markup Corpora for mathematical expression understanding , the task of which is formulated as a translation from Presentation to Content MathML Markups in our approach .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
This paper explores the use of MathML Pallel Markup Corpora for mathematical expression understanding , the task of which is formulated as a translation from Presentation to Content MathML Markups in our approach .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
This paper explores the use of MathML Pallel Markup Corpora for mathematical expression understanding , the task of which is formulated as a translation from Presentation to Content MathML Markups in our approach .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
This paper explores the use of MathML Pallel Markup Corpora for mathematical expression understanding , the task of which is formulated as a translation from Presentation to Content MathML Markups in our approach .
#<struct ReadData::Alignment source_numbers="", target_numbers="40", tag_name="wa">
This paper explores the use of MathML Pallel Markup Corpora for mathematical expression understanding , the task of which is formulated as a translation from Presentation to Content MathML Markups in our approach .
#<struct ReadData::Alignment source_numbers="", target_numbers="41", tag_name="wa">
This paper explores the use of MathML Pallel Markup Corpora for mathematical expression understanding , the task of which is formulated as a translation from Presentation to Content MathML Markups in our approach .
#<struct ReadData::Alignment source_numbers="", target_numbers="42", tag_name="wa">
This paper explores the use of MathML Pallel Markup Corpora for mathematical expression understanding , the task of which is formulated as a translation from Presentation to Content MathML Markups in our approach .
#<struct ReadData::Alignment source_numbers="", target_numbers="43", tag_name="wa">
This paper explores the use of MathML Pallel Markup Corpora for mathematical expression understanding , the task of which is formulated as a translation from Presentation to Content MathML Markups in our approach .
#<struct ReadData::Alignment source_numbers="", target_numbers="44", tag_name="wa">
This paper explores the use of MathML Pallel Markup Corpora for mathematical expression understanding , the task of which is formulated as a translation from Presentation to Content MathML Markups in our approach .
#<struct ReadData::Alignment source_numbers="", target_numbers="45", tag_name="wa">
This paper explores the use of MathML Pallel Markup Corpora for mathematical expression understanding , the task of which is formulated as a translation from Presentation to Content MathML Markups in our approach .
#<struct ReadData::Alignment source_numbers="", target_numbers="46", tag_name="wa">
This paper explores the use of MathML Pallel Markup Corpora for mathematical expression understanding , the task of which is formulated as a translation from Presentation to Content MathML Markups in our approach .
#<struct ReadData::Alignment source_numbers="", target_numbers="47", tag_name="wa">
This paper explores the use of MathML Pallel Markup Corpora for mathematical expression understanding , the task of which is formulated as a translation from Presentation to Content MathML Markups in our approach .
#<struct ReadData::Alignment source_numbers="", target_numbers="48", tag_name="wa">
This paper explores the use of MathML Pallel Markup Corpora for mathematical expression understanding , the task of which is formulated as a translation from Presentation to Content MathML Markups in our approach .
#<struct ReadData::Alignment source_numbers="", target_numbers="49", tag_name="wa">
This paper explores the use of MathML Pallel Markup Corpora for mathematical expression understanding , the task of which is formulated as a translation from Presentation to Content MathML Markups in our approach .
#<struct ReadData::Alignment source_numbers="", target_numbers="50", tag_name="wa">
This paper explores the use of MathML Pallel Markup Corpora for mathematical expression understanding , the task of which is formulated as a translation from Presentation to Content MathML Markups in our approach .
#<struct ReadData::Alignment source_numbers="", target_numbers="51", tag_name="wa">
This paper explores the use of MathML Pallel Markup Corpora for mathematical expression understanding , the task of which is formulated as a translation from Presentation to Content MathML Markups in our approach .
#<struct ReadData::Alignment source_numbers="", target_numbers="52", tag_name="wa">
This paper explores the use of MathML Pallel Markup Corpora for mathematical expression understanding , the task of which is formulated as a translation from Presentation to Content MathML Markups in our approach .
#<struct ReadData::Alignment source_numbers="", target_numbers="53", tag_name="wa">
This paper explores the use of MathML Pallel Markup Corpora for mathematical expression understanding , the task of which is formulated as a translation from Presentation to Content MathML Markups in our approach .
#<struct ReadData::Alignment source_numbers="", target_numbers="54", tag_name="wa">
This paper explores the use of MathML Pallel Markup Corpora for mathematical expression understanding , the task of which is formulated as a translation from Presentation to Content MathML Markups in our approach .
#<struct ReadData::Alignment source_numbers="", target_numbers="55", tag_name="wa">
This paper explores the use of MathML Pallel Markup Corpora for mathematical expression understanding , the task of which is formulated as a translation from Presentation to Content MathML Markups in our approach .
#<struct ReadData::Alignment source_numbers="", target_numbers="56", tag_name="wa">
This paper explores the use of MathML Pallel Markup Corpora for mathematical expression understanding , the task of which is formulated as a translation from Presentation to Content MathML Markups in our approach .
#<struct ReadData::Alignment source_numbers="", target_numbers="57", tag_name="wa">
In contrast to existing researches that mainly relied on manually encoded transformation rules , we adopt a Statistical-Machine-Translation-based method to automatically extract translation rules from parallel markup corpora .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
In contrast to existing researches that mainly relied on manually encoded transformation rules , we adopt a Statistical-Machine-Translation-based method to automatically extract translation rules from parallel markup corpora .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
In contrast to existing researches that mainly relied on manually encoded transformation rules , we adopt a Statistical-Machine-Translation-based method to automatically extract translation rules from parallel markup corpora .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
In contrast to existing researches that mainly relied on manually encoded transformation rules , we adopt a Statistical-Machine-Translation-based method to automatically extract translation rules from parallel markup corpora .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
In contrast to existing researches that mainly relied on manually encoded transformation rules , we adopt a Statistical-Machine-Translation-based method to automatically extract translation rules from parallel markup corpora .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
In contrast to existing researches that mainly relied on manually encoded transformation rules , we adopt a Statistical-Machine-Translation-based method to automatically extract translation rules from parallel markup corpora .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Experimental results on the Wolfram Function Site show that our approach achieves an improvement against the prior rule-based system .
#<struct ReadData::Alignment source_numbers="14", target_numbers="32", tag_name="wa">
Experimental results on the Wolfram Function Site show that our approach achieves an improvement against the prior rule-based system .
#<struct ReadData::Alignment source_numbers="18", target_numbers="45", tag_name="wa">
Experimental results on the Wolfram Function Site show that our approach achieves an improvement against the prior rule-based system .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
Experimental results on the Wolfram Function Site show that our approach achieves an improvement against the prior rule-based system .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
Experimental results on the Wolfram Function Site show that our approach achieves an improvement against the prior rule-based system .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Experimental results on the Wolfram Function Site show that our approach achieves an improvement against the prior rule-based system .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Experimental results on the Wolfram Function Site show that our approach achieves an improvement against the prior rule-based system .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
Experimental results on the Wolfram Function Site show that our approach achieves an improvement against the prior rule-based system .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
Experimental results on the Wolfram Function Site show that our approach achieves an improvement against the prior rule-based system .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
Experimental results on the Wolfram Function Site show that our approach achieves an improvement against the prior rule-based system .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
Experimental results on the Wolfram Function Site show that our approach achieves an improvement against the prior rule-based system .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
Experimental results on the Wolfram Function Site show that our approach achieves an improvement against the prior rule-based system .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
Experimental results on the Wolfram Function Site show that our approach achieves an improvement against the prior rule-based system .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
Experimental results on the Wolfram Function Site show that our approach achieves an improvement against the prior rule-based system .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
Experimental results on the Wolfram Function Site show that our approach achieves an improvement against the prior rule-based system .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
Experimental results on the Wolfram Function Site show that our approach achieves an improvement against the prior rule-based system .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
Experimental results on the Wolfram Function Site show that our approach achieves an improvement against the prior rule-based system .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
Experimental results on the Wolfram Function Site show that our approach achieves an improvement against the prior rule-based system .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
Experimental results on the Wolfram Function Site show that our approach achieves an improvement against the prior rule-based system .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
Experimental results on the Wolfram Function Site show that our approach achieves an improvement against the prior rule-based system .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
Experimental results on the Wolfram Function Site show that our approach achieves an improvement against the prior rule-based system .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
Experimental results on the Wolfram Function Site show that our approach achieves an improvement against the prior rule-based system .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
Experimental results on the Wolfram Function Site show that our approach achieves an improvement against the prior rule-based system .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
Experimental results on the Wolfram Function Site show that our approach achieves an improvement against the prior rule-based system .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
Experimental results on the Wolfram Function Site show that our approach achieves an improvement against the prior rule-based system .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
Experimental results on the Wolfram Function Site show that our approach achieves an improvement against the prior rule-based system .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
Experimental results on the Wolfram Function Site show that our approach achieves an improvement against the prior rule-based system .
#<struct ReadData::Alignment source_numbers="", target_numbers="40", tag_name="wa">
Experimental results on the Wolfram Function Site show that our approach achieves an improvement against the prior rule-based system .
#<struct ReadData::Alignment source_numbers="", target_numbers="41", tag_name="wa">
Experimental results on the Wolfram Function Site show that our approach achieves an improvement against the prior rule-based system .
#<struct ReadData::Alignment source_numbers="", target_numbers="42", tag_name="wa">
Experimental results on the Wolfram Function Site show that our approach achieves an improvement against the prior rule-based system .
#<struct ReadData::Alignment source_numbers="", target_numbers="43", tag_name="wa">
Experimental results on the Wolfram Function Site show that our approach achieves an improvement against the prior rule-based system .
#<struct ReadData::Alignment source_numbers="", target_numbers="44", tag_name="wa">
Experimental results on the Wolfram Function Site show that our approach achieves an improvement against the prior rule-based system .
#<struct ReadData::Alignment source_numbers="", target_numbers="46", tag_name="wa">
Experimental results on the Wolfram Function Site show that our approach achieves an improvement against the prior rule-based system .
#<struct ReadData::Alignment source_numbers="", target_numbers="47", tag_name="wa">
One of the most significant current discussions in the digitization of mathematical and scientific content and its applications is the semantic enrichment of mathematical documents , that is adding or associating semantic tags - usually concepts - to mathematical expressions .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
One of the most significant current discussions in the digitization of mathematical and scientific content and its applications is the semantic enrichment of mathematical documents , that is adding or associating semantic tags - usually concepts - to mathematical expressions .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
One of the most significant current discussions in the digitization of mathematical and scientific content and its applications is the semantic enrichment of mathematical documents , that is adding or associating semantic tags - usually concepts - to mathematical expressions .
#<struct ReadData::Alignment source_numbers="37", target_numbers="", tag_name="wa">
One of the most significant current discussions in the digitization of mathematical and scientific content and its applications is the semantic enrichment of mathematical documents , that is adding or associating semantic tags - usually concepts - to mathematical expressions .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
One of the most significant current discussions in the digitization of mathematical and scientific content and its applications is the semantic enrichment of mathematical documents , that is adding or associating semantic tags - usually concepts - to mathematical expressions .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
The direct application of this is enabling semantic searches for mathematical expressions by understanding the intent of the searcher and the contextual meaning of mathematical terms improve search accuracy .
#<struct ReadData::Alignment source_numbers="4", target_numbers="4", tag_name="wa">
The direct application of this is enabling semantic searches for mathematical expressions by understanding the intent of the searcher and the contextual meaning of mathematical terms improve search accuracy .
#<struct ReadData::Alignment source_numbers="6", target_numbers="6", tag_name="wa">
The direct application of this is enabling semantic searches for mathematical expressions by understanding the intent of the searcher and the contextual meaning of mathematical terms improve search accuracy .
#<struct ReadData::Alignment source_numbers="20", target_numbers="13", tag_name="wa">
The direct application of this is enabling semantic searches for mathematical expressions by understanding the intent of the searcher and the contextual meaning of mathematical terms improve search accuracy .
#<struct ReadData::Alignment source_numbers="23", target_numbers="18", tag_name="wa">
The direct application of this is enabling semantic searches for mathematical expressions by understanding the intent of the searcher and the contextual meaning of mathematical terms improve search accuracy .
#<struct ReadData::Alignment source_numbers="14", target_numbers="19", tag_name="wa">
The direct application of this is enabling semantic searches for mathematical expressions by understanding the intent of the searcher and the contextual meaning of mathematical terms improve search accuracy .
#<struct ReadData::Alignment source_numbers="16", target_numbers="21", tag_name="wa">
The direct application of this is enabling semantic searches for mathematical expressions by understanding the intent of the searcher and the contextual meaning of mathematical terms improve search accuracy .
#<struct ReadData::Alignment source_numbers="29", target_numbers="34", tag_name="wa">
The direct application of this is enabling semantic searches for mathematical expressions by understanding the intent of the searcher and the contextual meaning of mathematical terms improve search accuracy .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
The direct application of this is enabling semantic searches for mathematical expressions by understanding the intent of the searcher and the contextual meaning of mathematical terms improve search accuracy .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
The direct application of this is enabling semantic searches for mathematical expressions by understanding the intent of the searcher and the contextual meaning of mathematical terms improve search accuracy .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
The direct application of this is enabling semantic searches for mathematical expressions by understanding the intent of the searcher and the contextual meaning of mathematical terms improve search accuracy .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
The direct application of this is enabling semantic searches for mathematical expressions by understanding the intent of the searcher and the contextual meaning of mathematical terms improve search accuracy .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
The direct application of this is enabling semantic searches for mathematical expressions by understanding the intent of the searcher and the contextual meaning of mathematical terms improve search accuracy .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
The direct application of this is enabling semantic searches for mathematical expressions by understanding the intent of the searcher and the contextual meaning of mathematical terms improve search accuracy .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
The direct application of this is enabling semantic searches for mathematical expressions by understanding the intent of the searcher and the contextual meaning of mathematical terms improve search accuracy .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
The direct application of this is enabling semantic searches for mathematical expressions by understanding the intent of the searcher and the contextual meaning of mathematical terms improve search accuracy .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
The direct application of this is enabling semantic searches for mathematical expressions by understanding the intent of the searcher and the contextual meaning of mathematical terms improve search accuracy .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
The direct application of this is enabling semantic searches for mathematical expressions by understanding the intent of the searcher and the contextual meaning of mathematical terms improve search accuracy .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
- Second , the underlying mathematical meaning of an expression need to follow a semantic markup in a semantically rigorous way .
#<struct ReadData::Alignment source_numbers="10,11", target_numbers="10,11", tag_name="wa">
- The third problem is that new notations tend to be introduced and used as and when needed so a mechanism is required for referring to mathematical concepts outside of the base collection , allowing them to be represented .
#<struct ReadData::Alignment source_numbers="39", target_numbers="31", tag_name="wa">
- The third problem is that new notations tend to be introduced and used as and when needed so a mechanism is required for referring to mathematical concepts outside of the base collection , allowing them to be represented .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
- The third problem is that new notations tend to be introduced and used as and when needed so a mechanism is required for referring to mathematical concepts outside of the base collection , allowing them to be represented .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
- The third problem is that new notations tend to be introduced and used as and when needed so a mechanism is required for referring to mathematical concepts outside of the base collection , allowing them to be represented .
#<struct ReadData::Alignment source_numbers="33", target_numbers="", tag_name="wa">
- The third problem is that new notations tend to be introduced and used as and when needed so a mechanism is required for referring to mathematical concepts outside of the base collection , allowing them to be represented .
#<struct ReadData::Alignment source_numbers="34", target_numbers="", tag_name="wa">
- The third problem is that new notations tend to be introduced and used as and when needed so a mechanism is required for referring to mathematical concepts outside of the base collection , allowing them to be represented .
#<struct ReadData::Alignment source_numbers="35", target_numbers="", tag_name="wa">
- The third problem is that new notations tend to be introduced and used as and when needed so a mechanism is required for referring to mathematical concepts outside of the base collection , allowing them to be represented .
#<struct ReadData::Alignment source_numbers="36", target_numbers="", tag_name="wa">
- The third problem is that new notations tend to be introduced and used as and when needed so a mechanism is required for referring to mathematical concepts outside of the base collection , allowing them to be represented .
#<struct ReadData::Alignment source_numbers="37", target_numbers="", tag_name="wa">
- The third problem is that new notations tend to be introduced and used as and when needed so a mechanism is required for referring to mathematical concepts outside of the base collection , allowing them to be represented .
#<struct ReadData::Alignment source_numbers="38", target_numbers="", tag_name="wa">
The aim of this paper is to introduce a method for automatic mathematics semantic enrichment that capable of analyze and disambiguate mathematical terms .
#<struct ReadData::Alignment source_numbers="10", target_numbers="14", tag_name="wa">
The aim of this paper is to introduce a method for automatic mathematics semantic enrichment that capable of analyze and disambiguate mathematical terms .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
The aim of this paper is to introduce a method for automatic mathematics semantic enrichment that capable of analyze and disambiguate mathematical terms .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
The aim of this paper is to introduce a method for automatic mathematics semantic enrichment that capable of analyze and disambiguate mathematical terms .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
The aim of this paper is to introduce a method for automatic mathematics semantic enrichment that capable of analyze and disambiguate mathematical terms .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
The semantic enrichment task then becomes generating Content MathML outputs from Presentation MathML expressions .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
The semantic enrichment task then becomes generating Content MathML outputs from Presentation MathML expressions .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
- Last , large collections of formulas are available in MathML and we can easily assess these collections .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
- In the scope of this paper , we only make use the information within a mathematical expression for disambiguation when translating it to content markup .
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
- In the scope of this paper , we only make use the information within a mathematical expression for disambiguation when translating it to content markup .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
- Since it is a hand written rule-based system , SnuggleTeX requires mathematical knowledge and human effort to develop
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
- Since it is a hand written rule-based system , SnuggleTeX requires mathematical knowledge and human effort to develop
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
- Since it is a hand written rule-based system , SnuggleTeX requires mathematical knowledge and human effort to develop
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
- Since it is a hand written rule-based system , SnuggleTeX requires mathematical knowledge and human effort to develop
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
- Due to the diversity of mathematical expressions , SnuggleTeX is still to be considered experimental and has difficulty processing complicated mathematical symbols and expressions .
#<struct ReadData::Alignment source_numbers="14", target_numbers="12", tag_name="wa">
- Due to the diversity of mathematical expressions , SnuggleTeX is still to be considered experimental and has difficulty processing complicated mathematical symbols and expressions .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
- Due to the diversity of mathematical expressions , SnuggleTeX is still to be considered experimental and has difficulty processing complicated mathematical symbols and expressions .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
In this paper , we propose an approach that automatically learn the semantics inference from a presentation from parallel markup data .
#<struct ReadData::Alignment source_numbers="14", target_numbers="27", tag_name="wa">
In this paper , we propose an approach that automatically learn the semantics inference from a presentation from parallel markup data .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
In this paper , we propose an approach that automatically learn the semantics inference from a presentation from parallel markup data .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
In this paper , we propose an approach that automatically learn the semantics inference from a presentation from parallel markup data .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
In this paper , we propose an approach that automatically learn the semantics inference from a presentation from parallel markup data .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
In this paper , we propose an approach that automatically learn the semantics inference from a presentation from parallel markup data .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
In this paper , we propose an approach that automatically learn the semantics inference from a presentation from parallel markup data .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
In this paper , we propose an approach that automatically learn the semantics inference from a presentation from parallel markup data .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
In this paper , we propose an approach that automatically learn the semantics inference from a presentation from parallel markup data .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
In this paper , we propose an approach that automatically learn the semantics inference from a presentation from parallel markup data .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
In this paper , we propose an approach that automatically learn the semantics inference from a presentation from parallel markup data .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
In this paper , we propose an approach that automatically learn the semantics inference from a presentation from parallel markup data .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
In this paper , we propose an approach that automatically learn the semantics inference from a presentation from parallel markup data .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
In this paper , we propose an approach that automatically learn the semantics inference from a presentation from parallel markup data .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
In this paper , we propose an approach that automatically learn the semantics inference from a presentation from parallel markup data .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
In this paper , we propose an approach that automatically learn the semantics inference from a presentation from parallel markup data .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
In this paper , we propose an approach that automatically learn the semantics inference from a presentation from parallel markup data .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
In this paper , we propose an approach that automatically learn the semantics inference from a presentation from parallel markup data .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
In this paper , we propose an approach that automatically learn the semantics inference from a presentation from parallel markup data .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
In this paper , we propose an approach that automatically learn the semantics inference from a presentation from parallel markup data .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
In this paper , we propose an approach that automatically learn the semantics inference from a presentation from parallel markup data .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
In this paper , we propose an approach that automatically learn the semantics inference from a presentation from parallel markup data .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
In this paper , we propose an approach that automatically learn the semantics inference from a presentation from parallel markup data .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
In this paper , we propose an approach that automatically learn the semantics inference from a presentation from parallel markup data .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
In this paper , we propose an approach that automatically learn the semantics inference from a presentation from parallel markup data .
#<struct ReadData::Alignment source_numbers="", target_numbers="40", tag_name="wa">
The idea of this approach is based on statistical machine translation .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
The idea of this approach is based on statistical machine translation .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
The idea of this approach is based on statistical machine translation .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
The idea of this approach is based on statistical machine translation .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
The idea of this approach is based on statistical machine translation .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
The underlying mathematical meaning of an expression is inferred according to the probability distribution $ p( c | p ) $ that a semantic expression $ c $ is the translation of a presentation expression $ p $ .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
The underlying mathematical meaning of an expression is inferred according to the probability distribution $ p( c | p ) $ that a semantic expression $ c $ is the translation of a presentation expression $ p $ .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
The underlying mathematical meaning of an expression is inferred according to the probability distribution $ p( c | p ) $ that a semantic expression $ c $ is the translation of a presentation expression $ p $ .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
The probability distribution will be automatically learned from data that have both Presentation and Content MathML markup , that is the parallel markup MathML data .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
The probability distribution will be automatically learned from data that have both Presentation and Content MathML markup , that is the parallel markup MathML data .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
The probability distribution will be automatically learned from data that have both Presentation and Content MathML markup , that is the parallel markup MathML data .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
We also prepare another parallel markup MathML data by annotating mathematical expressions on 20 papers from The Archives of the Association for Computational Linguistics \CITE ( ACL-ARC ) .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
We also prepare another parallel markup MathML data by annotating mathematical expressions on 20 papers from The Archives of the Association for Computational Linguistics \CITE ( ACL-ARC ) .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
We also prepare another parallel markup MathML data by annotating mathematical expressions on 20 papers from The Archives of the Association for Computational Linguistics \CITE ( ACL-ARC ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
We also prepare another parallel markup MathML data by annotating mathematical expressions on 20 papers from The Archives of the Association for Computational Linguistics \CITE ( ACL-ARC ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
We have two main contributions in this paper
#<struct ReadData::Alignment source_numbers="1,2", target_numbers="1,2", tag_name="wa">
We have two main contributions in this paper
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
We have two main contributions in this paper
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
We have two main contributions in this paper
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
- First , successfully apply the machine translation techniques to the problem of mathematic semantic enrichment .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
- First , successfully apply the machine translation techniques to the problem of mathematic semantic enrichment .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Experimental results show that our system significantly outperforms the current rule-based system and it can handle a lot of practical cases in the mathematics semantic enrichment problem .
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
Since both quantity and quality of mathematical expressions are continuing to grow and expand through time , we believe that our system will cover most of real life mathematical expressions .
#<struct ReadData::Alignment source_numbers="16", target_numbers="11", tag_name="wa">
Since both quantity and quality of mathematical expressions are continuing to grow and expand through time , we believe that our system will cover most of real life mathematical expressions .
#<struct ReadData::Alignment source_numbers="12", target_numbers="12", tag_name="wa">
Since both quantity and quality of mathematical expressions are continuing to grow and expand through time , we believe that our system will cover most of real life mathematical expressions .
#<struct ReadData::Alignment source_numbers="22", target_numbers="18", tag_name="wa">
Since both quantity and quality of mathematical expressions are continuing to grow and expand through time , we believe that our system will cover most of real life mathematical expressions .
#<struct ReadData::Alignment source_numbers="23", target_numbers="22", tag_name="wa">
Since both quantity and quality of mathematical expressions are continuing to grow and expand through time , we believe that our system will cover most of real life mathematical expressions .
#<struct ReadData::Alignment source_numbers="30", target_numbers="26", tag_name="wa">
Since both quantity and quality of mathematical expressions are continuing to grow and expand through time , we believe that our system will cover most of real life mathematical expressions .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Since both quantity and quality of mathematical expressions are continuing to grow and expand through time , we believe that our system will cover most of real life mathematical expressions .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Since both quantity and quality of mathematical expressions are continuing to grow and expand through time , we believe that our system will cover most of real life mathematical expressions .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
Since both quantity and quality of mathematical expressions are continuing to grow and expand through time , we believe that our system will cover most of real life mathematical expressions .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
Since both quantity and quality of mathematical expressions are continuing to grow and expand through time , we believe that our system will cover most of real life mathematical expressions .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
Since both quantity and quality of mathematical expressions are continuing to grow and expand through time , we believe that our system will cover most of real life mathematical expressions .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
Since both quantity and quality of mathematical expressions are continuing to grow and expand through time , we believe that our system will cover most of real life mathematical expressions .
#<struct ReadData::Alignment source_numbers="26", target_numbers="", tag_name="wa">
Since both quantity and quality of mathematical expressions are continuing to grow and expand through time , we believe that our system will cover most of real life mathematical expressions .
#<struct ReadData::Alignment source_numbers="27", target_numbers="", tag_name="wa">
Since both quantity and quality of mathematical expressions are continuing to grow and expand through time , we believe that our system will cover most of real life mathematical expressions .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
Since both quantity and quality of mathematical expressions are continuing to grow and expand through time , we believe that our system will cover most of real life mathematical expressions .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
Since both quantity and quality of mathematical expressions are continuing to grow and expand through time , we believe that our system will cover most of real life mathematical expressions .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
- Second , mathematics knowledge such as symbol 's meanings or structural relations is automatically learned while training , therefor it is not required mathematics experts nor human effort and it is also easier to update the system given more data .
#<struct ReadData::Alignment source_numbers="36", target_numbers="22", tag_name="wa">
- Second , mathematics knowledge such as symbol 's meanings or structural relations is automatically learned while training , therefor it is not required mathematics experts nor human effort and it is also easier to update the system given more data .
#<struct ReadData::Alignment source_numbers="37", target_numbers="23", tag_name="wa">
- Second , mathematics knowledge such as symbol 's meanings or structural relations is automatically learned while training , therefor it is not required mathematics experts nor human effort and it is also easier to update the system given more data .
#<struct ReadData::Alignment source_numbers="22", target_numbers="25,26", tag_name="wa">
- Second , mathematics knowledge such as symbol 's meanings or structural relations is automatically learned while training , therefor it is not required mathematics experts nor human effort and it is also easier to update the system given more data .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
- Second , mathematics knowledge such as symbol 's meanings or structural relations is automatically learned while training , therefor it is not required mathematics experts nor human effort and it is also easier to update the system given more data .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
- Second , mathematics knowledge such as symbol 's meanings or structural relations is automatically learned while training , therefor it is not required mathematics experts nor human effort and it is also easier to update the system given more data .
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
- Second , mathematics knowledge such as symbol 's meanings or structural relations is automatically learned while training , therefor it is not required mathematics experts nor human effort and it is also easier to update the system given more data .
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
- Second , mathematics knowledge such as symbol 's meanings or structural relations is automatically learned while training , therefor it is not required mathematics experts nor human effort and it is also easier to update the system given more data .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
- Second , mathematics knowledge such as symbol 's meanings or structural relations is automatically learned while training , therefor it is not required mathematics experts nor human effort and it is also easier to update the system given more data .
#<struct ReadData::Alignment source_numbers="26", target_numbers="", tag_name="wa">
- Second , mathematics knowledge such as symbol 's meanings or structural relations is automatically learned while training , therefor it is not required mathematics experts nor human effort and it is also easier to update the system given more data .
#<struct ReadData::Alignment source_numbers="27", target_numbers="", tag_name="wa">
- Second , mathematics knowledge such as symbol 's meanings or structural relations is automatically learned while training , therefor it is not required mathematics experts nor human effort and it is also easier to update the system given more data .
#<struct ReadData::Alignment source_numbers="32", target_numbers="", tag_name="wa">
- Second , mathematics knowledge such as symbol 's meanings or structural relations is automatically learned while training , therefor it is not required mathematics experts nor human effort and it is also easier to update the system given more data .
#<struct ReadData::Alignment source_numbers="38", target_numbers="", tag_name="wa">
- Second , mathematics knowledge such as symbol 's meanings or structural relations is automatically learned while training , therefor it is not required mathematics experts nor human effort and it is also easier to update the system given more data .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
- Second , mathematics knowledge such as symbol 's meanings or structural relations is automatically learned while training , therefor it is not required mathematics experts nor human effort and it is also easier to update the system given more data .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
- Second , mathematics knowledge such as symbol 's meanings or structural relations is automatically learned while training , therefor it is not required mathematics experts nor human effort and it is also easier to update the system given more data .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
- Second , mathematics knowledge such as symbol 's meanings or structural relations is automatically learned while training , therefor it is not required mathematics experts nor human effort and it is also easier to update the system given more data .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
- Second , mathematics knowledge such as symbol 's meanings or structural relations is automatically learned while training , therefor it is not required mathematics experts nor human effort and it is also easier to update the system given more data .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
- Second , mathematics knowledge such as symbol 's meanings or structural relations is automatically learned while training , therefor it is not required mathematics experts nor human effort and it is also easier to update the system given more data .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
- Second , mathematics knowledge such as symbol 's meanings or structural relations is automatically learned while training , therefor it is not required mathematics experts nor human effort and it is also easier to update the system given more data .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
Since new notations keep growing , it is important to update the system as quick as possible .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
Since new notations keep growing , it is important to update the system as quick as possible .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Since new notations keep growing , it is important to update the system as quick as possible .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
In our experiments , we performed a 10-folds cross validation on mathematical expressions from 6 categories of the Wolfram Functions Site to evaluate the effectiveness of our proposed learning method .
#<struct ReadData::Alignment source_numbers="15", target_numbers="11", tag_name="wa">
In our experiments , we performed a 10-folds cross validation on mathematical expressions from 6 categories of the Wolfram Functions Site to evaluate the effectiveness of our proposed learning method .
#<struct ReadData::Alignment source_numbers="16", target_numbers="12", tag_name="wa">
In our experiments , we performed a 10-folds cross validation on mathematical expressions from 6 categories of the Wolfram Functions Site to evaluate the effectiveness of our proposed learning method .
#<struct ReadData::Alignment source_numbers="17", target_numbers="13", tag_name="wa">
In our experiments , we performed a 10-folds cross validation on mathematical expressions from 6 categories of the Wolfram Functions Site to evaluate the effectiveness of our proposed learning method .
#<struct ReadData::Alignment source_numbers="18", target_numbers="14", tag_name="wa">
In our experiments , we performed a 10-folds cross validation on mathematical expressions from 6 categories of the Wolfram Functions Site to evaluate the effectiveness of our proposed learning method .
#<struct ReadData::Alignment source_numbers="19", target_numbers="15", tag_name="wa">
In our experiments , we performed a 10-folds cross validation on mathematical expressions from 6 categories of the Wolfram Functions Site to evaluate the effectiveness of our proposed learning method .
#<struct ReadData::Alignment source_numbers="20", target_numbers="16", tag_name="wa">
In our experiments , we performed a 10-folds cross validation on mathematical expressions from 6 categories of the Wolfram Functions Site to evaluate the effectiveness of our proposed learning method .
#<struct ReadData::Alignment source_numbers="21", target_numbers="17", tag_name="wa">
In our experiments , we performed a 10-folds cross validation on mathematical expressions from 6 categories of the Wolfram Functions Site to evaluate the effectiveness of our proposed learning method .
#<struct ReadData::Alignment source_numbers="22", target_numbers="18", tag_name="wa">
In our experiments , we performed a 10-folds cross validation on mathematical expressions from 6 categories of the Wolfram Functions Site to evaluate the effectiveness of our proposed learning method .
#<struct ReadData::Alignment source_numbers="23", target_numbers="19", tag_name="wa">
In our experiments , we performed a 10-folds cross validation on mathematical expressions from 6 categories of the Wolfram Functions Site to evaluate the effectiveness of our proposed learning method .
#<struct ReadData::Alignment source_numbers="24", target_numbers="20", tag_name="wa">
In our experiments , we performed a 10-folds cross validation on mathematical expressions from 6 categories of the Wolfram Functions Site to evaluate the effectiveness of our proposed learning method .
#<struct ReadData::Alignment source_numbers="25", target_numbers="21", tag_name="wa">
In our experiments , we performed a 10-folds cross validation on mathematical expressions from 6 categories of the Wolfram Functions Site to evaluate the effectiveness of our proposed learning method .
#<struct ReadData::Alignment source_numbers="26", target_numbers="22", tag_name="wa">
In our experiments , we performed a 10-folds cross validation on mathematical expressions from 6 categories of the Wolfram Functions Site to evaluate the effectiveness of our proposed learning method .
#<struct ReadData::Alignment source_numbers="28", target_numbers="23", tag_name="wa">
In our experiments , we performed a 10-folds cross validation on mathematical expressions from 6 categories of the Wolfram Functions Site to evaluate the effectiveness of our proposed learning method .
#<struct ReadData::Alignment source_numbers="29", target_numbers="24", tag_name="wa">
In our experiments , we performed a 10-folds cross validation on mathematical expressions from 6 categories of the Wolfram Functions Site to evaluate the effectiveness of our proposed learning method .
#<struct ReadData::Alignment source_numbers="30", target_numbers="25", tag_name="wa">
In our experiments , we performed a 10-folds cross validation on mathematical expressions from 6 categories of the Wolfram Functions Site to evaluate the effectiveness of our proposed learning method .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
In our experiments , we performed a 10-folds cross validation on mathematical expressions from 6 categories of the Wolfram Functions Site to evaluate the effectiveness of our proposed learning method .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
In our experiments , we performed a 10-folds cross validation on mathematical expressions from 6 categories of the Wolfram Functions Site to evaluate the effectiveness of our proposed learning method .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
In our experiments , we performed a 10-folds cross validation on mathematical expressions from 6 categories of the Wolfram Functions Site to evaluate the effectiveness of our proposed learning method .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
In our experiments , we performed a 10-folds cross validation on mathematical expressions from 6 categories of the Wolfram Functions Site to evaluate the effectiveness of our proposed learning method .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
In our experiments , we performed a 10-folds cross validation on mathematical expressions from 6 categories of the Wolfram Functions Site to evaluate the effectiveness of our proposed learning method .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
In our experiments , we performed a 10-folds cross validation on mathematical expressions from 6 categories of the Wolfram Functions Site to evaluate the effectiveness of our proposed learning method .
#<struct ReadData::Alignment source_numbers="27", target_numbers="", tag_name="wa">
In our experiments , we performed a 10-folds cross validation on mathematical expressions from 6 categories of the Wolfram Functions Site to evaluate the effectiveness of our proposed learning method .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
In our experiments , we performed a 10-folds cross validation on mathematical expressions from 6 categories of the Wolfram Functions Site to evaluate the effectiveness of our proposed learning method .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
We set up another experiment to confirm the correlation between system performance and training set size and saw that increasing the size of training data actually boost the system performance .
#<struct ReadData::Alignment source_numbers="27", target_numbers="9", tag_name="wa">
We set up another experiment to confirm the correlation between system performance and training set size and saw that increasing the size of training data actually boost the system performance .
#<struct ReadData::Alignment source_numbers="28", target_numbers="10", tag_name="wa">
We set up another experiment to confirm the correlation between system performance and training set size and saw that increasing the size of training data actually boost the system performance .
#<struct ReadData::Alignment source_numbers="17,18", target_numbers="18,19", tag_name="wa">
We set up another experiment to confirm the correlation between system performance and training set size and saw that increasing the size of training data actually boost the system performance .
#<struct ReadData::Alignment source_numbers="10", target_numbers="29", tag_name="wa">
We set up another experiment to confirm the correlation between system performance and training set size and saw that increasing the size of training data actually boost the system performance .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
We set up another experiment to confirm the correlation between system performance and training set size and saw that increasing the size of training data actually boost the system performance .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
We set up another experiment to confirm the correlation between system performance and training set size and saw that increasing the size of training data actually boost the system performance .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
We set up another experiment to confirm the correlation between system performance and training set size and saw that increasing the size of training data actually boost the system performance .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
We set up another experiment to confirm the correlation between system performance and training set size and saw that increasing the size of training data actually boost the system performance .
#<struct ReadData::Alignment source_numbers="26", target_numbers="", tag_name="wa">
We set up another experiment to confirm the correlation between system performance and training set size and saw that increasing the size of training data actually boost the system performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
We set up another experiment to confirm the correlation between system performance and training set size and saw that increasing the size of training data actually boost the system performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
We set up another experiment to confirm the correlation between system performance and training set size and saw that increasing the size of training data actually boost the system performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
We set up another experiment to confirm the correlation between system performance and training set size and saw that increasing the size of training data actually boost the system performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
We set up another experiment to confirm the correlation between system performance and training set size and saw that increasing the size of training data actually boost the system performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
We set up another experiment to confirm the correlation between system performance and training set size and saw that increasing the size of training data actually boost the system performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
We also performed extensive side-by-side comparison with prior work \CITE over a data set from ACL-ARC scientific papers .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
We also performed extensive side-by-side comparison with prior work \CITE over a data set from ACL-ARC scientific papers .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
We also performed extensive side-by-side comparison with prior work \CITE over a data set from ACL-ARC scientific papers .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
We also performed extensive side-by-side comparison with prior work \CITE over a data set from ACL-ARC scientific papers .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Our experimental results show that the proposed approach works well on the mathematics semantic enrichment problem and it excels the previous work by providing significantly less error rate .
#<struct ReadData::Alignment source_numbers="25", target_numbers="26", tag_name="wa">
Our experimental results show that the proposed approach works well on the mathematics semantic enrichment problem and it excels the previous work by providing significantly less error rate .
#<struct ReadData::Alignment source_numbers="26", target_numbers="27", tag_name="wa">
Our experimental results show that the proposed approach works well on the mathematics semantic enrichment problem and it excels the previous work by providing significantly less error rate .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Our experimental results show that the proposed approach works well on the mathematics semantic enrichment problem and it excels the previous work by providing significantly less error rate .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
Our experimental results show that the proposed approach works well on the mathematics semantic enrichment problem and it excels the previous work by providing significantly less error rate .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Our experimental results show that the proposed approach works well on the mathematics semantic enrichment problem and it excels the previous work by providing significantly less error rate .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
Our experimental results show that the proposed approach works well on the mathematics semantic enrichment problem and it excels the previous work by providing significantly less error rate .
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
Our experimental results show that the proposed approach works well on the mathematics semantic enrichment problem and it excels the previous work by providing significantly less error rate .
#<struct ReadData::Alignment source_numbers="27", target_numbers="", tag_name="wa">
Our experimental results show that the proposed approach works well on the mathematics semantic enrichment problem and it excels the previous work by providing significantly less error rate .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Our experimental results show that the proposed approach works well on the mathematics semantic enrichment problem and it excels the previous work by providing significantly less error rate .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Our experimental results show that the proposed approach works well on the mathematics semantic enrichment problem and it excels the previous work by providing significantly less error rate .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Our experimental results show that the proposed approach works well on the mathematics semantic enrichment problem and it excels the previous work by providing significantly less error rate .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
Our experimental results show that the proposed approach works well on the mathematics semantic enrichment problem and it excels the previous work by providing significantly less error rate .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
Our experimental results show that the proposed approach works well on the mathematics semantic enrichment problem and it excels the previous work by providing significantly less error rate .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
The remainder of this paper is organized as follows : In Section 2 , we give a brief overview of the background and related work for semantic enrichment of mathematical expressions , while in Section 3 we present our proposed method .
#<struct ReadData::Alignment source_numbers="41", target_numbers="31", tag_name="wa">
The remainder of this paper is organized as follows : In Section 2 , we give a brief overview of the background and related work for semantic enrichment of mathematical expressions , while in Section 3 we present our proposed method .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
The remainder of this paper is organized as follows : In Section 2 , we give a brief overview of the background and related work for semantic enrichment of mathematical expressions , while in Section 3 we present our proposed method .
#<struct ReadData::Alignment source_numbers="31", target_numbers="", tag_name="wa">
The remainder of this paper is organized as follows : In Section 2 , we give a brief overview of the background and related work for semantic enrichment of mathematical expressions , while in Section 3 we present our proposed method .
#<struct ReadData::Alignment source_numbers="32", target_numbers="", tag_name="wa">
The remainder of this paper is organized as follows : In Section 2 , we give a brief overview of the background and related work for semantic enrichment of mathematical expressions , while in Section 3 we present our proposed method .
#<struct ReadData::Alignment source_numbers="33", target_numbers="", tag_name="wa">
The remainder of this paper is organized as follows : In Section 2 , we give a brief overview of the background and related work for semantic enrichment of mathematical expressions , while in Section 3 we present our proposed method .
#<struct ReadData::Alignment source_numbers="34", target_numbers="", tag_name="wa">
The remainder of this paper is organized as follows : In Section 2 , we give a brief overview of the background and related work for semantic enrichment of mathematical expressions , while in Section 3 we present our proposed method .
#<struct ReadData::Alignment source_numbers="35", target_numbers="", tag_name="wa">
The remainder of this paper is organized as follows : In Section 2 , we give a brief overview of the background and related work for semantic enrichment of mathematical expressions , while in Section 3 we present our proposed method .
#<struct ReadData::Alignment source_numbers="36", target_numbers="", tag_name="wa">
The remainder of this paper is organized as follows : In Section 2 , we give a brief overview of the background and related work for semantic enrichment of mathematical expressions , while in Section 3 we present our proposed method .
#<struct ReadData::Alignment source_numbers="37", target_numbers="", tag_name="wa">
The remainder of this paper is organized as follows : In Section 2 , we give a brief overview of the background and related work for semantic enrichment of mathematical expressions , while in Section 3 we present our proposed method .
#<struct ReadData::Alignment source_numbers="38", target_numbers="", tag_name="wa">
The remainder of this paper is organized as follows : In Section 2 , we give a brief overview of the background and related work for semantic enrichment of mathematical expressions , while in Section 3 we present our proposed method .
#<struct ReadData::Alignment source_numbers="39", target_numbers="", tag_name="wa">
The remainder of this paper is organized as follows : In Section 2 , we give a brief overview of the background and related work for semantic enrichment of mathematical expressions , while in Section 3 we present our proposed method .
#<struct ReadData::Alignment source_numbers="40", target_numbers="", tag_name="wa">
The remainder of this paper is organized as follows : In Section 2 , we give a brief overview of the background and related work for semantic enrichment of mathematical expressions , while in Section 3 we present our proposed method .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
We then describe the experimental setup and results in Section 4 .
#<struct ReadData::Alignment source_numbers="2", target_numbers="8", tag_name="wa">
We then describe the experimental setup and results in Section 4 .
#<struct ReadData::Alignment source_numbers="3", target_numbers="9", tag_name="wa">
We then describe the experimental setup and results in Section 4 .
#<struct ReadData::Alignment source_numbers="4", target_numbers="10", tag_name="wa">
We then describe the experimental setup and results in Section 4 .
#<struct ReadData::Alignment source_numbers="5", target_numbers="11", tag_name="wa">
We then describe the experimental setup and results in Section 4 .
#<struct ReadData::Alignment source_numbers="6", target_numbers="12", tag_name="wa">
We then describe the experimental setup and results in Section 4 .
#<struct ReadData::Alignment source_numbers="11", target_numbers="17", tag_name="wa">
We then describe the experimental setup and results in Section 4 .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
We then describe the experimental setup and results in Section 4 .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
We then describe the experimental setup and results in Section 4 .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
We then describe the experimental setup and results in Section 4 .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
We then describe the experimental setup and results in Section 4 .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
We then describe the experimental setup and results in Section 4 .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
We then describe the experimental setup and results in Section 4 .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
We then describe the experimental setup and results in Section 4 .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
A way of dealing with mathematical formulas in this format is to convert them to another text-based format , as seen in InftyReader \CITE .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
A way of dealing with mathematical formulas in this format is to convert them to another text-based format , as seen in InftyReader \CITE .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
A way of dealing with mathematical formulas in this format is to convert them to another text-based format , as seen in InftyReader \CITE .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
A way of dealing with mathematical formulas in this format is to convert them to another text-based format , as seen in InftyReader \CITE .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
A way of dealing with mathematical formulas in this format is to convert them to another text-based format , as seen in InftyReader \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
A way of dealing with mathematical formulas in this format is to convert them to another text-based format , as seen in InftyReader \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
A way of dealing with mathematical formulas in this format is to convert them to another text-based format , as seen in InftyReader \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
A way of dealing with mathematical formulas in this format is to convert them to another text-based format , as seen in InftyReader \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
For scientific documents , \TeX{} has been used to encode mathematical formulas .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
For scientific documents , \TeX{} has been used to encode mathematical formulas .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
For scientific documents , \TeX{} has been used to encode mathematical formulas .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
The formula is printed in a way a person would write by hand , or typeset the equation .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
The formula is printed in a way a person would write by hand , or typeset the equation .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
In some web pages , such as the Wikipedia site , a formula is displayed in both image and \TeX{} formats .
#<struct ReadData::Alignment source_numbers="12", target_numbers="12", tag_name="wa">
In some web pages , such as the Wikipedia site , a formula is displayed in both image and \TeX{} formats .
#<struct ReadData::Alignment source_numbers="13", target_numbers="13", tag_name="wa">
In some web pages , such as the Wikipedia site , a formula is displayed in both image and \TeX{} formats .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
MathML has two types of encoding , content-based encoding which is called Content MathML , dealing with the meaning of formulas , and presentation-based encoding which is called Presentation MathML , dealing with the display of formulas .
#<struct ReadData::Alignment source_numbers="30", target_numbers="9", tag_name="wa">
MathML has two types of encoding , content-based encoding which is called Content MathML , dealing with the meaning of formulas , and presentation-based encoding which is called Presentation MathML , dealing with the display of formulas .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
MathML has two types of encoding , content-based encoding which is called Content MathML , dealing with the meaning of formulas , and presentation-based encoding which is called Presentation MathML , dealing with the display of formulas .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
MathML has two types of encoding , content-based encoding which is called Content MathML , dealing with the meaning of formulas , and presentation-based encoding which is called Presentation MathML , dealing with the display of formulas .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
MathML has two types of encoding , content-based encoding which is called Content MathML , dealing with the meaning of formulas , and presentation-based encoding which is called Presentation MathML , dealing with the display of formulas .
#<struct ReadData::Alignment source_numbers="26", target_numbers="", tag_name="wa">
MathML has two types of encoding , content-based encoding which is called Content MathML , dealing with the meaning of formulas , and presentation-based encoding which is called Presentation MathML , dealing with the display of formulas .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
MathML has two types of encoding , content-based encoding which is called Content MathML , dealing with the meaning of formulas , and presentation-based encoding which is called Presentation MathML , dealing with the display of formulas .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
The illustration tree display of Presentation and Content Markup of the expression $ C_{-\frac{17}{2}}= \tilde {\infty} $ are depicted in Figure \REF and Figure \REF respectively .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
The illustration tree display of Presentation and Content Markup of the expression $ C_{-\frac{17}{2}}= \tilde {\infty} $ are depicted in Figure \REF and Figure \REF respectively .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
org Math \CITE , ASCIIMathML \CITE and OpenMath \CITE , but these markup can be converted to MathML using freely available tools .
#<struct ReadData::Alignment source_numbers="15,16", target_numbers="16,17", tag_name="wa">
org Math \CITE , ASCIIMathML \CITE and OpenMath \CITE , but these markup can be converted to MathML using freely available tools .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
org Math \CITE , ASCIIMathML \CITE and OpenMath \CITE , but these markup can be converted to MathML using freely available tools .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
In this section , we list some works that related to exploit the meaning of mathematical expressions .
#<struct ReadData::Alignment source_numbers="10,11", target_numbers="10,11", tag_name="wa">
In this section , we list some works that related to exploit the meaning of mathematical expressions .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
In this section , we list some works that related to exploit the meaning of mathematical expressions .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
In this section , we list some works that related to exploit the meaning of mathematical expressions .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
In this section , we list some works that related to exploit the meaning of mathematical expressions .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
For understanding mathematical expressions , Grigole et al. \CITE proposed an approach based on the surrounding text of mathematical expressions .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
For understanding mathematical expressions , Grigole et al. \CITE proposed an approach based on the surrounding text of mathematical expressions .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
For understanding mathematical expressions , Grigole et al. \CITE proposed an approach based on the surrounding text of mathematical expressions .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
The main idea of this approach is to use the surrounding text for disambiguation which is based on word sense disambiguation and lexical similarity .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
The main idea of this approach is to use the surrounding text for disambiguation which is based on word sense disambiguation and lexical similarity .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
The similarity scores obtained were weighted , summed up , and normalized by the length of the considered context .
#<struct ReadData::Alignment source_numbers="4", target_numbers="4", tag_name="wa">
The similarity scores obtained were weighted , summed up , and normalized by the length of the considered context .
#<struct ReadData::Alignment source_numbers="5", target_numbers="5", tag_name="wa">
The assigned interpretation is the Term Cluster with the highest similarity score .
#<struct ReadData::Alignment source_numbers="0", target_numbers="0", tag_name="wa">
The assigned interpretation is the Term Cluster with the highest similarity score .
#<struct ReadData::Alignment source_numbers="3", target_numbers="8", tag_name="wa">
The assigned interpretation is the Term Cluster with the highest similarity score .
#<struct ReadData::Alignment source_numbers="1", target_numbers="9", tag_name="wa">
The assigned interpretation is the Term Cluster with the highest similarity score .
#<struct ReadData::Alignment source_numbers="4", target_numbers="11", tag_name="wa">
The assigned interpretation is the Term Cluster with the highest similarity score .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
The approach was evaluated on 451 manually annotated mathematical expressions and the best result was 68.26 $ F_{0.5} $ score .
#<struct ReadData::Alignment source_numbers="18", target_numbers="18", tag_name="wa">
The approach was evaluated on 451 manually annotated mathematical expressions and the best result was 68.26 $ F_{0.5} $ score .
#<struct ReadData::Alignment source_numbers="16", target_numbers="22", tag_name="wa">
The approach was evaluated on 451 manually annotated mathematical expressions and the best result was 68.26 $ F_{0.5} $ score .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
To deal with the meanings of mathematical formulas , Nghiem et al. \CITE proposed an approach for extracting the names or descriptions of the formulas using natural language text surrounding them .
#<struct ReadData::Alignment source_numbers="18", target_numbers="25", tag_name="wa">
To deal with the meanings of mathematical formulas , Nghiem et al. \CITE proposed an approach for extracting the names or descriptions of the formulas using natural language text surrounding them .
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
This project investigates semantic enrichment , structural semantics and ambiguity resolution in mathematical corpora .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Unfortunately , there are no evaluation report on these systems .
#<struct ReadData::Alignment source_numbers="5", target_numbers="5", tag_name="wa">
Unfortunately , there are no evaluation report on these systems .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
Unfortunately , there are no evaluation report on these systems .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Unfortunately , there are no evaluation report on these systems .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
To translate mathematical expressions from the Presentation MathML to Content MathML format , a list of rules for translation is required .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
To translate mathematical expressions from the Presentation MathML to Content MathML format , a list of rules for translation is required .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Our task is inherently domain specific therefore we propose an approach which is based on statistical machine learning methods that automatically extract these rules from a dataset .
#<struct ReadData::Alignment source_numbers="21", target_numbers="19", tag_name="wa">
Our task is inherently domain specific therefore we propose an approach which is based on statistical machine learning methods that automatically extract these rules from a dataset .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
Our task is inherently domain specific therefore we propose an approach which is based on statistical machine learning methods that automatically extract these rules from a dataset .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Our task is inherently domain specific therefore we propose an approach which is based on statistical machine learning methods that automatically extract these rules from a dataset .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Our task is inherently domain specific therefore we propose an approach which is based on statistical machine learning methods that automatically extract these rules from a dataset .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
Our task is inherently domain specific therefore we propose an approach which is based on statistical machine learning methods that automatically extract these rules from a dataset .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
Our task is inherently domain specific therefore we propose an approach which is based on statistical machine learning methods that automatically extract these rules from a dataset .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
Our task is inherently domain specific therefore we propose an approach which is based on statistical machine learning methods that automatically extract these rules from a dataset .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
Our task is inherently domain specific therefore we propose an approach which is based on statistical machine learning methods that automatically extract these rules from a dataset .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Our task is inherently domain specific therefore we propose an approach which is based on statistical machine learning methods that automatically extract these rules from a dataset .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Our task is inherently domain specific therefore we propose an approach which is based on statistical machine learning methods that automatically extract these rules from a dataset .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Our task is inherently domain specific therefore we propose an approach which is based on statistical machine learning methods that automatically extract these rules from a dataset .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Our task is inherently domain specific therefore we propose an approach which is based on statistical machine learning methods that automatically extract these rules from a dataset .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Nowadays , statistical machine translation ( SMT ) is by far the most widely-studied machine translation method .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Nowadays , statistical machine translation ( SMT ) is by far the most widely-studied machine translation method .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Nowadays , statistical machine translation ( SMT ) is by far the most widely-studied machine translation method .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Nowadays , statistical machine translation ( SMT ) is by far the most widely-studied machine translation method .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
Nowadays , statistical machine translation ( SMT ) is by far the most widely-studied machine translation method .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Nowadays , statistical machine translation ( SMT ) is by far the most widely-studied machine translation method .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
Nowadays , statistical machine translation ( SMT ) is by far the most widely-studied machine translation method .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
SMT uses a very large data set of good translations , that is , a corpus of texts which have already been translated into other language , and then uses those texts to automatically infer a statistical model of translation .
#<struct ReadData::Alignment source_numbers="24,25", target_numbers="24,25", tag_name="wa">
SMT uses a very large data set of good translations , that is , a corpus of texts which have already been translated into other language , and then uses those texts to automatically infer a statistical model of translation .
#<struct ReadData::Alignment source_numbers="28", target_numbers="", tag_name="wa">
SMT uses a very large data set of good translations , that is , a corpus of texts which have already been translated into other language , and then uses those texts to automatically infer a statistical model of translation .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
The statistical model is then applied to new texts to make a translation .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
The statistical model is then applied to new texts to make a translation .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Tree-based or syntax-based SMT can be used for tree-to-tree translation but it has two drawbacks when apply to the problem of translating from Presentation to Content MathML expression .
#<struct ReadData::Alignment source_numbers="16", target_numbers="17,18", tag_name="wa">
Tree-based or syntax-based SMT can be used for tree-to-tree translation but it has two drawbacks when apply to the problem of translating from Presentation to Content MathML expression .
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
Tree-based or syntax-based SMT can be used for tree-to-tree translation but it has two drawbacks when apply to the problem of translating from Presentation to Content MathML expression .
#<struct ReadData::Alignment source_numbers="27", target_numbers="", tag_name="wa">
Tree-based or syntax-based SMT can be used for tree-to-tree translation but it has two drawbacks when apply to the problem of translating from Presentation to Content MathML expression .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
Tree-based or syntax-based SMT can be used for tree-to-tree translation but it has two drawbacks when apply to the problem of translating from Presentation to Content MathML expression .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
- The first drawback is tree-based SMT focus on generating the surface texts rather than the tree structures .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
While mathematical expressions have strict structures , it fails to fulfill this requirement .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
While mathematical expressions have strict structures , it fails to fulfill this requirement .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
While mathematical expressions have strict structures , it fails to fulfill this requirement .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
While mathematical expressions have strict structures , it fails to fulfill this requirement .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
- Preprocessing : processes MathML expressions to remove error expressions or format tags with no semantic meaning .
#<struct ReadData::Alignment source_numbers="7", target_numbers="9", tag_name="wa">
- Preprocessing : processes MathML expressions to remove error expressions or format tags with no semantic meaning .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
- Preprocessing : processes MathML expressions to remove error expressions or format tags with no semantic meaning .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
- Preprocessing : processes MathML expressions to remove error expressions or format tags with no semantic meaning .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
- Preprocessing : processes MathML expressions to remove error expressions or format tags with no semantic meaning .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
- Extracting Rules : given a dataset contains MathML parallel markup expressions , extract the rules for translation .
#<struct ReadData::Alignment source_numbers="2", target_numbers="1", tag_name="wa">
- Extracting Rules : given a dataset contains MathML parallel markup expressions , extract the rules for translation .
#<struct ReadData::Alignment source_numbers="4", target_numbers="7", tag_name="wa">
- Extracting Rules : given a dataset contains MathML parallel markup expressions , extract the rules for translation .
#<struct ReadData::Alignment source_numbers="18", target_numbers="23", tag_name="wa">
- Extracting Rules : given a dataset contains MathML parallel markup expressions , extract the rules for translation .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
- Extracting Rules : given a dataset contains MathML parallel markup expressions , extract the rules for translation .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
- Extracting Rules : given a dataset contains MathML parallel markup expressions , extract the rules for translation .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
- Extracting Rules : given a dataset contains MathML parallel markup expressions , extract the rules for translation .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
- Extracting Rules : given a dataset contains MathML parallel markup expressions , extract the rules for translation .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
- Extracting Rules : given a dataset contains MathML parallel markup expressions , extract the rules for translation .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
- Extracting Rules : given a dataset contains MathML parallel markup expressions , extract the rules for translation .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
- Extracting Rules : given a dataset contains MathML parallel markup expressions , extract the rules for translation .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
- Extracting Rules : given a dataset contains MathML parallel markup expressions , extract the rules for translation .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
- Extracting Rules : given a dataset contains MathML parallel markup expressions , extract the rules for translation .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
- Extracting Rules : given a dataset contains MathML parallel markup expressions , extract the rules for translation .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
- Extracting Rules : given a dataset contains MathML parallel markup expressions , extract the rules for translation .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
- Extracting Rules : given a dataset contains MathML parallel markup expressions , extract the rules for translation .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
- Extracting Rules : given a dataset contains MathML parallel markup expressions , extract the rules for translation .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
- Extracting Rules : given a dataset contains MathML parallel markup expressions , extract the rules for translation .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
- Extracting Rules : given a dataset contains MathML parallel markup expressions , extract the rules for translation .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
- Extracting Rules : given a dataset contains MathML parallel markup expressions , extract the rules for translation .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
- Extracting Rules : given a dataset contains MathML parallel markup expressions , extract the rules for translation .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
- Extracting Rules : given a dataset contains MathML parallel markup expressions , extract the rules for translation .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
- Extracting Rules : given a dataset contains MathML parallel markup expressions , extract the rules for translation .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
- Extracting Rules : given a dataset contains MathML parallel markup expressions , extract the rules for translation .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
- Extracting Rules : given a dataset contains MathML parallel markup expressions , extract the rules for translation .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
- Extracting Rules : given a dataset contains MathML parallel markup expressions , extract the rules for translation .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
- Extracting Rules : given a dataset contains MathML parallel markup expressions , extract the rules for translation .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
- Extracting Rules : given a dataset contains MathML parallel markup expressions , extract the rules for translation .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
- Extracting Rules : given a dataset contains MathML parallel markup expressions , extract the rules for translation .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
- Generating Content MathML : given a mathematical expressions in Presentation MathML markup , and a set of rules , generate Content MathML expressions to enrich the Presentation MathML expressions .
#<struct ReadData::Alignment source_numbers="5", target_numbers="8", tag_name="wa">
- Generating Content MathML : given a mathematical expressions in Presentation MathML markup , and a set of rules , generate Content MathML expressions to enrich the Presentation MathML expressions .
#<struct ReadData::Alignment source_numbers="20", target_numbers="23", tag_name="wa">
- Generating Content MathML : given a mathematical expressions in Presentation MathML markup , and a set of rules , generate Content MathML expressions to enrich the Presentation MathML expressions .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
- Generating Content MathML : given a mathematical expressions in Presentation MathML markup , and a set of rules , generate Content MathML expressions to enrich the Presentation MathML expressions .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
- Generating Content MathML : given a mathematical expressions in Presentation MathML markup , and a set of rules , generate Content MathML expressions to enrich the Presentation MathML expressions .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
- Generating Content MathML : given a mathematical expressions in Presentation MathML markup , and a set of rules , generate Content MathML expressions to enrich the Presentation MathML expressions .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
- Generating Content MathML : given a mathematical expressions in Presentation MathML markup , and a set of rules , generate Content MathML expressions to enrich the Presentation MathML expressions .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
- Generating Content MathML : given a mathematical expressions in Presentation MathML markup , and a set of rules , generate Content MathML expressions to enrich the Presentation MathML expressions .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
Token elements represent identifier 's names , function 's names , numbers , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
Token elements represent identifier 's names , function 's names , numbers , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
Token elements represent identifier 's names , function 's names , numbers , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Token elements represent identifier 's names , function 's names , numbers , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
Token elements represent identifier 's names , function 's names , numbers , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
Token elements represent identifier 's names , function 's names , numbers , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
Token elements represent identifier 's names , function 's names , numbers , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
Token elements represent identifier 's names , function 's names , numbers , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
Token elements represent identifier 's names , function 's names , numbers , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
Token elements represent identifier 's names , function 's names , numbers , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
Token elements represent identifier 's names , function 's names , numbers , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
Token elements represent identifier 's names , function 's names , numbers , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
Token elements represent identifier 's names , function 's names , numbers , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
Token elements represent identifier 's names , function 's names , numbers , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
Token elements represent identifier 's names , function 's names , numbers , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
Token elements represent identifier 's names , function 's names , numbers , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
Token elements represent identifier 's names , function 's names , numbers , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
Token elements represent identifier 's names , function 's names , numbers , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
Token elements represent identifier 's names , function 's names , numbers , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
Token elements represent identifier 's names , function 's names , numbers , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
Token elements represent identifier 's names , function 's names , numbers , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
Token elements represent identifier 's names , function 's names , numbers , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
Token elements represent identifier 's names , function 's names , numbers , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
Token elements represent identifier 's names , function 's names , numbers , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
Token elements represent identifier 's names , function 's names , numbers , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
Token elements represent identifier 's names , function 's names , numbers , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="40", tag_name="wa">
Token elements represent identifier 's names , function 's names , numbers , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="41", tag_name="wa">
Token elements represent identifier 's names , function 's names , numbers , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="42", tag_name="wa">
Token elements represent identifier 's names , function 's names , numbers , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="43", tag_name="wa">
Token elements represent identifier 's names , function 's names , numbers , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="44", tag_name="wa">
Token elements represent identifier 's names , function 's names , numbers , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="45", tag_name="wa">
Token elements represent identifier 's names , function 's names , numbers , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="46", tag_name="wa">
Token elements represent identifier 's names , function 's names , numbers , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="47", tag_name="wa">
Token elements represent identifier 's names , function 's names , numbers , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="48", tag_name="wa">
Token elements represent identifier 's names , function 's names , numbers , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="49", tag_name="wa">
Token elements represent identifier 's names , function 's names , numbers , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="50", tag_name="wa">
Token elements represent identifier 's names , function 's names , numbers , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="51", tag_name="wa">
Token elements represent identifier 's names , function 's names , numbers , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="52", tag_name="wa">
Token elements represent identifier 's names , function 's names , numbers , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="53", tag_name="wa">
Token elements represent identifier 's names , function 's names , numbers , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="54", tag_name="wa">
Token elements represent identifier 's names , function 's names , numbers , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="55", tag_name="wa">
Token elements represent identifier 's names , function 's names , numbers , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="56", tag_name="wa">
Token elements represent identifier 's names , function 's names , numbers , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="57", tag_name="wa">
Token elements represent identifier 's names , function 's names , numbers , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="58", tag_name="wa">
Token elements represent identifier 's names , function 's names , numbers , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="59", tag_name="wa">
Token elements represent identifier 's names , function 's names , numbers , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="60", tag_name="wa">
Token elements represent identifier 's names , function 's names , numbers , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="61", tag_name="wa">
Token elements represent identifier 's names , function 's names , numbers , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="62", tag_name="wa">
Token elements represent identifier 's names , function 's names , numbers , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="63", tag_name="wa">
Token elements represent identifier 's names , function 's names , numbers , etc.
#<struct ReadData::Alignment source_numbers="", target_numbers="64", tag_name="wa">
By investigating the data from the Wolfram Function Site , we noticed that there are elements that have no specific meaning , they are used for displaying purpose only and most of them are layout schemata .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
By investigating the data from the Wolfram Function Site , we noticed that there are elements that have no specific meaning , they are used for displaying purpose only and most of them are layout schemata .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
By investigating the data from the Wolfram Function Site , we noticed that there are elements that have no specific meaning , they are used for displaying purpose only and most of them are layout schemata .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
By investigating the data from the Wolfram Function Site , we noticed that there are elements that have no specific meaning , they are used for displaying purpose only and most of them are layout schemata .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
Another example are the pairs of parentheses , it is used to indicate that the expressions in the parentheses go together , while its structure already encoded that information .
#<struct ReadData::Alignment source_numbers="9", target_numbers="2", tag_name="wa">
Another example are the pairs of parentheses , it is used to indicate that the expressions in the parentheses go together , while its structure already encoded that information .
#<struct ReadData::Alignment source_numbers="2", target_numbers="8", tag_name="wa">
Another example are the pairs of parentheses , it is used to indicate that the expressions in the parentheses go together , while its structure already encoded that information .
#<struct ReadData::Alignment source_numbers="27", target_numbers="22", tag_name="wa">
Another example are the pairs of parentheses , it is used to indicate that the expressions in the parentheses go together , while its structure already encoded that information .
#<struct ReadData::Alignment source_numbers="23,24", target_numbers="23,24", tag_name="wa">
Another example are the pairs of parentheses , it is used to indicate that the expressions in the parentheses go together , while its structure already encoded that information .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Another example are the pairs of parentheses , it is used to indicate that the expressions in the parentheses go together , while its structure already encoded that information .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Another example are the pairs of parentheses , it is used to indicate that the expressions in the parentheses go together , while its structure already encoded that information .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
Another example are the pairs of parentheses , it is used to indicate that the expressions in the parentheses go together , while its structure already encoded that information .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Another example are the pairs of parentheses , it is used to indicate that the expressions in the parentheses go together , while its structure already encoded that information .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Another example are the pairs of parentheses , it is used to indicate that the expressions in the parentheses go together , while its structure already encoded that information .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
Another example are the pairs of parentheses , it is used to indicate that the expressions in the parentheses go together , while its structure already encoded that information .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
Another example are the pairs of parentheses , it is used to indicate that the expressions in the parentheses go together , while its structure already encoded that information .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
Another example are the pairs of parentheses , it is used to indicate that the expressions in the parentheses go together , while its structure already encoded that information .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
Another example are the pairs of parentheses , it is used to indicate that the expressions in the parentheses go together , while its structure already encoded that information .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
Another example are the pairs of parentheses , it is used to indicate that the expressions in the parentheses go together , while its structure already encoded that information .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
Another example are the pairs of parentheses , it is used to indicate that the expressions in the parentheses go together , while its structure already encoded that information .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
Another example are the pairs of parentheses , it is used to indicate that the expressions in the parentheses go together , while its structure already encoded that information .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
Another example are the pairs of parentheses , it is used to indicate that the expressions in the parentheses go together , while its structure already encoded that information .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
Another example are the pairs of parentheses , it is used to indicate that the expressions in the parentheses go together , while its structure already encoded that information .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
Another example are the pairs of parentheses , it is used to indicate that the expressions in the parentheses go together , while its structure already encoded that information .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
Another example are the pairs of parentheses , it is used to indicate that the expressions in the parentheses go together , while its structure already encoded that information .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
Another example are the pairs of parentheses , it is used to indicate that the expressions in the parentheses go together , while its structure already encoded that information .
#<struct ReadData::Alignment source_numbers="", target_numbers="40", tag_name="wa">
Another example are the pairs of parentheses , it is used to indicate that the expressions in the parentheses go together , while its structure already encoded that information .
#<struct ReadData::Alignment source_numbers="", target_numbers="41", tag_name="wa">
Another example are the pairs of parentheses , it is used to indicate that the expressions in the parentheses go together , while its structure already encoded that information .
#<struct ReadData::Alignment source_numbers="", target_numbers="42", tag_name="wa">
Another example are the pairs of parentheses , it is used to indicate that the expressions in the parentheses go together , while its structure already encoded that information .
#<struct ReadData::Alignment source_numbers="", target_numbers="43", tag_name="wa">
As a result , in this preprocessing step , these elements are removed .
#<struct ReadData::Alignment source_numbers="13", target_numbers="6", tag_name="wa">
As a result , in this preprocessing step , these elements are removed .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
As a result , in this preprocessing step , these elements are removed .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
As a result , in this preprocessing step , these elements are removed .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
As a result , in this preprocessing step , these elements are removed .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
As a result , in this preprocessing step , these elements are removed .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
As a result , in this preprocessing step , these elements are removed .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
As a result , in this preprocessing step , these elements are removed .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
As a result , in this preprocessing step , these elements are removed .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
As a result , in this preprocessing step , these elements are removed .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
As a result , in this preprocessing step , these elements are removed .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
As a result , in this preprocessing step , these elements are removed .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
In this step , we also removed mathematical expressions with error markups such as expressions that have no Content markup .
#<struct ReadData::Alignment source_numbers="20", target_numbers="16", tag_name="wa">
In this step , we also removed mathematical expressions with error markups such as expressions that have no Content markup .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
In this step , we also removed mathematical expressions with error markups such as expressions that have no Content markup .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
In this step , we also removed mathematical expressions with error markups such as expressions that have no Content markup .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
In this step , we also removed mathematical expressions with error markups such as expressions that have no Content markup .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
In this step , we also removed mathematical expressions with error markups such as expressions that have no Content markup .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
In this step , we also removed mathematical expressions with error markups such as expressions that have no Content markup .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
For simplification , expressions with more than 200 content nodes also be removed .
#<struct ReadData::Alignment source_numbers="10,11", target_numbers="10,11", tag_name="wa">
For simplification , expressions with more than 200 content nodes also be removed .
#<struct ReadData::Alignment source_numbers="12", target_numbers="12", tag_name="wa">
Based on the aligned data , we use some heuristics to extract rules which we called " fragment rules " .
#<struct ReadData::Alignment source_numbers="12,13", target_numbers="11,12", tag_name="wa">
Based on the aligned data , we use some heuristics to extract rules which we called " fragment rules " .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
These rules are applied to break the large Presentation MathML tree into smaller sub-trees while maintaining the structure of output Content MathML trees .
#<struct ReadData::Alignment source_numbers="6", target_numbers="20", tag_name="wa">
Each rule in fragment rule set is associated with its probability , that is the frequent that rule happened in the training data .
#<struct ReadData::Alignment source_numbers="14", target_numbers="3", tag_name="wa">
Each rule in fragment rule set is associated with its probability , that is the frequent that rule happened in the training data .
#<struct ReadData::Alignment source_numbers="20", target_numbers="16", tag_name="wa">
Each rule in fragment rule set is associated with its probability , that is the frequent that rule happened in the training data .
#<struct ReadData::Alignment source_numbers="23", target_numbers="27", tag_name="wa">
Each rule in fragment rule set is associated with its probability , that is the frequent that rule happened in the training data .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Each rule in fragment rule set is associated with its probability , that is the frequent that rule happened in the training data .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
Each rule in fragment rule set is associated with its probability , that is the frequent that rule happened in the training data .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
Each rule in fragment rule set is associated with its probability , that is the frequent that rule happened in the training data .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Each rule in fragment rule set is associated with its probability , that is the frequent that rule happened in the training data .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
Each rule in fragment rule set is associated with its probability , that is the frequent that rule happened in the training data .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Each rule in fragment rule set is associated with its probability , that is the frequent that rule happened in the training data .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
Each rule in fragment rule set is associated with its probability , that is the frequent that rule happened in the training data .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
Each rule in fragment rule set is associated with its probability , that is the frequent that rule happened in the training data .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
If the sub-trees can not be broken any longer , we extract another rules , which we called " translation rules " , at that point .
#<struct ReadData::Alignment source_numbers="11", target_numbers="12", tag_name="wa">
If the sub-trees can not be broken any longer , we extract another rules , which we called " translation rules " , at that point .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
If the sub-trees can not be broken any longer , we extract another rules , which we called " translation rules " , at that point .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
If the sub-trees can not be broken any longer , we extract another rules , which we called " translation rules " , at that point .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
If the sub-trees can not be broken any longer , we extract another rules , which we called " translation rules " , at that point .
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
If the sub-trees can not be broken any longer , we extract another rules , which we called " translation rules " , at that point .
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
If the sub-trees can not be broken any longer , we extract another rules , which we called " translation rules " , at that point .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
If the sub-trees can not be broken any longer , we extract another rules , which we called " translation rules " , at that point .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
If the sub-trees can not be broken any longer , we extract another rules , which we called " translation rules " , at that point .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
If the sub-trees can not be broken any longer , we extract another rules , which we called " translation rules " , at that point .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
If the sub-trees can not be broken any longer , we extract another rules , which we called " translation rules " , at that point .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
We then enhances the translation rule set with the translation terms extracted by GIZA++ .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
The pseudo code of the algorithm for extracting fragment rules is described in Algorithm \REF .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
The pseudo code of the algorithm for extracting fragment rules is described in Algorithm \REF .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
The pseudo code of the algorithm for extracting fragment rules is described in Algorithm \REF .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Given a mathematical expressions in Presentation MathML markup , the system will generate Content MathML markup of that expression .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
Given a mathematical expressions in Presentation MathML markup , the system will generate Content MathML markup of that expression .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
Given a mathematical expressions in Presentation MathML markup , the system will generate Content MathML markup of that expression .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
Given a mathematical expressions in Presentation MathML markup , the system will generate Content MathML markup of that expression .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
- First , the expression is preprocess to remove non semantic elements .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
- First , the expression is preprocess to remove non semantic elements .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
- First , the expression is preprocess to remove non semantic elements .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
The reason for this is that there is infinite number and we could never present every number in the rule .
#<struct ReadData::Alignment source_numbers="20", target_numbers="13", tag_name="wa">
The reason for this is that there is infinite number and we could never present every number in the rule .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
The reason for this is that there is infinite number and we could never present every number in the rule .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
The reason for this is that there is infinite number and we could never present every number in the rule .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
The reason for this is that there is infinite number and we could never present every number in the rule .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
The reason for this is that there is infinite number and we could never present every number in the rule .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
The reason for this is that there is infinite number and we could never present every number in the rule .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
The reason for this is that there is infinite number and we could never present every number in the rule .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
The reason for this is that there is infinite number and we could never present every number in the rule .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
The reason for this is that there is infinite number and we could never present every number in the rule .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
The reason for this is that there is infinite number and we could never present every number in the rule .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
The reason for this is that there is infinite number and we could never present every number in the rule .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
The reason for this is that there is infinite number and we could never present every number in the rule .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
The reason for this is that there is infinite number and we could never present every number in the rule .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
The reason for this is that there is infinite number and we could never present every number in the rule .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
The reason for this is that there is infinite number and we could never present every number in the rule .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
The reason for this is that there is infinite number and we could never present every number in the rule .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
The reason for this is that there is infinite number and we could never present every number in the rule .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
The experiments were carried out using the datasets from the Wolfram Function site .
#<struct ReadData::Alignment source_numbers="9", target_numbers="8", tag_name="wa">
The experiments were carried out using the datasets from the Wolfram Function site .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
These datasets we used contain 205 , 653 mathematical expressions belong to 6 categories .
#<struct ReadData::Alignment source_numbers="10,11", target_numbers="10,11", tag_name="wa">
These datasets we used contain 205 , 653 mathematical expressions belong to 6 categories .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
These datasets we used contain 205 , 653 mathematical expressions belong to 6 categories .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Training and testing were performed using 10-fold cross-validation ; for each category , the original corpus is partitioned into 10 subsets .
#<struct ReadData::Alignment source_numbers="16", target_numbers="16", tag_name="wa">
Training and testing were performed using 10-fold cross-validation ; for each category , the original corpus is partitioned into 10 subsets .
#<struct ReadData::Alignment source_numbers="17", target_numbers="17", tag_name="wa">
Training and testing were performed using 10-fold cross-validation ; for each category , the original corpus is partitioned into 10 subsets .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
Training and testing were performed using 10-fold cross-validation ; for each category , the original corpus is partitioned into 10 subsets .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Of the 10 subsets , a single subset is retained as the validation data for testing the model , and the remaining subsets are used as training data .
#<struct ReadData::Alignment source_numbers="20", target_numbers="1", tag_name="wa">
Of the 10 subsets , a single subset is retained as the validation data for testing the model , and the remaining subsets are used as training data .
#<struct ReadData::Alignment source_numbers="1,2", target_numbers="2", tag_name="wa">
Of the 10 subsets , a single subset is retained as the validation data for testing the model , and the remaining subsets are used as training data .
#<struct ReadData::Alignment source_numbers="23,24", target_numbers="23,24", tag_name="wa">
Of the 10 subsets , a single subset is retained as the validation data for testing the model , and the remaining subsets are used as training data .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
The cross-validation process is then repeated 10 times , with each of the 10 subsets used exactly once as the validation data .
#<struct ReadData::Alignment source_numbers="3", target_numbers="3", tag_name="wa">
The cross-validation process is then repeated 10 times , with each of the 10 subsets used exactly once as the validation data .
#<struct ReadData::Alignment source_numbers="5", target_numbers="4", tag_name="wa">
The cross-validation process is then repeated 10 times , with each of the 10 subsets used exactly once as the validation data .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
To prove the effectiveness of our models to real data , we conducted another experiment on the mathematical expressions in scientific papers .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
To prove the effectiveness of our models to real data , we conducted another experiment on the mathematical expressions in scientific papers .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Currently we have 20 papers from ACL archive , all of the math expressions in these papers are annotated manually with both Presentation Markup and Content Markup .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
Currently we have 20 papers from ACL archive , all of the math expressions in these papers are annotated manually with both Presentation Markup and Content Markup .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Currently we have 20 papers from ACL archive , all of the math expressions in these papers are annotated manually with both Presentation Markup and Content Markup .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
Currently we have 20 papers from ACL archive , all of the math expressions in these papers are annotated manually with both Presentation Markup and Content Markup .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
Currently we have 20 papers from ACL archive , all of the math expressions in these papers are annotated manually with both Presentation Markup and Content Markup .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
Currently we have 20 papers from ACL archive , all of the math expressions in these papers are annotated manually with both Presentation Markup and Content Markup .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
Currently we have 20 papers from ACL archive , all of the math expressions in these papers are annotated manually with both Presentation Markup and Content Markup .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
Currently we have 20 papers from ACL archive , all of the math expressions in these papers are annotated manually with both Presentation Markup and Content Markup .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
Currently we have 20 papers from ACL archive , all of the math expressions in these papers are annotated manually with both Presentation Markup and Content Markup .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
Currently we have 20 papers from ACL archive , all of the math expressions in these papers are annotated manually with both Presentation Markup and Content Markup .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
Currently we have 20 papers from ACL archive , all of the math expressions in these papers are annotated manually with both Presentation Markup and Content Markup .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
Currently we have 20 papers from ACL archive , all of the math expressions in these papers are annotated manually with both Presentation Markup and Content Markup .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
Currently we have 20 papers from ACL archive , all of the math expressions in these papers are annotated manually with both Presentation Markup and Content Markup .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
Currently we have 20 papers from ACL archive , all of the math expressions in these papers are annotated manually with both Presentation Markup and Content Markup .
#<struct ReadData::Alignment source_numbers="", target_numbers="40", tag_name="wa">
Currently we have 20 papers from ACL archive , all of the math expressions in these papers are annotated manually with both Presentation Markup and Content Markup .
#<struct ReadData::Alignment source_numbers="", target_numbers="41", tag_name="wa">
Currently we have 20 papers from ACL archive , all of the math expressions in these papers are annotated manually with both Presentation Markup and Content Markup .
#<struct ReadData::Alignment source_numbers="", target_numbers="42", tag_name="wa">
Currently we have 20 papers from ACL archive , all of the math expressions in these papers are annotated manually with both Presentation Markup and Content Markup .
#<struct ReadData::Alignment source_numbers="", target_numbers="43", tag_name="wa">
Currently we have 20 papers from ACL archive , all of the math expressions in these papers are annotated manually with both Presentation Markup and Content Markup .
#<struct ReadData::Alignment source_numbers="", target_numbers="44", tag_name="wa">
Currently we have 20 papers from ACL archive , all of the math expressions in these papers are annotated manually with both Presentation Markup and Content Markup .
#<struct ReadData::Alignment source_numbers="", target_numbers="45", tag_name="wa">
Currently we have 20 papers from ACL archive , all of the math expressions in these papers are annotated manually with both Presentation Markup and Content Markup .
#<struct ReadData::Alignment source_numbers="", target_numbers="46", tag_name="wa">
Currently we have 20 papers from ACL archive , all of the math expressions in these papers are annotated manually with both Presentation Markup and Content Markup .
#<struct ReadData::Alignment source_numbers="", target_numbers="47", tag_name="wa">
Currently we have 20 papers from ACL archive , all of the math expressions in these papers are annotated manually with both Presentation Markup and Content Markup .
#<struct ReadData::Alignment source_numbers="", target_numbers="48", tag_name="wa">
Currently we have 20 papers from ACL archive , all of the math expressions in these papers are annotated manually with both Presentation Markup and Content Markup .
#<struct ReadData::Alignment source_numbers="", target_numbers="49", tag_name="wa">
Currently we have 20 papers from ACL archive , all of the math expressions in these papers are annotated manually with both Presentation Markup and Content Markup .
#<struct ReadData::Alignment source_numbers="", target_numbers="50", tag_name="wa">
Currently we have 20 papers from ACL archive , all of the math expressions in these papers are annotated manually with both Presentation Markup and Content Markup .
#<struct ReadData::Alignment source_numbers="", target_numbers="51", tag_name="wa">
Currently we have 20 papers from ACL archive , all of the math expressions in these papers are annotated manually with both Presentation Markup and Content Markup .
#<struct ReadData::Alignment source_numbers="", target_numbers="52", tag_name="wa">
In the first experiment , the data is not compatible with SnuggleTeX since SnuggleTeX use ASCII MathML while the Wolfram Functions site does not .
#<struct ReadData::Alignment source_numbers="7,8", target_numbers="7,8", tag_name="wa">
In the first experiment , the data is not compatible with SnuggleTeX since SnuggleTeX use ASCII MathML while the Wolfram Functions site does not .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
In the first experiment , the data is not compatible with SnuggleTeX since SnuggleTeX use ASCII MathML while the Wolfram Functions site does not .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
In the second experiment with ACL-ARC data , we compared our model side by side with SnuggleTeX .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
In the second experiment with ACL-ARC data , we compared our model side by side with SnuggleTeX .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
In the second experiment with ACL-ARC data , we compared our model side by side with SnuggleTeX .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
Table \REF contains the various data statistics .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Table \REF contains the various data statistics .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Given a Presentation MathML expression $ e $ , we assume that tree $ A $ is the correct Content MathML tree of expression $ e $ and tree $ B $ is the output using the automatic translation .
#<struct ReadData::Alignment source_numbers="35", target_numbers="", tag_name="wa">
Given a Presentation MathML expression $ e $ , we assume that tree $ A $ is the correct Content MathML tree of expression $ e $ and tree $ B $ is the output using the automatic translation .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
In the experiments , we extend the conventional definition of " Translation Error Rate " and use a metric which is the combined version of
#<struct ReadData::Alignment source_numbers="20,21", target_numbers="20,21", tag_name="wa">
- Translation Error Rate \CITE : translation error rate is an error metric for machine translation that measures the number of edits required to change a system output into one of the references .
#<struct ReadData::Alignment source_numbers="31", target_numbers="1", tag_name="wa">
- Translation Error Rate \CITE : translation error rate is an error metric for machine translation that measures the number of edits required to change a system output into one of the references .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
TEDR is defined as the rate between ( 1 ) the minimal cost to transform a tree A into another tree B using edit operations and ( 2 ) the maximum number of nodes of A and B .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
TEDR is defined as the rate between ( 1 ) the minimal cost to transform a tree A into another tree B using edit operations and ( 2 ) the maximum number of nodes of A and B .
#<struct ReadData::Alignment source_numbers="", target_numbers="40", tag_name="wa">
TEDR is defined as the rate between ( 1 ) the minimal cost to transform a tree A into another tree B using edit operations and ( 2 ) the maximum number of nodes of A and B .
#<struct ReadData::Alignment source_numbers="", target_numbers="41", tag_name="wa">
TEDR is defined as the rate between ( 1 ) the minimal cost to transform a tree A into another tree B using edit operations and ( 2 ) the maximum number of nodes of A and B .
#<struct ReadData::Alignment source_numbers="", target_numbers="42", tag_name="wa">
TEDR is defined as the rate between ( 1 ) the minimal cost to transform a tree A into another tree B using edit operations and ( 2 ) the maximum number of nodes of A and B .
#<struct ReadData::Alignment source_numbers="", target_numbers="43", tag_name="wa">
TEDR is defined as the rate between ( 1 ) the minimal cost to transform a tree A into another tree B using edit operations and ( 2 ) the maximum number of nodes of A and B .
#<struct ReadData::Alignment source_numbers="", target_numbers="44", tag_name="wa">
TEDR is defined as the rate between ( 1 ) the minimal cost to transform a tree A into another tree B using edit operations and ( 2 ) the maximum number of nodes of A and B .
#<struct ReadData::Alignment source_numbers="", target_numbers="45", tag_name="wa">
TEDR is defined as the rate between ( 1 ) the minimal cost to transform a tree A into another tree B using edit operations and ( 2 ) the maximum number of nodes of A and B .
#<struct ReadData::Alignment source_numbers="", target_numbers="46", tag_name="wa">
TEDR is defined as the rate between ( 1 ) the minimal cost to transform a tree A into another tree B using edit operations and ( 2 ) the maximum number of nodes of A and B .
#<struct ReadData::Alignment source_numbers="", target_numbers="47", tag_name="wa">
TEDR is defined as the rate between ( 1 ) the minimal cost to transform a tree A into another tree B using edit operations and ( 2 ) the maximum number of nodes of A and B .
#<struct ReadData::Alignment source_numbers="", target_numbers="48", tag_name="wa">
TEDR is defined as the rate between ( 1 ) the minimal cost to transform a tree A into another tree B using edit operations and ( 2 ) the maximum number of nodes of A and B .
#<struct ReadData::Alignment source_numbers="", target_numbers="49", tag_name="wa">
TEDR is defined as the rate between ( 1 ) the minimal cost to transform a tree A into another tree B using edit operations and ( 2 ) the maximum number of nodes of A and B .
#<struct ReadData::Alignment source_numbers="", target_numbers="50", tag_name="wa">
TEDR is defined as the rate between ( 1 ) the minimal cost to transform a tree A into another tree B using edit operations and ( 2 ) the maximum number of nodes of A and B .
#<struct ReadData::Alignment source_numbers="", target_numbers="51", tag_name="wa">
TEDR is defined as the rate between ( 1 ) the minimal cost to transform a tree A into another tree B using edit operations and ( 2 ) the maximum number of nodes of A and B .
#<struct ReadData::Alignment source_numbers="", target_numbers="52", tag_name="wa">
TEDR is defined as the rate between ( 1 ) the minimal cost to transform a tree A into another tree B using edit operations and ( 2 ) the maximum number of nodes of A and B .
#<struct ReadData::Alignment source_numbers="", target_numbers="53", tag_name="wa">
TEDR is defined as the rate between ( 1 ) the minimal cost to transform a tree A into another tree B using edit operations and ( 2 ) the maximum number of nodes of A and B .
#<struct ReadData::Alignment source_numbers="", target_numbers="54", tag_name="wa">
TEDR is defined as the rate between ( 1 ) the minimal cost to transform a tree A into another tree B using edit operations and ( 2 ) the maximum number of nodes of A and B .
#<struct ReadData::Alignment source_numbers="", target_numbers="55", tag_name="wa">
TEDR is defined as the rate between ( 1 ) the minimal cost to transform a tree A into another tree B using edit operations and ( 2 ) the maximum number of nodes of A and B .
#<struct ReadData::Alignment source_numbers="", target_numbers="56", tag_name="wa">
TEDR is defined as the rate between ( 1 ) the minimal cost to transform a tree A into another tree B using edit operations and ( 2 ) the maximum number of nodes of A and B .
#<struct ReadData::Alignment source_numbers="", target_numbers="57", tag_name="wa">
TEDR is defined as the rate between ( 1 ) the minimal cost to transform a tree A into another tree B using edit operations and ( 2 ) the maximum number of nodes of A and B .
#<struct ReadData::Alignment source_numbers="", target_numbers="58", tag_name="wa">
TEDR is defined as the rate between ( 1 ) the minimal cost to transform a tree A into another tree B using edit operations and ( 2 ) the maximum number of nodes of A and B .
#<struct ReadData::Alignment source_numbers="", target_numbers="59", tag_name="wa">
Compare to the reference tree in Figure \REF , we need to substituting X node , inserting Y node , and deleting Z node , so that $ TED( A , B ) = x $ . While the maximum number of node of two trees is y .
#<struct ReadData::Alignment source_numbers="0", target_numbers="0", tag_name="wa">
Compare to the reference tree in Figure \REF , we need to substituting X node , inserting Y node , and deleting Z node , so that $ TED( A , B ) = x $ . While the maximum number of node of two trees is y .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Compare to the reference tree in Figure \REF , we need to substituting X node , inserting Y node , and deleting Z node , so that $ TED( A , B ) = x $ . While the maximum number of node of two trees is y .
#<struct ReadData::Alignment source_numbers="36", target_numbers="", tag_name="wa">
Compare to the reference tree in Figure \REF , we need to substituting X node , inserting Y node , and deleting Z node , so that $ TED( A , B ) = x $ . While the maximum number of node of two trees is y .
#<struct ReadData::Alignment source_numbers="37", target_numbers="", tag_name="wa">
Compare to the reference tree in Figure \REF , we need to substituting X node , inserting Y node , and deleting Z node , so that $ TED( A , B ) = x $ . While the maximum number of node of two trees is y .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Compare to the reference tree in Figure \REF , we need to substituting X node , inserting Y node , and deleting Z node , so that $ TED( A , B ) = x $ . While the maximum number of node of two trees is y .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
Compare to the reference tree in Figure \REF , we need to substituting X node , inserting Y node , and deleting Z node , so that $ TED( A , B ) = x $ . While the maximum number of node of two trees is y .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
For the data in Wolfram Function site , it appeared that SnuggleTeX is not applicable to this data since SnuggleTeX use ASCII MathML while the Wolfram Functions site does not .
#<struct ReadData::Alignment source_numbers="1", target_numbers="8", tag_name="wa">
For the data in Wolfram Function site , it appeared that SnuggleTeX is not applicable to this data since SnuggleTeX use ASCII MathML while the Wolfram Functions site does not .
#<struct ReadData::Alignment source_numbers="2", target_numbers="9", tag_name="wa">
For the data in Wolfram Function site , it appeared that SnuggleTeX is not applicable to this data since SnuggleTeX use ASCII MathML while the Wolfram Functions site does not .
#<struct ReadData::Alignment source_numbers="24", target_numbers="11", tag_name="wa">
For the data in Wolfram Function site , it appeared that SnuggleTeX is not applicable to this data since SnuggleTeX use ASCII MathML while the Wolfram Functions site does not .
#<struct ReadData::Alignment source_numbers="8", target_numbers="16", tag_name="wa">
For the data in Wolfram Function site , it appeared that SnuggleTeX is not applicable to this data since SnuggleTeX use ASCII MathML while the Wolfram Functions site does not .
#<struct ReadData::Alignment source_numbers="27", target_numbers="22", tag_name="wa">
For the data in Wolfram Function site , it appeared that SnuggleTeX is not applicable to this data since SnuggleTeX use ASCII MathML while the Wolfram Functions site does not .
#<struct ReadData::Alignment source_numbers="30", target_numbers="25", tag_name="wa">
For the data in Wolfram Function site , it appeared that SnuggleTeX is not applicable to this data since SnuggleTeX use ASCII MathML while the Wolfram Functions site does not .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
For the data in Wolfram Function site , it appeared that SnuggleTeX is not applicable to this data since SnuggleTeX use ASCII MathML while the Wolfram Functions site does not .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
For the data in Wolfram Function site , it appeared that SnuggleTeX is not applicable to this data since SnuggleTeX use ASCII MathML while the Wolfram Functions site does not .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
For the data in Wolfram Function site , it appeared that SnuggleTeX is not applicable to this data since SnuggleTeX use ASCII MathML while the Wolfram Functions site does not .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
For the data in Wolfram Function site , it appeared that SnuggleTeX is not applicable to this data since SnuggleTeX use ASCII MathML while the Wolfram Functions site does not .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
For the data in Wolfram Function site , it appeared that SnuggleTeX is not applicable to this data since SnuggleTeX use ASCII MathML while the Wolfram Functions site does not .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
For the data in Wolfram Function site , it appeared that SnuggleTeX is not applicable to this data since SnuggleTeX use ASCII MathML while the Wolfram Functions site does not .
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
For the data in Wolfram Function site , it appeared that SnuggleTeX is not applicable to this data since SnuggleTeX use ASCII MathML while the Wolfram Functions site does not .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
For the data in Wolfram Function site , it appeared that SnuggleTeX is not applicable to this data since SnuggleTeX use ASCII MathML while the Wolfram Functions site does not .
#<struct ReadData::Alignment source_numbers="26", target_numbers="", tag_name="wa">
For the data in Wolfram Function site , it appeared that SnuggleTeX is not applicable to this data since SnuggleTeX use ASCII MathML while the Wolfram Functions site does not .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
For the data in Wolfram Function site , it appeared that SnuggleTeX is not applicable to this data since SnuggleTeX use ASCII MathML while the Wolfram Functions site does not .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
For the data in Wolfram Function site , it appeared that SnuggleTeX is not applicable to this data since SnuggleTeX use ASCII MathML while the Wolfram Functions site does not .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
For the data in Wolfram Function site , it appeared that SnuggleTeX is not applicable to this data since SnuggleTeX use ASCII MathML while the Wolfram Functions site does not .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
Therefore we could not do the side-by-side comparison on this data .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Therefore we could not do the side-by-side comparison on this data .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
Therefore we could not do the side-by-side comparison on this data .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Therefore we could not do the side-by-side comparison on this data .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Our experimental results show that our approach can archive reasonable results , that is 20 percent TEDR with large training data .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Our experimental results show that our approach can archive reasonable results , that is 20 percent TEDR with large training data .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Our experimental results show that our approach can archive reasonable results , that is 20 percent TEDR with large training data .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Our experimental results show that our approach can archive reasonable results , that is 20 percent TEDR with large training data .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
For small data which has less than 3000 training samples , the results vary from 50 to 75 percent TEDR .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
For small data which has less than 3000 training samples , the results vary from 50 to 75 percent TEDR .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
For small data which has less than 3000 training samples , the results vary from 50 to 75 percent TEDR .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
For small data which has less than 3000 training samples , the results vary from 50 to 75 percent TEDR .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
For ACL-ARC data , the experimental results from our side-by-side comparison show that our system significantly outperforms SnuggleTeX in terms of Tree Edit Distance Rate .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
For ACL-ARC data , the experimental results from our side-by-side comparison show that our system significantly outperforms SnuggleTeX in terms of Tree Edit Distance Rate .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
For ACL-ARC data , the experimental results from our side-by-side comparison show that our system significantly outperforms SnuggleTeX in terms of Tree Edit Distance Rate .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Our system archived 24 percent TEDR less than the output using SnuggleTeX .
#<struct ReadData::Alignment source_numbers="6", target_numbers="6", tag_name="wa">
Our system archived 24 percent TEDR less than the output using SnuggleTeX .
#<struct ReadData::Alignment source_numbers="7", target_numbers="9,10", tag_name="wa">
Our system archived 24 percent TEDR less than the output using SnuggleTeX .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Our system archived 24 percent TEDR less than the output using SnuggleTeX .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Our system archived 24 percent TEDR less than the output using SnuggleTeX .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Our system archived 24 percent TEDR less than the output using SnuggleTeX .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Our system archived 24 percent TEDR less than the output using SnuggleTeX .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Our system archived 24 percent TEDR less than the output using SnuggleTeX .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
To find out the correlation between TEDR score and training set size , we set up an experiment using mathematical expressions in Elementary Functions category .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
To find out the correlation between TEDR score and training set size , we set up an experiment using mathematical expressions in Elementary Functions category .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
To find out the correlation between TEDR score and training set size , we set up an experiment using mathematical expressions in Elementary Functions category .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
We started with one fifth of the data , and then increase data one fifth each run .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
We started with one fifth of the data , and then increase data one fifth each run .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
We started with one fifth of the data , and then increase data one fifth each run .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
We started with one fifth of the data , and then increase data one fifth each run .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Table \REF and Table \REF show the TEDR of our proposed method on the Wolfram Functions Site data and in comparison with SnuggleTeX on ACL ARC data , respectively .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
In this paper , we discussed the problem of the semantic enrichment of mathematical expressions .
#<struct ReadData::Alignment source_numbers="15", target_numbers="10", tag_name="wa">
In this paper , we discussed the problem of the semantic enrichment of mathematical expressions .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
In this paper , we discussed the problem of the semantic enrichment of mathematical expressions .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
In this paper , we discussed the problem of the semantic enrichment of mathematical expressions .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
In this paper , we discussed the problem of the semantic enrichment of mathematical expressions .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
In this paper , we discussed the problem of the semantic enrichment of mathematical expressions .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
In this paper , we discussed the problem of the semantic enrichment of mathematical expressions .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Our experimental results show that our approach based on the statistical machine translation method for translating a Presentation MathML expression to a Content MathML expression has the significant improvement over a prior system .
#<struct ReadData::Alignment source_numbers="25,26", target_numbers="24", tag_name="wa">
Our experimental results show that our approach based on the statistical machine translation method for translating a Presentation MathML expression to a Content MathML expression has the significant improvement over a prior system .
#<struct ReadData::Alignment source_numbers="21", target_numbers="25", tag_name="wa">
Our experimental results show that our approach based on the statistical machine translation method for translating a Presentation MathML expression to a Content MathML expression has the significant improvement over a prior system .
#<struct ReadData::Alignment source_numbers="32", target_numbers="30", tag_name="wa">
Our experimental results show that our approach based on the statistical machine translation method for translating a Presentation MathML expression to a Content MathML expression has the significant improvement over a prior system .
#<struct ReadData::Alignment source_numbers="30", target_numbers="", tag_name="wa">
In the scope of this paper , we only consider the first context information .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
In the scope of this paper , we only consider the first context information .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
- Expanding the work by incorporating the surrounding information of mathematical expressions , for example definitions or other mathematical expressions .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
By combining the automatic extraction of fragment rules and translation rules , our approach has shown promising results .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
By combining the automatic extraction of fragment rules and translation rules , our approach has shown promising results .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
By combining the automatic extraction of fragment rules and translation rules , our approach has shown promising results .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
The experimental results confirm that this approach is helpful to the understanding of mathematical expressions .
#<struct ReadData::Alignment source_numbers="7", target_numbers="6,7", tag_name="wa">
The experimental results confirm that this approach is helpful to the understanding of mathematical expressions .
#<struct ReadData::Alignment source_numbers="8,9", target_numbers="8,9", tag_name="wa">
The experimental results confirm that this approach is helpful to the understanding of mathematical expressions .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
The experimental results confirm that this approach is helpful to the understanding of mathematical expressions .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
The experimental results confirm that this approach is helpful to the understanding of mathematical expressions .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
The experimental results confirm that this approach is helpful to the understanding of mathematical expressions .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Currently , our system deals only with a sub-part of mathematical notations .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Currently , our system deals only with a sub-part of mathematical notations .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Currently , our system deals only with a sub-part of mathematical notations .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Currently , our system deals only with a sub-part of mathematical notations .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
In future work , we should also consider expanding it to cover all mathematical notations .
#<struct ReadData::Alignment source_numbers="0", target_numbers="0", tag_name="wa">
In future work , we should also consider expanding it to cover all mathematical notations .
#<struct ReadData::Alignment source_numbers="1", target_numbers="2", tag_name="wa">
In future work , we should also consider expanding it to cover all mathematical notations .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
In future work , we should also consider expanding it to cover all mathematical notations .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
In future work , we should also consider expanding it to cover all mathematical notations .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Recent research shows a major part of difficult cases in event extraction for the biomedical domain are related to coreference .
#<struct ReadData::Alignment source_numbers="4", target_numbers="5", tag_name="wa">
Recent research shows a major part of difficult cases in event extraction for the biomedical domain are related to coreference .
#<struct ReadData::Alignment source_numbers="6,7", target_numbers="6", tag_name="wa">
Recent research shows a major part of difficult cases in event extraction for the biomedical domain are related to coreference .
#<struct ReadData::Alignment source_numbers="8", target_numbers="10", tag_name="wa">
Recent research shows a major part of difficult cases in event extraction for the biomedical domain are related to coreference .
#<struct ReadData::Alignment source_numbers="20", target_numbers="19", tag_name="wa">
Recent research shows a major part of difficult cases in event extraction for the biomedical domain are related to coreference .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Recent research shows a major part of difficult cases in event extraction for the biomedical domain are related to coreference .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
Recent research shows a major part of difficult cases in event extraction for the biomedical domain are related to coreference .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Recent research shows a major part of difficult cases in event extraction for the biomedical domain are related to coreference .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Recent research shows a major part of difficult cases in event extraction for the biomedical domain are related to coreference .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
To address the problem of coreference resolution in molecular biology literature , the Protein Coreference ( COREF ) task was arranged in the BioNLP-ST 2011 as a supporting task .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
To address the problem of coreference resolution in molecular biology literature , the Protein Coreference ( COREF ) task was arranged in the BioNLP-ST 2011 as a supporting task .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
To address the problem of coreference resolution in molecular biology literature , the Protein Coreference ( COREF ) task was arranged in the BioNLP-ST 2011 as a supporting task .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
To address the problem of coreference resolution in molecular biology literature , the Protein Coreference ( COREF ) task was arranged in the BioNLP-ST 2011 as a supporting task .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
However , the shared task results showed that transferring coreference resolution methods developed for other domains to the biological domain was not straight forward , which is supposed to be caused by the domain differences in coreference phenomena .
#<struct ReadData::Alignment source_numbers="6,7", target_numbers="6,7", tag_name="wa">
However , the shared task results showed that transferring coreference resolution methods developed for other domains to the biological domain was not straight forward , which is supposed to be caused by the domain differences in coreference phenomena .
#<struct ReadData::Alignment source_numbers="22", target_numbers="22", tag_name="wa">
However , the shared task results showed that transferring coreference resolution methods developed for other domains to the biological domain was not straight forward , which is supposed to be caused by the domain differences in coreference phenomena .
#<struct ReadData::Alignment source_numbers="30,31", target_numbers="24,25", tag_name="wa">
However , the shared task results showed that transferring coreference resolution methods developed for other domains to the biological domain was not straight forward , which is supposed to be caused by the domain differences in coreference phenomena .
#<struct ReadData::Alignment source_numbers="32", target_numbers="26", tag_name="wa">
However , the shared task results showed that transferring coreference resolution methods developed for other domains to the biological domain was not straight forward , which is supposed to be caused by the domain differences in coreference phenomena .
#<struct ReadData::Alignment source_numbers="33", target_numbers="27", tag_name="wa">
However , the shared task results showed that transferring coreference resolution methods developed for other domains to the biological domain was not straight forward , which is supposed to be caused by the domain differences in coreference phenomena .
#<struct ReadData::Alignment source_numbers="34", target_numbers="28", tag_name="wa">
However , the shared task results showed that transferring coreference resolution methods developed for other domains to the biological domain was not straight forward , which is supposed to be caused by the domain differences in coreference phenomena .
#<struct ReadData::Alignment source_numbers="35", target_numbers="29", tag_name="wa">
However , the shared task results showed that transferring coreference resolution methods developed for other domains to the biological domain was not straight forward , which is supposed to be caused by the domain differences in coreference phenomena .
#<struct ReadData::Alignment source_numbers="36", target_numbers="31", tag_name="wa">
However , the shared task results showed that transferring coreference resolution methods developed for other domains to the biological domain was not straight forward , which is supposed to be caused by the domain differences in coreference phenomena .
#<struct ReadData::Alignment source_numbers="37", target_numbers="32", tag_name="wa">
However , the shared task results showed that transferring coreference resolution methods developed for other domains to the biological domain was not straight forward , which is supposed to be caused by the domain differences in coreference phenomena .
#<struct ReadData::Alignment source_numbers="38", target_numbers="33", tag_name="wa">
However , the shared task results showed that transferring coreference resolution methods developed for other domains to the biological domain was not straight forward , which is supposed to be caused by the domain differences in coreference phenomena .
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
However , the shared task results showed that transferring coreference resolution methods developed for other domains to the biological domain was not straight forward , which is supposed to be caused by the domain differences in coreference phenomena .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
However , the shared task results showed that transferring coreference resolution methods developed for other domains to the biological domain was not straight forward , which is supposed to be caused by the domain differences in coreference phenomena .
#<struct ReadData::Alignment source_numbers="26", target_numbers="", tag_name="wa">
However , the shared task results showed that transferring coreference resolution methods developed for other domains to the biological domain was not straight forward , which is supposed to be caused by the domain differences in coreference phenomena .
#<struct ReadData::Alignment source_numbers="27", target_numbers="", tag_name="wa">
However , the shared task results showed that transferring coreference resolution methods developed for other domains to the biological domain was not straight forward , which is supposed to be caused by the domain differences in coreference phenomena .
#<struct ReadData::Alignment source_numbers="28", target_numbers="", tag_name="wa">
However , the shared task results showed that transferring coreference resolution methods developed for other domains to the biological domain was not straight forward , which is supposed to be caused by the domain differences in coreference phenomena .
#<struct ReadData::Alignment source_numbers="29", target_numbers="", tag_name="wa">
However , the shared task results showed that transferring coreference resolution methods developed for other domains to the biological domain was not straight forward , which is supposed to be caused by the domain differences in coreference phenomena .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
We studied the contribution of domain-specific information , i .e information indicating the protein type , in a rule-based protein coreference resolution system .
#<struct ReadData::Alignment source_numbers="11", target_numbers="11", tag_name="wa">
We studied the contribution of domain-specific information , i .e information indicating the protein type , in a rule-based protein coreference resolution system .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
We studied the contribution of domain-specific information , i .e information indicating the protein type , in a rule-based protein coreference resolution system .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
We studied the contribution of domain-specific information , i .e information indicating the protein type , in a rule-based protein coreference resolution system .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
We studied the contribution of domain-specific information , i .e information indicating the protein type , in a rule-based protein coreference resolution system .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
In particular , the domain-specific information is encoded into semantic classification modules whose output is used in different components of the coreference resolution .
#<struct ReadData::Alignment source_numbers="12", target_numbers="12,13,14", tag_name="wa">
We compared our system with the top four systems in the BioNLP-ST 2011 , and surprisingly we found that the minimal configuration has outperformed the best system in the BioNLP-ST 2011 .
#<struct ReadData::Alignment source_numbers="22", target_numbers="22", tag_name="wa">
We compared our system with the top four systems in the BioNLP-ST 2011 , and surprisingly we found that the minimal configuration has outperformed the best system in the BioNLP-ST 2011 .
#<struct ReadData::Alignment source_numbers="23", target_numbers="23", tag_name="wa">
We compared our system with the top four systems in the BioNLP-ST 2011 , and surprisingly we found that the minimal configuration has outperformed the best system in the BioNLP-ST 2011 .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
We compared our system with the top four systems in the BioNLP-ST 2011 , and surprisingly we found that the minimal configuration has outperformed the best system in the BioNLP-ST 2011 .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Analysis of the experimental results showed that semantic classification using protein information has contributed to an increase in performance ( 2.3 % on the test data , and 4 .0% on the development data , in F-score ) .
#<struct ReadData::Alignment source_numbers="5,6", target_numbers="5,6", tag_name="wa">
Analysis of the experimental results showed that semantic classification using protein information has contributed to an increase in performance ( 2.3 % on the test data , and 4 .0% on the development data , in F-score ) .
#<struct ReadData::Alignment source_numbers="26", target_numbers="9", tag_name="wa">
Analysis of the experimental results showed that semantic classification using protein information has contributed to an increase in performance ( 2.3 % on the test data , and 4 .0% on the development data , in F-score ) .
#<struct ReadData::Alignment source_numbers="34", target_numbers="13", tag_name="wa">
Analysis of the experimental results showed that semantic classification using protein information has contributed to an increase in performance ( 2.3 % on the test data , and 4 .0% on the development data , in F-score ) .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
Analysis of the experimental results showed that semantic classification using protein information has contributed to an increase in performance ( 2.3 % on the test data , and 4 .0% on the development data , in F-score ) .
#<struct ReadData::Alignment source_numbers="37", target_numbers="", tag_name="wa">
Analysis of the experimental results showed that semantic classification using protein information has contributed to an increase in performance ( 2.3 % on the test data , and 4 .0% on the development data , in F-score ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
Analysis of the experimental results showed that semantic classification using protein information has contributed to an increase in performance ( 2.3 % on the test data , and 4 .0% on the development data , in F-score ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
Analysis of the experimental results showed that semantic classification using protein information has contributed to an increase in performance ( 2.3 % on the test data , and 4 .0% on the development data , in F-score ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
Since such information is difficult to be transferred across different domains , we need to continue seeking for methods to exploit and use it in coreference resolution .
#<struct ReadData::Alignment source_numbers="23", target_numbers="1", tag_name="wa">
Since such information is difficult to be transferred across different domains , we need to continue seeking for methods to exploit and use it in coreference resolution .
#<struct ReadData::Alignment source_numbers="3", target_numbers="2", tag_name="wa">
Since such information is difficult to be transferred across different domains , we need to continue seeking for methods to exploit and use it in coreference resolution .
#<struct ReadData::Alignment source_numbers="5", target_numbers="4", tag_name="wa">
Since such information is difficult to be transferred across different domains , we need to continue seeking for methods to exploit and use it in coreference resolution .
#<struct ReadData::Alignment source_numbers="6,7", target_numbers="5", tag_name="wa">
Since such information is difficult to be transferred across different domains , we need to continue seeking for methods to exploit and use it in coreference resolution .
#<struct ReadData::Alignment source_numbers="19", target_numbers="16", tag_name="wa">
Since such information is difficult to be transferred across different domains , we need to continue seeking for methods to exploit and use it in coreference resolution .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Since such information is difficult to be transferred across different domains , we need to continue seeking for methods to exploit and use it in coreference resolution .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
Since such information is difficult to be transferred across different domains , we need to continue seeking for methods to exploit and use it in coreference resolution .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Since such information is difficult to be transferred across different domains , we need to continue seeking for methods to exploit and use it in coreference resolution .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Since such information is difficult to be transferred across different domains , we need to continue seeking for methods to exploit and use it in coreference resolution .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
Since such information is difficult to be transferred across different domains , we need to continue seeking for methods to exploit and use it in coreference resolution .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
While named entity recognition ( NER ) and relation or event extraction are regarded as standard tasks of biomedical information extraction ( IE ) , coreference resolution [ 2 , 16 , 30 ] is more and more recognized as an important component of IE for a higher performance .
#<struct ReadData::Alignment source_numbers="45", target_numbers="17", tag_name="wa">
While named entity recognition ( NER ) and relation or event extraction are regarded as standard tasks of biomedical information extraction ( IE ) , coreference resolution [ 2 , 16 , 30 ] is more and more recognized as an important component of IE for a higher performance .
#<struct ReadData::Alignment source_numbers="34", target_numbers="34", tag_name="wa">
While named entity recognition ( NER ) and relation or event extraction are regarded as standard tasks of biomedical information extraction ( IE ) , coreference resolution [ 2 , 16 , 30 ] is more and more recognized as an important component of IE for a higher performance .
#<struct ReadData::Alignment source_numbers="38", target_numbers="36", tag_name="wa">
While named entity recognition ( NER ) and relation or event extraction are regarded as standard tasks of biomedical information extraction ( IE ) , coreference resolution [ 2 , 16 , 30 ] is more and more recognized as an important component of IE for a higher performance .
#<struct ReadData::Alignment source_numbers="46", target_numbers="48", tag_name="wa">
While named entity recognition ( NER ) and relation or event extraction are regarded as standard tasks of biomedical information extraction ( IE ) , coreference resolution [ 2 , 16 , 30 ] is more and more recognized as an important component of IE for a higher performance .
#<struct ReadData::Alignment source_numbers="47", target_numbers="49", tag_name="wa">
While named entity recognition ( NER ) and relation or event extraction are regarded as standard tasks of biomedical information extraction ( IE ) , coreference resolution [ 2 , 16 , 30 ] is more and more recognized as an important component of IE for a higher performance .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
While named entity recognition ( NER ) and relation or event extraction are regarded as standard tasks of biomedical information extraction ( IE ) , coreference resolution [ 2 , 16 , 30 ] is more and more recognized as an important component of IE for a higher performance .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
While named entity recognition ( NER ) and relation or event extraction are regarded as standard tasks of biomedical information extraction ( IE ) , coreference resolution [ 2 , 16 , 30 ] is more and more recognized as an important component of IE for a higher performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
While named entity recognition ( NER ) and relation or event extraction are regarded as standard tasks of biomedical information extraction ( IE ) , coreference resolution [ 2 , 16 , 30 ] is more and more recognized as an important component of IE for a higher performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
While named entity recognition ( NER ) and relation or event extraction are regarded as standard tasks of biomedical information extraction ( IE ) , coreference resolution [ 2 , 16 , 30 ] is more and more recognized as an important component of IE for a higher performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="46", tag_name="wa">
While named entity recognition ( NER ) and relation or event extraction are regarded as standard tasks of biomedical information extraction ( IE ) , coreference resolution [ 2 , 16 , 30 ] is more and more recognized as an important component of IE for a higher performance .
#<struct ReadData::Alignment source_numbers="", target_numbers="47", tag_name="wa">
Without coreference resolution , the performance of IE is often substantially limited due to an abundance of coreference relations in natural language text , i.e. , information pieces written in text with involvement of a coreference relation are hard to be captured [ 9 , 14 ] .
#<struct ReadData::Alignment source_numbers="23", target_numbers="5", tag_name="wa">
Without coreference resolution , the performance of IE is often substantially limited due to an abundance of coreference relations in natural language text , i.e. , information pieces written in text with involvement of a coreference relation are hard to be captured [ 9 , 14 ] .
#<struct ReadData::Alignment source_numbers="25", target_numbers="11", tag_name="wa">
Without coreference resolution , the performance of IE is often substantially limited due to an abundance of coreference relations in natural language text , i.e. , information pieces written in text with involvement of a coreference relation are hard to be captured [ 9 , 14 ] .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Without coreference resolution , the performance of IE is often substantially limited due to an abundance of coreference relations in natural language text , i.e. , information pieces written in text with involvement of a coreference relation are hard to be captured [ 9 , 14 ] .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Without coreference resolution , the performance of IE is often substantially limited due to an abundance of coreference relations in natural language text , i.e. , information pieces written in text with involvement of a coreference relation are hard to be captured [ 9 , 14 ] .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Without coreference resolution , the performance of IE is often substantially limited due to an abundance of coreference relations in natural language text , i.e. , information pieces written in text with involvement of a coreference relation are hard to be captured [ 9 , 14 ] .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
Without coreference resolution , the performance of IE is often substantially limited due to an abundance of coreference relations in natural language text , i.e. , information pieces written in text with involvement of a coreference relation are hard to be captured [ 9 , 14 ] .
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
Without coreference resolution , the performance of IE is often substantially limited due to an abundance of coreference relations in natural language text , i.e. , information pieces written in text with involvement of a coreference relation are hard to be captured [ 9 , 14 ] .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Without coreference resolution , the performance of IE is often substantially limited due to an abundance of coreference relations in natural language text , i.e. , information pieces written in text with involvement of a coreference relation are hard to be captured [ 9 , 14 ] .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Without coreference resolution , the performance of IE is often substantially limited due to an abundance of coreference relations in natural language text , i.e. , information pieces written in text with involvement of a coreference relation are hard to be captured [ 9 , 14 ] .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Without coreference resolution , the performance of IE is often substantially limited due to an abundance of coreference relations in natural language text , i.e. , information pieces written in text with involvement of a coreference relation are hard to be captured [ 9 , 14 ] .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
There have been several attempts for coreference resolution , particularly for newswire texts [ 7 , 8 , 22 , 23 , 28 , 30 ] .
#<struct ReadData::Alignment source_numbers="26", target_numbers="31", tag_name="wa">
There have been several attempts for coreference resolution , particularly for newswire texts [ 7 , 8 , 22 , 23 , 28 , 30 ] .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
There have been several attempts for coreference resolution , particularly for newswire texts [ 7 , 8 , 22 , 23 , 28 , 30 ] .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
There have been several attempts for coreference resolution , particularly for newswire texts [ 7 , 8 , 22 , 23 , 28 , 30 ] .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
There have been several attempts for coreference resolution , particularly for newswire texts [ 7 , 8 , 22 , 23 , 28 , 30 ] .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
It is also one of the lessons from BioNLP Shared Task ( BioNLP-ST , hereafter ) 2009 that coreference relations in biomedical text substantially hinder the progress of fine-grained IE [ 10 ] .
#<struct ReadData::Alignment source_numbers="25", target_numbers="9", tag_name="wa">
It is also one of the lessons from BioNLP Shared Task ( BioNLP-ST , hereafter ) 2009 that coreference relations in biomedical text substantially hinder the progress of fine-grained IE [ 10 ] .
#<struct ReadData::Alignment source_numbers="33", target_numbers="41", tag_name="wa">
It is also one of the lessons from BioNLP Shared Task ( BioNLP-ST , hereafter ) 2009 that coreference relations in biomedical text substantially hinder the progress of fine-grained IE [ 10 ] .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
It is also one of the lessons from BioNLP Shared Task ( BioNLP-ST , hereafter ) 2009 that coreference relations in biomedical text substantially hinder the progress of fine-grained IE [ 10 ] .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
It is also one of the lessons from BioNLP Shared Task ( BioNLP-ST , hereafter ) 2009 that coreference relations in biomedical text substantially hinder the progress of fine-grained IE [ 10 ] .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
It is also one of the lessons from BioNLP Shared Task ( BioNLP-ST , hereafter ) 2009 that coreference relations in biomedical text substantially hinder the progress of fine-grained IE [ 10 ] .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
It is also one of the lessons from BioNLP Shared Task ( BioNLP-ST , hereafter ) 2009 that coreference relations in biomedical text substantially hinder the progress of fine-grained IE [ 10 ] .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
It is also one of the lessons from BioNLP Shared Task ( BioNLP-ST , hereafter ) 2009 that coreference relations in biomedical text substantially hinder the progress of fine-grained IE [ 10 ] .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
It is also one of the lessons from BioNLP Shared Task ( BioNLP-ST , hereafter ) 2009 that coreference relations in biomedical text substantially hinder the progress of fine-grained IE [ 10 ] .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
It is also one of the lessons from BioNLP Shared Task ( BioNLP-ST , hereafter ) 2009 that coreference relations in biomedical text substantially hinder the progress of fine-grained IE [ 10 ] .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
It is also one of the lessons from BioNLP Shared Task ( BioNLP-ST , hereafter ) 2009 that coreference relations in biomedical text substantially hinder the progress of fine-grained IE [ 10 ] .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
This task definition focuses on a specific type of entities , i.e. Protein .
#<struct ReadData::Alignment source_numbers="10", target_numbers="6", tag_name="wa">
This task definition focuses on a specific type of entities , i.e. Protein .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
This task definition focuses on a specific type of entities , i.e. Protein .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
This task definition focuses on a specific type of entities , i.e. Protein .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
This task definition focuses on a specific type of entities , i.e. Protein .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
In the figure , protein names are highlighted in bold face , P4 - P10 , and targeted anaphoric expressions of the shared task , e.g. pronouns and definite noun phrases , are T29 , and T32 , of which the antecedents are indicated by arrows if found in the text .
#<struct ReadData::Alignment source_numbers="9", target_numbers="12", tag_name="wa">
In the figure , protein names are highlighted in bold face , P4 - P10 , and targeted anaphoric expressions of the shared task , e.g. pronouns and definite noun phrases , are T29 , and T32 , of which the antecedents are indicated by arrows if found in the text .
#<struct ReadData::Alignment source_numbers="49", target_numbers="14", tag_name="wa">
In the figure , protein names are highlighted in bold face , P4 - P10 , and targeted anaphoric expressions of the shared task , e.g. pronouns and definite noun phrases , are T29 , and T32 , of which the antecedents are indicated by arrows if found in the text .
#<struct ReadData::Alignment source_numbers="34", target_numbers="31", tag_name="wa">
In the figure , protein names are highlighted in bold face , P4 - P10 , and targeted anaphoric expressions of the shared task , e.g. pronouns and definite noun phrases , are T29 , and T32 , of which the antecedents are indicated by arrows if found in the text .
#<struct ReadData::Alignment source_numbers="37", target_numbers="34", tag_name="wa">
In the figure , protein names are highlighted in bold face , P4 - P10 , and targeted anaphoric expressions of the shared task , e.g. pronouns and definite noun phrases , are T29 , and T32 , of which the antecedents are indicated by arrows if found in the text .
#<struct ReadData::Alignment source_numbers="38,39", target_numbers="35,36", tag_name="wa">
In the figure , protein names are highlighted in bold face , P4 - P10 , and targeted anaphoric expressions of the shared task , e.g. pronouns and definite noun phrases , are T29 , and T32 , of which the antecedents are indicated by arrows if found in the text .
#<struct ReadData::Alignment source_numbers="11", target_numbers="43", tag_name="wa">
In the figure , protein names are highlighted in bold face , P4 - P10 , and targeted anaphoric expressions of the shared task , e.g. pronouns and definite noun phrases , are T29 , and T32 , of which the antecedents are indicated by arrows if found in the text .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
In the figure , protein names are highlighted in bold face , P4 - P10 , and targeted anaphoric expressions of the shared task , e.g. pronouns and definite noun phrases , are T29 , and T32 , of which the antecedents are indicated by arrows if found in the text .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
In the figure , protein names are highlighted in bold face , P4 - P10 , and targeted anaphoric expressions of the shared task , e.g. pronouns and definite noun phrases , are T29 , and T32 , of which the antecedents are indicated by arrows if found in the text .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
In the figure , protein names are highlighted in bold face , P4 - P10 , and targeted anaphoric expressions of the shared task , e.g. pronouns and definite noun phrases , are T29 , and T32 , of which the antecedents are indicated by arrows if found in the text .
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
In the figure , protein names are highlighted in bold face , P4 - P10 , and targeted anaphoric expressions of the shared task , e.g. pronouns and definite noun phrases , are T29 , and T32 , of which the antecedents are indicated by arrows if found in the text .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
In the figure , protein names are highlighted in bold face , P4 - P10 , and targeted anaphoric expressions of the shared task , e.g. pronouns and definite noun phrases , are T29 , and T32 , of which the antecedents are indicated by arrows if found in the text .
#<struct ReadData::Alignment source_numbers="31", target_numbers="", tag_name="wa">
In the figure , protein names are highlighted in bold face , P4 - P10 , and targeted anaphoric expressions of the shared task , e.g. pronouns and definite noun phrases , are T29 , and T32 , of which the antecedents are indicated by arrows if found in the text .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
In the figure , protein names are highlighted in bold face , P4 - P10 , and targeted anaphoric expressions of the shared task , e.g. pronouns and definite noun phrases , are T29 , and T32 , of which the antecedents are indicated by arrows if found in the text .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
In the figure , protein names are highlighted in bold face , P4 - P10 , and targeted anaphoric expressions of the shared task , e.g. pronouns and definite noun phrases , are T29 , and T32 , of which the antecedents are indicated by arrows if found in the text .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
In the figure , protein names are highlighted in bold face , P4 - P10 , and targeted anaphoric expressions of the shared task , e.g. pronouns and definite noun phrases , are T29 , and T32 , of which the antecedents are indicated by arrows if found in the text .
#<struct ReadData::Alignment source_numbers="", target_numbers="47", tag_name="wa">
Without knowing this coreference relation , it becomes hard to capture the information written in the phrase , nuclear exclusion of this transcription factor , which is localization of p65 ( out of nucleus ) according to the framework of BioNLP-ST .
#<struct ReadData::Alignment source_numbers="8,9", target_numbers="8", tag_name="wa">
Without knowing this coreference relation , it becomes hard to capture the information written in the phrase , nuclear exclusion of this transcription factor , which is localization of p65 ( out of nucleus ) according to the framework of BioNLP-ST .
#<struct ReadData::Alignment source_numbers="36", target_numbers="9", tag_name="wa">
Without knowing this coreference relation , it becomes hard to capture the information written in the phrase , nuclear exclusion of this transcription factor , which is localization of p65 ( out of nucleus ) according to the framework of BioNLP-ST .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
Without knowing this coreference relation , it becomes hard to capture the information written in the phrase , nuclear exclusion of this transcription factor , which is localization of p65 ( out of nucleus ) according to the framework of BioNLP-ST .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
Without knowing this coreference relation , it becomes hard to capture the information written in the phrase , nuclear exclusion of this transcription factor , which is localization of p65 ( out of nucleus ) according to the framework of BioNLP-ST .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
A new term is introduced in the BioNLP-ST is antecedent protein , which indicates the protein mention contained in the antecedent expression , e.g. p65 in T28 .
#<struct ReadData::Alignment source_numbers="4", target_numbers="3", tag_name="wa">
A new term is introduced in the BioNLP-ST is antecedent protein , which indicates the protein mention contained in the antecedent expression , e.g. p65 in T28 .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
A new term is introduced in the BioNLP-ST is antecedent protein , which indicates the protein mention contained in the antecedent expression , e.g. p65 in T28 .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
There are other coreferential expressions which are ignored in the context of this COREF task such as this complex and the NF-kappa B transcription factor complex ( Figure 1 ) , since we only focus on the antecedent expressions that contain and point to protein mentions .
#<struct ReadData::Alignment source_numbers="30", target_numbers="5", tag_name="wa">
There are other coreferential expressions which are ignored in the context of this COREF task such as this complex and the NF-kappa B transcription factor complex ( Figure 1 ) , since we only focus on the antecedent expressions that contain and point to protein mentions .
#<struct ReadData::Alignment source_numbers="34", target_numbers="36", tag_name="wa">
There are other coreferential expressions which are ignored in the context of this COREF task such as this complex and the NF-kappa B transcription factor complex ( Figure 1 ) , since we only focus on the antecedent expressions that contain and point to protein mentions .
#<struct ReadData::Alignment source_numbers="32", target_numbers="", tag_name="wa">
There are other coreferential expressions which are ignored in the context of this COREF task such as this complex and the NF-kappa B transcription factor complex ( Figure 1 ) , since we only focus on the antecedent expressions that contain and point to protein mentions .
#<struct ReadData::Alignment source_numbers="33", target_numbers="", tag_name="wa">
There are other coreferential expressions which are ignored in the context of this COREF task such as this complex and the NF-kappa B transcription factor complex ( Figure 1 ) , since we only focus on the antecedent expressions that contain and point to protein mentions .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
There are other coreferential expressions which are ignored in the context of this COREF task such as this complex and the NF-kappa B transcription factor complex ( Figure 1 ) , since we only focus on the antecedent expressions that contain and point to protein mentions .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
There are other coreferential expressions which are ignored in the context of this COREF task such as this complex and the NF-kappa B transcription factor complex ( Figure 1 ) , since we only focus on the antecedent expressions that contain and point to protein mentions .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
There are other coreferential expressions which are ignored in the context of this COREF task such as this complex and the NF-kappa B transcription factor complex ( Figure 1 ) , since we only focus on the antecedent expressions that contain and point to protein mentions .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
There are other coreferential expressions which are ignored in the context of this COREF task such as this complex and the NF-kappa B transcription factor complex ( Figure 1 ) , since we only focus on the antecedent expressions that contain and point to protein mentions .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
The best system in the COREF shared task according to the primary evaluation found 22 .2% of anaphoric protein references at the precision of 73 .3% ( 34 .1% Fscore ) .
#<struct ReadData::Alignment source_numbers="29", target_numbers="", tag_name="wa">
The best system in the COREF shared task according to the primary evaluation found 22 .2% of anaphoric protein references at the precision of 73 .3% ( 34 .1% Fscore ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
The best system in the COREF shared task according to the primary evaluation found 22 .2% of anaphoric protein references at the precision of 73 .3% ( 34 .1% Fscore ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
The best system in the COREF shared task according to the primary evaluation found 22 .2% of anaphoric protein references at the precision of 73 .3% ( 34 .1% Fscore ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
This is an encouraging result , since the authors make use of an external coreference resolution tool originally built for the news domain , without much domain adaptation on the main coreference resolution algorithm .
#<struct ReadData::Alignment source_numbers="3", target_numbers="3", tag_name="wa">
This is an encouraging result , since the authors make use of an external coreference resolution tool originally built for the news domain , without much domain adaptation on the main coreference resolution algorithm .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
This is an encouraging result , since the authors make use of an external coreference resolution tool originally built for the news domain , without much domain adaptation on the main coreference resolution algorithm .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
This is an encouraging result , since the authors make use of an external coreference resolution tool originally built for the news domain , without much domain adaptation on the main coreference resolution algorithm .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
This is an encouraging result , since the authors make use of an external coreference resolution tool originally built for the news domain , without much domain adaptation on the main coreference resolution algorithm .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
This is an encouraging result , since the authors make use of an external coreference resolution tool originally built for the news domain , without much domain adaptation on the main coreference resolution algorithm .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
This is an encouraging result , since the authors make use of an external coreference resolution tool originally built for the news domain , without much domain adaptation on the main coreference resolution algorithm .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
This is an encouraging result , since the authors make use of an external coreference resolution tool originally built for the news domain , without much domain adaptation on the main coreference resolution algorithm .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Modifications are mostly made to the markable detection component and post processing for the output coreference links [ 11 ] .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Modifications are mostly made to the markable detection component and post processing for the output coreference links [ 11 ] .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
Modifications are mostly made to the markable detection component and post processing for the output coreference links [ 11 ] .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
However , the external coreference tool achieves much lower results on biological texts than that on news texts , from 66 .38% down to 49 .65% in MUC-score [ 11 , 27 ] , which is supposed to be caused by domain differences .
#<struct ReadData::Alignment source_numbers="9", target_numbers="7,8", tag_name="wa">
However , the external coreference tool achieves much lower results on biological texts than that on news texts , from 66 .38% down to 49 .65% in MUC-score [ 11 , 27 ] , which is supposed to be caused by domain differences .
#<struct ReadData::Alignment source_numbers="22", target_numbers="9", tag_name="wa">
However , the external coreference tool achieves much lower results on biological texts than that on news texts , from 66 .38% down to 49 .65% in MUC-score [ 11 , 27 ] , which is supposed to be caused by domain differences .
#<struct ReadData::Alignment source_numbers="23", target_numbers="21", tag_name="wa">
However , the external coreference tool achieves much lower results on biological texts than that on news texts , from 66 .38% down to 49 .65% in MUC-score [ 11 , 27 ] , which is supposed to be caused by domain differences .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
However , the external coreference tool achieves much lower results on biological texts than that on news texts , from 66 .38% down to 49 .65% in MUC-score [ 11 , 27 ] , which is supposed to be caused by domain differences .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
However , the external coreference tool achieves much lower results on biological texts than that on news texts , from 66 .38% down to 49 .65% in MUC-score [ 11 , 27 ] , which is supposed to be caused by domain differences .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
However , the external coreference tool achieves much lower results on biological texts than that on news texts , from 66 .38% down to 49 .65% in MUC-score [ 11 , 27 ] , which is supposed to be caused by domain differences .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
However , the external coreference tool achieves much lower results on biological texts than that on news texts , from 66 .38% down to 49 .65% in MUC-score [ 11 , 27 ] , which is supposed to be caused by domain differences .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
However , the external coreference tool achieves much lower results on biological texts than that on news texts , from 66 .38% down to 49 .65% in MUC-score [ 11 , 27 ] , which is supposed to be caused by domain differences .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
However , the external coreference tool achieves much lower results on biological texts than that on news texts , from 66 .38% down to 49 .65% in MUC-score [ 11 , 27 ] , which is supposed to be caused by domain differences .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
However , the external coreference tool achieves much lower results on biological texts than that on news texts , from 66 .38% down to 49 .65% in MUC-score [ 11 , 27 ] , which is supposed to be caused by domain differences .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
However , the external coreference tool achieves much lower results on biological texts than that on news texts , from 66 .38% down to 49 .65% in MUC-score [ 11 , 27 ] , which is supposed to be caused by domain differences .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
A detailed analysis on the _nal submissions of the COREF task participants was reported in the organizer 's papers [ 15 , 31 ] , which is summarized in table 2 .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
A detailed analysis on the _nal submissions of the COREF task participants was reported in the organizer 's papers [ 15 , 31 ] , which is summarized in table 2 .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
Below are examples of the coreference types .
#<struct ReadData::Alignment source_numbers="1", target_numbers="5", tag_name="wa">
Below are examples of the coreference types .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Below are examples of the coreference types .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Below are examples of the coreference types .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Below are examples of the coreference types .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Below are examples of the coreference types .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Below are examples of the coreference types .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Below are examples of the coreference types .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
- " . . . ,the phosphorylation status of [ TRAF2 ] had significant effects on the ability of [ the protein ] to bind to CD40 , " ( DNP )
#<struct ReadData::Alignment source_numbers="19", target_numbers="2", tag_name="wa">
- " . . . ,the phosphorylation status of [ TRAF2 ] had significant effects on the ability of [ the protein ] to bind to CD40 , " ( DNP )
#<struct ReadData::Alignment source_numbers="2", target_numbers="3", tag_name="wa">
- " . . . ,the phosphorylation status of [ TRAF2 ] had significant effects on the ability of [ the protein ] to bind to CD40 , " ( DNP )
#<struct ReadData::Alignment source_numbers="3", target_numbers="4", tag_name="wa">
- " . . . ,the phosphorylation status of [ TRAF2 ] had significant effects on the ability of [ the protein ] to bind to CD40 , " ( DNP )
#<struct ReadData::Alignment source_numbers="4", target_numbers="5", tag_name="wa">
- " . . . ,the phosphorylation status of [ TRAF2 ] had significant effects on the ability of [ the protein ] to bind to CD40 , " ( DNP )
#<struct ReadData::Alignment source_numbers="22", target_numbers="6", tag_name="wa">
- " . . . ,the phosphorylation status of [ TRAF2 ] had significant effects on the ability of [ the protein ] to bind to CD40 , " ( DNP )
#<struct ReadData::Alignment source_numbers="20", target_numbers="7", tag_name="wa">
- " . . . ,the phosphorylation status of [ TRAF2 ] had significant effects on the ability of [ the protein ] to bind to CD40 , " ( DNP )
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
- " . . . ,the phosphorylation status of [ TRAF2 ] had significant effects on the ability of [ the protein ] to bind to CD40 , " ( DNP )
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
- " . . . ,the phosphorylation status of [ TRAF2 ] had significant effects on the ability of [ the protein ] to bind to CD40 , " ( DNP )
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
- " . . . ,the phosphorylation status of [ TRAF2 ] had significant effects on the ability of [ the protein ] to bind to CD40 , " ( DNP )
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
- " Subnuclear fractionation reveals that there are [ two ATF1 isoforms ] [ which ] appear to differ with respect to DNA binding activity , " ( RELAT )
#<struct ReadData::Alignment source_numbers="15", target_numbers="14", tag_name="wa">
- " Subnuclear fractionation reveals that there are [ two ATF1 isoforms ] [ which ] appear to differ with respect to DNA binding activity , " ( RELAT )
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
- " Subnuclear fractionation reveals that there are [ two ATF1 isoforms ] [ which ] appear to differ with respect to DNA binding activity , " ( RELAT )
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
- " Subnuclear fractionation reveals that there are [ two ATF1 isoforms ] [ which ] appear to differ with respect to DNA binding activity , " ( RELAT )
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
The analysis results in also showed that the best resolution results for definite noun phrases ( the DNP type ) , and several pronouns of the PRON type are 27 .5% F-score and 10 .1 F-score respectively , which are far less than that for relative pronoun ( the RELAT type ) 66 .2 % F-score .
#<struct ReadData::Alignment source_numbers="1", target_numbers="1", tag_name="wa">
The analysis results in also showed that the best resolution results for definite noun phrases ( the DNP type ) , and several pronouns of the PRON type are 27 .5% F-score and 10 .1 F-score respectively , which are far less than that for relative pronoun ( the RELAT type ) 66 .2 % F-score .
#<struct ReadData::Alignment source_numbers="24", target_numbers="2", tag_name="wa">
The analysis results in also showed that the best resolution results for definite noun phrases ( the DNP type ) , and several pronouns of the PRON type are 27 .5% F-score and 10 .1 F-score respectively , which are far less than that for relative pronoun ( the RELAT type ) 66 .2 % F-score .
#<struct ReadData::Alignment source_numbers="25", target_numbers="3", tag_name="wa">
The analysis results in also showed that the best resolution results for definite noun phrases ( the DNP type ) , and several pronouns of the PRON type are 27 .5% F-score and 10 .1 F-score respectively , which are far less than that for relative pronoun ( the RELAT type ) 66 .2 % F-score .
#<struct ReadData::Alignment source_numbers="2", target_numbers="4", tag_name="wa">
The analysis results in also showed that the best resolution results for definite noun phrases ( the DNP type ) , and several pronouns of the PRON type are 27 .5% F-score and 10 .1 F-score respectively , which are far less than that for relative pronoun ( the RELAT type ) 66 .2 % F-score .
#<struct ReadData::Alignment source_numbers="5,6", target_numbers="5,6", tag_name="wa">
The analysis results in also showed that the best resolution results for definite noun phrases ( the DNP type ) , and several pronouns of the PRON type are 27 .5% F-score and 10 .1 F-score respectively , which are far less than that for relative pronoun ( the RELAT type ) 66 .2 % F-score .
#<struct ReadData::Alignment source_numbers="48", target_numbers="25", tag_name="wa">
The analysis results in also showed that the best resolution results for definite noun phrases ( the DNP type ) , and several pronouns of the PRON type are 27 .5% F-score and 10 .1 F-score respectively , which are far less than that for relative pronoun ( the RELAT type ) 66 .2 % F-score .
#<struct ReadData::Alignment source_numbers="39,40", target_numbers="41,42", tag_name="wa">
The analysis results in also showed that the best resolution results for definite noun phrases ( the DNP type ) , and several pronouns of the PRON type are 27 .5% F-score and 10 .1 F-score respectively , which are far less than that for relative pronoun ( the RELAT type ) 66 .2 % F-score .
#<struct ReadData::Alignment source_numbers="41,42", target_numbers="43,44", tag_name="wa">
The analysis results in also showed that the best resolution results for definite noun phrases ( the DNP type ) , and several pronouns of the PRON type are 27 .5% F-score and 10 .1 F-score respectively , which are far less than that for relative pronoun ( the RELAT type ) 66 .2 % F-score .
#<struct ReadData::Alignment source_numbers="55", target_numbers="46", tag_name="wa">
The analysis results in also showed that the best resolution results for definite noun phrases ( the DNP type ) , and several pronouns of the PRON type are 27 .5% F-score and 10 .1 F-score respectively , which are far less than that for relative pronoun ( the RELAT type ) 66 .2 % F-score .
#<struct ReadData::Alignment source_numbers="38", target_numbers="56", tag_name="wa">
The analysis results in also showed that the best resolution results for definite noun phrases ( the DNP type ) , and several pronouns of the PRON type are 27 .5% F-score and 10 .1 F-score respectively , which are far less than that for relative pronoun ( the RELAT type ) 66 .2 % F-score .
#<struct ReadData::Alignment source_numbers="56", target_numbers="63", tag_name="wa">
The analysis results in also showed that the best resolution results for definite noun phrases ( the DNP type ) , and several pronouns of the PRON type are 27 .5% F-score and 10 .1 F-score respectively , which are far less than that for relative pronoun ( the RELAT type ) 66 .2 % F-score .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
The analysis results in also showed that the best resolution results for definite noun phrases ( the DNP type ) , and several pronouns of the PRON type are 27 .5% F-score and 10 .1 F-score respectively , which are far less than that for relative pronoun ( the RELAT type ) 66 .2 % F-score .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
The analysis results in also showed that the best resolution results for definite noun phrases ( the DNP type ) , and several pronouns of the PRON type are 27 .5% F-score and 10 .1 F-score respectively , which are far less than that for relative pronoun ( the RELAT type ) 66 .2 % F-score .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
The analysis results in also showed that the best resolution results for definite noun phrases ( the DNP type ) , and several pronouns of the PRON type are 27 .5% F-score and 10 .1 F-score respectively , which are far less than that for relative pronoun ( the RELAT type ) 66 .2 % F-score .
#<struct ReadData::Alignment source_numbers="43", target_numbers="", tag_name="wa">
The analysis results in also showed that the best resolution results for definite noun phrases ( the DNP type ) , and several pronouns of the PRON type are 27 .5% F-score and 10 .1 F-score respectively , which are far less than that for relative pronoun ( the RELAT type ) 66 .2 % F-score .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
The analysis results in also showed that the best resolution results for definite noun phrases ( the DNP type ) , and several pronouns of the PRON type are 27 .5% F-score and 10 .1 F-score respectively , which are far less than that for relative pronoun ( the RELAT type ) 66 .2 % F-score .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
The analysis results in also showed that the best resolution results for definite noun phrases ( the DNP type ) , and several pronouns of the PRON type are 27 .5% F-score and 10 .1 F-score respectively , which are far less than that for relative pronoun ( the RELAT type ) 66 .2 % F-score .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
The analysis results in also showed that the best resolution results for definite noun phrases ( the DNP type ) , and several pronouns of the PRON type are 27 .5% F-score and 10 .1 F-score respectively , which are far less than that for relative pronoun ( the RELAT type ) 66 .2 % F-score .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
The analysis results in also showed that the best resolution results for definite noun phrases ( the DNP type ) , and several pronouns of the PRON type are 27 .5% F-score and 10 .1 F-score respectively , which are far less than that for relative pronoun ( the RELAT type ) 66 .2 % F-score .
#<struct ReadData::Alignment source_numbers="", target_numbers="40", tag_name="wa">
The analysis results in also showed that the best resolution results for definite noun phrases ( the DNP type ) , and several pronouns of the PRON type are 27 .5% F-score and 10 .1 F-score respectively , which are far less than that for relative pronoun ( the RELAT type ) 66 .2 % F-score .
#<struct ReadData::Alignment source_numbers="", target_numbers="45", tag_name="wa">
The analysis results in also showed that the best resolution results for definite noun phrases ( the DNP type ) , and several pronouns of the PRON type are 27 .5% F-score and 10 .1 F-score respectively , which are far less than that for relative pronoun ( the RELAT type ) 66 .2 % F-score .
#<struct ReadData::Alignment source_numbers="", target_numbers="51", tag_name="wa">
The analysis results in also showed that the best resolution results for definite noun phrases ( the DNP type ) , and several pronouns of the PRON type are 27 .5% F-score and 10 .1 F-score respectively , which are far less than that for relative pronoun ( the RELAT type ) 66 .2 % F-score .
#<struct ReadData::Alignment source_numbers="", target_numbers="55", tag_name="wa">
The analysis results in also showed that the best resolution results for definite noun phrases ( the DNP type ) , and several pronouns of the PRON type are 27 .5% F-score and 10 .1 F-score respectively , which are far less than that for relative pronoun ( the RELAT type ) 66 .2 % F-score .
#<struct ReadData::Alignment source_numbers="", target_numbers="57", tag_name="wa">
The analysis results in also showed that the best resolution results for definite noun phrases ( the DNP type ) , and several pronouns of the PRON type are 27 .5% F-score and 10 .1 F-score respectively , which are far less than that for relative pronoun ( the RELAT type ) 66 .2 % F-score .
#<struct ReadData::Alignment source_numbers="", target_numbers="62", tag_name="wa">
Thus , it can be inferred that definite noun phrases and pronouns are more difficult to be resolved than relative pronouns .
#<struct ReadData::Alignment source_numbers="12", target_numbers="8", tag_name="wa">
Thus , it can be inferred that definite noun phrases and pronouns are more difficult to be resolved than relative pronouns .
#<struct ReadData::Alignment source_numbers="15", target_numbers="11", tag_name="wa">
Thus , it can be inferred that definite noun phrases and pronouns are more difficult to be resolved than relative pronouns .
#<struct ReadData::Alignment source_numbers="16,17", target_numbers="12", tag_name="wa">
Thus , it can be inferred that definite noun phrases and pronouns are more difficult to be resolved than relative pronouns .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
The top four official results of the COREF shared task are shown again in the top four rows of Table 2 .
#<struct ReadData::Alignment source_numbers="11", target_numbers="11", tag_name="wa">
The top four official results of the COREF shared task are shown again in the top four rows of Table 2 .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
In this paper , we compare the contributions of different features in coreference resolution , two simple types of domain-portable information : discourse preference and number-agreement , and domain-specific information which can be considered as more difficult to be transferred across different domains .
#<struct ReadData::Alignment source_numbers="31,32", target_numbers="27", tag_name="wa">
In this paper , we compare the contributions of different features in coreference resolution , two simple types of domain-portable information : discourse preference and number-agreement , and domain-specific information which can be considered as more difficult to be transferred across different domains .
#<struct ReadData::Alignment source_numbers="14", target_numbers="29", tag_name="wa">
In this paper , we compare the contributions of different features in coreference resolution , two simple types of domain-portable information : discourse preference and number-agreement , and domain-specific information which can be considered as more difficult to be transferred across different domains .
#<struct ReadData::Alignment source_numbers="34", target_numbers="30", tag_name="wa">
In this paper , we compare the contributions of different features in coreference resolution , two simple types of domain-portable information : discourse preference and number-agreement , and domain-specific information which can be considered as more difficult to be transferred across different domains .
#<struct ReadData::Alignment source_numbers="37", target_numbers="39", tag_name="wa">
In this paper , we compare the contributions of different features in coreference resolution , two simple types of domain-portable information : discourse preference and number-agreement , and domain-specific information which can be considered as more difficult to be transferred across different domains .
#<struct ReadData::Alignment source_numbers="38", target_numbers="40", tag_name="wa">
In this paper , we compare the contributions of different features in coreference resolution , two simple types of domain-portable information : discourse preference and number-agreement , and domain-specific information which can be considered as more difficult to be transferred across different domains .
#<struct ReadData::Alignment source_numbers="27", target_numbers="", tag_name="wa">
In this paper , we compare the contributions of different features in coreference resolution , two simple types of domain-portable information : discourse preference and number-agreement , and domain-specific information which can be considered as more difficult to be transferred across different domains .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
In this paper , we compare the contributions of different features in coreference resolution , two simple types of domain-portable information : discourse preference and number-agreement , and domain-specific information which can be considered as more difficult to be transferred across different domains .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
In this paper , we compare the contributions of different features in coreference resolution , two simple types of domain-portable information : discourse preference and number-agreement , and domain-specific information which can be considered as more difficult to be transferred across different domains .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
In this paper , we compare the contributions of different features in coreference resolution , two simple types of domain-portable information : discourse preference and number-agreement , and domain-specific information which can be considered as more difficult to be transferred across different domains .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
In this paper , we compare the contributions of different features in coreference resolution , two simple types of domain-portable information : discourse preference and number-agreement , and domain-specific information which can be considered as more difficult to be transferred across different domains .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
In this paper , we compare the contributions of different features in coreference resolution , two simple types of domain-portable information : discourse preference and number-agreement , and domain-specific information which can be considered as more difficult to be transferred across different domains .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
In this paper , we compare the contributions of different features in coreference resolution , two simple types of domain-portable information : discourse preference and number-agreement , and domain-specific information which can be considered as more difficult to be transferred across different domains .
#<struct ReadData::Alignment source_numbers="", target_numbers="43", tag_name="wa">
In this paper , we compare the contributions of different features in coreference resolution , two simple types of domain-portable information : discourse preference and number-agreement , and domain-specific information which can be considered as more difficult to be transferred across different domains .
#<struct ReadData::Alignment source_numbers="", target_numbers="44", tag_name="wa">
Experimental results showed that domain specific semantic information is important for coreference resolution , and that simple semantic classification using semantic features helped our system to outperform the best reported result in the shared task .
#<struct ReadData::Alignment source_numbers="30", target_numbers="29", tag_name="wa">
Experimental results showed that domain specific semantic information is important for coreference resolution , and that simple semantic classification using semantic features helped our system to outperform the best reported result in the shared task .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
Experimental results showed that domain specific semantic information is important for coreference resolution , and that simple semantic classification using semantic features helped our system to outperform the best reported result in the shared task .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Experimental results showed that domain specific semantic information is important for coreference resolution , and that simple semantic classification using semantic features helped our system to outperform the best reported result in the shared task .
#<struct ReadData::Alignment source_numbers="28", target_numbers="", tag_name="wa">
Experimental results showed that domain specific semantic information is important for coreference resolution , and that simple semantic classification using semantic features helped our system to outperform the best reported result in the shared task .
#<struct ReadData::Alignment source_numbers="29", target_numbers="", tag_name="wa">
Experimental results showed that domain specific semantic information is important for coreference resolution , and that simple semantic classification using semantic features helped our system to outperform the best reported result in the shared task .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Experimental results showed that domain specific semantic information is important for coreference resolution , and that simple semantic classification using semantic features helped our system to outperform the best reported result in the shared task .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
Experimental results showed that domain specific semantic information is important for coreference resolution , and that simple semantic classification using semantic features helped our system to outperform the best reported result in the shared task .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
As we needed to get an insight into the problem , we took a rule-based approach , analyzing the training data of BioNLP-ST 2011 Coref task .
#<struct ReadData::Alignment source_numbers="3", target_numbers="2", tag_name="wa">
As we needed to get an insight into the problem , we took a rule-based approach , analyzing the training data of BioNLP-ST 2011 Coref task .
#<struct ReadData::Alignment source_numbers="4", target_numbers="3", tag_name="wa">
As we needed to get an insight into the problem , we took a rule-based approach , analyzing the training data of BioNLP-ST 2011 Coref task .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
As we needed to get an insight into the problem , we took a rule-based approach , analyzing the training data of BioNLP-ST 2011 Coref task .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
As we needed to get an insight into the problem , we took a rule-based approach , analyzing the training data of BioNLP-ST 2011 Coref task .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
As we needed to get an insight into the problem , we took a rule-based approach , analyzing the training data of BioNLP-ST 2011 Coref task .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
As we needed to get an insight into the problem , we took a rule-based approach , analyzing the training data of BioNLP-ST 2011 Coref task .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
As we needed to get an insight into the problem , we took a rule-based approach , analyzing the training data of BioNLP-ST 2011 Coref task .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
The performance of the system evaluated on the official test data set of the COREF task shows a significant improvement over the official winning system of the task .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
The performance of the system evaluated on the official test data set of the COREF task shows a significant improvement over the official winning system of the task .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
The performance of the system evaluated on the official test data set of the COREF task shows a significant improvement over the official winning system of the task .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
We used Genia Sentence Splitter and Enju Parser [ 15 ] for the purposes , respectively .
#<struct ReadData::Alignment source_numbers="12", target_numbers="2", tag_name="wa">
We used Genia Sentence Splitter and Enju Parser [ 15 ] for the purposes , respectively .
#<struct ReadData::Alignment source_numbers="14", target_numbers="18", tag_name="wa">
We used Genia Sentence Splitter and Enju Parser [ 15 ] for the purposes , respectively .
#<struct ReadData::Alignment source_numbers="16", target_numbers="20", tag_name="wa">
We used Genia Sentence Splitter and Enju Parser [ 15 ] for the purposes , respectively .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
We used Genia Sentence Splitter and Enju Parser [ 15 ] for the purposes , respectively .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
We used Genia Sentence Splitter and Enju Parser [ 15 ] for the purposes , respectively .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
We used Genia Sentence Splitter and Enju Parser [ 15 ] for the purposes , respectively .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
We used Genia Sentence Splitter and Enju Parser [ 15 ] for the purposes , respectively .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
We used Genia Sentence Splitter and Enju Parser [ 15 ] for the purposes , respectively .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
( Enju parser comes with a default tokenizer and part-of-speech tagger for biological text . ) Row 1 in the example Table 1 shows three sentences outputted from Genia Sentence Splitter , and noun phrases outputted from Enju Parser for the sentence S3 .
#<struct ReadData::Alignment source_numbers="40", target_numbers="28", tag_name="wa">
( Enju parser comes with a default tokenizer and part-of-speech tagger for biological text . ) Row 1 in the example Table 1 shows three sentences outputted from Genia Sentence Splitter , and noun phrases outputted from Enju Parser for the sentence S3 .
#<struct ReadData::Alignment source_numbers="26", target_numbers="29", tag_name="wa">
( Enju parser comes with a default tokenizer and part-of-speech tagger for biological text . ) Row 1 in the example Table 1 shows three sentences outputted from Genia Sentence Splitter , and noun phrases outputted from Enju Parser for the sentence S3 .
#<struct ReadData::Alignment source_numbers="31", target_numbers="35", tag_name="wa">
( Enju parser comes with a default tokenizer and part-of-speech tagger for biological text . ) Row 1 in the example Table 1 shows three sentences outputted from Genia Sentence Splitter , and noun phrases outputted from Enju Parser for the sentence S3 .
#<struct ReadData::Alignment source_numbers="35", target_numbers="41", tag_name="wa">
( Enju parser comes with a default tokenizer and part-of-speech tagger for biological text . ) Row 1 in the example Table 1 shows three sentences outputted from Genia Sentence Splitter , and noun phrases outputted from Enju Parser for the sentence S3 .
#<struct ReadData::Alignment source_numbers="43", target_numbers="51", tag_name="wa">
( Enju parser comes with a default tokenizer and part-of-speech tagger for biological text . ) Row 1 in the example Table 1 shows three sentences outputted from Genia Sentence Splitter , and noun phrases outputted from Enju Parser for the sentence S3 .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
( Enju parser comes with a default tokenizer and part-of-speech tagger for biological text . ) Row 1 in the example Table 1 shows three sentences outputted from Genia Sentence Splitter , and noun phrases outputted from Enju Parser for the sentence S3 .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
( Enju parser comes with a default tokenizer and part-of-speech tagger for biological text . ) Row 1 in the example Table 1 shows three sentences outputted from Genia Sentence Splitter , and noun phrases outputted from Enju Parser for the sentence S3 .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
( Enju parser comes with a default tokenizer and part-of-speech tagger for biological text . ) Row 1 in the example Table 1 shows three sentences outputted from Genia Sentence Splitter , and noun phrases outputted from Enju Parser for the sentence S3 .
#<struct ReadData::Alignment source_numbers="", target_numbers="40", tag_name="wa">
( Enju parser comes with a default tokenizer and part-of-speech tagger for biological text . ) Row 1 in the example Table 1 shows three sentences outputted from Genia Sentence Splitter , and noun phrases outputted from Enju Parser for the sentence S3 .
#<struct ReadData::Alignment source_numbers="", target_numbers="47", tag_name="wa">
( Enju parser comes with a default tokenizer and part-of-speech tagger for biological text . ) Row 1 in the example Table 1 shows three sentences outputted from Genia Sentence Splitter , and noun phrases outputted from Enju Parser for the sentence S3 .
#<struct ReadData::Alignment source_numbers="", target_numbers="49", tag_name="wa">
Due to the limit of space , only a part of the phrases are shown in the table .
#<struct ReadData::Alignment source_numbers="3", target_numbers="3", tag_name="wa">
Due to the limit of space , only a part of the phrases are shown in the table .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
The full parse tree of this sentence is separately shown in Figure 3 .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
The full parse tree of this sentence is separately shown in Figure 3 .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Step 1 - Markable detection : collects text chunks that are candidate coreferential expressions , which are also called markables following the jargon of MUC-7 .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
Step 1 - Markable detection : collects text chunks that are candidate coreferential expressions , which are also called markables following the jargon of MUC-7 .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Step 1 - Markable detection : collects text chunks that are candidate coreferential expressions , which are also called markables following the jargon of MUC-7 .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Step 1 - Markable detection : collects text chunks that are candidate coreferential expressions , which are also called markables following the jargon of MUC-7 .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
Step 1 - Markable detection : collects text chunks that are candidate coreferential expressions , which are also called markables following the jargon of MUC-7 .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
Step 1 - Markable detection : collects text chunks that are candidate coreferential expressions , which are also called markables following the jargon of MUC-7 .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
For the set of markables , noun phrases , which do not include subordinate clause , are collected as analyzed by a syntactic parser , Enju in our case .
#<struct ReadData::Alignment source_numbers="24", target_numbers="31", tag_name="wa">
For the set of markables , noun phrases , which do not include subordinate clause , are collected as analyzed by a syntactic parser , Enju in our case .
#<struct ReadData::Alignment source_numbers="29", target_numbers="34", tag_name="wa">
For the set of markables , noun phrases , which do not include subordinate clause , are collected as analyzed by a syntactic parser , Enju in our case .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
For the set of markables , noun phrases , which do not include subordinate clause , are collected as analyzed by a syntactic parser , Enju in our case .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
For the set of markables , noun phrases , which do not include subordinate clause , are collected as analyzed by a syntactic parser , Enju in our case .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
For the set of markables , noun phrases , which do not include subordinate clause , are collected as analyzed by a syntactic parser , Enju in our case .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
For the set of markables , noun phrases , which do not include subordinate clause , are collected as analyzed by a syntactic parser , Enju in our case .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
Then , for chunks that share the same head word , which is normally the main noun of a noun phrase , only the longest is taken .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
Since the Enju parser output such head-word information for every noun phrase , we make use of this information for our processing without any modification .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Since the Enju parser output such head-word information for every noun phrase , we make use of this information for our processing without any modification .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
In the sentence S3 , three noun phrases recognized by the NX and NP tags of Enju output , role , role for c-Myc in apoptosis , and this role for c-Myc in apoptosis ( Step 0 results ) share the same head word role , thus only the longest one this role for c-Myc in apoptosis is selected .
#<struct ReadData::Alignment source_numbers="48", target_numbers="16", tag_name="wa">
In the sentence S3 , three noun phrases recognized by the NX and NP tags of Enju output , role , role for c-Myc in apoptosis , and this role for c-Myc in apoptosis ( Step 0 results ) share the same head word role , thus only the longest one this role for c-Myc in apoptosis is selected .
#<struct ReadData::Alignment source_numbers="59", target_numbers="63", tag_name="wa">
In the sentence S3 , three noun phrases recognized by the NX and NP tags of Enju output , role , role for c-Myc in apoptosis , and this role for c-Myc in apoptosis ( Step 0 results ) share the same head word role , thus only the longest one this role for c-Myc in apoptosis is selected .
#<struct ReadData::Alignment source_numbers="42", target_numbers="", tag_name="wa">
In the sentence S3 , three noun phrases recognized by the NX and NP tags of Enju output , role , role for c-Myc in apoptosis , and this role for c-Myc in apoptosis ( Step 0 results ) share the same head word role , thus only the longest one this role for c-Myc in apoptosis is selected .
#<struct ReadData::Alignment source_numbers="43", target_numbers="", tag_name="wa">
In the sentence S3 , three noun phrases recognized by the NX and NP tags of Enju output , role , role for c-Myc in apoptosis , and this role for c-Myc in apoptosis ( Step 0 results ) share the same head word role , thus only the longest one this role for c-Myc in apoptosis is selected .
#<struct ReadData::Alignment source_numbers="50", target_numbers="", tag_name="wa">
In the sentence S3 , three noun phrases recognized by the NX and NP tags of Enju output , role , role for c-Myc in apoptosis , and this role for c-Myc in apoptosis ( Step 0 results ) share the same head word role , thus only the longest one this role for c-Myc in apoptosis is selected .
#<struct ReadData::Alignment source_numbers="", target_numbers="43", tag_name="wa">
In the sentence S3 , three noun phrases recognized by the NX and NP tags of Enju output , role , role for c-Myc in apoptosis , and this role for c-Myc in apoptosis ( Step 0 results ) share the same head word role , thus only the longest one this role for c-Myc in apoptosis is selected .
#<struct ReadData::Alignment source_numbers="", target_numbers="45", tag_name="wa">
In the sentence S3 , three noun phrases recognized by the NX and NP tags of Enju output , role , role for c-Myc in apoptosis , and this role for c-Myc in apoptosis ( Step 0 results ) share the same head word role , thus only the longest one this role for c-Myc in apoptosis is selected .
#<struct ReadData::Alignment source_numbers="", target_numbers="49", tag_name="wa">
In the sentence S3 , three noun phrases recognized by the NX and NP tags of Enju output , role , role for c-Myc in apoptosis , and this role for c-Myc in apoptosis ( Step 0 results ) share the same head word role , thus only the longest one this role for c-Myc in apoptosis is selected .
#<struct ReadData::Alignment source_numbers="", target_numbers="51", tag_name="wa">
In the sentence S3 , three noun phrases recognized by the NX and NP tags of Enju output , role , role for c-Myc in apoptosis , and this role for c-Myc in apoptosis ( Step 0 results ) share the same head word role , thus only the longest one this role for c-Myc in apoptosis is selected .
#<struct ReadData::Alignment source_numbers="", target_numbers="52", tag_name="wa">
In the sentence S3 , three noun phrases recognized by the NX and NP tags of Enju output , role , role for c-Myc in apoptosis , and this role for c-Myc in apoptosis ( Step 0 results ) share the same head word role , thus only the longest one this role for c-Myc in apoptosis is selected .
#<struct ReadData::Alignment source_numbers="", target_numbers="53", tag_name="wa">
In the sentence S3 , three noun phrases recognized by the NX and NP tags of Enju output , role , role for c-Myc in apoptosis , and this role for c-Myc in apoptosis ( Step 0 results ) share the same head word role , thus only the longest one this role for c-Myc in apoptosis is selected .
#<struct ReadData::Alignment source_numbers="", target_numbers="60", tag_name="wa">
Step 2 - Anaphor selection : determines candidate anaphoric expressions , which are basically pronouns and definite noun phrases ( a minority of anaphors are indefinite noun phrases or entity names , which act as appositions . )
#<struct ReadData::Alignment source_numbers="31", target_numbers="18", tag_name="wa">
Step 2 - Anaphor selection : determines candidate anaphoric expressions , which are basically pronouns and definite noun phrases ( a minority of anaphors are indefinite noun phrases or entity names , which act as appositions . )
#<struct ReadData::Alignment source_numbers="24", target_numbers="19", tag_name="wa">
Step 2 - Anaphor selection : determines candidate anaphoric expressions , which are basically pronouns and definite noun phrases ( a minority of anaphors are indefinite noun phrases or entity names , which act as appositions . )
#<struct ReadData::Alignment source_numbers="36", target_numbers="21", tag_name="wa">
Step 2 - Anaphor selection : determines candidate anaphoric expressions , which are basically pronouns and definite noun phrases ( a minority of anaphors are indefinite noun phrases or entity names , which act as appositions . )
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
Step 2 - Anaphor selection : determines candidate anaphoric expressions , which are basically pronouns and definite noun phrases ( a minority of anaphors are indefinite noun phrases or entity names , which act as appositions . )
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Step 2 - Anaphor selection : determines candidate anaphoric expressions , which are basically pronouns and definite noun phrases ( a minority of anaphors are indefinite noun phrases or entity names , which act as appositions . )
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
Step 2 - Anaphor selection : determines candidate anaphoric expressions , which are basically pronouns and definite noun phrases ( a minority of anaphors are indefinite noun phrases or entity names , which act as appositions . )
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
Step 2 - Anaphor selection : determines candidate anaphoric expressions , which are basically pronouns and definite noun phrases ( a minority of anaphors are indefinite noun phrases or entity names , which act as appositions . )
#<struct ReadData::Alignment source_numbers="37", target_numbers="", tag_name="wa">
Step 2 - Anaphor selection : determines candidate anaphoric expressions , which are basically pronouns and definite noun phrases ( a minority of anaphors are indefinite noun phrases or entity names , which act as appositions . )
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Step 2 - Anaphor selection : determines candidate anaphoric expressions , which are basically pronouns and definite noun phrases ( a minority of anaphors are indefinite noun phrases or entity names , which act as appositions . )
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
Step 2 - Anaphor selection : determines candidate anaphoric expressions , which are basically pronouns and definite noun phrases ( a minority of anaphors are indefinite noun phrases or entity names , which act as appositions . )
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
Step 2 - Anaphor selection : determines candidate anaphoric expressions , which are basically pronouns and definite noun phrases ( a minority of anaphors are indefinite noun phrases or entity names , which act as appositions . )
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
Step 2 - Anaphor selection : determines candidate anaphoric expressions , which are basically pronouns and definite noun phrases ( a minority of anaphors are indefinite noun phrases or entity names , which act as appositions . )
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
Step 2 - Anaphor selection : determines candidate anaphoric expressions , which are basically pronouns and definite noun phrases ( a minority of anaphors are indefinite noun phrases or entity names , which act as appositions . )
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
We implemented two types of filters : syntactic and semantic filters .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Syntactic filters are used to filter out pleonastic its , or pronouns such as he , she , which are not expected to refer to proteins .
#<struct ReadData::Alignment source_numbers="17", target_numbers="12", tag_name="wa">
Syntactic filters are used to filter out pleonastic its , or pronouns such as he , she , which are not expected to refer to proteins .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
Syntactic filters are used to filter out pleonastic its , or pronouns such as he , she , which are not expected to refer to proteins .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
Syntactic filters are used to filter out pleonastic its , or pronouns such as he , she , which are not expected to refer to proteins .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Syntactic filters are used to filter out pleonastic its , or pronouns such as he , she , which are not expected to refer to proteins .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Syntactic filters are used to filter out pleonastic its , or pronouns such as he , she , which are not expected to refer to proteins .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
Moreover , because the focus of our task is protein references , semantic filters can be used to filter out non-protein anaphors at this stage .
#<struct ReadData::Alignment source_numbers="8", target_numbers="5", tag_name="wa">
Moreover , because the focus of our task is protein references , semantic filters can be used to filter out non-protein anaphors at this stage .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
Moreover , because the focus of our task is protein references , semantic filters can be used to filter out non-protein anaphors at this stage .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
Moreover , because the focus of our task is protein references , semantic filters can be used to filter out non-protein anaphors at this stage .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Moreover , because the focus of our task is protein references , semantic filters can be used to filter out non-protein anaphors at this stage .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
In practice , for definite noun phrase type of anaphors , this is done using a list of possible head words of protein references , and for pronouns , their context words are used .
#<struct ReadData::Alignment source_numbers="24", target_numbers="14", tag_name="wa">
In practice , for definite noun phrase type of anaphors , this is done using a list of possible head words of protein references , and for pronouns , their context words are used .
#<struct ReadData::Alignment source_numbers="33", target_numbers="15,16", tag_name="wa">
In practice , for definite noun phrase type of anaphors , this is done using a list of possible head words of protein references , and for pronouns , their context words are used .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
In practice , for definite noun phrase type of anaphors , this is done using a list of possible head words of protein references , and for pronouns , their context words are used .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
In practice , for definite noun phrase type of anaphors , this is done using a list of possible head words of protein references , and for pronouns , their context words are used .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
In practice , for definite noun phrase type of anaphors , this is done using a list of possible head words of protein references , and for pronouns , their context words are used .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
In practice , for definite noun phrase type of anaphors , this is done using a list of possible head words of protein references , and for pronouns , their context words are used .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
In practice , for definite noun phrase type of anaphors , this is done using a list of possible head words of protein references , and for pronouns , their context words are used .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
In practice , for definite noun phrase type of anaphors , this is done using a list of possible head words of protein references , and for pronouns , their context words are used .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
More details of the methods can be found in the following section .
#<struct ReadData::Alignment source_numbers="3,4", target_numbers="3,4", tag_name="wa">
One of the candidates will become the response antecedent as a result of the antecedent prediction step .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
In theory , all expressions in the set of markables can become antecedent candidates , however too much candidates makes it difficult to achieve correct antecedent prediction .
#<struct ReadData::Alignment source_numbers="16,17", target_numbers="17,18", tag_name="wa">
In theory , all expressions in the set of markables can become antecedent candidates , however too much candidates makes it difficult to achieve correct antecedent prediction .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
In our system , this is done by using a window size in sentences , together with several syntactic filters .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
The idea behind this is that some types of syntactic relations imply the impossibility of coreference relations between its argument noun phrases and the inclusive expressions of these noun phrases .
#<struct ReadData::Alignment source_numbers="3", target_numbers="3", tag_name="wa">
The idea behind this is that some types of syntactic relations imply the impossibility of coreference relations between its argument noun phrases and the inclusive expressions of these noun phrases .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
For example , the two expressions dominant negative form and its in our example in Table 1 , can not be coreferential with each other , since they are connected via the preposition of .
#<struct ReadData::Alignment source_numbers="18,19", target_numbers="19,20", tag_name="wa">
For example , the two expressions dominant negative form and its in our example in Table 1 , can not be coreferential with each other , since they are connected via the preposition of .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
For example , the two expressions dominant negative form and its in our example in Table 1 , can not be coreferential with each other , since they are connected via the preposition of .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Another syntactic filter removes pronouns which are not in the same pronoun family as the anaphor .
#<struct ReadData::Alignment source_numbers="5,6", target_numbers="5,6", tag_name="wa">
Step 4 - Antecedent predicion : selects the best candidate in the antecedent candidate set , and forms a response coreference link .
#<struct ReadData::Alignment source_numbers="6,7", target_numbers="15", tag_name="wa">
Step 4 - Antecedent predicion : selects the best candidate in the antecedent candidate set , and forms a response coreference link .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
Step 4 - Antecedent predicion : selects the best candidate in the antecedent candidate set , and forms a response coreference link .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
Step 4 - Antecedent predicion : selects the best candidate in the antecedent candidate set , and forms a response coreference link .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Step 4 - Antecedent predicion : selects the best candidate in the antecedent candidate set , and forms a response coreference link .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Step 4 - Antecedent predicion : selects the best candidate in the antecedent candidate set , and forms a response coreference link .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Step 4 - Antecedent predicion : selects the best candidate in the antecedent candidate set , and forms a response coreference link .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
Step 4 - Antecedent predicion : selects the best candidate in the antecedent candidate set , and forms a response coreference link .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
-Rule 1 ( Number agreement - NUM-AGREE ) : The candidate which is not number conflict with anaphor is selected .
#<struct ReadData::Alignment source_numbers="12", target_numbers="13", tag_name="wa">
-Rule 1 ( Number agreement - NUM-AGREE ) : The candidate which is not number conflict with anaphor is selected .
#<struct ReadData::Alignment source_numbers="13", target_numbers="14", tag_name="wa">
-Rule 1 ( Number agreement - NUM-AGREE ) : The candidate which is not number conflict with anaphor is selected .
#<struct ReadData::Alignment source_numbers="15", target_numbers="15", tag_name="wa">
-Rule 1 ( Number agreement - NUM-AGREE ) : The candidate which is not number conflict with anaphor is selected .
#<struct ReadData::Alignment source_numbers="14", target_numbers="17", tag_name="wa">
-Rule 1 ( Number agreement - NUM-AGREE ) : The candidate which is not number conflict with anaphor is selected .
#<struct ReadData::Alignment source_numbers="20", target_numbers="24", tag_name="wa">
-Rule 1 ( Number agreement - NUM-AGREE ) : The candidate which is not number conflict with anaphor is selected .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
-Rule 1 ( Number agreement - NUM-AGREE ) : The candidate which is not number conflict with anaphor is selected .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
-Rule 1 ( Number agreement - NUM-AGREE ) : The candidate which is not number conflict with anaphor is selected .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
The rules are implemented using different features of expressions such as syntactic types of expression , head noun , semantic types , etc. , in a similar way to [ 22 ] .
#<struct ReadData::Alignment source_numbers="23", target_numbers="9", tag_name="wa">
The rules are implemented using different features of expressions such as syntactic types of expression , head noun , semantic types , etc. , in a similar way to [ 22 ] .
#<struct ReadData::Alignment source_numbers="25,26,27,28", target_numbers="25,26,27,28", tag_name="wa">
The rules are implemented using different features of expressions such as syntactic types of expression , head noun , semantic types , etc. , in a similar way to [ 22 ] .
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
The rules are implemented using different features of expressions such as syntactic types of expression , head noun , semantic types , etc. , in a similar way to [ 22 ] .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
The rules are implemented using different features of expressions such as syntactic types of expression , head noun , semantic types , etc. , in a similar way to [ 22 ] .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
Each rule in the decision list compares two candidates , and returns the preferrable candidate in concern with the anaphor .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
Each rule in the decision list compares two candidates , and returns the preferrable candidate in concern with the anaphor .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Thanks to this rule , the decision list never results in the equility result .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Thanks to this rule , the decision list never results in the equility result .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Thanks to this rule , the decision list never results in the equility result .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Thanks to this rule , the decision list never results in the equility result .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Thanks to this rule , the decision list never results in the equility result .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
By this way , candidates can be sorted , and the best candidate is selected as antecedent .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
By this way , candidates can be sorted , and the best candidate is selected as antecedent .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Figure 4 illustrates how the decision list works when comparing two candidates and .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
In this step , we want to filter out those pronouns and definite noun phrases that are not target of this task , comprised of two types : non-anaphoric expressions , and anaphoric expressions which do not point to proteins .
#<struct ReadData::Alignment source_numbers="40", target_numbers="23", tag_name="wa">
In this step , we want to filter out those pronouns and definite noun phrases that are not target of this task , comprised of two types : non-anaphoric expressions , and anaphoric expressions which do not point to proteins .
#<struct ReadData::Alignment source_numbers="33", target_numbers="25", tag_name="wa">
In this step , we want to filter out those pronouns and definite noun phrases that are not target of this task , comprised of two types : non-anaphoric expressions , and anaphoric expressions which do not point to proteins .
#<struct ReadData::Alignment source_numbers="35,36", target_numbers="26", tag_name="wa">
In this step , we want to filter out those pronouns and definite noun phrases that are not target of this task , comprised of two types : non-anaphoric expressions , and anaphoric expressions which do not point to proteins .
#<struct ReadData::Alignment source_numbers="22", target_numbers="38", tag_name="wa">
In this step , we want to filter out those pronouns and definite noun phrases that are not target of this task , comprised of two types : non-anaphoric expressions , and anaphoric expressions which do not point to proteins .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
In this step , we want to filter out those pronouns and definite noun phrases that are not target of this task , comprised of two types : non-anaphoric expressions , and anaphoric expressions which do not point to proteins .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
In this step , we want to filter out those pronouns and definite noun phrases that are not target of this task , comprised of two types : non-anaphoric expressions , and anaphoric expressions which do not point to proteins .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
In this step , we want to filter out those pronouns and definite noun phrases that are not target of this task , comprised of two types : non-anaphoric expressions , and anaphoric expressions which do not point to proteins .
#<struct ReadData::Alignment source_numbers="", target_numbers="40", tag_name="wa">
In this step , we want to filter out those pronouns and definite noun phrases that are not target of this task , comprised of two types : non-anaphoric expressions , and anaphoric expressions which do not point to proteins .
#<struct ReadData::Alignment source_numbers="", target_numbers="41", tag_name="wa">
In this step , we want to filter out those pronouns and definite noun phrases that are not target of this task , comprised of two types : non-anaphoric expressions , and anaphoric expressions which do not point to proteins .
#<struct ReadData::Alignment source_numbers="", target_numbers="45", tag_name="wa">
Anaphoric expression means an expression that has a noun phrase as antecedent .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Anaphoric expression means an expression that has a noun phrase as antecedent .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Anaphoric expression means an expression that has a noun phrase as antecedent .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
This means expressions with a sentence or phrase antecedents , or nominal but successive antecedents , are not our target and should be filtered out .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
This means expressions with a sentence or phrase antecedents , or nominal but successive antecedents , are not our target and should be filtered out .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
This means expressions with a sentence or phrase antecedents , or nominal but successive antecedents , are not our target and should be filtered out .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
This means expressions with a sentence or phrase antecedents , or nominal but successive antecedents , are not our target and should be filtered out .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Non-anaphoric expressions includes first and second person pronouns such as I , we , you , . . . , and pleonastic it .
#<struct ReadData::Alignment source_numbers="23", target_numbers="18", tag_name="wa">
Non-anaphoric expressions includes first and second person pronouns such as I , we , you , . . . , and pleonastic it .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Non-anaphoric expressions includes first and second person pronouns such as I , we , you , . . . , and pleonastic it .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
Non-anaphoric expressions includes first and second person pronouns such as I , we , you , . . . , and pleonastic it .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
Non-anaphoric expressions includes first and second person pronouns such as I , we , you , . . . , and pleonastic it .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
Non-anaphoric expressions includes first and second person pronouns such as I , we , you , . . . , and pleonastic it .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
Non-anaphoric expressions includes first and second person pronouns such as I , we , you , . . . , and pleonastic it .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
Non-anaphoric expressions includes first and second person pronouns such as I , we , you , . . . , and pleonastic it .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
First and second person pronouns are easily to be recognized by the part-of-speech tags , thus we use part-of-speech information for the filtering .
#<struct ReadData::Alignment source_numbers="5", target_numbers="4", tag_name="wa">
First and second person pronouns are easily to be recognized by the part-of-speech tags , thus we use part-of-speech information for the filtering .
#<struct ReadData::Alignment source_numbers="9", target_numbers="6", tag_name="wa">
First and second person pronouns are easily to be recognized by the part-of-speech tags , thus we use part-of-speech information for the filtering .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
First and second person pronouns are easily to be recognized by the part-of-speech tags , thus we use part-of-speech information for the filtering .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
First and second person pronouns are easily to be recognized by the part-of-speech tags , thus we use part-of-speech information for the filtering .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
First and second person pronouns are easily to be recognized by the part-of-speech tags , thus we use part-of-speech information for the filtering .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
First and second person pronouns are easily to be recognized by the part-of-speech tags , thus we use part-of-speech information for the filtering .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
First and second person pronouns are easily to be recognized by the part-of-speech tags , thus we use part-of-speech information for the filtering .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
For pleonastic it , we make use of the following four patterns , which are similar to [ 13 ]
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
To recognize and filter anaphoric expressions which do not point to proteins , the system is based on the protein semantic classification results determined by the method presented below .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
To recognize and filter anaphoric expressions which do not point to proteins , the system is based on the protein semantic classification results determined by the method presented below .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Basically all expressions detected in the initial expression set are antecedent candidate , except for anaphoric pronouns .
#<struct ReadData::Alignment source_numbers="12", target_numbers="16", tag_name="wa">
Basically all expressions detected in the initial expression set are antecedent candidate , except for anaphoric pronouns .
#<struct ReadData::Alignment source_numbers="17", target_numbers="23", tag_name="wa">
Basically all expressions detected in the initial expression set are antecedent candidate , except for anaphoric pronouns .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Window size sets a border to include or exclude antecedent candidates .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Window size sets a border to include or exclude antecedent candidates .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
Window size sets a border to include or exclude antecedent candidates .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
Window size sets a border to include or exclude antecedent candidates .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Window size sets a border to include or exclude antecedent candidates .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Window size sets a border to include or exclude antecedent candidates .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
This is a common method for antecedent candidate filtering having been used in the previous work [ 3 , 5 , 26 ] .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
This is a common method for antecedent candidate filtering having been used in the previous work [ 3 , 5 , 26 ] .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
This is a common method for antecedent candidate filtering having been used in the previous work [ 3 , 5 , 26 ] .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
This is a common method for antecedent candidate filtering having been used in the previous work [ 3 , 5 , 26 ] .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
This is a common method for antecedent candidate filtering having been used in the previous work [ 3 , 5 , 26 ] .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
This is a common method for antecedent candidate filtering having been used in the previous work [ 3 , 5 , 26 ] .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
Since our task focuses on anaphoric coreference , antecedent expressions normally appear not too far ( in sentence distance ) from the anaphors , using window sizes is a proper technique .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
Since our task focuses on anaphoric coreference , antecedent expressions normally appear not too far ( in sentence distance ) from the anaphors , using window sizes is a proper technique .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
Syntactic dependency relations The fact that arguments of some dependency relations such as poss-arg12 and prep-arg12 do not corefer with each other enables us to use them to correctly eliminate the number of antecedent candidates .
#<struct ReadData::Alignment source_numbers="25,26", target_numbers="25,26", tag_name="wa">
Syntactic dependency relations The fact that arguments of some dependency relations such as poss-arg12 and prep-arg12 do not corefer with each other enables us to use them to correctly eliminate the number of antecedent candidates .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
Syntactic dependency relations The fact that arguments of some dependency relations such as poss-arg12 and prep-arg12 do not corefer with each other enables us to use them to correctly eliminate the number of antecedent candidates .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
Syntactic dependency relations The fact that arguments of some dependency relations such as poss-arg12 and prep-arg12 do not corefer with each other enables us to use them to correctly eliminate the number of antecedent candidates .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Syntactic dependency relations The fact that arguments of some dependency relations such as poss-arg12 and prep-arg12 do not corefer with each other enables us to use them to correctly eliminate the number of antecedent candidates .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
Syntactic dependency relations The fact that arguments of some dependency relations such as poss-arg12 and prep-arg12 do not corefer with each other enables us to use them to correctly eliminate the number of antecedent candidates .
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
Syntactic dependency relations The fact that arguments of some dependency relations such as poss-arg12 and prep-arg12 do not corefer with each other enables us to use them to correctly eliminate the number of antecedent candidates .
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
Syntactic dependency relations The fact that arguments of some dependency relations such as poss-arg12 and prep-arg12 do not corefer with each other enables us to use them to correctly eliminate the number of antecedent candidates .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Syntactic dependency relations The fact that arguments of some dependency relations such as poss-arg12 and prep-arg12 do not corefer with each other enables us to use them to correctly eliminate the number of antecedent candidates .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Syntactic dependency relations The fact that arguments of some dependency relations such as poss-arg12 and prep-arg12 do not corefer with each other enables us to use them to correctly eliminate the number of antecedent candidates .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
Syntactic dependency relations The fact that arguments of some dependency relations such as poss-arg12 and prep-arg12 do not corefer with each other enables us to use them to correctly eliminate the number of antecedent candidates .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
Syntactic dependency relations The fact that arguments of some dependency relations such as poss-arg12 and prep-arg12 do not corefer with each other enables us to use them to correctly eliminate the number of antecedent candidates .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
Syntactic dependency relations The fact that arguments of some dependency relations such as poss-arg12 and prep-arg12 do not corefer with each other enables us to use them to correctly eliminate the number of antecedent candidates .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
For instance , two such truncated forms definitely cannot be antecedent of the protein in this context two such truncated forms of the protein
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
For instance , two such truncated forms definitely cannot be antecedent of the protein in this context two such truncated forms of the protein
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
This is exactly what our system does .
#<struct ReadData::Alignment source_numbers="1", target_numbers="2", tag_name="wa">
This is exactly what our system does .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
This is exactly what our system does .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
This is exactly what our system does .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
This is exactly what our system does .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
This is exactly what our system does .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
This is exactly what our system does .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
This is exactly what our system does .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
This is exactly what our system does .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
However , a disadvantage of this method is when the parser makes mistake on finding the correct arguments , coreference also fails , as in the example " . . .of transcription factor NF-kappa B also encodes a p70 I kappa B protein , I kappa B gamma , which is identical to the C-terminal 607 amino acids of . . . "
#<struct ReadData::Alignment source_numbers="52", target_numbers="4", tag_name="wa">
However , a disadvantage of this method is when the parser makes mistake on finding the correct arguments , coreference also fails , as in the example " . . .of transcription factor NF-kappa B also encodes a p70 I kappa B protein , I kappa B gamma , which is identical to the C-terminal 607 amino acids of . . . "
#<struct ReadData::Alignment source_numbers="37", target_numbers="14", tag_name="wa">
However , a disadvantage of this method is when the parser makes mistake on finding the correct arguments , coreference also fails , as in the example " . . .of transcription factor NF-kappa B also encodes a p70 I kappa B protein , I kappa B gamma , which is identical to the C-terminal 607 amino acids of . . . "
#<struct ReadData::Alignment source_numbers="53", target_numbers="22", tag_name="wa">
However , a disadvantage of this method is when the parser makes mistake on finding the correct arguments , coreference also fails , as in the example " . . .of transcription factor NF-kappa B also encodes a p70 I kappa B protein , I kappa B gamma , which is identical to the C-terminal 607 amino acids of . . . "
#<struct ReadData::Alignment source_numbers="61", target_numbers="26", tag_name="wa">
However , a disadvantage of this method is when the parser makes mistake on finding the correct arguments , coreference also fails , as in the example " . . .of transcription factor NF-kappa B also encodes a p70 I kappa B protein , I kappa B gamma , which is identical to the C-terminal 607 amino acids of . . . "
#<struct ReadData::Alignment source_numbers="50", target_numbers="28", tag_name="wa">
However , a disadvantage of this method is when the parser makes mistake on finding the correct arguments , coreference also fails , as in the example " . . .of transcription factor NF-kappa B also encodes a p70 I kappa B protein , I kappa B gamma , which is identical to the C-terminal 607 amino acids of . . . "
#<struct ReadData::Alignment source_numbers="24", target_numbers="30", tag_name="wa">
However , a disadvantage of this method is when the parser makes mistake on finding the correct arguments , coreference also fails , as in the example " . . .of transcription factor NF-kappa B also encodes a p70 I kappa B protein , I kappa B gamma , which is identical to the C-terminal 607 amino acids of . . . "
#<struct ReadData::Alignment source_numbers="25", target_numbers="31", tag_name="wa">
However , a disadvantage of this method is when the parser makes mistake on finding the correct arguments , coreference also fails , as in the example " . . .of transcription factor NF-kappa B also encodes a p70 I kappa B protein , I kappa B gamma , which is identical to the C-terminal 607 amino acids of . . . "
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
However , a disadvantage of this method is when the parser makes mistake on finding the correct arguments , coreference also fails , as in the example " . . .of transcription factor NF-kappa B also encodes a p70 I kappa B protein , I kappa B gamma , which is identical to the C-terminal 607 amino acids of . . . "
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
However , a disadvantage of this method is when the parser makes mistake on finding the correct arguments , coreference also fails , as in the example " . . .of transcription factor NF-kappa B also encodes a p70 I kappa B protein , I kappa B gamma , which is identical to the C-terminal 607 amino acids of . . . "
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
However , a disadvantage of this method is when the parser makes mistake on finding the correct arguments , coreference also fails , as in the example " . . .of transcription factor NF-kappa B also encodes a p70 I kappa B protein , I kappa B gamma , which is identical to the C-terminal 607 amino acids of . . . "
#<struct ReadData::Alignment source_numbers="26", target_numbers="", tag_name="wa">
However , a disadvantage of this method is when the parser makes mistake on finding the correct arguments , coreference also fails , as in the example " . . .of transcription factor NF-kappa B also encodes a p70 I kappa B protein , I kappa B gamma , which is identical to the C-terminal 607 amino acids of . . . "
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
However , a disadvantage of this method is when the parser makes mistake on finding the correct arguments , coreference also fails , as in the example " . . .of transcription factor NF-kappa B also encodes a p70 I kappa B protein , I kappa B gamma , which is identical to the C-terminal 607 amino acids of . . . "
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
However , a disadvantage of this method is when the parser makes mistake on finding the correct arguments , coreference also fails , as in the example " . . .of transcription factor NF-kappa B also encodes a p70 I kappa B protein , I kappa B gamma , which is identical to the C-terminal 607 amino acids of . . . "
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
However , a disadvantage of this method is when the parser makes mistake on finding the correct arguments , coreference also fails , as in the example " . . .of transcription factor NF-kappa B also encodes a p70 I kappa B protein , I kappa B gamma , which is identical to the C-terminal 607 amino acids of . . . "
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
However , a disadvantage of this method is when the parser makes mistake on finding the correct arguments , coreference also fails , as in the example " . . .of transcription factor NF-kappa B also encodes a p70 I kappa B protein , I kappa B gamma , which is identical to the C-terminal 607 amino acids of . . . "
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
However , a disadvantage of this method is when the parser makes mistake on finding the correct arguments , coreference also fails , as in the example " . . .of transcription factor NF-kappa B also encodes a p70 I kappa B protein , I kappa B gamma , which is identical to the C-terminal 607 amino acids of . . . "
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
However , a disadvantage of this method is when the parser makes mistake on finding the correct arguments , coreference also fails , as in the example " . . .of transcription factor NF-kappa B also encodes a p70 I kappa B protein , I kappa B gamma , which is identical to the C-terminal 607 amino acids of . . . "
#<struct ReadData::Alignment source_numbers="", target_numbers="44", tag_name="wa">
However , a disadvantage of this method is when the parser makes mistake on finding the correct arguments , coreference also fails , as in the example " . . .of transcription factor NF-kappa B also encodes a p70 I kappa B protein , I kappa B gamma , which is identical to the C-terminal 607 amino acids of . . . "
#<struct ReadData::Alignment source_numbers="", target_numbers="57", tag_name="wa">
However , a disadvantage of this method is when the parser makes mistake on finding the correct arguments , coreference also fails , as in the example " . . .of transcription factor NF-kappa B also encodes a p70 I kappa B protein , I kappa B gamma , which is identical to the C-terminal 607 amino acids of . . . "
#<struct ReadData::Alignment source_numbers="", target_numbers="59", tag_name="wa">
However , a disadvantage of this method is when the parser makes mistake on finding the correct arguments , coreference also fails , as in the example " . . .of transcription factor NF-kappa B also encodes a p70 I kappa B protein , I kappa B gamma , which is identical to the C-terminal 607 amino acids of . . . "
#<struct ReadData::Alignment source_numbers="", target_numbers="60", tag_name="wa">
However , a disadvantage of this method is when the parser makes mistake on finding the correct arguments , coreference also fails , as in the example " . . .of transcription factor NF-kappa B also encodes a p70 I kappa B protein , I kappa B gamma , which is identical to the C-terminal 607 amino acids of . . . "
#<struct ReadData::Alignment source_numbers="", target_numbers="68", tag_name="wa">
If one candidate satisfies and the other does not , the procedure ends with the result that the former will be preferable to the latter .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
If one candidate satisfies and the other does not , the procedure ends with the result that the former will be preferable to the latter .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
The rules are applied in a succession order one after another until the inequality occurs , or end of the rule list is reached .
#<struct ReadData::Alignment source_numbers="19", target_numbers="20", tag_name="wa">
The rules are applied in a succession order one after another until the inequality occurs , or end of the rule list is reached .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
The rules are applied in a succession order one after another until the inequality occurs , or end of the rule list is reached .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
The rules are applied in a succession order one after another until the inequality occurs , or end of the rule list is reached .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
The rules are applied in a succession order one after another until the inequality occurs , or end of the rule list is reached .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
The rules are applied in a succession order one after another until the inequality occurs , or end of the rule list is reached .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
The rules are applied in a succession order one after another until the inequality occurs , or end of the rule list is reached .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
The default rule of the procedure prefers the closer antecedent candidate .
#<struct ReadData::Alignment source_numbers="11", target_numbers="16", tag_name="wa">
The default rule of the procedure prefers the closer antecedent candidate .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
The default rule of the procedure prefers the closer antecedent candidate .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
The default rule of the procedure prefers the closer antecedent candidate .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
The default rule of the procedure prefers the closer antecedent candidate .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
The default rule of the procedure prefers the closer antecedent candidate .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
The default rule of the procedure prefers the closer antecedent candidate .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
The default rule of the procedure prefers the closer antecedent candidate .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
By definition , two coreferential expressions refer to the same thing , which implies a semantic-constraint on coreference relationship .
#<struct ReadData::Alignment source_numbers="8,9", target_numbers="6,7", tag_name="wa">
By definition , two coreferential expressions refer to the same thing , which implies a semantic-constraint on coreference relationship .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
By definition , two coreferential expressions refer to the same thing , which implies a semantic-constraint on coreference relationship .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
By definition , two coreferential expressions refer to the same thing , which implies a semantic-constraint on coreference relationship .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
In practice , this compatibility is checked based on a given taxonomy of semantic classes in the following manner : two semantic classes are considered compatible or agreed with each other , when they have synonym relation , e.g. , or hypernym-hyponym relation .
#<struct ReadData::Alignment source_numbers="38", target_numbers="", tag_name="wa">
In practice , this compatibility is checked based on a given taxonomy of semantic classes in the following manner : two semantic classes are considered compatible or agreed with each other , when they have synonym relation , e.g. , or hypernym-hyponym relation .
#<struct ReadData::Alignment source_numbers="39", target_numbers="", tag_name="wa">
In this work , we only focus on the Protein type , ignoring other possible semantic types , so we do not take the structure of taxonomy into account .
#<struct ReadData::Alignment source_numbers="21", target_numbers="25", tag_name="wa">
In this work , we only focus on the Protein type , ignoring other possible semantic types , so we do not take the structure of taxonomy into account .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
In this work , we only focus on the Protein type , ignoring other possible semantic types , so we do not take the structure of taxonomy into account .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
In this work , we only focus on the Protein type , ignoring other possible semantic types , so we do not take the structure of taxonomy into account .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
Thus , the likelihood that two expressions are semantically compatible is definitely beneficial for antecedent prediction , besides syntactic information .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Thus , the likelihood that two expressions are semantically compatible is definitely beneficial for antecedent prediction , besides syntactic information .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Thus , the likelihood that two expressions are semantically compatible is definitely beneficial for antecedent prediction , besides syntactic information .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Focusing on specific entity types , i.e. Protein type , helps us to find a proper method for determining the likelihood , and how to encode the likelihood in coreference resolution .
#<struct ReadData::Alignment source_numbers="21", target_numbers="7", tag_name="wa">
Focusing on specific entity types , i.e. Protein type , helps us to find a proper method for determining the likelihood , and how to encode the likelihood in coreference resolution .
#<struct ReadData::Alignment source_numbers="25", target_numbers="26", tag_name="wa">
Focusing on specific entity types , i.e. Protein type , helps us to find a proper method for determining the likelihood , and how to encode the likelihood in coreference resolution .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Focusing on specific entity types , i.e. Protein type , helps us to find a proper method for determining the likelihood , and how to encode the likelihood in coreference resolution .
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
Focusing on specific entity types , i.e. Protein type , helps us to find a proper method for determining the likelihood , and how to encode the likelihood in coreference resolution .
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
Focusing on specific entity types , i.e. Protein type , helps us to find a proper method for determining the likelihood , and how to encode the likelihood in coreference resolution .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
Focusing on specific entity types , i.e. Protein type , helps us to find a proper method for determining the likelihood , and how to encode the likelihood in coreference resolution .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
Focusing on specific entity types , i.e. Protein type , helps us to find a proper method for determining the likelihood , and how to encode the likelihood in coreference resolution .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
Focusing on specific entity types , i.e. Protein type , helps us to find a proper method for determining the likelihood , and how to encode the likelihood in coreference resolution .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
Since gold protein annotations are given , we can use them in combination with syntactic information to judge whether an expression is protein-referential expession or not .
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
Since gold protein annotations are given , we can use them in combination with syntactic information to judge whether an expression is protein-referential expession or not .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
In details , if an expression is a noun phrase with a single head word , and it contains a protein mention that completely overlaps with the head word , then the expression is classied as Protein .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
In details , if an expression is a noun phrase with a single head word , and it contains a protein mention that completely overlaps with the head word , then the expression is classied as Protein .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
In details , if an expression is a noun phrase with a single head word , and it contains a protein mention that completely overlaps with the head word , then the expression is classied as Protein .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
In details , if an expression is a noun phrase with a single head word , and it contains a protein mention that completely overlaps with the head word , then the expression is classied as Protein .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
In details , if an expression is a noun phrase with a single head word , and it contains a protein mention that completely overlaps with the head word , then the expression is classied as Protein .
#<struct ReadData::Alignment source_numbers="34", target_numbers="", tag_name="wa">
In details , if an expression is a noun phrase with a single head word , and it contains a protein mention that completely overlaps with the head word , then the expression is classied as Protein .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
In details , if an expression is a noun phrase with a single head word , and it contains a protein mention that completely overlaps with the head word , then the expression is classied as Protein .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
Another case is when the head noun is either protein or gene , and has a protein mention as its premodifier , such as the Tax protein .
#<struct ReadData::Alignment source_numbers="21", target_numbers="3", tag_name="wa">
Another case is when the head noun is either protein or gene , and has a protein mention as its premodifier , such as the Tax protein .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Another case is when the head noun is either protein or gene , and has a protein mention as its premodifier , such as the Tax protein .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Another case is when the head noun is either protein or gene , and has a protein mention as its premodifier , such as the Tax protein .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Another case is when the head noun is either protein or gene , and has a protein mention as its premodifier , such as the Tax protein .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
Pronouns , in particular , possessive pronouns occupy the majority of anaphoric pronouns in biological texts ( Table 5 ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
However , they do not contain in themselves much useful information for the resolution , thus we need to exploit more information from its context [ 17 ] .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
However , they do not contain in themselves much useful information for the resolution , thus we need to exploit more information from its context [ 17 ] .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
However , they do not contain in themselves much useful information for the resolution , thus we need to exploit more information from its context [ 17 ] .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
However , they do not contain in themselves much useful information for the resolution , thus we need to exploit more information from its context [ 17 ] .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
We implemented a simple function to classify the semantic type of a possessive pronoun based on its context word .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
In particular , we check the noun phrase whose determiner is its or their ; if the noun phrase contains a protein key word then the inclusive pronoun is classified into the Protein semantic type .
#<struct ReadData::Alignment source_numbers="31", target_numbers="10", tag_name="wa">
In particular , we check the noun phrase whose determiner is its or their ; if the noun phrase contains a protein key word then the inclusive pronoun is classified into the Protein semantic type .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
In particular , we check the noun phrase whose determiner is its or their ; if the noun phrase contains a protein key word then the inclusive pronoun is classified into the Protein semantic type .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
In particular , we check the noun phrase whose determiner is its or their ; if the noun phrase contains a protein key word then the inclusive pronoun is classified into the Protein semantic type .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
In particular , we check the noun phrase whose determiner is its or their ; if the noun phrase contains a protein key word then the inclusive pronoun is classified into the Protein semantic type .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
In particular , we check the noun phrase whose determiner is its or their ; if the noun phrase contains a protein key word then the inclusive pronoun is classified into the Protein semantic type .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
protein key words can be a verb , a noun or an adjective that coocurred with protein mentions and can be used as a clue to distinguish the protein type from other semantic types .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
protein key words can be a verb , a noun or an adjective that coocurred with protein mentions and can be used as a clue to distinguish the protein type from other semantic types .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
protein key words can be a verb , a noun or an adjective that coocurred with protein mentions and can be used as a clue to distinguish the protein type from other semantic types .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
protein key words can be a verb , a noun or an adjective that coocurred with protein mentions and can be used as a clue to distinguish the protein type from other semantic types .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
protein key words can be a verb , a noun or an adjective that coocurred with protein mentions and can be used as a clue to distinguish the protein type from other semantic types .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
For example , the word binding in the following noun phrases its heterodimeric binding partner , or its binding site is a good clue to infer that it must be a protein reference .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
For example , the word binding in the following noun phrases its heterodimeric binding partner , or its binding site is a good clue to infer that it must be a protein reference .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
For example , the word binding in the following noun phrases its heterodimeric binding partner , or its binding site is a good clue to infer that it must be a protein reference .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
For our preliminary experiment , we collect these key words manually by checking the noun phrases containing its and their in training data .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
For our preliminary experiment , we collect these key words manually by checking the noun phrases containing its and their in training data .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
For our preliminary experiment , we collect these key words manually by checking the noun phrases containing its and their in training data .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
For our preliminary experiment , we collect these key words manually by checking the noun phrases containing its and their in training data .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
Our final protein key word set includes 12 words : binding , expression , interaction , regulation , phosphatase activity , localization , gene , sequence , region , phosphorylation , transactivation , and transcription .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
Our final protein key word set includes 12 words : binding , expression , interaction , regulation , phosphatase activity , localization , gene , sequence , region , phosphorylation , transactivation , and transcription .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
Our final protein key word set includes 12 words : binding , expression , interaction , regulation , phosphatase activity , localization , gene , sequence , region , phosphorylation , transactivation , and transcription .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Coreferential definite noun phrases in text are used in broader meaning of coreference .
#<struct ReadData::Alignment source_numbers="7,8", target_numbers="7,8", tag_name="wa">
Coreferential definite noun phrases in text are used in broader meaning of coreference .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Coreferential definite noun phrases in text are used in broader meaning of coreference .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Coreferential definite noun phrases in text are used in broader meaning of coreference .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Coreferential definite noun phrases in text are used in broader meaning of coreference .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
In other words , their antecedents do not necessarily exist in the textual context ; in particular in biomedical scientific papers , many definite noun phrases do not have antecedents since the referred concepts can be anything understood by experts in the domain .
#<struct ReadData::Alignment source_numbers="21", target_numbers="17", tag_name="wa">
In other words , their antecedents do not necessarily exist in the textual context ; in particular in biomedical scientific papers , many definite noun phrases do not have antecedents since the referred concepts can be anything understood by experts in the domain .
#<struct ReadData::Alignment source_numbers="43", target_numbers="50", tag_name="wa">
In other words , their antecedents do not necessarily exist in the textual context ; in particular in biomedical scientific papers , many definite noun phrases do not have antecedents since the referred concepts can be anything understood by experts in the domain .
#<struct ReadData::Alignment source_numbers="32", target_numbers="", tag_name="wa">
In other words , their antecedents do not necessarily exist in the textual context ; in particular in biomedical scientific papers , many definite noun phrases do not have antecedents since the referred concepts can be anything understood by experts in the domain .
#<struct ReadData::Alignment source_numbers="35", target_numbers="", tag_name="wa">
In other words , their antecedents do not necessarily exist in the textual context ; in particular in biomedical scientific papers , many definite noun phrases do not have antecedents since the referred concepts can be anything understood by experts in the domain .
#<struct ReadData::Alignment source_numbers="36", target_numbers="", tag_name="wa">
In other words , their antecedents do not necessarily exist in the textual context ; in particular in biomedical scientific papers , many definite noun phrases do not have antecedents since the referred concepts can be anything understood by experts in the domain .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
In other words , their antecedents do not necessarily exist in the textual context ; in particular in biomedical scientific papers , many definite noun phrases do not have antecedents since the referred concepts can be anything understood by experts in the domain .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
In other words , their antecedents do not necessarily exist in the textual context ; in particular in biomedical scientific papers , many definite noun phrases do not have antecedents since the referred concepts can be anything understood by experts in the domain .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
In other words , their antecedents do not necessarily exist in the textual context ; in particular in biomedical scientific papers , many definite noun phrases do not have antecedents since the referred concepts can be anything understood by experts in the domain .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
In other words , their antecedents do not necessarily exist in the textual context ; in particular in biomedical scientific papers , many definite noun phrases do not have antecedents since the referred concepts can be anything understood by experts in the domain .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
In other words , their antecedents do not necessarily exist in the textual context ; in particular in biomedical scientific papers , many definite noun phrases do not have antecedents since the referred concepts can be anything understood by experts in the domain .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
In other words , their antecedents do not necessarily exist in the textual context ; in particular in biomedical scientific papers , many definite noun phrases do not have antecedents since the referred concepts can be anything understood by experts in the domain .
#<struct ReadData::Alignment source_numbers="", target_numbers="40", tag_name="wa">
In other words , their antecedents do not necessarily exist in the textual context ; in particular in biomedical scientific papers , many definite noun phrases do not have antecedents since the referred concepts can be anything understood by experts in the domain .
#<struct ReadData::Alignment source_numbers="", target_numbers="41", tag_name="wa">
In other words , their antecedents do not necessarily exist in the textual context ; in particular in biomedical scientific papers , many definite noun phrases do not have antecedents since the referred concepts can be anything understood by experts in the domain .
#<struct ReadData::Alignment source_numbers="", target_numbers="44", tag_name="wa">
In other words , their antecedents do not necessarily exist in the textual context ; in particular in biomedical scientific papers , many definite noun phrases do not have antecedents since the referred concepts can be anything understood by experts in the domain .
#<struct ReadData::Alignment source_numbers="", target_numbers="45", tag_name="wa">
Distinguishing such non-anaphoric definite noun phrases from anaphoric ones is an uneasy task .
#<struct ReadData::Alignment source_numbers="9,10", target_numbers="9,10", tag_name="wa">
Distinguishing such non-anaphoric definite noun phrases from anaphoric ones is an uneasy task .
#<struct ReadData::Alignment source_numbers="11", target_numbers="11", tag_name="wa">
Knowing their semantic type helps to filter out irrelevant candidate antecedents , increasing chance to pick up the right antecedent or the precision of antecedent prediction .
#<struct ReadData::Alignment source_numbers="21", target_numbers="14", tag_name="wa">
Knowing their semantic type helps to filter out irrelevant candidate antecedents , increasing chance to pick up the right antecedent or the precision of antecedent prediction .
#<struct ReadData::Alignment source_numbers="13,14", target_numbers="15,16", tag_name="wa">
Knowing their semantic type helps to filter out irrelevant candidate antecedents , increasing chance to pick up the right antecedent or the precision of antecedent prediction .
#<struct ReadData::Alignment source_numbers="15", target_numbers="17", tag_name="wa">
Knowing their semantic type helps to filter out irrelevant candidate antecedents , increasing chance to pick up the right antecedent or the precision of antecedent prediction .
#<struct ReadData::Alignment source_numbers="26", target_numbers="30", tag_name="wa">
Knowing their semantic type helps to filter out irrelevant candidate antecedents , increasing chance to pick up the right antecedent or the precision of antecedent prediction .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
Knowing their semantic type helps to filter out irrelevant candidate antecedents , increasing chance to pick up the right antecedent or the precision of antecedent prediction .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
Knowing their semantic type helps to filter out irrelevant candidate antecedents , increasing chance to pick up the right antecedent or the precision of antecedent prediction .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
Knowing their semantic type helps to filter out irrelevant candidate antecedents , increasing chance to pick up the right antecedent or the precision of antecedent prediction .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
Knowing their semantic type helps to filter out irrelevant candidate antecedents , increasing chance to pick up the right antecedent or the precision of antecedent prediction .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
Knowing their semantic type helps to filter out irrelevant candidate antecedents , increasing chance to pick up the right antecedent or the precision of antecedent prediction .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
We tested two different head word lists : one is built automatically from the gold anaphoric nominals in gold data , the other word list contains top seven common head words : protein , gene , factor , molecule , element , family , inhibitor , and receptor .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
We tested two different head word lists : one is built automatically from the gold anaphoric nominals in gold data , the other word list contains top seven common head words : protein , gene , factor , molecule , element , family , inhibitor , and receptor .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
Those candidates which are not agree with the anaphor in semantics are filtered out .
#<struct ReadData::Alignment source_numbers="2,3", target_numbers="2,3", tag_name="wa">
Our minimal system configuration includes all the processing and filters from step 0 to step 3 as explained in the above section ( RB-MIN ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
For antecedent candidate selection , the window size used in step 4 is set to 2 , which means antecedent candidates are collected in the two nearest sentences from the anaphor , and the sentence embedding the anaphor .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
As the statistics measured on the training set of the corpus shows that 97 .0% percent of protein coreference links have antecedents appearing in within 2 sentences .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
As the statistics measured on the training set of the corpus shows that 97 .0% percent of protein coreference links have antecedents appearing in within 2 sentences .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
As the statistics measured on the training set of the corpus shows that 97 .0% percent of protein coreference links have antecedents appearing in within 2 sentences .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
The word list used to filter out anaphoric definite noun phrases in step 2 contains the following words : protein , gene , factor , molecule , element ,family , inhibitor , and receptor .
#<struct ReadData::Alignment source_numbers="31", target_numbers="28", tag_name="wa">
The word list used to filter out anaphoric definite noun phrases in step 2 contains the following words : protein , gene , factor , molecule , element ,family , inhibitor , and receptor .
#<struct ReadData::Alignment source_numbers="29", target_numbers="30", tag_name="wa">
The word list used to filter out anaphoric definite noun phrases in step 2 contains the following words : protein , gene , factor , molecule , element ,family , inhibitor , and receptor .
#<struct ReadData::Alignment source_numbers="28", target_numbers="", tag_name="wa">
The word list used to filter out anaphoric definite noun phrases in step 2 contains the following words : protein , gene , factor , molecule , element ,family , inhibitor , and receptor .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
The word list used to filter out anaphoric definite noun phrases in step 2 contains the following words : protein , gene , factor , molecule , element ,family , inhibitor , and receptor .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
Besides , premodifiers of definite noun phrases are also limited to numbers and popular premodifiers of proteins such as nuclear , transcription .
#<struct ReadData::Alignment source_numbers="1", target_numbers="15", tag_name="wa">
Besides , premodifiers of definite noun phrases are also limited to numbers and popular premodifiers of proteins such as nuclear , transcription .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Besides , premodifiers of definite noun phrases are also limited to numbers and popular premodifiers of proteins such as nuclear , transcription .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Besides , premodifiers of definite noun phrases are also limited to numbers and popular premodifiers of proteins such as nuclear , transcription .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Besides , premodifiers of definite noun phrases are also limited to numbers and popular premodifiers of proteins such as nuclear , transcription .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
To keep the minimal configuration simple , step 4 - antecedent selection of the baseline only uses the default comparison rule , which assures the closest antecedent candidate is selected .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
This primary evaluation method , which was particularly designed for the shared task , is based on protein coreference links automatically generated from manually annotated coreference links .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
This primary evaluation method , which was particularly designed for the shared task , is based on protein coreference links automatically generated from manually annotated coreference links .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
This primary evaluation method , which was particularly designed for the shared task , is based on protein coreference links automatically generated from manually annotated coreference links .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
Note that RB-MIN with minimal configuration already outperforms the best result by the UU team , with up to 7 .1% higher in Fscore .
#<struct ReadData::Alignment source_numbers="12", target_numbers="2", tag_name="wa">
Note that RB-MIN with minimal configuration already outperforms the best result by the UU team , with up to 7 .1% higher in Fscore .
#<struct ReadData::Alignment source_numbers="15", target_numbers="9", tag_name="wa">
Note that RB-MIN with minimal configuration already outperforms the best result by the UU team , with up to 7 .1% higher in Fscore .
#<struct ReadData::Alignment source_numbers="21", target_numbers="26", tag_name="wa">
Note that RB-MIN with minimal configuration already outperforms the best result by the UU team , with up to 7 .1% higher in Fscore .
#<struct ReadData::Alignment source_numbers="24", target_numbers="30", tag_name="wa">
Note that RB-MIN with minimal configuration already outperforms the best result by the UU team , with up to 7 .1% higher in Fscore .
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
Note that RB-MIN with minimal configuration already outperforms the best result by the UU team , with up to 7 .1% higher in Fscore .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Note that RB-MIN with minimal configuration already outperforms the best result by the UU team , with up to 7 .1% higher in Fscore .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Note that RB-MIN with minimal configuration already outperforms the best result by the UU team , with up to 7 .1% higher in Fscore .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
Note that RB-MIN with minimal configuration already outperforms the best result by the UU team , with up to 7 .1% higher in Fscore .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Note that RB-MIN with minimal configuration already outperforms the best result by the UU team , with up to 7 .1% higher in Fscore .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
Note that RB-MIN with minimal configuration already outperforms the best result by the UU team , with up to 7 .1% higher in Fscore .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
Note that RB-MIN with minimal configuration already outperforms the best result by the UU team , with up to 7 .1% higher in Fscore .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
Since RB-MIN uses similar preprocessing tools as UU [ 11 ] , but less information in antecedent prediction , this gap in performance is supposed to be caused by the different markable detection methods .
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
Since RB-MIN uses similar preprocessing tools as UU [ 11 ] , but less information in antecedent prediction , this gap in performance is supposed to be caused by the different markable detection methods .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
Since RB-MIN uses similar preprocessing tools as UU [ 11 ] , but less information in antecedent prediction , this gap in performance is supposed to be caused by the different markable detection methods .
#<struct ReadData::Alignment source_numbers="26", target_numbers="", tag_name="wa">
Since RB-MIN uses similar preprocessing tools as UU [ 11 ] , but less information in antecedent prediction , this gap in performance is supposed to be caused by the different markable detection methods .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
Breaking down the system performance by types of anaphors gives us an insight into what have been solved by our methods , and what needs more improvement effort .
#<struct ReadData::Alignment source_numbers="9,10", target_numbers="11,12", tag_name="wa">
Breaking down the system performance by types of anaphors gives us an insight into what have been solved by our methods , and what needs more improvement effort .
#<struct ReadData::Alignment source_numbers="15,16", target_numbers="17,18", tag_name="wa">
Breaking down the system performance by types of anaphors gives us an insight into what have been solved by our methods , and what needs more improvement effort .
#<struct ReadData::Alignment source_numbers="17", target_numbers="21", tag_name="wa">
Breaking down the system performance by types of anaphors gives us an insight into what have been solved by our methods , and what needs more improvement effort .
#<struct ReadData::Alignment source_numbers="18", target_numbers="22", tag_name="wa">
Breaking down the system performance by types of anaphors gives us an insight into what have been solved by our methods , and what needs more improvement effort .
#<struct ReadData::Alignment source_numbers="19", target_numbers="23", tag_name="wa">
Breaking down the system performance by types of anaphors gives us an insight into what have been solved by our methods , and what needs more improvement effort .
#<struct ReadData::Alignment source_numbers="20", target_numbers="24", tag_name="wa">
Breaking down the system performance by types of anaphors gives us an insight into what have been solved by our methods , and what needs more improvement effort .
#<struct ReadData::Alignment source_numbers="21", target_numbers="25", tag_name="wa">
Breaking down the system performance by types of anaphors gives us an insight into what have been solved by our methods , and what needs more improvement effort .
#<struct ReadData::Alignment source_numbers="22", target_numbers="26", tag_name="wa">
Breaking down the system performance by types of anaphors gives us an insight into what have been solved by our methods , and what needs more improvement effort .
#<struct ReadData::Alignment source_numbers="28", target_numbers="33", tag_name="wa">
Breaking down the system performance by types of anaphors gives us an insight into what have been solved by our methods , and what needs more improvement effort .
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
Breaking down the system performance by types of anaphors gives us an insight into what have been solved by our methods , and what needs more improvement effort .
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
Breaking down the system performance by types of anaphors gives us an insight into what have been solved by our methods , and what needs more improvement effort .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
Breaking down the system performance by types of anaphors gives us an insight into what have been solved by our methods , and what needs more improvement effort .
#<struct ReadData::Alignment source_numbers="27", target_numbers="", tag_name="wa">
Breaking down the system performance by types of anaphors gives us an insight into what have been solved by our methods , and what needs more improvement effort .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Breaking down the system performance by types of anaphors gives us an insight into what have been solved by our methods , and what needs more improvement effort .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Breaking down the system performance by types of anaphors gives us an insight into what have been solved by our methods , and what needs more improvement effort .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Breaking down the system performance by types of anaphors gives us an insight into what have been solved by our methods , and what needs more improvement effort .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
Breaking down the system performance by types of anaphors gives us an insight into what have been solved by our methods , and what needs more improvement effort .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
Breaking down the system performance by types of anaphors gives us an insight into what have been solved by our methods , and what needs more improvement effort .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
Breaking down the system performance by types of anaphors gives us an insight into what have been solved by our methods , and what needs more improvement effort .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
Breaking down the system performance by types of anaphors gives us an insight into what have been solved by our methods , and what needs more improvement effort .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
Breaking down the system performance by types of anaphors gives us an insight into what have been solved by our methods , and what needs more improvement effort .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
Breaking down the system performance by types of anaphors gives us an insight into what have been solved by our methods , and what needs more improvement effort .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
However , it should be noted that our antecedent prediction for the RELAT type is based completely on the output of Enju parser for the RELAT type , so in order to improve this type of coreference , we have to find ways to overcome the parse errors on noun phrase boundary detection and relative clause attachment ( See section Discussions ) .
#<struct ReadData::Alignment source_numbers="45", target_numbers="21", tag_name="wa">
However , it should be noted that our antecedent prediction for the RELAT type is based completely on the output of Enju parser for the RELAT type , so in order to improve this type of coreference , we have to find ways to overcome the parse errors on noun phrase boundary detection and relative clause attachment ( See section Discussions ) .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
However , it should be noted that our antecedent prediction for the RELAT type is based completely on the output of Enju parser for the RELAT type , so in order to improve this type of coreference , we have to find ways to overcome the parse errors on noun phrase boundary detection and relative clause attachment ( See section Discussions ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
However , it should be noted that our antecedent prediction for the RELAT type is based completely on the output of Enju parser for the RELAT type , so in order to improve this type of coreference , we have to find ways to overcome the parse errors on noun phrase boundary detection and relative clause attachment ( See section Discussions ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="46", tag_name="wa">
The analysis results are given in section Discussions .
#<struct ReadData::Alignment source_numbers="1", target_numbers="1,2,3", tag_name="wa">
The analysis results are given in section Discussions .
#<struct ReadData::Alignment source_numbers="8", target_numbers="12", tag_name="wa">
The analysis results are given in section Discussions .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
The analysis results are given in section Discussions .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
The analysis results are given in section Discussions .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
The combination of rule 1 , 2 and 3 resulted in 62 .4% fscore ( RB-MIN+1 , 2 , 3 ) ( Table 3 ) In this configuration , rule 2 contribute to the increasement of 4 points Fscore on the development set , and 2 .3 points Fscore on the test set , when comparing RB-MIN+1 , 3 and RB-MIN+1 , 2 , 3 .
#<struct ReadData::Alignment source_numbers="31,32", target_numbers="32,33", tag_name="wa">
The combination of rule 1 , 2 and 3 resulted in 62 .4% fscore ( RB-MIN+1 , 2 , 3 ) ( Table 3 ) In this configuration , rule 2 contribute to the increasement of 4 points Fscore on the development set , and 2 .3 points Fscore on the test set , when comparing RB-MIN+1 , 3 and RB-MIN+1 , 2 , 3 .
#<struct ReadData::Alignment source_numbers="39,40,41", target_numbers="38,39,40", tag_name="wa">
The combination of rule 1 , 2 and 3 resulted in 62 .4% fscore ( RB-MIN+1 , 2 , 3 ) ( Table 3 ) In this configuration , rule 2 contribute to the increasement of 4 points Fscore on the development set , and 2 .3 points Fscore on the test set , when comparing RB-MIN+1 , 3 and RB-MIN+1 , 2 , 3 .
#<struct ReadData::Alignment source_numbers="45", target_numbers="44", tag_name="wa">
The combination of rule 1 , 2 and 3 resulted in 62 .4% fscore ( RB-MIN+1 , 2 , 3 ) ( Table 3 ) In this configuration , rule 2 contribute to the increasement of 4 points Fscore on the development set , and 2 .3 points Fscore on the test set , when comparing RB-MIN+1 , 3 and RB-MIN+1 , 2 , 3 .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
The combination of rule 1 , 2 and 3 resulted in 62 .4% fscore ( RB-MIN+1 , 2 , 3 ) ( Table 3 ) In this configuration , rule 2 contribute to the increasement of 4 points Fscore on the development set , and 2 .3 points Fscore on the test set , when comparing RB-MIN+1 , 3 and RB-MIN+1 , 2 , 3 .
#<struct ReadData::Alignment source_numbers="33", target_numbers="", tag_name="wa">
The combination of rule 1 , 2 and 3 resulted in 62 .4% fscore ( RB-MIN+1 , 2 , 3 ) ( Table 3 ) In this configuration , rule 2 contribute to the increasement of 4 points Fscore on the development set , and 2 .3 points Fscore on the test set , when comparing RB-MIN+1 , 3 and RB-MIN+1 , 2 , 3 .
#<struct ReadData::Alignment source_numbers="34", target_numbers="", tag_name="wa">
The combination of rule 1 , 2 and 3 resulted in 62 .4% fscore ( RB-MIN+1 , 2 , 3 ) ( Table 3 ) In this configuration , rule 2 contribute to the increasement of 4 points Fscore on the development set , and 2 .3 points Fscore on the test set , when comparing RB-MIN+1 , 3 and RB-MIN+1 , 2 , 3 .
#<struct ReadData::Alignment source_numbers="35", target_numbers="", tag_name="wa">
The combination of rule 1 , 2 and 3 resulted in 62 .4% fscore ( RB-MIN+1 , 2 , 3 ) ( Table 3 ) In this configuration , rule 2 contribute to the increasement of 4 points Fscore on the development set , and 2 .3 points Fscore on the test set , when comparing RB-MIN+1 , 3 and RB-MIN+1 , 2 , 3 .
#<struct ReadData::Alignment source_numbers="36", target_numbers="", tag_name="wa">
The combination of rule 1 , 2 and 3 resulted in 62 .4% fscore ( RB-MIN+1 , 2 , 3 ) ( Table 3 ) In this configuration , rule 2 contribute to the increasement of 4 points Fscore on the development set , and 2 .3 points Fscore on the test set , when comparing RB-MIN+1 , 3 and RB-MIN+1 , 2 , 3 .
#<struct ReadData::Alignment source_numbers="37", target_numbers="", tag_name="wa">
The combination of rule 1 , 2 and 3 resulted in 62 .4% fscore ( RB-MIN+1 , 2 , 3 ) ( Table 3 ) In this configuration , rule 2 contribute to the increasement of 4 points Fscore on the development set , and 2 .3 points Fscore on the test set , when comparing RB-MIN+1 , 3 and RB-MIN+1 , 2 , 3 .
#<struct ReadData::Alignment source_numbers="38", target_numbers="", tag_name="wa">
The combination of rule 1 , 2 and 3 resulted in 62 .4% fscore ( RB-MIN+1 , 2 , 3 ) ( Table 3 ) In this configuration , rule 2 contribute to the increasement of 4 points Fscore on the development set , and 2 .3 points Fscore on the test set , when comparing RB-MIN+1 , 3 and RB-MIN+1 , 2 , 3 .
#<struct ReadData::Alignment source_numbers="46", target_numbers="", tag_name="wa">
The combination of rule 1 , 2 and 3 resulted in 62 .4% fscore ( RB-MIN+1 , 2 , 3 ) ( Table 3 ) In this configuration , rule 2 contribute to the increasement of 4 points Fscore on the development set , and 2 .3 points Fscore on the test set , when comparing RB-MIN+1 , 3 and RB-MIN+1 , 2 , 3 .
#<struct ReadData::Alignment source_numbers="47", target_numbers="", tag_name="wa">
The combination of rule 1 , 2 and 3 resulted in 62 .4% fscore ( RB-MIN+1 , 2 , 3 ) ( Table 3 ) In this configuration , rule 2 contribute to the increasement of 4 points Fscore on the development set , and 2 .3 points Fscore on the test set , when comparing RB-MIN+1 , 3 and RB-MIN+1 , 2 , 3 .
#<struct ReadData::Alignment source_numbers="48", target_numbers="", tag_name="wa">
The combination of rule 1 , 2 and 3 resulted in 62 .4% fscore ( RB-MIN+1 , 2 , 3 ) ( Table 3 ) In this configuration , rule 2 contribute to the increasement of 4 points Fscore on the development set , and 2 .3 points Fscore on the test set , when comparing RB-MIN+1 , 3 and RB-MIN+1 , 2 , 3 .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
The combination of rule 1 , 2 and 3 resulted in 62 .4% fscore ( RB-MIN+1 , 2 , 3 ) ( Table 3 ) In this configuration , rule 2 contribute to the increasement of 4 points Fscore on the development set , and 2 .3 points Fscore on the test set , when comparing RB-MIN+1 , 3 and RB-MIN+1 , 2 , 3 .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
The combination of rule 1 , 2 and 3 resulted in 62 .4% fscore ( RB-MIN+1 , 2 , 3 ) ( Table 3 ) In this configuration , rule 2 contribute to the increasement of 4 points Fscore on the development set , and 2 .3 points Fscore on the test set , when comparing RB-MIN+1 , 3 and RB-MIN+1 , 2 , 3 .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
The combination of rule 1 , 2 and 3 resulted in 62 .4% fscore ( RB-MIN+1 , 2 , 3 ) ( Table 3 ) In this configuration , rule 2 contribute to the increasement of 4 points Fscore on the development set , and 2 .3 points Fscore on the test set , when comparing RB-MIN+1 , 3 and RB-MIN+1 , 2 , 3 .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
The combination of rule 1 , 2 and 3 resulted in 62 .4% fscore ( RB-MIN+1 , 2 , 3 ) ( Table 3 ) In this configuration , rule 2 contribute to the increasement of 4 points Fscore on the development set , and 2 .3 points Fscore on the test set , when comparing RB-MIN+1 , 3 and RB-MIN+1 , 2 , 3 .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
The combination of rule 1 , 2 and 3 resulted in 62 .4% fscore ( RB-MIN+1 , 2 , 3 ) ( Table 3 ) In this configuration , rule 2 contribute to the increasement of 4 points Fscore on the development set , and 2 .3 points Fscore on the test set , when comparing RB-MIN+1 , 3 and RB-MIN+1 , 2 , 3 .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
The combination of rule 1 , 2 and 3 resulted in 62 .4% fscore ( RB-MIN+1 , 2 , 3 ) ( Table 3 ) In this configuration , rule 2 contribute to the increasement of 4 points Fscore on the development set , and 2 .3 points Fscore on the test set , when comparing RB-MIN+1 , 3 and RB-MIN+1 , 2 , 3 .
#<struct ReadData::Alignment source_numbers="", target_numbers="45", tag_name="wa">
The combination of rule 1 , 2 and 3 resulted in 62 .4% fscore ( RB-MIN+1 , 2 , 3 ) ( Table 3 ) In this configuration , rule 2 contribute to the increasement of 4 points Fscore on the development set , and 2 .3 points Fscore on the test set , when comparing RB-MIN+1 , 3 and RB-MIN+1 , 2 , 3 .
#<struct ReadData::Alignment source_numbers="", target_numbers="46", tag_name="wa">
The combination of rule 1 , 2 and 3 resulted in 62 .4% fscore ( RB-MIN+1 , 2 , 3 ) ( Table 3 ) In this configuration , rule 2 contribute to the increasement of 4 points Fscore on the development set , and 2 .3 points Fscore on the test set , when comparing RB-MIN+1 , 3 and RB-MIN+1 , 2 , 3 .
#<struct ReadData::Alignment source_numbers="", target_numbers="47", tag_name="wa">
This gain is due to the fact that the rule ensures the semantic type of antecedents is the same as their anaphors , enabling the correct detection of antecedents .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
This gain is due to the fact that the rule ensures the semantic type of antecedents is the same as their anaphors , enabling the correct detection of antecedents .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
In other words , if anaphor is classified as a protein reference , then antecedent must also be a protein reference .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
( Coreference examples in this paper are represented as below : gold anaphoric and antecedent expressions are bracketed , antecedents before anaphors ; gold protein mentions are underlined ; and incorrect response antecedents are in italics . )
#<struct ReadData::Alignment source_numbers="34", target_numbers="8", tag_name="wa">
( Coreference examples in this paper are represented as below : gold anaphoric and antecedent expressions are bracketed , antecedents before anaphors ; gold protein mentions are underlined ; and incorrect response antecedents are in italics . )
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
( Coreference examples in this paper are represented as below : gold anaphoric and antecedent expressions are bracketed , antecedents before anaphors ; gold protein mentions are underlined ; and incorrect response antecedents are in italics . )
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
( Coreference examples in this paper are represented as below : gold anaphoric and antecedent expressions are bracketed , antecedents before anaphors ; gold protein mentions are underlined ; and incorrect response antecedents are in italics . )
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
( Coreference examples in this paper are represented as below : gold anaphoric and antecedent expressions are bracketed , antecedents before anaphors ; gold protein mentions are underlined ; and incorrect response antecedents are in italics . )
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
( Coreference examples in this paper are represented as below : gold anaphoric and antecedent expressions are bracketed , antecedents before anaphors ; gold protein mentions are underlined ; and incorrect response antecedents are in italics . )
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
( Coreference examples in this paper are represented as below : gold anaphoric and antecedent expressions are bracketed , antecedents before anaphors ; gold protein mentions are underlined ; and incorrect response antecedents are in italics . )
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
Meanwhile since this transcription factor is recognized as a protein reference , its closest protein antecedent IRF-1 was successfully detected by RB-FULL .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Another interesting example is
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Another interesting example is
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Although studies and a dominant negative form of its heterodimeric binding partner have been crossed out because of disagreement in numbers , and violation of abandoned syntactic constraints correspondingly , the system would return the incorrect antecedent apoptosis instead of c-Myc .
#<struct ReadData::Alignment source_numbers="29", target_numbers="28", tag_name="wa">
Although studies and a dominant negative form of its heterodimeric binding partner have been crossed out because of disagreement in numbers , and violation of abandoned syntactic constraints correspondingly , the system would return the incorrect antecedent apoptosis instead of c-Myc .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
In our system , domain-specific semantic information is ultilized at two places : anaphor selection and antecedent prediction .
#<struct ReadData::Alignment source_numbers="9,10", target_numbers="9,10", tag_name="wa">
In our system , domain-specific semantic information is ultilized at two places : anaphor selection and antecedent prediction .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
In our system , domain-specific semantic information is ultilized at two places : anaphor selection and antecedent prediction .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
The effect of semantic information in antecedent prediction has been analyzed in above section .
#<struct ReadData::Alignment source_numbers="13", target_numbers="12,13", tag_name="wa">
To classify anaphors into protein or non-protein reference , our system employs a head-word based classfier for definite noun phrases , DEFNP-ANA-SEM , and a context-based classifier for pronouns , PRO-ANA-SEM ( Section Methods ) .
#<struct ReadData::Alignment source_numbers="26", target_numbers="15", tag_name="wa">
To classify anaphors into protein or non-protein reference , our system employs a head-word based classfier for definite noun phrases , DEFNP-ANA-SEM , and a context-based classifier for pronouns , PRO-ANA-SEM ( Section Methods ) .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
To classify anaphors into protein or non-protein reference , our system employs a head-word based classfier for definite noun phrases , DEFNP-ANA-SEM , and a context-based classifier for pronouns , PRO-ANA-SEM ( Section Methods ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
Without limiting the number of anaphors by using semantic information-based filtering , the precision significantly drops , causing a big decrease in Fscore ( Table 4 , RB-FULL w / o DEFNP-ANA-SEM ) . .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
Without limiting the number of anaphors by using semantic information-based filtering , the precision significantly drops , causing a big decrease in Fscore ( Table 4 , RB-FULL w / o DEFNP-ANA-SEM ) . .
#<struct ReadData::Alignment source_numbers="28", target_numbers="", tag_name="wa">
Without limiting the number of anaphors by using semantic information-based filtering , the precision significantly drops , causing a big decrease in Fscore ( Table 4 , RB-FULL w / o DEFNP-ANA-SEM ) . .
#<struct ReadData::Alignment source_numbers="29", target_numbers="", tag_name="wa">
Without limiting the number of anaphors by using semantic information-based filtering , the precision significantly drops , causing a big decrease in Fscore ( Table 4 , RB-FULL w / o DEFNP-ANA-SEM ) . .
#<struct ReadData::Alignment source_numbers="30", target_numbers="", tag_name="wa">
Without limiting the number of anaphors by using semantic information-based filtering , the precision significantly drops , causing a big decrease in Fscore ( Table 4 , RB-FULL w / o DEFNP-ANA-SEM ) . .
#<struct ReadData::Alignment source_numbers="34", target_numbers="", tag_name="wa">
Without limiting the number of anaphors by using semantic information-based filtering , the precision significantly drops , causing a big decrease in Fscore ( Table 4 , RB-FULL w / o DEFNP-ANA-SEM ) . .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
Without limiting the number of anaphors by using semantic information-based filtering , the precision significantly drops , causing a big decrease in Fscore ( Table 4 , RB-FULL w / o DEFNP-ANA-SEM ) . .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
This is because the semantic filter is the only way to filter out definite noun phrase anaphors .
#<struct ReadData::Alignment source_numbers="0", target_numbers="0", tag_name="wa">
This is because the semantic filter is the only way to filter out definite noun phrase anaphors .
#<struct ReadData::Alignment source_numbers="2", target_numbers="3", tag_name="wa">
This is because the semantic filter is the only way to filter out definite noun phrase anaphors .
#<struct ReadData::Alignment source_numbers="10", target_numbers="4", tag_name="wa">
This is because the semantic filter is the only way to filter out definite noun phrase anaphors .
#<struct ReadData::Alignment source_numbers="7", target_numbers="5", tag_name="wa">
This is because the semantic filter is the only way to filter out definite noun phrase anaphors .
#<struct ReadData::Alignment source_numbers="17", target_numbers="22", tag_name="wa">
This is because the semantic filter is the only way to filter out definite noun phrase anaphors .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
This is because the semantic filter is the only way to filter out definite noun phrase anaphors .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
This is because the semantic filter is the only way to filter out definite noun phrase anaphors .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
This is because the semantic filter is the only way to filter out definite noun phrase anaphors .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
This is because the semantic filter is the only way to filter out definite noun phrase anaphors .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
In our system , contextual information of possessive pronouns is utilized through the protein key words ( Section Methods ) , and this contributed to 1 .8% gain in f-score ( Table 4 , RB-FULL w / o PRO-ANA-SEM ) .
#<struct ReadData::Alignment source_numbers="29", target_numbers="", tag_name="wa">
In our system , contextual information of possessive pronouns is utilized through the protein key words ( Section Methods ) , and this contributed to 1 .8% gain in f-score ( Table 4 , RB-FULL w / o PRO-ANA-SEM ) .
#<struct ReadData::Alignment source_numbers="35", target_numbers="", tag_name="wa">
In our system , contextual information of possessive pronouns is utilized through the protein key words ( Section Methods ) , and this contributed to 1 .8% gain in f-score ( Table 4 , RB-FULL w / o PRO-ANA-SEM ) .
#<struct ReadData::Alignment source_numbers="36", target_numbers="", tag_name="wa">
In our system , contextual information of possessive pronouns is utilized through the protein key words ( Section Methods ) , and this contributed to 1 .8% gain in f-score ( Table 4 , RB-FULL w / o PRO-ANA-SEM ) .
#<struct ReadData::Alignment source_numbers="37", target_numbers="", tag_name="wa">
In our system , contextual information of possessive pronouns is utilized through the protein key words ( Section Methods ) , and this contributed to 1 .8% gain in f-score ( Table 4 , RB-FULL w / o PRO-ANA-SEM ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
In our system , contextual information of possessive pronouns is utilized through the protein key words ( Section Methods ) , and this contributed to 1 .8% gain in f-score ( Table 4 , RB-FULL w / o PRO-ANA-SEM ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
This is an encouraging sign to seek for a systematic method to exploit and include such contextual information in coreference resolution .
#<struct ReadData::Alignment source_numbers="0", target_numbers="0", tag_name="wa">
This is an encouraging sign to seek for a systematic method to exploit and include such contextual information in coreference resolution .
#<struct ReadData::Alignment source_numbers="1,2", target_numbers="2,3", tag_name="wa">
This is an encouraging sign to seek for a systematic method to exploit and include such contextual information in coreference resolution .
#<struct ReadData::Alignment source_numbers="7", target_numbers="6", tag_name="wa">
This is an encouraging sign to seek for a systematic method to exploit and include such contextual information in coreference resolution .
#<struct ReadData::Alignment source_numbers="12,13", target_numbers="12,13", tag_name="wa">
This is an encouraging sign to seek for a systematic method to exploit and include such contextual information in coreference resolution .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
This is an encouraging sign to seek for a systematic method to exploit and include such contextual information in coreference resolution .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
This is an encouraging sign to seek for a systematic method to exploit and include such contextual information in coreference resolution .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
This is an encouraging sign to seek for a systematic method to exploit and include such contextual information in coreference resolution .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
This is an encouraging sign to seek for a systematic method to exploit and include such contextual information in coreference resolution .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
This is an encouraging sign to seek for a systematic method to exploit and include such contextual information in coreference resolution .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
This is an encouraging sign to seek for a systematic method to exploit and include such contextual information in coreference resolution .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
This is an encouraging sign to seek for a systematic method to exploit and include such contextual information in coreference resolution .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Below are the examples showing the effectiveness of semantic information from the context of pronouns .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Below are the examples showing the effectiveness of semantic information from the context of pronouns .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Below are the examples showing the effectiveness of semantic information from the context of pronouns .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
Below are the examples showing the effectiveness of semantic information from the context of pronouns .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
Below are the examples showing the effectiveness of semantic information from the context of pronouns .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Below are the examples showing the effectiveness of semantic information from the context of pronouns .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
Below are the examples showing the effectiveness of semantic information from the context of pronouns .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Below are the examples showing the effectiveness of semantic information from the context of pronouns .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Below are the examples showing the effectiveness of semantic information from the context of pronouns .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
In all the above examples , the appearance of words such as binding , transactivation , DNA target sequence in the noun phrases of which the anaphor plays a role as a determiner , is contextual indicator for the protein type .
#<struct ReadData::Alignment source_numbers="37", target_numbers="23", tag_name="wa">
In all the above examples , the appearance of words such as binding , transactivation , DNA target sequence in the noun phrases of which the anaphor plays a role as a determiner , is contextual indicator for the protein type .
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
In all the above examples , the appearance of words such as binding , transactivation , DNA target sequence in the noun phrases of which the anaphor plays a role as a determiner , is contextual indicator for the protein type .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
However , we found in the data several coreferential expressions violating this constraint .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
For instance , the anaphor and antecedent in the following :
#<struct ReadData::Alignment source_numbers="1", target_numbers="9", tag_name="wa">
For instance , the anaphor and antecedent in the following :
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
For instance , the anaphor and antecedent in the following :
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
For instance , the anaphor and antecedent in the following :
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
For instance , the anaphor and antecedent in the following :
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
For instance , the anaphor and antecedent in the following :
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
For instance , the anaphor and antecedent in the following :
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
For instance , the anaphor and antecedent in the following :
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
For instance , the anaphor and antecedent in the following :
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
For instance , the anaphor and antecedent in the following :
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
Therefore , when the proteins appear in premodifiers or postmodifers of noun phrases as [ cDNAs encoding EBF or a covalent homodimer of E47 ] in this example
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
In furture , corpus annotation and evaluation scheme should be revised for the ease of automation of coreference resolution .
#<struct ReadData::Alignment source_numbers="10", target_numbers="3,4", tag_name="wa">
In furture , corpus annotation and evaluation scheme should be revised for the ease of automation of coreference resolution .
#<struct ReadData::Alignment source_numbers="8", target_numbers="10", tag_name="wa">
In furture , corpus annotation and evaluation scheme should be revised for the ease of automation of coreference resolution .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
In furture , corpus annotation and evaluation scheme should be revised for the ease of automation of coreference resolution .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
In furture , corpus annotation and evaluation scheme should be revised for the ease of automation of coreference resolution .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
In furture , corpus annotation and evaluation scheme should be revised for the ease of automation of coreference resolution .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
In furture , corpus annotation and evaluation scheme should be revised for the ease of automation of coreference resolution .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
The following example shows a coordination-structured antecedent AML1 / CBF beta , C / EBP , Ets , c-Myb , HOX , and MZF-1 that was failed to be detected by the parser .
#<struct ReadData::Alignment source_numbers="26", target_numbers="25", tag_name="wa">
The following example shows a coordination-structured antecedent AML1 / CBF beta , C / EBP , Ets , c-Myb , HOX , and MZF-1 that was failed to be detected by the parser .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
Our work has confirmed again that domain knowledge is indispensable for coreference resolution .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
Our work has confirmed again that domain knowledge is indispensable for coreference resolution .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
Our work has confirmed again that domain knowledge is indispensable for coreference resolution .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Our work has confirmed again that domain knowledge is indispensable for coreference resolution .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Since the biologicaldomain has richer knowledge resources than any other domain , it would be interesting to continue studying how to exploit and employ domain-specific semantic information in coreference resolution for this domain .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Since the biologicaldomain has richer knowledge resources than any other domain , it would be interesting to continue studying how to exploit and employ domain-specific semantic information in coreference resolution for this domain .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Since the biologicaldomain has richer knowledge resources than any other domain , it would be interesting to continue studying how to exploit and employ domain-specific semantic information in coreference resolution for this domain .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
This subproblem is often thought as an easy task in coreference resolution systems , however , indeed it is an important subtask which strongly affects the performance of coreference system .
#<struct ReadData::Alignment source_numbers="15", target_numbers="15", tag_name="wa">
This subproblem is often thought as an easy task in coreference resolution systems , however , indeed it is an important subtask which strongly affects the performance of coreference system .
#<struct ReadData::Alignment source_numbers="13", target_numbers="18", tag_name="wa">
This subproblem is often thought as an easy task in coreference resolution systems , however , indeed it is an important subtask which strongly affects the performance of coreference system .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
This subproblem is often thought as an easy task in coreference resolution systems , however , indeed it is an important subtask which strongly affects the performance of coreference system .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
This subproblem is often thought as an easy task in coreference resolution systems , however , indeed it is an important subtask which strongly affects the performance of coreference system .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
This subproblem is often thought as an easy task in coreference resolution systems , however , indeed it is an important subtask which strongly affects the performance of coreference system .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
This subproblem is often thought as an easy task in coreference resolution systems , however , indeed it is an important subtask which strongly affects the performance of coreference system .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
This subproblem is often thought as an easy task in coreference resolution systems , however , indeed it is an important subtask which strongly affects the performance of coreference system .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
This subproblem is often thought as an easy task in coreference resolution systems , however , indeed it is an important subtask which strongly affects the performance of coreference system .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
This subproblem is often thought as an easy task in coreference resolution systems , however , indeed it is an important subtask which strongly affects the performance of coreference system .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
This subproblem is often thought as an easy task in coreference resolution systems , however , indeed it is an important subtask which strongly affects the performance of coreference system .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
Sticking to the gold data in the designing markable detection method as we did in this paper is one of the strategies .
#<struct ReadData::Alignment source_numbers="13", target_numbers="13", tag_name="wa">
Sticking to the gold data in the designing markable detection method as we did in this paper is one of the strategies .
#<struct ReadData::Alignment source_numbers="21", target_numbers="21", tag_name="wa">
Sticking to the gold data in the designing markable detection method as we did in this paper is one of the strategies .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
Sticking to the gold data in the designing markable detection method as we did in this paper is one of the strategies .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
Sticking to the gold data in the designing markable detection method as we did in this paper is one of the strategies .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
Sticking to the gold data in the designing markable detection method as we did in this paper is one of the strategies .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
Sticking to the gold data in the designing markable detection method as we did in this paper is one of the strategies .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Sticking to the gold data in the designing markable detection method as we did in this paper is one of the strategies .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
However , from another perspective , the perspective of coreference data creation , we should revise the markable annotations , for the sake of automatic and robust markable detection .
#<struct ReadData::Alignment source_numbers="15,16", target_numbers="10,11,12", tag_name="wa">
However , from another perspective , the perspective of coreference data creation , we should revise the markable annotations , for the sake of automatic and robust markable detection .
#<struct ReadData::Alignment source_numbers="14", target_numbers="15", tag_name="wa">
However , from another perspective , the perspective of coreference data creation , we should revise the markable annotations , for the sake of automatic and robust markable detection .
#<struct ReadData::Alignment source_numbers="29", target_numbers="23", tag_name="wa">
However , from another perspective , the perspective of coreference data creation , we should revise the markable annotations , for the sake of automatic and robust markable detection .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
However , from another perspective , the perspective of coreference data creation , we should revise the markable annotations , for the sake of automatic and robust markable detection .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
However , from another perspective , the perspective of coreference data creation , we should revise the markable annotations , for the sake of automatic and robust markable detection .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
However , from another perspective , the perspective of coreference data creation , we should revise the markable annotations , for the sake of automatic and robust markable detection .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
However , from another perspective , the perspective of coreference data creation , we should revise the markable annotations , for the sake of automatic and robust markable detection .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
However , from another perspective , the perspective of coreference data creation , we should revise the markable annotations , for the sake of automatic and robust markable detection .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
However , from another perspective , the perspective of coreference data creation , we should revise the markable annotations , for the sake of automatic and robust markable detection .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
However , from another perspective , the perspective of coreference data creation , we should revise the markable annotations , for the sake of automatic and robust markable detection .
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
However , from another perspective , the perspective of coreference data creation , we should revise the markable annotations , for the sake of automatic and robust markable detection .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
However , from another perspective , the perspective of coreference data creation , we should revise the markable annotations , for the sake of automatic and robust markable detection .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
As for the future , more effort should be spent on automating the semantic classification for coreference expressions using context .
#<struct ReadData::Alignment source_numbers="3", target_numbers="1", tag_name="wa">
As for the future , more effort should be spent on automating the semantic classification for coreference expressions using context .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
As for the future , more effort should be spent on automating the semantic classification for coreference expressions using context .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
As for the future , more effort should be spent on automating the semantic classification for coreference expressions using context .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
As for the future , more effort should be spent on automating the semantic classification for coreference expressions using context .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
As for the future , more effort should be spent on automating the semantic classification for coreference expressions using context .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
As for the future , more effort should be spent on automating the semantic classification for coreference expressions using context .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Furthermore , it would be interesting to test the results in this study in a machine learning framework .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
Furthermore , it would be interesting to test the results in this study in a machine learning framework .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
Furthermore , it would be interesting to test the results in this study in a machine learning framework .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
The success of corpus-based methods has made syntactically annotated corpora important resources for natural language processing .
#<struct ReadData::Alignment source_numbers="5", target_numbers="3,4", tag_name="wa">
The success of corpus-based methods has made syntactically annotated corpora important resources for natural language processing .
#<struct ReadData::Alignment source_numbers="16", target_numbers="21", tag_name="wa">
The success of corpus-based methods has made syntactically annotated corpora important resources for natural language processing .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
The success of corpus-based methods has made syntactically annotated corpora important resources for natural language processing .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
The success of corpus-based methods has made syntactically annotated corpora important resources for natural language processing .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
The success of corpus-based methods has made syntactically annotated corpora important resources for natural language processing .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
The success of corpus-based methods has made syntactically annotated corpora important resources for natural language processing .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
The success of corpus-based methods has made syntactically annotated corpora important resources for natural language processing .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
The success of corpus-based methods has made syntactically annotated corpora important resources for natural language processing .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
The success of corpus-based methods has made syntactically annotated corpora important resources for natural language processing .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
The success of corpus-based methods has made syntactically annotated corpora important resources for natural language processing .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
The success of corpus-based methods has made syntactically annotated corpora important resources for natural language processing .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
This is also a concern of Vietnamese Treebank ( VTB ) , the first and the only publicly available syntactically annotated corpus so far for the Vietnamese language .
#<struct ReadData::Alignment source_numbers="24", target_numbers="5", tag_name="wa">
This is also a concern of Vietnamese Treebank ( VTB ) , the first and the only publicly available syntactically annotated corpus so far for the Vietnamese language .
#<struct ReadData::Alignment source_numbers="15", target_numbers="6", tag_name="wa">
This is also a concern of Vietnamese Treebank ( VTB ) , the first and the only publicly available syntactically annotated corpus so far for the Vietnamese language .
#<struct ReadData::Alignment source_numbers="22,23", target_numbers="24,25", tag_name="wa">
This is also a concern of Vietnamese Treebank ( VTB ) , the first and the only publicly available syntactically annotated corpus so far for the Vietnamese language .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
This is also a concern of Vietnamese Treebank ( VTB ) , the first and the only publicly available syntactically annotated corpus so far for the Vietnamese language .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
This is also a concern of Vietnamese Treebank ( VTB ) , the first and the only publicly available syntactically annotated corpus so far for the Vietnamese language .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
This is also a concern of Vietnamese Treebank ( VTB ) , the first and the only publicly available syntactically annotated corpus so far for the Vietnamese language .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
Although word segmentation is straight-forward for space-delimited languages like English , this is not true for languages like Vietnamese of which no standard criterion for word segmentation exists .
#<struct ReadData::Alignment source_numbers="19,20", target_numbers="20,21", tag_name="wa">
Although word segmentation is straight-forward for space-delimited languages like English , this is not true for languages like Vietnamese of which no standard criterion for word segmentation exists .
#<struct ReadData::Alignment source_numbers="27", target_numbers="30", tag_name="wa">
Although word segmentation is straight-forward for space-delimited languages like English , this is not true for languages like Vietnamese of which no standard criterion for word segmentation exists .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
Although word segmentation is straight-forward for space-delimited languages like English , this is not true for languages like Vietnamese of which no standard criterion for word segmentation exists .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
Although word segmentation is straight-forward for space-delimited languages like English , this is not true for languages like Vietnamese of which no standard criterion for word segmentation exists .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
Although word segmentation is straight-forward for space-delimited languages like English , this is not true for languages like Vietnamese of which no standard criterion for word segmentation exists .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
Then , by combining and splitting the inconsistent annotations detected , we could observe the influence of different word segmentation criteria on automatic word segmentation , and the applications of word segmentation , including text classification and English-Vietnamese statistical machine translation .
#<struct ReadData::Alignment source_numbers="8", target_numbers="8", tag_name="wa">
Then , by combining and splitting the inconsistent annotations detected , we could observe the influence of different word segmentation criteria on automatic word segmentation , and the applications of word segmentation , including text classification and English-Vietnamese statistical machine translation .
#<struct ReadData::Alignment source_numbers="9", target_numbers="11", tag_name="wa">
Then , by combining and splitting the inconsistent annotations detected , we could observe the influence of different word segmentation criteria on automatic word segmentation , and the applications of word segmentation , including text classification and English-Vietnamese statistical machine translation .
#<struct ReadData::Alignment source_numbers="41", target_numbers="45", tag_name="wa">
Then , by combining and splitting the inconsistent annotations detected , we could observe the influence of different word segmentation criteria on automatic word segmentation , and the applications of word segmentation , including text classification and English-Vietnamese statistical machine translation .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Then , by combining and splitting the inconsistent annotations detected , we could observe the influence of different word segmentation criteria on automatic word segmentation , and the applications of word segmentation , including text classification and English-Vietnamese statistical machine translation .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Treebanks , corpora annotated with syntatic structures , have become more and more impor-tant for language processing .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Treebanks , corpora annotated with syntatic structures , have become more and more impor-tant for language processing .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
Treebanks , corpora annotated with syntatic structures , have become more and more impor-tant for language processing .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Treebanks , corpora annotated with syntatic structures , have become more and more impor-tant for language processing .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Treebanks , corpora annotated with syntatic structures , have become more and more impor-tant for language processing .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Treebanks , corpora annotated with syntatic structures , have become more and more impor-tant for language processing .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
To strengthen the automatic processing of the Vietnamese language , the Vietnamese treebank ( VTB ) has been built as a part of the national project `` Vietnamese language and speech processing ( VLSP ) '' ( Nguyen et al ., 2009b ) .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
To strengthen the automatic processing of the Vietnamese language , the Vietnamese treebank ( VTB ) has been built as a part of the national project `` Vietnamese language and speech processing ( VLSP ) '' ( Nguyen et al ., 2009b ) .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
To strengthen the automatic processing of the Vietnamese language , the Vietnamese treebank ( VTB ) has been built as a part of the national project `` Vietnamese language and speech processing ( VLSP ) '' ( Nguyen et al ., 2009b ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
To strengthen the automatic processing of the Vietnamese language , the Vietnamese treebank ( VTB ) has been built as a part of the national project `` Vietnamese language and speech processing ( VLSP ) '' ( Nguyen et al ., 2009b ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
To strengthen the automatic processing of the Vietnamese language , the Vietnamese treebank ( VTB ) has been built as a part of the national project `` Vietnamese language and speech processing ( VLSP ) '' ( Nguyen et al ., 2009b ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
To strengthen the automatic processing of the Vietnamese language , the Vietnamese treebank ( VTB ) has been built as a part of the national project `` Vietnamese language and speech processing ( VLSP ) '' ( Nguyen et al ., 2009b ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
To strengthen the automatic processing of the Vietnamese language , the Vietnamese treebank ( VTB ) has been built as a part of the national project `` Vietnamese language and speech processing ( VLSP ) '' ( Nguyen et al ., 2009b ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
This performance is far lower than the state-of-the-art performance reported for Berkeley Parser on English Penn Treebank , 90 .3% in F-score ( Petrov et al ., 2006 ) .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
This performance is far lower than the state-of-the-art performance reported for Berkeley Parser on English Penn Treebank , 90 .3% in F-score ( Petrov et al ., 2006 ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
This performance is far lower than the state-of-the-art performance reported for Berkeley Parser on English Penn Treebank , 90 .3% in F-score ( Petrov et al ., 2006 ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
This performance is far lower than the state-of-the-art performance reported for Berkeley Parser on English Penn Treebank , 90 .3% in F-score ( Petrov et al ., 2006 ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
There are two possible reasons for this .
#<struct ReadData::Alignment source_numbers="4,5", target_numbers="4,5", tag_name="wa">
There are two possible reasons for this .
#<struct ReadData::Alignment source_numbers="6", target_numbers="7", tag_name="wa">
There are two possible reasons for this .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
There are two possible reasons for this .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
First , the quality of VTB is not good enough to build a good a parser , including the quality of the annotation scheme , the annotation guidelines , and the annotation process .
#<struct ReadData::Alignment source_numbers="6", target_numbers="5", tag_name="wa">
First , the quality of VTB is not good enough to build a good a parser , including the quality of the annotation scheme , the annotation guidelines , and the annotation process .
#<struct ReadData::Alignment source_numbers="16", target_numbers="10", tag_name="wa">
First , the quality of VTB is not good enough to build a good a parser , including the quality of the annotation scheme , the annotation guidelines , and the annotation process .
#<struct ReadData::Alignment source_numbers="17", target_numbers="11", tag_name="wa">
First , the quality of VTB is not good enough to build a good a parser , including the quality of the annotation scheme , the annotation guidelines , and the annotation process .
#<struct ReadData::Alignment source_numbers="18", target_numbers="12", tag_name="wa">
First , the quality of VTB is not good enough to build a good a parser , including the quality of the annotation scheme , the annotation guidelines , and the annotation process .
#<struct ReadData::Alignment source_numbers="19", target_numbers="13", tag_name="wa">
First , the quality of VTB is not good enough to build a good a parser , including the quality of the annotation scheme , the annotation guidelines , and the annotation process .
#<struct ReadData::Alignment source_numbers="20", target_numbers="14", tag_name="wa">
First , the quality of VTB is not good enough to build a good a parser , including the quality of the annotation scheme , the annotation guidelines , and the annotation process .
#<struct ReadData::Alignment source_numbers="21", target_numbers="15", tag_name="wa">
First , the quality of VTB is not good enough to build a good a parser , including the quality of the annotation scheme , the annotation guidelines , and the annotation process .
#<struct ReadData::Alignment source_numbers="22", target_numbers="16", tag_name="wa">
First , the quality of VTB is not good enough to build a good a parser , including the quality of the annotation scheme , the annotation guidelines , and the annotation process .
#<struct ReadData::Alignment source_numbers="23", target_numbers="17", tag_name="wa">
First , the quality of VTB is not good enough to build a good a parser , including the quality of the annotation scheme , the annotation guidelines , and the annotation process .
#<struct ReadData::Alignment source_numbers="24", target_numbers="18", tag_name="wa">
First , the quality of VTB is not good enough to build a good a parser , including the quality of the annotation scheme , the annotation guidelines , and the annotation process .
#<struct ReadData::Alignment source_numbers="25", target_numbers="19", tag_name="wa">
First , the quality of VTB is not good enough to build a good a parser , including the quality of the annotation scheme , the annotation guidelines , and the annotation process .
#<struct ReadData::Alignment source_numbers="26", target_numbers="20", tag_name="wa">
First , the quality of VTB is not good enough to build a good a parser , including the quality of the annotation scheme , the annotation guidelines , and the annotation process .
#<struct ReadData::Alignment source_numbers="27", target_numbers="21", tag_name="wa">
First , the quality of VTB is not good enough to build a good a parser , including the quality of the annotation scheme , the annotation guidelines , and the annotation process .
#<struct ReadData::Alignment source_numbers="28", target_numbers="22", tag_name="wa">
First , the quality of VTB is not good enough to build a good a parser , including the quality of the annotation scheme , the annotation guidelines , and the annotation process .
#<struct ReadData::Alignment source_numbers="29", target_numbers="23", tag_name="wa">
First , the quality of VTB is not good enough to build a good a parser , including the quality of the annotation scheme , the annotation guidelines , and the annotation process .
#<struct ReadData::Alignment source_numbers="30", target_numbers="24", tag_name="wa">
First , the quality of VTB is not good enough to build a good a parser , including the quality of the annotation scheme , the annotation guidelines , and the annotation process .
#<struct ReadData::Alignment source_numbers="31", target_numbers="25", tag_name="wa">
First , the quality of VTB is not good enough to build a good a parser , including the quality of the annotation scheme , the annotation guidelines , and the annotation process .
#<struct ReadData::Alignment source_numbers="32", target_numbers="26", tag_name="wa">
First , the quality of VTB is not good enough to build a good a parser , including the quality of the annotation scheme , the annotation guidelines , and the annotation process .
#<struct ReadData::Alignment source_numbers="33", target_numbers="27", tag_name="wa">
First , the quality of VTB is not good enough to build a good a parser , including the quality of the annotation scheme , the annotation guidelines , and the annotation process .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
First , the quality of VTB is not good enough to build a good a parser , including the quality of the annotation scheme , the annotation guidelines , and the annotation process .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
First , the quality of VTB is not good enough to build a good a parser , including the quality of the annotation scheme , the annotation guidelines , and the annotation process .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
First , the quality of VTB is not good enough to build a good a parser , including the quality of the annotation scheme , the annotation guidelines , and the annotation process .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
First , the quality of VTB is not good enough to build a good a parser , including the quality of the annotation scheme , the annotation guidelines , and the annotation process .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
First , the quality of VTB is not good enough to build a good a parser , including the quality of the annotation scheme , the annotation guidelines , and the annotation process .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
First , the quality of VTB is not good enough to build a good a parser , including the quality of the annotation scheme , the annotation guidelines , and the annotation process .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
First , the quality of VTB is not good enough to build a good a parser , including the quality of the annotation scheme , the annotation guidelines , and the annotation process .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
First , the quality of VTB is not good enough to build a good a parser , including the quality of the annotation scheme , the annotation guidelines , and the annotation process .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
First , the quality of VTB is not good enough to build a good a parser , including the quality of the annotation scheme , the annotation guidelines , and the annotation process .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
First , the quality of VTB is not good enough to build a good a parser , including the quality of the annotation scheme , the annotation guidelines , and the annotation process .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
First , the quality of VTB is not good enough to build a good a parser , including the quality of the annotation scheme , the annotation guidelines , and the annotation process .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
First , the quality of VTB is not good enough to build a good a parser , including the quality of the annotation scheme , the annotation guidelines , and the annotation process .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
First , the quality of VTB is not good enough to build a good a parser , including the quality of the annotation scheme , the annotation guidelines , and the annotation process .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
First , the quality of VTB is not good enough to build a good a parser , including the quality of the annotation scheme , the annotation guidelines , and the annotation process .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Second , parsing Vietnamese is a diffcult problem by its own , and we need to seek new solutions to the problem .
#<struct ReadData::Alignment source_numbers="4", target_numbers="3", tag_name="wa">
Second , parsing Vietnamese is a diffcult problem by its own , and we need to seek new solutions to the problem .
#<struct ReadData::Alignment source_numbers="20", target_numbers="4", tag_name="wa">
Second , parsing Vietnamese is a diffcult problem by its own , and we need to seek new solutions to the problem .
#<struct ReadData::Alignment source_numbers="7", target_numbers="5,6", tag_name="wa">
Second , parsing Vietnamese is a diffcult problem by its own , and we need to seek new solutions to the problem .
#<struct ReadData::Alignment source_numbers="19", target_numbers="16", tag_name="wa">
Second , parsing Vietnamese is a diffcult problem by its own , and we need to seek new solutions to the problem .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Second , parsing Vietnamese is a diffcult problem by its own , and we need to seek new solutions to the problem .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Second , parsing Vietnamese is a diffcult problem by its own , and we need to seek new solutions to the problem .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Second , parsing Vietnamese is a diffcult problem by its own , and we need to seek new solutions to the problem .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
Second , parsing Vietnamese is a diffcult problem by its own , and we need to seek new solutions to the problem .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Second , parsing Vietnamese is a diffcult problem by its own , and we need to seek new solutions to the problem .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Second , parsing Vietnamese is a diffcult problem by its own , and we need to seek new solutions to the problem .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Second , parsing Vietnamese is a diffcult problem by its own , and we need to seek new solutions to the problem .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
Second , parsing Vietnamese is a diffcult problem by its own , and we need to seek new solutions to the problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Second , parsing Vietnamese is a diffcult problem by its own , and we need to seek new solutions to the problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Second , parsing Vietnamese is a diffcult problem by its own , and we need to seek new solutions to the problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Second , parsing Vietnamese is a diffcult problem by its own , and we need to seek new solutions to the problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Second , parsing Vietnamese is a diffcult problem by its own , and we need to seek new solutions to the problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Second , parsing Vietnamese is a diffcult problem by its own , and we need to seek new solutions to the problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
This paper focuses on the word segmentation issues since the most basic unit of a treebank is word ( Di Sciullo and Edwin , 1987 ) , and defining `` What are words ? '' is the first problem that a treebank has to solve ( Xia , 2000b ,a ; Sornlertlamvanich et al ., 1997 , 1999 ) .
#<struct ReadData::Alignment source_numbers="4", target_numbers="4", tag_name="wa">
This paper focuses on the word segmentation issues since the most basic unit of a treebank is word ( Di Sciullo and Edwin , 1987 ) , and defining `` What are words ? '' is the first problem that a treebank has to solve ( Xia , 2000b ,a ; Sornlertlamvanich et al ., 1997 , 1999 ) .
#<struct ReadData::Alignment source_numbers="5", target_numbers="5", tag_name="wa">
This paper focuses on the word segmentation issues since the most basic unit of a treebank is word ( Di Sciullo and Edwin , 1987 ) , and defining `` What are words ? '' is the first problem that a treebank has to solve ( Xia , 2000b ,a ; Sornlertlamvanich et al ., 1997 , 1999 ) .
#<struct ReadData::Alignment source_numbers="6", target_numbers="6", tag_name="wa">
This paper focuses on the word segmentation issues since the most basic unit of a treebank is word ( Di Sciullo and Edwin , 1987 ) , and defining `` What are words ? '' is the first problem that a treebank has to solve ( Xia , 2000b ,a ; Sornlertlamvanich et al ., 1997 , 1999 ) .
#<struct ReadData::Alignment source_numbers="56", target_numbers="7", tag_name="wa">
This paper focuses on the word segmentation issues since the most basic unit of a treebank is word ( Di Sciullo and Edwin , 1987 ) , and defining `` What are words ? '' is the first problem that a treebank has to solve ( Xia , 2000b ,a ; Sornlertlamvanich et al ., 1997 , 1999 ) .
#<struct ReadData::Alignment source_numbers="31", target_numbers="16", tag_name="wa">
This paper focuses on the word segmentation issues since the most basic unit of a treebank is word ( Di Sciullo and Edwin , 1987 ) , and defining `` What are words ? '' is the first problem that a treebank has to solve ( Xia , 2000b ,a ; Sornlertlamvanich et al ., 1997 , 1999 ) .
#<struct ReadData::Alignment source_numbers="32", target_numbers="17", tag_name="wa">
This paper focuses on the word segmentation issues since the most basic unit of a treebank is word ( Di Sciullo and Edwin , 1987 ) , and defining `` What are words ? '' is the first problem that a treebank has to solve ( Xia , 2000b ,a ; Sornlertlamvanich et al ., 1997 , 1999 ) .
#<struct ReadData::Alignment source_numbers="36", target_numbers="33", tag_name="wa">
This paper focuses on the word segmentation issues since the most basic unit of a treebank is word ( Di Sciullo and Edwin , 1987 ) , and defining `` What are words ? '' is the first problem that a treebank has to solve ( Xia , 2000b ,a ; Sornlertlamvanich et al ., 1997 , 1999 ) .
#<struct ReadData::Alignment source_numbers="37", target_numbers="34", tag_name="wa">
This paper focuses on the word segmentation issues since the most basic unit of a treebank is word ( Di Sciullo and Edwin , 1987 ) , and defining `` What are words ? '' is the first problem that a treebank has to solve ( Xia , 2000b ,a ; Sornlertlamvanich et al ., 1997 , 1999 ) .
#<struct ReadData::Alignment source_numbers="59", target_numbers="50", tag_name="wa">
This paper focuses on the word segmentation issues since the most basic unit of a treebank is word ( Di Sciullo and Edwin , 1987 ) , and defining `` What are words ? '' is the first problem that a treebank has to solve ( Xia , 2000b ,a ; Sornlertlamvanich et al ., 1997 , 1999 ) .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
This paper focuses on the word segmentation issues since the most basic unit of a treebank is word ( Di Sciullo and Edwin , 1987 ) , and defining `` What are words ? '' is the first problem that a treebank has to solve ( Xia , 2000b ,a ; Sornlertlamvanich et al ., 1997 , 1999 ) .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
This paper focuses on the word segmentation issues since the most basic unit of a treebank is word ( Di Sciullo and Edwin , 1987 ) , and defining `` What are words ? '' is the first problem that a treebank has to solve ( Xia , 2000b ,a ; Sornlertlamvanich et al ., 1997 , 1999 ) .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
This paper focuses on the word segmentation issues since the most basic unit of a treebank is word ( Di Sciullo and Edwin , 1987 ) , and defining `` What are words ? '' is the first problem that a treebank has to solve ( Xia , 2000b ,a ; Sornlertlamvanich et al ., 1997 , 1999 ) .
#<struct ReadData::Alignment source_numbers="30", target_numbers="", tag_name="wa">
This paper focuses on the word segmentation issues since the most basic unit of a treebank is word ( Di Sciullo and Edwin , 1987 ) , and defining `` What are words ? '' is the first problem that a treebank has to solve ( Xia , 2000b ,a ; Sornlertlamvanich et al ., 1997 , 1999 ) .
#<struct ReadData::Alignment source_numbers="33", target_numbers="", tag_name="wa">
This paper focuses on the word segmentation issues since the most basic unit of a treebank is word ( Di Sciullo and Edwin , 1987 ) , and defining `` What are words ? '' is the first problem that a treebank has to solve ( Xia , 2000b ,a ; Sornlertlamvanich et al ., 1997 , 1999 ) .
#<struct ReadData::Alignment source_numbers="38", target_numbers="", tag_name="wa">
This paper focuses on the word segmentation issues since the most basic unit of a treebank is word ( Di Sciullo and Edwin , 1987 ) , and defining `` What are words ? '' is the first problem that a treebank has to solve ( Xia , 2000b ,a ; Sornlertlamvanich et al ., 1997 , 1999 ) .
#<struct ReadData::Alignment source_numbers="39", target_numbers="", tag_name="wa">
This paper focuses on the word segmentation issues since the most basic unit of a treebank is word ( Di Sciullo and Edwin , 1987 ) , and defining `` What are words ? '' is the first problem that a treebank has to solve ( Xia , 2000b ,a ; Sornlertlamvanich et al ., 1997 , 1999 ) .
#<struct ReadData::Alignment source_numbers="40", target_numbers="", tag_name="wa">
This paper focuses on the word segmentation issues since the most basic unit of a treebank is word ( Di Sciullo and Edwin , 1987 ) , and defining `` What are words ? '' is the first problem that a treebank has to solve ( Xia , 2000b ,a ; Sornlertlamvanich et al ., 1997 , 1999 ) .
#<struct ReadData::Alignment source_numbers="41", target_numbers="", tag_name="wa">
This paper focuses on the word segmentation issues since the most basic unit of a treebank is word ( Di Sciullo and Edwin , 1987 ) , and defining `` What are words ? '' is the first problem that a treebank has to solve ( Xia , 2000b ,a ; Sornlertlamvanich et al ., 1997 , 1999 ) .
#<struct ReadData::Alignment source_numbers="42", target_numbers="", tag_name="wa">
This paper focuses on the word segmentation issues since the most basic unit of a treebank is word ( Di Sciullo and Edwin , 1987 ) , and defining `` What are words ? '' is the first problem that a treebank has to solve ( Xia , 2000b ,a ; Sornlertlamvanich et al ., 1997 , 1999 ) .
#<struct ReadData::Alignment source_numbers="43", target_numbers="", tag_name="wa">
This paper focuses on the word segmentation issues since the most basic unit of a treebank is word ( Di Sciullo and Edwin , 1987 ) , and defining `` What are words ? '' is the first problem that a treebank has to solve ( Xia , 2000b ,a ; Sornlertlamvanich et al ., 1997 , 1999 ) .
#<struct ReadData::Alignment source_numbers="44", target_numbers="", tag_name="wa">
This paper focuses on the word segmentation issues since the most basic unit of a treebank is word ( Di Sciullo and Edwin , 1987 ) , and defining `` What are words ? '' is the first problem that a treebank has to solve ( Xia , 2000b ,a ; Sornlertlamvanich et al ., 1997 , 1999 ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
This paper focuses on the word segmentation issues since the most basic unit of a treebank is word ( Di Sciullo and Edwin , 1987 ) , and defining `` What are words ? '' is the first problem that a treebank has to solve ( Xia , 2000b ,a ; Sornlertlamvanich et al ., 1997 , 1999 ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
This paper focuses on the word segmentation issues since the most basic unit of a treebank is word ( Di Sciullo and Edwin , 1987 ) , and defining `` What are words ? '' is the first problem that a treebank has to solve ( Xia , 2000b ,a ; Sornlertlamvanich et al ., 1997 , 1999 ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="47", tag_name="wa">
For languages like English , answering this question is almost trivial because the blank spaces denote word delimiters .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
For languages like English , answering this question is almost trivial because the blank spaces denote word delimiters .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
For languages like English , answering this question is almost trivial because the blank spaces denote word delimiters .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
For languages like English , answering this question is almost trivial because the blank spaces denote word delimiters .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
For languages like English , answering this question is almost trivial because the blank spaces denote word delimiters .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
For languages like English , answering this question is almost trivial because the blank spaces denote word delimiters .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
For languages like English , answering this question is almost trivial because the blank spaces denote word delimiters .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
For languages like English , answering this question is almost trivial because the blank spaces denote word delimiters .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
For example , the sentence `` H❅c sinh h❅c sinh h❅c ( students learn biology )1 '' is composed of three words `` h❅c sinh ( student ) '' , `` h❅c ( learn ) , '' and `` sinh h❅c ( biology ) ; '' Word segmentation is expected to break down the sentence at the boundaries of these words , not to split `` h❅c sinh ( student ) '' and `` sinh h❅c ( biology ) '' .
#<struct ReadData::Alignment source_numbers="61", target_numbers="22", tag_name="wa">
For example , the sentence `` H❅c sinh h❅c sinh h❅c ( students learn biology )1 '' is composed of three words `` h❅c sinh ( student ) '' , `` h❅c ( learn ) , '' and `` sinh h❅c ( biology ) ; '' Word segmentation is expected to break down the sentence at the boundaries of these words , not to split `` h❅c sinh ( student ) '' and `` sinh h❅c ( biology ) '' .
#<struct ReadData::Alignment source_numbers="80", target_numbers="46", tag_name="wa">
For example , the sentence `` H❅c sinh h❅c sinh h❅c ( students learn biology )1 '' is composed of three words `` h❅c sinh ( student ) '' , `` h❅c ( learn ) , '' and `` sinh h❅c ( biology ) ; '' Word segmentation is expected to break down the sentence at the boundaries of these words , not to split `` h❅c sinh ( student ) '' and `` sinh h❅c ( biology ) '' .
#<struct ReadData::Alignment source_numbers="62", target_numbers="63", tag_name="wa">
For example , the sentence `` H❅c sinh h❅c sinh h❅c ( students learn biology )1 '' is composed of three words `` h❅c sinh ( student ) '' , `` h❅c ( learn ) , '' and `` sinh h❅c ( biology ) ; '' Word segmentation is expected to break down the sentence at the boundaries of these words , not to split `` h❅c sinh ( student ) '' and `` sinh h❅c ( biology ) '' .
#<struct ReadData::Alignment source_numbers="63,64", target_numbers="64,65", tag_name="wa">
For example , the sentence `` H❅c sinh h❅c sinh h❅c ( students learn biology )1 '' is composed of three words `` h❅c sinh ( student ) '' , `` h❅c ( learn ) , '' and `` sinh h❅c ( biology ) ; '' Word segmentation is expected to break down the sentence at the boundaries of these words , not to split `` h❅c sinh ( student ) '' and `` sinh h❅c ( biology ) '' .
#<struct ReadData::Alignment source_numbers="44", target_numbers="", tag_name="wa">
For example , the sentence `` H❅c sinh h❅c sinh h❅c ( students learn biology )1 '' is composed of three words `` h❅c sinh ( student ) '' , `` h❅c ( learn ) , '' and `` sinh h❅c ( biology ) ; '' Word segmentation is expected to break down the sentence at the boundaries of these words , not to split `` h❅c sinh ( student ) '' and `` sinh h❅c ( biology ) '' .
#<struct ReadData::Alignment source_numbers="", target_numbers="62", tag_name="wa">
For example , the sentence `` H❅c sinh h❅c sinh h❅c ( students learn biology )1 '' is composed of three words `` h❅c sinh ( student ) '' , `` h❅c ( learn ) , '' and `` sinh h❅c ( biology ) ; '' Word segmentation is expected to break down the sentence at the boundaries of these words , not to split `` h❅c sinh ( student ) '' and `` sinh h❅c ( biology ) '' .
#<struct ReadData::Alignment source_numbers="", target_numbers="81", tag_name="wa">
In such context , the extracted words are more appropriate for building a dictionary than for corpus-based language processing , which are out of the focus of this paper .
#<struct ReadData::Alignment source_numbers="19", target_numbers="15", tag_name="wa">
In such context , the extracted words are more appropriate for building a dictionary than for corpus-based language processing , which are out of the focus of this paper .
#<struct ReadData::Alignment source_numbers="14", target_numbers="17", tag_name="wa">
In such context , the extracted words are more appropriate for building a dictionary than for corpus-based language processing , which are out of the focus of this paper .
#<struct ReadData::Alignment source_numbers="22,23", target_numbers="25,26", tag_name="wa">
In such context , the extracted words are more appropriate for building a dictionary than for corpus-based language processing , which are out of the focus of this paper .
#<struct ReadData::Alignment source_numbers="24", target_numbers="27", tag_name="wa">
In such context , the extracted words are more appropriate for building a dictionary than for corpus-based language processing , which are out of the focus of this paper .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
In such context , the extracted words are more appropriate for building a dictionary than for corpus-based language processing , which are out of the focus of this paper .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
In such context , the extracted words are more appropriate for building a dictionary than for corpus-based language processing , which are out of the focus of this paper .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
In such context , the extracted words are more appropriate for building a dictionary than for corpus-based language processing , which are out of the focus of this paper .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
Establishing a gold standard for Vietnamese word segmentation faces some diffcuties coming from the characteristics of the language .
#<struct ReadData::Alignment source_numbers="13", target_numbers="2", tag_name="wa">
Establishing a gold standard for Vietnamese word segmentation faces some diffcuties coming from the characteristics of the language .
#<struct ReadData::Alignment source_numbers="14", target_numbers="4", tag_name="wa">
Establishing a gold standard for Vietnamese word segmentation faces some diffcuties coming from the characteristics of the language .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Establishing a gold standard for Vietnamese word segmentation faces some diffcuties coming from the characteristics of the language .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Establishing a gold standard for Vietnamese word segmentation faces some diffcuties coming from the characteristics of the language .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Establishing a gold standard for Vietnamese word segmentation faces some diffcuties coming from the characteristics of the language .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
Establishing a gold standard for Vietnamese word segmentation faces some diffcuties coming from the characteristics of the language .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
Establishing a gold standard for Vietnamese word segmentation faces some diffcuties coming from the characteristics of the language .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Establishing a gold standard for Vietnamese word segmentation faces some diffcuties coming from the characteristics of the language .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Establishing a gold standard for Vietnamese word segmentation faces some diffcuties coming from the characteristics of the language .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Establishing a gold standard for Vietnamese word segmentation faces some diffcuties coming from the characteristics of the language .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Establishing a gold standard for Vietnamese word segmentation faces some diffcuties coming from the characteristics of the language .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Establishing a gold standard for Vietnamese word segmentation faces some diffcuties coming from the characteristics of the language .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Establishing a gold standard for Vietnamese word segmentation faces some diffcuties coming from the characteristics of the language .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
Establishing a gold standard for Vietnamese word segmentation faces some diffcuties coming from the characteristics of the language .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
Establishing a gold standard for Vietnamese word segmentation faces some diffcuties coming from the characteristics of the language .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
The diffculties of Vietnamese word segmentation have been recognized by many researchers ( Ha , 2003 ; Nguyen et al ., 2004 , 2006 ; Le et al ., 2010 ) .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
The diffculties of Vietnamese word segmentation have been recognized by many researchers ( Ha , 2003 ; Nguyen et al ., 2004 , 2006 ; Le et al ., 2010 ) .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
The diffculties of Vietnamese word segmentation have been recognized by many researchers ( Ha , 2003 ; Nguyen et al ., 2004 , 2006 ; Le et al ., 2010 ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
The diffculties of Vietnamese word segmentation have been recognized by many researchers ( Ha , 2003 ; Nguyen et al ., 2004 , 2006 ; Le et al ., 2010 ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Although most people agree that the Vietnamese language has two types of words : single and compound , there is little consensus on how to segment a sentence into words .
#<struct ReadData::Alignment source_numbers="24", target_numbers="23", tag_name="wa">
Although most people agree that the Vietnamese language has two types of words : single and compound , there is little consensus on how to segment a sentence into words .
#<struct ReadData::Alignment source_numbers="25", target_numbers="27", tag_name="wa">
Although most people agree that the Vietnamese language has two types of words : single and compound , there is little consensus on how to segment a sentence into words .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
Although most people agree that the Vietnamese language has two types of words : single and compound , there is little consensus on how to segment a sentence into words .
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
Although most people agree that the Vietnamese language has two types of words : single and compound , there is little consensus on how to segment a sentence into words .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
Although most people agree that the Vietnamese language has two types of words : single and compound , there is little consensus on how to segment a sentence into words .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
Although most people agree that the Vietnamese language has two types of words : single and compound , there is little consensus on how to segment a sentence into words .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
Although most people agree that the Vietnamese language has two types of words : single and compound , there is little consensus on how to segment a sentence into words .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
The disagreement is not only because of the different functions of blank spaces as mentioned above , but also because Vietnamese is not an inflectional language like English or Japanese , where morphological forms can be useful clues for word segmentation .
#<struct ReadData::Alignment source_numbers="26", target_numbers="29,30,31,32", tag_name="wa">
The disagreement is not only because of the different functions of blank spaces as mentioned above , but also because Vietnamese is not an inflectional language like English or Japanese , where morphological forms can be useful clues for word segmentation .
#<struct ReadData::Alignment source_numbers="38", target_numbers="33", tag_name="wa">
The disagreement is not only because of the different functions of blank spaces as mentioned above , but also because Vietnamese is not an inflectional language like English or Japanese , where morphological forms can be useful clues for word segmentation .
#<struct ReadData::Alignment source_numbers="41", target_numbers="49", tag_name="wa">
The disagreement is not only because of the different functions of blank spaces as mentioned above , but also because Vietnamese is not an inflectional language like English or Japanese , where morphological forms can be useful clues for word segmentation .
#<struct ReadData::Alignment source_numbers="35", target_numbers="", tag_name="wa">
The disagreement is not only because of the different functions of blank spaces as mentioned above , but also because Vietnamese is not an inflectional language like English or Japanese , where morphological forms can be useful clues for word segmentation .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
The disagreement is not only because of the different functions of blank spaces as mentioned above , but also because Vietnamese is not an inflectional language like English or Japanese , where morphological forms can be useful clues for word segmentation .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
The disagreement is not only because of the different functions of blank spaces as mentioned above , but also because Vietnamese is not an inflectional language like English or Japanese , where morphological forms can be useful clues for word segmentation .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
The disagreement is not only because of the different functions of blank spaces as mentioned above , but also because Vietnamese is not an inflectional language like English or Japanese , where morphological forms can be useful clues for word segmentation .
#<struct ReadData::Alignment source_numbers="", target_numbers="43", tag_name="wa">
The disagreement is not only because of the different functions of blank spaces as mentioned above , but also because Vietnamese is not an inflectional language like English or Japanese , where morphological forms can be useful clues for word segmentation .
#<struct ReadData::Alignment source_numbers="", target_numbers="46", tag_name="wa">
While the similar problems also happen with Chinese word segmentation ( Xia , 2000b ) , Vietnamese word segmentation may be more diffcult because the modern Vietnamese writing system is based on Latin characters , which represents the pronunciation but not the meaning of words .
#<struct ReadData::Alignment source_numbers="34", target_numbers="22", tag_name="wa">
While the similar problems also happen with Chinese word segmentation ( Xia , 2000b ) , Vietnamese word segmentation may be more diffcult because the modern Vietnamese writing system is based on Latin characters , which represents the pronunciation but not the meaning of words .
#<struct ReadData::Alignment source_numbers="36,37", target_numbers="36,37", tag_name="wa">
While the similar problems also happen with Chinese word segmentation ( Xia , 2000b ) , Vietnamese word segmentation may be more diffcult because the modern Vietnamese writing system is based on Latin characters , which represents the pronunciation but not the meaning of words .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
While the similar problems also happen with Chinese word segmentation ( Xia , 2000b ) , Vietnamese word segmentation may be more diffcult because the modern Vietnamese writing system is based on Latin characters , which represents the pronunciation but not the meaning of words .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
While the similar problems also happen with Chinese word segmentation ( Xia , 2000b ) , Vietnamese word segmentation may be more diffcult because the modern Vietnamese writing system is based on Latin characters , which represents the pronunciation but not the meaning of words .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
While the similar problems also happen with Chinese word segmentation ( Xia , 2000b ) , Vietnamese word segmentation may be more diffcult because the modern Vietnamese writing system is based on Latin characters , which represents the pronunciation but not the meaning of words .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
All these characteristics make it diffcult to perform word segmentation for Vietnamese both manually and automatically , and have resulted in different criteria for word segmenation .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
All these characteristics make it diffcult to perform word segmentation for Vietnamese both manually and automatically , and have resulted in different criteria for word segmenation .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
All these characteristics make it diffcult to perform word segmentation for Vietnamese both manually and automatically , and have resulted in different criteria for word segmenation .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
However , so far there have been few studies on the challenges in word segmentation , and the comparison of different word segmentation criteria .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
In this paper , a brief introduction of the Vietnamese treebank VTB and its annotation scheme are given in Section 2 .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
In this paper , a brief introduction of the Vietnamese treebank VTB and its annotation scheme are given in Section 2 .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
In this paper , a brief introduction of the Vietnamese treebank VTB and its annotation scheme are given in Section 2 .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
In this paper , a brief introduction of the Vietnamese treebank VTB and its annotation scheme are given in Section 2 .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
The rest , which can be considered as the most diffcult and controversial cases of word segmentation , were used to create different versions of the VTB corpus representing different word segmentation criteria .
#<struct ReadData::Alignment source_numbers="13,14", target_numbers="13,14", tag_name="wa">
The rest , which can be considered as the most diffcult and controversial cases of word segmentation , were used to create different versions of the VTB corpus representing different word segmentation criteria .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
The rest , which can be considered as the most diffcult and controversial cases of word segmentation , were used to create different versions of the VTB corpus representing different word segmentation criteria .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
The rest , which can be considered as the most diffcult and controversial cases of word segmentation , were used to create different versions of the VTB corpus representing different word segmentation criteria .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
Finally , we evaluated these criteria in automatic word segmentation , and its application in text classification and English-Vietnamese statistical machine translation in Section 4 .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
This study also promotes the computational linguistic studies on how to transfer methods developed for a popular language like English to a language that has not yet intensively studied .
#<struct ReadData::Alignment source_numbers="24", target_numbers="26", tag_name="wa">
This study also promotes the computational linguistic studies on how to transfer methods developed for a popular language like English to a language that has not yet intensively studied .
#<struct ReadData::Alignment source_numbers="25", target_numbers="27", tag_name="wa">
This study also promotes the computational linguistic studies on how to transfer methods developed for a popular language like English to a language that has not yet intensively studied .
#<struct ReadData::Alignment source_numbers="28", target_numbers="31", tag_name="wa">
This study also promotes the computational linguistic studies on how to transfer methods developed for a popular language like English to a language that has not yet intensively studied .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
This study also promotes the computational linguistic studies on how to transfer methods developed for a popular language like English to a language that has not yet intensively studied .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
This study also promotes the computational linguistic studies on how to transfer methods developed for a popular language like English to a language that has not yet intensively studied .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
Word segmentation in VTB aims to found a standard for word segmentation in a context of multi-level language processing .
#<struct ReadData::Alignment source_numbers="4,5", target_numbers="4,5", tag_name="wa">
Word segmentation in VTB aims to found a standard for word segmentation in a context of multi-level language processing .
#<struct ReadData::Alignment source_numbers="6", target_numbers="6", tag_name="wa">
VTB specifies 12 types of units that should be identified as words ( Table 1 ) ( Nguyen et al ., a ) , which can be divided into three groups : single , compound , and special `` words '' .
#<struct ReadData::Alignment source_numbers="27", target_numbers="27", tag_name="wa">
VTB specifies 12 types of units that should be identified as words ( Table 1 ) ( Nguyen et al ., a ) , which can be divided into three groups : single , compound , and special `` words '' .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
The terminology tokens refers to text spans separated with each other by blank spaces .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
The terminology tokens refers to text spans separated with each other by blank spaces .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
The terminology tokens refers to text spans separated with each other by blank spaces .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
The terminology tokens refers to text spans separated with each other by blank spaces .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Special `` words '' can be idioms , locutions , proper names , date times , numbers , symbols , sentence marks , foreign words , or abbreviations .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
Special `` words '' can be idioms , locutions , proper names , date times , numbers , symbols , sentence marks , foreign words , or abbreviations .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Special `` words '' can be idioms , locutions , proper names , date times , numbers , symbols , sentence marks , foreign words , or abbreviations .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
The segmentation of these types of words forms a basis for the POS tagging , with 18 different POS tags shown in Table 2 ( Nguyen et al ., c ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
Each unit in Table 1 goes with several example words of which English translations are given in parentheses .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Each unit in Table 1 goes with several example words of which English translations are given in parentheses .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
Each unit in Table 1 goes with several example words of which English translations are given in parentheses .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
Each unit in Table 1 goes with several example words of which English translations are given in parentheses .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Each unit in Table 1 goes with several example words of which English translations are given in parentheses .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Besides , we added a translation for each token when possible , so that the readers unfamiliar with Vietnamese can have an intuitive idea of how the compound words are formed .
#<struct ReadData::Alignment source_numbers="9,10", target_numbers="10,11", tag_name="wa">
Besides , we added a translation for each token when possible , so that the readers unfamiliar with Vietnamese can have an intuitive idea of how the compound words are formed .
#<struct ReadData::Alignment source_numbers="29", target_numbers="17", tag_name="wa">
Besides , we added a translation for each token when possible , so that the readers unfamiliar with Vietnamese can have an intuitive idea of how the compound words are formed .
#<struct ReadData::Alignment source_numbers="24,25", target_numbers="26,27,28", tag_name="wa">
Besides , we added a translation for each token when possible , so that the readers unfamiliar with Vietnamese can have an intuitive idea of how the compound words are formed .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Besides , we added a translation for each token when possible , so that the readers unfamiliar with Vietnamese can have an intuitive idea of how the compound words are formed .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Besides , we added a translation for each token when possible , so that the readers unfamiliar with Vietnamese can have an intuitive idea of how the compound words are formed .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Besides , we added a translation for each token when possible , so that the readers unfamiliar with Vietnamese can have an intuitive idea of how the compound words are formed .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
Besides , we added a translation for each token when possible , so that the readers unfamiliar with Vietnamese can have an intuitive idea of how the compound words are formed .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
However , for some tokens , we could not find any appropriate English translation , so we give it an empty translation marked with an asterisk .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
Note that a Vietnamese word or a token in context can have other meanings in addition to the given translations .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
A special type of words in Vietnamese is classifer noun , denoted by the part-of-speech Nc in Table 2 .
#<struct ReadData::Alignment source_numbers="0", target_numbers="0", tag_name="wa">
A special type of words in Vietnamese is classifer noun , denoted by the part-of-speech Nc in Table 2 .
#<struct ReadData::Alignment source_numbers="10", target_numbers="3", tag_name="wa">
A special type of words in Vietnamese is classifer noun , denoted by the part-of-speech Nc in Table 2 .
#<struct ReadData::Alignment source_numbers="11", target_numbers="4", tag_name="wa">
A special type of words in Vietnamese is classifer noun , denoted by the part-of-speech Nc in Table 2 .
#<struct ReadData::Alignment source_numbers="12", target_numbers="5", tag_name="wa">
A special type of words in Vietnamese is classifer noun , denoted by the part-of-speech Nc in Table 2 .
#<struct ReadData::Alignment source_numbers="13", target_numbers="6", tag_name="wa">
A special type of words in Vietnamese is classifer noun , denoted by the part-of-speech Nc in Table 2 .
#<struct ReadData::Alignment source_numbers="14", target_numbers="7", tag_name="wa">
A special type of words in Vietnamese is classifer noun , denoted by the part-of-speech Nc in Table 2 .
#<struct ReadData::Alignment source_numbers="15", target_numbers="8", tag_name="wa">
A special type of words in Vietnamese is classifer noun , denoted by the part-of-speech Nc in Table 2 .
#<struct ReadData::Alignment source_numbers="16", target_numbers="9", tag_name="wa">
A special type of words in Vietnamese is classifer noun , denoted by the part-of-speech Nc in Table 2 .
#<struct ReadData::Alignment source_numbers="17", target_numbers="10", tag_name="wa">
A special type of words in Vietnamese is classifer noun , denoted by the part-of-speech Nc in Table 2 .
#<struct ReadData::Alignment source_numbers="18", target_numbers="11", tag_name="wa">
A special type of words in Vietnamese is classifer noun , denoted by the part-of-speech Nc in Table 2 .
#<struct ReadData::Alignment source_numbers="7", target_numbers="13", tag_name="wa">
A special type of words in Vietnamese is classifer noun , denoted by the part-of-speech Nc in Table 2 .
#<struct ReadData::Alignment source_numbers="5", target_numbers="19", tag_name="wa">
A special type of words in Vietnamese is classifer noun , denoted by the part-of-speech Nc in Table 2 .
#<struct ReadData::Alignment source_numbers="6", target_numbers="20", tag_name="wa">
A special type of words in Vietnamese is classifer noun , denoted by the part-of-speech Nc in Table 2 .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
A special type of words in Vietnamese is classifer noun , denoted by the part-of-speech Nc in Table 2 .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
A special type of words in Vietnamese is classifer noun , denoted by the part-of-speech Nc in Table 2 .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
A special type of words in Vietnamese is classifer noun , denoted by the part-of-speech Nc in Table 2 .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Classifier nouns are specific to several Southeast Asian languages like Vietnamese and Thai .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
For example , the common noun `` bàn '' means tables in general , while `` cái bàn '' means a specific table similar to the table in English .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
In this section , we analyzed the VTB corpus to know whether the diffculties in Vietnamese word segmentation affected the quality of VTB annotations .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
In this section , we analyzed the VTB corpus to know whether the diffculties in Vietnamese word segmentation affected the quality of VTB annotations .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
In this section , we analyzed the VTB corpus to know whether the diffculties in Vietnamese word segmentation affected the quality of VTB annotations .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
In this section , we analyzed the VTB corpus to know whether the diffculties in Vietnamese word segmentation affected the quality of VTB annotations .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
The analysis results revealed several types of inconsistent annotations , which are also
#<struct ReadData::Alignment source_numbers="0", target_numbers="0", tag_name="wa">
The analysis results revealed several types of inconsistent annotations , which are also
#<struct ReadData::Alignment source_numbers="1", target_numbers="1", tag_name="wa">
The analysis results revealed several types of inconsistent annotations , which are also
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Our analysis is based on two types of inconsistency : variation and structural inconsistency , whose definitions and details are given below .
#<struct ReadData::Alignment source_numbers="15", target_numbers="15", tag_name="wa">
Our analysis is based on two types of inconsistency : variation and structural inconsistency , whose definitions and details are given below .
#<struct ReadData::Alignment source_numbers="19", target_numbers="16", tag_name="wa">
Our analysis is based on two types of inconsistency : variation and structural inconsistency , whose definitions and details are given below .
#<struct ReadData::Alignment source_numbers="16", target_numbers="17", tag_name="wa">
Our analysis is based on two types of inconsistency : variation and structural inconsistency , whose definitions and details are given below .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
Our analysis is based on two types of inconsistency : variation and structural inconsistency , whose definitions and details are given below .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
Our analysis is based on two types of inconsistency : variation and structural inconsistency , whose definitions and details are given below .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
Variation inconsistency : is a sequence of tokens which have more than one way of seg-mentation in the corpus .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
Variation inconsistency : is a sequence of tokens which have more than one way of seg-mentation in the corpus .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Variation inconsistency : is a sequence of tokens which have more than one way of seg-mentation in the corpus .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
For example , `` con gái/girl '' can remain as one word , or be segmented into two words `` con '' and `` gái '' .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
A variation can be an annotation inconsistency , or an ambiguity inVietnamese .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
A variation can be an annotation inconsistency , or an ambiguity inVietnamese .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
A variation can be an annotation inconsistency , or an ambiguity inVietnamese .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
While ambiguity cases reflect the diffculty of the language , annotation inconsistencies are usually caused by the confusion in the decision of annotators , which should be eliminated in annotation .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
While ambiguity cases reflect the diffculty of the language , annotation inconsistencies are usually caused by the confusion in the decision of annotators , which should be eliminated in annotation .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
We use the term variation instance to refer a single occurence of a variation .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
We use the term variation instance to refer a single occurence of a variation .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
For example , `` con gái/girl '' and `` con trai/boy '' have similar structures , a combination of a classifier noun and a common noun Nc + N , so when `` con gái/girl '' is splitted and `` con trai/boy '' is not , it is considered as a structural inconsistency of Nc .
#<struct ReadData::Alignment source_numbers="15", target_numbers="26", tag_name="wa">
For example , `` con gái/girl '' and `` con trai/boy '' have similar structures , a combination of a classifier noun and a common noun Nc + N , so when `` con gái/girl '' is splitted and `` con trai/boy '' is not , it is considered as a structural inconsistency of Nc .
#<struct ReadData::Alignment source_numbers="45", target_numbers="39", tag_name="wa">
For example , `` con gái/girl '' and `` con trai/boy '' have similar structures , a combination of a classifier noun and a common noun Nc + N , so when `` con gái/girl '' is splitted and `` con trai/boy '' is not , it is considered as a structural inconsistency of Nc .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
For example , `` con gái/girl '' and `` con trai/boy '' have similar structures , a combination of a classifier noun and a common noun Nc + N , so when `` con gái/girl '' is splitted and `` con trai/boy '' is not , it is considered as a structural inconsistency of Nc .
#<struct ReadData::Alignment source_numbers="", target_numbers="47", tag_name="wa">
It is likely that structural inconsistency in word segmentation level makes the higher levels of processing , POS tagging and bracketing , become more complicated .
#<struct ReadData::Alignment source_numbers="11", target_numbers="7", tag_name="wa">
It is likely that structural inconsistency in word segmentation level makes the higher levels of processing , POS tagging and bracketing , become more complicated .
#<struct ReadData::Alignment source_numbers="23,24", target_numbers="11,12", tag_name="wa">
It is likely that structural inconsistency in word segmentation level makes the higher levels of processing , POS tagging and bracketing , become more complicated .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
It is likely that structural inconsistency in word segmentation level makes the higher levels of processing , POS tagging and bracketing , become more complicated .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
It is likely that structural inconsistency in word segmentation level makes the higher levels of processing , POS tagging and bracketing , become more complicated .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
It is likely that structural inconsistency in word segmentation level makes the higher levels of processing , POS tagging and bracketing , become more complicated .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
It is likely that structural inconsistency in word segmentation level makes the higher levels of processing , POS tagging and bracketing , become more complicated .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
The detection method for variation inconsistency is based on N-gram sequences and the phrase structures in VTB treebank , following the definition of variation inconsistency above .
#<struct ReadData::Alignment source_numbers="16", target_numbers="17", tag_name="wa">
The detection method for variation inconsistency is based on N-gram sequences and the phrase structures in VTB treebank , following the definition of variation inconsistency above .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
The detection method for variation inconsistency is based on N-gram sequences and the phrase structures in VTB treebank , following the definition of variation inconsistency above .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
The detection method for variation inconsistency is based on N-gram sequences and the phrase structures in VTB treebank , following the definition of variation inconsistency above .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
The detection method for variation inconsistency is based on N-gram sequences and the phrase structures in VTB treebank , following the definition of variation inconsistency above .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
Table 3 shows the overall statistics of the variation inconsistency detected by the above method .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Most of the diffcult cases of word segmentation lie in two-token variations , occupying the majority of variations ( 92 .9% ) .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Most of the diffcult cases of word segmentation lie in two-token variations , occupying the majority of variations ( 92 .9% ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
This ratio of 2-gram variations is much higher than the evarage ratio of two-token words in Vietnamese reported in ( Nguyen et al., 2009a ) , which is 80% percent .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
This ratio of 2-gram variations is much higher than the evarage ratio of two-token words in Vietnamese reported in ( Nguyen et al., 2009a ) , which is 80% percent .
#<struct ReadData::Alignment source_numbers="29", target_numbers="", tag_name="wa">
This ratio of 2-gram variations is much higher than the evarage ratio of two-token words in Vietnamese reported in ( Nguyen et al., 2009a ) , which is 80% percent .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
This ratio of 2-gram variations is much higher than the evarage ratio of two-token words in Vietnamese reported in ( Nguyen et al., 2009a ) , which is 80% percent .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
This ratio of 2-gram variations is much higher than the evarage ratio of two-token words in Vietnamese reported in ( Nguyen et al., 2009a ) , which is 80% percent .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
Variations have lengths of three and four tokens occupy 6 .1% and 1 .0% , respectively .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
We estimated the precision of our method by randomly selected 130 2-gram variation instances extracted from the above method , and manually checked whether they are true inconsistency .
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
We estimated the precision of our method by randomly selected 130 2-gram variation instances extracted from the above method , and manually checked whether they are true inconsistency .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
We estimated the precision of our method by randomly selected 130 2-gram variation instances extracted from the above method , and manually checked whether they are true inconsistency .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
We estimated the precision of our method by randomly selected 130 2-gram variation instances extracted from the above method , and manually checked whether they are true inconsistency .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
We estimated the precision of our method by randomly selected 130 2-gram variation instances extracted from the above method , and manually checked whether they are true inconsistency .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
Only one instance is an ambiguous sequence giá c , which is one word when it means price , and two words giá / price c / all in đàu có giá c / all have ( their own ) price .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Only one instance is an ambiguous sequence giá c , which is one word when it means price , and two words giá / price c / all in đàu có giá c / all have ( their own ) price .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
The precision of our method is high enough so that so we can use the extracted variations to study the insights of word segmentation problem .
#<struct ReadData::Alignment source_numbers="19", target_numbers="19", tag_name="wa">
The precision of our method is high enough so that so we can use the extracted variations to study the insights of word segmentation problem .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
The precision of our method is high enough so that so we can use the extracted variations to study the insights of word segmentation problem .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
The precision of our method is high enough so that so we can use the extracted variations to study the insights of word segmentation problem .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
The precision of our method is high enough so that so we can use the extracted variations to study the insights of word segmentation problem .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
The precision of our method is high enough so that so we can use the extracted variations to study the insights of word segmentation problem .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
The precision of our method is high enough so that so we can use the extracted variations to study the insights of word segmentation problem .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
The precision of our method is high enough so that so we can use the extracted variations to study the insights of word segmentation problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
The precision of our method is high enough so that so we can use the extracted variations to study the insights of word segmentation problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
The precision of our method is high enough so that so we can use the extracted variations to study the insights of word segmentation problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
The precision of our method is high enough so that so we can use the extracted variations to study the insights of word segmentation problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
We further analyzed the 2-gram variations to know what types of 2-grams were most confusing to annotators .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
We further analyzed the 2-gram variations to know what types of 2-grams were most confusing to annotators .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
We further analyzed the 2-gram variations to know what types of 2-grams were most confusing to annotators .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
We further analyzed the 2-gram variations to know what types of 2-grams were most confusing to annotators .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
The analysis results showed that compound nouns , compound verbs , and compound adjectives are the top diffcult cases of word segmentation .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
The analysis results showed that compound nouns , compound verbs , and compound adjectives are the top diffcult cases of word segmentation .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
The analysis results showed that compound nouns , compound verbs , and compound adjectives are the top diffcult cases of word segmentation .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
The analysis results showed that compound nouns , compound verbs , and compound adjectives are the top diffcult cases of word segmentation .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
The analysis results showed that compound nouns , compound verbs , and compound adjectives are the top diffcult cases of word segmentation .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
There are totally 54 patterns of POS sequence , of which top 10 confusing patterns , a long with their counts of 2-gram variations , and examples are shown in Table 4 .
#<struct ReadData::Alignment source_numbers="16", target_numbers="2", tag_name="wa">
There are totally 54 patterns of POS sequence , of which top 10 confusing patterns , a long with their counts of 2-gram variations , and examples are shown in Table 4 .
#<struct ReadData::Alignment source_numbers="9", target_numbers="4", tag_name="wa">
There are totally 54 patterns of POS sequence , of which top 10 confusing patterns , a long with their counts of 2-gram variations , and examples are shown in Table 4 .
#<struct ReadData::Alignment source_numbers="32", target_numbers="10", tag_name="wa">
There are totally 54 patterns of POS sequence , of which top 10 confusing patterns , a long with their counts of 2-gram variations , and examples are shown in Table 4 .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
There are totally 54 patterns of POS sequence , of which top 10 confusing patterns , a long with their counts of 2-gram variations , and examples are shown in Table 4 .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
There are totally 54 patterns of POS sequence , of which top 10 confusing patterns , a long with their counts of 2-gram variations , and examples are shown in Table 4 .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
There are totally 54 patterns of POS sequence , of which top 10 confusing patterns , a long with their counts of 2-gram variations , and examples are shown in Table 4 .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
There are totally 54 patterns of POS sequence , of which top 10 confusing patterns , a long with their counts of 2-gram variations , and examples are shown in Table 4 .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
There are totally 54 patterns of POS sequence , of which top 10 confusing patterns , a long with their counts of 2-gram variations , and examples are shown in Table 4 .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
There are totally 54 patterns of POS sequence , of which top 10 confusing patterns , a long with their counts of 2-gram variations , and examples are shown in Table 4 .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
There are totally 54 patterns of POS sequence , of which top 10 confusing patterns , a long with their counts of 2-gram variations , and examples are shown in Table 4 .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
Table 5 and Table 6 show the POS patterns which a specific POS tag appearing at the beginning or ending of the sequence .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Table 5 and Table 6 show the POS patterns which a specific POS tag appearing at the beginning or ending of the sequence .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Table 5 and Table 6 show the POS patterns which a specific POS tag appearing at the beginning or ending of the sequence .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Table 5 and Table 6 show the POS patterns which a specific POS tag appearing at the beginning or ending of the sequence .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
Investigating the inconsistent 2-grams extracted , we found that most of them are compound words according to the VTB guidelines ( Section 2 ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
This can be seen through the examples given in Table 4 , where the meanings of tokens are given with a subscript .
#<struct ReadData::Alignment source_numbers="6,7", target_numbers="6,7", tag_name="wa">
This problem seems to have caused a lot of trouble for the annotators of VTB .
#<struct ReadData::Alignment source_numbers="5,6", target_numbers="2", tag_name="wa">
This problem seems to have caused a lot of trouble for the annotators of VTB .
#<struct ReadData::Alignment source_numbers="3", target_numbers="4", tag_name="wa">
This problem seems to have caused a lot of trouble for the annotators of VTB .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
This problem seems to have caused a lot of trouble for the annotators of VTB .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
This problem seems to have caused a lot of trouble for the annotators of VTB .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
This problem seems to have caused a lot of trouble for the annotators of VTB .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
This problem seems to have caused a lot of trouble for the annotators of VTB .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
This problem seems to have caused a lot of trouble for the annotators of VTB .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
This problem seems to have caused a lot of trouble for the annotators of VTB .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
This problem seems to have caused a lot of trouble for the annotators of VTB .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
This problem seems to have caused a lot of trouble for the annotators of VTB .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
This problem seems to have caused a lot of trouble for the annotators of VTB .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Furthermore , observing the POS patterns in Table 5 and Table 6 , we can see the potential of structural inconsistency , in particular for closed-set POS tags .
#<struct ReadData::Alignment source_numbers="24", target_numbers="19", tag_name="wa">
Furthermore , observing the POS patterns in Table 5 and Table 6 , we can see the potential of structural inconsistency , in particular for closed-set POS tags .
#<struct ReadData::Alignment source_numbers="22,23", target_numbers="23,24", tag_name="wa">
Furthermore , observing the POS patterns in Table 5 and Table 6 , we can see the potential of structural inconsistency , in particular for closed-set POS tags .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
Among them , classifier nouns ( Nc ) and affxes ( S ) are two typical cases of structural inconsistency , which will be used in several settings of our experiments .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Among them , classifier nouns ( Nc ) and affxes ( S ) are two typical cases of structural inconsistency , which will be used in several settings of our experiments .
#<struct ReadData::Alignment source_numbers="28", target_numbers="", tag_name="wa">
Among them , classifier nouns ( Nc ) and affxes ( S ) are two typical cases of structural inconsistency , which will be used in several settings of our experiments .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Among them , classifier nouns ( Nc ) and affxes ( S ) are two typical cases of structural inconsistency , which will be used in several settings of our experiments .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
The same affx or classifier noun can modify different nouns , so when they are sometimes splitted , and sometimes combined in the variations , we can conclude that classifier nouns and affxes involve in structural inconsistency .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
The same affx or classifier noun can modify different nouns , so when they are sometimes splitted , and sometimes combined in the variations , we can conclude that classifier nouns and affxes involve in structural inconsistency .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
The same affx or classifier noun can modify different nouns , so when they are sometimes splitted , and sometimes combined in the variations , we can conclude that classifier nouns and affxes involve in structural inconsistency .
#<struct ReadData::Alignment source_numbers="32", target_numbers="", tag_name="wa">
The same affx or classifier noun can modify different nouns , so when they are sometimes splitted , and sometimes combined in the variations , we can conclude that classifier nouns and affxes involve in structural inconsistency .
#<struct ReadData::Alignment source_numbers="34", target_numbers="", tag_name="wa">
The same affx or classifier noun can modify different nouns , so when they are sometimes splitted , and sometimes combined in the variations , we can conclude that classifier nouns and affxes involve in structural inconsistency .
#<struct ReadData::Alignment source_numbers="35", target_numbers="", tag_name="wa">
The same affx or classifier noun can modify different nouns , so when they are sometimes splitted , and sometimes combined in the variations , we can conclude that classifier nouns and affxes involve in structural inconsistency .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
The same affx or classifier noun can modify different nouns , so when they are sometimes splitted , and sometimes combined in the variations , we can conclude that classifier nouns and affxes involve in structural inconsistency .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
In the following section , we presents our detection method for structural inconsistency for classifier nouns and affxes .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
In the following section , we presents our detection method for structural inconsistency for classifier nouns and affxes .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
The detection method for structural inconsistency of classifier nouns and affxes is simple .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
The detection method for structural inconsistency of classifier nouns and affxes is simple .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
First , we collected all affxes and classifier nouns in the VTB corpus . Then , extracted 2-grams containing these affxes or classifier nouns , which also are the structural inconsistencies .
#<struct ReadData::Alignment source_numbers="1", target_numbers="11", tag_name="wa">
First , we collected all affxes and classifier nouns in the VTB corpus . Then , extracted 2-grams containing these affxes or classifier nouns , which also are the structural inconsistencies .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
First , we collected all affxes and classifier nouns in the VTB corpus . Then , extracted 2-grams containing these affxes or classifier nouns , which also are the structural inconsistencies .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
First , we collected all affxes and classifier nouns in the VTB corpus . Then , extracted 2-grams containing these affxes or classifier nouns , which also are the structural inconsistencies .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
First , we collected all affxes and classifier nouns in the VTB corpus . Then , extracted 2-grams containing these affxes or classifier nouns , which also are the structural inconsistencies .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
First , we collected all affxes and classifier nouns in the VTB corpus . Then , extracted 2-grams containing these affxes or classifier nouns , which also are the structural inconsistencies .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
First , we collected all affxes and classifier nouns in the VTB corpus . Then , extracted 2-grams containing these affxes or classifier nouns , which also are the structural inconsistencies .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
First , we collected all affxes and classifier nouns in the VTB corpus . Then , extracted 2-grams containing these affxes or classifier nouns , which also are the structural inconsistencies .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
First , we collected all affxes and classifier nouns in the VTB corpus . Then , extracted 2-grams containing these affxes or classifier nouns , which also are the structural inconsistencies .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
First , we collected all affxes and classifier nouns in the VTB corpus . Then , extracted 2-grams containing these affxes or classifier nouns , which also are the structural inconsistencies .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
First , we collected all affxes and classifier nouns in the VTB corpus . Then , extracted 2-grams containing these affxes or classifier nouns , which also are the structural inconsistencies .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
First , we collected all affxes and classifier nouns in the VTB corpus . Then , extracted 2-grams containing these affxes or classifier nouns , which also are the structural inconsistencies .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
First , we collected all affxes and classifier nouns in the VTB corpus . Then , extracted 2-grams containing these affxes or classifier nouns , which also are the structural inconsistencies .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
Note that even though the sequence " con trai " is always splitted into two words throughout the corpus , it can still be an inconsistency if we consider similar structures such as " con gái " .
#<struct ReadData::Alignment source_numbers="19", target_numbers="4", tag_name="wa">
Note that even though the sequence " con trai " is always splitted into two words throughout the corpus , it can still be an inconsistency if we consider similar structures such as " con gái " .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Note that even though the sequence " con trai " is always splitted into two words throughout the corpus , it can still be an inconsistency if we consider similar structures such as " con gái " .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Note that even though the sequence " con trai " is always splitted into two words throughout the corpus , it can still be an inconsistency if we consider similar structures such as " con gái " .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Note that even though the sequence " con trai " is always splitted into two words throughout the corpus , it can still be an inconsistency if we consider similar structures such as " con gái " .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Note that even though the sequence " con trai " is always splitted into two words throughout the corpus , it can still be an inconsistency if we consider similar structures such as " con gái " .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
Note that even though the sequence " con trai " is always splitted into two words throughout the corpus , it can still be an inconsistency if we consider similar structures such as " con gái " .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
In other words , by this method , we extract sequences that may be consistent at the surface level , but are not consistent if we consider the higher analysis levels , POS tagging .
#<struct ReadData::Alignment source_numbers="31", target_numbers="24", tag_name="wa">
In other words , by this method , we extract sequences that may be consistent at the surface level , but are not consistent if we consider the higher analysis levels , POS tagging .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
According to the VTB POS-tagging annotation guidelines ( Nguyen et al., c ) , classifier nouns should be separated from the words they modify .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
However , in practice it is confusing when the classifier noun can be stand alone as a single word .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
However , in practice it is confusing when the classifier noun can be stand alone as a single word .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
However , in practice it is confusing when the classifier noun can be stand alone as a single word .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
However , in practice it is confusing when the classifier noun can be stand alone as a single word .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
For example a classifier noun , e.g. , " con " in " con trai ( boy ) " , or " con gái ( girl ) " , can also be a simple word which means " I ( first person pronoun used by a child when talking to his / her parents ) " , or part of a complex noun " con cái ( children ) " .
#<struct ReadData::Alignment source_numbers="56", target_numbers="35", tag_name="wa">
For example a classifier noun , e.g. , " con " in " con trai ( boy ) " , or " con gái ( girl ) " , can also be a simple word which means " I ( first person pronoun used by a child when talking to his / her parents ) " , or part of a complex noun " con cái ( children ) " .
#<struct ReadData::Alignment source_numbers="", target_numbers="57", tag_name="wa">
Therefore , in our experiments , we want to evaluate the " splitting " and " combining " of these diffcult cases , to see whether the solution is fruitful for applications of the corpus .
#<struct ReadData::Alignment source_numbers="29,30", target_numbers="30,31", tag_name="wa">
Therefore , in our experiments , we want to evaluate the " splitting " and " combining " of these diffcult cases , to see whether the solution is fruitful for applications of the corpus .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
Therefore , in our experiments , we want to evaluate the " splitting " and " combining " of these diffcult cases , to see whether the solution is fruitful for applications of the corpus .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
Therefore , in our experiments , we want to evaluate the " splitting " and " combining " of these diffcult cases , to see whether the solution is fruitful for applications of the corpus .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
Examing the variations extracted by the variation inconsistency detection , we found that there are cases when a special character like percentage % in " 30% " , is splitted or combined with " 30 " .
#<struct ReadData::Alignment source_numbers="22", target_numbers="25", tag_name="wa">
Examing the variations extracted by the variation inconsistency detection , we found that there are cases when a special character like percentage % in " 30% " , is splitted or combined with " 30 " .
#<struct ReadData::Alignment source_numbers="23", target_numbers="27", tag_name="wa">
Examing the variations extracted by the variation inconsistency detection , we found that there are cases when a special character like percentage % in " 30% " , is splitted or combined with " 30 " .
#<struct ReadData::Alignment source_numbers="24", target_numbers="28", tag_name="wa">
Examing the variations extracted by the variation inconsistency detection , we found that there are cases when a special character like percentage % in " 30% " , is splitted or combined with " 30 " .
#<struct ReadData::Alignment source_numbers="25", target_numbers="29", tag_name="wa">
Examing the variations extracted by the variation inconsistency detection , we found that there are cases when a special character like percentage % in " 30% " , is splitted or combined with " 30 " .
#<struct ReadData::Alignment source_numbers="26", target_numbers="30", tag_name="wa">
Examing the variations extracted by the variation inconsistency detection , we found that there are cases when a special character like percentage % in " 30% " , is splitted or combined with " 30 " .
#<struct ReadData::Alignment source_numbers="36", target_numbers="40", tag_name="wa">
Examing the variations extracted by the variation inconsistency detection , we found that there are cases when a special character like percentage % in " 30% " , is splitted or combined with " 30 " .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Examing the variations extracted by the variation inconsistency detection , we found that there are cases when a special character like percentage % in " 30% " , is splitted or combined with " 30 " .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Examing the variations extracted by the variation inconsistency detection , we found that there are cases when a special character like percentage % in " 30% " , is splitted or combined with " 30 " .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
Examing the variations extracted by the variation inconsistency detection , we found that there are cases when a special character like percentage % in " 30% " , is splitted or combined with " 30 " .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
Checking structural inconsistency of these special characters including percentage% , hyphen - , and so on , we found quite a significant amount of inconsistent annotations .
#<struct ReadData::Alignment source_numbers="16", target_numbers="8", tag_name="wa">
Checking structural inconsistency of these special characters including percentage% , hyphen - , and so on , we found quite a significant amount of inconsistent annotations .
#<struct ReadData::Alignment source_numbers="9", target_numbers="14", tag_name="wa">
Checking structural inconsistency of these special characters including percentage% , hyphen - , and so on , we found quite a significant amount of inconsistent annotations .
#<struct ReadData::Alignment source_numbers="11", target_numbers="17", tag_name="wa">
Checking structural inconsistency of these special characters including percentage% , hyphen - , and so on , we found quite a significant amount of inconsistent annotations .
#<struct ReadData::Alignment source_numbers="12", target_numbers="19", tag_name="wa">
Checking structural inconsistency of these special characters including percentage% , hyphen - , and so on , we found quite a significant amount of inconsistent annotations .
#<struct ReadData::Alignment source_numbers="20,21,22,23", target_numbers="27,28,29,30", tag_name="wa">
Checking structural inconsistency of these special characters including percentage% , hyphen - , and so on , we found quite a significant amount of inconsistent annotations .
#<struct ReadData::Alignment source_numbers="26", target_numbers="33", tag_name="wa">
Checking structural inconsistency of these special characters including percentage% , hyphen - , and so on , we found quite a significant amount of inconsistent annotations .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Checking structural inconsistency of these special characters including percentage% , hyphen - , and so on , we found quite a significant amount of inconsistent annotations .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Checking structural inconsistency of these special characters including percentage% , hyphen - , and so on , we found quite a significant amount of inconsistent annotations .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
Checking structural inconsistency of these special characters including percentage% , hyphen - , and so on , we found quite a significant amount of inconsistent annotations .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
Checking structural inconsistency of these special characters including percentage% , hyphen - , and so on , we found quite a significant amount of inconsistent annotations .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Checking structural inconsistency of these special characters including percentage% , hyphen - , and so on , we found quite a significant amount of inconsistent annotations .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Checking structural inconsistency of these special characters including percentage% , hyphen - , and so on , we found quite a significant amount of inconsistent annotations .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Checking structural inconsistency of these special characters including percentage% , hyphen - , and so on , we found quite a significant amount of inconsistent annotations .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
Checking structural inconsistency of these special characters including percentage% , hyphen - , and so on , we found quite a significant amount of inconsistent annotations .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
Checking structural inconsistency of these special characters including percentage% , hyphen - , and so on , we found quite a significant amount of inconsistent annotations .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Checking structural inconsistency of these special characters including percentage% , hyphen - , and so on , we found quite a significant amount of inconsistent annotations .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
Checking structural inconsistency of these special characters including percentage% , hyphen - , and so on , we found quite a significant amount of inconsistent annotations .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
Checking structural inconsistency of these special characters including percentage% , hyphen - , and so on , we found quite a significant amount of inconsistent annotations .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
Checking structural inconsistency of these special characters including percentage% , hyphen - , and so on , we found quite a significant amount of inconsistent annotations .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
Checking structural inconsistency of these special characters including percentage% , hyphen - , and so on , we found quite a significant amount of inconsistent annotations .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
For example , the character % in " 30% " is splitted but is combined with the number in " 50 % " , which is considered as a structural inconsistency .
#<struct ReadData::Alignment source_numbers="23", target_numbers="5", tag_name="wa">
For example , the character % in " 30% " is splitted but is combined with the number in " 50 % " , which is considered as a structural inconsistency .
#<struct ReadData::Alignment source_numbers="28", target_numbers="19", tag_name="wa">
For example , the character % in " 30% " is splitted but is combined with the number in " 50 % " , which is considered as a structural inconsistency .
#<struct ReadData::Alignment source_numbers="26,27", target_numbers="27,28,29,30,31", tag_name="wa">
For example , the character % in " 30% " is splitted but is combined with the number in " 50 % " , which is considered as a structural inconsistency .
#<struct ReadData::Alignment source_numbers="31", target_numbers="35", tag_name="wa">
For example , the character % in " 30% " is splitted but is combined with the number in " 50 % " , which is considered as a structural inconsistency .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
For example , the character % in " 30% " is splitted but is combined with the number in " 50 % " , which is considered as a structural inconsistency .
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
For example , the character % in " 30% " is splitted but is combined with the number in " 50 % " , which is considered as a structural inconsistency .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
For example , the character % in " 30% " is splitted but is combined with the number in " 50 % " , which is considered as a structural inconsistency .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
For example , the character % in " 30% " is splitted but is combined with the number in " 50 % " , which is considered as a structural inconsistency .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
For example , the character % in " 30% " is splitted but is combined with the number in " 50 % " , which is considered as a structural inconsistency .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
For example , the character % in " 30% " is splitted but is combined with the number in " 50 % " , which is considered as a structural inconsistency .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
Note that although it can be argued that whether " N% " can be splitted into two words or combined in one word is dependent on the blank space in between N and " % " .
#<struct ReadData::Alignment source_numbers="14", target_numbers="7", tag_name="wa">
Note that although it can be argued that whether " N% " can be splitted into two words or combined in one word is dependent on the blank space in between N and " % " .
#<struct ReadData::Alignment source_numbers="36", target_numbers="31", tag_name="wa">
Note that although it can be argued that whether " N% " can be splitted into two words or combined in one word is dependent on the blank space in between N and " % " .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Note that although it can be argued that whether " N% " can be splitted into two words or combined in one word is dependent on the blank space in between N and " % " .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Note that although it can be argued that whether " N% " can be splitted into two words or combined in one word is dependent on the blank space in between N and " % " .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
Note that although it can be argued that whether " N% " can be splitted into two words or combined in one word is dependent on the blank space in between N and " % " .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
Note that although it can be argued that whether " N% " can be splitted into two words or combined in one word is dependent on the blank space in between N and " % " .
#<struct ReadData::Alignment source_numbers="29", target_numbers="", tag_name="wa">
Note that although it can be argued that whether " N% " can be splitted into two words or combined in one word is dependent on the blank space in between N and " % " .
#<struct ReadData::Alignment source_numbers="30", target_numbers="", tag_name="wa">
Note that although it can be argued that whether " N% " can be splitted into two words or combined in one word is dependent on the blank space in between N and " % " .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
It does matter higher-levels of annotation such as POS tagging because we may need one or two different POS tags for different ways of annotation .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
It does matter higher-levels of annotation such as POS tagging because we may need one or two different POS tags for different ways of annotation .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
It does matter higher-levels of annotation such as POS tagging because we may need one or two different POS tags for different ways of annotation .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
It does matter higher-levels of annotation such as POS tagging because we may need one or two different POS tags for different ways of annotation .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
It does matter higher-levels of annotation such as POS tagging because we may need one or two different POS tags for different ways of annotation .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
It does matter higher-levels of annotation such as POS tagging because we may need one or two different POS tags for different ways of annotation .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
It does matter higher-levels of annotation such as POS tagging because we may need one or two different POS tags for different ways of annotation .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
It does matter higher-levels of annotation such as POS tagging because we may need one or two different POS tags for different ways of annotation .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Therefore , we think it is better to carefully preprocess text and segment these special characters in a consistent way .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
To improve the quality of VTB corpus , we extracted the probably problematic sequences using patterns of the special characters , and manually fixed this type of inconsistency .
#<struct ReadData::Alignment source_numbers="17", target_numbers="5", tag_name="wa">
To improve the quality of VTB corpus , we extracted the probably problematic sequences using patterns of the special characters , and manually fixed this type of inconsistency .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
To improve the quality of VTB corpus , we extracted the probably problematic sequences using patterns of the special characters , and manually fixed this type of inconsistency .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Automatically modification is diffcult since we must check the semantics of the special characters in their contexts .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
For example , hyphens in date expressions like " 5-4-1975 " , which means the date " April the fifth , 1975 , " are combined with the numbers .
#<struct ReadData::Alignment source_numbers="13,14", target_numbers="13,14,15", tag_name="wa">
For example , hyphens in date expressions like " 5-4-1975 " , which means the date " April the fifth , 1975 , " are combined with the numbers .
#<struct ReadData::Alignment source_numbers="22", target_numbers="17", tag_name="wa">
For example , hyphens in date expressions like " 5-4-1975 " , which means the date " April the fifth , 1975 , " are combined with the numbers .
#<struct ReadData::Alignment source_numbers="17", target_numbers="22", tag_name="wa">
For example , hyphens in date expressions like " 5-4-1975 " , which means the date " April the fifth , 1975 , " are combined with the numbers .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
For example , hyphens in date expressions like " 5-4-1975 " , which means the date " April the fifth , 1975 , " are combined with the numbers .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
However , when the hypen has a meaning of " ( from ) to " or " around .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
However , when the hypen has a meaning of " ( from ) to " or " around .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
However , when the hypen has a meaning of " ( from ) to " or " around .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
However , when the hypen has a meaning of " ( from ) to " or " around .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
However , when the hypen has a meaning of " ( from ) to " or " around .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
However , when the hypen has a meaning of " ( from ) to " or " around .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
However , when the hypen has a meaning of " ( from ) to " or " around .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
or " , as in " 2-3 gi░ sáng " meaning " around 2 or 3 o’clock in the morning " , we decided to separate it from the surrounding numbers .
#<struct ReadData::Alignment source_numbers="21", target_numbers="10", tag_name="wa">
or " , as in " 2-3 gi░ sáng " meaning " around 2 or 3 o’clock in the morning " , we decided to separate it from the surrounding numbers .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
The variation inconsistency and structural inconsistency found in Section 3 above can also be seen as representatives of different word segmentation criteria for Vietnamese .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Then , by using these data sets , we could observe the influence of the different word segmentation criteria on three tasks : automatic word segmenation , text classification , and English-Vietnamese statistical machine translation .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
Then , by using these data sets , we could observe the influence of the different word segmentation criteria on three tasks : automatic word segmenation , text classification , and English-Vietnamese statistical machine translation .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
These data sets are used in our experiments as illustrated in Figure 1 .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
The core of YamCha is the Support Vector Machine ( SVM ) machine learning method , which has been proved to be effective in NLP tasks .
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
The core of YamCha is the Support Vector Machine ( SVM ) machine learning method , which has been proved to be effective in NLP tasks .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
Label of each token is determined based on the lexical features of two preceding words and two following words of that token .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Label of each token is determined based on the lexical features of two preceding words and two following words of that token .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Label of each token is determined based on the lexical features of two preceding words and two following words of that token .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
Text classification is defined as a task of determining for an input document the most suitable topic from the predefined topics .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
The difference is that we performed for document level , not for sentence level .
#<struct ReadData::Alignment source_numbers="10", target_numbers="13", tag_name="wa">
The difference is that we performed for document level , not for sentence level .
#<struct ReadData::Alignment source_numbers="14", target_numbers="19", tag_name="wa">
The difference is that we performed for document level , not for sentence level .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
The difference is that we performed for document level , not for sentence level .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
The difference is that we performed for document level , not for sentence level .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
The difference is that we performed for document level , not for sentence level .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
The difference is that we performed for document level , not for sentence level .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
The difference is that we performed for document level , not for sentence level .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
The difference is that we performed for document level , not for sentence level .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
Processing of the system is summarized as follows .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Processing of the system is summarized as follows .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
An SVM-based classifier predicts the most probable topic for the vector , which also is the topic of the input document .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
An SVM-based classifier predicts the most probable topic for the vector , which also is the topic of the input document .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
In our experiment for comparison of different word segmentation criteria in topic classification , we only vary the word segmentation model used for this task , while fixing other configurations .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
A phrase-based SMT system for English-Vietnamese translation was implemented .
#<struct ReadData::Alignment source_numbers="9", target_numbers="9", tag_name="wa">
And the experimental results with text classification and English-Vietnamese statistical machine translation are shown in Table 10 and Table 11 , respectively .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
And the experimental results with text classification and English-Vietnamese statistical machine translation are shown in Table 10 and Table 11 , respectively .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
And the experimental results with text classification and English-Vietnamese statistical machine translation are shown in Table 10 and Table 11 , respectively .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
There are two important conclusions can be drawn from these tables : ( 1 ) Quality of the treebank strongly affects the applications since our BASE model and most of other enhanced models improved the performance of TC and SMT systems ; ( 2 ) " Splitting " seems to be a good solution for word segmentation of controversial cases , including the split of variations , affxes , and classifier nouns .
#<struct ReadData::Alignment source_numbers="68", target_numbers="25", tag_name="wa">
There are two important conclusions can be drawn from these tables : ( 1 ) Quality of the treebank strongly affects the applications since our BASE model and most of other enhanced models improved the performance of TC and SMT systems ; ( 2 ) " Splitting " seems to be a good solution for word segmentation of controversial cases , including the split of variations , affxes , and classifier nouns .
#<struct ReadData::Alignment source_numbers="62", target_numbers="33", tag_name="wa">
There are two important conclusions can be drawn from these tables : ( 1 ) Quality of the treebank strongly affects the applications since our BASE model and most of other enhanced models improved the performance of TC and SMT systems ; ( 2 ) " Splitting " seems to be a good solution for word segmentation of controversial cases , including the split of variations , affxes , and classifier nouns .
#<struct ReadData::Alignment source_numbers="72", target_numbers="76", tag_name="wa">
There are two important conclusions can be drawn from these tables : ( 1 ) Quality of the treebank strongly affects the applications since our BASE model and most of other enhanced models improved the performance of TC and SMT systems ; ( 2 ) " Splitting " seems to be a good solution for word segmentation of controversial cases , including the split of variations , affxes , and classifier nouns .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
There are two important conclusions can be drawn from these tables : ( 1 ) Quality of the treebank strongly affects the applications since our BASE model and most of other enhanced models improved the performance of TC and SMT systems ; ( 2 ) " Splitting " seems to be a good solution for word segmentation of controversial cases , including the split of variations , affxes , and classifier nouns .
#<struct ReadData::Alignment source_numbers="57", target_numbers="", tag_name="wa">
There are two important conclusions can be drawn from these tables : ( 1 ) Quality of the treebank strongly affects the applications since our BASE model and most of other enhanced models improved the performance of TC and SMT systems ; ( 2 ) " Splitting " seems to be a good solution for word segmentation of controversial cases , including the split of variations , affxes , and classifier nouns .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
There are two important conclusions can be drawn from these tables : ( 1 ) Quality of the treebank strongly affects the applications since our BASE model and most of other enhanced models improved the performance of TC and SMT systems ; ( 2 ) " Splitting " seems to be a good solution for word segmentation of controversial cases , including the split of variations , affxes , and classifier nouns .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
There are two important conclusions can be drawn from these tables : ( 1 ) Quality of the treebank strongly affects the applications since our BASE model and most of other enhanced models improved the performance of TC and SMT systems ; ( 2 ) " Splitting " seems to be a good solution for word segmentation of controversial cases , including the split of variations , affxes , and classifier nouns .
#<struct ReadData::Alignment source_numbers="", target_numbers="61", tag_name="wa">
There are two important conclusions can be drawn from these tables : ( 1 ) Quality of the treebank strongly affects the applications since our BASE model and most of other enhanced models improved the performance of TC and SMT systems ; ( 2 ) " Splitting " seems to be a good solution for word segmentation of controversial cases , including the split of variations , affxes , and classifier nouns .
#<struct ReadData::Alignment source_numbers="", target_numbers="66", tag_name="wa">
There are two important conclusions can be drawn from these tables : ( 1 ) Quality of the treebank strongly affects the applications since our BASE model and most of other enhanced models improved the performance of TC and SMT systems ; ( 2 ) " Splitting " seems to be a good solution for word segmentation of controversial cases , including the split of variations , affxes , and classifier nouns .
#<struct ReadData::Alignment source_numbers="", target_numbers="72", tag_name="wa">
Except for STRUCT_NC , all the modifications to the original VTB corpus increase the performance of WS .
#<struct ReadData::Alignment source_numbers="15", target_numbers="3", tag_name="wa">
Except for STRUCT_NC , all the modifications to the original VTB corpus increase the performance of WS .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Except for STRUCT_NC , all the modifications to the original VTB corpus increase the performance of WS .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Except for STRUCT_NC , all the modifications to the original VTB corpus increase the performance of WS .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Except for STRUCT_NC , all the modifications to the original VTB corpus increase the performance of WS .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Except for STRUCT_NC , all the modifications to the original VTB corpus increase the performance of WS .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Except for STRUCT_NC , all the modifications to the original VTB corpus increase the performance of WS .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Except for STRUCT_NC , all the modifications to the original VTB corpus increase the performance of WS .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
In both SMT and TC experiments , the BASE model which is based on the manually-modified inconsistency of special characters , achieved better results than the ORG model .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
The SMT results show that three out of six augmented models , VAR_SPLIT , VAR_FREQ and BASE , gave higher performance than the ORG configuration .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
The SMT results show that three out of six augmented models , VAR_SPLIT , VAR_FREQ and BASE , gave higher performance than the ORG configuration .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
The SMT results show that three out of six augmented models , VAR_SPLIT , VAR_FREQ and BASE , gave higher performance than the ORG configuration .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
The SMT results show that three out of six augmented models , VAR_SPLIT , VAR_FREQ and BASE , gave higher performance than the ORG configuration .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
The SMT results show that three out of six augmented models , VAR_SPLIT , VAR_FREQ and BASE , gave higher performance than the ORG configuration .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
Among them , the best model VAR_SPLIT achieved 36 .91 BLEU score , which is 0 .55 higher than ORG .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
Among them , the best model VAR_SPLIT achieved 36 .91 BLEU score , which is 0 .55 higher than ORG .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Among them , the best model VAR_SPLIT achieved 36 .91 BLEU score , which is 0 .55 higher than ORG .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
In TC results , all six augmented models have higher results than ORG .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
In TC results , all six augmented models have higher results than ORG .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
In general , the augmented models are better than the ORG .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
In general , the augmented models are better than the ORG .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Additionally , because our automatic methods for inconsistency detection could not cover all types of inconsistency in word segmentation annotation , further improvement of corpus quality is demanded .
#<struct ReadData::Alignment source_numbers="23", target_numbers="13", tag_name="wa">
Additionally , because our automatic methods for inconsistency detection could not cover all types of inconsistency in word segmentation annotation , further improvement of corpus quality is demanded .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Additionally , because our automatic methods for inconsistency detection could not cover all types of inconsistency in word segmentation annotation , further improvement of corpus quality is demanded .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
Comparing the results of STRUCT_AFFIX and STRUCT_NC with BASE in WS , TC , and SMT , we can observe that combining affxes with their head nouns resulted in slightly better results for WS , TC , and does not change the performance of SMT .
#<struct ReadData::Alignment source_numbers="37", target_numbers="34", tag_name="wa">
Comparing the results of STRUCT_AFFIX and STRUCT_NC with BASE in WS , TC , and SMT , we can observe that combining affxes with their head nouns resulted in slightly better results for WS , TC , and does not change the performance of SMT .
#<struct ReadData::Alignment source_numbers="36", target_numbers="36", tag_name="wa">
Comparing the results of STRUCT_AFFIX and STRUCT_NC with BASE in WS , TC , and SMT , we can observe that combining affxes with their head nouns resulted in slightly better results for WS , TC , and does not change the performance of SMT .
#<struct ReadData::Alignment source_numbers="39", target_numbers="39", tag_name="wa">
Comparing the results of STRUCT_AFFIX and STRUCT_NC with BASE in WS , TC , and SMT , we can observe that combining affxes with their head nouns resulted in slightly better results for WS , TC , and does not change the performance of SMT .
#<struct ReadData::Alignment source_numbers="40", target_numbers="40", tag_name="wa">
Comparing the results of STRUCT_AFFIX and STRUCT_NC with BASE in WS , TC , and SMT , we can observe that combining affxes with their head nouns resulted in slightly better results for WS , TC , and does not change the performance of SMT .
#<struct ReadData::Alignment source_numbers="34", target_numbers="", tag_name="wa">
Comparing the results of STRUCT_AFFIX and STRUCT_NC with BASE in WS , TC , and SMT , we can observe that combining affxes with their head nouns resulted in slightly better results for WS , TC , and does not change the performance of SMT .
#<struct ReadData::Alignment source_numbers="38", target_numbers="", tag_name="wa">
Comparing the results of STRUCT_AFFIX and STRUCT_NC with BASE in WS , TC , and SMT , we can observe that combining affxes with their head nouns resulted in slightly better results for WS , TC , and does not change the performance of SMT .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
Comparing the results of STRUCT_AFFIX and STRUCT_NC with BASE in WS , TC , and SMT , we can observe that combining affxes with their head nouns resulted in slightly better results for WS , TC , and does not change the performance of SMT .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
However , the combination of clasifier nouns with their head nouns had negative effects on WS and SMT .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
However , the combination of clasifier nouns with their head nouns had negative effects on WS and SMT .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Another intention of our experiment is to compare two solutions for controversial cases of word segmentation , splitting and combining .
#<struct ReadData::Alignment source_numbers="2", target_numbers="5", tag_name="wa">
Another intention of our experiment is to compare two solutions for controversial cases of word segmentation , splitting and combining .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Another intention of our experiment is to compare two solutions for controversial cases of word segmentation , splitting and combining .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Another intention of our experiment is to compare two solutions for controversial cases of word segmentation , splitting and combining .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Another intention of our experiment is to compare two solutions for controversial cases of word segmentation , splitting and combining .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Another intention of our experiment is to compare two solutions for controversial cases of word segmentation , splitting and combining .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Splitting and combining variations are reflected by VAR_COMB and VAR_SPLIT , while STRUCT_AFFIX and STRUCT_NC represent the combination of affxes or classifier nouns with the words they modify .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
Splitting and combining variations are reflected by VAR_COMB and VAR_SPLIT , while STRUCT_AFFIX and STRUCT_NC represent the combination of affxes or classifier nouns with the words they modify .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
Splitting and combining variations are reflected by VAR_COMB and VAR_SPLIT , while STRUCT_AFFIX and STRUCT_NC represent the combination of affxes or classifier nouns with the words they modify .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
In this paper , we have shown a quantitative analysis of the diffculties in word segmentation , through the detection of problematic cases in the Vietnamese treebank .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
In this paper , we have shown a quantitative analysis of the diffculties in word segmentation , through the detection of problematic cases in the Vietnamese treebank .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
In this paper , we have shown a quantitative analysis of the diffculties in word segmentation , through the detection of problematic cases in the Vietnamese treebank .
#<struct ReadData::Alignment source_numbers="26", target_numbers="", tag_name="wa">
In this paper , we have shown a quantitative analysis of the diffculties in word segmentation , through the detection of problematic cases in the Vietnamese treebank .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
In this paper , we have shown a quantitative analysis of the diffculties in word segmentation , through the detection of problematic cases in the Vietnamese treebank .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
In this paper , we have shown a quantitative analysis of the diffculties in word segmentation , through the detection of problematic cases in the Vietnamese treebank .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
Our experimental results showed that manual modification done for annotation of spe-cial characters and most of other word segmentation criteria significantly improved the performances of automatic word segmentation , text classification and statistical machine translation , comparing with the use of the original VTB corpus .
#<struct ReadData::Alignment source_numbers="28", target_numbers="7", tag_name="wa">
Our experimental results showed that manual modification done for annotation of spe-cial characters and most of other word segmentation criteria significantly improved the performances of automatic word segmentation , text classification and statistical machine translation , comparing with the use of the original VTB corpus .
#<struct ReadData::Alignment source_numbers="35", target_numbers="14", tag_name="wa">
Our experimental results showed that manual modification done for annotation of spe-cial characters and most of other word segmentation criteria significantly improved the performances of automatic word segmentation , text classification and statistical machine translation , comparing with the use of the original VTB corpus .
#<struct ReadData::Alignment source_numbers="36", target_numbers="39", tag_name="wa">
Our experimental results showed that manual modification done for annotation of spe-cial characters and most of other word segmentation criteria significantly improved the performances of automatic word segmentation , text classification and statistical machine translation , comparing with the use of the original VTB corpus .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
Our experimental results showed that manual modification done for annotation of spe-cial characters and most of other word segmentation criteria significantly improved the performances of automatic word segmentation , text classification and statistical machine translation , comparing with the use of the original VTB corpus .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
Our experimental results showed that manual modification done for annotation of spe-cial characters and most of other word segmentation criteria significantly improved the performances of automatic word segmentation , text classification and statistical machine translation , comparing with the use of the original VTB corpus .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
Our experimental results showed that manual modification done for annotation of spe-cial characters and most of other word segmentation criteria significantly improved the performances of automatic word segmentation , text classification and statistical machine translation , comparing with the use of the original VTB corpus .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
Our experimental results showed that manual modification done for annotation of spe-cial characters and most of other word segmentation criteria significantly improved the performances of automatic word segmentation , text classification and statistical machine translation , comparing with the use of the original VTB corpus .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
Our experimental results showed that manual modification done for annotation of spe-cial characters and most of other word segmentation criteria significantly improved the performances of automatic word segmentation , text classification and statistical machine translation , comparing with the use of the original VTB corpus .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
Since the VTB corpus is the first effort in building a treebank for Vietnamese , and is the only corpus publicly available for NLP research , this study contributes to further improvement of the corpus quality , which is essential for building effcient NLP systems .
#<struct ReadData::Alignment source_numbers="37,38", target_numbers="20,21", tag_name="wa">
Since the VTB corpus is the first effort in building a treebank for Vietnamese , and is the only corpus publicly available for NLP research , this study contributes to further improvement of the corpus quality , which is essential for building effcient NLP systems .
#<struct ReadData::Alignment source_numbers="42", target_numbers="", tag_name="wa">
Since the VTB corpus is the first effort in building a treebank for Vietnamese , and is the only corpus publicly available for NLP research , this study contributes to further improvement of the corpus quality , which is essential for building effcient NLP systems .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
Since the VTB corpus is the first effort in building a treebank for Vietnamese , and is the only corpus publicly available for NLP research , this study contributes to further improvement of the corpus quality , which is essential for building effcient NLP systems .
#<struct ReadData::Alignment source_numbers="", target_numbers="40", tag_name="wa">
Since the VTB corpus is the first effort in building a treebank for Vietnamese , and is the only corpus publicly available for NLP research , this study contributes to further improvement of the corpus quality , which is essential for building effcient NLP systems .
#<struct ReadData::Alignment source_numbers="", target_numbers="44", tag_name="wa">
Face retrieval on large-scale news video datasets
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Face retrieval on large-scale news video datasets
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Although there are several approaches proposed to cope with this problem , their extremely high computational cost limits their scalability on largescale video datasets that may contain millions faces of hundreds characters .
#<struct ReadData::Alignment source_numbers="2", target_numbers="3,4", tag_name="wa">
Although there are several approaches proposed to cope with this problem , their extremely high computational cost limits their scalability on largescale video datasets that may contain millions faces of hundreds characters .
#<struct ReadData::Alignment source_numbers="5", target_numbers="5", tag_name="wa">
Although there are several approaches proposed to cope with this problem , their extremely high computational cost limits their scalability on largescale video datasets that may contain millions faces of hundreds characters .
#<struct ReadData::Alignment source_numbers="7,8", target_numbers="7,8", tag_name="wa">
Although there are several approaches proposed to cope with this problem , their extremely high computational cost limits their scalability on largescale video datasets that may contain millions faces of hundreds characters .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Although there are several approaches proposed to cope with this problem , their extremely high computational cost limits their scalability on largescale video datasets that may contain millions faces of hundreds characters .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
Although there are several approaches proposed to cope with this problem , their extremely high computational cost limits their scalability on largescale video datasets that may contain millions faces of hundreds characters .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
Although there are several approaches proposed to cope with this problem , their extremely high computational cost limits their scalability on largescale video datasets that may contain millions faces of hundreds characters .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
Although there are several approaches proposed to cope with this problem , their extremely high computational cost limits their scalability on largescale video datasets that may contain millions faces of hundreds characters .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
In this paper , we introduce approaches for face retrieval which are scalable on such datasets while maintaining competitive performances with the state-of-the-art approaches .
#<struct ReadData::Alignment source_numbers="6,7", target_numbers="6,7", tag_name="wa">
In this paper , we introduce approaches for face retrieval which are scalable on such datasets while maintaining competitive performances with the state-of-the-art approaches .
#<struct ReadData::Alignment source_numbers="10,11", target_numbers="10,11", tag_name="wa">
In this paper , we introduce approaches for face retrieval which are scalable on such datasets while maintaining competitive performances with the state-of-the-art approaches .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
In this paper , we introduce approaches for face retrieval which are scalable on such datasets while maintaining competitive performances with the state-of-the-art approaches .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
In this paper , we introduce approaches for face retrieval which are scalable on such datasets while maintaining competitive performances with the state-of-the-art approaches .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
To utilize the variability of face appearances in video , we use a set of face images called face-track to represent for the appearance of a character in a video shot .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
To utilize the variability of face appearances in video , we use a set of face images called face-track to represent for the appearance of a character in a video shot .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
To utilize the variability of face appearances in video , we use a set of face images called face-track to represent for the appearance of a character in a video shot .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
Our first proposal is an approach for extracting face-tracks .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
Our first proposal is an approach for extracting face-tracks .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Our first proposal is an approach for extracting face-tracks .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Our first proposal is an approach for extracting face-tracks .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Our first proposal is an approach for extracting face-tracks .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
We use a point tracker for exploring the connections between detected faces belonging to the same character , then grouping them into one face-track .
#<struct ReadData::Alignment source_numbers="6,7", target_numbers="6,7", tag_name="wa">
We use a point tracker for exploring the connections between detected faces belonging to the same character , then grouping them into one face-track .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
We use a point tracker for exploring the connections between detected faces belonging to the same character , then grouping them into one face-track .
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
We use a point tracker for exploring the connections between detected faces belonging to the same character , then grouping them into one face-track .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
We use a point tracker for exploring the connections between detected faces belonging to the same character , then grouping them into one face-track .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
We use a point tracker for exploring the connections between detected faces belonging to the same character , then grouping them into one face-track .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
We use a point tracker for exploring the connections between detected faces belonging to the same character , then grouping them into one face-track .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
In the second proposal , we introduce an efficient approach to match face-tracks for retrieval .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
In the second proposal , we introduce an efficient approach to match face-tracks for retrieval .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
In the second proposal , we introduce an efficient approach to match face-tracks for retrieval .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Instead of using all faces in face-tracks to compute their similarity , our approach select representative faces for each face-track .
#<struct ReadData::Alignment source_numbers="20", target_numbers="24", tag_name="wa">
Instead of using all faces in face-tracks to compute their similarity , our approach select representative faces for each face-track .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
Instead of using all faces in face-tracks to compute their similarity , our approach select representative faces for each face-track .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
Instead of using all faces in face-tracks to compute their similarity , our approach select representative faces for each face-track .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Instead of using all faces in face-tracks to compute their similarity , our approach select representative faces for each face-track .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Instead of using all faces in face-tracks to compute their similarity , our approach select representative faces for each face-track .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
Instead of using all faces in face-tracks to compute their similarity , our approach select representative faces for each face-track .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
The representative faces are sampled from the original face-track .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
The representative faces are sampled from the original face-track .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
The representative faces are sampled from the original face-track .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
As a result , we significantly reduce the computational cost for face-track matching while taking into account variability of faces in face-tracks for high matching accuracy .
#<struct ReadData::Alignment source_numbers="9,10", target_numbers="9,10", tag_name="wa">
As a result , we significantly reduce the computational cost for face-track matching while taking into account variability of faces in face-tracks for high matching accuracy .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
As a result , we significantly reduce the computational cost for face-track matching while taking into account variability of faces in face-tracks for high matching accuracy .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
As a result , we significantly reduce the computational cost for face-track matching while taking into account variability of faces in face-tracks for high matching accuracy .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
As a result , we significantly reduce the computational cost for face-track matching while taking into account variability of faces in face-tracks for high matching accuracy .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
As a result , we significantly reduce the computational cost for face-track matching while taking into account variability of faces in face-tracks for high matching accuracy .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
As a result , we significantly reduce the computational cost for face-track matching while taking into account variability of faces in face-tracks for high matching accuracy .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
Experiments are conducted on two face-track datasets extracted from real-world news videos , .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Experiments are conducted on two face-track datasets extracted from real-world news videos , .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Their scales have not been considered in literature ever .
#<struct ReadData::Alignment source_numbers="1", target_numbers="0", tag_name="wa">
Their scales have not been considered in literature ever .
#<struct ReadData::Alignment source_numbers="2", target_numbers="2", tag_name="wa">
Their scales have not been considered in literature ever .
#<struct ReadData::Alignment source_numbers="3", target_numbers="3", tag_name="wa">
Their scales have not been considered in literature ever .
#<struct ReadData::Alignment source_numbers="4", target_numbers="4", tag_name="wa">
Their scales have not been considered in literature ever .
#<struct ReadData::Alignment source_numbers="5", target_numbers="5", tag_name="wa">
Their scales have not been considered in literature ever .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Their scales have not been considered in literature ever .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Their scales have not been considered in literature ever .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
One dataset contains 1,497 face-tracks of 41 characters extracted from 370 hours of TRECVID videos .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
One dataset contains 1,497 face-tracks of 41 characters extracted from 370 hours of TRECVID videos .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
One dataset contains 1,497 face-tracks of 41 characters extracted from 370 hours of TRECVID videos .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
The other dataset provides 5,567 face-tracks of 111 characters observed from television news program ( NHK News 7 ) channel in 11 years .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
The other dataset provides 5,567 face-tracks of 111 characters observed from television news program ( NHK News 7 ) channel in 11 years .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
The other dataset provides 5,567 face-tracks of 111 characters observed from television news program ( NHK News 7 ) channel in 11 years .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
The other dataset provides 5,567 face-tracks of 111 characters observed from television news program ( NHK News 7 ) channel in 11 years .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
The other dataset provides 5,567 face-tracks of 111 characters observed from television news program ( NHK News 7 ) channel in 11 years .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
The other dataset provides 5,567 face-tracks of 111 characters observed from television news program ( NHK News 7 ) channel in 11 years .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
The experimental results demonstrate that our proposed approaches achieved a remarkable balance between accuracy and efficiency.
#<struct ReadData::Alignment source_numbers="3,4", target_numbers="3,4", tag_name="wa">
News videos play an important role in our sources of information nowadays because of their rich and important contents .
#<struct ReadData::Alignment source_numbers="5,6", target_numbers="5,6", tag_name="wa">
News videos play an important role in our sources of information nowadays because of their rich and important contents .
#<struct ReadData::Alignment source_numbers="8", target_numbers="7,8", tag_name="wa">
News videos play an important role in our sources of information nowadays because of their rich and important contents .
#<struct ReadData::Alignment source_numbers="16,17", target_numbers="16,17", tag_name="wa">
News videos play an important role in our sources of information nowadays because of their rich and important contents .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
With the advances of modern technology , a huge amount of news videos can be obtained easily .
#<struct ReadData::Alignment source_numbers="3,4", target_numbers="3,4", tag_name="wa">
Accordingly , it creates an urgent demand for retrieving useful information in such news video datasets .
#<struct ReadData::Alignment source_numbers="6,7", target_numbers="6,7", tag_name="wa">
Accordingly , it creates an urgent demand for retrieving useful information in such news video datasets .
#<struct ReadData::Alignment source_numbers="8", target_numbers="8", tag_name="wa">
Accordingly , it creates an urgent demand for retrieving useful information in such news video datasets .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Accordingly , it creates an urgent demand for retrieving useful information in such news video datasets .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
Accordingly , it creates an urgent demand for retrieving useful information in such news video datasets .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Accordingly , it creates an urgent demand for retrieving useful information in such news video datasets .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
Since most of the news is related to human , human face retrieval , which is defined as the task of extracting and returning faces relevant to a given query , obviously becomes an important task .
#<struct ReadData::Alignment source_numbers="9", target_numbers="7", tag_name="wa">
Since most of the news is related to human , human face retrieval , which is defined as the task of extracting and returning faces relevant to a given query , obviously becomes an important task .
#<struct ReadData::Alignment source_numbers="13", target_numbers="11", tag_name="wa">
Since most of the news is related to human , human face retrieval , which is defined as the task of extracting and returning faces relevant to a given query , obviously becomes an important task .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Since most of the news is related to human , human face retrieval , which is defined as the task of extracting and returning faces relevant to a given query , obviously becomes an important task .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Since most of the news is related to human , human face retrieval , which is defined as the task of extracting and returning faces relevant to a given query , obviously becomes an important task .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
Since most of the news is related to human , human face retrieval , which is defined as the task of extracting and returning faces relevant to a given query , obviously becomes an important task .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
A robust face retrieval system on large-scale news video datasets is indeed of much benefit to a wide range of applications .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
A robust face retrieval system on large-scale news video datasets is indeed of much benefit to a wide range of applications .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
A robust face retrieval system on large-scale news video datasets is indeed of much benefit to a wide range of applications .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
A robust face retrieval system on large-scale news video datasets is indeed of much benefit to a wide range of applications .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
With the list , important events related to the character can be detected or summarized.
#<struct ReadData::Alignment source_numbers="1,2", target_numbers="1,2,3", tag_name="wa">
On the other hand , efficiency is also an issue of such a face retrieval system beside its accuracy since scales of available datasets are getting larger rapidly , for instance , exceeding thousands hours of videos with millions faces of hundreds character .
#<struct ReadData::Alignment source_numbers="18", target_numbers="1", tag_name="wa">
On the other hand , efficiency is also an issue of such a face retrieval system beside its accuracy since scales of available datasets are getting larger rapidly , for instance , exceeding thousands hours of videos with millions faces of hundreds character .
#<struct ReadData::Alignment source_numbers="1", target_numbers="15", tag_name="wa">
On the other hand , efficiency is also an issue of such a face retrieval system beside its accuracy since scales of available datasets are getting larger rapidly , for instance , exceeding thousands hours of videos with millions faces of hundreds character .
#<struct ReadData::Alignment source_numbers="28", target_numbers="24", tag_name="wa">
On the other hand , efficiency is also an issue of such a face retrieval system beside its accuracy since scales of available datasets are getting larger rapidly , for instance , exceeding thousands hours of videos with millions faces of hundreds character .
#<struct ReadData::Alignment source_numbers="31", target_numbers="27", tag_name="wa">
On the other hand , efficiency is also an issue of such a face retrieval system beside its accuracy since scales of available datasets are getting larger rapidly , for instance , exceeding thousands hours of videos with millions faces of hundreds character .
#<struct ReadData::Alignment source_numbers="10", target_numbers="30", tag_name="wa">
On the other hand , efficiency is also an issue of such a face retrieval system beside its accuracy since scales of available datasets are getting larger rapidly , for instance , exceeding thousands hours of videos with millions faces of hundreds character .
#<struct ReadData::Alignment source_numbers="42", target_numbers="41", tag_name="wa">
On the other hand , efficiency is also an issue of such a face retrieval system beside its accuracy since scales of available datasets are getting larger rapidly , for instance , exceeding thousands hours of videos with millions faces of hundreds character .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
On the other hand , efficiency is also an issue of such a face retrieval system beside its accuracy since scales of available datasets are getting larger rapidly , for instance , exceeding thousands hours of videos with millions faces of hundreds character .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
On the other hand , efficiency is also an issue of such a face retrieval system beside its accuracy since scales of available datasets are getting larger rapidly , for instance , exceeding thousands hours of videos with millions faces of hundreds character .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
On the other hand , efficiency is also an issue of such a face retrieval system beside its accuracy since scales of available datasets are getting larger rapidly , for instance , exceeding thousands hours of videos with millions faces of hundreds character .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
On the other hand , efficiency is also an issue of such a face retrieval system beside its accuracy since scales of available datasets are getting larger rapidly , for instance , exceeding thousands hours of videos with millions faces of hundreds character .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
On the other hand , efficiency is also an issue of such a face retrieval system beside its accuracy since scales of available datasets are getting larger rapidly , for instance , exceeding thousands hours of videos with millions faces of hundreds character .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
On the other hand , efficiency is also an issue of such a face retrieval system beside its accuracy since scales of available datasets are getting larger rapidly , for instance , exceeding thousands hours of videos with millions faces of hundreds character .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
On the other hand , efficiency is also an issue of such a face retrieval system beside its accuracy since scales of available datasets are getting larger rapidly , for instance , exceeding thousands hours of videos with millions faces of hundreds character .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
On the other hand , efficiency is also an issue of such a face retrieval system beside its accuracy since scales of available datasets are getting larger rapidly , for instance , exceeding thousands hours of videos with millions faces of hundreds character .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
On the other hand , efficiency is also an issue of such a face retrieval system beside its accuracy since scales of available datasets are getting larger rapidly , for instance , exceeding thousands hours of videos with millions faces of hundreds character .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
On the other hand , efficiency is also an issue of such a face retrieval system beside its accuracy since scales of available datasets are getting larger rapidly , for instance , exceeding thousands hours of videos with millions faces of hundreds character .
#<struct ReadData::Alignment source_numbers="", target_numbers="40", tag_name="wa">
Thus , accurate and efficient approaches for face retrieval are always required.
#<struct ReadData::Alignment source_numbers="5,6", target_numbers="5,6", tag_name="wa">
Generally , there are two principle steps in a face retrieval system .
#<struct ReadData::Alignment source_numbers="3", target_numbers="6", tag_name="wa">
Generally , there are two principle steps in a face retrieval system .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Generally , there are two principle steps in a face retrieval system .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Generally , there are two principle steps in a face retrieval system .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Generally , there are two principle steps in a face retrieval system .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Generally , there are two principle steps in a face retrieval system .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
And , the second step is matching the extracted ones with a given query to return a rank list .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
And , the second step is matching the extracted ones with a given query to return a rank list .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
And , the second step is matching the extracted ones with a given query to return a rank list .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
And , the second step is matching the extracted ones with a given query to return a rank list .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
And , the second step is matching the extracted ones with a given query to return a rank list .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
And , the second step is matching the extracted ones with a given query to return a rank list .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
And , the second step is matching the extracted ones with a given query to return a rank list .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
While conventional approaches consider single face images as the basic units for extracting and matching \CITE , recently proposed approaches sifted towards sets of face images called face-tracks .
#<struct ReadData::Alignment source_numbers="21", target_numbers="21,22", tag_name="wa">
While conventional approaches consider single face images as the basic units for extracting and matching \CITE , recently proposed approaches sifted towards sets of face images called face-tracks .
#<struct ReadData::Alignment source_numbers="28", target_numbers="32", tag_name="wa">
While conventional approaches consider single face images as the basic units for extracting and matching \CITE , recently proposed approaches sifted towards sets of face images called face-tracks .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
While conventional approaches consider single face images as the basic units for extracting and matching \CITE , recently proposed approaches sifted towards sets of face images called face-tracks .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
While conventional approaches consider single face images as the basic units for extracting and matching \CITE , recently proposed approaches sifted towards sets of face images called face-tracks .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
While conventional approaches consider single face images as the basic units for extracting and matching \CITE , recently proposed approaches sifted towards sets of face images called face-tracks .
#<struct ReadData::Alignment source_numbers="27", target_numbers="", tag_name="wa">
While conventional approaches consider single face images as the basic units for extracting and matching \CITE , recently proposed approaches sifted towards sets of face images called face-tracks .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
While conventional approaches consider single face images as the basic units for extracting and matching \CITE , recently proposed approaches sifted towards sets of face images called face-tracks .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
While conventional approaches consider single face images as the basic units for extracting and matching \CITE , recently proposed approaches sifted towards sets of face images called face-tracks .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
While conventional approaches consider single face images as the basic units for extracting and matching \CITE , recently proposed approaches sifted towards sets of face images called face-tracks .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
While conventional approaches consider single face images as the basic units for extracting and matching \CITE , recently proposed approaches sifted towards sets of face images called face-tracks .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
While conventional approaches consider single face images as the basic units for extracting and matching \CITE , recently proposed approaches sifted towards sets of face images called face-tracks .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
While conventional approaches consider single face images as the basic units for extracting and matching \CITE , recently proposed approaches sifted towards sets of face images called face-tracks .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
A face-track contains multiple face images belonging to the same individual character within a video shot .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
A face-track contains multiple face images belonging to the same individual character within a video shot .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
A face-track contains multiple face images belonging to the same individual character within a video shot .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Face images in a face-track may present the corresponding character under different viewpoints and facial expressions ( as shown in Figure 1 ) .
#<struct ReadData::Alignment source_numbers="23", target_numbers="27", tag_name="wa">
Face images in a face-track may present the corresponding character under different viewpoints and facial expressions ( as shown in Figure 1 ) .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Face images in a face-track may present the corresponding character under different viewpoints and facial expressions ( as shown in Figure 1 ) .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
Face images in a face-track may present the corresponding character under different viewpoints and facial expressions ( as shown in Figure 1 ) .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Face images in a face-track may present the corresponding character under different viewpoints and facial expressions ( as shown in Figure 1 ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Face images in a face-track may present the corresponding character under different viewpoints and facial expressions ( as shown in Figure 1 ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Face images in a face-track may present the corresponding character under different viewpoints and facial expressions ( as shown in Figure 1 ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Face images in a face-track may present the corresponding character under different viewpoints and facial expressions ( as shown in Figure 1 ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
Face images in a face-track may present the corresponding character under different viewpoints and facial expressions ( as shown in Figure 1 ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
By exploiting the plenteous information from multiple exemplar faces in face-tracks , face-track based approaches are expected to achieve more robust and stable performance.
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
By exploiting the plenteous information from multiple exemplar faces in face-tracks , face-track based approaches are expected to achieve more robust and stable performance.
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
By exploiting the plenteous information from multiple exemplar faces in face-tracks , face-track based approaches are expected to achieve more robust and stable performance.
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
By exploiting the plenteous information from multiple exemplar faces in face-tracks , face-track based approaches are expected to achieve more robust and stable performance.
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
By exploiting the plenteous information from multiple exemplar faces in face-tracks , face-track based approaches are expected to achieve more robust and stable performance.
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
By exploiting the plenteous information from multiple exemplar faces in face-tracks , face-track based approaches are expected to achieve more robust and stable performance.
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
By exploiting the plenteous information from multiple exemplar faces in face-tracks , face-track based approaches are expected to achieve more robust and stable performance.
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
Once all face-tracks in video shots are extracted , they are matched with the query to return a ranked list as the output of the face retrieval system .
#<struct ReadData::Alignment source_numbers="24", target_numbers="2", tag_name="wa">
Once all face-tracks in video shots are extracted , they are matched with the query to return a ranked list as the output of the face retrieval system .
#<struct ReadData::Alignment source_numbers="25", target_numbers="3", tag_name="wa">
Once all face-tracks in video shots are extracted , they are matched with the query to return a ranked list as the output of the face retrieval system .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Once all face-tracks in video shots are extracted , they are matched with the query to return a ranked list as the output of the face retrieval system .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Once all face-tracks in video shots are extracted , they are matched with the query to return a ranked list as the output of the face retrieval system .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Once all face-tracks in video shots are extracted , they are matched with the query to return a ranked list as the output of the face retrieval system .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
Once all face-tracks in video shots are extracted , they are matched with the query to return a ranked list as the output of the face retrieval system .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
Since each face-track is a set of face images , matching face-tracks essentially can be thought of as a problem of matching image sets .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Since each face-track is a set of face images , matching face-tracks essentially can be thought of as a problem of matching image sets .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Since each face-track is a set of face images , matching face-tracks essentially can be thought of as a problem of matching image sets .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
Since each face-track is a set of face images , matching face-tracks essentially can be thought of as a problem of matching image sets .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Since each face-track is a set of face images , matching face-tracks essentially can be thought of as a problem of matching image sets .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Since each face-track is a set of face images , matching face-tracks essentially can be thought of as a problem of matching image sets .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Since each face-track is a set of face images , matching face-tracks essentially can be thought of as a problem of matching image sets .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
Since each face-track is a set of face images , matching face-tracks essentially can be thought of as a problem of matching image sets .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
There are several approaches introduced to deal with this problem \CITE .
#<struct ReadData::Alignment source_numbers="1", target_numbers="2,3", tag_name="wa">
There are several approaches introduced to deal with this problem \CITE .
#<struct ReadData::Alignment source_numbers="4", target_numbers="4", tag_name="wa">
There are several approaches introduced to deal with this problem \CITE .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
There are several approaches introduced to deal with this problem \CITE .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
There are several approaches introduced to deal with this problem \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
In these works , image set has been modeled in different way , such as distributions \CITE , subspaces \CITE , convex geometric region in feature space \CITE , or more general manifolds \CITE .
#<struct ReadData::Alignment source_numbers="14", target_numbers="15", tag_name="wa">
In these works , image set has been modeled in different way , such as distributions \CITE , subspaces \CITE , convex geometric region in feature space \CITE , or more general manifolds \CITE .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
In these works , image set has been modeled in different way , such as distributions \CITE , subspaces \CITE , convex geometric region in feature space \CITE , or more general manifolds \CITE .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
In these works , image set has been modeled in different way , such as distributions \CITE , subspaces \CITE , convex geometric region in feature space \CITE , or more general manifolds \CITE .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
In these works , image set has been modeled in different way , such as distributions \CITE , subspaces \CITE , convex geometric region in feature space \CITE , or more general manifolds \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
In these works , image set has been modeled in different way , such as distributions \CITE , subspaces \CITE , convex geometric region in feature space \CITE , or more general manifolds \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
In these works , image set has been modeled in different way , such as distributions \CITE , subspaces \CITE , convex geometric region in feature space \CITE , or more general manifolds \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Although these approaches shown promising results on benchmark datasets , they require high computational costs to characterize the representation of face-tracks , such as computing the convex geometric region in \CITE , the probability in \CITE , and the eigenvectors in \CITE .
#<struct ReadData::Alignment source_numbers="3", target_numbers="4", tag_name="wa">
Although these approaches shown promising results on benchmark datasets , they require high computational costs to characterize the representation of face-tracks , such as computing the convex geometric region in \CITE , the probability in \CITE , and the eigenvectors in \CITE .
#<struct ReadData::Alignment source_numbers="40", target_numbers="7", tag_name="wa">
Although these approaches shown promising results on benchmark datasets , they require high computational costs to characterize the representation of face-tracks , such as computing the convex geometric region in \CITE , the probability in \CITE , and the eigenvectors in \CITE .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
Although these approaches shown promising results on benchmark datasets , they require high computational costs to characterize the representation of face-tracks , such as computing the convex geometric region in \CITE , the probability in \CITE , and the eigenvectors in \CITE .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
Although these approaches shown promising results on benchmark datasets , they require high computational costs to characterize the representation of face-tracks , such as computing the convex geometric region in \CITE , the probability in \CITE , and the eigenvectors in \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Although these approaches shown promising results on benchmark datasets , they require high computational costs to characterize the representation of face-tracks , such as computing the convex geometric region in \CITE , the probability in \CITE , and the eigenvectors in \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
Although these approaches shown promising results on benchmark datasets , they require high computational costs to characterize the representation of face-tracks , such as computing the convex geometric region in \CITE , the probability in \CITE , and the eigenvectors in \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
Although these approaches shown promising results on benchmark datasets , they require high computational costs to characterize the representation of face-tracks , such as computing the convex geometric region in \CITE , the probability in \CITE , and the eigenvectors in \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="42", tag_name="wa">
Their complexity in modeling facetracks and estimating similarity between face-tracks limits their practicability on large-scale datasets.
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
Their complexity in modeling facetracks and estimating similarity between face-tracks limits their practicability on large-scale datasets.
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Their complexity in modeling facetracks and estimating similarity between face-tracks limits their practicability on large-scale datasets.
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
Their complexity in modeling facetracks and estimating similarity between face-tracks limits their practicability on large-scale datasets.
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Their complexity in modeling facetracks and estimating similarity between face-tracks limits their practicability on large-scale datasets.
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Their complexity in modeling facetracks and estimating similarity between face-tracks limits their practicability on large-scale datasets.
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
Their complexity in modeling facetracks and estimating similarity between face-tracks limits their practicability on large-scale datasets.
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
Their complexity in modeling facetracks and estimating similarity between face-tracks limits their practicability on large-scale datasets.
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
Working toward solving the above problems , our contributions in this paper is three-fold.
#<struct ReadData::Alignment source_numbers="12", target_numbers="2", tag_name="wa">
Working toward solving the above problems , our contributions in this paper is three-fold.
#<struct ReadData::Alignment source_numbers="6", target_numbers="11", tag_name="wa">
Working toward solving the above problems , our contributions in this paper is three-fold.
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Working toward solving the above problems , our contributions in this paper is three-fold.
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Working toward solving the above problems , our contributions in this paper is three-fold.
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Working toward solving the above problems , our contributions in this paper is three-fold.
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Working toward solving the above problems , our contributions in this paper is three-fold.
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Working toward solving the above problems , our contributions in this paper is three-fold.
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
Working toward solving the above problems , our contributions in this paper is three-fold.
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Working toward solving the above problems , our contributions in this paper is three-fold.
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Working toward solving the above problems , our contributions in this paper is three-fold.
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Working toward solving the above problems , our contributions in this paper is three-fold.
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Working toward solving the above problems , our contributions in this paper is three-fold.
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
Robust face-track extraction on news video .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
Robust face-track extraction on news video .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
To enhance the performance of face-track matching , face-tracks should be first extracted accurately .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
To enhance the performance of face-track matching , face-tracks should be first extracted accurately .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
To enhance the performance of face-track matching , face-tracks should be first extracted accurately .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
, We introduce an approach for this purpose .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
, We introduce an approach for this purpose .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
, We introduce an approach for this purpose .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
, We introduce an approach for this purpose .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Our approach is motivated by a study of Everingham et al .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Our approach is motivated by a study of Everingham et al .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Our approach is motivated by a study of Everingham et al .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
The basic idea is to employ a point tracker ( Kanade-Lucas-Tomasi tracker \CITE ) to establish the connections between faces belonging to the same character in consecutive frames of a shot .
#<struct ReadData::Alignment source_numbers="5,6", target_numbers="5,6", tag_name="wa">
, In constrast to the approach in \CITE , which is failed to deal with specific problems of news video caused by sudden illumination change and partial occlusion , our approach is incorporated techniques to overcome the problems .
#<struct ReadData::Alignment source_numbers="31,32", target_numbers="2", tag_name="wa">
, In constrast to the approach in \CITE , which is failed to deal with specific problems of news video caused by sudden illumination change and partial occlusion , our approach is incorporated techniques to overcome the problems .
#<struct ReadData::Alignment source_numbers="15", target_numbers="6", tag_name="wa">
, In constrast to the approach in \CITE , which is failed to deal with specific problems of news video caused by sudden illumination change and partial occlusion , our approach is incorporated techniques to overcome the problems .
#<struct ReadData::Alignment source_numbers="16", target_numbers="7", tag_name="wa">
, In constrast to the approach in \CITE , which is failed to deal with specific problems of news video caused by sudden illumination change and partial occlusion , our approach is incorporated techniques to overcome the problems .
#<struct ReadData::Alignment source_numbers="14", target_numbers="8", tag_name="wa">
, In constrast to the approach in \CITE , which is failed to deal with specific problems of news video caused by sudden illumination change and partial occlusion , our approach is incorporated techniques to overcome the problems .
#<struct ReadData::Alignment source_numbers="28", target_numbers="19", tag_name="wa">
, In constrast to the approach in \CITE , which is failed to deal with specific problems of news video caused by sudden illumination change and partial occlusion , our approach is incorporated techniques to overcome the problems .
#<struct ReadData::Alignment source_numbers="6", target_numbers="20", tag_name="wa">
, In constrast to the approach in \CITE , which is failed to deal with specific problems of news video caused by sudden illumination change and partial occlusion , our approach is incorporated techniques to overcome the problems .
#<struct ReadData::Alignment source_numbers="8", target_numbers="27", tag_name="wa">
, In constrast to the approach in \CITE , which is failed to deal with specific problems of news video caused by sudden illumination change and partial occlusion , our approach is incorporated techniques to overcome the problems .
#<struct ReadData::Alignment source_numbers="11", target_numbers="29", tag_name="wa">
, In constrast to the approach in \CITE , which is failed to deal with specific problems of news video caused by sudden illumination change and partial occlusion , our approach is incorporated techniques to overcome the problems .
#<struct ReadData::Alignment source_numbers="0", target_numbers="33", tag_name="wa">
, In constrast to the approach in \CITE , which is failed to deal with specific problems of news video caused by sudden illumination change and partial occlusion , our approach is incorporated techniques to overcome the problems .
#<struct ReadData::Alignment source_numbers="36,37", target_numbers="34,35", tag_name="wa">
, In constrast to the approach in \CITE , which is failed to deal with specific problems of news video caused by sudden illumination change and partial occlusion , our approach is incorporated techniques to overcome the problems .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
, In constrast to the approach in \CITE , which is failed to deal with specific problems of news video caused by sudden illumination change and partial occlusion , our approach is incorporated techniques to overcome the problems .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
, In constrast to the approach in \CITE , which is failed to deal with specific problems of news video caused by sudden illumination change and partial occlusion , our approach is incorporated techniques to overcome the problems .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
, In constrast to the approach in \CITE , which is failed to deal with specific problems of news video caused by sudden illumination change and partial occlusion , our approach is incorporated techniques to overcome the problems .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
, In constrast to the approach in \CITE , which is failed to deal with specific problems of news video caused by sudden illumination change and partial occlusion , our approach is incorporated techniques to overcome the problems .
#<struct ReadData::Alignment source_numbers="29", target_numbers="", tag_name="wa">
, In constrast to the approach in \CITE , which is failed to deal with specific problems of news video caused by sudden illumination change and partial occlusion , our approach is incorporated techniques to overcome the problems .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
, In constrast to the approach in \CITE , which is failed to deal with specific problems of news video caused by sudden illumination change and partial occlusion , our approach is incorporated techniques to overcome the problems .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
, In constrast to the approach in \CITE , which is failed to deal with specific problems of news video caused by sudden illumination change and partial occlusion , our approach is incorporated techniques to overcome the problems .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
, In constrast to the approach in \CITE , which is failed to deal with specific problems of news video caused by sudden illumination change and partial occlusion , our approach is incorporated techniques to overcome the problems .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
Evaluations on a collection of real-world news videos showed that our proposed face-track extraction approach achieved approximately 95% accuracy , a significant improvement compare the approach in \CITE .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Evaluations on a collection of real-world news videos showed that our proposed face-track extraction approach achieved approximately 95% accuracy , a significant improvement compare the approach in \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
We introduce an approach which significantly reduces the computational cost for face-track matching while maintaining a competitive performance compare to those of the state-of-the-art approaches .
#<struct ReadData::Alignment source_numbers="3,4", target_numbers="3,4", tag_name="wa">
We introduce an approach which significantly reduces the computational cost for face-track matching while maintaining a competitive performance compare to those of the state-of-the-art approaches .
#<struct ReadData::Alignment source_numbers="25", target_numbers="21", tag_name="wa">
We introduce an approach which significantly reduces the computational cost for face-track matching while maintaining a competitive performance compare to those of the state-of-the-art approaches .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
We introduce an approach which significantly reduces the computational cost for face-track matching while maintaining a competitive performance compare to those of the state-of-the-art approaches .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
We introduce an approach which significantly reduces the computational cost for face-track matching while maintaining a competitive performance compare to those of the state-of-the-art approaches .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
We introduce an approach which significantly reduces the computational cost for face-track matching while maintaining a competitive performance compare to those of the state-of-the-art approaches .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
We introduce an approach which significantly reduces the computational cost for face-track matching while maintaining a competitive performance compare to those of the state-of-the-art approaches .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
Based on the observation that face-tracks obtained by tracking provide highly similar faces in consecutive frames , we argue that it is redundant to use all faces in a face-track for learning the variation of faces .
#<struct ReadData::Alignment source_numbers="32", target_numbers="27", tag_name="wa">
Based on the observation that face-tracks obtained by tracking provide highly similar faces in consecutive frames , we argue that it is redundant to use all faces in a face-track for learning the variation of faces .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Based on the observation that face-tracks obtained by tracking provide highly similar faces in consecutive frames , we argue that it is redundant to use all faces in a face-track for learning the variation of faces .
#<struct ReadData::Alignment source_numbers="29", target_numbers="", tag_name="wa">
Based on the observation that face-tracks obtained by tracking provide highly similar faces in consecutive frames , we argue that it is redundant to use all faces in a face-track for learning the variation of faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Based on the observation that face-tracks obtained by tracking provide highly similar faces in consecutive frames , we argue that it is redundant to use all faces in a face-track for learning the variation of faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Based on the observation that face-tracks obtained by tracking provide highly similar faces in consecutive frames , we argue that it is redundant to use all faces in a face-track for learning the variation of faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
Based on the observation that face-tracks obtained by tracking provide highly similar faces in consecutive frames , we argue that it is redundant to use all faces in a face-track for learning the variation of faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
Based on the observation that face-tracks obtained by tracking provide highly similar faces in consecutive frames , we argue that it is redundant to use all faces in a face-track for learning the variation of faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
Thus , a set of faces is sampled from the original face-track for matching .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
Thus , a set of faces is sampled from the original face-track for matching .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
Thus , a set of faces is sampled from the original face-track for matching .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
The size of the set is much smaller than the size of original face-track .
#<struct ReadData::Alignment source_numbers="9", target_numbers="11", tag_name="wa">
The size of the set is much smaller than the size of original face-track .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
The size of the set is much smaller than the size of original face-track .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
The size of the set is much smaller than the size of original face-track .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
The size of the set is much smaller than the size of original face-track .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
The size of the set is much smaller than the size of original face-track .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Then , the mean face of sampled faces in the set is computed .
#<struct ReadData::Alignment source_numbers="1", target_numbers="1", tag_name="wa">
Then , the mean face of sampled faces in the set is computed .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Then , the mean face of sampled faces in the set is computed .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Then , the mean face of sampled faces in the set is computed .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
The similarity between two face-tracks is the distance between their mean faces.
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
The similarity between two face-tracks is the distance between their mean faces.
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
The similarity between two face-tracks is the distance between their mean faces.
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
We investigated the problem of face-retrieval on news video datasets whose scales have not been considered in literature ever .
#<struct ReadData::Alignment source_numbers="13", target_numbers="14", tag_name="wa">
We investigated the problem of face-retrieval on news video datasets whose scales have not been considered in literature ever .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
We investigated the problem of face-retrieval on news video datasets whose scales have not been considered in literature ever .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
We investigated the problem of face-retrieval on news video datasets whose scales have not been considered in literature ever .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
We investigated the problem of face-retrieval on news video datasets whose scales have not been considered in literature ever .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
We investigated the problem of face-retrieval on news video datasets whose scales have not been considered in literature ever .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
We investigated the problem of face-retrieval on news video datasets whose scales have not been considered in literature ever .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Our first dataset is from 370 hours TRECVID news videos which contains 405,887 detected faces belonging to 41 individuals .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Our first dataset is from 370 hours TRECVID news videos which contains 405,887 detected faces belonging to 41 individuals .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Our first dataset is from 370 hours TRECVID news videos which contains 405,887 detected faces belonging to 41 individuals .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
The second dataset is observed from NHK News7 channel in 11 years .
#<struct ReadData::Alignment source_numbers="4", target_numbers="10", tag_name="wa">
The second dataset is observed from NHK News7 channel in 11 years .
#<struct ReadData::Alignment source_numbers="6", target_numbers="13", tag_name="wa">
The second dataset is observed from NHK News7 channel in 11 years .
#<struct ReadData::Alignment source_numbers="10", target_numbers="18", tag_name="wa">
The second dataset is observed from NHK News7 channel in 11 years .
#<struct ReadData::Alignment source_numbers="11", target_numbers="19", tag_name="wa">
The second dataset is observed from NHK News7 channel in 11 years .
#<struct ReadData::Alignment source_numbers="12", target_numbers="20", tag_name="wa">
The second dataset is observed from NHK News7 channel in 11 years .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
The second dataset is observed from NHK News7 channel in 11 years .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
The second dataset is observed from NHK News7 channel in 11 years .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
The second dataset is observed from NHK News7 channel in 11 years .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
The second dataset is observed from NHK News7 channel in 11 years .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
The second dataset is observed from NHK News7 channel in 11 years .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
The second dataset is observed from NHK News7 channel in 11 years .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
The second dataset is observed from NHK News7 channel in 11 years .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
The second dataset is observed from NHK News7 channel in 11 years .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
The second dataset is observed from NHK News7 channel in 11 years .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
The second dataset is observed from NHK News7 channel in 11 years .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
The second dataset is observed from NHK News7 channel in 11 years .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
The second dataset is observed from NHK News7 channel in 11 years .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
The second dataset is observed from NHK News7 channel in 11 years .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
The second dataset is observed from NHK News7 channel in 11 years .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
The second dataset is observed from NHK News7 channel in 11 years .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
In this dataset , 1.2 millions faces of 111 individuals are provided .
#<struct ReadData::Alignment source_numbers="12", target_numbers="1", tag_name="wa">
In this dataset , 1.2 millions faces of 111 individuals are provided .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
In this dataset , 1.2 millions faces of 111 individuals are provided .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
In this dataset , 1.2 millions faces of 111 individuals are provided .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
In this dataset , 1.2 millions faces of 111 individuals are provided .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
In this dataset , 1.2 millions faces of 111 individuals are provided .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
In this dataset , 1.2 millions faces of 111 individuals are provided .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
In this dataset , 1.2 millions faces of 111 individuals are provided .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
In this dataset , 1.2 millions faces of 111 individuals are provided .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
In this dataset , 1.2 millions faces of 111 individuals are provided .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
In this dataset , 1.2 millions faces of 111 individuals are provided .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
In this dataset , 1.2 millions faces of 111 individuals are provided .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
The total number of available face-track is 5,567 .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
The total number of available face-track is 5,567 .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
The total number of available face-track is 5,567 .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Number of occurrence of each individual character varies from 4 to 550 .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Number of occurrence of each individual character varies from 4 to 550 .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Section 3 and Section 4 describe our face-track extraction and matching , approaches respectively .
#<struct ReadData::Alignment source_numbers="0", target_numbers="0", tag_name="wa">
Section 3 and Section 4 describe our face-track extraction and matching , approaches respectively .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
Section 5 presents our experimental settings , .
#<struct ReadData::Alignment source_numbers="7", target_numbers="12", tag_name="wa">
Section 5 presents our experimental settings , .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Section 5 presents our experimental settings , .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Section 5 presents our experimental settings , .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Section 5 presents our experimental settings , .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Section 5 presents our experimental settings , .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
Conclusion is given in the final Section 6.
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Conclusion is given in the final Section 6.
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Conclusion is given in the final Section 6.
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Conclusion is given in the final Section 6.
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
Conclusion is given in the final Section 6.
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
Conclusion is given in the final Section 6.
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Conclusion is given in the final Section 6.
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
Conclusion is given in the final Section 6.
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Conclusion is given in the final Section 6.
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Existing studies on automatic face-track extraction follow a standard paradigm that consists of two basic steps , detecting faces in frames and grouping faces of the same character into face-tracks .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Existing studies on automatic face-track extraction follow a standard paradigm that consists of two basic steps , detecting faces in frames and grouping faces of the same character into face-tracks .
#<struct ReadData::Alignment source_numbers="29", target_numbers="", tag_name="wa">
Existing studies on automatic face-track extraction follow a standard paradigm that consists of two basic steps , detecting faces in frames and grouping faces of the same character into face-tracks .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Existing studies on automatic face-track extraction follow a standard paradigm that consists of two basic steps , detecting faces in frames and grouping faces of the same character into face-tracks .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
Existing studies on automatic face-track extraction follow a standard paradigm that consists of two basic steps , detecting faces in frames and grouping faces of the same character into face-tracks .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
Then , in the second step , detected faces of the same character will be grouped by using either clustering approaches \CITE or tracking approaches \CITE .
#<struct ReadData::Alignment source_numbers="13,14", target_numbers="13", tag_name="wa">
Then , in the second step , detected faces of the same character will be grouped by using either clustering approaches \CITE or tracking approaches \CITE .
#<struct ReadData::Alignment source_numbers="15", target_numbers="14", tag_name="wa">
Then , in the second step , detected faces of the same character will be grouped by using either clustering approaches \CITE or tracking approaches \CITE .
#<struct ReadData::Alignment source_numbers="24", target_numbers="22", tag_name="wa">
Then , in the second step , detected faces of the same character will be grouped by using either clustering approaches \CITE or tracking approaches \CITE .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Then , in the second step , detected faces of the same character will be grouped by using either clustering approaches \CITE or tracking approaches \CITE .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Then , in the second step , detected faces of the same character will be grouped by using either clustering approaches \CITE or tracking approaches \CITE .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
Then , in the second step , detected faces of the same character will be grouped by using either clustering approaches \CITE or tracking approaches \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
builds a color histogram for the hair , face , and torso associated with each detected face in a frame .
#<struct ReadData::Alignment source_numbers="0", target_numbers="0", tag_name="wa">
A concatenated vector of the normalized color histograms represents the face .
#<struct ReadData::Alignment source_numbers="8,9", target_numbers="8,9", tag_name="wa">
Limitations of this approach includes the expensive computational cost for constructing and clustering high dimensional representation feature vectors; and , its dependence on determining a reasonable threshold for the clustering algorithm to ensure no group contains faces of multiple characters and groups are not over-fragmented.
#<struct ReadData::Alignment source_numbers="20", target_numbers="6", tag_name="wa">
Limitations of this approach includes the expensive computational cost for constructing and clustering high dimensional representation feature vectors; and , its dependence on determining a reasonable threshold for the clustering algorithm to ensure no group contains faces of multiple characters and groups are not over-fragmented.
#<struct ReadData::Alignment source_numbers="13", target_numbers="7", tag_name="wa">
Limitations of this approach includes the expensive computational cost for constructing and clustering high dimensional representation feature vectors; and , its dependence on determining a reasonable threshold for the clustering algorithm to ensure no group contains faces of multiple characters and groups are not over-fragmented.
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Limitations of this approach includes the expensive computational cost for constructing and clustering high dimensional representation feature vectors; and , its dependence on determining a reasonable threshold for the clustering algorithm to ensure no group contains faces of multiple characters and groups are not over-fragmented.
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Limitations of this approach includes the expensive computational cost for constructing and clustering high dimensional representation feature vectors; and , its dependence on determining a reasonable threshold for the clustering algorithm to ensure no group contains faces of multiple characters and groups are not over-fragmented.
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
Limitations of this approach includes the expensive computational cost for constructing and clustering high dimensional representation feature vectors; and , its dependence on determining a reasonable threshold for the clustering algorithm to ensure no group contains faces of multiple characters and groups are not over-fragmented.
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
Limitations of this approach includes the expensive computational cost for constructing and clustering high dimensional representation feature vectors; and , its dependence on determining a reasonable threshold for the clustering algorithm to ensure no group contains faces of multiple characters and groups are not over-fragmented.
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
Limitations of this approach includes the expensive computational cost for constructing and clustering high dimensional representation feature vectors; and , its dependence on determining a reasonable threshold for the clustering algorithm to ensure no group contains faces of multiple characters and groups are not over-fragmented.
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Limitations of this approach includes the expensive computational cost for constructing and clustering high dimensional representation feature vectors; and , its dependence on determining a reasonable threshold for the clustering algorithm to ensure no group contains faces of multiple characters and groups are not over-fragmented.
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Limitations of this approach includes the expensive computational cost for constructing and clustering high dimensional representation feature vectors; and , its dependence on determining a reasonable threshold for the clustering algorithm to ensure no group contains faces of multiple characters and groups are not over-fragmented.
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Limitations of this approach includes the expensive computational cost for constructing and clustering high dimensional representation feature vectors; and , its dependence on determining a reasonable threshold for the clustering algorithm to ensure no group contains faces of multiple characters and groups are not over-fragmented.
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
Limitations of this approach includes the expensive computational cost for constructing and clustering high dimensional representation feature vectors; and , its dependence on determining a reasonable threshold for the clustering algorithm to ensure no group contains faces of multiple characters and groups are not over-fragmented.
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
Limitations of this approach includes the expensive computational cost for constructing and clustering high dimensional representation feature vectors; and , its dependence on determining a reasonable threshold for the clustering algorithm to ensure no group contains faces of multiple characters and groups are not over-fragmented.
#<struct ReadData::Alignment source_numbers="", target_numbers="42", tag_name="wa">
On the other hand , Everingham etl al .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
On the other hand , Everingham etl al .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
This tracker can develop tracks on deforming objects , where the between frame region deformation can be modelled by an affine geometric transformation plus perturbations .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
This tracker can develop tracks on deforming objects , where the between frame region deformation can be modelled by an affine geometric transformation plus perturbations .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
This tracker can develop tracks on deforming objects , where the between frame region deformation can be modelled by an affine geometric transformation plus perturbations .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
The disadvantage of this tracker is the computational cost for locating and tracking affine covariance regions .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
The disadvantage of this tracker is the computational cost for locating and tracking affine covariance regions .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
The disadvantage of this tracker is the computational cost for locating and tracking affine covariance regions .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
in \CITE , .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
in \CITE , .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
The authors employ Kanade-Lucas-Tomasi ( KLT ) tracker to create a set of point tracks starting at some frame in a shot and continuing until some later frame .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
The authors employ Kanade-Lucas-Tomasi ( KLT ) tracker to create a set of point tracks starting at some frame in a shot and continuing until some later frame .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
The authors employ Kanade-Lucas-Tomasi ( KLT ) tracker to create a set of point tracks starting at some frame in a shot and continuing until some later frame .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
The authors employ Kanade-Lucas-Tomasi ( KLT ) tracker to create a set of point tracks starting at some frame in a shot and continuing until some later frame .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
The authors employ Kanade-Lucas-Tomasi ( KLT ) tracker to create a set of point tracks starting at some frame in a shot and continuing until some later frame .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
The authors employ Kanade-Lucas-Tomasi ( KLT ) tracker to create a set of point tracks starting at some frame in a shot and continuing until some later frame .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Grouping faces in different frames of one character is based on enumerating track points shared between faces .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Grouping faces in different frames of one character is based on enumerating track points shared between faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Although using tracking is an efficient solution , it may return poor tracking results since trackers are very sensitive to illumination changes and partial occlusions .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
Although using tracking is an efficient solution , it may return poor tracking results since trackers are very sensitive to illumination changes and partial occlusions .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
There are two major categories of approaches target to employ multiple-exemplar of faces in face-tracks ( i.e. , sets of face images ) for robust face matching and recognition .
#<struct ReadData::Alignment source_numbers="20", target_numbers="14", tag_name="wa">
There are two major categories of approaches target to employ multiple-exemplar of faces in face-tracks ( i.e. , sets of face images ) for robust face matching and recognition .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
There are two major categories of approaches target to employ multiple-exemplar of faces in face-tracks ( i.e. , sets of face images ) for robust face matching and recognition .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
There are two major categories of approaches target to employ multiple-exemplar of faces in face-tracks ( i.e. , sets of face images ) for robust face matching and recognition .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
There are two major categories of approaches target to employ multiple-exemplar of faces in face-tracks ( i.e. , sets of face images ) for robust face matching and recognition .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
There are two major categories of approaches target to employ multiple-exemplar of faces in face-tracks ( i.e. , sets of face images ) for robust face matching and recognition .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
There are two major categories of approaches target to employ multiple-exemplar of faces in face-tracks ( i.e. , sets of face images ) for robust face matching and recognition .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
There are two major categories of approaches target to employ multiple-exemplar of faces in face-tracks ( i.e. , sets of face images ) for robust face matching and recognition .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
Approaches in the first category \CITE make use of both face images and temporal order of their appearances .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Approaches in the first category \CITE make use of both face images and temporal order of their appearances .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Approaches in the first category \CITE make use of both face images and temporal order of their appearances .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Face dynamics within the video sequence are modeled and exploited to improve recognition accuracy .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Face dynamics within the video sequence are modeled and exploited to improve recognition accuracy .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
They than use the trained statistical face model to incorporate identity evidence over a sequence .
#<struct ReadData::Alignment source_numbers="2,3", target_numbers="2,3", tag_name="wa">
They than use the trained statistical face model to incorporate identity evidence over a sequence .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
They than use the trained statistical face model to incorporate identity evidence over a sequence .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
In \CITE , Liu and Chen use an adaptive Hidden Markov Model ( HMM ) for this face recognition problem .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
In \CITE , Liu and Chen use an adaptive Hidden Markov Model ( HMM ) for this face recognition problem .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
In \CITE , Liu and Chen use an adaptive Hidden Markov Model ( HMM ) for this face recognition problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
In \CITE , Liu and Chen use an adaptive Hidden Markov Model ( HMM ) for this face recognition problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
In the training face , they create a HMM model for each character to learn the statistics and temporal dynamics using the eigen-face image sequence .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Without relying on temporal coherence between consecutive images , approaches in the second category uses multiple face images only .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Without relying on temporal coherence between consecutive images , approaches in the second category uses multiple face images only .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
They treat the problem as a set matching problem .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
They treat the problem as a set matching problem .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
They treat the problem as a set matching problem .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
They treat the problem as a set matching problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
However , to make the computation tractable , they made a assumption that faces are normally distributed , which may not be true \CITE .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
However , to make the computation tractable , they made a assumption that faces are normally distributed , which may not be true \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Cevikalp and Triggs \CITE claimed a face sequence was a set of points and discovered a convex geometric region expanded by these points .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
For this reason , they are not scalable for large-scale video datasets .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
For this reason , they are not scalable for large-scale video datasets .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Face Datasets .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Face Datasets .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
To evaluate performance of face matching approaches , most of recent works on face retrieval in video uses two benchmark datasets Mobo ( Motion of Body ) \CITE and Honda / UCSD \CITE .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
To evaluate performance of face matching approaches , most of recent works on face retrieval in video uses two benchmark datasets Mobo ( Motion of Body ) \CITE and Honda / UCSD \CITE .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
To evaluate performance of face matching approaches , most of recent works on face retrieval in video uses two benchmark datasets Mobo ( Motion of Body ) \CITE and Honda / UCSD \CITE .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
To evaluate performance of face matching approaches , most of recent works on face retrieval in video uses two benchmark datasets Mobo ( Motion of Body ) \CITE and Honda / UCSD \CITE .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
To evaluate performance of face matching approaches , most of recent works on face retrieval in video uses two benchmark datasets Mobo ( Motion of Body ) \CITE and Honda / UCSD \CITE .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
To evaluate performance of face matching approaches , most of recent works on face retrieval in video uses two benchmark datasets Mobo ( Motion of Body ) \CITE and Honda / UCSD \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
To evaluate performance of face matching approaches , most of recent works on face retrieval in video uses two benchmark datasets Mobo ( Motion of Body ) \CITE and Honda / UCSD \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
To evaluate performance of face matching approaches , most of recent works on face retrieval in video uses two benchmark datasets Mobo ( Motion of Body ) \CITE and Honda / UCSD \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
To evaluate performance of face matching approaches , most of recent works on face retrieval in video uses two benchmark datasets Mobo ( Motion of Body ) \CITE and Honda / UCSD \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
Scales of these datasets are limited , they are varying from hundreds to thousands face images of tens individual characters .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Scales of these datasets are limited , they are varying from hundreds to thousands face images of tens individual characters .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Scales of these datasets are limited , they are varying from hundreds to thousands face images of tens individual characters .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Scales of these datasets are limited , they are varying from hundreds to thousands face images of tens individual characters .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
One of the largest available face dataset recently is the Youtube Faces dataset \CITE , .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
One of the largest available face dataset recently is the Youtube Faces dataset \CITE , .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
One of the largest available face dataset recently is the Youtube Faces dataset \CITE , .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
It provides 3,425 videos of 1,595 individual characters .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
However , one character has only around 2.15 videos .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
However , one character has only around 2.15 videos .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Such a small number of samples for each character is not sufficient for stably evaluating a face matching or recognition approach , which is an important part of a face retrieval system .
#<struct ReadData::Alignment source_numbers="11,12", target_numbers="11,12", tag_name="wa">
Such a small number of samples for each character is not sufficient for stably evaluating a face matching or recognition approach , which is an important part of a face retrieval system .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
Such a small number of samples for each character is not sufficient for stably evaluating a face matching or recognition approach , which is an important part of a face retrieval system .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
Such a small number of samples for each character is not sufficient for stably evaluating a face matching or recognition approach , which is an important part of a face retrieval system .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
Because of all above mentioned reasons , we prepare new datasets for evaluating the approaches.
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Because of all above mentioned reasons , we prepare new datasets for evaluating the approaches.
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
Because of all above mentioned reasons , we prepare new datasets for evaluating the approaches.
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
Because of all above mentioned reasons , we prepare new datasets for evaluating the approaches.
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Because of all above mentioned reasons , we prepare new datasets for evaluating the approaches.
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Because of all above mentioned reasons , we prepare new datasets for evaluating the approaches.
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
In the offline stage , face-tracks in all shots of videos are extracted using our face-track extraction approach ( described in Section 4 ) .
#<struct ReadData::Alignment source_numbers="9,10", target_numbers="10", tag_name="wa">
In the offline stage , face-tracks in all shots of videos are extracted using our face-track extraction approach ( described in Section 4 ) .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
In the offline stage , face-tracks in all shots of videos are extracted using our face-track extraction approach ( described in Section 4 ) .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
In the offline stage , face-tracks in all shots of videos are extracted using our face-track extraction approach ( described in Section 4 ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
In the offline stage , face-tracks in all shots of videos are extracted using our face-track extraction approach ( described in Section 4 ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
In the offline stage , face-tracks in all shots of videos are extracted using our face-track extraction approach ( described in Section 4 ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
One extracted face-track contains multiple face images of one individual character , varied under different viewpoints , illumination conditions , and expressions within a shot .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
One extracted face-track contains multiple face images of one individual character , varied under different viewpoints , illumination conditions , and expressions within a shot .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
One extracted face-track contains multiple face images of one individual character , varied under different viewpoints , illumination conditions , and expressions within a shot .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
One extracted face-track contains multiple face images of one individual character , varied under different viewpoints , illumination conditions , and expressions within a shot .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
One extracted face-track contains multiple face images of one individual character , varied under different viewpoints , illumination conditions , and expressions within a shot .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
A single face image in a face-track is represented by a feature vector .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
A single face image in a face-track is represented by a feature vector .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
A single face image in a face-track is represented by a feature vector .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
A single face image in a face-track is represented by a feature vector .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
A single face image in a face-track is represented by a feature vector .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Our contribution here is to make the face-track extraction approach robust to sudden illumination changes , scattered appearance of characters , and occlusions.
#<struct ReadData::Alignment source_numbers="5", target_numbers="4", tag_name="wa">
Our contribution here is to make the face-track extraction approach robust to sudden illumination changes , scattered appearance of characters , and occlusions.
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
Given a face-track as an input retrieval query , the online stage of our system starts by using our proposed face-track matching algorithm ( described in Section 5 ) to estimate the similarity between a query face-track and each face-track in the retrieved set containing all face-tracks extracted from the dataset in the offline stage .
#<struct ReadData::Alignment source_numbers="55", target_numbers="59", tag_name="wa">
Given a face-track as an input retrieval query , the online stage of our system starts by using our proposed face-track matching algorithm ( described in Section 5 ) to estimate the similarity between a query face-track and each face-track in the retrieved set containing all face-tracks extracted from the dataset in the offline stage .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Given a face-track as an input retrieval query , the online stage of our system starts by using our proposed face-track matching algorithm ( described in Section 5 ) to estimate the similarity between a query face-track and each face-track in the retrieved set containing all face-tracks extracted from the dataset in the offline stage .
#<struct ReadData::Alignment source_numbers="36", target_numbers="", tag_name="wa">
Given a face-track as an input retrieval query , the online stage of our system starts by using our proposed face-track matching algorithm ( described in Section 5 ) to estimate the similarity between a query face-track and each face-track in the retrieved set containing all face-tracks extracted from the dataset in the offline stage .
#<struct ReadData::Alignment source_numbers="39", target_numbers="", tag_name="wa">
Given a face-track as an input retrieval query , the online stage of our system starts by using our proposed face-track matching algorithm ( described in Section 5 ) to estimate the similarity between a query face-track and each face-track in the retrieved set containing all face-tracks extracted from the dataset in the offline stage .
#<struct ReadData::Alignment source_numbers="46", target_numbers="", tag_name="wa">
Given a face-track as an input retrieval query , the online stage of our system starts by using our proposed face-track matching algorithm ( described in Section 5 ) to estimate the similarity between a query face-track and each face-track in the retrieved set containing all face-tracks extracted from the dataset in the offline stage .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Given a face-track as an input retrieval query , the online stage of our system starts by using our proposed face-track matching algorithm ( described in Section 5 ) to estimate the similarity between a query face-track and each face-track in the retrieved set containing all face-tracks extracted from the dataset in the offline stage .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Given a face-track as an input retrieval query , the online stage of our system starts by using our proposed face-track matching algorithm ( described in Section 5 ) to estimate the similarity between a query face-track and each face-track in the retrieved set containing all face-tracks extracted from the dataset in the offline stage .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
Given a face-track as an input retrieval query , the online stage of our system starts by using our proposed face-track matching algorithm ( described in Section 5 ) to estimate the similarity between a query face-track and each face-track in the retrieved set containing all face-tracks extracted from the dataset in the offline stage .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
Given a face-track as an input retrieval query , the online stage of our system starts by using our proposed face-track matching algorithm ( described in Section 5 ) to estimate the similarity between a query face-track and each face-track in the retrieved set containing all face-tracks extracted from the dataset in the offline stage .
#<struct ReadData::Alignment source_numbers="", target_numbers="41", tag_name="wa">
Given a face-track as an input retrieval query , the online stage of our system starts by using our proposed face-track matching algorithm ( described in Section 5 ) to estimate the similarity between a query face-track and each face-track in the retrieved set containing all face-tracks extracted from the dataset in the offline stage .
#<struct ReadData::Alignment source_numbers="", target_numbers="42", tag_name="wa">
Given a face-track as an input retrieval query , the online stage of our system starts by using our proposed face-track matching algorithm ( described in Section 5 ) to estimate the similarity between a query face-track and each face-track in the retrieved set containing all face-tracks extracted from the dataset in the offline stage .
#<struct ReadData::Alignment source_numbers="", target_numbers="49", tag_name="wa">
Given a face-track as an input retrieval query , the online stage of our system starts by using our proposed face-track matching algorithm ( described in Section 5 ) to estimate the similarity between a query face-track and each face-track in the retrieved set containing all face-tracks extracted from the dataset in the offline stage .
#<struct ReadData::Alignment source_numbers="", target_numbers="50", tag_name="wa">
A ranked list of the evaluated face-tracks is returned as retrieval results of the online stage .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
A ranked list of the evaluated face-tracks is returned as retrieval results of the online stage .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
A ranked list of the evaluated face-tracks is returned as retrieval results of the online stage .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Since the retrieved set is huge , our approach targets an extremely efficient face-track matching strategy while maintaining competitive performance with state-ofthe-art approaches.
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Since the retrieved set is huge , our approach targets an extremely efficient face-track matching strategy while maintaining competitive performance with state-ofthe-art approaches.
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
Since the retrieved set is huge , our approach targets an extremely efficient face-track matching strategy while maintaining competitive performance with state-ofthe-art approaches.
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Since the retrieved set is huge , our approach targets an extremely efficient face-track matching strategy while maintaining competitive performance with state-ofthe-art approaches.
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
Such sets of face images are called face-tracks ( sometimes called face sequences ) .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Such sets of face images are called face-tracks ( sometimes called face sequences ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Such sets of face images are called face-tracks ( sometimes called face sequences ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
A common strategy of existing approaches for face-track extraction consists of detecting faces in frames and grouping detected faces of the same character .
#<struct ReadData::Alignment source_numbers="2,3", target_numbers="2,3", tag_name="wa">
A common strategy of existing approaches for face-track extraction consists of detecting faces in frames and grouping detected faces of the same character .
#<struct ReadData::Alignment source_numbers="20", target_numbers="4", tag_name="wa">
A common strategy of existing approaches for face-track extraction consists of detecting faces in frames and grouping detected faces of the same character .
#<struct ReadData::Alignment source_numbers="5,6", target_numbers="6,7", tag_name="wa">
A common strategy of existing approaches for face-track extraction consists of detecting faces in frames and grouping detected faces of the same character .
#<struct ReadData::Alignment source_numbers="9,10", target_numbers="10,11", tag_name="wa">
A common strategy of existing approaches for face-track extraction consists of detecting faces in frames and grouping detected faces of the same character .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
While detecting faces is done by using a standard face detector ( e.g. , Viola-Jones face detector ) \CITE , grouping detected faces requires comprehensive techniques to identify faces of the same character.
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
While detecting faces is done by using a standard face detector ( e.g. , Viola-Jones face detector ) \CITE , grouping detected faces requires comprehensive techniques to identify faces of the same character.
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
In this section , we first briefly introduce an approach for face-track extraction proposed by Everingham et al .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
In this section , we first briefly introduce an approach for face-track extraction proposed by Everingham et al .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Its problems as it is applied to news video and our proposed solutions to overcome the problems is then presented.
#<struct ReadData::Alignment source_numbers="15", target_numbers="3", tag_name="wa">
Its problems as it is applied to news video and our proposed solutions to overcome the problems is then presented.
#<struct ReadData::Alignment source_numbers="16", target_numbers="4", tag_name="wa">
Its problems as it is applied to news video and our proposed solutions to overcome the problems is then presented.
#<struct ReadData::Alignment source_numbers="2", target_numbers="8", tag_name="wa">
Its problems as it is applied to news video and our proposed solutions to overcome the problems is then presented.
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Its problems as it is applied to news video and our proposed solutions to overcome the problems is then presented.
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Its problems as it is applied to news video and our proposed solutions to overcome the problems is then presented.
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
Its problems as it is applied to news video and our proposed solutions to overcome the problems is then presented.
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
Its problems as it is applied to news video and our proposed solutions to overcome the problems is then presented.
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
Its problems as it is applied to news video and our proposed solutions to overcome the problems is then presented.
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
Its problems as it is applied to news video and our proposed solutions to overcome the problems is then presented.
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
Its problems as it is applied to news video and our proposed solutions to overcome the problems is then presented.
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
Its problems as it is applied to news video and our proposed solutions to overcome the problems is then presented.
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Its problems as it is applied to news video and our proposed solutions to overcome the problems is then presented.
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Its problems as it is applied to news video and our proposed solutions to overcome the problems is then presented.
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Its problems as it is applied to news video and our proposed solutions to overcome the problems is then presented.
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Its problems as it is applied to news video and our proposed solutions to overcome the problems is then presented.
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Its problems as it is applied to news video and our proposed solutions to overcome the problems is then presented.
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
To group detected faces into face-tracks , connections between faces belonging to the same character in different frames should be established .
#<struct ReadData::Alignment source_numbers="8", target_numbers="12", tag_name="wa">
To group detected faces into face-tracks , connections between faces belonging to the same character in different frames should be established .
#<struct ReadData::Alignment source_numbers="9", target_numbers="13", tag_name="wa">
To group detected faces into face-tracks , connections between faces belonging to the same character in different frames should be established .
#<struct ReadData::Alignment source_numbers="10", target_numbers="14", tag_name="wa">
To group detected faces into face-tracks , connections between faces belonging to the same character in different frames should be established .
#<struct ReadData::Alignment source_numbers="11", target_numbers="15", tag_name="wa">
To group detected faces into face-tracks , connections between faces belonging to the same character in different frames should be established .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
To group detected faces into face-tracks , connections between faces belonging to the same character in different frames should be established .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
To group detected faces into face-tracks , connections between faces belonging to the same character in different frames should be established .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
in \CITE propose to use KLT tracker for this purpose .
#<struct ReadData::Alignment source_numbers="2,3", target_numbers="2", tag_name="wa">
in \CITE propose to use KLT tracker for this purpose .
#<struct ReadData::Alignment source_numbers="4", target_numbers="4", tag_name="wa">
in \CITE propose to use KLT tracker for this purpose .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
in \CITE propose to use KLT tracker for this purpose .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Points which can not be propagated from one frame to the next are eliminated and replaced with new points .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Points which can not be propagated from one frame to the next are eliminated and replaced with new points .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Given two faces in different frames , if the number of point tracks passing through both faces is larger than half of the total number of point tracks which are not in common to both faces , they are grouped into one face-track.
#<struct ReadData::Alignment source_numbers="28,29", target_numbers="28,29", tag_name="wa">
Given two faces in different frames , if the number of point tracks passing through both faces is larger than half of the total number of point tracks which are not in common to both faces , they are grouped into one face-track.
#<struct ReadData::Alignment source_numbers="37,38", target_numbers="37,38", tag_name="wa">
Given two faces in different frames , if the number of point tracks passing through both faces is larger than half of the total number of point tracks which are not in common to both faces , they are grouped into one face-track.
#<struct ReadData::Alignment source_numbers="31", target_numbers="", tag_name="wa">
Given two faces in different frames , if the number of point tracks passing through both faces is larger than half of the total number of point tracks which are not in common to both faces , they are grouped into one face-track.
#<struct ReadData::Alignment source_numbers="42", target_numbers="", tag_name="wa">
Given two faces in different frames , if the number of point tracks passing through both faces is larger than half of the total number of point tracks which are not in common to both faces , they are grouped into one face-track.
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
Given two faces in different frames , if the number of point tracks passing through both faces is larger than half of the total number of point tracks which are not in common to both faces , they are grouped into one face-track.
#<struct ReadData::Alignment source_numbers="", target_numbers="42", tag_name="wa">
Given two faces in different frames , if the number of point tracks passing through both faces is larger than half of the total number of point tracks which are not in common to both faces , they are grouped into one face-track.
#<struct ReadData::Alignment source_numbers="", target_numbers="43", tag_name="wa">
has demonstrated its efficiency and robustness on drama videos \CITE , directly applying the approach to news videos results poor performances due to following issues.
#<struct ReadData::Alignment source_numbers="1,2", target_numbers="1,2", tag_name="wa">
has demonstrated its efficiency and robustness on drama videos \CITE , directly applying the approach to news videos results poor performances due to following issues.
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
has demonstrated its efficiency and robustness on drama videos \CITE , directly applying the approach to news videos results poor performances due to following issues.
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Since the KLT tracker uses intensity variance for computing the image motion to find the correspondence between points in different frames , it is unreliable when there is a sudden and significant change in illumination .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Since the KLT tracker uses intensity variance for computing the image motion to find the correspondence between points in different frames , it is unreliable when there is a sudden and significant change in illumination .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
In \CITE , track point generation is totally independent with face appearances .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
In \CITE , track point generation is totally independent with face appearances .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
As a result , a face , which does not appear in the aforementioned frames , may not contain any point .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
As a result , a face , which does not appear in the aforementioned frames , may not contain any point .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
To successfully connect actual faces of the same character in different frames , track points generated for the first face should be tracked and retained inside the latter faces for a sufficient number of shared points between faces .
#<struct ReadData::Alignment source_numbers="26", target_numbers="13", tag_name="wa">
To successfully connect actual faces of the same character in different frames , track points generated for the first face should be tracked and retained inside the latter faces for a sufficient number of shared points between faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
It results in face connection failure .
#<struct ReadData::Alignment source_numbers="1", target_numbers="0", tag_name="wa">
It results in face connection failure .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
But , they become meaningless to determine the connection between faces.
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
But , they become meaningless to determine the connection between faces.
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Based on above observed limitations of the approach in \CITE on news videos , we integrate techniques to bypass these liminations in our proposed approach for face-track extraction on news videos.
#<struct ReadData::Alignment source_numbers="10,11", target_numbers="12,13", tag_name="wa">
Based on above observed limitations of the approach in \CITE on news videos , we integrate techniques to bypass these liminations in our proposed approach for face-track extraction on news videos.
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Based on above observed limitations of the approach in \CITE on news videos , we integrate techniques to bypass these liminations in our proposed approach for face-track extraction on news videos.
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
Based on above observed limitations of the approach in \CITE on news videos , we integrate techniques to bypass these liminations in our proposed approach for face-track extraction on news videos.
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
Based on above observed limitations of the approach in \CITE on news videos , we integrate techniques to bypass these liminations in our proposed approach for face-track extraction on news videos.
#<struct ReadData::Alignment source_numbers="28", target_numbers="", tag_name="wa">
Based on above observed limitations of the approach in \CITE on news videos , we integrate techniques to bypass these liminations in our proposed approach for face-track extraction on news videos.
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Based on above observed limitations of the approach in \CITE on news videos , we integrate techniques to bypass these liminations in our proposed approach for face-track extraction on news videos.
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
Based on above observed limitations of the approach in \CITE on news videos , we integrate techniques to bypass these liminations in our proposed approach for face-track extraction on news videos.
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
Based on above observed limitations of the approach in \CITE on news videos , we integrate techniques to bypass these liminations in our proposed approach for face-track extraction on news videos.
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
Based on above observed limitations of the approach in \CITE on news videos , we integrate techniques to bypass these liminations in our proposed approach for face-track extraction on news videos.
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
Firstly , \CITE , our approach does not compare all possible pairs of faces in a shot for face grouping as in \CITE .
#<struct ReadData::Alignment source_numbers="21", target_numbers="3", tag_name="wa">
Firstly , \CITE , our approach does not compare all possible pairs of faces in a shot for face grouping as in \CITE .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
Firstly , \CITE , our approach does not compare all possible pairs of faces in a shot for face grouping as in \CITE .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
Firstly , \CITE , our approach does not compare all possible pairs of faces in a shot for face grouping as in \CITE .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
Firstly , \CITE , our approach does not compare all possible pairs of faces in a shot for face grouping as in \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Firstly , \CITE , our approach does not compare all possible pairs of faces in a shot for face grouping as in \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
Such pair-wise comparison rapidly becomes intractable as the number of faces in a shot increases .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Such pair-wise comparison rapidly becomes intractable as the number of faces in a shot increases .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Such pair-wise comparison rapidly becomes intractable as the number of faces in a shot increases .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Such pair-wise comparison rapidly becomes intractable as the number of faces in a shot increases .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Instead of that , we group faces into face-track following temporal order of their appearances .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Instead of that , we group faces into face-track following temporal order of their appearances .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Instead of that , we group faces into face-track following temporal order of their appearances .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Instead of that , we group faces into face-track following temporal order of their appearances .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Instead of that , we group faces into face-track following temporal order of their appearances .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Instead of that , we group faces into face-track following temporal order of their appearances .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Instead of that , we group faces into face-track following temporal order of their appearances .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Instead of that , we group faces into face-track following temporal order of their appearances .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
A detected face in the current frame is considered to group into existing face-tracks formed by previously detected faces only .
#<struct ReadData::Alignment source_numbers="10", target_numbers="10", tag_name="wa">
A detected face in the current frame is considered to group into existing face-tracks formed by previously detected faces only .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
A detected face in the current frame is considered to group into existing face-tracks formed by previously detected faces only .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
A detected face in the current frame is considered to group into existing face-tracks formed by previously detected faces only .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
A detected face in the current frame is considered to group into existing face-tracks formed by previously detected faces only .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
A detected face in the current frame is considered to group into existing face-tracks formed by previously detected faces only .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Secondly , as our first observation , a sudden illumination change in any frame make the KLT tracker failed to track points properly .
#<struct ReadData::Alignment source_numbers="18", target_numbers="21", tag_name="wa">
Secondly , as our first observation , a sudden illumination change in any frame make the KLT tracker failed to track points properly .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Secondly , as our first observation , a sudden illumination change in any frame make the KLT tracker failed to track points properly .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Secondly , as our first observation , a sudden illumination change in any frame make the KLT tracker failed to track points properly .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
Because such illumination changes are very common and they mostly appear together with important character in a news , a solution to this problem is vital .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Because such illumination changes are very common and they mostly appear together with important character in a news , a solution to this problem is vital .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Because such illumination changes are very common and they mostly appear together with important character in a news , a solution to this problem is vital .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
Because such illumination changes are very common and they mostly appear together with important character in a news , a solution to this problem is vital .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Because such illumination changes are very common and they mostly appear together with important character in a news , a solution to this problem is vital .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Because such illumination changes are very common and they mostly appear together with important character in a news , a solution to this problem is vital .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Because such illumination changes are very common and they mostly appear together with important character in a news , a solution to this problem is vital .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
We learn that the occurences of such illumination changes are usually very short ( less than 3 frames ) .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
We learn that the occurences of such illumination changes are usually very short ( less than 3 frames ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
And , faces appeared in those frames are less informative for recognition since most of the facial identity characteristics are loss due to overlighting .
#<struct ReadData::Alignment source_numbers="3", target_numbers="6", tag_name="wa">
And , faces appeared in those frames are less informative for recognition since most of the facial identity characteristics are loss due to overlighting .
#<struct ReadData::Alignment source_numbers="12,13", target_numbers="15,16", tag_name="wa">
And , faces appeared in those frames are less informative for recognition since most of the facial identity characteristics are loss due to overlighting .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
And , faces appeared in those frames are less informative for recognition since most of the facial identity characteristics are loss due to overlighting .
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
And , faces appeared in those frames are less informative for recognition since most of the facial identity characteristics are loss due to overlighting .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
And , faces appeared in those frames are less informative for recognition since most of the facial identity characteristics are loss due to overlighting .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
And , faces appeared in those frames are less informative for recognition since most of the facial identity characteristics are loss due to overlighting .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
And , faces appeared in those frames are less informative for recognition since most of the facial identity characteristics are loss due to overlighting .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
And , faces appeared in those frames are less informative for recognition since most of the facial identity characteristics are loss due to overlighting .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
, They can not enrich information of its corresponding face-track , but may add noise .
#<struct ReadData::Alignment source_numbers="15", target_numbers="19", tag_name="wa">
, They can not enrich information of its corresponding face-track , but may add noise .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
, They can not enrich information of its corresponding face-track , but may add noise .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
, They can not enrich information of its corresponding face-track , but may add noise .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
, They can not enrich information of its corresponding face-track , but may add noise .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
, They can not enrich information of its corresponding face-track , but may add noise .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
, They can not enrich information of its corresponding face-track , but may add noise .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
, They can not enrich information of its corresponding face-track , but may add noise .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
, They can not enrich information of its corresponding face-track , but may add noise .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
, They can not enrich information of its corresponding face-track , but may add noise .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
, They can not enrich information of its corresponding face-track , but may add noise .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
, They can not enrich information of its corresponding face-track , but may add noise .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
Therefore , our solution is to detect and skip all frames contain sudden illumination changes , .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
We call such frames as flashframes.
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
We call such frames as flashframes.
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
We call such frames as flashframes.
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
We call such frames as flashframes.
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
We call such frames as flashframes.
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
We call such frames as flashframes.
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
We call such frames as flashframes.
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
We call such frames as flashframes.
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
To indetify flash-frames , we measures the brightness of frames in the video shot .
#<struct ReadData::Alignment source_numbers="9", target_numbers="3", tag_name="wa">
To indetify flash-frames , we measures the brightness of frames in the video shot .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
To indetify flash-frames , we measures the brightness of frames in the video shot .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
To indetify flash-frames , we measures the brightness of frames in the video shot .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
To indetify flash-frames , we measures the brightness of frames in the video shot .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
To indetify flash-frames , we measures the brightness of frames in the video shot .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
If the brightness of a frame significantly increases compared with those of its neighbors , the frame is declared as a flash-frame and is skipped for processing .
#<struct ReadData::Alignment source_numbers="23", target_numbers="6", tag_name="wa">
If the brightness of a frame significantly increases compared with those of its neighbors , the frame is declared as a flash-frame and is skipped for processing .
#<struct ReadData::Alignment source_numbers="7", target_numbers="8", tag_name="wa">
If the brightness of a frame significantly increases compared with those of its neighbors , the frame is declared as a flash-frame and is skipped for processing .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
If the brightness of a frame significantly increases compared with those of its neighbors , the frame is declared as a flash-frame and is skipped for processing .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
If the brightness of a frame significantly increases compared with those of its neighbors , the frame is declared as a flash-frame and is skipped for processing .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
If the brightness of a frame significantly increases compared with those of its neighbors , the frame is declared as a flash-frame and is skipped for processing .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
If the brightness of a frame significantly increases compared with those of its neighbors , the frame is declared as a flash-frame and is skipped for processing .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
If the brightness of a frame significantly increases compared with those of its neighbors , the frame is declared as a flash-frame and is skipped for processing .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
If the brightness of a frame significantly increases compared with those of its neighbors , the frame is declared as a flash-frame and is skipped for processing .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
If the brightness of a frame significantly increases compared with those of its neighbors , the frame is declared as a flash-frame and is skipped for processing .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
Particularly , given a frame \SYM with t indicates its frame index , we compute the average luminosity L of the frame \SYM and its consicutive frames \SYM , where i = \SYM; t +W+ 1 , and W is the potential length of a sudden illumination change .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
Particularly , given a frame \SYM with t indicates its frame index , we compute the average luminosity L of the frame \SYM and its consicutive frames \SYM , where i = \SYM; t +W+ 1 , and W is the potential length of a sudden illumination change .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
If L( \SYM ) > L( \SYM ) and L( \SYM ) > L( \SYM ) , \SYM is defined as flash-frames regarding a predefined brightness sensitive threshold \SYM .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
If L( \SYM ) > L( \SYM ) and L( \SYM ) > L( \SYM ) , \SYM is defined as flash-frames regarding a predefined brightness sensitive threshold \SYM .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
If L( \SYM ) > L( \SYM ) and L( \SYM ) > L( \SYM ) , \SYM is defined as flash-frames regarding a predefined brightness sensitive threshold \SYM .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
If L( \SYM ) > L( \SYM ) and L( \SYM ) > L( \SYM ) , \SYM is defined as flash-frames regarding a predefined brightness sensitive threshold \SYM .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
If L( \SYM ) > L( \SYM ) and L( \SYM ) > L( \SYM ) , \SYM is defined as flash-frames regarding a predefined brightness sensitive threshold \SYM .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
If L( \SYM ) > L( \SYM ) and L( \SYM ) > L( \SYM ) , \SYM is defined as flash-frames regarding a predefined brightness sensitive threshold \SYM .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
In our experiments , we found that \SYM = 1:25 and W = {1; 2; 3} are optimal for detecting all flash-frames with a low false alarm rate.
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
In our experiments , we found that \SYM = 1:25 and W = {1; 2; 3} are optimal for detecting all flash-frames with a low false alarm rate.
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
In our experiments , we found that \SYM = 1:25 and W = {1; 2; 3} are optimal for detecting all flash-frames with a low false alarm rate.
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
All point tracking and face grouping processes are initialized from this frame , not at the first frame of the shot as in \CITE .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
All point tracking and face grouping processes are initialized from this frame , not at the first frame of the shot as in \CITE .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
All point tracking and face grouping processes are initialized from this frame , not at the first frame of the shot as in \CITE .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
All point tracking and face grouping processes are initialized from this frame , not at the first frame of the shot as in \CITE .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
All point tracking and face grouping processes are initialized from this frame , not at the first frame of the shot as in \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
All point tracking and face grouping processes are initialized from this frame , not at the first frame of the shot as in \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
This helps us to save computational cost as well as to avoid tracking errors caused by transition effects between shots .
#<struct ReadData::Alignment source_numbers="11", target_numbers="9", tag_name="wa">
This helps us to save computational cost as well as to avoid tracking errors caused by transition effects between shots .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
This helps us to save computational cost as well as to avoid tracking errors caused by transition effects between shots .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
This helps us to save computational cost as well as to avoid tracking errors caused by transition effects between shots .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
This helps us to save computational cost as well as to avoid tracking errors caused by transition effects between shots .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
This helps us to save computational cost as well as to avoid tracking errors caused by transition effects between shots .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Each face now becomes the first face of a corresponding newly formed face-track.
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
Each face now becomes the first face of a corresponding newly formed face-track.
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
Each face now becomes the first face of a corresponding newly formed face-track.
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
After the initialization , we sequentially process each frame afterwards , knowing all flash-frames will be skipped .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
After the initialization , we sequentially process each frame afterwards , knowing all flash-frames will be skipped .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
After the initialization , we sequentially process each frame afterwards , knowing all flash-frames will be skipped .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
After the initialization , we sequentially process each frame afterwards , knowing all flash-frames will be skipped .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
At a given frame , points from the previous frame are tracked by the KLT tracker to update their locations .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
At a given frame , points from the previous frame are tracked by the KLT tracker to update their locations .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
If there are faces detected , each face is checked against all existing facetracks formed in the previous frames to find out which facetrack it belongs to .
#<struct ReadData::Alignment source_numbers="27", target_numbers="31", tag_name="wa">
If there are faces detected , each face is checked against all existing facetracks formed in the previous frames to find out which facetrack it belongs to .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
If there are faces detected , each face is checked against all existing facetracks formed in the previous frames to find out which facetrack it belongs to .
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
If there are faces detected , each face is checked against all existing facetracks formed in the previous frames to find out which facetrack it belongs to .
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
If there are faces detected , each face is checked against all existing facetracks formed in the previous frames to find out which facetrack it belongs to .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
If there are faces detected , each face is checked against all existing facetracks formed in the previous frames to find out which facetrack it belongs to .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
If there are faces detected , each face is checked against all existing facetracks formed in the previous frames to find out which facetrack it belongs to .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
If there are faces detected , each face is checked against all existing facetracks formed in the previous frames to find out which facetrack it belongs to .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
If there are faces detected , each face is checked against all existing facetracks formed in the previous frames to find out which facetrack it belongs to .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
If there are faces detected , each face is checked against all existing facetracks formed in the previous frames to find out which facetrack it belongs to .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
If there are faces detected , each face is checked against all existing facetracks formed in the previous frames to find out which facetrack it belongs to .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
Checking between a face and a facetrack is based on enumerating points shared by both the face and the last appeared face of the face-track .
#<struct ReadData::Alignment source_numbers="21", target_numbers="7", tag_name="wa">
Checking between a face and a facetrack is based on enumerating points shared by both the face and the last appeared face of the face-track .
#<struct ReadData::Alignment source_numbers="23", target_numbers="13", tag_name="wa">
Checking between a face and a facetrack is based on enumerating points shared by both the face and the last appeared face of the face-track .
#<struct ReadData::Alignment source_numbers="20", target_numbers="25", tag_name="wa">
Checking between a face and a facetrack is based on enumerating points shared by both the face and the last appeared face of the face-track .
#<struct ReadData::Alignment source_numbers="25", target_numbers="30", tag_name="wa">
Checking between a face and a facetrack is based on enumerating points shared by both the face and the last appeared face of the face-track .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Checking between a face and a facetrack is based on enumerating points shared by both the face and the last appeared face of the face-track .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
Checking between a face and a facetrack is based on enumerating points shared by both the face and the last appeared face of the face-track .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
Checking between a face and a facetrack is based on enumerating points shared by both the face and the last appeared face of the face-track .
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
Checking between a face and a facetrack is based on enumerating points shared by both the face and the last appeared face of the face-track .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Checking between a face and a facetrack is based on enumerating points shared by both the face and the last appeared face of the face-track .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Checking between a face and a facetrack is based on enumerating points shared by both the face and the last appeared face of the face-track .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
Checking between a face and a facetrack is based on enumerating points shared by both the face and the last appeared face of the face-track .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
Checking between a face and a facetrack is based on enumerating points shared by both the face and the last appeared face of the face-track .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
Checking between a face and a facetrack is based on enumerating points shared by both the face and the last appeared face of the face-track .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
Checking between a face and a facetrack is based on enumerating points shared by both the face and the last appeared face of the face-track .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
Checking between a face and a facetrack is based on enumerating points shared by both the face and the last appeared face of the face-track .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
If the enumerated number is larger than half of the total number of points which are not in common to both faces , the faces is grouped into the face-track .
#<struct ReadData::Alignment source_numbers="14,15", target_numbers="14,15", tag_name="wa">
If the enumerated number is larger than half of the total number of points which are not in common to both faces , the faces is grouped into the face-track .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
If the enumerated number is larger than half of the total number of points which are not in common to both faces , the faces is grouped into the face-track .
#<struct ReadData::Alignment source_numbers="29", target_numbers="", tag_name="wa">
If the enumerated number is larger than half of the total number of points which are not in common to both faces , the faces is grouped into the face-track .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
If the enumerated number is larger than half of the total number of points which are not in common to both faces , the faces is grouped into the face-track .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
Our grouping criterion here is similar to \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Our grouping criterion here is similar to \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
A face which can not be grouped into any face-track is treated as an initial face of a new face-track .
#<struct ReadData::Alignment source_numbers="2", target_numbers="1,2", tag_name="wa">
A face which can not be grouped into any face-track is treated as an initial face of a new face-track .
#<struct ReadData::Alignment source_numbers="1", target_numbers="8", tag_name="wa">
A face which can not be grouped into any face-track is treated as an initial face of a new face-track .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
A face which can not be grouped into any face-track is treated as an initial face of a new face-track .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
A face which can not be grouped into any face-track is treated as an initial face of a new face-track .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
A face which can not be grouped into any face-track is treated as an initial face of a new face-track .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
A face which can not be grouped into any face-track is treated as an initial face of a new face-track .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
A face which can not be grouped into any face-track is treated as an initial face of a new face-track .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
A face which can not be grouped into any face-track is treated as an initial face of a new face-track .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
We then generate new track points inside such faces for tracking an grouping its corresponding faces in latter frames .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
We then generate new track points inside such faces for tracking an grouping its corresponding faces in latter frames .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
We can ensure that there are always track points for all faces appear in the shot .
#<struct ReadData::Alignment source_numbers="12", target_numbers="12", tag_name="wa">
We can ensure that there are always track points for all faces appear in the shot .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
We can ensure that there are always track points for all faces appear in the shot .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
Consequently , our approach overcomes the second observed limitation of \CITE.
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Consequently , our approach overcomes the second observed limitation of \CITE.
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
In other case , when a face in the current frame is grouped to an existing face-track , we prepare points for further tracking .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
In other case , when a face in the current frame is grouped to an existing face-track , we prepare points for further tracking .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
In other case , when a face in the current frame is grouped to an existing face-track , we prepare points for further tracking .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
In other case , when a face in the current frame is grouped to an existing face-track , we prepare points for further tracking .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
In other case , when a face in the current frame is grouped to an existing face-track , we prepare points for further tracking .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
We remove all points which are inside the last appeared face of the face-track but not inside the current face , and vice versa .
#<struct ReadData::Alignment source_numbers="4,5", target_numbers="4,5", tag_name="wa">
We remove all points which are inside the last appeared face of the face-track but not inside the current face , and vice versa .
#<struct ReadData::Alignment source_numbers="9", target_numbers="11", tag_name="wa">
We remove all points which are inside the last appeared face of the face-track but not inside the current face , and vice versa .
#<struct ReadData::Alignment source_numbers="19", target_numbers="14", tag_name="wa">
We remove all points which are inside the last appeared face of the face-track but not inside the current face , and vice versa .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
We remove all points which are inside the last appeared face of the face-track but not inside the current face , and vice versa .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
We remove all points which are inside the last appeared face of the face-track but not inside the current face , and vice versa .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
We remove all points which are inside the last appeared face of the face-track but not inside the current face , and vice versa .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
We remove all points which are inside the last appeared face of the face-track but not inside the current face , and vice versa .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
We remove all points which are inside the last appeared face of the face-track but not inside the current face , and vice versa .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
We remove all points which are inside the last appeared face of the face-track but not inside the current face , and vice versa .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
Since such points are likely tracked incorrectly , eliminating them prevent us from transferring tracking errors to latter frames .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Since such points are likely tracked incorrectly , eliminating them prevent us from transferring tracking errors to latter frames .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Points which are shared by both faces are kept .
#<struct ReadData::Alignment source_numbers="1,2", target_numbers="1,2", tag_name="wa">
By doing that , our tracking results through a long sequence of frames become more accurate and reliable .
#<struct ReadData::Alignment source_numbers="1,2", target_numbers="1,2", tag_name="wa">
By doing that , our tracking results through a long sequence of frames become more accurate and reliable .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
By doing that , our tracking results through a long sequence of frames become more accurate and reliable .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
When a face is partly and slowly occluded , our approach can discard incorrectly tracked points as well as reproduce points for the face after being occluded .
#<struct ReadData::Alignment source_numbers="25", target_numbers="25", tag_name="wa">
When a face is partly and slowly occluded , our approach can discard incorrectly tracked points as well as reproduce points for the face after being occluded .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
When a face is partly and slowly occluded , our approach can discard incorrectly tracked points as well as reproduce points for the face after being occluded .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
When a face is partly and slowly occluded , our approach can discard incorrectly tracked points as well as reproduce points for the face after being occluded .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
When a face is partly and slowly occluded , our approach can discard incorrectly tracked points as well as reproduce points for the face after being occluded .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
When a face is partly and slowly occluded , our approach can discard incorrectly tracked points as well as reproduce points for the face after being occluded .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
When a face is partly and slowly occluded , our approach can discard incorrectly tracked points as well as reproduce points for the face after being occluded .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
Our approach continuously process the next frame until reaching the end of the shot .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Our approach continuously process the next frame until reaching the end of the shot .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Our approach continuously process the next frame until reaching the end of the shot .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
There are several approaches have been proposed for matching face-tracks ( as presented in Section 2 ) .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
There are several approaches have been proposed for matching face-tracks ( as presented in Section 2 ) .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
There are several approaches have been proposed for matching face-tracks ( as presented in Section 2 ) .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
There are several approaches have been proposed for matching face-tracks ( as presented in Section 2 ) .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
There are several approaches have been proposed for matching face-tracks ( as presented in Section 2 ) .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
There are several approaches have been proposed for matching face-tracks ( as presented in Section 2 ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
There are several approaches have been proposed for matching face-tracks ( as presented in Section 2 ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
There are several approaches have been proposed for matching face-tracks ( as presented in Section 2 ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
There are several approaches have been proposed for matching face-tracks ( as presented in Section 2 ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
, Although these existing approaches achive high accuracy on benchmark datasets , their expensive computational costs limits their practical applications on large-scale datasets .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
, Although these existing approaches achive high accuracy on benchmark datasets , their expensive computational costs limits their practical applications on large-scale datasets .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
, Although these existing approaches achive high accuracy on benchmark datasets , their expensive computational costs limits their practical applications on large-scale datasets .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
, Although these existing approaches achive high accuracy on benchmark datasets , their expensive computational costs limits their practical applications on large-scale datasets .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
, Although these existing approaches achive high accuracy on benchmark datasets , their expensive computational costs limits their practical applications on large-scale datasets .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
, Although these existing approaches achive high accuracy on benchmark datasets , their expensive computational costs limits their practical applications on large-scale datasets .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
, Although these existing approaches achive high accuracy on benchmark datasets , their expensive computational costs limits their practical applications on large-scale datasets .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
, Although these existing approaches achive high accuracy on benchmark datasets , their expensive computational costs limits their practical applications on large-scale datasets .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
, Although these existing approaches achive high accuracy on benchmark datasets , their expensive computational costs limits their practical applications on large-scale datasets .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
, Although these existing approaches achive high accuracy on benchmark datasets , their expensive computational costs limits their practical applications on large-scale datasets .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
, Although these existing approaches achive high accuracy on benchmark datasets , their expensive computational costs limits their practical applications on large-scale datasets .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
This motivate us to target an matching approach which is balanced between accuracy and computational cost .
#<struct ReadData::Alignment source_numbers="7,8", target_numbers="7,8", tag_name="wa">
This motivate us to target an matching approach which is balanced between accuracy and computational cost .
#<struct ReadData::Alignment source_numbers="9", target_numbers="9", tag_name="wa">
This motivate us to target an matching approach which is balanced between accuracy and computational cost .
#<struct ReadData::Alignment source_numbers="10", target_numbers="11,12", tag_name="wa">
This motivate us to target an matching approach which is balanced between accuracy and computational cost .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
This motivate us to target an matching approach which is balanced between accuracy and computational cost .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
This motivate us to target an matching approach which is balanced between accuracy and computational cost .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
The approach should be extremely efficient while archiving competitive performance compare to state-of-the-art approaches�f.
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
The approach should be extremely efficient while archiving competitive performance compare to state-of-the-art approaches�f.
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
The approach should be extremely efficient while archiving competitive performance compare to state-of-the-art approaches�f.
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
The approach should be extremely efficient while archiving competitive performance compare to state-of-the-art approaches�f.
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
The approach should be extremely efficient while archiving competitive performance compare to state-of-the-art approaches�f.
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
The approach should be extremely efficient while archiving competitive performance compare to state-of-the-art approaches�f.
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
The approach should be extremely efficient while archiving competitive performance compare to state-of-the-art approaches�f.
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
In order to maintain a competitive accuracy , we still employ plenteous information from multiple faces of a facetrack to enrich its representation .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
In order to maintain a competitive accuracy , we still employ plenteous information from multiple faces of a facetrack to enrich its representation .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
In order to maintain a competitive accuracy , we still employ plenteous information from multiple faces of a facetrack to enrich its representation .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
In order to maintain a competitive accuracy , we still employ plenteous information from multiple faces of a facetrack to enrich its representation .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
In order to maintain a competitive accuracy , we still employ plenteous information from multiple faces of a facetrack to enrich its representation .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
In order to maintain a competitive accuracy , we still employ plenteous information from multiple faces of a facetrack to enrich its representation .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
In order to maintain a competitive accuracy , we still employ plenteous information from multiple faces of a facetrack to enrich its representation .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
In order to maintain a competitive accuracy , we still employ plenteous information from multiple faces of a facetrack to enrich its representation .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
In order to maintain a competitive accuracy , we still employ plenteous information from multiple faces of a facetrack to enrich its representation .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
However , instead of using all faces in a face-track , we propose to subsample the faces .
#<struct ReadData::Alignment source_numbers="15", target_numbers="6", tag_name="wa">
However , instead of using all faces in a face-track , we propose to subsample the faces .
#<struct ReadData::Alignment source_numbers="14", target_numbers="17", tag_name="wa">
However , instead of using all faces in a face-track , we propose to subsample the faces .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
However , instead of using all faces in a face-track , we propose to subsample the faces .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
However , instead of using all faces in a face-track , we propose to subsample the faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
However , instead of using all faces in a face-track , we propose to subsample the faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
However , instead of using all faces in a face-track , we propose to subsample the faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
However , instead of using all faces in a face-track , we propose to subsample the faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
By doing that , the require computational cost can be reduced while a sufficient amount of information is kept for improving accuracy .
#<struct ReadData::Alignment source_numbers="1,2", target_numbers="1,2", tag_name="wa">
By doing that , the require computational cost can be reduced while a sufficient amount of information is kept for improving accuracy .
#<struct ReadData::Alignment source_numbers="18", target_numbers="12", tag_name="wa">
By doing that , the require computational cost can be reduced while a sufficient amount of information is kept for improving accuracy .
#<struct ReadData::Alignment source_numbers="13", target_numbers="17", tag_name="wa">
By doing that , the require computational cost can be reduced while a sufficient amount of information is kept for improving accuracy .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
By doing that , the require computational cost can be reduced while a sufficient amount of information is kept for improving accuracy .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
By doing that , the require computational cost can be reduced while a sufficient amount of information is kept for improving accuracy .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
By doing that , the require computational cost can be reduced while a sufficient amount of information is kept for improving accuracy .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
By doing that , the require computational cost can be reduced while a sufficient amount of information is kept for improving accuracy .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
We called our approach as k-Faces.
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
Given a specific value of k , which indicates the expected size of the sub-sampled set of a face-track , the approach starts by dividing each face-track into k parts following its temporal order .
#<struct ReadData::Alignment source_numbers="34", target_numbers="39", tag_name="wa">
Given a specific value of k , which indicates the expected size of the sub-sampled set of a face-track , the approach starts by dividing each face-track into k parts following its temporal order .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
Given a specific value of k , which indicates the expected size of the sub-sampled set of a face-track , the approach starts by dividing each face-track into k parts following its temporal order .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
Given a specific value of k , which indicates the expected size of the sub-sampled set of a face-track , the approach starts by dividing each face-track into k parts following its temporal order .
#<struct ReadData::Alignment source_numbers="26", target_numbers="", tag_name="wa">
Given a specific value of k , which indicates the expected size of the sub-sampled set of a face-track , the approach starts by dividing each face-track into k parts following its temporal order .
#<struct ReadData::Alignment source_numbers="30", target_numbers="", tag_name="wa">
Given a specific value of k , which indicates the expected size of the sub-sampled set of a face-track , the approach starts by dividing each face-track into k parts following its temporal order .
#<struct ReadData::Alignment source_numbers="31", target_numbers="", tag_name="wa">
Given a specific value of k , which indicates the expected size of the sub-sampled set of a face-track , the approach starts by dividing each face-track into k parts following its temporal order .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Given a specific value of k , which indicates the expected size of the sub-sampled set of a face-track , the approach starts by dividing each face-track into k parts following its temporal order .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
Given a specific value of k , which indicates the expected size of the sub-sampled set of a face-track , the approach starts by dividing each face-track into k parts following its temporal order .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
Given a specific value of k , which indicates the expected size of the sub-sampled set of a face-track , the approach starts by dividing each face-track into k parts following its temporal order .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
Given a specific value of k , which indicates the expected size of the sub-sampled set of a face-track , the approach starts by dividing each face-track into k parts following its temporal order .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
Given a specific value of k , which indicates the expected size of the sub-sampled set of a face-track , the approach starts by dividing each face-track into k parts following its temporal order .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
Given a specific value of k , which indicates the expected size of the sub-sampled set of a face-track , the approach starts by dividing each face-track into k parts following its temporal order .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
Given a specific value of k , which indicates the expected size of the sub-sampled set of a face-track , the approach starts by dividing each face-track into k parts following its temporal order .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
Given a specific value of k , which indicates the expected size of the sub-sampled set of a face-track , the approach starts by dividing each face-track into k parts following its temporal order .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
Given a specific value of k , which indicates the expected size of the sub-sampled set of a face-track , the approach starts by dividing each face-track into k parts following its temporal order .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
The similarity between two face-tracks is now the distance between their mean faces.
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
The similarity between two face-tracks is now the distance between their mean faces.
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
The similarity between two face-tracks is now the distance between their mean faces.
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Let denote mA = {\SYM; \SYM; : :; \SYM} and mB = {\SYM ; \SYM; : :; \SYM} are two mean faces of two face-track A and B , respectively , with N imposes the number of dimension of the feature space .
#<struct ReadData::Alignment source_numbers="39", target_numbers="18", tag_name="wa">
Let denote mA = {\SYM; \SYM; : :; \SYM} and mB = {\SYM ; \SYM; : :; \SYM} are two mean faces of two face-track A and B , respectively , with N imposes the number of dimension of the feature space .
#<struct ReadData::Alignment source_numbers="18", target_numbers="32", tag_name="wa">
Let denote mA = {\SYM; \SYM; : :; \SYM} and mB = {\SYM ; \SYM; : :; \SYM} are two mean faces of two face-track A and B , respectively , with N imposes the number of dimension of the feature space .
#<struct ReadData::Alignment source_numbers="37,38", target_numbers="36,37", tag_name="wa">
Let denote mA = {\SYM; \SYM; : :; \SYM} and mB = {\SYM ; \SYM; : :; \SYM} are two mean faces of two face-track A and B , respectively , with N imposes the number of dimension of the feature space .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
Let denote mA = {\SYM; \SYM; : :; \SYM} and mB = {\SYM ; \SYM; : :; \SYM} are two mean faces of two face-track A and B , respectively , with N imposes the number of dimension of the feature space .
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
Let denote mA = {\SYM; \SYM; : :; \SYM} and mB = {\SYM ; \SYM; : :; \SYM} are two mean faces of two face-track A and B , respectively , with N imposes the number of dimension of the feature space .
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
Let denote mA = {\SYM; \SYM; : :; \SYM} and mB = {\SYM ; \SYM; : :; \SYM} are two mean faces of two face-track A and B , respectively , with N imposes the number of dimension of the feature space .
#<struct ReadData::Alignment source_numbers="33", target_numbers="", tag_name="wa">
Let denote mA = {\SYM; \SYM; : :; \SYM} and mB = {\SYM ; \SYM; : :; \SYM} are two mean faces of two face-track A and B , respectively , with N imposes the number of dimension of the feature space .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
Let denote mA = {\SYM; \SYM; : :; \SYM} and mB = {\SYM ; \SYM; : :; \SYM} are two mean faces of two face-track A and B , respectively , with N imposes the number of dimension of the feature space .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
Let denote mA = {\SYM; \SYM; : :; \SYM} and mB = {\SYM ; \SYM; : :; \SYM} are two mean faces of two face-track A and B , respectively , with N imposes the number of dimension of the feature space .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
An illustration of our k-Faces , is shown in Figure 4 .
#<struct ReadData::Alignment source_numbers="1", target_numbers="2", tag_name="wa">
An illustration of our k-Faces , is shown in Figure 4 .
#<struct ReadData::Alignment source_numbers="6", target_numbers="8", tag_name="wa">
An illustration of our k-Faces , is shown in Figure 4 .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
An illustration of our k-Faces , is shown in Figure 4 .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
An illustration of our k-Faces , is shown in Figure 4 .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
An illustration of our k-Faces , is shown in Figure 4 .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
An illustration of our k-Faces , is shown in Figure 4 .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
An illustration of our k-Faces , is shown in Figure 4 .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Its pseudo-code is presented as follows .
#<struct ReadData::Alignment source_numbers="6", target_numbers="1", tag_name="wa">
Its pseudo-code is presented as follows .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Its pseudo-code is presented as follows .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Its pseudo-code is presented as follows .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Its pseudo-code is presented as follows .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
Its pseudo-code is presented as follows .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
Its pseudo-code is presented as follows .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Its pseudo-code is presented as follows .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Clearly , the higher value of k is selected , the more faces in each face-track are selected to compute the representative face of the face track .
#<struct ReadData::Alignment source_numbers="24", target_numbers="4", tag_name="wa">
Clearly , the higher value of k is selected , the more faces in each face-track are selected to compute the representative face of the face track .
#<struct ReadData::Alignment source_numbers="8", target_numbers="8", tag_name="wa">
Clearly , the higher value of k is selected , the more faces in each face-track are selected to compute the representative face of the face track .
#<struct ReadData::Alignment source_numbers="25", target_numbers="15", tag_name="wa">
Clearly , the higher value of k is selected , the more faces in each face-track are selected to compute the representative face of the face track .
#<struct ReadData::Alignment source_numbers="26", target_numbers="16", tag_name="wa">
Clearly , the higher value of k is selected , the more faces in each face-track are selected to compute the representative face of the face track .
#<struct ReadData::Alignment source_numbers="17", target_numbers="17", tag_name="wa">
Clearly , the higher value of k is selected , the more faces in each face-track are selected to compute the representative face of the face track .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Clearly , the higher value of k is selected , the more faces in each face-track are selected to compute the representative face of the face track .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
Clearly , the higher value of k is selected , the more faces in each face-track are selected to compute the representative face of the face track .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
Clearly , the higher value of k is selected , the more faces in each face-track are selected to compute the representative face of the face track .
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
Clearly , the higher value of k is selected , the more faces in each face-track are selected to compute the representative face of the face track .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
Clearly , the higher value of k is selected , the more faces in each face-track are selected to compute the representative face of the face track .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
And , better approximations , may result in higher accuracies .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
And , better approximations , may result in higher accuracies .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
And , better approximations , may result in higher accuracies .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
By using k as a predefined parameter , k-Faces provides flexibility for users in balancing their expected accuracy and the cost which they can afford ( or time they can wait for the result ).
#<struct ReadData::Alignment source_numbers="32", target_numbers="15", tag_name="wa">
By using k as a predefined parameter , k-Faces provides flexibility for users in balancing their expected accuracy and the cost which they can afford ( or time they can wait for the result ).
#<struct ReadData::Alignment source_numbers="28", target_numbers="17", tag_name="wa">
By using k as a predefined parameter , k-Faces provides flexibility for users in balancing their expected accuracy and the cost which they can afford ( or time they can wait for the result ).
#<struct ReadData::Alignment source_numbers="30,31", target_numbers="18", tag_name="wa">
By using k as a predefined parameter , k-Faces provides flexibility for users in balancing their expected accuracy and the cost which they can afford ( or time they can wait for the result ).
#<struct ReadData::Alignment source_numbers="11", target_numbers="33", tag_name="wa">
By using k as a predefined parameter , k-Faces provides flexibility for users in balancing their expected accuracy and the cost which they can afford ( or time they can wait for the result ).
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
By using k as a predefined parameter , k-Faces provides flexibility for users in balancing their expected accuracy and the cost which they can afford ( or time they can wait for the result ).
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
By using k as a predefined parameter , k-Faces provides flexibility for users in balancing their expected accuracy and the cost which they can afford ( or time they can wait for the result ).
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
By using k as a predefined parameter , k-Faces provides flexibility for users in balancing their expected accuracy and the cost which they can afford ( or time they can wait for the result ).
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
By using k as a predefined parameter , k-Faces provides flexibility for users in balancing their expected accuracy and the cost which they can afford ( or time they can wait for the result ).
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
By using k as a predefined parameter , k-Faces provides flexibility for users in balancing their expected accuracy and the cost which they can afford ( or time they can wait for the result ).
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
By using k as a predefined parameter , k-Faces provides flexibility for users in balancing their expected accuracy and the cost which they can afford ( or time they can wait for the result ).
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
Besides that , since k-Faces averages multiple faces for a representative face of a face-track , the effects of noisy or outliers faces on estimating the similarity of face-tracks will be substantially reduced.
#<struct ReadData::Alignment source_numbers="25", target_numbers="8", tag_name="wa">
Besides that , since k-Faces averages multiple faces for a representative face of a face-track , the effects of noisy or outliers faces on estimating the similarity of face-tracks will be substantially reduced.
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Besides that , since k-Faces averages multiple faces for a representative face of a face-track , the effects of noisy or outliers faces on estimating the similarity of face-tracks will be substantially reduced.
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
Besides that , since k-Faces averages multiple faces for a representative face of a face-track , the effects of noisy or outliers faces on estimating the similarity of face-tracks will be substantially reduced.
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Besides that , since k-Faces averages multiple faces for a representative face of a face-track , the effects of noisy or outliers faces on estimating the similarity of face-tracks will be substantially reduced.
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
Besides that , since k-Faces averages multiple faces for a representative face of a face-track , the effects of noisy or outliers faces on estimating the similarity of face-tracks will be substantially reduced.
#<struct ReadData::Alignment source_numbers="28", target_numbers="", tag_name="wa">
Besides that , since k-Faces averages multiple faces for a representative face of a face-track , the effects of noisy or outliers faces on estimating the similarity of face-tracks will be substantially reduced.
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Besides that , since k-Faces averages multiple faces for a representative face of a face-track , the effects of noisy or outliers faces on estimating the similarity of face-tracks will be substantially reduced.
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Besides that , since k-Faces averages multiple faces for a representative face of a face-track , the effects of noisy or outliers faces on estimating the similarity of face-tracks will be substantially reduced.
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Besides that , since k-Faces averages multiple faces for a representative face of a face-track , the effects of noisy or outliers faces on estimating the similarity of face-tracks will be substantially reduced.
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
Besides that , since k-Faces averages multiple faces for a representative face of a face-track , the effects of noisy or outliers faces on estimating the similarity of face-tracks will be substantially reduced.
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
Besides that , since k-Faces averages multiple faces for a representative face of a face-track , the effects of noisy or outliers faces on estimating the similarity of face-tracks will be substantially reduced.
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
The experiments are divided into two parts .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
The experiments are divided into two parts .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
In the first part , we evaluate the performance of the proposed approach for face-track extraction , .
#<struct ReadData::Alignment source_numbers="6", target_numbers="3", tag_name="wa">
In the first part , we evaluate the performance of the proposed approach for face-track extraction , .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
In the first part , we evaluate the performance of the proposed approach for face-track extraction , .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
In the first part , we evaluate the performance of the proposed approach for face-track extraction , .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
In the first part , we evaluate the performance of the proposed approach for face-track extraction , .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
In the first part , we evaluate the performance of the proposed approach for face-track extraction , .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
In the first part , we evaluate the performance of the proposed approach for face-track extraction , .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
In the first part , we evaluate the performance of the proposed approach for face-track extraction , .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
In the first part , we evaluate the performance of the proposed approach for face-track extraction , .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
In the first part , we evaluate the performance of the proposed approach for face-track extraction , .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Evaluation of the proposed approach for face-track matching is given in the second part.
#<struct ReadData::Alignment source_numbers="6", target_numbers="0", tag_name="wa">
Evaluation of the proposed approach for face-track matching is given in the second part.
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Evaluation of the proposed approach for face-track matching is given in the second part.
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Evaluation of the proposed approach for face-track matching is given in the second part.
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Evaluation of the proposed approach for face-track matching is given in the second part.
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
Evaluation of the proposed approach for face-track matching is given in the second part.
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
Evaluation of the proposed approach for face-track matching is given in the second part.
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Evaluation of the proposed approach for face-track matching is given in the second part.
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Evaluation of the proposed approach for face-track matching is given in the second part.
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Evaluation of the proposed approach for face-track matching is given in the second part.
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Evaluation of the proposed approach for face-track matching is given in the second part.
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Evaluation of the proposed approach for face-track matching is given in the second part.
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
Evaluation of the proposed approach for face-track matching is given in the second part.
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
Evaluation of the proposed approach for face-track matching is given in the second part.
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
Evaluation of the proposed approach for face-track matching is given in the second part.
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
We tested our proposed approach for face-track extraction on 8 video sequences from different video broadcasting stations , including NHK News 7 , ABC News , and CNN News.
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
We tested our proposed approach for face-track extraction on 8 video sequences from different video broadcasting stations , including NHK News 7 , ABC News , and CNN News.
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
A face detector based on Viola-Jones approach \CITE was used for detecting near frontal faces in every frame of these video sequences .
#<struct ReadData::Alignment source_numbers="8", target_numbers="9", tag_name="wa">
A face detector based on Viola-Jones approach \CITE was used for detecting near frontal faces in every frame of these video sequences .
#<struct ReadData::Alignment source_numbers="9", target_numbers="10", tag_name="wa">
A face detector based on Viola-Jones approach \CITE was used for detecting near frontal faces in every frame of these video sequences .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
A face detector based on Viola-Jones approach \CITE was used for detecting near frontal faces in every frame of these video sequences .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
Ground-truth information on face-tracks in videos is manually prepared .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
Ground-truth information on face-tracks in videos is manually prepared .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Ground-truth information on face-tracks in videos is manually prepared .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
A face-track of one character appearing in a video shot is annotated by indexes of the frames which the first face and the last face of that character occur .
#<struct ReadData::Alignment source_numbers="24", target_numbers="1", tag_name="wa">
A face-track of one character appearing in a video shot is annotated by indexes of the frames which the first face and the last face of that character occur .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
A face-track of one character appearing in a video shot is annotated by indexes of the frames which the first face and the last face of that character occur .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
A face-track of one character appearing in a video shot is annotated by indexes of the frames which the first face and the last face of that character occur .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
A face-track of one character appearing in a video shot is annotated by indexes of the frames which the first face and the last face of that character occur .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
A face-track of one character appearing in a video shot is annotated by indexes of the frames which the first face and the last face of that character occur .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
A face-track of one character appearing in a video shot is annotated by indexes of the frames which the first face and the last face of that character occur .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
A face-track of one character appearing in a video shot is annotated by indexes of the frames which the first face and the last face of that character occur .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
A face-track of one character appearing in a video shot is annotated by indexes of the frames which the first face and the last face of that character occur .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
An approach is called exactly extracting a face-track if it provides precise starting and ending frame indexes of the face-track , compared to ground-truth annotation .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
An approach is called exactly extracting a face-track if it provides precise starting and ending frame indexes of the face-track , compared to ground-truth annotation .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
An approach is called exactly extracting a face-track if it provides precise starting and ending frame indexes of the face-track , compared to ground-truth annotation .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
An approach is called exactly extracting a face-track if it provides precise starting and ending frame indexes of the face-track , compared to ground-truth annotation .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
An approach is called exactly extracting a face-track if it provides precise starting and ending frame indexes of the face-track , compared to ground-truth annotation .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
An approach is called exactly extracting a face-track if it provides precise starting and ending frame indexes of the face-track , compared to ground-truth annotation .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
An approach is called exactly extracting a face-track if it provides precise starting and ending frame indexes of the face-track , compared to ground-truth annotation .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
An approach is called exactly extracting a face-track if it provides precise starting and ending frame indexes of the face-track , compared to ground-truth annotation .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
An approach is called exactly extracting a face-track if it provides precise starting and ending frame indexes of the face-track , compared to ground-truth annotation .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
Note that if a character moves out of the frame then moves in again , annotators will divide the appearance of that character into two independent face-tracks in our ground-truth .
#<struct ReadData::Alignment source_numbers="23", target_numbers="14", tag_name="wa">
Note that if a character moves out of the frame then moves in again , annotators will divide the appearance of that character into two independent face-tracks in our ground-truth .
#<struct ReadData::Alignment source_numbers="12", target_numbers="31", tag_name="wa">
Note that if a character moves out of the frame then moves in again , annotators will divide the appearance of that character into two independent face-tracks in our ground-truth .
#<struct ReadData::Alignment source_numbers="30", target_numbers="34", tag_name="wa">
Note that if a character moves out of the frame then moves in again , annotators will divide the appearance of that character into two independent face-tracks in our ground-truth .
#<struct ReadData::Alignment source_numbers="26", target_numbers="", tag_name="wa">
Note that if a character moves out of the frame then moves in again , annotators will divide the appearance of that character into two independent face-tracks in our ground-truth .
#<struct ReadData::Alignment source_numbers="27", target_numbers="", tag_name="wa">
Note that if a character moves out of the frame then moves in again , annotators will divide the appearance of that character into two independent face-tracks in our ground-truth .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Note that if a character moves out of the frame then moves in again , annotators will divide the appearance of that character into two independent face-tracks in our ground-truth .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Note that if a character moves out of the frame then moves in again , annotators will divide the appearance of that character into two independent face-tracks in our ground-truth .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
Note that if a character moves out of the frame then moves in again , annotators will divide the appearance of that character into two independent face-tracks in our ground-truth .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
Note that if a character moves out of the frame then moves in again , annotators will divide the appearance of that character into two independent face-tracks in our ground-truth .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
Note that if a character moves out of the frame then moves in again , annotators will divide the appearance of that character into two independent face-tracks in our ground-truth .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
Note that if a character moves out of the frame then moves in again , annotators will divide the appearance of that character into two independent face-tracks in our ground-truth .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
The number of frames , faces , and face tracks are shown in Table 1 .
#<struct ReadData::Alignment source_numbers="10,11", target_numbers="2", tag_name="wa">
The number of frames , faces , and face tracks are shown in Table 1 .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
The number of frames , faces , and face tracks are shown in Table 1 .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
The number of frames , faces , and face tracks are shown in Table 1 .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
In this experiment , we directly compare our approach with one proposed by Everingham et al .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
In this experiment , we directly compare our approach with one proposed by Everingham et al .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
As shown in Table 2 , by detecting flash-frames , our approach successfully overcomes the problem of face-track fragmentation due to illumination changes .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
As shown in Table 2 , by detecting flash-frames , our approach successfully overcomes the problem of face-track fragmentation due to illumination changes .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
As shown in Table 2 , by detecting flash-frames , our approach successfully overcomes the problem of face-track fragmentation due to illumination changes .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
is almost failed to do that .
#<struct ReadData::Alignment source_numbers="2", target_numbers="2", tag_name="wa">
is almost failed to do that .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
is almost failed to do that .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
In addition , the results also shows that our approach is superior to the approach by Everingham et al .
#<struct ReadData::Alignment source_numbers="6,7", target_numbers="6,7", tag_name="wa">
In addition , the results also shows that our approach is superior to the approach by Everingham et al .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
In addition , the results also shows that our approach is superior to the approach by Everingham et al .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
In addition , the results also shows that our approach is superior to the approach by Everingham et al .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
In addition , the results also shows that our approach is superior to the approach by Everingham et al .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
In addition , the results also shows that our approach is superior to the approach by Everingham et al .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
in handling problem caused by partial occlusion and appearance of character in the middle of a shot .
#<struct ReadData::Alignment source_numbers="15", target_numbers="11", tag_name="wa">
in handling problem caused by partial occlusion and appearance of character in the middle of a shot .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
All face-tracks which we could not extract exactly are those fully occluded at some frames during their occurences .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
All face-tracks which we could not extract exactly are those fully occluded at some frames during their occurences .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
All face-tracks which we could not extract exactly are those fully occluded at some frames during their occurences .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
All face-tracks which we could not extract exactly are those fully occluded at some frames during their occurences .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
All face-tracks which we could not extract exactly are those fully occluded at some frames during their occurences .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
All face-tracks which we could not extract exactly are those fully occluded at some frames during their occurences .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
All face-tracks which we could not extract exactly are those fully occluded at some frames during their occurences .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
All face-tracks which we could not extract exactly are those fully occluded at some frames during their occurences .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
All face-tracks which we could not extract exactly are those fully occluded at some frames during their occurences .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
All face-tracks which we could not extract exactly are those fully occluded at some frames during their occurences .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
All face-tracks which we could not extract exactly are those fully occluded at some frames during their occurences .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
All face-tracks which we could not extract exactly are those fully occluded at some frames during their occurences .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
Thus , there is no clue to re-group face of that person after such full occlusions .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Thus , there is no clue to re-group face of that person after such full occlusions .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
Thus , there is no clue to re-group face of that person after such full occlusions .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Thus , there is no clue to re-group face of that person after such full occlusions .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
To handle this problem , using only tracker is not enough .
#<struct ReadData::Alignment source_numbers="4", target_numbers="0", tag_name="wa">
To handle this problem , using only tracker is not enough .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
To handle this problem , using only tracker is not enough .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
To handle this problem , using only tracker is not enough .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
To handle this problem , using only tracker is not enough .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
One can apply visual information based clustering to group the fragmented face-track , as in \CITE , .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
One can apply visual information based clustering to group the fragmented face-track , as in \CITE , .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
One can apply visual information based clustering to group the fragmented face-track , as in \CITE , .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
One can apply visual information based clustering to group the fragmented face-track , as in \CITE , .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
One can apply visual information based clustering to group the fragmented face-track , as in \CITE , .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
One can apply visual information based clustering to group the fragmented face-track , as in \CITE , .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
One can apply visual information based clustering to group the fragmented face-track , as in \CITE , .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
One can apply visual information based clustering to group the fragmented face-track , as in \CITE , .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
Obviously , extra cost is required .
#<struct ReadData::Alignment source_numbers="4,5", target_numbers="2", tag_name="wa">
Obviously , extra cost is required .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Obviously , extra cost is required .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
However , we observe that fully occlusion is rarely happened in news video since characters reported in the news are recorded with care , especially with important and well-known character .
#<struct ReadData::Alignment source_numbers="9", target_numbers="8", tag_name="wa">
However , we observe that fully occlusion is rarely happened in news video since characters reported in the news are recorded with care , especially with important and well-known character .
#<struct ReadData::Alignment source_numbers="17", target_numbers="13", tag_name="wa">
However , we observe that fully occlusion is rarely happened in news video since characters reported in the news are recorded with care , especially with important and well-known character .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
However , we observe that fully occlusion is rarely happened in news video since characters reported in the news are recorded with care , especially with important and well-known character .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
However , we observe that fully occlusion is rarely happened in news video since characters reported in the news are recorded with care , especially with important and well-known character .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
However , we observe that fully occlusion is rarely happened in news video since characters reported in the news are recorded with care , especially with important and well-known character .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
However , we observe that fully occlusion is rarely happened in news video since characters reported in the news are recorded with care , especially with important and well-known character .
#<struct ReadData::Alignment source_numbers="29", target_numbers="", tag_name="wa">
However , we observe that fully occlusion is rarely happened in news video since characters reported in the news are recorded with care , especially with important and well-known character .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
However , we observe that fully occlusion is rarely happened in news video since characters reported in the news are recorded with care , especially with important and well-known character .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
However , we observe that fully occlusion is rarely happened in news video since characters reported in the news are recorded with care , especially with important and well-known character .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
However , we observe that fully occlusion is rarely happened in news video since characters reported in the news are recorded with care , especially with important and well-known character .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
However , we observe that fully occlusion is rarely happened in news video since characters reported in the news are recorded with care , especially with important and well-known character .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
This is a special property of news videos .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
This is a special property of news videos .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
These facts clearly indicate that our approach is robust and outperforms the approach of Everingham et al .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
These facts clearly indicate that our approach is robust and outperforms the approach of Everingham et al .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
These facts clearly indicate that our approach is robust and outperforms the approach of Everingham et al .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
In terms of speed , our approach is approximately 2 times slower than the approach of Everingham .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
In terms of speed , our approach is approximately 2 times slower than the approach of Everingham .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
In terms of speed , our approach is approximately 2 times slower than the approach of Everingham .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
In terms of speed , our approach is approximately 2 times slower than the approach of Everingham .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
In terms of speed , our approach is approximately 2 times slower than the approach of Everingham .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
However , our complexity is somehow linear to total number of face , because we consequently enlarge face-tracks following temporal order by checking new faces with only one last appeared face of each face-track .
#<struct ReadData::Alignment source_numbers="11", target_numbers="18", tag_name="wa">
However , our complexity is somehow linear to total number of face , because we consequently enlarge face-tracks following temporal order by checking new faces with only one last appeared face of each face-track .
#<struct ReadData::Alignment source_numbers="27,28", target_numbers="31,32", tag_name="wa">
However , our complexity is somehow linear to total number of face , because we consequently enlarge face-tracks following temporal order by checking new faces with only one last appeared face of each face-track .
#<struct ReadData::Alignment source_numbers="29", target_numbers="35", tag_name="wa">
However , our complexity is somehow linear to total number of face , because we consequently enlarge face-tracks following temporal order by checking new faces with only one last appeared face of each face-track .
#<struct ReadData::Alignment source_numbers="31,32", target_numbers="36,37", tag_name="wa">
However , our complexity is somehow linear to total number of face , because we consequently enlarge face-tracks following temporal order by checking new faces with only one last appeared face of each face-track .
#<struct ReadData::Alignment source_numbers="34", target_numbers="40", tag_name="wa">
However , our complexity is somehow linear to total number of face , because we consequently enlarge face-tracks following temporal order by checking new faces with only one last appeared face of each face-track .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
However , our complexity is somehow linear to total number of face , because we consequently enlarge face-tracks following temporal order by checking new faces with only one last appeared face of each face-track .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
However , our complexity is somehow linear to total number of face , because we consequently enlarge face-tracks following temporal order by checking new faces with only one last appeared face of each face-track .
#<struct ReadData::Alignment source_numbers="33", target_numbers="", tag_name="wa">
However , our complexity is somehow linear to total number of face , because we consequently enlarge face-tracks following temporal order by checking new faces with only one last appeared face of each face-track .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
However , our complexity is somehow linear to total number of face , because we consequently enlarge face-tracks following temporal order by checking new faces with only one last appeared face of each face-track .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
However , our complexity is somehow linear to total number of face , because we consequently enlarge face-tracks following temporal order by checking new faces with only one last appeared face of each face-track .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
However , our complexity is somehow linear to total number of face , because we consequently enlarge face-tracks following temporal order by checking new faces with only one last appeared face of each face-track .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
However , our complexity is somehow linear to total number of face , because we consequently enlarge face-tracks following temporal order by checking new faces with only one last appeared face of each face-track .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
However , our complexity is somehow linear to total number of face , because we consequently enlarge face-tracks following temporal order by checking new faces with only one last appeared face of each face-track .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
However , our complexity is somehow linear to total number of face , because we consequently enlarge face-tracks following temporal order by checking new faces with only one last appeared face of each face-track .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
compare all pairs of faces in the shot .
#<struct ReadData::Alignment source_numbers="0", target_numbers="0", tag_name="wa">
If this number is getting larger , the gap in speed between our approach and the approach by Everingham et al .
#<struct ReadData::Alignment source_numbers="15", target_numbers="1", tag_name="wa">
If this number is getting larger , the gap in speed between our approach and the approach by Everingham et al .
#<struct ReadData::Alignment source_numbers="2,3", target_numbers="2,3", tag_name="wa">
If this number is getting larger , the gap in speed between our approach and the approach by Everingham et al .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
If this number is getting larger , the gap in speed between our approach and the approach by Everingham et al .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
If this number is getting larger , the gap in speed between our approach and the approach by Everingham et al .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
If this number is getting larger , the gap in speed between our approach and the approach by Everingham et al .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
If this number is getting larger , the gap in speed between our approach and the approach by Everingham et al .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
If this number is getting larger , the gap in speed between our approach and the approach by Everingham et al .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
If this number is getting larger , the gap in speed between our approach and the approach by Everingham et al .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
will be narrowed rapidly.
#<struct ReadData::Alignment source_numbers="2", target_numbers="1", tag_name="wa">
will be narrowed rapidly.
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Because all presented problems here , such as those due to flash , occlusion , and in-the-middle face appearance , are practically observed , overcoming them is vital for practical application .
#<struct ReadData::Alignment source_numbers="31", target_numbers="36", tag_name="wa">
Because all presented problems here , such as those due to flash , occlusion , and in-the-middle face appearance , are practically observed , overcoming them is vital for practical application .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
Because all presented problems here , such as those due to flash , occlusion , and in-the-middle face appearance , are practically observed , overcoming them is vital for practical application .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
Because all presented problems here , such as those due to flash , occlusion , and in-the-middle face appearance , are practically observed , overcoming them is vital for practical application .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
In this experiment , we show that our proposed techniques and solutions for the problems are robust and efficient enough for extracting face-tracks in real-world news videos by successfully extracting 94% of all face-tracks .
#<struct ReadData::Alignment source_numbers="11,12", target_numbers="11,12", tag_name="wa">
In this experiment , we show that our proposed techniques and solutions for the problems are robust and efficient enough for extracting face-tracks in real-world news videos by successfully extracting 94% of all face-tracks .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
In this experiment , we show that our proposed techniques and solutions for the problems are robust and efficient enough for extracting face-tracks in real-world news videos by successfully extracting 94% of all face-tracks .
#<struct ReadData::Alignment source_numbers="33", target_numbers="", tag_name="wa">
In this experiment , we show that our proposed techniques and solutions for the problems are robust and efficient enough for extracting face-tracks in real-world news videos by successfully extracting 94% of all face-tracks .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
In this experiment , we show that our proposed techniques and solutions for the problems are robust and efficient enough for extracting face-tracks in real-world news videos by successfully extracting 94% of all face-tracks .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
In this experiment , we show that our proposed techniques and solutions for the problems are robust and efficient enough for extracting face-tracks in real-world news videos by successfully extracting 94% of all face-tracks .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
In this experiment , we show that our proposed techniques and solutions for the problems are robust and efficient enough for extracting face-tracks in real-world news videos by successfully extracting 94% of all face-tracks .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
From our observations , one can use other complex techniques to handle the problems .
#<struct ReadData::Alignment source_numbers="4,5", target_numbers="8,9", tag_name="wa">
From our observations , one can use other complex techniques to handle the problems .
#<struct ReadData::Alignment source_numbers="6", target_numbers="10", tag_name="wa">
From our observations , one can use other complex techniques to handle the problems .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
From our observations , one can use other complex techniques to handle the problems .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
From our observations , one can use other complex techniques to handle the problems .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
However , a trade-o_ between completely obtaining 6% remaining face-tracks and an overly expensive computational cost should be considered with care.
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
However , a trade-o_ between completely obtaining 6% remaining face-tracks and an overly expensive computational cost should be considered with care.
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
However , a trade-o_ between completely obtaining 6% remaining face-tracks and an overly expensive computational cost should be considered with care.
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
However , a trade-o_ between completely obtaining 6% remaining face-tracks and an overly expensive computational cost should be considered with care.
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
However , a trade-o_ between completely obtaining 6% remaining face-tracks and an overly expensive computational cost should be considered with care.
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
However , a trade-o_ between completely obtaining 6% remaining face-tracks and an overly expensive computational cost should be considered with care.
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
However , a trade-o_ between completely obtaining 6% remaining face-tracks and an overly expensive computational cost should be considered with care.
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
However , a trade-o_ between completely obtaining 6% remaining face-tracks and an overly expensive computational cost should be considered with care.
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
However , a trade-o_ between completely obtaining 6% remaining face-tracks and an overly expensive computational cost should be considered with care.
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
Face-tracks in videos of the datasets are extracted by using our proposed approach for face-track extraction ( see section 4.2 ) .
#<struct ReadData::Alignment source_numbers="6", target_numbers="2", tag_name="wa">
Face-tracks in videos of the datasets are extracted by using our proposed approach for face-track extraction ( see section 4.2 ) .
#<struct ReadData::Alignment source_numbers="7", target_numbers="3", tag_name="wa">
Face-tracks in videos of the datasets are extracted by using our proposed approach for face-track extraction ( see section 4.2 ) .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Face-tracks in videos of the datasets are extracted by using our proposed approach for face-track extraction ( see section 4.2 ) .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Face-tracks in videos of the datasets are extracted by using our proposed approach for face-track extraction ( see section 4.2 ) .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
Face-tracks in videos of the datasets are extracted by using our proposed approach for face-track extraction ( see section 4.2 ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Face-tracks in videos of the datasets are extracted by using our proposed approach for face-track extraction ( see section 4.2 ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Face-tracks in videos of the datasets are extracted by using our proposed approach for face-track extraction ( see section 4.2 ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Face-tracks in videos of the datasets are extracted by using our proposed approach for face-track extraction ( see section 4.2 ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Identity of the character associated with each extracted face-track is given by annotators .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Identity of the character associated with each extracted face-track is given by annotators .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Identity of the character associated with each extracted face-track is given by annotators .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Identity of the character associated with each extracted face-track is given by annotators .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Identity of the character associated with each extracted face-track is given by annotators .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Since our approach extract face-tracks in each video shot , shot boundaries for videos are required .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Since our approach extract face-tracks in each video shot , shot boundaries for videos are required .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
Since our approach extract face-tracks in each video shot , shot boundaries for videos are required .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
Since our approach extract face-tracks in each video shot , shot boundaries for videos are required .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Since our approach extract face-tracks in each video shot , shot boundaries for videos are required .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Since our approach extract face-tracks in each video shot , shot boundaries for videos are required .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Since our approach extract face-tracks in each video shot , shot boundaries for videos are required .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
The whole process , including detecting shot boundaries and face-track extraction , is fully automatic.
#<struct ReadData::Alignment source_numbers="7", target_numbers="6", tag_name="wa">
The whole process , including detecting shot boundaries and face-track extraction , is fully automatic.
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
The whole process , including detecting shot boundaries and face-track extraction , is fully automatic.
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
The whole process , including detecting shot boundaries and face-track extraction , is fully automatic.
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
The whole process , including detecting shot boundaries and face-track extraction , is fully automatic.
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
TRECVID Dataset .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
TRECVID Dataset .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
The total number of frames that we processed was approximately 35 millions frames .
#<struct ReadData::Alignment source_numbers="11", target_numbers="11", tag_name="wa">
The total number of frames that we processed was approximately 35 millions frames .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
We filtered out short face tracks that had less than ten faces , .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
This resulted in 35,836 face tracks .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Finally , we annotated 1,497 face tracks containing 405,887 faces of 41 well known individual characters .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
Finally , we annotated 1,497 face tracks containing 405,887 faces of 41 well known individual characters .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
Finally , we annotated 1,497 face tracks containing 405,887 faces of 41 well known individual characters .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
NHKNews7 Dataset .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
NHKNews7 Dataset .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
This dataset is observed from NHKNews7 channel in 11 years .
#<struct ReadData::Alignment source_numbers="2", target_numbers="2,3", tag_name="wa">
This dataset is observed from NHKNews7 channel in 11 years .
#<struct ReadData::Alignment source_numbers="3", target_numbers="4", tag_name="wa">
This dataset is observed from NHKNews7 channel in 11 years .
#<struct ReadData::Alignment source_numbers="10", target_numbers="14", tag_name="wa">
This dataset is observed from NHKNews7 channel in 11 years .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
This dataset is observed from NHKNews7 channel in 11 years .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
This dataset is observed from NHKNews7 channel in 11 years .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
This dataset is observed from NHKNews7 channel in 11 years .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
This dataset is observed from NHKNews7 channel in 11 years .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
This dataset is observed from NHKNews7 channel in 11 years .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
This dataset is observed from NHKNews7 channel in 11 years .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
This dataset is observed from NHKNews7 channel in 11 years .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
The total number of face-tracks is 5,567 .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
The total number of face-tracks is 5,567 .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
The total number of face-tracks is 5,567 .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Each character has from 4 to 550 face-tracks .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Each character has from 4 to 550 face-tracks .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Each character has from 4 to 550 face-tracks .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
In this dataset , we discard facetracks with fewer than 100 faces and more than 500 faces .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
In this dataset , we discard facetracks with fewer than 100 faces and more than 500 faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
In this dataset , we discard facetracks with fewer than 100 faces and more than 500 faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
In the Table 4 , we compare our datasets with some public benchmark datasets .
#<struct ReadData::Alignment source_numbers="5,6", target_numbers="5", tag_name="wa">
In the Table 4 , we compare our datasets with some public benchmark datasets .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
In the Table 4 , we compare our datasets with some public benchmark datasets .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
In the Table 4 , we compare our datasets with some public benchmark datasets .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
In the Table 4 , we compare our datasets with some public benchmark datasets .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
In the Table 4 , we compare our datasets with some public benchmark datasets .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
In the Table 4 , we compare our datasets with some public benchmark datasets .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
In the Table 4 , we compare our datasets with some public benchmark datasets .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
, It is obvious that our datasets are extremely higher than datasets , such as MoBo and Honda / UCSD , on all statistical terms , including the number of videos , characters , and average length of face-track .
#<struct ReadData::Alignment source_numbers="21", target_numbers="1", tag_name="wa">
, It is obvious that our datasets are extremely higher than datasets , such as MoBo and Honda / UCSD , on all statistical terms , including the number of videos , characters , and average length of face-track .
#<struct ReadData::Alignment source_numbers="27", target_numbers="2", tag_name="wa">
, It is obvious that our datasets are extremely higher than datasets , such as MoBo and Honda / UCSD , on all statistical terms , including the number of videos , characters , and average length of face-track .
#<struct ReadData::Alignment source_numbers="0", target_numbers="4", tag_name="wa">
, It is obvious that our datasets are extremely higher than datasets , such as MoBo and Honda / UCSD , on all statistical terms , including the number of videos , characters , and average length of face-track .
#<struct ReadData::Alignment source_numbers="2", target_numbers="6", tag_name="wa">
, It is obvious that our datasets are extremely higher than datasets , such as MoBo and Honda / UCSD , on all statistical terms , including the number of videos , characters , and average length of face-track .
#<struct ReadData::Alignment source_numbers="3", target_numbers="7", tag_name="wa">
, It is obvious that our datasets are extremely higher than datasets , such as MoBo and Honda / UCSD , on all statistical terms , including the number of videos , characters , and average length of face-track .
#<struct ReadData::Alignment source_numbers="4", target_numbers="8", tag_name="wa">
, It is obvious that our datasets are extremely higher than datasets , such as MoBo and Honda / UCSD , on all statistical terms , including the number of videos , characters , and average length of face-track .
#<struct ReadData::Alignment source_numbers="5", target_numbers="9", tag_name="wa">
, It is obvious that our datasets are extremely higher than datasets , such as MoBo and Honda / UCSD , on all statistical terms , including the number of videos , characters , and average length of face-track .
#<struct ReadData::Alignment source_numbers="6", target_numbers="10", tag_name="wa">
, It is obvious that our datasets are extremely higher than datasets , such as MoBo and Honda / UCSD , on all statistical terms , including the number of videos , characters , and average length of face-track .
#<struct ReadData::Alignment source_numbers="25", target_numbers="30", tag_name="wa">
, It is obvious that our datasets are extremely higher than datasets , such as MoBo and Honda / UCSD , on all statistical terms , including the number of videos , characters , and average length of face-track .
#<struct ReadData::Alignment source_numbers="31", target_numbers="35", tag_name="wa">
, It is obvious that our datasets are extremely higher than datasets , such as MoBo and Honda / UCSD , on all statistical terms , including the number of videos , characters , and average length of face-track .
#<struct ReadData::Alignment source_numbers="39", target_numbers="44", tag_name="wa">
, It is obvious that our datasets are extremely higher than datasets , such as MoBo and Honda / UCSD , on all statistical terms , including the number of videos , characters , and average length of face-track .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
, It is obvious that our datasets are extremely higher than datasets , such as MoBo and Honda / UCSD , on all statistical terms , including the number of videos , characters , and average length of face-track .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
, It is obvious that our datasets are extremely higher than datasets , such as MoBo and Honda / UCSD , on all statistical terms , including the number of videos , characters , and average length of face-track .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
, It is obvious that our datasets are extremely higher than datasets , such as MoBo and Honda / UCSD , on all statistical terms , including the number of videos , characters , and average length of face-track .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
, It is obvious that our datasets are extremely higher than datasets , such as MoBo and Honda / UCSD , on all statistical terms , including the number of videos , characters , and average length of face-track .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
, It is obvious that our datasets are extremely higher than datasets , such as MoBo and Honda / UCSD , on all statistical terms , including the number of videos , characters , and average length of face-track .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
, It is obvious that our datasets are extremely higher than datasets , such as MoBo and Honda / UCSD , on all statistical terms , including the number of videos , characters , and average length of face-track .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
, It is obvious that our datasets are extremely higher than datasets , such as MoBo and Honda / UCSD , on all statistical terms , including the number of videos , characters , and average length of face-track .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
, It is obvious that our datasets are extremely higher than datasets , such as MoBo and Honda / UCSD , on all statistical terms , including the number of videos , characters , and average length of face-track .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
, It is obvious that our datasets are extremely higher than datasets , such as MoBo and Honda / UCSD , on all statistical terms , including the number of videos , characters , and average length of face-track .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
, It is obvious that our datasets are extremely higher than datasets , such as MoBo and Honda / UCSD , on all statistical terms , including the number of videos , characters , and average length of face-track .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
, It is obvious that our datasets are extremely higher than datasets , such as MoBo and Honda / UCSD , on all statistical terms , including the number of videos , characters , and average length of face-track .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
Compared to Youtube Faces dataset , although ours have less number of character ( or subjects ) , we provide much more face-tracks ( or video shots ) per character , .
#<struct ReadData::Alignment source_numbers="17", target_numbers="7", tag_name="wa">
Compared to Youtube Faces dataset , although ours have less number of character ( or subjects ) , we provide much more face-tracks ( or video shots ) per character , .
#<struct ReadData::Alignment source_numbers="30", target_numbers="21", tag_name="wa">
Compared to Youtube Faces dataset , although ours have less number of character ( or subjects ) , we provide much more face-tracks ( or video shots ) per character , .
#<struct ReadData::Alignment source_numbers="7", target_numbers="23", tag_name="wa">
Compared to Youtube Faces dataset , although ours have less number of character ( or subjects ) , we provide much more face-tracks ( or video shots ) per character , .
#<struct ReadData::Alignment source_numbers="10,11", target_numbers="27,28", tag_name="wa">
Compared to Youtube Faces dataset , although ours have less number of character ( or subjects ) , we provide much more face-tracks ( or video shots ) per character , .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Compared to Youtube Faces dataset , although ours have less number of character ( or subjects ) , we provide much more face-tracks ( or video shots ) per character , .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Compared to Youtube Faces dataset , although ours have less number of character ( or subjects ) , we provide much more face-tracks ( or video shots ) per character , .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
Compared to Youtube Faces dataset , although ours have less number of character ( or subjects ) , we provide much more face-tracks ( or video shots ) per character , .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Compared to Youtube Faces dataset , although ours have less number of character ( or subjects ) , we provide much more face-tracks ( or video shots ) per character , .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
Compared to Youtube Faces dataset , although ours have less number of character ( or subjects ) , we provide much more face-tracks ( or video shots ) per character , .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Compared to Youtube Faces dataset , although ours have less number of character ( or subjects ) , we provide much more face-tracks ( or video shots ) per character , .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
Compared to Youtube Faces dataset , although ours have less number of character ( or subjects ) , we provide much more face-tracks ( or video shots ) per character , .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
Thus , ours are more relevant for evaluating retrieval system.
#<struct ReadData::Alignment source_numbers="2", target_numbers="2", tag_name="wa">
Thus , ours are more relevant for evaluating retrieval system.
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
Thus , ours are more relevant for evaluating retrieval system.
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Thus , ours are more relevant for evaluating retrieval system.
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Thus , ours are more relevant for evaluating retrieval system.
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Statistical information of our datasets is given in the Figure 5 .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Statistical information of our datasets is given in the Figure 5 .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Statistical information of our datasets is given in the Figure 5 .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Statistical information of our datasets is given in the Figure 5 .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
Statistical information of our datasets is given in the Figure 5 .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Statistical information of our datasets is given in the Figure 5 .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Statistical information of our datasets is given in the Figure 5 .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Statistical information of our datasets is given in the Figure 5 .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
The datasets can be downloaded at http: / / satohlab .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
The datasets can be downloaded at http: / / satohlab .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
However , due to copyright issues , face images in face-tracks can not be published .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
However , due to copyright issues , face images in face-tracks can not be published .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
However , due to copyright issues , face images in face-tracks can not be published .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
A feature vector of a face is extracted by computing descriptors of the local appearance of the face around each of the located facial features .
#<struct ReadData::Alignment source_numbers="21", target_numbers="10", tag_name="wa">
A feature vector of a face is extracted by computing descriptors of the local appearance of the face around each of the located facial features .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
A feature vector of a face is extracted by computing descriptors of the local appearance of the face around each of the located facial features .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
A feature vector of a face is extracted by computing descriptors of the local appearance of the face around each of the located facial features .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
They estimate an affine transformation , which transform the located facial feature points to a canonical set of feature positions .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
They estimate an affine transformation , which transform the located facial feature points to a canonical set of feature positions .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
They estimate an affine transformation , which transform the located facial feature points to a canonical set of feature positions .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
They estimate an affine transformation , which transform the located facial feature points to a canonical set of feature positions .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
They estimate an affine transformation , which transform the located facial feature points to a canonical set of feature positions .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
They estimate an affine transformation , which transform the located facial feature points to a canonical set of feature positions .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
We compare k-Faces with several approaches , including approaches based on pair-wise distances , MSM \CITE and CMSM \CITE.
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
We compare k-Faces with several approaches , including approaches based on pair-wise distances , MSM \CITE and CMSM \CITE.
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Given two face-tracks having multiple face images represented as feature vectors , pair-wise based approaches compute distances between each possible pair of feature vectors in two face-tracks .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Given two face-tracks having multiple face images represented as feature vectors , pair-wise based approaches compute distances between each possible pair of feature vectors in two face-tracks .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
Given two face-tracks having multiple face images represented as feature vectors , pair-wise based approaches compute distances between each possible pair of feature vectors in two face-tracks .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
Given two face-tracks having multiple face images represented as feature vectors , pair-wise based approaches compute distances between each possible pair of feature vectors in two face-tracks .
#<struct ReadData::Alignment source_numbers="26", target_numbers="", tag_name="wa">
Given two face-tracks having multiple face images represented as feature vectors , pair-wise based approaches compute distances between each possible pair of feature vectors in two face-tracks .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Given two face-tracks having multiple face images represented as feature vectors , pair-wise based approaches compute distances between each possible pair of feature vectors in two face-tracks .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Given two face-tracks having multiple face images represented as feature vectors , pair-wise based approaches compute distances between each possible pair of feature vectors in two face-tracks .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Given two face-tracks having multiple face images represented as feature vectors , pair-wise based approaches compute distances between each possible pair of feature vectors in two face-tracks .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
Given two face-tracks having multiple face images represented as feature vectors , pair-wise based approaches compute distances between each possible pair of feature vectors in two face-tracks .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
They then use the maximum distance , the minimum distance , or the mean distance of the computed pair-wise distances as the similarity measurement between two face-tracks .
#<struct ReadData::Alignment source_numbers="3", target_numbers="18", tag_name="wa">
They then use the maximum distance , the minimum distance , or the mean distance of the computed pair-wise distances as the similarity measurement between two face-tracks .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
They then use the maximum distance , the minimum distance , or the mean distance of the computed pair-wise distances as the similarity measurement between two face-tracks .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
They then use the maximum distance , the minimum distance , or the mean distance of the computed pair-wise distances as the similarity measurement between two face-tracks .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
They then use the maximum distance , the minimum distance , or the mean distance of the computed pair-wise distances as the similarity measurement between two face-tracks .
#<struct ReadData::Alignment source_numbers="26", target_numbers="", tag_name="wa">
They then use the maximum distance , the minimum distance , or the mean distance of the computed pair-wise distances as the similarity measurement between two face-tracks .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
They then use the maximum distance , the minimum distance , or the mean distance of the computed pair-wise distances as the similarity measurement between two face-tracks .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
They then use the maximum distance , the minimum distance , or the mean distance of the computed pair-wise distances as the similarity measurement between two face-tracks .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
They then use the maximum distance , the minimum distance , or the mean distance of the computed pair-wise distances as the similarity measurement between two face-tracks .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
They then use the maximum distance , the minimum distance , or the mean distance of the computed pair-wise distances as the similarity measurement between two face-tracks .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
We denote the approaches as pair:max , pair:min , and pair:mean , respectively ( see Figure 6 for illustration ) .
#<struct ReadData::Alignment source_numbers="1", target_numbers="1", tag_name="wa">
We denote the approaches as pair:max , pair:min , and pair:mean , respectively ( see Figure 6 for illustration ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Regarding to \CITE , if the pair-wise based approaches are representative for non-parametric sampled based approaches , MSM and CMSM are representative for approaches based on parametric model .
#<struct ReadData::Alignment source_numbers="21,22", target_numbers="18,19", tag_name="wa">
Regarding to \CITE , if the pair-wise based approaches are representative for non-parametric sampled based approaches , MSM and CMSM are representative for approaches based on parametric model .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
Regarding to \CITE , if the pair-wise based approaches are representative for non-parametric sampled based approaches , MSM and CMSM are representative for approaches based on parametric model .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Regarding to \CITE , if the pair-wise based approaches are representative for non-parametric sampled based approaches , MSM and CMSM are representative for approaches based on parametric model .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
Regarding to \CITE , if the pair-wise based approaches are representative for non-parametric sampled based approaches , MSM and CMSM are representative for approaches based on parametric model .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
Regarding to \CITE , if the pair-wise based approaches are representative for non-parametric sampled based approaches , MSM and CMSM are representative for approaches based on parametric model .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
Regarding to \CITE , if the pair-wise based approaches are representative for non-parametric sampled based approaches , MSM and CMSM are representative for approaches based on parametric model .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
Regarding to \CITE , if the pair-wise based approaches are representative for non-parametric sampled based approaches , MSM and CMSM are representative for approaches based on parametric model .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Regarding to \CITE , if the pair-wise based approaches are representative for non-parametric sampled based approaches , MSM and CMSM are representative for approaches based on parametric model .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Regarding to \CITE , if the pair-wise based approaches are representative for non-parametric sampled based approaches , MSM and CMSM are representative for approaches based on parametric model .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Regarding to \CITE , if the pair-wise based approaches are representative for non-parametric sampled based approaches , MSM and CMSM are representative for approaches based on parametric model .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
CMSM is an extension of MSM , in which subspaces of the sets are projected on a constraint subspace .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
CMSM is an extension of MSM , in which subspaces of the sets are projected on a constraint subspace .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
By doing that , the subspaces are expected to be better separatable .
#<struct ReadData::Alignment source_numbers="1,2", target_numbers="1,2", tag_name="wa">
By doing that , the subspaces are expected to be better separatable .
#<struct ReadData::Alignment source_numbers="9,10", target_numbers="9,10", tag_name="wa">
By doing that , the subspaces are expected to be better separatable .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
By doing that , the subspaces are expected to be better separatable .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
By doing that , the subspaces are expected to be better separatable .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
By doing that , the subspaces are expected to be better separatable .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
All of these approaches had been shown their robustness on benchmark datasets , such as MoBo , HondaUCSD , and Youtube Faces .
#<struct ReadData::Alignment source_numbers="4,5", target_numbers="4", tag_name="wa">
All of these approaches had been shown their robustness on benchmark datasets , such as MoBo , HondaUCSD , and Youtube Faces .
#<struct ReadData::Alignment source_numbers="6", target_numbers="5", tag_name="wa">
All of these approaches had been shown their robustness on benchmark datasets , such as MoBo , HondaUCSD , and Youtube Faces .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
All of these approaches had been shown their robustness on benchmark datasets , such as MoBo , HondaUCSD , and Youtube Faces .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
All of these approaches had been shown their robustness on benchmark datasets , such as MoBo , HondaUCSD , and Youtube Faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
All of these approaches had been shown their robustness on benchmark datasets , such as MoBo , HondaUCSD , and Youtube Faces .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
Besides evaluating k-Faces with different values of k as well as different types of distance ( e.g. , Euclidean , L1 , cosine ) , we try another criterion to select k representative faces in a face-track .
#<struct ReadData::Alignment source_numbers="21", target_numbers="19", tag_name="wa">
Besides evaluating k-Faces with different values of k as well as different types of distance ( e.g. , Euclidean , L1 , cosine ) , we try another criterion to select k representative faces in a face-track .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Besides evaluating k-Faces with different values of k as well as different types of distance ( e.g. , Euclidean , L1 , cosine ) , we try another criterion to select k representative faces in a face-track .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Besides evaluating k-Faces with different values of k as well as different types of distance ( e.g. , Euclidean , L1 , cosine ) , we try another criterion to select k representative faces in a face-track .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Besides evaluating k-Faces with different values of k as well as different types of distance ( e.g. , Euclidean , L1 , cosine ) , we try another criterion to select k representative faces in a face-track .
#<struct ReadData::Alignment source_numbers="36", target_numbers="", tag_name="wa">
Besides evaluating k-Faces with different values of k as well as different types of distance ( e.g. , Euclidean , L1 , cosine ) , we try another criterion to select k representative faces in a face-track .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Besides evaluating k-Faces with different values of k as well as different types of distance ( e.g. , Euclidean , L1 , cosine ) , we try another criterion to select k representative faces in a face-track .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
Besides evaluating k-Faces with different values of k as well as different types of distance ( e.g. , Euclidean , L1 , cosine ) , we try another criterion to select k representative faces in a face-track .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
Besides evaluating k-Faces with different values of k as well as different types of distance ( e.g. , Euclidean , L1 , cosine ) , we try another criterion to select k representative faces in a face-track .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
In the original way , we proposed to select these faces by partitioning the face-track following temporal order and selecting the middle face of each partition .
#<struct ReadData::Alignment source_numbers="19", target_numbers="7", tag_name="wa">
In the original way , we proposed to select these faces by partitioning the face-track following temporal order and selecting the middle face of each partition .
#<struct ReadData::Alignment source_numbers="7", target_numbers="16", tag_name="wa">
In the original way , we proposed to select these faces by partitioning the face-track following temporal order and selecting the middle face of each partition .
#<struct ReadData::Alignment source_numbers="20", target_numbers="17", tag_name="wa">
In the original way , we proposed to select these faces by partitioning the face-track following temporal order and selecting the middle face of each partition .
#<struct ReadData::Alignment source_numbers="8", target_numbers="21", tag_name="wa">
In the original way , we proposed to select these faces by partitioning the face-track following temporal order and selecting the middle face of each partition .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
In the original way , we proposed to select these faces by partitioning the face-track following temporal order and selecting the middle face of each partition .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
In the original way , we proposed to select these faces by partitioning the face-track following temporal order and selecting the middle face of each partition .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
In the original way , we proposed to select these faces by partitioning the face-track following temporal order and selecting the middle face of each partition .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
In the original way , we proposed to select these faces by partitioning the face-track following temporal order and selecting the middle face of each partition .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
In the original way , we proposed to select these faces by partitioning the face-track following temporal order and selecting the middle face of each partition .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
However , an yet another criterion can be applied to select these representative faces is based on clustering .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
However , an yet another criterion can be applied to select these representative faces is based on clustering .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
However , an yet another criterion can be applied to select these representative faces is based on clustering .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
In this new way , all faces in a face-track will be clustered in to k groups by a clustering algorithm .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
In this new way , all faces in a face-track will be clustered in to k groups by a clustering algorithm .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
In this new way , all faces in a face-track will be clustered in to k groups by a clustering algorithm .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
In this new way , all faces in a face-track will be clustered in to k groups by a clustering algorithm .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
Then , the mean of k centroids is used as the representative face for the face-track .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
Then , the mean of k centroids is used as the representative face for the face-track .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
Then , the mean of k centroids is used as the representative face for the face-track .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
We denote the former k-Faces as k-Faces.Temporal and the latter k-Faces as k-Faces.KMeans.
#<struct ReadData::Alignment source_numbers="1", target_numbers="1", tag_name="wa">
We denote the former k-Faces as k-Faces.Temporal and the latter k-Faces as k-Faces.KMeans.
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
We denote the former k-Faces as k-Faces.Temporal and the latter k-Faces as k-Faces.KMeans.
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
We evaluate performance of a face-track matching approach by computing the average precision on the rank list returned by the approach .
#<struct ReadData::Alignment source_numbers="19", target_numbers="2", tag_name="wa">
We evaluate performance of a face-track matching approach by computing the average precision on the rank list returned by the approach .
#<struct ReadData::Alignment source_numbers="17", target_numbers="20", tag_name="wa">
We evaluate performance of a face-track matching approach by computing the average precision on the rank list returned by the approach .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
We evaluate performance of a face-track matching approach by computing the average precision on the rank list returned by the approach .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
We evaluate performance of a face-track matching approach by computing the average precision on the rank list returned by the approach .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
We evaluate performance of a face-track matching approach by computing the average precision on the rank list returned by the approach .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
We evaluate performance of a face-track matching approach by computing the average precision on the rank list returned by the approach .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
We evaluate performance of a face-track matching approach by computing the average precision on the rank list returned by the approach .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
In particular , for each dataset , each face-track is alternatively picked out as a query facetrack , while the remaining face-tracks are used as the retrieved database .
#<struct ReadData::Alignment source_numbers="3,4", target_numbers="3,4", tag_name="wa">
In particular , for each dataset , each face-track is alternatively picked out as a query facetrack , while the remaining face-tracks are used as the retrieved database .
#<struct ReadData::Alignment source_numbers="14", target_numbers="7", tag_name="wa">
In particular , for each dataset , each face-track is alternatively picked out as a query facetrack , while the remaining face-tracks are used as the retrieved database .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
In particular , for each dataset , each face-track is alternatively picked out as a query facetrack , while the remaining face-tracks are used as the retrieved database .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
In particular , for each dataset , each face-track is alternatively picked out as a query facetrack , while the remaining face-tracks are used as the retrieved database .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
In particular , for each dataset , each face-track is alternatively picked out as a query facetrack , while the remaining face-tracks are used as the retrieved database .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
In particular , for each dataset , each face-track is alternatively picked out as a query facetrack , while the remaining face-tracks are used as the retrieved database .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
In particular , for each dataset , each face-track is alternatively picked out as a query facetrack , while the remaining face-tracks are used as the retrieved database .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
In particular , for each dataset , each face-track is alternatively picked out as a query facetrack , while the remaining face-tracks are used as the retrieved database .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
In particular , for each dataset , each face-track is alternatively picked out as a query facetrack , while the remaining face-tracks are used as the retrieved database .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
In particular , for each dataset , each face-track is alternatively picked out as a query facetrack , while the remaining face-tracks are used as the retrieved database .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
In particular , for each dataset , each face-track is alternatively picked out as a query facetrack , while the remaining face-tracks are used as the retrieved database .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
In particular , for each dataset , each face-track is alternatively picked out as a query facetrack , while the remaining face-tracks are used as the retrieved database .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
, Average precision of the returned ranked list is computed , given a query .
#<struct ReadData::Alignment source_numbers="10", target_numbers="14", tag_name="wa">
, Average precision of the returned ranked list is computed , given a query .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
, Average precision of the returned ranked list is computed , given a query .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
, Average precision of the returned ranked list is computed , given a query .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
, Average precision of the returned ranked list is computed , given a query .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Finally , the mean of all average precision ( MAP ) from all query is reported as the overall evaluation metric for the approach on the database.
#<struct ReadData::Alignment source_numbers="21", target_numbers="12", tag_name="wa">
Finally , the mean of all average precision ( MAP ) from all query is reported as the overall evaluation metric for the approach on the database.
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
Finally , the mean of all average precision ( MAP ) from all query is reported as the overall evaluation metric for the approach on the database.
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
Finally , the mean of all average precision ( MAP ) from all query is reported as the overall evaluation metric for the approach on the database.
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
Finally , the mean of all average precision ( MAP ) from all query is reported as the overall evaluation metric for the approach on the database.
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
Finally , the mean of all average precision ( MAP ) from all query is reported as the overall evaluation metric for the approach on the database.
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
Finally , the mean of all average precision ( MAP ) from all query is reported as the overall evaluation metric for the approach on the database.
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
Let denote r as a rank in the returned face-track list , Pre( r ) as is the precision at the rank r of the list , Nl as the length of the list , Nhit as the total number of face-tracks matched with the query face-track q , and I sMatched( k ) as a binary function returning 1 if the face-track at rank r is matched with q ( based on ground-truth annotations ) , zero otherwise .
#<struct ReadData::Alignment source_numbers="26", target_numbers="22", tag_name="wa">
Let denote r as a rank in the returned face-track list , Pre( r ) as is the precision at the rank r of the list , Nl as the length of the list , Nhit as the total number of face-tracks matched with the query face-track q , and I sMatched( k ) as a binary function returning 1 if the face-track at rank r is matched with q ( based on ground-truth annotations ) , zero otherwise .
#<struct ReadData::Alignment source_numbers="34", target_numbers="29", tag_name="wa">
Let denote r as a rank in the returned face-track list , Pre( r ) as is the precision at the rank r of the list , Nl as the length of the list , Nhit as the total number of face-tracks matched with the query face-track q , and I sMatched( k ) as a binary function returning 1 if the face-track at rank r is matched with q ( based on ground-truth annotations ) , zero otherwise .
#<struct ReadData::Alignment source_numbers="37", target_numbers="31", tag_name="wa">
Let denote r as a rank in the returned face-track list , Pre( r ) as is the precision at the rank r of the list , Nl as the length of the list , Nhit as the total number of face-tracks matched with the query face-track q , and I sMatched( k ) as a binary function returning 1 if the face-track at rank r is matched with q ( based on ground-truth annotations ) , zero otherwise .
#<struct ReadData::Alignment source_numbers="47", target_numbers="43", tag_name="wa">
Let denote r as a rank in the returned face-track list , Pre( r ) as is the precision at the rank r of the list , Nl as the length of the list , Nhit as the total number of face-tracks matched with the query face-track q , and I sMatched( k ) as a binary function returning 1 if the face-track at rank r is matched with q ( based on ground-truth annotations ) , zero otherwise .
#<struct ReadData::Alignment source_numbers="48", target_numbers="44", tag_name="wa">
Let denote r as a rank in the returned face-track list , Pre( r ) as is the precision at the rank r of the list , Nl as the length of the list , Nhit as the total number of face-tracks matched with the query face-track q , and I sMatched( k ) as a binary function returning 1 if the face-track at rank r is matched with q ( based on ground-truth annotations ) , zero otherwise .
#<struct ReadData::Alignment source_numbers="49", target_numbers="45", tag_name="wa">
Let denote r as a rank in the returned face-track list , Pre( r ) as is the precision at the rank r of the list , Nl as the length of the list , Nhit as the total number of face-tracks matched with the query face-track q , and I sMatched( k ) as a binary function returning 1 if the face-track at rank r is matched with q ( based on ground-truth annotations ) , zero otherwise .
#<struct ReadData::Alignment source_numbers="50", target_numbers="46", tag_name="wa">
Let denote r as a rank in the returned face-track list , Pre( r ) as is the precision at the rank r of the list , Nl as the length of the list , Nhit as the total number of face-tracks matched with the query face-track q , and I sMatched( k ) as a binary function returning 1 if the face-track at rank r is matched with q ( based on ground-truth annotations ) , zero otherwise .
#<struct ReadData::Alignment source_numbers="51", target_numbers="47", tag_name="wa">
Let denote r as a rank in the returned face-track list , Pre( r ) as is the precision at the rank r of the list , Nl as the length of the list , Nhit as the total number of face-tracks matched with the query face-track q , and I sMatched( k ) as a binary function returning 1 if the face-track at rank r is matched with q ( based on ground-truth annotations ) , zero otherwise .
#<struct ReadData::Alignment source_numbers="52", target_numbers="48", tag_name="wa">
Let denote r as a rank in the returned face-track list , Pre( r ) as is the precision at the rank r of the list , Nl as the length of the list , Nhit as the total number of face-tracks matched with the query face-track q , and I sMatched( k ) as a binary function returning 1 if the face-track at rank r is matched with q ( based on ground-truth annotations ) , zero otherwise .
#<struct ReadData::Alignment source_numbers="53", target_numbers="49", tag_name="wa">
Let denote r as a rank in the returned face-track list , Pre( r ) as is the precision at the rank r of the list , Nl as the length of the list , Nhit as the total number of face-tracks matched with the query face-track q , and I sMatched( k ) as a binary function returning 1 if the face-track at rank r is matched with q ( based on ground-truth annotations ) , zero otherwise .
#<struct ReadData::Alignment source_numbers="55", target_numbers="50", tag_name="wa">
Let denote r as a rank in the returned face-track list , Pre( r ) as is the precision at the rank r of the list , Nl as the length of the list , Nhit as the total number of face-tracks matched with the query face-track q , and I sMatched( k ) as a binary function returning 1 if the face-track at rank r is matched with q ( based on ground-truth annotations ) , zero otherwise .
#<struct ReadData::Alignment source_numbers="56", target_numbers="51", tag_name="wa">
Let denote r as a rank in the returned face-track list , Pre( r ) as is the precision at the rank r of the list , Nl as the length of the list , Nhit as the total number of face-tracks matched with the query face-track q , and I sMatched( k ) as a binary function returning 1 if the face-track at rank r is matched with q ( based on ground-truth annotations ) , zero otherwise .
#<struct ReadData::Alignment source_numbers="57", target_numbers="52", tag_name="wa">
Let denote r as a rank in the returned face-track list , Pre( r ) as is the precision at the rank r of the list , Nl as the length of the list , Nhit as the total number of face-tracks matched with the query face-track q , and I sMatched( k ) as a binary function returning 1 if the face-track at rank r is matched with q ( based on ground-truth annotations ) , zero otherwise .
#<struct ReadData::Alignment source_numbers="58", target_numbers="53", tag_name="wa">
Let denote r as a rank in the returned face-track list , Pre( r ) as is the precision at the rank r of the list , Nl as the length of the list , Nhit as the total number of face-tracks matched with the query face-track q , and I sMatched( k ) as a binary function returning 1 if the face-track at rank r is matched with q ( based on ground-truth annotations ) , zero otherwise .
#<struct ReadData::Alignment source_numbers="59", target_numbers="54", tag_name="wa">
Let denote r as a rank in the returned face-track list , Pre( r ) as is the precision at the rank r of the list , Nl as the length of the list , Nhit as the total number of face-tracks matched with the query face-track q , and I sMatched( k ) as a binary function returning 1 if the face-track at rank r is matched with q ( based on ground-truth annotations ) , zero otherwise .
#<struct ReadData::Alignment source_numbers="60", target_numbers="55", tag_name="wa">
Let denote r as a rank in the returned face-track list , Pre( r ) as is the precision at the rank r of the list , Nl as the length of the list , Nhit as the total number of face-tracks matched with the query face-track q , and I sMatched( k ) as a binary function returning 1 if the face-track at rank r is matched with q ( based on ground-truth annotations ) , zero otherwise .
#<struct ReadData::Alignment source_numbers="61", target_numbers="56", tag_name="wa">
Let denote r as a rank in the returned face-track list , Pre( r ) as is the precision at the rank r of the list , Nl as the length of the list , Nhit as the total number of face-tracks matched with the query face-track q , and I sMatched( k ) as a binary function returning 1 if the face-track at rank r is matched with q ( based on ground-truth annotations ) , zero otherwise .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
Let denote r as a rank in the returned face-track list , Pre( r ) as is the precision at the rank r of the list , Nl as the length of the list , Nhit as the total number of face-tracks matched with the query face-track q , and I sMatched( k ) as a binary function returning 1 if the face-track at rank r is matched with q ( based on ground-truth annotations ) , zero otherwise .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
Let denote r as a rank in the returned face-track list , Pre( r ) as is the precision at the rank r of the list , Nl as the length of the list , Nhit as the total number of face-tracks matched with the query face-track q , and I sMatched( k ) as a binary function returning 1 if the face-track at rank r is matched with q ( based on ground-truth annotations ) , zero otherwise .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
Let denote r as a rank in the returned face-track list , Pre( r ) as is the precision at the rank r of the list , Nl as the length of the list , Nhit as the total number of face-tracks matched with the query face-track q , and I sMatched( k ) as a binary function returning 1 if the face-track at rank r is matched with q ( based on ground-truth annotations ) , zero otherwise .
#<struct ReadData::Alignment source_numbers="28", target_numbers="", tag_name="wa">
Let denote r as a rank in the returned face-track list , Pre( r ) as is the precision at the rank r of the list , Nl as the length of the list , Nhit as the total number of face-tracks matched with the query face-track q , and I sMatched( k ) as a binary function returning 1 if the face-track at rank r is matched with q ( based on ground-truth annotations ) , zero otherwise .
#<struct ReadData::Alignment source_numbers="36", target_numbers="", tag_name="wa">
Let denote r as a rank in the returned face-track list , Pre( r ) as is the precision at the rank r of the list , Nl as the length of the list , Nhit as the total number of face-tracks matched with the query face-track q , and I sMatched( k ) as a binary function returning 1 if the face-track at rank r is matched with q ( based on ground-truth annotations ) , zero otherwise .
#<struct ReadData::Alignment source_numbers="41", target_numbers="", tag_name="wa">
Let denote r as a rank in the returned face-track list , Pre( r ) as is the precision at the rank r of the list , Nl as the length of the list , Nhit as the total number of face-tracks matched with the query face-track q , and I sMatched( k ) as a binary function returning 1 if the face-track at rank r is matched with q ( based on ground-truth annotations ) , zero otherwise .
#<struct ReadData::Alignment source_numbers="46", target_numbers="", tag_name="wa">
Let denote r as a rank in the returned face-track list , Pre( r ) as is the precision at the rank r of the list , Nl as the length of the list , Nhit as the total number of face-tracks matched with the query face-track q , and I sMatched( k ) as a binary function returning 1 if the face-track at rank r is matched with q ( based on ground-truth annotations ) , zero otherwise .
#<struct ReadData::Alignment source_numbers="54", target_numbers="", tag_name="wa">
Let denote r as a rank in the returned face-track list , Pre( r ) as is the precision at the rank r of the list , Nl as the length of the list , Nhit as the total number of face-tracks matched with the query face-track q , and I sMatched( k ) as a binary function returning 1 if the face-track at rank r is matched with q ( based on ground-truth annotations ) , zero otherwise .
#<struct ReadData::Alignment source_numbers="62", target_numbers="", tag_name="wa">
Let denote r as a rank in the returned face-track list , Pre( r ) as is the precision at the rank r of the list , Nl as the length of the list , Nhit as the total number of face-tracks matched with the query face-track q , and I sMatched( k ) as a binary function returning 1 if the face-track at rank r is matched with q ( based on ground-truth annotations ) , zero otherwise .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
Let denote r as a rank in the returned face-track list , Pre( r ) as is the precision at the rank r of the list , Nl as the length of the list , Nhit as the total number of face-tracks matched with the query face-track q , and I sMatched( k ) as a binary function returning 1 if the face-track at rank r is matched with q ( based on ground-truth annotations ) , zero otherwise .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
Let denote r as a rank in the returned face-track list , Pre( r ) as is the precision at the rank r of the list , Nl as the length of the list , Nhit as the total number of face-tracks matched with the query face-track q , and I sMatched( k ) as a binary function returning 1 if the face-track at rank r is matched with q ( based on ground-truth annotations ) , zero otherwise .
#<struct ReadData::Alignment source_numbers="", target_numbers="41", tag_name="wa">
Let denote r as a rank in the returned face-track list , Pre( r ) as is the precision at the rank r of the list , Nl as the length of the list , Nhit as the total number of face-tracks matched with the query face-track q , and I sMatched( k ) as a binary function returning 1 if the face-track at rank r is matched with q ( based on ground-truth annotations ) , zero otherwise .
#<struct ReadData::Alignment source_numbers="", target_numbers="42", tag_name="wa">
Let denote r as a rank in the returned face-track list , Pre( r ) as is the precision at the rank r of the list , Nl as the length of the list , Nhit as the total number of face-tracks matched with the query face-track q , and I sMatched( k ) as a binary function returning 1 if the face-track at rank r is matched with q ( based on ground-truth annotations ) , zero otherwise .
#<struct ReadData::Alignment source_numbers="", target_numbers="57", tag_name="wa">
Let denote r as a rank in the returned face-track list , Pre( r ) as is the precision at the rank r of the list , Nl as the length of the list , Nhit as the total number of face-tracks matched with the query face-track q , and I sMatched( k ) as a binary function returning 1 if the face-track at rank r is matched with q ( based on ground-truth annotations ) , zero otherwise .
#<struct ReadData::Alignment source_numbers="", target_numbers="58", tag_name="wa">
Let denote r as a rank in the returned face-track list , Pre( r ) as is the precision at the rank r of the list , Nl as the length of the list , Nhit as the total number of face-tracks matched with the query face-track q , and I sMatched( k ) as a binary function returning 1 if the face-track at rank r is matched with q ( based on ground-truth annotations ) , zero otherwise .
#<struct ReadData::Alignment source_numbers="", target_numbers="72", tag_name="wa">
Then , the MAP of the evaluated approach can be computed as following: \MATH
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
Then , the MAP of the evaluated approach can be computed as following: \MATH
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
Besides MAP , we record processing times of the approaches on each dataset for efficiency comparison.
#<struct ReadData::Alignment source_numbers="10,11", target_numbers="12,13", tag_name="wa">
Besides MAP , we record processing times of the approaches on each dataset for efficiency comparison.
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
Besides MAP , we record processing times of the approaches on each dataset for efficiency comparison.
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
Besides MAP , we record processing times of the approaches on each dataset for efficiency comparison.
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
Besides MAP , we record processing times of the approaches on each dataset for efficiency comparison.
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Besides MAP , we record processing times of the approaches on each dataset for efficiency comparison.
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Besides MAP , we record processing times of the approaches on each dataset for efficiency comparison.
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
Besides MAP , we record processing times of the approaches on each dataset for efficiency comparison.
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
Besides MAP , we record processing times of the approaches on each dataset for efficiency comparison.
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Besides MAP , we record processing times of the approaches on each dataset for efficiency comparison.
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
Figure 7 presents Mean Average Precision ( MAP ) of all evaluated approaches on our two datasets , Trecvid and NHKNews7 .
#<struct ReadData::Alignment source_numbers="12,13", target_numbers="14,15", tag_name="wa">
Figure 7 presents Mean Average Precision ( MAP ) of all evaluated approaches on our two datasets , Trecvid and NHKNews7 .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
Figure 7 presents Mean Average Precision ( MAP ) of all evaluated approaches on our two datasets , Trecvid and NHKNews7 .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
Figure 7 presents Mean Average Precision ( MAP ) of all evaluated approaches on our two datasets , Trecvid and NHKNews7 .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Figure 7 presents Mean Average Precision ( MAP ) of all evaluated approaches on our two datasets , Trecvid and NHKNews7 .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Figure 7 presents Mean Average Precision ( MAP ) of all evaluated approaches on our two datasets , Trecvid and NHKNews7 .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Figure 7 presents Mean Average Precision ( MAP ) of all evaluated approaches on our two datasets , Trecvid and NHKNews7 .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Generally , all MAPs vary from 64.61% to 76.54% on Trecvid dataset .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Generally , all MAPs vary from 64.61% to 76.54% on Trecvid dataset .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Meanwhile , , the best MAP is 60.99% , and the worst MAP is 42.75% on NHKNews7 dataset .
#<struct ReadData::Alignment source_numbers="10", target_numbers="3", tag_name="wa">
Meanwhile , , the best MAP is 60.99% , and the worst MAP is 42.75% on NHKNews7 dataset .
#<struct ReadData::Alignment source_numbers="2", target_numbers="6", tag_name="wa">
Meanwhile , , the best MAP is 60.99% , and the worst MAP is 42.75% on NHKNews7 dataset .
#<struct ReadData::Alignment source_numbers="8", target_numbers="12", tag_name="wa">
Meanwhile , , the best MAP is 60.99% , and the worst MAP is 42.75% on NHKNews7 dataset .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
Meanwhile , , the best MAP is 60.99% , and the worst MAP is 42.75% on NHKNews7 dataset .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
The gap of MAPs between two datasets can be explained by following reasons .
#<struct ReadData::Alignment source_numbers="1", target_numbers="1,2,3", tag_name="wa">
The gap of MAPs between two datasets can be explained by following reasons .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Firstly , the number of characters in NHKNews7 is more larger than those in Trecvid , 111 characters in NHKNews7 compared to 41 characters in Trecvid .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Firstly , the number of characters in NHKNews7 is more larger than those in Trecvid , 111 characters in NHKNews7 compared to 41 characters in Trecvid .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
Firstly , the number of characters in NHKNews7 is more larger than those in Trecvid , 111 characters in NHKNews7 compared to 41 characters in Trecvid .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
This clearly increases the probability of mismatching face-tracks .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
This clearly increases the probability of mismatching face-tracks .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
This clearly increases the probability of mismatching face-tracks .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Secondly , videos in NHKNews7 are recorded during a long time ( i.e. , 11 years ) .
#<struct ReadData::Alignment source_numbers="5", target_numbers="6", tag_name="wa">
Secondly , videos in NHKNews7 are recorded during a long time ( i.e. , 11 years ) .
#<struct ReadData::Alignment source_numbers="6", target_numbers="7", tag_name="wa">
Secondly , videos in NHKNews7 are recorded during a long time ( i.e. , 11 years ) .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Secondly , videos in NHKNews7 are recorded during a long time ( i.e. , 11 years ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Thus , besides facial variations caused by enviromental conditions at the time of recording ( e.g. , illumination , pose , viewpoint ) in each face-track , face-tracks of a character themself also contain biological variation of the character during time .
#<struct ReadData::Alignment source_numbers="37", target_numbers="11", tag_name="wa">
Thus , besides facial variations caused by enviromental conditions at the time of recording ( e.g. , illumination , pose , viewpoint ) in each face-track , face-tracks of a character themself also contain biological variation of the character during time .
#<struct ReadData::Alignment source_numbers="26", target_numbers="28", tag_name="wa">
Thus , besides facial variations caused by enviromental conditions at the time of recording ( e.g. , illumination , pose , viewpoint ) in each face-track , face-tracks of a character themself also contain biological variation of the character during time .
#<struct ReadData::Alignment source_numbers="41", target_numbers="46", tag_name="wa">
Thus , besides facial variations caused by enviromental conditions at the time of recording ( e.g. , illumination , pose , viewpoint ) in each face-track , face-tracks of a character themself also contain biological variation of the character during time .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Thus , besides facial variations caused by enviromental conditions at the time of recording ( e.g. , illumination , pose , viewpoint ) in each face-track , face-tracks of a character themself also contain biological variation of the character during time .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
Thus , besides facial variations caused by enviromental conditions at the time of recording ( e.g. , illumination , pose , viewpoint ) in each face-track , face-tracks of a character themself also contain biological variation of the character during time .
#<struct ReadData::Alignment source_numbers="27", target_numbers="", tag_name="wa">
Thus , besides facial variations caused by enviromental conditions at the time of recording ( e.g. , illumination , pose , viewpoint ) in each face-track , face-tracks of a character themself also contain biological variation of the character during time .
#<struct ReadData::Alignment source_numbers="29", target_numbers="", tag_name="wa">
Thus , besides facial variations caused by enviromental conditions at the time of recording ( e.g. , illumination , pose , viewpoint ) in each face-track , face-tracks of a character themself also contain biological variation of the character during time .
#<struct ReadData::Alignment source_numbers="31", target_numbers="", tag_name="wa">
Thus , besides facial variations caused by enviromental conditions at the time of recording ( e.g. , illumination , pose , viewpoint ) in each face-track , face-tracks of a character themself also contain biological variation of the character during time .
#<struct ReadData::Alignment source_numbers="33", target_numbers="", tag_name="wa">
Thus , besides facial variations caused by enviromental conditions at the time of recording ( e.g. , illumination , pose , viewpoint ) in each face-track , face-tracks of a character themself also contain biological variation of the character during time .
#<struct ReadData::Alignment source_numbers="39", target_numbers="", tag_name="wa">
Thus , besides facial variations caused by enviromental conditions at the time of recording ( e.g. , illumination , pose , viewpoint ) in each face-track , face-tracks of a character themself also contain biological variation of the character during time .
#<struct ReadData::Alignment source_numbers="40", target_numbers="", tag_name="wa">
Thus , besides facial variations caused by enviromental conditions at the time of recording ( e.g. , illumination , pose , viewpoint ) in each face-track , face-tracks of a character themself also contain biological variation of the character during time .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Thus , besides facial variations caused by enviromental conditions at the time of recording ( e.g. , illumination , pose , viewpoint ) in each face-track , face-tracks of a character themself also contain biological variation of the character during time .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Thus , besides facial variations caused by enviromental conditions at the time of recording ( e.g. , illumination , pose , viewpoint ) in each face-track , face-tracks of a character themself also contain biological variation of the character during time .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
Thus , besides facial variations caused by enviromental conditions at the time of recording ( e.g. , illumination , pose , viewpoint ) in each face-track , face-tracks of a character themself also contain biological variation of the character during time .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
Thus , besides facial variations caused by enviromental conditions at the time of recording ( e.g. , illumination , pose , viewpoint ) in each face-track , face-tracks of a character themself also contain biological variation of the character during time .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
Thus , besides facial variations caused by enviromental conditions at the time of recording ( e.g. , illumination , pose , viewpoint ) in each face-track , face-tracks of a character themself also contain biological variation of the character during time .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
Thus , besides facial variations caused by enviromental conditions at the time of recording ( e.g. , illumination , pose , viewpoint ) in each face-track , face-tracks of a character themself also contain biological variation of the character during time .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
Thus , besides facial variations caused by enviromental conditions at the time of recording ( e.g. , illumination , pose , viewpoint ) in each face-track , face-tracks of a character themself also contain biological variation of the character during time .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
Thus , besides facial variations caused by enviromental conditions at the time of recording ( e.g. , illumination , pose , viewpoint ) in each face-track , face-tracks of a character themself also contain biological variation of the character during time .
#<struct ReadData::Alignment source_numbers="", target_numbers="42", tag_name="wa">
Thus , besides facial variations caused by enviromental conditions at the time of recording ( e.g. , illumination , pose , viewpoint ) in each face-track , face-tracks of a character themself also contain biological variation of the character during time .
#<struct ReadData::Alignment source_numbers="", target_numbers="44", tag_name="wa">
Thus , besides facial variations caused by enviromental conditions at the time of recording ( e.g. , illumination , pose , viewpoint ) in each face-track , face-tracks of a character themself also contain biological variation of the character during time .
#<struct ReadData::Alignment source_numbers="", target_numbers="45", tag_name="wa">
For instance , a character may look older after several years ( see Figure 8 , for example ) .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
For instance , a character may look older after several years ( see Figure 8 , for example ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Due to those reasons , matching faces in NHKNews7 becomes more challenging , .
#<struct ReadData::Alignment source_numbers="2,3", target_numbers="1,2", tag_name="wa">
Due to those reasons , matching faces in NHKNews7 becomes more challenging , .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Due to those reasons , matching faces in NHKNews7 becomes more challenging , .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Due to those reasons , matching faces in NHKNews7 becomes more challenging , .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Due to those reasons , matching faces in NHKNews7 becomes more challenging , .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
It results in drops of MAP( s ) of all evaluated approaches.
#<struct ReadData::Alignment source_numbers="1", target_numbers="0", tag_name="wa">
It results in drops of MAP( s ) of all evaluated approaches.
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
It results in drops of MAP( s ) of all evaluated approaches.
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
It results in drops of MAP( s ) of all evaluated approaches.
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
It results in drops of MAP( s ) of all evaluated approaches.
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
It results in drops of MAP( s ) of all evaluated approaches.
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
It results in drops of MAP( s ) of all evaluated approaches.
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
It results in drops of MAP( s ) of all evaluated approaches.
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
A clear and consistent observation from both datasets is that pair:min ( i.e. , min-min ) always achieves the best MAPs , which are 76.54% and 60.99% on two dataset , respectively .
#<struct ReadData::Alignment source_numbers="27", target_numbers="", tag_name="wa">
A clear and consistent observation from both datasets is that pair:min ( i.e. , min-min ) always achieves the best MAPs , which are 76.54% and 60.99% on two dataset , respectively .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
Among several distance types , L1 is the optimal one to be used with pair:min .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Among several distance types , L1 is the optimal one to be used with pair:min .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
However , there is a minor accuracy gap between pair:min using L1 and pair:min using Euclidean .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
And , computing Euclidean distance between two feature vectors is more expensive than computing their L1 distance .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
And , computing Euclidean distance between two feature vectors is more expensive than computing their L1 distance .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
And , computing Euclidean distance between two feature vectors is more expensive than computing their L1 distance .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
This is because pair:mean uses the mean of all pair-wise distances between two face-tracks as their similarity score .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
This is because pair:mean uses the mean of all pair-wise distances between two face-tracks as their similarity score .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
This is because pair:mean uses the mean of all pair-wise distances between two face-tracks as their similarity score .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
This is because pair:mean uses the mean of all pair-wise distances between two face-tracks as their similarity score .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
This is because pair:mean uses the mean of all pair-wise distances between two face-tracks as their similarity score .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
At the same time , it eliminates the influence of pairs containing identical faces , which can help to instantly determine they are belong to the same character .
#<struct ReadData::Alignment source_numbers="25", target_numbers="22", tag_name="wa">
At the same time , it eliminates the influence of pairs containing identical faces , which can help to instantly determine they are belong to the same character .
#<struct ReadData::Alignment source_numbers="23", target_numbers="24", tag_name="wa">
At the same time , it eliminates the influence of pairs containing identical faces , which can help to instantly determine they are belong to the same character .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
At the same time , it eliminates the influence of pairs containing identical faces , which can help to instantly determine they are belong to the same character .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
At the same time , it eliminates the influence of pairs containing identical faces , which can help to instantly determine they are belong to the same character .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
At the same time , it eliminates the influence of pairs containing identical faces , which can help to instantly determine they are belong to the same character .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
At the same time , it eliminates the influence of pairs containing identical faces , which can help to instantly determine they are belong to the same character .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
Thus , discriminative power of the computed similarity score is reduced , compared to one computed by pair:min .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
Thus , discriminative power of the computed similarity score is reduced , compared to one computed by pair:min .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
It causes the gap of MAPs between pair:min and pair:min .
#<struct ReadData::Alignment source_numbers="3", target_numbers="3,4", tag_name="wa">
It causes the gap of MAPs between pair:min and pair:min .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
It causes the gap of MAPs between pair:min and pair:min .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
It causes the gap of MAPs between pair:min and pair:min .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
More generally , this explains why such a gap between pair:min and pair:mean on NHKNews7 is larger than on Trecvid .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
More generally , this explains why such a gap between pair:min and pair:mean on NHKNews7 is larger than on Trecvid .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
More generally , this explains why such a gap between pair:min and pair:mean on NHKNews7 is larger than on Trecvid .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
More generally , this explains why such a gap between pair:min and pair:mean on NHKNews7 is larger than on Trecvid .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
Since the average length of face-tracks on NHKNews7 is longer ( i.e. , each face-track contains more sample faces of a character ) , there is more chance that two face-tracks of the same character contain identical faces.
#<struct ReadData::Alignment source_numbers="25,26", target_numbers="27,28,29", tag_name="wa">
Since the average length of face-tracks on NHKNews7 is longer ( i.e. , each face-track contains more sample faces of a character ) , there is more chance that two face-tracks of the same character contain identical faces.
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Since the average length of face-tracks on NHKNews7 is longer ( i.e. , each face-track contains more sample faces of a character ) , there is more chance that two face-tracks of the same character contain identical faces.
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Since the average length of face-tracks on NHKNews7 is longer ( i.e. , each face-track contains more sample faces of a character ) , there is more chance that two face-tracks of the same character contain identical faces.
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
Since the average length of face-tracks on NHKNews7 is longer ( i.e. , each face-track contains more sample faces of a character ) , there is more chance that two face-tracks of the same character contain identical faces.
#<struct ReadData::Alignment source_numbers="30", target_numbers="", tag_name="wa">
Since the average length of face-tracks on NHKNews7 is longer ( i.e. , each face-track contains more sample faces of a character ) , there is more chance that two face-tracks of the same character contain identical faces.
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Since the average length of face-tracks on NHKNews7 is longer ( i.e. , each face-track contains more sample faces of a character ) , there is more chance that two face-tracks of the same character contain identical faces.
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Since the average length of face-tracks on NHKNews7 is longer ( i.e. , each face-track contains more sample faces of a character ) , there is more chance that two face-tracks of the same character contain identical faces.
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Since the average length of face-tracks on NHKNews7 is longer ( i.e. , each face-track contains more sample faces of a character ) , there is more chance that two face-tracks of the same character contain identical faces.
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
Since the average length of face-tracks on NHKNews7 is longer ( i.e. , each face-track contains more sample faces of a character ) , there is more chance that two face-tracks of the same character contain identical faces.
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
Since the average length of face-tracks on NHKNews7 is longer ( i.e. , each face-track contains more sample faces of a character ) , there is more chance that two face-tracks of the same character contain identical faces.
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
Since the average length of face-tracks on NHKNews7 is longer ( i.e. , each face-track contains more sample faces of a character ) , there is more chance that two face-tracks of the same character contain identical faces.
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
About our k-Faces , its MAP increases when k increases .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
About our k-Faces , its MAP increases when k increases .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Since k-Faces.KMeans always use all faces in a facetrack for clustering and selecting centroids for representative faces , the final mean face is less sensitive to k .
#<struct ReadData::Alignment source_numbers="21", target_numbers="9", tag_name="wa">
Since k-Faces.KMeans always use all faces in a facetrack for clustering and selecting centroids for representative faces , the final mean face is less sensitive to k .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Since k-Faces.KMeans always use all faces in a facetrack for clustering and selecting centroids for representative faces , the final mean face is less sensitive to k .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Since k-Faces.KMeans always use all faces in a facetrack for clustering and selecting centroids for representative faces , the final mean face is less sensitive to k .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Since k-Faces.KMeans always use all faces in a facetrack for clustering and selecting centroids for representative faces , the final mean face is less sensitive to k .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Since k-Faces.KMeans always use all faces in a facetrack for clustering and selecting centroids for representative faces , the final mean face is less sensitive to k .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
On the contrary , k plays an important role in k-Faces.Temporal .
#<struct ReadData::Alignment source_numbers="1,2", target_numbers="1", tag_name="wa">
On the contrary , k plays an important role in k-Faces.Temporal .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
On the contrary , k plays an important role in k-Faces.Temporal .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
The higher k is set , the more representative faces of each facetrack are selected .
#<struct ReadData::Alignment source_numbers="4", target_numbers="4", tag_name="wa">
The higher k is set , the more representative faces of each facetrack are selected .
#<struct ReadData::Alignment source_numbers="14", target_numbers="14", tag_name="wa">
The higher k is set , the more representative faces of each facetrack are selected .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
The higher k is set , the more representative faces of each facetrack are selected .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
The higher k is set , the more representative faces of each facetrack are selected .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
The higher k is set , the more representative faces of each facetrack are selected .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
The higher k is set , the more representative faces of each facetrack are selected .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Thus , the final mean face of each facetrack becomes more reliable and accurate .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Thus , the final mean face of each facetrack becomes more reliable and accurate .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Thus , the final mean face of each facetrack becomes more reliable and accurate .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Meanwhile , its disadvantage is the expensive computational cost to perform clustering faces on a high dimensional feature space ( i.e. , 1937 dimensions ) .
#<struct ReadData::Alignment source_numbers="15", target_numbers="6", tag_name="wa">
Meanwhile , its disadvantage is the expensive computational cost to perform clustering faces on a high dimensional feature space ( i.e. , 1937 dimensions ) .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Meanwhile , its disadvantage is the expensive computational cost to perform clustering faces on a high dimensional feature space ( i.e. , 1937 dimensions ) .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
Meanwhile , its disadvantage is the expensive computational cost to perform clustering faces on a high dimensional feature space ( i.e. , 1937 dimensions ) .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Meanwhile , its disadvantage is the expensive computational cost to perform clustering faces on a high dimensional feature space ( i.e. , 1937 dimensions ) .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Meanwhile , its disadvantage is the expensive computational cost to perform clustering faces on a high dimensional feature space ( i.e. , 1937 dimensions ) .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
Meanwhile , its disadvantage is the expensive computational cost to perform clustering faces on a high dimensional feature space ( i.e. , 1937 dimensions ) .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
Meanwhile , its disadvantage is the expensive computational cost to perform clustering faces on a high dimensional feature space ( i.e. , 1937 dimensions ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Meanwhile , its disadvantage is the expensive computational cost to perform clustering faces on a high dimensional feature space ( i.e. , 1937 dimensions ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Meanwhile , its disadvantage is the expensive computational cost to perform clustering faces on a high dimensional feature space ( i.e. , 1937 dimensions ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Meanwhile , its disadvantage is the expensive computational cost to perform clustering faces on a high dimensional feature space ( i.e. , 1937 dimensions ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
On both datasets , when k increases from 2 to 20 , MAPs of k-Faces approaches grow rapidly .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
On both datasets , when k increases from 2 to 20 , MAPs of k-Faces approaches grow rapidly .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
However , theirs MAPs become stable from 20 afterwards .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
However , theirs MAPs become stable from 20 afterwards .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
However , theirs MAPs become stable from 20 afterwards .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
However , theirs MAPs become stable from 20 afterwards .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
However , theirs MAPs become stable from 20 afterwards .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
However , theirs MAPs become stable from 20 afterwards .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Since keep increasing k does not help to obtain imporant accuracy improvement but expensive computational cost , we select k = 20 to investigate the trade-off between accuracy and computational costs of k-Faces approaches compared to others .
#<struct ReadData::Alignment source_numbers="2", target_numbers="2", tag_name="wa">
Since keep increasing k does not help to obtain imporant accuracy improvement but expensive computational cost , we select k = 20 to investigate the trade-off between accuracy and computational costs of k-Faces approaches compared to others .
#<struct ReadData::Alignment source_numbers="10", target_numbers="8", tag_name="wa">
Since keep increasing k does not help to obtain imporant accuracy improvement but expensive computational cost , we select k = 20 to investigate the trade-off between accuracy and computational costs of k-Faces approaches compared to others .
#<struct ReadData::Alignment source_numbers="24", target_numbers="11", tag_name="wa">
Since keep increasing k does not help to obtain imporant accuracy improvement but expensive computational cost , we select k = 20 to investigate the trade-off between accuracy and computational costs of k-Faces approaches compared to others .
#<struct ReadData::Alignment source_numbers="23", target_numbers="21,22", tag_name="wa">
Since keep increasing k does not help to obtain imporant accuracy improvement but expensive computational cost , we select k = 20 to investigate the trade-off between accuracy and computational costs of k-Faces approaches compared to others .
#<struct ReadData::Alignment source_numbers="30,31", target_numbers="29,30", tag_name="wa">
Since keep increasing k does not help to obtain imporant accuracy improvement but expensive computational cost , we select k = 20 to investigate the trade-off between accuracy and computational costs of k-Faces approaches compared to others .
#<struct ReadData::Alignment source_numbers="34,35", target_numbers="33,34,35", tag_name="wa">
Since keep increasing k does not help to obtain imporant accuracy improvement but expensive computational cost , we select k = 20 to investigate the trade-off between accuracy and computational costs of k-Faces approaches compared to others .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Since keep increasing k does not help to obtain imporant accuracy improvement but expensive computational cost , we select k = 20 to investigate the trade-off between accuracy and computational costs of k-Faces approaches compared to others .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Since keep increasing k does not help to obtain imporant accuracy improvement but expensive computational cost , we select k = 20 to investigate the trade-off between accuracy and computational costs of k-Faces approaches compared to others .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Since keep increasing k does not help to obtain imporant accuracy improvement but expensive computational cost , we select k = 20 to investigate the trade-off between accuracy and computational costs of k-Faces approaches compared to others .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Since keep increasing k does not help to obtain imporant accuracy improvement but expensive computational cost , we select k = 20 to investigate the trade-off between accuracy and computational costs of k-Faces approaches compared to others .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Since keep increasing k does not help to obtain imporant accuracy improvement but expensive computational cost , we select k = 20 to investigate the trade-off between accuracy and computational costs of k-Faces approaches compared to others .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
Since keep increasing k does not help to obtain imporant accuracy improvement but expensive computational cost , we select k = 20 to investigate the trade-off between accuracy and computational costs of k-Faces approaches compared to others .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
Since keep increasing k does not help to obtain imporant accuracy improvement but expensive computational cost , we select k = 20 to investigate the trade-off between accuracy and computational costs of k-Faces approaches compared to others .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
Since keep increasing k does not help to obtain imporant accuracy improvement but expensive computational cost , we select k = 20 to investigate the trade-off between accuracy and computational costs of k-Faces approaches compared to others .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Since keep increasing k does not help to obtain imporant accuracy improvement but expensive computational cost , we select k = 20 to investigate the trade-off between accuracy and computational costs of k-Faces approaches compared to others .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Since keep increasing k does not help to obtain imporant accuracy improvement but expensive computational cost , we select k = 20 to investigate the trade-off between accuracy and computational costs of k-Faces approaches compared to others .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Since keep increasing k does not help to obtain imporant accuracy improvement but expensive computational cost , we select k = 20 to investigate the trade-off between accuracy and computational costs of k-Faces approaches compared to others .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Since keep increasing k does not help to obtain imporant accuracy improvement but expensive computational cost , we select k = 20 to investigate the trade-off between accuracy and computational costs of k-Faces approaches compared to others .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
Since keep increasing k does not help to obtain imporant accuracy improvement but expensive computational cost , we select k = 20 to investigate the trade-off between accuracy and computational costs of k-Faces approaches compared to others .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
We report MAP and processing time of each approach in the Table 5 .
#<struct ReadData::Alignment source_numbers="10", target_numbers="3", tag_name="wa">
We report MAP and processing time of each approach in the Table 5 .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
We report MAP and processing time of each approach in the Table 5 .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
We report MAP and processing time of each approach in the Table 5 .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
We report MAP and processing time of each approach in the Table 5 .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Processing time is separated into two parts , corresponding to preprocessing time and matching time .
#<struct ReadData::Alignment source_numbers="15", target_numbers="11", tag_name="wa">
Processing time is separated into two parts , corresponding to preprocessing time and matching time .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Processing time is separated into two parts , corresponding to preprocessing time and matching time .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Processing time is separated into two parts , corresponding to preprocessing time and matching time .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
Processing time is separated into two parts , corresponding to preprocessing time and matching time .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
Preprocessing time presents time required for preprocessing face-tracks before matching .
#<struct ReadData::Alignment source_numbers="6", target_numbers="1", tag_name="wa">
Preprocessing time presents time required for preprocessing face-tracks before matching .
#<struct ReadData::Alignment source_numbers="2", target_numbers="10", tag_name="wa">
Preprocessing time presents time required for preprocessing face-tracks before matching .
#<struct ReadData::Alignment source_numbers="10", target_numbers="14", tag_name="wa">
Preprocessing time presents time required for preprocessing face-tracks before matching .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Preprocessing time presents time required for preprocessing face-tracks before matching .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Preprocessing time presents time required for preprocessing face-tracks before matching .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Preprocessing time presents time required for preprocessing face-tracks before matching .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Preprocessing time presents time required for preprocessing face-tracks before matching .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Preprocessing time presents time required for preprocessing face-tracks before matching .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Preprocessing time presents time required for preprocessing face-tracks before matching .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Preprocessing time presents time required for preprocessing face-tracks before matching .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
With k-Faces approaches , preprocessing facetracks includes selecting representative faces and computing their mean face .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
With k-Faces approaches , preprocessing facetracks includes selecting representative faces and computing their mean face .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
With k-Faces approaches , preprocessing facetracks includes selecting representative faces and computing their mean face .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
With k-Faces approaches , preprocessing facetracks includes selecting representative faces and computing their mean face .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
With k-Faces approaches , preprocessing facetracks includes selecting representative faces and computing their mean face .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
In MSM and CMSM , it indicates time for computing subspaces for face-tracks .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
In MSM and CMSM , it indicates time for computing subspaces for face-tracks .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
In MSM and CMSM , it indicates time for computing subspaces for face-tracks .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
In MSM and CMSM , it indicates time for computing subspaces for face-tracks .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
In MSM and CMSM , it indicates time for computing subspaces for face-tracks .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
In MSM and CMSM , it indicates time for computing subspaces for face-tracks .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
In MSM and CMSM , it indicates time for computing subspaces for face-tracks .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
In MSM and CMSM , it indicates time for computing subspaces for face-tracks .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
In MSM and CMSM , it indicates time for computing subspaces for face-tracks .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
Matching time is averaged for one query run .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Matching time is averaged for one query run .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
Matching time is averaged for one query run .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Matching time is averaged for one query run .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Time unit is second.
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Time unit is second.
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
Time unit is second.
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Time unit is second.
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Time unit is second.
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
According to Table 5 , k-Faces.KMeans and k- Faces.Temporal achieve almost equal accuracy and consume the same amount of time for one query on both datasets .
#<struct ReadData::Alignment source_numbers="23,24", target_numbers="24,25", tag_name="wa">
According to Table 5 , k-Faces.KMeans and k- Faces.Temporal achieve almost equal accuracy and consume the same amount of time for one query on both datasets .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
According to Table 5 , k-Faces.KMeans and k- Faces.Temporal achieve almost equal accuracy and consume the same amount of time for one query on both datasets .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
According to Table 5 , k-Faces.KMeans and k- Faces.Temporal achieve almost equal accuracy and consume the same amount of time for one query on both datasets .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
According to Table 5 , k-Faces.KMeans and k- Faces.Temporal achieve almost equal accuracy and consume the same amount of time for one query on both datasets .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
According to Table 5 , k-Faces.KMeans and k- Faces.Temporal achieve almost equal accuracy and consume the same amount of time for one query on both datasets .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
However , k-Faces.Temporal is hundreds times ( 240 times on Trecvid and 360 times on NHKNews7 ) faster than k-Faces.Temporal in the preprocessing phase .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
However , k-Faces.Temporal is hundreds times ( 240 times on Trecvid and 360 times on NHKNews7 ) faster than k-Faces.Temporal in the preprocessing phase .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
However , k-Faces.Temporal is hundreds times ( 240 times on Trecvid and 360 times on NHKNews7 ) faster than k-Faces.Temporal in the preprocessing phase .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
However , k-Faces.Temporal is hundreds times ( 240 times on Trecvid and 360 times on NHKNews7 ) faster than k-Faces.Temporal in the preprocessing phase .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
However , k-Faces.Temporal is hundreds times ( 240 times on Trecvid and 360 times on NHKNews7 ) faster than k-Faces.Temporal in the preprocessing phase .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
This suggest that , selecting presentative faces based on tempo .
#<struct ReadData::Alignment source_numbers="1,2", target_numbers="1,2,3", tag_name="wa">
This suggest that , selecting presentative faces based on tempo .
#<struct ReadData::Alignment source_numbers="3", target_numbers="10", tag_name="wa">
This suggest that , selecting presentative faces based on tempo .
#<struct ReadData::Alignment source_numbers="4", target_numbers="11", tag_name="wa">
This suggest that , selecting presentative faces based on tempo .
#<struct ReadData::Alignment source_numbers="6", target_numbers="13", tag_name="wa">
This suggest that , selecting presentative faces based on tempo .
#<struct ReadData::Alignment source_numbers="7", target_numbers="14", tag_name="wa">
This suggest that , selecting presentative faces based on tempo .
#<struct ReadData::Alignment source_numbers="8", target_numbers="15", tag_name="wa">
This suggest that , selecting presentative faces based on tempo .
#<struct ReadData::Alignment source_numbers="10", target_numbers="25", tag_name="wa">
This suggest that , selecting presentative faces based on tempo .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
This suggest that , selecting presentative faces based on tempo .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
This suggest that , selecting presentative faces based on tempo .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
This suggest that , selecting presentative faces based on tempo .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
This suggest that , selecting presentative faces based on tempo .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
This suggest that , selecting presentative faces based on tempo .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
This suggest that , selecting presentative faces based on tempo .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
This suggest that , selecting presentative faces based on tempo .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
This suggest that , selecting presentative faces based on tempo .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
This suggest that , selecting presentative faces based on tempo .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
This suggest that , selecting presentative faces based on tempo .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
This suggest that , selecting presentative faces based on tempo .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
This suggest that , selecting presentative faces based on tempo .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
This suggest that , selecting presentative faces based on tempo .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
This suggest that , selecting presentative faces based on tempo .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
This suggest that , selecting presentative faces based on tempo .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
This suggest that , selecting presentative faces based on tempo .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
This suggest that , selecting presentative faces based on tempo .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
ral sampling is better than one based on clustering , in both terms of accuracy and efficiency.
#<struct ReadData::Alignment source_numbers="9", target_numbers="0", tag_name="wa">
ral sampling is better than one based on clustering , in both terms of accuracy and efficiency.
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
ral sampling is better than one based on clustering , in both terms of accuracy and efficiency.
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
ral sampling is better than one based on clustering , in both terms of accuracy and efficiency.
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
ral sampling is better than one based on clustering , in both terms of accuracy and efficiency.
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
ral sampling is better than one based on clustering , in both terms of accuracy and efficiency.
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
ral sampling is better than one based on clustering , in both terms of accuracy and efficiency.
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
ral sampling is better than one based on clustering , in both terms of accuracy and efficiency.
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
ral sampling is better than one based on clustering , in both terms of accuracy and efficiency.
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
ral sampling is better than one based on clustering , in both terms of accuracy and efficiency.
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
ral sampling is better than one based on clustering , in both terms of accuracy and efficiency.
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
ral sampling is better than one based on clustering , in both terms of accuracy and efficiency.
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
ral sampling is better than one based on clustering , in both terms of accuracy and efficiency.
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
ral sampling is better than one based on clustering , in both terms of accuracy and efficiency.
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
ral sampling is better than one based on clustering , in both terms of accuracy and efficiency.
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
ral sampling is better than one based on clustering , in both terms of accuracy and efficiency.
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
ral sampling is better than one based on clustering , in both terms of accuracy and efficiency.
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
Compared to state-of-the-art approaches , our k- Faces.Temporal is thousands times faster than the best approach , which is pair:min , and hundred times faster than MSM and CMSM on both datasets .
#<struct ReadData::Alignment source_numbers="22", target_numbers="23,24", tag_name="wa">
Compared to state-of-the-art approaches , our k- Faces.Temporal is thousands times faster than the best approach , which is pair:min , and hundred times faster than MSM and CMSM on both datasets .
#<struct ReadData::Alignment source_numbers="29,30", target_numbers="31,32", tag_name="wa">
In terms of accuracy , k-Faces take second place , with 73.65% on Trevid dataset , after pair:min .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
In terms of accuracy , k-Faces take second place , with 73.65% on Trevid dataset , after pair:min .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
The gap with pair:min is 2.89% difference in MAP .
#<struct ReadData::Alignment source_numbers="0", target_numbers="0", tag_name="wa">
The gap with pair:min is 2.89% difference in MAP .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
The gap with pair:min is 2.89% difference in MAP .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
The gap with pair:min is 2.89% difference in MAP .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
The gap with pair:min is 2.89% difference in MAP .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
The gap with pair:min is 2.89% difference in MAP .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
The gap with pair:min is 2.89% difference in MAP .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Meanwhile , it is significantly better than MSM and CMSM , which respectively achieve 69.20% and 64.62% .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Meanwhile , it is significantly better than MSM and CMSM , which respectively achieve 69.20% and 64.62% .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Meanwhile , it is significantly better than MSM and CMSM , which respectively achieve 69.20% and 64.62% .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Meanwhile , it is significantly better than MSM and CMSM , which respectively achieve 69.20% and 64.62% .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
On NHKNews7 dataset , our k-Faces.Temporal is still better than CMSM , but is worse than pair:min and MSM .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
On NHKNews7 dataset , our k-Faces.Temporal is still better than CMSM , but is worse than pair:min and MSM .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
On NHKNews7 dataset , our k-Faces.Temporal is still better than CMSM , but is worse than pair:min and MSM .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
On NHKNews7 dataset , our k-Faces.Temporal is still better than CMSM , but is worse than pair:min and MSM .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
One may concern that why MSM perform poorly on Trecvid dataset , but it is superior to our k-Faces.Temporal on NHKNews7 .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
One may concern that why MSM perform poorly on Trecvid dataset , but it is superior to our k-Faces.Temporal on NHKNews7 .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
One may concern that why MSM perform poorly on Trecvid dataset , but it is superior to our k-Faces.Temporal on NHKNews7 .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
One may concern that why MSM perform poorly on Trecvid dataset , but it is superior to our k-Faces.Temporal on NHKNews7 .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
One may concern that why MSM perform poorly on Trecvid dataset , but it is superior to our k-Faces.Temporal on NHKNews7 .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
One may concern that why MSM perform poorly on Trecvid dataset , but it is superior to our k-Faces.Temporal on NHKNews7 .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
One may concern that why MSM perform poorly on Trecvid dataset , but it is superior to our k-Faces.Temporal on NHKNews7 .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
One may concern that why MSM perform poorly on Trecvid dataset , but it is superior to our k-Faces.Temporal on NHKNews7 .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
This is due to the fact that face-tracks on NHKNews7 dataset is larger than those on Trecvid dataset .
#<struct ReadData::Alignment source_numbers="1,2,3,4", target_numbers="1,2,3,4,5", tag_name="wa">
This is due to the fact that face-tracks on NHKNews7 dataset is larger than those on Trecvid dataset .
#<struct ReadData::Alignment source_numbers="18", target_numbers="23", tag_name="wa">
This is due to the fact that face-tracks on NHKNews7 dataset is larger than those on Trecvid dataset .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
This is due to the fact that face-tracks on NHKNews7 dataset is larger than those on Trecvid dataset .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
This is due to the fact that face-tracks on NHKNews7 dataset is larger than those on Trecvid dataset .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
This is due to the fact that face-tracks on NHKNews7 dataset is larger than those on Trecvid dataset .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
This is due to the fact that face-tracks on NHKNews7 dataset is larger than those on Trecvid dataset .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
This is due to the fact that face-tracks on NHKNews7 dataset is larger than those on Trecvid dataset .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
This is due to the fact that face-tracks on NHKNews7 dataset is larger than those on Trecvid dataset .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
This is due to the fact that face-tracks on NHKNews7 dataset is larger than those on Trecvid dataset .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
This is due to the fact that face-tracks on NHKNews7 dataset is larger than those on Trecvid dataset .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
Therefore , more sample faces in each face-track can be used to obtain a reliable subspace .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Therefore , more sample faces in each face-track can be used to obtain a reliable subspace .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Therefore , more sample faces in each face-track can be used to obtain a reliable subspace .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
As expected , the results in this experiment demonstrate that our proposed approach is extremely efficient while archiving comparable performance with state-of-the-art approaches�f.
#<struct ReadData::Alignment source_numbers="8,9", target_numbers="8,9", tag_name="wa">
As expected , the results in this experiment demonstrate that our proposed approach is extremely efficient while archiving comparable performance with state-of-the-art approaches�f.
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
As expected , the results in this experiment demonstrate that our proposed approach is extremely efficient while archiving comparable performance with state-of-the-art approaches�f.
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
As expected , the results in this experiment demonstrate that our proposed approach is extremely efficient while archiving comparable performance with state-of-the-art approaches�f.
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
As expected , the results in this experiment demonstrate that our proposed approach is extremely efficient while archiving comparable performance with state-of-the-art approaches�f.
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
As expected , the results in this experiment demonstrate that our proposed approach is extremely efficient while archiving comparable performance with state-of-the-art approaches�f.
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
As expected , the results in this experiment demonstrate that our proposed approach is extremely efficient while archiving comparable performance with state-of-the-art approaches�f.
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
As expected , the results in this experiment demonstrate that our proposed approach is extremely efficient while archiving comparable performance with state-of-the-art approaches�f.
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
In this paper , we investigate face retrieval on large-scale news video datasets .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
In this paper , we investigate face retrieval on large-scale news video datasets .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Our contributions is 3-fold .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
Our contributions is 3-fold .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Firstly , we presented practical problems when a tracker is used to extract face-tracks in news videos .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
Firstly , we presented practical problems when a tracker is used to extract face-tracks in news videos .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Firstly , we presented practical problems when a tracker is used to extract face-tracks in news videos .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
Firstly , we presented practical problems when a tracker is used to extract face-tracks in news videos .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
Based on that , we introduce techniques and solutions to bypass the problems for robust face-track extraction .
#<struct ReadData::Alignment source_numbers="12,13", target_numbers="12,13", tag_name="wa">
Based on that , we introduce techniques and solutions to bypass the problems for robust face-track extraction .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Based on that , we introduce techniques and solutions to bypass the problems for robust face-track extraction .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Based on that , we introduce techniques and solutions to bypass the problems for robust face-track extraction .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
Based on that , we introduce techniques and solutions to bypass the problems for robust face-track extraction .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Based on that , we introduce techniques and solutions to bypass the problems for robust face-track extraction .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Based on that , we introduce techniques and solutions to bypass the problems for robust face-track extraction .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
Based on that , we introduce techniques and solutions to bypass the problems for robust face-track extraction .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Secondly , we present an approach for face-track matching which significantly reduces the computational cost and achive competitive performance compared to state-of-the-art approaches .
#<struct ReadData::Alignment source_numbers="19,20", target_numbers="19,20", tag_name="wa">
Secondly , we present an approach for face-track matching which significantly reduces the computational cost and achive competitive performance compared to state-of-the-art approaches .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Secondly , we present an approach for face-track matching which significantly reduces the computational cost and achive competitive performance compared to state-of-the-art approaches .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
Secondly , we present an approach for face-track matching which significantly reduces the computational cost and achive competitive performance compared to state-of-the-art approaches .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
Secondly , we present an approach for face-track matching which significantly reduces the computational cost and achive competitive performance compared to state-of-the-art approaches .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Secondly , we present an approach for face-track matching which significantly reduces the computational cost and achive competitive performance compared to state-of-the-art approaches .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
Secondly , we present an approach for face-track matching which significantly reduces the computational cost and achive competitive performance compared to state-of-the-art approaches .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
Thirdly , we prepare , evaluate state-of-the-art face retreival approaches , and publish real-world face-track datasets whose scale have not been considered in literature ever.
#<struct ReadData::Alignment source_numbers="19", target_numbers="22", tag_name="wa">
Thirdly , we prepare , evaluate state-of-the-art face retreival approaches , and publish real-world face-track datasets whose scale have not been considered in literature ever.
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Thirdly , we prepare , evaluate state-of-the-art face retreival approaches , and publish real-world face-track datasets whose scale have not been considered in literature ever.
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
Thirdly , we prepare , evaluate state-of-the-art face retreival approaches , and publish real-world face-track datasets whose scale have not been considered in literature ever.
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
Thirdly , we prepare , evaluate state-of-the-art face retreival approaches , and publish real-world face-track datasets whose scale have not been considered in literature ever.
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
Thirdly , we prepare , evaluate state-of-the-art face retreival approaches , and publish real-world face-track datasets whose scale have not been considered in literature ever.
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
Thirdly , we prepare , evaluate state-of-the-art face retreival approaches , and publish real-world face-track datasets whose scale have not been considered in literature ever.
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Thirdly , we prepare , evaluate state-of-the-art face retreival approaches , and publish real-world face-track datasets whose scale have not been considered in literature ever.
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Thirdly , we prepare , evaluate state-of-the-art face retreival approaches , and publish real-world face-track datasets whose scale have not been considered in literature ever.
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Thirdly , we prepare , evaluate state-of-the-art face retreival approaches , and publish real-world face-track datasets whose scale have not been considered in literature ever.
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
Thirdly , we prepare , evaluate state-of-the-art face retreival approaches , and publish real-world face-track datasets whose scale have not been considered in literature ever.
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
Thirdly , we prepare , evaluate state-of-the-art face retreival approaches , and publish real-world face-track datasets whose scale have not been considered in literature ever.
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
Thirdly , we prepare , evaluate state-of-the-art face retreival approaches , and publish real-world face-track datasets whose scale have not been considered in literature ever.
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
This paper presents a novel recommendation system , named Recommend-Me , to faciliate users in searching and exploring images of an unknown image database .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
This paper presents a novel recommendation system , named Recommend-Me , to faciliate users in searching and exploring images of an unknown image database .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
This paper presents a novel recommendation system , named Recommend-Me , to faciliate users in searching and exploring images of an unknown image database .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
This paper presents a novel recommendation system , named Recommend-Me , to faciliate users in searching and exploring images of an unknown image database .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
Given an initial query image , Recommend-Me automatically introduces its recommendations to users .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Given an initial query image , Recommend-Me automatically introduces its recommendations to users .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
So that , users can make their own decisions before any actual search .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
So that , users can make their own decisions before any actual search .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
So that , users can make their own decisions before any actual search .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
So that , users can make their own decisions before any actual search .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
So that , users can make their own decisions before any actual search .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
We introduce an efficient approach for Recommend-Me to deal with quantifying occurences of multiple candidate items over images of the database .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
We introduce an efficient approach for Recommend-Me to deal with quantifying occurences of multiple candidate items over images of the database .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
We introduce an efficient approach for Recommend-Me to deal with quantifying occurences of multiple candidate items over images of the database .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
We introduce an efficient approach for Recommend-Me to deal with quantifying occurences of multiple candidate items over images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
We introduce an efficient approach for Recommend-Me to deal with quantifying occurences of multiple candidate items over images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
We introduce an efficient approach for Recommend-Me to deal with quantifying occurences of multiple candidate items over images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
Instead of scanning the database for each candidate item repspectively , the approach enumerate occurences of multiple candidate items simultaneously by investigating pairs of highly similar regions , knowing one pair is formed by a region in the intial image and a region in an image of the database .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Instead of scanning the database for each candidate item repspectively , the approach enumerate occurences of multiple candidate items simultaneously by investigating pairs of highly similar regions , knowing one pair is formed by a region in the intial image and a region in an image of the database .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
Instead of scanning the database for each candidate item repspectively , the approach enumerate occurences of multiple candidate items simultaneously by investigating pairs of highly similar regions , knowing one pair is formed by a region in the intial image and a region in an image of the database .
#<struct ReadData::Alignment source_numbers="38", target_numbers="", tag_name="wa">
Instead of scanning the database for each candidate item repspectively , the approach enumerate occurences of multiple candidate items simultaneously by investigating pairs of highly similar regions , knowing one pair is formed by a region in the intial image and a region in an image of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Instead of scanning the database for each candidate item repspectively , the approach enumerate occurences of multiple candidate items simultaneously by investigating pairs of highly similar regions , knowing one pair is formed by a region in the intial image and a region in an image of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
We formulate the problem of finding such pairs as an opmization problem , which can be solved by a branch-and-bound algorithm .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
We formulate the problem of finding such pairs as an opmization problem , which can be solved by a branch-and-bound algorithm .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Experiments conducted on a real-life and publicly available dataset demonstrate the efficiency , the robustness and a promissing application of our system .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
Experiments conducted on a real-life and publicly available dataset demonstrate the efficiency , the robustness and a promissing application of our system .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Experiments conducted on a real-life and publicly available dataset demonstrate the efficiency , the robustness and a promissing application of our system .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
With the advances of modern technology , a large amount of digital images nowadays can be created and stored easily .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
With the advances of modern technology , a large amount of digital images nowadays can be created and stored easily .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
With the advances of modern technology , a large amount of digital images nowadays can be created and stored easily .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
As a result , the exponential growth of image repositories creates the urgent needs for searching images . Because of its importance and wide applications , image search has attracted more interest in recent years .
#<struct ReadData::Alignment source_numbers="3", target_numbers="7", tag_name="wa">
As a result , the exponential growth of image repositories creates the urgent needs for searching images . Because of its importance and wide applications , image search has attracted more interest in recent years .
#<struct ReadData::Alignment source_numbers="25", target_numbers="9", tag_name="wa">
As a result , the exponential growth of image repositories creates the urgent needs for searching images . Because of its importance and wide applications , image search has attracted more interest in recent years .
#<struct ReadData::Alignment source_numbers="28", target_numbers="10", tag_name="wa">
As a result , the exponential growth of image repositories creates the urgent needs for searching images . Because of its importance and wide applications , image search has attracted more interest in recent years .
#<struct ReadData::Alignment source_numbers="10", target_numbers="11", tag_name="wa">
As a result , the exponential growth of image repositories creates the urgent needs for searching images . Because of its importance and wide applications , image search has attracted more interest in recent years .
#<struct ReadData::Alignment source_numbers="11,12", target_numbers="12,13", tag_name="wa">
As a result , the exponential growth of image repositories creates the urgent needs for searching images . Because of its importance and wide applications , image search has attracted more interest in recent years .
#<struct ReadData::Alignment source_numbers="13,14", target_numbers="14,15", tag_name="wa">
As a result , the exponential growth of image repositories creates the urgent needs for searching images . Because of its importance and wide applications , image search has attracted more interest in recent years .
#<struct ReadData::Alignment source_numbers="17", target_numbers="21", tag_name="wa">
As a result , the exponential growth of image repositories creates the urgent needs for searching images . Because of its importance and wide applications , image search has attracted more interest in recent years .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
As a result , the exponential growth of image repositories creates the urgent needs for searching images . Because of its importance and wide applications , image search has attracted more interest in recent years .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
As a result , the exponential growth of image repositories creates the urgent needs for searching images . Because of its importance and wide applications , image search has attracted more interest in recent years .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
As a result , the exponential growth of image repositories creates the urgent needs for searching images . Because of its importance and wide applications , image search has attracted more interest in recent years .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
As a result , the exponential growth of image repositories creates the urgent needs for searching images . Because of its importance and wide applications , image search has attracted more interest in recent years .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
As a result , the exponential growth of image repositories creates the urgent needs for searching images . Because of its importance and wide applications , image search has attracted more interest in recent years .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
As a result , the exponential growth of image repositories creates the urgent needs for searching images . Because of its importance and wide applications , image search has attracted more interest in recent years .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
As a result , the exponential growth of image repositories creates the urgent needs for searching images . Because of its importance and wide applications , image search has attracted more interest in recent years .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
As a result , the exponential growth of image repositories creates the urgent needs for searching images . Because of its importance and wide applications , image search has attracted more interest in recent years .
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
As a result , the exponential growth of image repositories creates the urgent needs for searching images . Because of its importance and wide applications , image search has attracted more interest in recent years .
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
As a result , the exponential growth of image repositories creates the urgent needs for searching images . Because of its importance and wide applications , image search has attracted more interest in recent years .
#<struct ReadData::Alignment source_numbers="26", target_numbers="", tag_name="wa">
As a result , the exponential growth of image repositories creates the urgent needs for searching images . Because of its importance and wide applications , image search has attracted more interest in recent years .
#<struct ReadData::Alignment source_numbers="27", target_numbers="", tag_name="wa">
As a result , the exponential growth of image repositories creates the urgent needs for searching images . Because of its importance and wide applications , image search has attracted more interest in recent years .
#<struct ReadData::Alignment source_numbers="29", target_numbers="", tag_name="wa">
As a result , the exponential growth of image repositories creates the urgent needs for searching images . Because of its importance and wide applications , image search has attracted more interest in recent years .
#<struct ReadData::Alignment source_numbers="30", target_numbers="", tag_name="wa">
As a result , the exponential growth of image repositories creates the urgent needs for searching images . Because of its importance and wide applications , image search has attracted more interest in recent years .
#<struct ReadData::Alignment source_numbers="31", target_numbers="", tag_name="wa">
As a result , the exponential growth of image repositories creates the urgent needs for searching images . Because of its importance and wide applications , image search has attracted more interest in recent years .
#<struct ReadData::Alignment source_numbers="32", target_numbers="", tag_name="wa">
As a result , the exponential growth of image repositories creates the urgent needs for searching images . Because of its importance and wide applications , image search has attracted more interest in recent years .
#<struct ReadData::Alignment source_numbers="33", target_numbers="", tag_name="wa">
As a result , the exponential growth of image repositories creates the urgent needs for searching images . Because of its importance and wide applications , image search has attracted more interest in recent years .
#<struct ReadData::Alignment source_numbers="34", target_numbers="", tag_name="wa">
As a result , the exponential growth of image repositories creates the urgent needs for searching images . Because of its importance and wide applications , image search has attracted more interest in recent years .
#<struct ReadData::Alignment source_numbers="35", target_numbers="", tag_name="wa">
As a result , the exponential growth of image repositories creates the urgent needs for searching images . Because of its importance and wide applications , image search has attracted more interest in recent years .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
As a result , the exponential growth of image repositories creates the urgent needs for searching images . Because of its importance and wide applications , image search has attracted more interest in recent years .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
As a result , the exponential growth of image repositories creates the urgent needs for searching images . Because of its importance and wide applications , image search has attracted more interest in recent years .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
As a result , the exponential growth of image repositories creates the urgent needs for searching images . Because of its importance and wide applications , image search has attracted more interest in recent years .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
As a result , the exponential growth of image repositories creates the urgent needs for searching images . Because of its importance and wide applications , image search has attracted more interest in recent years .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
In a typical scenario of image search , users supply a query item which is usually represented by a region cropped from an image .
#<struct ReadData::Alignment source_numbers="7", target_numbers="1", tag_name="wa">
In a typical scenario of image search , users supply a query item which is usually represented by a region cropped from an image .
#<struct ReadData::Alignment source_numbers="4", target_numbers="11", tag_name="wa">
In a typical scenario of image search , users supply a query item which is usually represented by a region cropped from an image .
#<struct ReadData::Alignment source_numbers="24", target_numbers="19", tag_name="wa">
In a typical scenario of image search , users supply a query item which is usually represented by a region cropped from an image .
#<struct ReadData::Alignment source_numbers="8", target_numbers="25", tag_name="wa">
In a typical scenario of image search , users supply a query item which is usually represented by a region cropped from an image .
#<struct ReadData::Alignment source_numbers="9", target_numbers="26", tag_name="wa">
In a typical scenario of image search , users supply a query item which is usually represented by a region cropped from an image .
#<struct ReadData::Alignment source_numbers="10", target_numbers="27", tag_name="wa">
In a typical scenario of image search , users supply a query item which is usually represented by a region cropped from an image .
#<struct ReadData::Alignment source_numbers="11", target_numbers="28", tag_name="wa">
In a typical scenario of image search , users supply a query item which is usually represented by a region cropped from an image .
#<struct ReadData::Alignment source_numbers="12", target_numbers="29", tag_name="wa">
In a typical scenario of image search , users supply a query item which is usually represented by a region cropped from an image .
#<struct ReadData::Alignment source_numbers="13", target_numbers="31", tag_name="wa">
In a typical scenario of image search , users supply a query item which is usually represented by a region cropped from an image .
#<struct ReadData::Alignment source_numbers="14", target_numbers="32", tag_name="wa">
In a typical scenario of image search , users supply a query item which is usually represented by a region cropped from an image .
#<struct ReadData::Alignment source_numbers="15", target_numbers="33", tag_name="wa">
In a typical scenario of image search , users supply a query item which is usually represented by a region cropped from an image .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
In a typical scenario of image search , users supply a query item which is usually represented by a region cropped from an image .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
In a typical scenario of image search , users supply a query item which is usually represented by a region cropped from an image .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
In a typical scenario of image search , users supply a query item which is usually represented by a region cropped from an image .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
In a typical scenario of image search , users supply a query item which is usually represented by a region cropped from an image .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
In a typical scenario of image search , users supply a query item which is usually represented by a region cropped from an image .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
In a typical scenario of image search , users supply a query item which is usually represented by a region cropped from an image .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
In a typical scenario of image search , users supply a query item which is usually represented by a region cropped from an image .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
In a typical scenario of image search , users supply a query item which is usually represented by a region cropped from an image .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
In a typical scenario of image search , users supply a query item which is usually represented by a region cropped from an image .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
In a typical scenario of image search , users supply a query item which is usually represented by a region cropped from an image .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
In a typical scenario of image search , users supply a query item which is usually represented by a region cropped from an image .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
In a typical scenario of image search , users supply a query item which is usually represented by a region cropped from an image .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
In a typical scenario of image search , users supply a query item which is usually represented by a region cropped from an image .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
In a typical scenario of image search , users supply a query item which is usually represented by a region cropped from an image .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
In a typical scenario of image search , users supply a query item which is usually represented by a region cropped from an image .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
In a typical scenario of image search , users supply a query item which is usually represented by a region cropped from an image .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
In a typical scenario of image search , users supply a query item which is usually represented by a region cropped from an image .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
In a typical scenario of image search , users supply a query item which is usually represented by a region cropped from an image .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
In a typical scenario of image search , users supply a query item which is usually represented by a region cropped from an image .
#<struct ReadData::Alignment source_numbers="", target_numbers="40", tag_name="wa">
Several extensive works have been conducted with great interest on improving search performance \CITE .
#<struct ReadData::Alignment source_numbers="6", target_numbers="5", tag_name="wa">
Several extensive works have been conducted with great interest on improving search performance \CITE .
#<struct ReadData::Alignment source_numbers="14", target_numbers="18", tag_name="wa">
Several extensive works have been conducted with great interest on improving search performance \CITE .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Several extensive works have been conducted with great interest on improving search performance \CITE .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Several extensive works have been conducted with great interest on improving search performance \CITE .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Several extensive works have been conducted with great interest on improving search performance \CITE .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Several extensive works have been conducted with great interest on improving search performance \CITE .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Several extensive works have been conducted with great interest on improving search performance \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Several extensive works have been conducted with great interest on improving search performance \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Several extensive works have been conducted with great interest on improving search performance \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Several extensive works have been conducted with great interest on improving search performance \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Several extensive works have been conducted with great interest on improving search performance \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
Several extensive works have been conducted with great interest on improving search performance \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Several extensive works have been conducted with great interest on improving search performance \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Several extensive works have been conducted with great interest on improving search performance \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
The reason is because relevant items are not in the database .
#<struct ReadData::Alignment source_numbers="2,3", target_numbers="2,3", tag_name="wa">
A normal user without prior knowledge about the retrieved database has no choice but search by trial-and-error .
#<struct ReadData::Alignment source_numbers="14", target_numbers="14", tag_name="wa">
A normal user without prior knowledge about the retrieved database has no choice but search by trial-and-error .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
A normal user without prior knowledge about the retrieved database has no choice but search by trial-and-error .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
A normal user without prior knowledge about the retrieved database has no choice but search by trial-and-error .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
A normal user without prior knowledge about the retrieved database has no choice but search by trial-and-error .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
A normal user without prior knowledge about the retrieved database has no choice but search by trial-and-error .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
We tackle this problem to facilitate users in searching and exploring images of such unknown database .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
We tackle this problem to facilitate users in searching and exploring images of such unknown database .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
We tackle this problem to facilitate users in searching and exploring images of such unknown database .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
We tackle this problem to facilitate users in searching and exploring images of such unknown database .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
We tackle this problem to facilitate users in searching and exploring images of such unknown database .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Each recommended item is assigned a number to clarify how many images of the database it occurs .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Each recommended item is assigned a number to clarify how many images of the database it occurs .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Each recommended item is assigned a number to clarify how many images of the database it occurs .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
By providing such recommendations , Recommend-Me supports users to :
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
By providing such recommendations , Recommend-Me supports users to :
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
No extra information or knowledge is required for input but an initial query image and a retrieved database .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
No extra information or knowledge is required for input but an initial query image and a retrieved database .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
No extra information or knowledge is required for input but an initial query image and a retrieved database .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
No extra information or knowledge is required for input but an initial query image and a retrieved database .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
No extra information or knowledge is required for input but an initial query image and a retrieved database .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
No extra information or knowledge is required for input but an initial query image and a retrieved database .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
No extra information or knowledge is required for input but an initial query image and a retrieved database .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
No extra information or knowledge is required for input but an initial query image and a retrieved database .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
No extra information or knowledge is required for input but an initial query image and a retrieved database .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
No extra information or knowledge is required for input but an initial query image and a retrieved database .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
No extra information or knowledge is required for input but an initial query image and a retrieved database .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
No extra information or knowledge is required for input but an initial query image and a retrieved database .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
No extra information or knowledge is required for input but an initial query image and a retrieved database .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
No extra information or knowledge is required for input but an initial query image and a retrieved database .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
No extra information or knowledge is required for input but an initial query image and a retrieved database .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
No extra information or knowledge is required for input but an initial query image and a retrieved database .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
No extra information or knowledge is required for input but an initial query image and a retrieved database .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
No extra information or knowledge is required for input but an initial query image and a retrieved database .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
No extra information or knowledge is required for input but an initial query image and a retrieved database .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
No extra information or knowledge is required for input but an initial query image and a retrieved database .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
No extra information or knowledge is required for input but an initial query image and a retrieved database .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
No extra information or knowledge is required for input but an initial query image and a retrieved database .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
No extra information or knowledge is required for input but an initial query image and a retrieved database .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
No extra information or knowledge is required for input but an initial query image and a retrieved database .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
No extra information or knowledge is required for input but an initial query image and a retrieved database .
#<struct ReadData::Alignment source_numbers="", target_numbers="40", tag_name="wa">
No extra information or knowledge is required for input but an initial query image and a retrieved database .
#<struct ReadData::Alignment source_numbers="", target_numbers="41", tag_name="wa">
To automatically generate recommendations , we need to address several critical issues .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
First , there is a huge pool of candidate items in the initial query image .
#<struct ReadData::Alignment source_numbers="3", target_numbers="3", tag_name="wa">
First , there is a huge pool of candidate items in the initial query image .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
First , there is a huge pool of candidate items in the initial query image .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Examining all of them requires enormous computational cost .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
Examining all of them requires enormous computational cost .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Examining all of them requires enormous computational cost .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Second , even if a candidate item is known , enumerating its occurrences in the database is not trivial because it is subject to many variations such as viewpoint and scale changes , rotation or occlusion .
#<struct ReadData::Alignment source_numbers="17", target_numbers="18", tag_name="wa">
Second , even if a candidate item is known , enumerating its occurrences in the database is not trivial because it is subject to many variations such as viewpoint and scale changes , rotation or occlusion .
#<struct ReadData::Alignment source_numbers="18", target_numbers="19", tag_name="wa">
Second , even if a candidate item is known , enumerating its occurrences in the database is not trivial because it is subject to many variations such as viewpoint and scale changes , rotation or occlusion .
#<struct ReadData::Alignment source_numbers="30", target_numbers="31", tag_name="wa">
Second , even if a candidate item is known , enumerating its occurrences in the database is not trivial because it is subject to many variations such as viewpoint and scale changes , rotation or occlusion .
#<struct ReadData::Alignment source_numbers="26", target_numbers="", tag_name="wa">
Second , even if a candidate item is known , enumerating its occurrences in the database is not trivial because it is subject to many variations such as viewpoint and scale changes , rotation or occlusion .
#<struct ReadData::Alignment source_numbers="27", target_numbers="", tag_name="wa">
Second , even if a candidate item is known , enumerating its occurrences in the database is not trivial because it is subject to many variations such as viewpoint and scale changes , rotation or occlusion .
#<struct ReadData::Alignment source_numbers="29", target_numbers="", tag_name="wa">
Second , even if a candidate item is known , enumerating its occurrences in the database is not trivial because it is subject to many variations such as viewpoint and scale changes , rotation or occlusion .
#<struct ReadData::Alignment source_numbers="31", target_numbers="", tag_name="wa">
Second , even if a candidate item is known , enumerating its occurrences in the database is not trivial because it is subject to many variations such as viewpoint and scale changes , rotation or occlusion .
#<struct ReadData::Alignment source_numbers="34", target_numbers="", tag_name="wa">
Second , even if a candidate item is known , enumerating its occurrences in the database is not trivial because it is subject to many variations such as viewpoint and scale changes , rotation or occlusion .
#<struct ReadData::Alignment source_numbers="36", target_numbers="", tag_name="wa">
Second , even if a candidate item is known , enumerating its occurrences in the database is not trivial because it is subject to many variations such as viewpoint and scale changes , rotation or occlusion .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Second , even if a candidate item is known , enumerating its occurrences in the database is not trivial because it is subject to many variations such as viewpoint and scale changes , rotation or occlusion .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
Second , even if a candidate item is known , enumerating its occurrences in the database is not trivial because it is subject to many variations such as viewpoint and scale changes , rotation or occlusion .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
Second , even if a candidate item is known , enumerating its occurrences in the database is not trivial because it is subject to many variations such as viewpoint and scale changes , rotation or occlusion .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
Second , even if a candidate item is known , enumerating its occurrences in the database is not trivial because it is subject to many variations such as viewpoint and scale changes , rotation or occlusion .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
Second , even if a candidate item is known , enumerating its occurrences in the database is not trivial because it is subject to many variations such as viewpoint and scale changes , rotation or occlusion .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
Second , even if a candidate item is known , enumerating its occurrences in the database is not trivial because it is subject to many variations such as viewpoint and scale changes , rotation or occlusion .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
Furthermore , scanning over all regions in images of the database will inevitably be prohibitive , if not infeasible for practical purposes .
#<struct ReadData::Alignment source_numbers="9", target_numbers="2", tag_name="wa">
Furthermore , scanning over all regions in images of the database will inevitably be prohibitive , if not infeasible for practical purposes .
#<struct ReadData::Alignment source_numbers="5,6", target_numbers="7,8,9", tag_name="wa">
Furthermore , scanning over all regions in images of the database will inevitably be prohibitive , if not infeasible for practical purposes .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
Furthermore , scanning over all regions in images of the database will inevitably be prohibitive , if not infeasible for practical purposes .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
Furthermore , scanning over all regions in images of the database will inevitably be prohibitive , if not infeasible for practical purposes .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
Furthermore , scanning over all regions in images of the database will inevitably be prohibitive , if not infeasible for practical purposes .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
Furthermore , scanning over all regions in images of the database will inevitably be prohibitive , if not infeasible for practical purposes .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Furthermore , scanning over all regions in images of the database will inevitably be prohibitive , if not infeasible for practical purposes .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Furthermore , scanning over all regions in images of the database will inevitably be prohibitive , if not infeasible for practical purposes .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
In this paper , we employ state-of-the-art techniques such as SIFT and Bag-of-Words ( BoW ) model to handle matching regions under variations .
#<struct ReadData::Alignment source_numbers="23", target_numbers="29", tag_name="wa">
In this paper , we employ state-of-the-art techniques such as SIFT and Bag-of-Words ( BoW ) model to handle matching regions under variations .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
In this paper , we employ state-of-the-art techniques such as SIFT and Bag-of-Words ( BoW ) model to handle matching regions under variations .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
In this paper , we employ state-of-the-art techniques such as SIFT and Bag-of-Words ( BoW ) model to handle matching regions under variations .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
In this paper , we employ state-of-the-art techniques such as SIFT and Bag-of-Words ( BoW ) model to handle matching regions under variations .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
In this paper , we employ state-of-the-art techniques such as SIFT and Bag-of-Words ( BoW ) model to handle matching regions under variations .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
In this paper , we employ state-of-the-art techniques such as SIFT and Bag-of-Words ( BoW ) model to handle matching regions under variations .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
Our main focus is an efficient approach for quantifying occurences of candidate items over the database to generate recommendations .
#<struct ReadData::Alignment source_numbers="19", target_numbers="23", tag_name="wa">
Our main focus is an efficient approach for quantifying occurences of candidate items over the database to generate recommendations .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Our main focus is an efficient approach for quantifying occurences of candidate items over the database to generate recommendations .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
Our main focus is an efficient approach for quantifying occurences of candidate items over the database to generate recommendations .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Our main focus is an efficient approach for quantifying occurences of candidate items over the database to generate recommendations .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Our main focus is an efficient approach for quantifying occurences of candidate items over the database to generate recommendations .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
Our main focus is an efficient approach for quantifying occurences of candidate items over the database to generate recommendations .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
Our main focus is an efficient approach for quantifying occurences of candidate items over the database to generate recommendations .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
Our main focus is an efficient approach for quantifying occurences of candidate items over the database to generate recommendations .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
The efficiency advantages of our approach come from various methodologies .
#<struct ReadData::Alignment source_numbers="6", target_numbers="4", tag_name="wa">
The efficiency advantages of our approach come from various methodologies .
#<struct ReadData::Alignment source_numbers="4", target_numbers="6", tag_name="wa">
The efficiency advantages of our approach come from various methodologies .
#<struct ReadData::Alignment source_numbers="3", target_numbers="8", tag_name="wa">
The efficiency advantages of our approach come from various methodologies .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
The efficiency advantages of our approach come from various methodologies .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
The efficiency advantages of our approach come from various methodologies .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
The efficiency advantages of our approach come from various methodologies .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
The efficiency advantages of our approach come from various methodologies .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Based on an observation that users are mostly interested in object-like items , we use a selective search approach proposed by Van de Sande et al. \CITE to sample regions bounding object-like items in all images as a preprocessing step .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Based on an observation that users are mostly interested in object-like items , we use a selective search approach proposed by Van de Sande et al. \CITE to sample regions bounding object-like items in all images as a preprocessing step .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Based on an observation that users are mostly interested in object-like items , we use a selective search approach proposed by Van de Sande et al. \CITE to sample regions bounding object-like items in all images as a preprocessing step .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Based on an observation that users are mostly interested in object-like items , we use a selective search approach proposed by Van de Sande et al. \CITE to sample regions bounding object-like items in all images as a preprocessing step .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
By applying the approach instead of other naive sampling approach such as sliding windows , the number of items ( i.e. regions ) that need to be processed in each image dramatically reduces .
#<struct ReadData::Alignment source_numbers="2,3", target_numbers="2,3", tag_name="wa">
By applying the approach instead of other naive sampling approach such as sliding windows , the number of items ( i.e. regions ) that need to be processed in each image dramatically reduces .
#<struct ReadData::Alignment source_numbers="25", target_numbers="18", tag_name="wa">
By applying the approach instead of other naive sampling approach such as sliding windows , the number of items ( i.e. regions ) that need to be processed in each image dramatically reduces .
#<struct ReadData::Alignment source_numbers="33", target_numbers="37", tag_name="wa">
By applying the approach instead of other naive sampling approach such as sliding windows , the number of items ( i.e. regions ) that need to be processed in each image dramatically reduces .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
By applying the approach instead of other naive sampling approach such as sliding windows , the number of items ( i.e. regions ) that need to be processed in each image dramatically reduces .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
By applying the approach instead of other naive sampling approach such as sliding windows , the number of items ( i.e. regions ) that need to be processed in each image dramatically reduces .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
By applying the approach instead of other naive sampling approach such as sliding windows , the number of items ( i.e. regions ) that need to be processed in each image dramatically reduces .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
By applying the approach instead of other naive sampling approach such as sliding windows , the number of items ( i.e. regions ) that need to be processed in each image dramatically reduces .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
By applying the approach instead of other naive sampling approach such as sliding windows , the number of items ( i.e. regions ) that need to be processed in each image dramatically reduces .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
Given two sets of regions , one contains regions of candidate items in the initial query image and the other contains regions of items in images of the database .
#<struct ReadData::Alignment source_numbers="29", target_numbers="43", tag_name="wa">
Given two sets of regions , one contains regions of candidate items in the initial query image and the other contains regions of items in images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
Given two sets of regions , one contains regions of candidate items in the initial query image and the other contains regions of items in images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
Given two sets of regions , one contains regions of candidate items in the initial query image and the other contains regions of items in images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
Given two sets of regions , one contains regions of candidate items in the initial query image and the other contains regions of items in images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
Given two sets of regions , one contains regions of candidate items in the initial query image and the other contains regions of items in images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
Given two sets of regions , one contains regions of candidate items in the initial query image and the other contains regions of items in images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
Given two sets of regions , one contains regions of candidate items in the initial query image and the other contains regions of items in images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
Given two sets of regions , one contains regions of candidate items in the initial query image and the other contains regions of items in images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
Given two sets of regions , one contains regions of candidate items in the initial query image and the other contains regions of items in images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
Given two sets of regions , one contains regions of candidate items in the initial query image and the other contains regions of items in images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
Given two sets of regions , one contains regions of candidate items in the initial query image and the other contains regions of items in images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
Given two sets of regions , one contains regions of candidate items in the initial query image and the other contains regions of items in images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="40", tag_name="wa">
Given two sets of regions , one contains regions of candidate items in the initial query image and the other contains regions of items in images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="41", tag_name="wa">
Given two sets of regions , one contains regions of candidate items in the initial query image and the other contains regions of items in images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="42", tag_name="wa">
Finding occurences of all candidate items in the database can be equally treated as finding pairs of matched regions , knowing a pair is formed by a region in one of the sets with a region in the other .
#<struct ReadData::Alignment source_numbers="9", target_numbers="2", tag_name="wa">
Finding occurences of all candidate items in the database can be equally treated as finding pairs of matched regions , knowing a pair is formed by a region in one of the sets with a region in the other .
#<struct ReadData::Alignment source_numbers="10", target_numbers="3", tag_name="wa">
Finding occurences of all candidate items in the database can be equally treated as finding pairs of matched regions , knowing a pair is formed by a region in one of the sets with a region in the other .
#<struct ReadData::Alignment source_numbers="12", target_numbers="5", tag_name="wa">
Finding occurences of all candidate items in the database can be equally treated as finding pairs of matched regions , knowing a pair is formed by a region in one of the sets with a region in the other .
#<struct ReadData::Alignment source_numbers="13", target_numbers="6", tag_name="wa">
Finding occurences of all candidate items in the database can be equally treated as finding pairs of matched regions , knowing a pair is formed by a region in one of the sets with a region in the other .
#<struct ReadData::Alignment source_numbers="14", target_numbers="7", tag_name="wa">
Finding occurences of all candidate items in the database can be equally treated as finding pairs of matched regions , knowing a pair is formed by a region in one of the sets with a region in the other .
#<struct ReadData::Alignment source_numbers="15", target_numbers="8", tag_name="wa">
Finding occurences of all candidate items in the database can be equally treated as finding pairs of matched regions , knowing a pair is formed by a region in one of the sets with a region in the other .
#<struct ReadData::Alignment source_numbers="16", target_numbers="9", tag_name="wa">
Finding occurences of all candidate items in the database can be equally treated as finding pairs of matched regions , knowing a pair is formed by a region in one of the sets with a region in the other .
#<struct ReadData::Alignment source_numbers="17", target_numbers="10", tag_name="wa">
Finding occurences of all candidate items in the database can be equally treated as finding pairs of matched regions , knowing a pair is formed by a region in one of the sets with a region in the other .
#<struct ReadData::Alignment source_numbers="18", target_numbers="11", tag_name="wa">
Finding occurences of all candidate items in the database can be equally treated as finding pairs of matched regions , knowing a pair is formed by a region in one of the sets with a region in the other .
#<struct ReadData::Alignment source_numbers="19", target_numbers="12", tag_name="wa">
Finding occurences of all candidate items in the database can be equally treated as finding pairs of matched regions , knowing a pair is formed by a region in one of the sets with a region in the other .
#<struct ReadData::Alignment source_numbers="20", target_numbers="13", tag_name="wa">
Finding occurences of all candidate items in the database can be equally treated as finding pairs of matched regions , knowing a pair is formed by a region in one of the sets with a region in the other .
#<struct ReadData::Alignment source_numbers="21", target_numbers="15", tag_name="wa">
Finding occurences of all candidate items in the database can be equally treated as finding pairs of matched regions , knowing a pair is formed by a region in one of the sets with a region in the other .
#<struct ReadData::Alignment source_numbers="22", target_numbers="16", tag_name="wa">
Finding occurences of all candidate items in the database can be equally treated as finding pairs of matched regions , knowing a pair is formed by a region in one of the sets with a region in the other .
#<struct ReadData::Alignment source_numbers="23", target_numbers="17", tag_name="wa">
Finding occurences of all candidate items in the database can be equally treated as finding pairs of matched regions , knowing a pair is formed by a region in one of the sets with a region in the other .
#<struct ReadData::Alignment source_numbers="24", target_numbers="18", tag_name="wa">
Finding occurences of all candidate items in the database can be equally treated as finding pairs of matched regions , knowing a pair is formed by a region in one of the sets with a region in the other .
#<struct ReadData::Alignment source_numbers="25", target_numbers="19", tag_name="wa">
Finding occurences of all candidate items in the database can be equally treated as finding pairs of matched regions , knowing a pair is formed by a region in one of the sets with a region in the other .
#<struct ReadData::Alignment source_numbers="26", target_numbers="20", tag_name="wa">
Finding occurences of all candidate items in the database can be equally treated as finding pairs of matched regions , knowing a pair is formed by a region in one of the sets with a region in the other .
#<struct ReadData::Alignment source_numbers="27", target_numbers="21", tag_name="wa">
Finding occurences of all candidate items in the database can be equally treated as finding pairs of matched regions , knowing a pair is formed by a region in one of the sets with a region in the other .
#<struct ReadData::Alignment source_numbers="28", target_numbers="22", tag_name="wa">
Finding occurences of all candidate items in the database can be equally treated as finding pairs of matched regions , knowing a pair is formed by a region in one of the sets with a region in the other .
#<struct ReadData::Alignment source_numbers="29", target_numbers="23", tag_name="wa">
Finding occurences of all candidate items in the database can be equally treated as finding pairs of matched regions , knowing a pair is formed by a region in one of the sets with a region in the other .
#<struct ReadData::Alignment source_numbers="30", target_numbers="24", tag_name="wa">
Finding occurences of all candidate items in the database can be equally treated as finding pairs of matched regions , knowing a pair is formed by a region in one of the sets with a region in the other .
#<struct ReadData::Alignment source_numbers="31", target_numbers="25", tag_name="wa">
Finding occurences of all candidate items in the database can be equally treated as finding pairs of matched regions , knowing a pair is formed by a region in one of the sets with a region in the other .
#<struct ReadData::Alignment source_numbers="32", target_numbers="26", tag_name="wa">
Finding occurences of all candidate items in the database can be equally treated as finding pairs of matched regions , knowing a pair is formed by a region in one of the sets with a region in the other .
#<struct ReadData::Alignment source_numbers="33", target_numbers="27", tag_name="wa">
Finding occurences of all candidate items in the database can be equally treated as finding pairs of matched regions , knowing a pair is formed by a region in one of the sets with a region in the other .
#<struct ReadData::Alignment source_numbers="34", target_numbers="28", tag_name="wa">
Finding occurences of all candidate items in the database can be equally treated as finding pairs of matched regions , knowing a pair is formed by a region in one of the sets with a region in the other .
#<struct ReadData::Alignment source_numbers="35", target_numbers="29", tag_name="wa">
Finding occurences of all candidate items in the database can be equally treated as finding pairs of matched regions , knowing a pair is formed by a region in one of the sets with a region in the other .
#<struct ReadData::Alignment source_numbers="36", target_numbers="30", tag_name="wa">
Finding occurences of all candidate items in the database can be equally treated as finding pairs of matched regions , knowing a pair is formed by a region in one of the sets with a region in the other .
#<struct ReadData::Alignment source_numbers="37", target_numbers="31", tag_name="wa">
Finding occurences of all candidate items in the database can be equally treated as finding pairs of matched regions , knowing a pair is formed by a region in one of the sets with a region in the other .
#<struct ReadData::Alignment source_numbers="38", target_numbers="32", tag_name="wa">
Finding occurences of all candidate items in the database can be equally treated as finding pairs of matched regions , knowing a pair is formed by a region in one of the sets with a region in the other .
#<struct ReadData::Alignment source_numbers="39", target_numbers="33", tag_name="wa">
Finding occurences of all candidate items in the database can be equally treated as finding pairs of matched regions , knowing a pair is formed by a region in one of the sets with a region in the other .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Finding occurences of all candidate items in the database can be equally treated as finding pairs of matched regions , knowing a pair is formed by a region in one of the sets with a region in the other .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Finding occurences of all candidate items in the database can be equally treated as finding pairs of matched regions , knowing a pair is formed by a region in one of the sets with a region in the other .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Finding occurences of all candidate items in the database can be equally treated as finding pairs of matched regions , knowing a pair is formed by a region in one of the sets with a region in the other .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
Finding occurences of all candidate items in the database can be equally treated as finding pairs of matched regions , knowing a pair is formed by a region in one of the sets with a region in the other .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
Finding occurences of all candidate items in the database can be equally treated as finding pairs of matched regions , knowing a pair is formed by a region in one of the sets with a region in the other .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Finding occurences of all candidate items in the database can be equally treated as finding pairs of matched regions , knowing a pair is formed by a region in one of the sets with a region in the other .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
Finding occurences of all candidate items in the database can be equally treated as finding pairs of matched regions , knowing a pair is formed by a region in one of the sets with a region in the other .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Finding occurences of all candidate items in the database can be equally treated as finding pairs of matched regions , knowing a pair is formed by a region in one of the sets with a region in the other .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Finding occurences of all candidate items in the database can be equally treated as finding pairs of matched regions , knowing a pair is formed by a region in one of the sets with a region in the other .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
Finding occurences of all candidate items in the database can be equally treated as finding pairs of matched regions , knowing a pair is formed by a region in one of the sets with a region in the other .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Finding occurences of all candidate items in the database can be equally treated as finding pairs of matched regions , knowing a pair is formed by a region in one of the sets with a region in the other .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Finding occurences of all candidate items in the database can be equally treated as finding pairs of matched regions , knowing a pair is formed by a region in one of the sets with a region in the other .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Finding occurences of all candidate items in the database can be equally treated as finding pairs of matched regions , knowing a pair is formed by a region in one of the sets with a region in the other .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
So , if top region pairs with sufficient high similarity scores are found , we can enumerate occurences of the items .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
So , if top region pairs with sufficient high similarity scores are found , we can enumerate occurences of the items .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
Based on these insights , we make an yet another efficiency boost by formulating the problem as an optimization problem which can be solved by applying a branh-and-bound algorithm .
#<struct ReadData::Alignment source_numbers="3", target_numbers="3", tag_name="wa">
Based on these insights , we make an yet another efficiency boost by formulating the problem as an optimization problem which can be solved by applying a branh-and-bound algorithm .
#<struct ReadData::Alignment source_numbers="21", target_numbers="6", tag_name="wa">
Based on these insights , we make an yet another efficiency boost by formulating the problem as an optimization problem which can be solved by applying a branh-and-bound algorithm .
#<struct ReadData::Alignment source_numbers="11", target_numbers="7", tag_name="wa">
Based on these insights , we make an yet another efficiency boost by formulating the problem as an optimization problem which can be solved by applying a branh-and-bound algorithm .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Based on these insights , we make an yet another efficiency boost by formulating the problem as an optimization problem which can be solved by applying a branh-and-bound algorithm .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
Based on these insights , we make an yet another efficiency boost by formulating the problem as an optimization problem which can be solved by applying a branh-and-bound algorithm .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Based on these insights , we make an yet another efficiency boost by formulating the problem as an optimization problem which can be solved by applying a branh-and-bound algorithm .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Based on these insights , we make an yet another efficiency boost by formulating the problem as an optimization problem which can be solved by applying a branh-and-bound algorithm .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
Based on these insights , we make an yet another efficiency boost by formulating the problem as an optimization problem which can be solved by applying a branh-and-bound algorithm .
#<struct ReadData::Alignment source_numbers="27", target_numbers="", tag_name="wa">
Based on these insights , we make an yet another efficiency boost by formulating the problem as an optimization problem which can be solved by applying a branh-and-bound algorithm .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Based on these insights , we make an yet another efficiency boost by formulating the problem as an optimization problem which can be solved by applying a branh-and-bound algorithm .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Based on these insights , we make an yet another efficiency boost by formulating the problem as an optimization problem which can be solved by applying a branh-and-bound algorithm .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
Based on these insights , we make an yet another efficiency boost by formulating the problem as an optimization problem which can be solved by applying a branh-and-bound algorithm .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
Based on these insights , we make an yet another efficiency boost by formulating the problem as an optimization problem which can be solved by applying a branh-and-bound algorithm .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
In order to do that , we introduce a novel representation based on hierarchical structure to describe a set of region pairs and a corresponding function bounding the similarity scores of pairs over such a set .
#<struct ReadData::Alignment source_numbers="34", target_numbers="13", tag_name="wa">
In order to do that , we introduce a novel representation based on hierarchical structure to describe a set of region pairs and a corresponding function bounding the similarity scores of pairs over such a set .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
Related Works .
#<struct ReadData::Alignment source_numbers="1", target_numbers="1", tag_name="wa">
With respect to discovering common items , Recommend-Me is related to recent studies on mining common items in image databases such as \CITE .
#<struct ReadData::Alignment source_numbers="1", target_numbers="2", tag_name="wa">
With respect to discovering common items , Recommend-Me is related to recent studies on mining common items in image databases such as \CITE .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
With respect to discovering common items , Recommend-Me is related to recent studies on mining common items in image databases such as \CITE .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
With respect to discovering common items , Recommend-Me is related to recent studies on mining common items in image databases such as \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
With respect to discovering common items , Recommend-Me is related to recent studies on mining common items in image databases such as \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
With respect to discovering common items , Recommend-Me is related to recent studies on mining common items in image databases such as \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
However , in contrast to these studies , Recommend-Me targets items which are shared by both an image database and user interest limited in an input initial image .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
However , in contrast to these studies , Recommend-Me targets items which are shared by both an image database and user interest limited in an input initial image .
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
However , in contrast to these studies , Recommend-Me targets items which are shared by both an image database and user interest limited in an input initial image .
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
However , in contrast to these studies , Recommend-Me targets items which are shared by both an image database and user interest limited in an input initial image .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
However , in contrast to these studies , Recommend-Me targets items which are shared by both an image database and user interest limited in an input initial image .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
However , in contrast to these studies , Recommend-Me targets items which are shared by both an image database and user interest limited in an input initial image .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
One can employ these techniques to our problem by firstly figuring out common items among images of the database , then looking them up in the initial query image again for recommendations .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
One can employ these techniques to our problem by firstly figuring out common items among images of the database , then looking them up in the initial query image again for recommendations .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
One can employ these techniques to our problem by firstly figuring out common items among images of the database , then looking them up in the initial query image again for recommendations .
#<struct ReadData::Alignment source_numbers="30", target_numbers="", tag_name="wa">
One can employ these techniques to our problem by firstly figuring out common items among images of the database , then looking them up in the initial query image again for recommendations .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
One can employ these techniques to our problem by firstly figuring out common items among images of the database , then looking them up in the initial query image again for recommendations .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
One can employ these techniques to our problem by firstly figuring out common items among images of the database , then looking them up in the initial query image again for recommendations .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
One can employ these techniques to our problem by firstly figuring out common items among images of the database , then looking them up in the initial query image again for recommendations .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
However , by doing that , extra costs for mining unnecessary items , which appear in the database but the initial query image , arise accordingly .
#<struct ReadData::Alignment source_numbers="19", target_numbers="5", tag_name="wa">
However , by doing that , extra costs for mining unnecessary items , which appear in the database but the initial query image , arise accordingly .
#<struct ReadData::Alignment source_numbers="7,8", target_numbers="7,8", tag_name="wa">
However , by doing that , extra costs for mining unnecessary items , which appear in the database but the initial query image , arise accordingly .
#<struct ReadData::Alignment source_numbers="5", target_numbers="17", tag_name="wa">
However , by doing that , extra costs for mining unnecessary items , which appear in the database but the initial query image , arise accordingly .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
However , by doing that , extra costs for mining unnecessary items , which appear in the database but the initial query image , arise accordingly .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
However , by doing that , extra costs for mining unnecessary items , which appear in the database but the initial query image , arise accordingly .
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
However , by doing that , extra costs for mining unnecessary items , which appear in the database but the initial query image , arise accordingly .
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
However , by doing that , extra costs for mining unnecessary items , which appear in the database but the initial query image , arise accordingly .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
However , by doing that , extra costs for mining unnecessary items , which appear in the database but the initial query image , arise accordingly .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
However , by doing that , extra costs for mining unnecessary items , which appear in the database but the initial query image , arise accordingly .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
However , by doing that , extra costs for mining unnecessary items , which appear in the database but the initial query image , arise accordingly .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
However , by doing that , extra costs for mining unnecessary items , which appear in the database but the initial query image , arise accordingly .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
One of the most related works to Recommend-Me for query suggestion is proposed by Zha et al in \CITE .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
One of the most related works to Recommend-Me for query suggestion is proposed by Zha et al in \CITE .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
One of the most related works to Recommend-Me for query suggestion is proposed by Zha et al in \CITE .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
One of the most related works to Recommend-Me for query suggestion is proposed by Zha et al in \CITE .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
One of the most related works to Recommend-Me for query suggestion is proposed by Zha et al in \CITE .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
One of the most related works to Recommend-Me for query suggestion is proposed by Zha et al in \CITE .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
One of the most related works to Recommend-Me for query suggestion is proposed by Zha et al in \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
One of the most related works to Recommend-Me for query suggestion is proposed by Zha et al in \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
One of the most related works to Recommend-Me for query suggestion is proposed by Zha et al in \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
They introduced a system called Visual Query Suggestion ( VQS ) which simultanously provides both keyword and image suggestions for users .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
They introduced a system called Visual Query Suggestion ( VQS ) which simultanously provides both keyword and image suggestions for users .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
They introduced a system called Visual Query Suggestion ( VQS ) which simultanously provides both keyword and image suggestions for users .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
They introduced a system called Visual Query Suggestion ( VQS ) which simultanously provides both keyword and image suggestions for users .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
They introduced a system called Visual Query Suggestion ( VQS ) which simultanously provides both keyword and image suggestions for users .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
They introduced a system called Visual Query Suggestion ( VQS ) which simultanously provides both keyword and image suggestions for users .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
VQS requires an initial text query for suggestion formulation and its suggestions are both keywords and images .
#<struct ReadData::Alignment source_numbers="7", target_numbers="9", tag_name="wa">
VQS requires an initial text query for suggestion formulation and its suggestions are both keywords and images .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
VQS requires an initial text query for suggestion formulation and its suggestions are both keywords and images .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
VQS requires an initial text query for suggestion formulation and its suggestions are both keywords and images .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
VQS requires an initial text query for suggestion formulation and its suggestions are both keywords and images .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
On the other hand , Recommend-Me takes an image as input and its outputs are regions in the image .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
Above all , although both Recommend-Me and VQS aim at facilitating users in searching images , the targeted problems are different .
#<struct ReadData::Alignment source_numbers="10", target_numbers="10", tag_name="wa">
Above all , although both Recommend-Me and VQS aim at facilitating users in searching images , the targeted problems are different .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
Above all , although both Recommend-Me and VQS aim at facilitating users in searching images , the targeted problems are different .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
Above all , although both Recommend-Me and VQS aim at facilitating users in searching images , the targeted problems are different .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
Above all , although both Recommend-Me and VQS aim at facilitating users in searching images , the targeted problems are different .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
Above all , although both Recommend-Me and VQS aim at facilitating users in searching images , the targeted problems are different .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Above all , although both Recommend-Me and VQS aim at facilitating users in searching images , the targeted problems are different .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
VQS proposes to help users to overcome query ambiguity formulation by precisely expressing search intents , assuming relevant items are always available .
#<struct ReadData::Alignment source_numbers="22", target_numbers="26", tag_name="wa">
VQS proposes to help users to overcome query ambiguity formulation by precisely expressing search intents , assuming relevant items are always available .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
VQS proposes to help users to overcome query ambiguity formulation by precisely expressing search intents , assuming relevant items are always available .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
VQS proposes to help users to overcome query ambiguity formulation by precisely expressing search intents , assuming relevant items are always available .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
VQS proposes to help users to overcome query ambiguity formulation by precisely expressing search intents , assuming relevant items are always available .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
VQS proposes to help users to overcome query ambiguity formulation by precisely expressing search intents , assuming relevant items are always available .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
VQS proposes to help users to overcome query ambiguity formulation by precisely expressing search intents , assuming relevant items are always available .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
VQS proposes to help users to overcome query ambiguity formulation by precisely expressing search intents , assuming relevant items are always available .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
VQS proposes to help users to overcome query ambiguity formulation by precisely expressing search intents , assuming relevant items are always available .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
VQS proposes to help users to overcome query ambiguity formulation by precisely expressing search intents , assuming relevant items are always available .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
Meanwhile , Recommend-Me supports users to select queries based on the existence of their relevant items in the retrieved database .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
Meanwhile , Recommend-Me supports users to select queries based on the existence of their relevant items in the retrieved database .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
To the best of our knowledge , Recommend-Me is the first attempt towards its targeted suggestion scheme .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
To the best of our knowledge , Recommend-Me is the first attempt towards its targeted suggestion scheme .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
To the best of our knowledge , Recommend-Me is the first attempt towards its targeted suggestion scheme .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
To the best of our knowledge , Recommend-Me is the first attempt towards its targeted suggestion scheme .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
To the best of our knowledge , Recommend-Me is the first attempt towards its targeted suggestion scheme .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
To the best of our knowledge , Recommend-Me is the first attempt towards its targeted suggestion scheme .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
From technical point of view , our solution is motivated by recent works for object localization and subimage retrieval based on branch-and-bound optimization \CITE .
#<struct ReadData::Alignment source_numbers="12,13", target_numbers="13", tag_name="wa">
From technical point of view , our solution is motivated by recent works for object localization and subimage retrieval based on branch-and-bound optimization \CITE .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
However , ours is differentiated in the way we represent sets of region pairs , instead of sets of regions only .
#<struct ReadData::Alignment source_numbers="6", target_numbers="6", tag_name="wa">
However , ours is differentiated in the way we represent sets of region pairs , instead of sets of regions only .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
However , ours is differentiated in the way we represent sets of region pairs , instead of sets of regions only .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
However , ours is differentiated in the way we represent sets of region pairs , instead of sets of regions only .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
However , ours is differentiated in the way we represent sets of region pairs , instead of sets of regions only .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Meanwhile , we utilize hierarchical structures in order to do that , since our regions are discrete .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Meanwhile , we utilize hierarchical structures in order to do that , since our regions are discrete .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Meanwhile , we utilize hierarchical structures in order to do that , since our regions are discrete .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Although coordinate intervals as in ESS ( or ESR ) can be extended to represent set of region pairs , such criterion may suffer the branch-and-bound algorithm from curse-of-dimensionality problem since the number of dimension required is at least doubled .
#<struct ReadData::Alignment source_numbers="31", target_numbers="24", tag_name="wa">
Although coordinate intervals as in ESS ( or ESR ) can be extended to represent set of region pairs , such criterion may suffer the branch-and-bound algorithm from curse-of-dimensionality problem since the number of dimension required is at least doubled .
#<struct ReadData::Alignment source_numbers="40", target_numbers="45", tag_name="wa">
Although coordinate intervals as in ESS ( or ESR ) can be extended to represent set of region pairs , such criterion may suffer the branch-and-bound algorithm from curse-of-dimensionality problem since the number of dimension required is at least doubled .
#<struct ReadData::Alignment source_numbers="36", target_numbers="", tag_name="wa">
Although coordinate intervals as in ESS ( or ESR ) can be extended to represent set of region pairs , such criterion may suffer the branch-and-bound algorithm from curse-of-dimensionality problem since the number of dimension required is at least doubled .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
Although coordinate intervals as in ESS ( or ESR ) can be extended to represent set of region pairs , such criterion may suffer the branch-and-bound algorithm from curse-of-dimensionality problem since the number of dimension required is at least doubled .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
Although coordinate intervals as in ESS ( or ESR ) can be extended to represent set of region pairs , such criterion may suffer the branch-and-bound algorithm from curse-of-dimensionality problem since the number of dimension required is at least doubled .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
Finally , ours and ESS , ESR do not share common approach to construct bounding quality function and to compute bounding values over the sets .
#<struct ReadData::Alignment source_numbers="11", target_numbers="13", tag_name="wa">
Finally , ours and ESS , ESR do not share common approach to construct bounding quality function and to compute bounding values over the sets .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Finally , ours and ESS , ESR do not share common approach to construct bounding quality function and to compute bounding values over the sets .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Finally , ours and ESS , ESR do not share common approach to construct bounding quality function and to compute bounding values over the sets .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Finally , ours and ESS , ESR do not share common approach to construct bounding quality function and to compute bounding values over the sets .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Finally , ours and ESS , ESR do not share common approach to construct bounding quality function and to compute bounding values over the sets .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Finally , ours and ESS , ESR do not share common approach to construct bounding quality function and to compute bounding values over the sets .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Finally , ours and ESS , ESR do not share common approach to construct bounding quality function and to compute bounding values over the sets .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Finally , ours and ESS , ESR do not share common approach to construct bounding quality function and to compute bounding values over the sets .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Finally , ours and ESS , ESR do not share common approach to construct bounding quality function and to compute bounding values over the sets .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Finally , ours and ESS , ESR do not share common approach to construct bounding quality function and to compute bounding values over the sets .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Finally , ours and ESS , ESR do not share common approach to construct bounding quality function and to compute bounding values over the sets .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
Finally , ours and ESS , ESR do not share common approach to construct bounding quality function and to compute bounding values over the sets .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
Details of our proposed approaches for finding region pairs with highest similarity scores are given in Section 3 .
#<struct ReadData::Alignment source_numbers="5,6", target_numbers="5", tag_name="wa">
Details of our proposed approaches for finding region pairs with highest similarity scores are given in Section 3 .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Details of our proposed approaches for finding region pairs with highest similarity scores are given in Section 3 .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Details of our proposed approaches for finding region pairs with highest similarity scores are given in Section 3 .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
Details of our proposed approaches for finding region pairs with highest similarity scores are given in Section 3 .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
Details of our proposed approaches for finding region pairs with highest similarity scores are given in Section 3 .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Details of our proposed approaches for finding region pairs with highest similarity scores are given in Section 3 .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Details of our proposed approaches for finding region pairs with highest similarity scores are given in Section 3 .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Section 5 concludes our paper .
#<struct ReadData::Alignment source_numbers="2,3", target_numbers="2,3", tag_name="wa">
The framework of Recommend-Me consists of 4 main steps towards formulating final recommendations for users .
#<struct ReadData::Alignment source_numbers="15", target_numbers="9", tag_name="wa">
The framework of Recommend-Me consists of 4 main steps towards formulating final recommendations for users .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
The framework of Recommend-Me consists of 4 main steps towards formulating final recommendations for users .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
The framework of Recommend-Me consists of 4 main steps towards formulating final recommendations for users .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
The framework of Recommend-Me consists of 4 main steps towards formulating final recommendations for users .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
The framework of Recommend-Me consists of 4 main steps towards formulating final recommendations for users .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
The framework of Recommend-Me consists of 4 main steps towards formulating final recommendations for users .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
Step 1 : Candidate item selection in images .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
Step 1 : Candidate item selection in images .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
Step 1 : Candidate item selection in images .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Step 1 : Candidate item selection in images .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Step 1 : Candidate item selection in images .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Step 1 : Candidate item selection in images .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Using all possible rectangular regions in images as candidate items is overly expensive for further processing .
#<struct ReadData::Alignment source_numbers="14", target_numbers="15", tag_name="wa">
Using all possible rectangular regions in images as candidate items is overly expensive for further processing .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
Using all possible rectangular regions in images as candidate items is overly expensive for further processing .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Using all possible rectangular regions in images as candidate items is overly expensive for further processing .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
More importantly , human users are often get attracted by object-like items .
#<struct ReadData::Alignment source_numbers="8", target_numbers="6", tag_name="wa">
More importantly , human users are often get attracted by object-like items .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
More importantly , human users are often get attracted by object-like items .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
The approach starts by oversegmenting an image into disjoint regions .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
The approach starts by oversegmenting an image into disjoint regions .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Then , it performs a greedy algorithm which iteratively merges the two most similar regions together until the whole image becomes a single region .
#<struct ReadData::Alignment source_numbers="6", target_numbers="10", tag_name="wa">
Then , it performs a greedy algorithm which iteratively merges the two most similar regions together until the whole image becomes a single region .
#<struct ReadData::Alignment source_numbers="8", target_numbers="12", tag_name="wa">
Then , it performs a greedy algorithm which iteratively merges the two most similar regions together until the whole image becomes a single region .
#<struct ReadData::Alignment source_numbers="9", target_numbers="13", tag_name="wa">
Then , it performs a greedy algorithm which iteratively merges the two most similar regions together until the whole image becomes a single region .
#<struct ReadData::Alignment source_numbers="10", target_numbers="14", tag_name="wa">
Then , it performs a greedy algorithm which iteratively merges the two most similar regions together until the whole image becomes a single region .
#<struct ReadData::Alignment source_numbers="11", target_numbers="15", tag_name="wa">
Then , it performs a greedy algorithm which iteratively merges the two most similar regions together until the whole image becomes a single region .
#<struct ReadData::Alignment source_numbers="12", target_numbers="16", tag_name="wa">
Then , it performs a greedy algorithm which iteratively merges the two most similar regions together until the whole image becomes a single region .
#<struct ReadData::Alignment source_numbers="13", target_numbers="17", tag_name="wa">
Then , it performs a greedy algorithm which iteratively merges the two most similar regions together until the whole image becomes a single region .
#<struct ReadData::Alignment source_numbers="14", target_numbers="18", tag_name="wa">
Then , it performs a greedy algorithm which iteratively merges the two most similar regions together until the whole image becomes a single region .
#<struct ReadData::Alignment source_numbers="15", target_numbers="19", tag_name="wa">
Then , it performs a greedy algorithm which iteratively merges the two most similar regions together until the whole image becomes a single region .
#<struct ReadData::Alignment source_numbers="16", target_numbers="20", tag_name="wa">
Then , it performs a greedy algorithm which iteratively merges the two most similar regions together until the whole image becomes a single region .
#<struct ReadData::Alignment source_numbers="17", target_numbers="21", tag_name="wa">
Then , it performs a greedy algorithm which iteratively merges the two most similar regions together until the whole image becomes a single region .
#<struct ReadData::Alignment source_numbers="18", target_numbers="22", tag_name="wa">
Then , it performs a greedy algorithm which iteratively merges the two most similar regions together until the whole image becomes a single region .
#<struct ReadData::Alignment source_numbers="19", target_numbers="23", tag_name="wa">
Then , it performs a greedy algorithm which iteratively merges the two most similar regions together until the whole image becomes a single region .
#<struct ReadData::Alignment source_numbers="20", target_numbers="24", tag_name="wa">
Then , it performs a greedy algorithm which iteratively merges the two most similar regions together until the whole image becomes a single region .
#<struct ReadData::Alignment source_numbers="21", target_numbers="25", tag_name="wa">
Then , it performs a greedy algorithm which iteratively merges the two most similar regions together until the whole image becomes a single region .
#<struct ReadData::Alignment source_numbers="22", target_numbers="26", tag_name="wa">
Then , it performs a greedy algorithm which iteratively merges the two most similar regions together until the whole image becomes a single region .
#<struct ReadData::Alignment source_numbers="23", target_numbers="27", tag_name="wa">
Then , it performs a greedy algorithm which iteratively merges the two most similar regions together until the whole image becomes a single region .
#<struct ReadData::Alignment source_numbers="24", target_numbers="28", tag_name="wa">
Then , it performs a greedy algorithm which iteratively merges the two most similar regions together until the whole image becomes a single region .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
Then , it performs a greedy algorithm which iteratively merges the two most similar regions together until the whole image becomes a single region .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Then , it performs a greedy algorithm which iteratively merges the two most similar regions together until the whole image becomes a single region .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Then , it performs a greedy algorithm which iteratively merges the two most similar regions together until the whole image becomes a single region .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Then , it performs a greedy algorithm which iteratively merges the two most similar regions together until the whole image becomes a single region .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Then , it performs a greedy algorithm which iteratively merges the two most similar regions together until the whole image becomes a single region .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
All region throughout the hierarchy is considered as candidate items .
#<struct ReadData::Alignment source_numbers="5", target_numbers="5", tag_name="wa">
All region throughout the hierarchy is considered as candidate items .
#<struct ReadData::Alignment source_numbers="6,7", target_numbers="6,7,8", tag_name="wa">
In this step , we perform our proposed approach , explained in Section 3 , to find top \MATH ( an expected number of returned region pairs ) of such pairs in the pool .
#<struct ReadData::Alignment source_numbers="32", target_numbers="6", tag_name="wa">
In this step , we perform our proposed approach , explained in Section 3 , to find top \MATH ( an expected number of returned region pairs ) of such pairs in the pool .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
In this step , we perform our proposed approach , explained in Section 3 , to find top \MATH ( an expected number of returned region pairs ) of such pairs in the pool .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
In this step , we perform our proposed approach , explained in Section 3 , to find top \MATH ( an expected number of returned region pairs ) of such pairs in the pool .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
In this step , we perform our proposed approach , explained in Section 3 , to find top \MATH ( an expected number of returned region pairs ) of such pairs in the pool .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
In this step , we perform our proposed approach , explained in Section 3 , to find top \MATH ( an expected number of returned region pairs ) of such pairs in the pool .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
In this step , we perform our proposed approach , explained in Section 3 , to find top \MATH ( an expected number of returned region pairs ) of such pairs in the pool .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
In this step , we perform our proposed approach , explained in Section 3 , to find top \MATH ( an expected number of returned region pairs ) of such pairs in the pool .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
Given \MATH region pairs returned in Step 2 and assuming each region pair in \MATH pairs is formed by a candidate item and its corresponding match , we now can enumerate the number of occurences of the items .
#<struct ReadData::Alignment source_numbers="36", target_numbers="14", tag_name="wa">
Given \MATH region pairs returned in Step 2 and assuming each region pair in \MATH pairs is formed by a candidate item and its corresponding match , we now can enumerate the number of occurences of the items .
#<struct ReadData::Alignment source_numbers="28", target_numbers="", tag_name="wa">
Given \MATH region pairs returned in Step 2 and assuming each region pair in \MATH pairs is formed by a candidate item and its corresponding match , we now can enumerate the number of occurences of the items .
#<struct ReadData::Alignment source_numbers="34", target_numbers="", tag_name="wa">
Given \MATH region pairs returned in Step 2 and assuming each region pair in \MATH pairs is formed by a candidate item and its corresponding match , we now can enumerate the number of occurences of the items .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
Given \MATH region pairs returned in Step 2 and assuming each region pair in \MATH pairs is formed by a candidate item and its corresponding match , we now can enumerate the number of occurences of the items .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
However , there are several regions highly overlap each other due to merging in Step 1 .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
However , there are several regions highly overlap each other due to merging in Step 1 .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
However , there are several regions highly overlap each other due to merging in Step 1 .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
However , there are several regions highly overlap each other due to merging in Step 1 .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
They are perceived as the same item by human being .
#<struct ReadData::Alignment source_numbers="1", target_numbers="2,3", tag_name="wa">
They are perceived as the same item by human being .
#<struct ReadData::Alignment source_numbers="2", target_numbers="4", tag_name="wa">
They are perceived as the same item by human being .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
They are perceived as the same item by human being .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
They are perceived as the same item by human being .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
They are perceived as the same item by human being .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
They are perceived as the same item by human being .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
They are perceived as the same item by human being .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Thus , we propose to use maximal clique analysis technique to group such regions for consistent recommendations .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Thus , we propose to use maximal clique analysis technique to group such regions for consistent recommendations .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
Thus , we propose to use maximal clique analysis technique to group such regions for consistent recommendations .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Thus , we propose to use maximal clique analysis technique to group such regions for consistent recommendations .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Thus , we propose to use maximal clique analysis technique to group such regions for consistent recommendations .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Thus , we propose to use maximal clique analysis technique to group such regions for consistent recommendations .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
Using those numbers , we rank all groups and then introduce them to users as our recommendations .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Using those numbers , we rank all groups and then introduce them to users as our recommendations .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Using those numbers , we rank all groups and then introduce them to users as our recommendations .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
Using those numbers , we rank all groups and then introduce them to users as our recommendations .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Representative of each group is a rectangular region located by averaging coordinates of all member regions of the group .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Representative of each group is a rectangular region located by averaging coordinates of all member regions of the group .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Representative of each group is a rectangular region located by averaging coordinates of all member regions of the group .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
In this section , we introduce our proposed approach for efficiently finding top \MATH similar region pairs in the pool of all possible region pairs .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
In this section , we introduce our proposed approach for efficiently finding top \MATH similar region pairs in the pool of all possible region pairs .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
In this section , we introduce our proposed approach for efficiently finding top \MATH similar region pairs in the pool of all possible region pairs .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
With a similarity function \MATH , we have to solve the following optimization problem in order to find the region pair \MATH with the highest similarity score .
#<struct ReadData::Alignment source_numbers="23", target_numbers="2", tag_name="wa">
With a similarity function \MATH , we have to solve the following optimization problem in order to find the region pair \MATH with the highest similarity score .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
With a similarity function \MATH , we have to solve the following optimization problem in order to find the region pair \MATH with the highest similarity score .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
With a similarity function \MATH , we have to solve the following optimization problem in order to find the region pair \MATH with the highest similarity score .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
With a similarity function \MATH , we have to solve the following optimization problem in order to find the region pair \MATH with the highest similarity score .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
With a similarity function \MATH , we have to solve the following optimization problem in order to find the region pair \MATH with the highest similarity score .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
We propose to use a branch-and-bound algorithm \CITE for the problem .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
We propose to use a branch-and-bound algorithm \CITE for the problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
We propose to use a branch-and-bound algorithm \CITE for the problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
We propose to use a branch-and-bound algorithm \CITE for the problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Once \MATH is found , we can obtain the other top region pairs by continuing the search processs with the remaining search spaces , in which found top pairs eliminated .
#<struct ReadData::Alignment source_numbers="29", target_numbers="32", tag_name="wa">
Once \MATH is found , we can obtain the other top region pairs by continuing the search processs with the remaining search spaces , in which found top pairs eliminated .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
Once \MATH is found , we can obtain the other top region pairs by continuing the search processs with the remaining search spaces , in which found top pairs eliminated .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Once \MATH is found , we can obtain the other top region pairs by continuing the search processs with the remaining search spaces , in which found top pairs eliminated .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
Once \MATH is found , we can obtain the other top region pairs by continuing the search processs with the remaining search spaces , in which found top pairs eliminated .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
A general branch-and-bound algorithm works by hierarchically dividing the parameter space into disjoint parts , known as branching step .
#<struct ReadData::Alignment source_numbers="15,16", target_numbers="17,18", tag_name="wa">
A general branch-and-bound algorithm works by hierarchically dividing the parameter space into disjoint parts , known as branching step .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
A general branch-and-bound algorithm works by hierarchically dividing the parameter space into disjoint parts , known as branching step .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
A general branch-and-bound algorithm works by hierarchically dividing the parameter space into disjoint parts , known as branching step .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
A general branch-and-bound algorithm works by hierarchically dividing the parameter space into disjoint parts , known as branching step .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
In the bounding step , each part is assigned an upper bound value that the quality function could take on any of the members of the part .
#<struct ReadData::Alignment source_numbers="12,13", target_numbers="13", tag_name="wa">
In the bounding step , each part is assigned an upper bound value that the quality function could take on any of the members of the part .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
In the bounding step , each part is assigned an upper bound value that the quality function could take on any of the members of the part .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
In the bounding step , each part is assigned an upper bound value that the quality function could take on any of the members of the part .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
In the bounding step , each part is assigned an upper bound value that the quality function could take on any of the members of the part .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
In the bounding step , each part is assigned an upper bound value that the quality function could take on any of the members of the part .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
In the bounding step , each part is assigned an upper bound value that the quality function could take on any of the members of the part .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
In the bounding step , each part is assigned an upper bound value that the quality function could take on any of the members of the part .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
In the bounding step , each part is assigned an upper bound value that the quality function could take on any of the members of the part .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
In the bounding step , each part is assigned an upper bound value that the quality function could take on any of the members of the part .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
In the bounding step , each part is assigned an upper bound value that the quality function could take on any of the members of the part .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
In the bounding step , each part is assigned an upper bound value that the quality function could take on any of the members of the part .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
In the bounding step , each part is assigned an upper bound value that the quality function could take on any of the members of the part .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
In the bounding step , each part is assigned an upper bound value that the quality function could take on any of the members of the part .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
In the bounding step , each part is assigned an upper bound value that the quality function could take on any of the members of the part .
#<struct ReadData::Alignment source_numbers="", target_numbers="40", tag_name="wa">
In the bounding step , each part is assigned an upper bound value that the quality function could take on any of the members of the part .
#<struct ReadData::Alignment source_numbers="", target_numbers="41", tag_name="wa">
In the bounding step , each part is assigned an upper bound value that the quality function could take on any of the members of the part .
#<struct ReadData::Alignment source_numbers="", target_numbers="42", tag_name="wa">
In the bounding step , each part is assigned an upper bound value that the quality function could take on any of the members of the part .
#<struct ReadData::Alignment source_numbers="", target_numbers="43", tag_name="wa">
In the bounding step , each part is assigned an upper bound value that the quality function could take on any of the members of the part .
#<struct ReadData::Alignment source_numbers="", target_numbers="44", tag_name="wa">
In the bounding step , each part is assigned an upper bound value that the quality function could take on any of the members of the part .
#<struct ReadData::Alignment source_numbers="", target_numbers="45", tag_name="wa">
In the bounding step , each part is assigned an upper bound value that the quality function could take on any of the members of the part .
#<struct ReadData::Alignment source_numbers="", target_numbers="46", tag_name="wa">
In the bounding step , each part is assigned an upper bound value that the quality function could take on any of the members of the part .
#<struct ReadData::Alignment source_numbers="", target_numbers="47", tag_name="wa">
In the bounding step , each part is assigned an upper bound value that the quality function could take on any of the members of the part .
#<struct ReadData::Alignment source_numbers="", target_numbers="48", tag_name="wa">
In the bounding step , each part is assigned an upper bound value that the quality function could take on any of the members of the part .
#<struct ReadData::Alignment source_numbers="", target_numbers="49", tag_name="wa">
In the bounding step , each part is assigned an upper bound value that the quality function could take on any of the members of the part .
#<struct ReadData::Alignment source_numbers="", target_numbers="50", tag_name="wa">
In the bounding step , each part is assigned an upper bound value that the quality function could take on any of the members of the part .
#<struct ReadData::Alignment source_numbers="", target_numbers="51", tag_name="wa">
In the bounding step , each part is assigned an upper bound value that the quality function could take on any of the members of the part .
#<struct ReadData::Alignment source_numbers="", target_numbers="52", tag_name="wa">
In the bounding step , each part is assigned an upper bound value that the quality function could take on any of the members of the part .
#<struct ReadData::Alignment source_numbers="", target_numbers="53", tag_name="wa">
In the bounding step , each part is assigned an upper bound value that the quality function could take on any of the members of the part .
#<struct ReadData::Alignment source_numbers="", target_numbers="54", tag_name="wa">
In the bounding step , each part is assigned an upper bound value that the quality function could take on any of the members of the part .
#<struct ReadData::Alignment source_numbers="", target_numbers="55", tag_name="wa">
In the bounding step , each part is assigned an upper bound value that the quality function could take on any of the members of the part .
#<struct ReadData::Alignment source_numbers="", target_numbers="56", tag_name="wa">
In the bounding step , each part is assigned an upper bound value that the quality function could take on any of the members of the part .
#<struct ReadData::Alignment source_numbers="", target_numbers="57", tag_name="wa">
In the bounding step , each part is assigned an upper bound value that the quality function could take on any of the members of the part .
#<struct ReadData::Alignment source_numbers="", target_numbers="58", tag_name="wa">
In the bounding step , each part is assigned an upper bound value that the quality function could take on any of the members of the part .
#<struct ReadData::Alignment source_numbers="", target_numbers="59", tag_name="wa">
In the bounding step , each part is assigned an upper bound value that the quality function could take on any of the members of the part .
#<struct ReadData::Alignment source_numbers="", target_numbers="60", tag_name="wa">
In the bounding step , each part is assigned an upper bound value that the quality function could take on any of the members of the part .
#<struct ReadData::Alignment source_numbers="", target_numbers="61", tag_name="wa">
In the bounding step , each part is assigned an upper bound value that the quality function could take on any of the members of the part .
#<struct ReadData::Alignment source_numbers="", target_numbers="62", tag_name="wa">
In the bounding step , each part is assigned an upper bound value that the quality function could take on any of the members of the part .
#<struct ReadData::Alignment source_numbers="", target_numbers="63", tag_name="wa">
In the bounding step , each part is assigned an upper bound value that the quality function could take on any of the members of the part .
#<struct ReadData::Alignment source_numbers="", target_numbers="64", tag_name="wa">
In the bounding step , each part is assigned an upper bound value that the quality function could take on any of the members of the part .
#<struct ReadData::Alignment source_numbers="", target_numbers="65", tag_name="wa">
In the bounding step , each part is assigned an upper bound value that the quality function could take on any of the members of the part .
#<struct ReadData::Alignment source_numbers="", target_numbers="66", tag_name="wa">
In the bounding step , each part is assigned an upper bound value that the quality function could take on any of the members of the part .
#<struct ReadData::Alignment source_numbers="", target_numbers="67", tag_name="wa">
Parts of the parameter space with higher upper bound values are examined first .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Parts of the parameter space with higher upper bound values are examined first .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Parts of the parameter space with higher upper bound values are examined first .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
So , many portions of the parameter space can be eliminated if their upper bound values imply that they cannot contain the maximum .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
So , many portions of the parameter space can be eliminated if their upper bound values imply that they cannot contain the maximum .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Adapting to our problem , the parameter space is the set of all region pairs \MATH , and the quality function is the similarity function \MATH .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Adapting to our problem , the parameter space is the set of all region pairs \MATH , and the quality function is the similarity function \MATH .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Adapting to our problem , the parameter space is the set of all region pairs \MATH , and the quality function is the similarity function \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
- if each node is repsented by a histgoram \MATH with \MATH bins , the value at each bin of a child node is constrainted to be equal or smaller the value at the same bin of its parent node .
#<struct ReadData::Alignment source_numbers="16,17", target_numbers="16,17", tag_name="wa">
- if each node is repsented by a histgoram \MATH with \MATH bins , the value at each bin of a child node is constrainted to be equal or smaller the value at the same bin of its parent node .
#<struct ReadData::Alignment source_numbers="31,32", target_numbers="32,33", tag_name="wa">
- if each node is repsented by a histgoram \MATH with \MATH bins , the value at each bin of a child node is constrainted to be equal or smaller the value at the same bin of its parent node .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
- if each node is repsented by a histgoram \MATH with \MATH bins , the value at each bin of a child node is constrainted to be equal or smaller the value at the same bin of its parent node .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
- if each node is repsented by a histgoram \MATH with \MATH bins , the value at each bin of a child node is constrainted to be equal or smaller the value at the same bin of its parent node .
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
- if each node is repsented by a histgoram \MATH with \MATH bins , the value at each bin of a child node is constrainted to be equal or smaller the value at the same bin of its parent node .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
- if each node is repsented by a histgoram \MATH with \MATH bins , the value at each bin of a child node is constrainted to be equal or smaller the value at the same bin of its parent node .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
- if each node is repsented by a histgoram \MATH with \MATH bins , the value at each bin of a child node is constrainted to be equal or smaller the value at the same bin of its parent node .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
- if each node is repsented by a histgoram \MATH with \MATH bins , the value at each bin of a child node is constrainted to be equal or smaller the value at the same bin of its parent node .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
Given such structures , we show in the following how a branch-and-bound algorithm applied to our problem .
#<struct ReadData::Alignment source_numbers="8", target_numbers="8", tag_name="wa">
Given such structures , we show in the following how a branch-and-bound algorithm applied to our problem .
#<struct ReadData::Alignment source_numbers="7", target_numbers="10", tag_name="wa">
Given such structures , we show in the following how a branch-and-bound algorithm applied to our problem .
#<struct ReadData::Alignment source_numbers="13", target_numbers="15", tag_name="wa">
Given such structures , we show in the following how a branch-and-bound algorithm applied to our problem .
#<struct ReadData::Alignment source_numbers="14", target_numbers="16", tag_name="wa">
Given such structures , we show in the following how a branch-and-bound algorithm applied to our problem .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Given such structures , we show in the following how a branch-and-bound algorithm applied to our problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
Given such structures , we show in the following how a branch-and-bound algorithm applied to our problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
Given such structures , we show in the following how a branch-and-bound algorithm applied to our problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Given such structures , we show in the following how a branch-and-bound algorithm applied to our problem .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
And , \MATH denotes the set containing all leaf nodes explored from \MATH .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
And , \MATH denotes the set containing all leaf nodes explored from \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Given \MATH indicates the set of node pairs formed by paring nodes in \MATH with nodes in \MATH , we have : \MATH
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Given \MATH indicates the set of node pairs formed by paring nodes in \MATH with nodes in \MATH , we have : \MATH
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Given \MATH indicates the set of node pairs formed by paring nodes in \MATH with nodes in \MATH , we have : \MATH
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Given \MATH indicates the set of node pairs formed by paring nodes in \MATH with nodes in \MATH , we have : \MATH
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
Given \MATH indicates the set of node pairs formed by paring nodes in \MATH with nodes in \MATH , we have : \MATH
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
Given \MATH indicates the set of node pairs formed by paring nodes in \MATH with nodes in \MATH , we have : \MATH
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
Given \MATH indicates the set of node pairs formed by paring nodes in \MATH with nodes in \MATH , we have : \MATH
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
Given \MATH indicates the set of node pairs formed by paring nodes in \MATH with nodes in \MATH , we have : \MATH
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
Given \MATH indicates the set of node pairs formed by paring nodes in \MATH with nodes in \MATH , we have : \MATH
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
Given \MATH indicates the set of node pairs formed by paring nodes in \MATH with nodes in \MATH , we have : \MATH
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
Given \MATH indicates the set of node pairs formed by paring nodes in \MATH with nodes in \MATH , we have : \MATH
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
So , if \MATH and \MATH are roots of \MATH and \MATH respectively , \MATH will exactly be the entire search space \MATH .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
So , if \MATH and \MATH are roots of \MATH and \MATH respectively , \MATH will exactly be the entire search space \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Dividing the search space ( i.e. set of region pairs ) covered by \MATH is straightforward by utilizing the hierarchical structures \MATH , \MATH at certain nodes \MATH , \MATH .
#<struct ReadData::Alignment source_numbers="14", target_numbers="15,16", tag_name="wa">
Dividing the search space ( i.e. set of region pairs ) covered by \MATH is straightforward by utilizing the hierarchical structures \MATH , \MATH at certain nodes \MATH , \MATH .
#<struct ReadData::Alignment source_numbers="15", target_numbers="18", tag_name="wa">
Dividing the search space ( i.e. set of region pairs ) covered by \MATH is straightforward by utilizing the hierarchical structures \MATH , \MATH at certain nodes \MATH , \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Dividing the search space ( i.e. set of region pairs ) covered by \MATH is straightforward by utilizing the hierarchical structures \MATH , \MATH at certain nodes \MATH , \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
Dividing the search space ( i.e. set of region pairs ) covered by \MATH is straightforward by utilizing the hierarchical structures \MATH , \MATH at certain nodes \MATH , \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
Dividing the search space ( i.e. set of region pairs ) covered by \MATH is straightforward by utilizing the hierarchical structures \MATH , \MATH at certain nodes \MATH , \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
Dividing the search space ( i.e. set of region pairs ) covered by \MATH is straightforward by utilizing the hierarchical structures \MATH , \MATH at certain nodes \MATH , \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
Dividing the search space ( i.e. set of region pairs ) covered by \MATH is straightforward by utilizing the hierarchical structures \MATH , \MATH at certain nodes \MATH , \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
Dividing the search space ( i.e. set of region pairs ) covered by \MATH is straightforward by utilizing the hierarchical structures \MATH , \MATH at certain nodes \MATH , \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
Dividing the search space ( i.e. set of region pairs ) covered by \MATH is straightforward by utilizing the hierarchical structures \MATH , \MATH at certain nodes \MATH , \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="40", tag_name="wa">
Dividing the search space ( i.e. set of region pairs ) covered by \MATH is straightforward by utilizing the hierarchical structures \MATH , \MATH at certain nodes \MATH , \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="41", tag_name="wa">
Dividing the search space ( i.e. set of region pairs ) covered by \MATH is straightforward by utilizing the hierarchical structures \MATH , \MATH at certain nodes \MATH , \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="42", tag_name="wa">
Selecting which way to divide can be based on sizes of \MATH and \MATH .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Selecting which way to divide can be based on sizes of \MATH and \MATH .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
We select the larger one to be divided first .
#<struct ReadData::Alignment source_numbers="5,6,7", target_numbers="1", tag_name="wa">
We select the larger one to be divided first .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
An illustration of a branching step is given in Figure \REF .
#<struct ReadData::Alignment source_numbers="6", target_numbers="3", tag_name="wa">
An illustration of a branching step is given in Figure \REF .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
An illustration of a branching step is given in Figure \REF .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
An illustration of a branching step is given in Figure \REF .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
An illustration of a branching step is given in Figure \REF .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
An illustration of a branching step is given in Figure \REF .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
An essential requirement for branch-and-bound is the quality bounding function \MATH used to evaluate how necessary a part of the search space should be examined .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
An essential requirement for branch-and-bound is the quality bounding function \MATH used to evaluate how necessary a part of the search space should be examined .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
An essential requirement for branch-and-bound is the quality bounding function \MATH used to evaluate how necessary a part of the search space should be examined .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
An essential requirement for branch-and-bound is the quality bounding function \MATH used to evaluate how necessary a part of the search space should be examined .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
An essential requirement for branch-and-bound is the quality bounding function \MATH used to evaluate how necessary a part of the search space should be examined .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
An essential requirement for branch-and-bound is the quality bounding function \MATH used to evaluate how necessary a part of the search space should be examined .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
An essential requirement for branch-and-bound is the quality bounding function \MATH used to evaluate how necessary a part of the search space should be examined .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
An essential requirement for branch-and-bound is the quality bounding function \MATH used to evaluate how necessary a part of the search space should be examined .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
An essential requirement for branch-and-bound is the quality bounding function \MATH used to evaluate how necessary a part of the search space should be examined .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
An essential requirement for branch-and-bound is the quality bounding function \MATH used to evaluate how necessary a part of the search space should be examined .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
An essential requirement for branch-and-bound is the quality bounding function \MATH used to evaluate how necessary a part of the search space should be examined .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
An essential requirement for branch-and-bound is the quality bounding function \MATH used to evaluate how necessary a part of the search space should be examined .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
An essential requirement for branch-and-bound is the quality bounding function \MATH used to evaluate how necessary a part of the search space should be examined .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
An essential requirement for branch-and-bound is the quality bounding function \MATH used to evaluate how necessary a part of the search space should be examined .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
An essential requirement for branch-and-bound is the quality bounding function \MATH used to evaluate how necessary a part of the search space should be examined .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
Particularly , \MATH bounds the upper values of \MATH over a set of node pairs ( i.e. region pairs ) .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Particularly , \MATH bounds the upper values of \MATH over a set of node pairs ( i.e. region pairs ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Particularly , \MATH bounds the upper values of \MATH over a set of node pairs ( i.e. region pairs ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Assuming we are now evaluating the upper bound of \MATH over all region pairs in \MATH .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Assuming we are now evaluating the upper bound of \MATH over all region pairs in \MATH .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
Assuming we are now evaluating the upper bound of \MATH over all region pairs in \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Assuming we are now evaluating the upper bound of \MATH over all region pairs in \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Assuming we are now evaluating the upper bound of \MATH over all region pairs in \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Assuming we are now evaluating the upper bound of \MATH over all region pairs in \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Among several types of distance for estimating the similarity of two regions , we stick to Normalized Histogram Intersection ( NHI ) distance since it is well-balanced between computational efficiency and robustness~\cite{ESR} .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Among several types of distance for estimating the similarity of two regions , we stick to Normalized Histogram Intersection ( NHI ) distance since it is well-balanced between computational efficiency and robustness~\cite{ESR} .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
Among several types of distance for estimating the similarity of two regions , we stick to Normalized Histogram Intersection ( NHI ) distance since it is well-balanced between computational efficiency and robustness~\cite{ESR} .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
Among several types of distance for estimating the similarity of two regions , we stick to Normalized Histogram Intersection ( NHI ) distance since it is well-balanced between computational efficiency and robustness~\cite{ESR} .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
Among several types of distance for estimating the similarity of two regions , we stick to Normalized Histogram Intersection ( NHI ) distance since it is well-balanced between computational efficiency and robustness~\cite{ESR} .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Among several types of distance for estimating the similarity of two regions , we stick to Normalized Histogram Intersection ( NHI ) distance since it is well-balanced between computational efficiency and robustness~\cite{ESR} .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Among several types of distance for estimating the similarity of two regions , we stick to Normalized Histogram Intersection ( NHI ) distance since it is well-balanced between computational efficiency and robustness~\cite{ESR} .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
We then rely on NHI to define \MATH bounding the values of \MATH , with : \MATH
#<struct ReadData::Alignment source_numbers="2", target_numbers="3", tag_name="wa">
We then rely on NHI to define \MATH bounding the values of \MATH , with : \MATH
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
As a result , the bounding value \MATH over \MATH can be clearly observed as : \MATH
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
As a result , the bounding value \MATH over \MATH can be clearly observed as : \MATH
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
As a result , the bounding value \MATH over \MATH can be clearly observed as : \MATH
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
As a result , the bounding value \MATH over \MATH can be clearly observed as : \MATH
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
As a result , the bounding value \MATH over \MATH can be clearly observed as : \MATH
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
As a result , the bounding value \MATH over \MATH can be clearly observed as : \MATH
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
As a result , the bounding value \MATH over \MATH can be clearly observed as : \MATH
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
As a result , the bounding value \MATH over \MATH can be clearly observed as : \MATH
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
As a result , the bounding value \MATH over \MATH can be clearly observed as : \MATH
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
As a result , the bounding value \MATH over \MATH can be clearly observed as : \MATH
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
As a result , the bounding value \MATH over \MATH can be clearly observed as : \MATH
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
As a result , the bounding value \MATH over \MATH can be clearly observed as : \MATH
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
As a result , the bounding value \MATH over \MATH can be clearly observed as : \MATH
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
As a result , the bounding value \MATH over \MATH can be clearly observed as : \MATH
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
As a result , the bounding value \MATH over \MATH can be clearly observed as : \MATH
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
As a result , the bounding value \MATH over \MATH can be clearly observed as : \MATH
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
As a result , the bounding value \MATH over \MATH can be clearly observed as : \MATH
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
As a result , the bounding value \MATH over \MATH can be clearly observed as : \MATH
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
As a result , the bounding value \MATH over \MATH can be clearly observed as : \MATH
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
As a result , the bounding value \MATH over \MATH can be clearly observed as : \MATH
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
As a result , the bounding value \MATH over \MATH can be clearly observed as : \MATH
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
As a result , the bounding value \MATH over \MATH can be clearly observed as : \MATH
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
As a result , the bounding value \MATH over \MATH can be clearly observed as : \MATH
#<struct ReadData::Alignment source_numbers="", target_numbers="39", tag_name="wa">
We can efficiently evaluate \MATH for the set of region pairs \MATH because \MATH is relied only on histogram representation of single rectangular regions \MATH and \MATH .
#<struct ReadData::Alignment source_numbers="15", target_numbers="14", tag_name="wa">
We can efficiently evaluate \MATH for the set of region pairs \MATH because \MATH is relied only on histogram representation of single rectangular regions \MATH and \MATH .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
And , the normalization terms , which indicate the minimum number of visual words inside any member region of \MATH , \MATH , are computed once by using integral image technique .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
And , the normalization terms , which indicate the minimum number of visual words inside any member region of \MATH , \MATH , are computed once by using integral image technique .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Inspired by \CITE , we form the algorithm in best-first manner .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Inspired by \CITE , we form the algorithm in best-first manner .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Inspired by \CITE , we form the algorithm in best-first manner .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Inspired by \CITE , we form the algorithm in best-first manner .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
Inspired by \CITE , we form the algorithm in best-first manner .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
Inspired by \CITE , we form the algorithm in best-first manner .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
Inspired by \CITE , we form the algorithm in best-first manner .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Inspired by \CITE , we form the algorithm in best-first manner .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
Inspired by \CITE , we form the algorithm in best-first manner .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
Inspired by \CITE , we form the algorithm in best-first manner .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
Inspired by \CITE , we form the algorithm in best-first manner .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
Inspired by \CITE , we form the algorithm in best-first manner .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
Inspired by \CITE , we form the algorithm in best-first manner .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
Inspired by \CITE , we form the algorithm in best-first manner .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
Inspired by \CITE , we form the algorithm in best-first manner .
#<struct ReadData::Alignment source_numbers="", target_numbers="25", tag_name="wa">
Inspired by \CITE , we form the algorithm in best-first manner .
#<struct ReadData::Alignment source_numbers="", target_numbers="26", tag_name="wa">
Inspired by \CITE , we form the algorithm in best-first manner .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
Inspired by \CITE , we form the algorithm in best-first manner .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
Inspired by \CITE , we form the algorithm in best-first manner .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
Inspired by \CITE , we form the algorithm in best-first manner .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
Inspired by \CITE , we form the algorithm in best-first manner .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
Inspired by \CITE , we form the algorithm in best-first manner .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
Inspired by \CITE , we form the algorithm in best-first manner .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
Inspired by \CITE , we form the algorithm in best-first manner .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
Inspired by \CITE , we form the algorithm in best-first manner .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
Inspired by \CITE , we form the algorithm in best-first manner .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
Inspired by \CITE , we form the algorithm in best-first manner .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
Inspired by \CITE , we form the algorithm in best-first manner .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
The algorithm examines next the set having highest bounding value \MATH .
#<struct ReadData::Alignment source_numbers="3", target_numbers="13", tag_name="wa">
The algorithm examines next the set having highest bounding value \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
The algorithm examines next the set having highest bounding value \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
The algorithm examines next the set having highest bounding value \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
The algorithm examines next the set having highest bounding value \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
The algorithm examines next the set having highest bounding value \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
The algorithm examines next the set having highest bounding value \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
The algorithm examines next the set having highest bounding value \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
The algorithm examines next the set having highest bounding value \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
The algorithm examines next the set having highest bounding value \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
The algorithm examines next the set having highest bounding value \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
The algorithm examines next the set having highest bounding value \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
To obtain more than one region pair , we simply continue the loop in the Algorithm 1 until the expected number of region pairs \MATH have been reached .
#<struct ReadData::Alignment source_numbers="18", target_numbers="17", tag_name="wa">
To obtain more than one region pair , we simply continue the loop in the Algorithm 1 until the expected number of region pairs \MATH have been reached .
#<struct ReadData::Alignment source_numbers="26", target_numbers="24", tag_name="wa">
To obtain more than one region pair , we simply continue the loop in the Algorithm 1 until the expected number of region pairs \MATH have been reached .
#<struct ReadData::Alignment source_numbers="27", target_numbers="25", tag_name="wa">
To obtain more than one region pair , we simply continue the loop in the Algorithm 1 until the expected number of region pairs \MATH have been reached .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
To obtain more than one region pair , we simply continue the loop in the Algorithm 1 until the expected number of region pairs \MATH have been reached .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
To obtain more than one region pair , we simply continue the loop in the Algorithm 1 until the expected number of region pairs \MATH have been reached .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
To obtain more than one region pair , we simply continue the loop in the Algorithm 1 until the expected number of region pairs \MATH have been reached .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
There are two type of region set for organization .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
There are two type of region set for organization .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
As a result , we have the constraint ( b ) satisfied .
#<struct ReadData::Alignment source_numbers="11", target_numbers="9", tag_name="wa">
As a result , we have the constraint ( b ) satisfied .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
As a result , we have the constraint ( b ) satisfied .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
As a result , we have the constraint ( b ) satisfied .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
However , because we want to use all regions corresponding to all nodes throughout the tree as candidate item regions , the constraint ( a ) will be violated if we keep using the tree for the branch-and-bound based algorithm .
#<struct ReadData::Alignment source_numbers="38", target_numbers="", tag_name="wa">
The generated node is exactly the same as the non-leaf node it attach to , which now becomes a virtual node .
#<struct ReadData::Alignment source_numbers="12,13", target_numbers="13,14", tag_name="wa">
The generated node is exactly the same as the non-leaf node it attach to , which now becomes a virtual node .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
By doing that , we keep the spatial covering property of the orginal binary tree for the new hierarchical structure .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
By doing that , we keep the spatial covering property of the orginal binary tree for the new hierarchical structure .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
And , all non-leaf nodes will be taken into account as candidate item regions via their attachments .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
And , all non-leaf nodes will be taken into account as candidate item regions via their attachments .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
The new hierarchical structure therefore satisfy both the constraints ( a ) and ( b ) .
#<struct ReadData::Alignment source_numbers="16", target_numbers="8", tag_name="wa">
The new hierarchical structure therefore satisfy both the constraints ( a ) and ( b ) .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
The new hierarchical structure therefore satisfy both the constraints ( a ) and ( b ) .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
The new hierarchical structure therefore satisfy both the constraints ( a ) and ( b ) .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
The new hierarchical structure therefore satisfy both the constraints ( a ) and ( b ) .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
The new hierarchical structure therefore satisfy both the constraints ( a ) and ( b ) .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
The new hierarchical structure therefore satisfy both the constraints ( a ) and ( b ) .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
The new hierarchical structure therefore satisfy both the constraints ( a ) and ( b ) .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
An illustration is presented in Figure X .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
An illustration is presented in Figure X .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
An illustration is presented in Figure X .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
An illustration is presented in Figure X .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
An illustration is presented in Figure X .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
An illustration is presented in Figure X .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
An illustration is presented in Figure X .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
With a set containing regions of multiple images , we perform a two-stage organization procedure .
#<struct ReadData::Alignment source_numbers="4,5", target_numbers="4,5", tag_name="wa">
At the first stage , regions in each image are organized into a hierarchical structure as we presented above .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
At the first stage , regions in each image are organized into a hierarchical structure as we presented above .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
At the first stage , regions in each image are organized into a hierarchical structure as we presented above .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
At the first stage , regions in each image are organized into a hierarchical structure as we presented above .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
Given multiple hierarchical structures returned from the first stage , we use their root nodes as initial elements to construct an yet another hierarchical structure over them by divisive clustering .
#<struct ReadData::Alignment source_numbers="4", target_numbers="5", tag_name="wa">
Given multiple hierarchical structures returned from the first stage , we use their root nodes as initial elements to construct an yet another hierarchical structure over them by divisive clustering .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Given multiple hierarchical structures returned from the first stage , we use their root nodes as initial elements to construct an yet another hierarchical structure over them by divisive clustering .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
Given multiple hierarchical structures returned from the first stage , we use their root nodes as initial elements to construct an yet another hierarchical structure over them by divisive clustering .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Given multiple hierarchical structures returned from the first stage , we use their root nodes as initial elements to construct an yet another hierarchical structure over them by divisive clustering .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
Given multiple hierarchical structures returned from the first stage , we use their root nodes as initial elements to construct an yet another hierarchical structure over them by divisive clustering .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
Given multiple hierarchical structures returned from the first stage , we use their root nodes as initial elements to construct an yet another hierarchical structure over them by divisive clustering .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
Given multiple hierarchical structures returned from the first stage , we use their root nodes as initial elements to construct an yet another hierarchical structure over them by divisive clustering .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
Given multiple hierarchical structures returned from the first stage , we use their root nodes as initial elements to construct an yet another hierarchical structure over them by divisive clustering .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
Given multiple hierarchical structures returned from the first stage , we use their root nodes as initial elements to construct an yet another hierarchical structure over them by divisive clustering .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
Given multiple hierarchical structures returned from the first stage , we use their root nodes as initial elements to construct an yet another hierarchical structure over them by divisive clustering .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
Given multiple hierarchical structures returned from the first stage , we use their root nodes as initial elements to construct an yet another hierarchical structure over them by divisive clustering .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
Then , splits are peformed recursively as one moves down the hierarcy .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
Then , splits are peformed recursively as one moves down the hierarcy .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
Then , splits are peformed recursively as one moves down the hierarcy .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
Then , splits are peformed recursively as one moves down the hierarcy .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Then , splits are peformed recursively as one moves down the hierarcy .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
Then , splits are peformed recursively as one moves down the hierarcy .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
In each splitting step , the splitted set is divided into $k$ parts by using $k$-means clustering algorithm .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
Once the hierchical structure is completed , we then compute histogram representation for all of its non-leaf nodes .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Once the hierchical structure is completed , we then compute histogram representation for all of its non-leaf nodes .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Once the hierchical structure is completed , we then compute histogram representation for all of its non-leaf nodes .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
The value at each hitogram bin of a non-leaf nodes is the maximum of all values at the same bin of its child nodes .
#<struct ReadData::Alignment source_numbers="16,17,18", target_numbers="16,17,18", tag_name="wa">
The value at each hitogram bin of a non-leaf nodes is the maximum of all values at the same bin of its child nodes .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
The value at each hitogram bin of a non-leaf nodes is the maximum of all values at the same bin of its child nodes .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
This is to ensure the constraint ( b ) sastified .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
This is to ensure the constraint ( b ) sastified .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
This is to ensure the constraint ( b ) sastified .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
At last , by unifying results of both stages , we have a unique hierarchical structure over the set of regions of multiple images , which satisfies the both constraints .
#<struct ReadData::Alignment source_numbers="27", target_numbers="4", tag_name="wa">
At last , by unifying results of both stages , we have a unique hierarchical structure over the set of regions of multiple images , which satisfies the both constraints .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
At last , by unifying results of both stages , we have a unique hierarchical structure over the set of regions of multiple images , which satisfies the both constraints .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
At last , by unifying results of both stages , we have a unique hierarchical structure over the set of regions of multiple images , which satisfies the both constraints .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
We show an illustration in Figure Y .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
We show an illustration in Figure Y .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
We show an illustration in Figure Y .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
We show an illustration in Figure Y .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
We show an illustration in Figure Y .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Both structures are then becomes input for our proposed approach to find top region pairs with highest similarity scores for recommendation generation .
#<struct ReadData::Alignment source_numbers="4", target_numbers="3", tag_name="wa">
Both structures are then becomes input for our proposed approach to find top region pairs with highest similarity scores for recommendation generation .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Both structures are then becomes input for our proposed approach to find top region pairs with highest similarity scores for recommendation generation .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Both structures are then becomes input for our proposed approach to find top region pairs with highest similarity scores for recommendation generation .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
Both structures are then becomes input for our proposed approach to find top region pairs with highest similarity scores for recommendation generation .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
Both structures are then becomes input for our proposed approach to find top region pairs with highest similarity scores for recommendation generation .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
Both structures are then becomes input for our proposed approach to find top region pairs with highest similarity scores for recommendation generation .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
Note that , because the hierarchical for regions of images in the database is independent of query , we construct it only one time .
#<struct ReadData::Alignment source_numbers="15", target_numbers="5", tag_name="wa">
Note that , because the hierarchical for regions of images in the database is independent of query , we construct it only one time .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Note that , because the hierarchical for regions of images in the database is independent of query , we construct it only one time .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
Note that , because the hierarchical for regions of images in the database is independent of query , we construct it only one time .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
A recommendation is a good one if it exactly locates an item which exists in the database .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
A recommendation is a good one if it exactly locates an item which exists in the database .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
We call such recommendations as hit recommendations . Thus , a good recommendation system should accurately provide such hit recommendation to users .
#<struct ReadData::Alignment source_numbers="6", target_numbers="5", tag_name="wa">
We call such recommendations as hit recommendations . Thus , a good recommendation system should accurately provide such hit recommendation to users .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
We call such recommendations as hit recommendations . Thus , a good recommendation system should accurately provide such hit recommendation to users .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
We call such recommendations as hit recommendations . Thus , a good recommendation system should accurately provide such hit recommendation to users .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
We call such recommendations as hit recommendations . Thus , a good recommendation system should accurately provide such hit recommendation to users .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
We call such recommendations as hit recommendations . Thus , a good recommendation system should accurately provide such hit recommendation to users .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
We call such recommendations as hit recommendations . Thus , a good recommendation system should accurately provide such hit recommendation to users .
#<struct ReadData::Alignment source_numbers="18", target_numbers="", tag_name="wa">
We call such recommendations as hit recommendations . Thus , a good recommendation system should accurately provide such hit recommendation to users .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
We call such recommendations as hit recommendations . Thus , a good recommendation system should accurately provide such hit recommendation to users .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
We call such recommendations as hit recommendations . Thus , a good recommendation system should accurately provide such hit recommendation to users .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
We call such recommendations as hit recommendations . Thus , a good recommendation system should accurately provide such hit recommendation to users .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
We call such recommendations as hit recommendations . Thus , a good recommendation system should accurately provide such hit recommendation to users .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
More importantly , users always expect that hit recommendations are ranked higher than false recommendations ( if there are some of them ) on the list of all recommendations introduced by the system .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
More importantly , users always expect that hit recommendations are ranked higher than false recommendations ( if there are some of them ) on the list of all recommendations introduced by the system .
#<struct ReadData::Alignment source_numbers="27", target_numbers="", tag_name="wa">
More importantly , users always expect that hit recommendations are ranked higher than false recommendations ( if there are some of them ) on the list of all recommendations introduced by the system .
#<struct ReadData::Alignment source_numbers="29", target_numbers="", tag_name="wa">
More importantly , users always expect that hit recommendations are ranked higher than false recommendations ( if there are some of them ) on the list of all recommendations introduced by the system .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
More importantly , users always expect that hit recommendations are ranked higher than false recommendations ( if there are some of them ) on the list of all recommendations introduced by the system .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
Based on those insights , we evaluate Recommend-Me system using two evaluation metrics : precision on introducing recommendation and rank of the first hit recommendation on the list .
#<struct ReadData::Alignment source_numbers="26", target_numbers="7", tag_name="wa">
Based on those insights , we evaluate Recommend-Me system using two evaluation metrics : precision on introducing recommendation and rank of the first hit recommendation on the list .
#<struct ReadData::Alignment source_numbers="17,18", target_numbers="18,19", tag_name="wa">
Based on those insights , we evaluate Recommend-Me system using two evaluation metrics : precision on introducing recommendation and rank of the first hit recommendation on the list .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Based on those insights , we evaluate Recommend-Me system using two evaluation metrics : precision on introducing recommendation and rank of the first hit recommendation on the list .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
Based on those insights , we evaluate Recommend-Me system using two evaluation metrics : precision on introducing recommendation and rank of the first hit recommendation on the list .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
Based on those insights , we evaluate Recommend-Me system using two evaluation metrics : precision on introducing recommendation and rank of the first hit recommendation on the list .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
Based on those insights , we evaluate Recommend-Me system using two evaluation metrics : precision on introducing recommendation and rank of the first hit recommendation on the list .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
Based on those insights , we evaluate Recommend-Me system using two evaluation metrics : precision on introducing recommendation and rank of the first hit recommendation on the list .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Based on those insights , we evaluate Recommend-Me system using two evaluation metrics : precision on introducing recommendation and rank of the first hit recommendation on the list .
#<struct ReadData::Alignment source_numbers="", target_numbers="27", tag_name="wa">
Given an initial query image with ground-truth annotation indicates bounding box of an item known existed in the database , Recommend-Me is determined to precisely introduce recommendation if at least one of its recommendation is a hit recommendation .
#<struct ReadData::Alignment source_numbers="23", target_numbers="16", tag_name="wa">
Given an initial query image with ground-truth annotation indicates bounding box of an item known existed in the database , Recommend-Me is determined to precisely introduce recommendation if at least one of its recommendation is a hit recommendation .
#<struct ReadData::Alignment source_numbers="35", target_numbers="24", tag_name="wa">
Given an initial query image with ground-truth annotation indicates bounding box of an item known existed in the database , Recommend-Me is determined to precisely introduce recommendation if at least one of its recommendation is a hit recommendation .
#<struct ReadData::Alignment source_numbers="33", target_numbers="32", tag_name="wa">
Given an initial query image with ground-truth annotation indicates bounding box of an item known existed in the database , Recommend-Me is determined to precisely introduce recommendation if at least one of its recommendation is a hit recommendation .
#<struct ReadData::Alignment source_numbers="37", target_numbers="36", tag_name="wa">
Given an initial query image with ground-truth annotation indicates bounding box of an item known existed in the database , Recommend-Me is determined to precisely introduce recommendation if at least one of its recommendation is a hit recommendation .
#<struct ReadData::Alignment source_numbers="15", target_numbers="", tag_name="wa">
Given an initial query image with ground-truth annotation indicates bounding box of an item known existed in the database , Recommend-Me is determined to precisely introduce recommendation if at least one of its recommendation is a hit recommendation .
#<struct ReadData::Alignment source_numbers="16", target_numbers="", tag_name="wa">
Given an initial query image with ground-truth annotation indicates bounding box of an item known existed in the database , Recommend-Me is determined to precisely introduce recommendation if at least one of its recommendation is a hit recommendation .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
Given an initial query image with ground-truth annotation indicates bounding box of an item known existed in the database , Recommend-Me is determined to precisely introduce recommendation if at least one of its recommendation is a hit recommendation .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
Given an initial query image with ground-truth annotation indicates bounding box of an item known existed in the database , Recommend-Me is determined to precisely introduce recommendation if at least one of its recommendation is a hit recommendation .
#<struct ReadData::Alignment source_numbers="24", target_numbers="", tag_name="wa">
Given an initial query image with ground-truth annotation indicates bounding box of an item known existed in the database , Recommend-Me is determined to precisely introduce recommendation if at least one of its recommendation is a hit recommendation .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
Given an initial query image with ground-truth annotation indicates bounding box of an item known existed in the database , Recommend-Me is determined to precisely introduce recommendation if at least one of its recommendation is a hit recommendation .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
Given an initial query image with ground-truth annotation indicates bounding box of an item known existed in the database , Recommend-Me is determined to precisely introduce recommendation if at least one of its recommendation is a hit recommendation .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
Given an initial query image with ground-truth annotation indicates bounding box of an item known existed in the database , Recommend-Me is determined to precisely introduce recommendation if at least one of its recommendation is a hit recommendation .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
Given an initial query image with ground-truth annotation indicates bounding box of an item known existed in the database , Recommend-Me is determined to precisely introduce recommendation if at least one of its recommendation is a hit recommendation .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
We apply an approach used in Pascal VOC challenge to clarify whether a recommendation is a hit recommendation .
#<struct ReadData::Alignment source_numbers="4", target_numbers="1", tag_name="wa">
We apply an approach used in Pascal VOC challenge to clarify whether a recommendation is a hit recommendation .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
We apply an approach used in Pascal VOC challenge to clarify whether a recommendation is a hit recommendation .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
We apply an approach used in Pascal VOC challenge to clarify whether a recommendation is a hit recommendation .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
We apply an approach used in Pascal VOC challenge to clarify whether a recommendation is a hit recommendation .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
We apply an approach used in Pascal VOC challenge to clarify whether a recommendation is a hit recommendation .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
Because our target is not to improve search techniques but to facilitate query selection procedure , search performance simply relies on standard techniques if users take an recommendation as a search query .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
Because our target is not to improve search techniques but to facilitate query selection procedure , search performance simply relies on standard techniques if users take an recommendation as a search query .
#<struct ReadData::Alignment source_numbers="17", target_numbers="", tag_name="wa">
Because our target is not to improve search techniques but to facilitate query selection procedure , search performance simply relies on standard techniques if users take an recommendation as a search query .
#<struct ReadData::Alignment source_numbers="25", target_numbers="", tag_name="wa">
Because our target is not to improve search techniques but to facilitate query selection procedure , search performance simply relies on standard techniques if users take an recommendation as a search query .
#<struct ReadData::Alignment source_numbers="", target_numbers="24", tag_name="wa">
To evaluate the efficiency of Recommend-Me on finding \MATH region pairs with highest similarity scores , we compute the number of evaluation for the quality bounding function in the branch-and-bound algorithm .
#<struct ReadData::Alignment source_numbers="27", target_numbers="6", tag_name="wa">
To evaluate the efficiency of Recommend-Me on finding \MATH region pairs with highest similarity scores , we compute the number of evaluation for the quality bounding function in the branch-and-bound algorithm .
#<struct ReadData::Alignment source_numbers="28", target_numbers="12", tag_name="wa">
To evaluate the efficiency of Recommend-Me on finding \MATH region pairs with highest similarity scores , we compute the number of evaluation for the quality bounding function in the branch-and-bound algorithm .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
To evaluate the efficiency of Recommend-Me on finding \MATH region pairs with highest similarity scores , we compute the number of evaluation for the quality bounding function in the branch-and-bound algorithm .
#<struct ReadData::Alignment source_numbers="", target_numbers="28", tag_name="wa">
To evaluate the efficiency of Recommend-Me on finding \MATH region pairs with highest similarity scores , we compute the number of evaluation for the quality bounding function in the branch-and-bound algorithm .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
This number is then divided by the size of all possible region pairs formed by regions in the initial query image and regions in images of the database .
#<struct ReadData::Alignment source_numbers="2", target_numbers="39", tag_name="wa">
This number is then divided by the size of all possible region pairs formed by regions in the initial query image and regions in images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
This number is then divided by the size of all possible region pairs formed by regions in the initial query image and regions in images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
This number is then divided by the size of all possible region pairs formed by regions in the initial query image and regions in images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="30", tag_name="wa">
This number is then divided by the size of all possible region pairs formed by regions in the initial query image and regions in images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="31", tag_name="wa">
This number is then divided by the size of all possible region pairs formed by regions in the initial query image and regions in images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="32", tag_name="wa">
This number is then divided by the size of all possible region pairs formed by regions in the initial query image and regions in images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="33", tag_name="wa">
This number is then divided by the size of all possible region pairs formed by regions in the initial query image and regions in images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="34", tag_name="wa">
This number is then divided by the size of all possible region pairs formed by regions in the initial query image and regions in images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="35", tag_name="wa">
This number is then divided by the size of all possible region pairs formed by regions in the initial query image and regions in images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="36", tag_name="wa">
This number is then divided by the size of all possible region pairs formed by regions in the initial query image and regions in images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="37", tag_name="wa">
This number is then divided by the size of all possible region pairs formed by regions in the initial query image and regions in images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="38", tag_name="wa">
This number is then divided by the size of all possible region pairs formed by regions in the initial query image and regions in images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="40", tag_name="wa">
This number is then divided by the size of all possible region pairs formed by regions in the initial query image and regions in images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="41", tag_name="wa">
This number is then divided by the size of all possible region pairs formed by regions in the initial query image and regions in images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="42", tag_name="wa">
This number is then divided by the size of all possible region pairs formed by regions in the initial query image and regions in images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="43", tag_name="wa">
This number is then divided by the size of all possible region pairs formed by regions in the initial query image and regions in images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="44", tag_name="wa">
This number is then divided by the size of all possible region pairs formed by regions in the initial query image and regions in images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="45", tag_name="wa">
This number is then divided by the size of all possible region pairs formed by regions in the initial query image and regions in images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="46", tag_name="wa">
This number is then divided by the size of all possible region pairs formed by regions in the initial query image and regions in images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="47", tag_name="wa">
This number is then divided by the size of all possible region pairs formed by regions in the initial query image and regions in images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="48", tag_name="wa">
This number is then divided by the size of all possible region pairs formed by regions in the initial query image and regions in images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="49", tag_name="wa">
This number is then divided by the size of all possible region pairs formed by regions in the initial query image and regions in images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="50", tag_name="wa">
This number is then divided by the size of all possible region pairs formed by regions in the initial query image and regions in images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="51", tag_name="wa">
This number is then divided by the size of all possible region pairs formed by regions in the initial query image and regions in images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="52", tag_name="wa">
This number is then divided by the size of all possible region pairs formed by regions in the initial query image and regions in images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="53", tag_name="wa">
This number is then divided by the size of all possible region pairs formed by regions in the initial query image and regions in images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="54", tag_name="wa">
This number is then divided by the size of all possible region pairs formed by regions in the initial query image and regions in images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="55", tag_name="wa">
This number is then divided by the size of all possible region pairs formed by regions in the initial query image and regions in images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="56", tag_name="wa">
This number is then divided by the size of all possible region pairs formed by regions in the initial query image and regions in images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="57", tag_name="wa">
This number is then divided by the size of all possible region pairs formed by regions in the initial query image and regions in images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="58", tag_name="wa">
This number is then divided by the size of all possible region pairs formed by regions in the initial query image and regions in images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="59", tag_name="wa">
This number is then divided by the size of all possible region pairs formed by regions in the initial query image and regions in images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="60", tag_name="wa">
This number is then divided by the size of all possible region pairs formed by regions in the initial query image and regions in images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="61", tag_name="wa">
This number is then divided by the size of all possible region pairs formed by regions in the initial query image and regions in images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="62", tag_name="wa">
This number is then divided by the size of all possible region pairs formed by regions in the initial query image and regions in images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="63", tag_name="wa">
This number is then divided by the size of all possible region pairs formed by regions in the initial query image and regions in images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="64", tag_name="wa">
This number is then divided by the size of all possible region pairs formed by regions in the initial query image and regions in images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="65", tag_name="wa">
This number is then divided by the size of all possible region pairs formed by regions in the initial query image and regions in images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="66", tag_name="wa">
This number is then divided by the size of all possible region pairs formed by regions in the initial query image and regions in images of the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="67", tag_name="wa">
The fraction is reported as the efficiency improvement of Recommend-Me .
#<struct ReadData::Alignment source_numbers="2", target_numbers="2", tag_name="wa">
The fraction is reported as the efficiency improvement of Recommend-Me .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
The fraction is reported as the efficiency improvement of Recommend-Me .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
The fraction is reported as the efficiency improvement of Recommend-Me .
#<struct ReadData::Alignment source_numbers="", target_numbers="3", tag_name="wa">
The fraction is reported as the efficiency improvement of Recommend-Me .
#<struct ReadData::Alignment source_numbers="", target_numbers="4", tag_name="wa">
The fraction is reported as the efficiency improvement of Recommend-Me .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
Note that , regions in images are pre-selected as in Step 1 of our framework .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
Visual words in images are located by dense grid sampling and Different-of-Gaussian( DoG ) detector .
#<struct ReadData::Alignment source_numbers="12", target_numbers="16", tag_name="wa">
Visual words in images are located by dense grid sampling and Different-of-Gaussian( DoG ) detector .
#<struct ReadData::Alignment source_numbers="13", target_numbers="17", tag_name="wa">
Visual words in images are located by dense grid sampling and Different-of-Gaussian( DoG ) detector .
#<struct ReadData::Alignment source_numbers="15", target_numbers="19", tag_name="wa">
Visual words in images are located by dense grid sampling and Different-of-Gaussian( DoG ) detector .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
Visual words in images are located by dense grid sampling and Different-of-Gaussian( DoG ) detector .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Visual words in images are located by dense grid sampling and Different-of-Gaussian( DoG ) detector .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
Visual words in images are located by dense grid sampling and Different-of-Gaussian( DoG ) detector .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
A codebook of 2000 visual words is built using standard K-Means algorithm .
#<struct ReadData::Alignment source_numbers="6,7", target_numbers="6,7", tag_name="wa">
%to cluster points on a set of random images .% Additionally , the set of interest points obtained by DoG in the query image is used to remove regions without any of such points inside .
#<struct ReadData::Alignment source_numbers="31", target_numbers="16", tag_name="wa">
%to cluster points on a set of random images .% Additionally , the set of interest points obtained by DoG in the query image is used to remove regions without any of such points inside .
#<struct ReadData::Alignment source_numbers="21", target_numbers="20", tag_name="wa">
%to cluster points on a set of random images .% Additionally , the set of interest points obtained by DoG in the query image is used to remove regions without any of such points inside .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
This helps us to eliminate less meaningful regions such as a portion of the sky , solid color regions , etc for recommendation .
#<struct ReadData::Alignment source_numbers="22", target_numbers="21", tag_name="wa">
This helps us to eliminate less meaningful regions such as a portion of the sky , solid color regions , etc for recommendation .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
This helps us to eliminate less meaningful regions such as a portion of the sky , solid color regions , etc for recommendation .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
This helps us to eliminate less meaningful regions such as a portion of the sky , solid color regions , etc for recommendation .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
This helps us to eliminate less meaningful regions such as a portion of the sky , solid color regions , etc for recommendation .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
This helps us to eliminate less meaningful regions such as a portion of the sky , solid color regions , etc for recommendation .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
This helps us to eliminate less meaningful regions such as a portion of the sky , solid color regions , etc for recommendation .
#<struct ReadData::Alignment source_numbers="", target_numbers="17", tag_name="wa">
This helps us to eliminate less meaningful regions such as a portion of the sky , solid color regions , etc for recommendation .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
This helps us to eliminate less meaningful regions such as a portion of the sky , solid color regions , etc for recommendation .
#<struct ReadData::Alignment source_numbers="", target_numbers="19", tag_name="wa">
This helps us to eliminate less meaningful regions such as a portion of the sky , solid color regions , etc for recommendation .
#<struct ReadData::Alignment source_numbers="", target_numbers="20", tag_name="wa">
As mentioned above , we use the approach introduced in \CITE on different color channel for region selection .
#<struct ReadData::Alignment source_numbers="5,6", target_numbers="5,6", tag_name="wa">
As mentioned above , we use the approach introduced in \CITE on different color channel for region selection .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
In this experiment , we used two color channels which are RGB and Hue , since regions generated on those channels can cover 99 .72\% area of the annotated item regions in our dataset .
#<struct ReadData::Alignment source_numbers="27", target_numbers="15", tag_name="wa">
In this experiment , we used two color channels which are RGB and Hue , since regions generated on those channels can cover 99 .72\% area of the annotated item regions in our dataset .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
In this experiment , we used two color channels which are RGB and Hue , since regions generated on those channels can cover 99 .72\% area of the annotated item regions in our dataset .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
In this experiment , we used two color channels which are RGB and Hue , since regions generated on those channels can cover 99 .72\% area of the annotated item regions in our dataset .
#<struct ReadData::Alignment source_numbers="", target_numbers="9", tag_name="wa">
In this experiment , we used two color channels which are RGB and Hue , since regions generated on those channels can cover 99 .72\% area of the annotated item regions in our dataset .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
A virtual root node is created to compose two color-dependent binary trees into one unique binary tree for each image .
#<struct ReadData::Alignment source_numbers="4", target_numbers="4", tag_name="wa">
A virtual root node is created to compose two color-dependent binary trees into one unique binary tree for each image .
#<struct ReadData::Alignment source_numbers="5", target_numbers="5", tag_name="wa">
Given the set of regions in the initial query image , we build a graph in which two regions are connected if they highly overlap each other ( we use the approach of Pascal VOC with tighter threshold , 0 .8 ) .
#<struct ReadData::Alignment source_numbers="12,13", target_numbers="12,13", tag_name="wa">
Given the set of regions in the initial query image , we build a graph in which two regions are connected if they highly overlap each other ( we use the approach of Pascal VOC with tighter threshold , 0 .8 ) .
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
Given the set of regions in the initial query image , we build a graph in which two regions are connected if they highly overlap each other ( we use the approach of Pascal VOC with tighter threshold , 0 .8 ) .
#<struct ReadData::Alignment source_numbers="", target_numbers="23", tag_name="wa">
Bron-Kerbosch algorithm is then applied to find all maximal cliques in the graph .
#<struct ReadData::Alignment source_numbers="2", target_numbers="3", tag_name="wa">
Bron-Kerbosch algorithm is then applied to find all maximal cliques in the graph .
#<struct ReadData::Alignment source_numbers="4", target_numbers="5", tag_name="wa">
One clique is one group of regions .
#<struct ReadData::Alignment source_numbers="2,3", target_numbers="2,3", tag_name="wa">
Figure \REF shows our evaluation results .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
Figure \REF shows our evaluation results .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
The reported numbers of precision , rank of the first hit recommendation as well as efficiency improvement are averaged as we perform Recommend-Me with 375 different initial query images and an individual value of \MATH .
#<struct ReadData::Alignment source_numbers="18", target_numbers="15", tag_name="wa">
The reported numbers of precision , rank of the first hit recommendation as well as efficiency improvement are averaged as we perform Recommend-Me with 375 different initial query images and an individual value of \MATH .
#<struct ReadData::Alignment source_numbers="3", target_numbers="16", tag_name="wa">
The reported numbers of precision , rank of the first hit recommendation as well as efficiency improvement are averaged as we perform Recommend-Me with 375 different initial query images and an individual value of \MATH .
#<struct ReadData::Alignment source_numbers="35", target_numbers="30", tag_name="wa">
The reported numbers of precision , rank of the first hit recommendation as well as efficiency improvement are averaged as we perform Recommend-Me with 375 different initial query images and an individual value of \MATH .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
The reported numbers of precision , rank of the first hit recommendation as well as efficiency improvement are averaged as we perform Recommend-Me with 375 different initial query images and an individual value of \MATH .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
The reported numbers of precision , rank of the first hit recommendation as well as efficiency improvement are averaged as we perform Recommend-Me with 375 different initial query images and an individual value of \MATH .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
The reported numbers of precision , rank of the first hit recommendation as well as efficiency improvement are averaged as we perform Recommend-Me with 375 different initial query images and an individual value of \MATH .
#<struct ReadData::Alignment source_numbers="14", target_numbers="", tag_name="wa">
The reported numbers of precision , rank of the first hit recommendation as well as efficiency improvement are averaged as we perform Recommend-Me with 375 different initial query images and an individual value of \MATH .
#<struct ReadData::Alignment source_numbers="19", target_numbers="", tag_name="wa">
The reported numbers of precision , rank of the first hit recommendation as well as efficiency improvement are averaged as we perform Recommend-Me with 375 different initial query images and an individual value of \MATH .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
The reported numbers of precision , rank of the first hit recommendation as well as efficiency improvement are averaged as we perform Recommend-Me with 375 different initial query images and an individual value of \MATH .
#<struct ReadData::Alignment source_numbers="21", target_numbers="", tag_name="wa">
The reported numbers of precision , rank of the first hit recommendation as well as efficiency improvement are averaged as we perform Recommend-Me with 375 different initial query images and an individual value of \MATH .
#<struct ReadData::Alignment source_numbers="23", target_numbers="", tag_name="wa">
The reported numbers of precision , rank of the first hit recommendation as well as efficiency improvement are averaged as we perform Recommend-Me with 375 different initial query images and an individual value of \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="10", tag_name="wa">
The reported numbers of precision , rank of the first hit recommendation as well as efficiency improvement are averaged as we perform Recommend-Me with 375 different initial query images and an individual value of \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
The reported numbers of precision , rank of the first hit recommendation as well as efficiency improvement are averaged as we perform Recommend-Me with 375 different initial query images and an individual value of \MATH .
#<struct ReadData::Alignment source_numbers="", target_numbers="18", tag_name="wa">
The results show that Recommend-Me can successfully introduce hit recommendations to users with high precision ( approximately 80 .27\% ) .
#<struct ReadData::Alignment source_numbers="7", target_numbers="6", tag_name="wa">
The results show that Recommend-Me can successfully introduce hit recommendations to users with high precision ( approximately 80 .27\% ) .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
On the returned list of all recommendations , a hit recommendation usually takes the first two places on the list .
#<struct ReadData::Alignment source_numbers="10", target_numbers="9", tag_name="wa">
On the returned list of all recommendations , a hit recommendation usually takes the first two places on the list .
#<struct ReadData::Alignment source_numbers="12", target_numbers="11", tag_name="wa">
On the returned list of all recommendations , a hit recommendation usually takes the first two places on the list .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
We observed that there are two types of false recommendations on the top places of the list .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
We observed that there are two types of false recommendations on the top places of the list .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
We observed that there are two types of false recommendations on the top places of the list .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
We observed that there are two types of false recommendations on the top places of the list .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
We observed that there are two types of false recommendations on the top places of the list .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
We observed that there are two types of false recommendations on the top places of the list .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
We observed that there are two types of false recommendations on the top places of the list .
#<struct ReadData::Alignment source_numbers="", target_numbers="7", tag_name="wa">
The first type consists background regions ( e.g. trees , buildings , roads ) which are easily found in many images .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
The second type is the items lacking of manual annotation such as windows , cars and humans .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
However , if users are interested in using them as hints to explore the database , they are still very much helpful .
#<struct ReadData::Alignment source_numbers="17,18", target_numbers="17,18,19", tag_name="wa">
However , if users are interested in using them as hints to explore the database , they are still very much helpful .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
By increasing \MATH , we obtain more region pairs with sufficient hight similarity scores .
#<struct ReadData::Alignment source_numbers="5", target_numbers="6", tag_name="wa">
By increasing \MATH , we obtain more region pairs with sufficient hight similarity scores .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
By increasing \MATH , we obtain more region pairs with sufficient hight similarity scores .
#<struct ReadData::Alignment source_numbers="", target_numbers="5", tag_name="wa">
By increasing \MATH , we obtain more region pairs with sufficient hight similarity scores .
#<struct ReadData::Alignment source_numbers="", target_numbers="12", tag_name="wa">
It brings more chances to get region pairs of the annotated item , thus improves the precision .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
It brings more chances to get region pairs of the annotated item , thus improves the precision .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
It brings more chances to get region pairs of the annotated item , thus improves the precision .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
However , the trade-off is that more unexpected items are also returned .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
This results in a drop of average rank of the first hit recommendation .
#<struct ReadData::Alignment source_numbers="4,5", target_numbers="4,5", tag_name="wa">
When \MATH increases from 2000 to 10000 , the precision also increases from 74 .67\% to 81 .97\% ; meanwhile , the average rank of the first hit recommendation drops to 2 .27 from 1 .78 .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
It is worth noting that keeping inreasing \MATH may not always give better precision since precision relies on not only \MATH but also the robustness of the region comparision techniques .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
It is worth noting that keeping inreasing \MATH may not always give better precision since precision relies on not only \MATH but also the robustness of the region comparision techniques .
#<struct ReadData::Alignment source_numbers="28", target_numbers="", tag_name="wa">
It is worth noting that keeping inreasing \MATH may not always give better precision since precision relies on not only \MATH but also the robustness of the region comparision techniques .
#<struct ReadData::Alignment source_numbers="", target_numbers="6", tag_name="wa">
It is worth noting that keeping inreasing \MATH may not always give better precision since precision relies on not only \MATH but also the robustness of the region comparision techniques .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
It is worth noting that keeping inreasing \MATH may not always give better precision since precision relies on not only \MATH but also the robustness of the region comparision techniques .
#<struct ReadData::Alignment source_numbers="", target_numbers="29", tag_name="wa">
Recommend-Me cannot provide any hit recommendation for around 20\% of initial query images due to the fact that our region comparision technique cannot deal with significant variations of items .
#<struct ReadData::Alignment source_numbers="27,28", target_numbers="28,29,30", tag_name="wa">
Recommend-Me cannot provide any hit recommendation for around 20\% of initial query images due to the fact that our region comparision technique cannot deal with significant variations of items .
#<struct ReadData::Alignment source_numbers="20", target_numbers="", tag_name="wa">
Recommend-Me cannot provide any hit recommendation for around 20\% of initial query images due to the fact that our region comparision technique cannot deal with significant variations of items .
#<struct ReadData::Alignment source_numbers="", target_numbers="21", tag_name="wa">
It is the decline of efficiency improvement of Recommend-Me .
#<struct ReadData::Alignment source_numbers="3,4", target_numbers="3,4,5", tag_name="wa">
This is because the branch-and-bound algorithm has to visit more parts of the total search space in order to find extra local optimals .
#<struct ReadData::Alignment source_numbers="22", target_numbers="", tag_name="wa">
This is because the branch-and-bound algorithm has to visit more parts of the total search space in order to find extra local optimals .
#<struct ReadData::Alignment source_numbers="", target_numbers="22", tag_name="wa">
Its superiority is important for practical applications .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
Its superiority is important for practical applications .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
Its superiority is important for practical applications .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
Its superiority is important for practical applications .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
Figure \REF presents examples of hit recommendations returned by our Recommend-Me .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
Figure \REF presents examples of hit recommendations returned by our Recommend-Me .
#<struct ReadData::Alignment source_numbers="9", target_numbers="", tag_name="wa">
Figure \REF presents examples of hit recommendations returned by our Recommend-Me .
#<struct ReadData::Alignment source_numbers="10", target_numbers="", tag_name="wa">
Figure \REF presents examples of hit recommendations returned by our Recommend-Me .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
In this paper , we introduced a new system , named Recommend-Me , for visual query suggestion .
#<struct ReadData::Alignment source_numbers="9", target_numbers="3", tag_name="wa">
In this paper , we introduced a new system , named Recommend-Me , for visual query suggestion .
#<struct ReadData::Alignment source_numbers="12", target_numbers="6", tag_name="wa">
In this paper , we introduced a new system , named Recommend-Me , for visual query suggestion .
#<struct ReadData::Alignment source_numbers="17", target_numbers="12", tag_name="wa">
In this paper , we introduced a new system , named Recommend-Me , for visual query suggestion .
#<struct ReadData::Alignment source_numbers="0", target_numbers="", tag_name="wa">
In this paper , we introduced a new system , named Recommend-Me , for visual query suggestion .
#<struct ReadData::Alignment source_numbers="1", target_numbers="", tag_name="wa">
In this paper , we introduced a new system , named Recommend-Me , for visual query suggestion .
#<struct ReadData::Alignment source_numbers="2", target_numbers="", tag_name="wa">
In this paper , we introduced a new system , named Recommend-Me , for visual query suggestion .
#<struct ReadData::Alignment source_numbers="3", target_numbers="", tag_name="wa">
In this paper , we introduced a new system , named Recommend-Me , for visual query suggestion .
#<struct ReadData::Alignment source_numbers="4", target_numbers="", tag_name="wa">
In this paper , we introduced a new system , named Recommend-Me , for visual query suggestion .
#<struct ReadData::Alignment source_numbers="5", target_numbers="", tag_name="wa">
In this paper , we introduced a new system , named Recommend-Me , for visual query suggestion .
#<struct ReadData::Alignment source_numbers="6", target_numbers="", tag_name="wa">
In this paper , we introduced a new system , named Recommend-Me , for visual query suggestion .
#<struct ReadData::Alignment source_numbers="7", target_numbers="", tag_name="wa">
In this paper , we introduced a new system , named Recommend-Me , for visual query suggestion .
#<struct ReadData::Alignment source_numbers="8", target_numbers="", tag_name="wa">
In this paper , we introduced a new system , named Recommend-Me , for visual query suggestion .
#<struct ReadData::Alignment source_numbers="", target_numbers="0", tag_name="wa">
In this paper , we introduced a new system , named Recommend-Me , for visual query suggestion .
#<struct ReadData::Alignment source_numbers="", target_numbers="1", tag_name="wa">
In this paper , we introduced a new system , named Recommend-Me , for visual query suggestion .
#<struct ReadData::Alignment source_numbers="", target_numbers="2", tag_name="wa">
In this paper , we introduced a new system , named Recommend-Me , for visual query suggestion .
#<struct ReadData::Alignment source_numbers="", target_numbers="8", tag_name="wa">
Given an initial query image and a retrieved database , Recommend-Me introduces recommendations that imposes which and how frequent items in the initial query image appear in the database .
#<struct ReadData::Alignment source_numbers="11", target_numbers="", tag_name="wa">
Given an initial query image and a retrieved database , Recommend-Me introduces recommendations that imposes which and how frequent items in the initial query image appear in the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="11", tag_name="wa">
Given an initial query image and a retrieved database , Recommend-Me introduces recommendations that imposes which and how frequent items in the initial query image appear in the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="15", tag_name="wa">
Given an initial query image and a retrieved database , Recommend-Me introduces recommendations that imposes which and how frequent items in the initial query image appear in the database .
#<struct ReadData::Alignment source_numbers="", target_numbers="16", tag_name="wa">
An efficient solution to make Recommend-Me practical is presented .
#<struct ReadData::Alignment source_numbers="7", target_numbers="7,8", tag_name="wa">
To the best of our knowledge , Recommend-Me is the first attempt toward its targeted suggestion scheme .
#<struct ReadData::Alignment source_numbers="12", target_numbers="", tag_name="wa">
To the best of our knowledge , Recommend-Me is the first attempt toward its targeted suggestion scheme .
#<struct ReadData::Alignment source_numbers="13", target_numbers="", tag_name="wa">
To the best of our knowledge , Recommend-Me is the first attempt toward its targeted suggestion scheme .
#<struct ReadData::Alignment source_numbers="", target_numbers="13", tag_name="wa">
To the best of our knowledge , Recommend-Me is the first attempt toward its targeted suggestion scheme .
#<struct ReadData::Alignment source_numbers="", target_numbers="14", tag_name="wa">
