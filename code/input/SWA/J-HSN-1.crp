0
<document>
<document>
1
<abstract>
<abstract>
2
<p>
<p>
3
While word segmentation is a necessary step to process languages like Chinese and Japanese , its effects on Statistical Machine Translation ( SMT ) have not been discussed intensively in such languages .
While word segmentation is necessary for processing the Chinese and Japanese languages , its effects on Statistical Machine Translation ( SMT ) have not yet been thoroughly discussed for such languages .
4
In this paper , we investigate the effects of word segmentation methods on SMT , by comparing evaluation results of translation outputs while varying word segmentation methods .
In this paper , we investigate the effects of word segmentation methods on SMT , by comparing the evaluation results of the translation outputs , while varying word segmentation methods .
5
Additionally , meta-evaluations of evaluation metrics are also provided to investigate validity of the metrics .
Additionally , meta-evaluations of evaluation metrics are also provided to investigate the validity of the metrics .
6
The experiments revealed that supervised morphological analyzers were competitive , and considerably better than an unsupervised analyzer and a heuristic segmentation method .
The experimental results confirmed that supervised morphological analyzers were competitive with , and performed considerably better than an unsupervised analyzer and a heuristic segmentation method .
7
However , a character-based segmentation has achieved 10 .27 positive and 1 .95 negative differences in word-based and character-based BLEU , depending on corpus sizes and domains .
However , a character-based segmentation achieved 10 .27 positive and 1 .95 negative differences in word-based and character-based BLEU , depending on the corpus sizes and domains .
8
For this result we discuss the problem of the comparability of evaluation metrics and the possibility of better word segmentation than popular supervised morphological analyzers .
In conclusion , we discuss the problem of the comparability of evaluation metrics , and consider ways of improving word segmentation more than popular supervised morphological analyzers .
9
</p>
</p>
10
<section label = " Introduction’’>
<section label = " Introduction’’>
11
<p>
<p>
12
Several natural languages like Chinese and Japanese do not have to put spaces between words in their written forms .
Several languages , including Chinese and Japanese , do not require spaces between words , in their written forms .
13
In order to process such languages , we need to tokenize each sentence .
In order to process such languages , we need to tokenize each sentence .
14
This process is called word segmentation .
This process is called word segmentation .
15
Since the process is fundamental and indispensable , we need to explore how word segmentation affects Natural Language Processing applications .
Since word segmentation is a fundamental process , and is therefore indispensable , it is important that we explore how word segmentation affects Natural Language Processing applications .
16
</p>
</p>
17
<p>
<p>
18
Therefore , we investigate how Japanese word segmentation affects on SMT between English and Japanese , by comparing various word segmentation methods and evaluation metrics .
Thus , we investigate how Japanese word segmentation affects SMT between English and Japanese , by comparing various word segmentation methods and evaluation metrics .
19
The word segmentation methods includes both standard Japanese morphological analyzers and several heuristic methods .
The word segmentation methods include both standard Japanese morphological analyzers and several heuristic methods .
20
We also examine an unsupervised morphological analyzer and its results .
In addition , we examine an unsupervised morphological analyzer , and its results .
21
In addition , we focus on the meta-evaluation of the current evaluation metrics and find whether the metrics are consistent or not , when we vary word segmentation methods .
We focus on the meta-evaluation of the current evaluation metrics and determine whether the metrics are consistent or not , when we vary word segmentation methods .
22
</p>
</p>
23
</section>
</section>
24
<section label = " Related works’’>
<section label = " Related works’’>
25
<p>
<p>
26
Al-Haj and Lavie ( 2012 ) compared 12 heuristic word segmentation methods based on outputs of a standard Arabic POS tagger , and found the optimum combination in terms of BLEU on English-Arabic SMT .
Al-Haj and Lavie ( 2012 ) compared 12 heuristic word segmentation methods based on the outputs of a standard Arabic POS tagger , and found the optimum combination in terms of BLEU on English-Arabic SMT .
27
They acquired the 2 .3 score improvement from the worst to the best combinations .
They acquired a 2 .3 score improvement in comparing the worst to best combinations .
28
</p>
</p>
29
<p>
<p>
30
Wang et al.
Wang et al.
31
( 2010 ) suggested a new short unit word segmentation standard in Chinese which defines a more frequent string subset as a word .
( 2010 ) suggested a new short unit word segmentation standard in Chinese , which defines a more frequent string subset as a word .
32
For instance , They separated one word " 全球化 globalization " into two words " 全球 global " and " 化 -lization " .
For instance , one word “全球化 globalization” was separated into two words “全球 global” and “化 -lization” .
33
By this standard , they obtained 1 .0 BLEU score improvement within Chinese-Japanese SMT .
By this standard , they obtained 1 .0 BLEU score improvement within Chinese-Japanese SMT .
34
</p>
</p>
35
<p>
<p>
36
Though , they have not discussed about BLEU is a good metric for such an evaluation of word segmentation .
However , it has not yet been discussed whether BLEU is a good metric for such an evaluation of word segmentation .
37
In addition , comparison of morphological analyzers are necessary because different analyzers produce different outputs to SMT .
In addition , comparing morphological analyzers is necessary , because different analyzers produce different outputs to SMT .
38
Therefore , we conduct several translation tasks between English and Japanese .
We therefore conduct several translation tasks between English and Japanese .
39
We measure the qualities of Japanese morphological analyzers and compare them with other word segmentation methods .
We measure the qualities of Japanese morphological analyzers and compare them with other word segmentation methods .
40
We also investigate consistencies of evaluation metrics by comparing results .
We also investigate consistencies of evaluation metrics by comparing the results .
41
</p>
</p>
42
</section>
</section>
43
<section label = " Experimental setup’’>
<section label = " Experimental setup’’>
44
<p>
<p>
45
This work aims to empirically compare representative word segmentation methods in terms of SMT quality .
This work aims at empirically comparing representative word segmentation methods in terms of the SMT quality .
46
The following experiments are designed in order to answer these questions :
The following experiments are designed in order to answer these questions :
47
</p>
</p>
48
<p>
<p>
49
- How a variety of word segmentation methods ( supervised morphological analysis , unsupervised segmentation , and heuristic methods ) affect SMT evaluation metrics , depending on corpus sizes and domains .
- How a variety of word segmentation methods ( supervised morphological analysis , unsupervised segmentation , and heuristic methods ) affects the SMT evaluation metrics , depending on the corpus sizes and domains .
50
</p>
</p>
51
<p>
<p>
52
- Whether or not SMT evaluation metrics provide a consistent measure while varying word segmentation methods .
- Whether or not SMT evaluation metrics provide a consistent measure , while varying word segmentation methods .
53
</p>
</p>
54
<p>
<p>
55
We setup word segmentation methods , corpora , and evaluation metrics as three parameters of our experiments to see the effects of Japanese word segmentation on SMT .
We set up word segmentation methods , corpora , and evaluation metrics , as the three parameters for our experiments , in order to observe the effects of Japanese word segmentation on SMT .
56
</p>
</p>
57
<subsection label = " Word segmentation methods’’>
<subsection label = " Word segmentation methods’’>
58
<p>
<p>
59
As shown in Table 1 , the following word segmentation methods output delimiters ( " | " represents a delimiter ) for a given input character sequence .
As shown in Table 1 , the following word segmentation methods output delimiters ( “|” represents a delimiter ) for a given input character sequence .
60
</p>
</p>
61
<subsubsection label = " Morphological analyzer’’>
<subsubsection label = " Morphological analyzer’’>
62
<p>
<p>
63
The most popular method for Japanese word segmentation is to apply a morphological analyzer to obtain morpheme-based segmentation .
The most popular method for Japanese word segmentation is to apply a morphological analyzer to obtain morpheme-based segmentation .
64
It is , however , not clear which analyzer works better for the SMT task than the other analyzers .
It is ; however , unclear as to which analyzer works better for the SMT task .
65
Therefore , we use four representative morphological analyzers and compare them :
Therefore , we use four representative morphological analyzers and compare them :
66
</p>
</p>
67
<p>
<p>
68
- KyTea predicts word segmentation delimiters by pointwise prediction ( Neubig et al. , 2011 ) , using linear Support Vector Machine or logistic regression .
- KyTea predicts word segmentation delimiters by pointwise prediction ( Neubig et al. , 2011 ) , using linear Support Vector Machine or logistic regression .
69
</p>
</p>
70
<p>
<p>
71
- MeCab regards word segmentation as a sequence labeling problem .
- MeCab regards word segmentation as a sequence labeling problem .
72
It uses Conditional Random Field for learning ( Kudo et al. , 2004 ) .
It uses Conditional Random Field for learning ( Kudo et al. , 2004 ) .
73
</p>
</p>
74
<p>
<p>
75
- JUMAN also regards word segmentation as a sequence labeling , but it decides the minimum cost paths without machine learning , from segmentation and association costs in human annotated lexicons and automatically generated Web lexicons .
- JUMAN also regards word segmentation as a sequence labeling problem , but it decides the minimum cost paths without machine learning , from segmentation and association costs in human annotated lexicons and automatically generated Web lexicons .
76
</p>
</p>
77
<p>
<p>
78
The accuracy of supervised morphological analyzers KyTea , MeCab , and JUMAN is reported to be over 98\% for news text .
The accuracy of supervised morphological analyzers KyTea , MeCab , and JUMAN is reported to be over 98% for news texts .
79
On the other hand , the unsupervised method latticelm achieved 66 .6% accuracy ( Mochihashi et al. , 2009 ) for human annotated news text , while the method does not have any answers of word definitions .
On the other hand , the unsupervised method , latticelm , achieved 66 .6% accuracy ( Mochihashi et al. , 2009 ) for human annotated news texts , while the method does not have any answers for word definitions .
80
Therefore , it is not possible to compare such a result with the supervised results . Even though , it is fair to compare it with SMT contribution point of view .
Therefore , it is not possible to compare its result with the supervised results , even though it is fair to compare it from the SMT contribution point-of-view .
81
</p>
</p>
82
<p>
<p>
83
Furthermore , their policies about word segmentation definitions are very much different .
Furthermore , their policies concerning word segmentation definitions vary significantly .
84
While MeCab can change its definitions by external lexicons and JUMAN has its own internal standard , KyTea is based on the short unit standard of Balanced Corpus of Contemporary Written Japanese , which is considered one of the shortest definitions of Japanese words .
While MeCab can change its definitions by external lexicons , and JUMAN has its own internal standard , KyTea is based on the short unit standard of the Balanced Corpus of Contemporary Written Japanese , which is considered to have one of the shortest definitions of Japanese words .
85
For example , if we are given a string " 見れば( if someone see ) " , MeCab separates it into two words " 見れ | ば " and JUMAN keep the same string , but KyTea outputs it as three words " 見 | れ | ば " where every character is a word .
For example , if we are given a string , “見れば( if someone sees )” , MeCab separates it into two words , “見れ | ば” and JUMAN retains the same string , but KyTea outputs it as three words , “見 | れ | ば” where every character is a word .
86
In the case of latticelm , as it has no supervised definition of words , it uses the expectation maximized length of words for every word depending on training data .
For latticelm , since it has no supervised definition of words , it uses the expectation maximized length of words for every word , depending on the training data .
87
</p>
</p>
88
<p>
<p>
89
We also investigate such morphological analysis accuracy and word definition problems in our experiments .
In our experiments , we further investigate such morphological analysis accuracies and word definition problems .
90
</p>
</p>
91
</subsubsection>
</subsubsection>
92
<subsubsection label = " Heuristic segmentation’’>
<subsubsection label = " Heuristic segmentation’’>
93
<p>
<p>
94
Chang et al.
Chang et al.
95
( 2008 ) suggested that word segmentation consistency and granularity can be important factors for SMT .
( 2008 ) suggested that word segmentation consistency and granularity can be important factors for SMT .
96
</p>
</p>
97
<p>
<p>
98
Therefore , we introduce two heuristic methods for Japanese word segmentation .
Therefore , we introduce two heuristic methods for Japanese word segmentation .
99
</p>
</p>
100
<p>
<p>
101
One is segmentation by character category ( CAT ) , and the other is segmentation by characters ( CHAR ) .
One method is segmentation by character category ( CAT ) , and the other is segmentation by characters ( CHAR ) .
102
CAT puts a word boundary when character categories change .
CAT places a word boundary when character categories change .
103
Character categories in Japanese include : Kanji ( Chinese character ) , Hiragana , Katakana , Latin alphabet , numeral digit , multi-byte alphabet , multi-byte digit , and other tokens .
Character categories in Japanese include : Kanji ( Chinese character ) , Hiragana , Katakana , Latin alphabet , numeral digit , multi-byte alphabet , multi-byte digit , and other tokens .
104
The CHAR method considers every Unicode character as a word as proposed by Xu et al.
The CHAR method considers every Unicode character as a word , as proposed by Xu et al.
105
( 2004 ) .
( 2004 ) .
106
</p>
</p>
107
</subsubsection>
</subsubsection>
108
</subsection>
</subsection>
109
<subsection label = " Corpora’’>
<subsection label = " Corpora’’>
110
<p>
<p>
111
We use two news corpora : Reuters corpora ( REUTERS ) and Japanese-English News Article Alignment Data ( JENAAD ) ( Utiyama and Isahara , 2003 ) .
We use two news corpora : Reuters corpora ( REUTERS ) and Japanese-English News Article Alignment Data ( JENAAD ) ( Utiyama and Isahara , 2003 ) .
112
Another corpus we use in the experiments is a Wikipedia corpus , Japanese-English Bilingual Corpus of Wikipedia 's Kyoto Articles 2 .01 ( WIKIPEDIA ) .
Another corpus we use in the experiments is a Wikipedia corpus : the Japanese-English Bilingual Corpus of Wikipedia 's Kyoto Articles 2 .01 ( WIKIPEDIA ) .
113
From these corpora , we prepared three data sets as explained below .
From these corpora , we prepared three data sets , as explained below .
114
</p>
</p>
115
<subsubsection label = " REUTERS’’>
<subsubsection label = " REUTERS’’>
116
<p>
<p>
117
In the case of REUTERS , we have used all 56 ,282 sentences .
For REUTERS , we used all 56 ,282 sentences .
118
Then , we split the data into three parts : the first 1 ,000 as the test , the next 500 as the development , and the rest 55 ,282 as the training data .
Then , we split the data into three parts : the first 1 ,000 as the test , the next 500 as the development , and the remaining 55 ,282 as the training data .
119
</p>
</p>
120
</subsubsection>
</subsubsection>
121
<subsubsection label = " JENAAD+REUTERS’’>
<subsubsection label = " JENAAD+REUTERS’’>
122
<p>
<p>
123
In this data , we have combined JENAAD and REUTERS news corpora to get one news corpus .
For this data , we combined the JENAAD and REUTERS news corpora to acquire one news corpus .
124
We have used all 56 ,282 and 150 ,000 sentences respectively .
We used all 56 ,282 and 150 ,000 sentences , respectively .
125
For each corpus , we divide it into the first 1 ,000 , the next 500 , and the rest for test , development , and training .
For each corpus , we divided the sentences into the first 1 ,000 for testing , the next 500 for development , and the remaining for training .
126
We have gathered 2000 , 1000 , and 203 ,782 sentences for test , development , and training , respectively , in total .
In total , we gathered 2000 , 1000 , and 203 ,782 sentences for test , development , and training , respectively .
127
</p>
</p>
128
</subsubsection>
</subsubsection>
129
<subsubsection label = " WIKIPEDIA’’>
<subsubsection label = " WIKIPEDIA’’>
130
<p>
<p>
131
Firstly , since the WIKIPEDIA corpus is a multi-category XML dataset , we have sorted them by the DOCID in the ascending order and by the document categories LTT , EPR , FML , BDS , CLT , BLD , GNM , SCL , ROD , SNT , PNM , HST , RLW , and SAT .
Since the WIKIPEDIA corpus is a multi-category XML dataset , we sorted them by the DOCID in ascending order , and by the document categories : LTT , EPR , FML , BDS , CLT , BLD , GNM , SCL , ROD , SNT , PNM , HST , RLW , and SAT .
132
Secondly , we parsed it by xml .etree .ElementTree .parse of Python 2 .7 .2 , and obtained 477 ,036 sentence pairs without parsing errors .
Next , we parsed it by xml .etree .ElementTree .parse of Python 2 .7 .2 , and obtained 477 ,036 sentence pairs without parsing errors .
133
Thirdly , sentence pairs that include a character " | " in English or Japanese are removed because it caused a problem with Moses .
Then , sentence pairs that include a character “|” in English or Japanese were removed , because it caused a problem with Moses .
134
Finally , we obtained 477 ,012 sentence pairs in total .
Finally , we obtained 477 ,012 sentence pairs in total .
135
In order to adjust the balance of the domains , we have sampled the data twice : First we extract the first line for every 477 lines .
In order to adjust the balance of the domains , we sampled the data twice : First , we extracted the first line for every 477 lines .
136
After this , we have merged the remaining 476 ,012 lines and from this extract the first line for every 952 lines .
Then , we merged the remaining 476 ,012 lines , and from this extract , we extracted the first line for every 952 lines .
137
Finally , we have obtained 1 ,000 test , 500 development , and 475 ,512 training data .
Finally , we obtained 1 ,000 test , 500 development , and 475 ,512 training data .
138
</p>
</p>
139
</subsubsection >
</subsubsection >
140
</subsection>
</subsection>
141
<subsection label = " Evaluation Metrics’’>
<subsection label = " Evaluation Metrics’’>
142
<p>
<p>
143
We have launched two word-based evaluation methods : BLEU ( Papineni et al. , 2002 ) with 4-gram setting and RIBES ( Isozaki et al. , 2010a ) , which has been reported to have a much higher correlation to human evaluation than BLEU within English-Japanese translation tasks ( Sudoh et al. , 2011 ) .
We have launched two word-based evaluation methods : BLEU ( Papineni et al. , 2002 ) with 4-gram setting and RIBES ( Isozaki et al. , 2010a ) , which has been reported to have a much higher correlation to human evaluation than BLEU within English-Japanese translation tasks ( Sudoh et al. , 2011 ) .
144
</p>
</p>
145
<p>
<p>
146
Currently , the most popular way to evaluate Statistical Machine Translation is to use word-based evaluation metrics such as BLEU and RIBES .
Currently , the most popular way to evaluate SMT is to use word-based evaluation metrics , such as BLEU and RIBES .
147
However , these word-based evaluation metrics have a problem on independency of word segmentation evaluations .
However , these word-based evaluation metrics have a problem on independency of word segmentation evaluations .
148
</p>
</p>
149
<p>
<p>
150
If we do not have segmented reference and test data , we cannot evaluate outputs by word-based evaluation metrics .
If we do not have segmented reference and test data , we cannot evaluate the outputs by word-based evaluation metrics .
151
For example , in the case of English-Japanese translations , we must tokenize reference data to evaluate SMT outputs .
For example , for English-Japanese translations , we must tokenize reference data to evaluate SMT outputs .
152
On the other hand , in the case of Japanese-English translations , we must tokenize test data to evaluate the outputs .
On the other hand , for Japanese-English translations , we must tokenize test data to evaluate the outputs .
153
As a result , we need to tokenize every sentence by word segmentation before evaluation , and it is hard to independently evaluate the effects of word segmentation on training data .
As a result , we need to tokenize every sentence by word segmentation before evaluation , and it is therefore difficult to independently evaluate the effects of word segmentation on training data .
154
</p>
</p>
155
<p>
<p>
156
It is also possible to detokenize SMT outputs first , and then tokenize them by the shared word segmentation .
It is also possible to detokenize SMT outputs first , and then tokenize them by the shared word segmentation .
157
However , our preliminary experiments showed that the results obtained with this method were not independent from word segmentation of training data .
However , our preliminary experiments indicated that the results obtained with this method were not independent from word segmentation of the training data .
158
And the best results were obtained when we use the same word segmentation as the training data .
The best results were obtained when we used the same word segmentation as the training data .
159
Hence , this problem remains if we keep our word-based evaluations .
Hence , if we keep our word-based evaluations , this problem remains .
160
</p>
</p>
161
<p>
<p>
162
In order to manage such a problem , we use one character-based metric BLEU in Characters ( De-noual and Lepage , 2005 ) with 4-gram .
In order to manage this issue , we used one character-based metric BLEU in Characters ( De-noual and Lepage , 2005 ) with 4-gram .
163
As this method evaluates the character-level information , outputs are not required to be segmented and it is free from word segmentation variations .
As this method evaluates the character-level information , outputs are not required to be segmented , and it is free from word segmentation variations .
164
</p>
</p>
165
</subsection>
</subsection>
166
<subsection label = " The pipeline’’>
<subsection label = " The pipeline’’>
167
<p>
<p>
168
We have conducted English and Japanese machine translation in both directions by the following steps :
We have conducted English and Japanese machine translation in both directions , following the steps below :
169
</p>
</p>
170
<p>
<p>
171
1Apply the Head-Finalization ( Isozaki et al. , 2010b ) to English text in the case of English-Japanese translation .
1 .Apply the Head-Finalization ( Isozaki et al. , 2010b ) to English text in the case of English-Japanese translation .
172
</p>
</p>
173
<p>
<p>
174
2Run Japanese word segmentation methods and a normalization script which was introduced by the NTCIR-9 PATMT task .
2 .Run Japanese word segmentation methods and a normalization script , which was introduced by the NTCIR-9 PATMT task .
175
</p>
</p>
176
<p>
<p>
177
3Tokenize and lowercase English text by Moses' tokenizer and lowercase scripts .
3 .Tokenize and lowercase English texts by Moses' tokenizer and lowercase scripts .
178
</p>
</p>
179
<p>
<p>
180
4Create language models from target languages' training data , with SRILM 1 .5 .12 .
4 .Create language models from target languages' training data , with SRILM 1 .5 .12 .
181
</p>
</p>
182
<p>
<p>
183
5Create translation models with Giza++ 1 .0 .5 ( 2011-09-24 ) .
5 .Create translation models with Giza++ 1 .0 .5 ( 2011-09-24 ) .
184
</p>
</p>
185
<p>
<p>
186
6Decode source test data with Moses ( 2010-08-13 ) .
6 .Decode source test data with Moses ( 2010-08-13 ) .
187
</p>
</p>
188
<p>
<p>
189
7Compute evaluation scores of the outputs .
7 .Compute evaluation scores of the outputs .
190
</p>
</p>
191
<subsubsection label = " Head finalization’’>
<subsubsection label = " Head finalization’’>
192
<p>
<p>
193
We used Enju 2 .4 .2 ( Miyao and Tsujii , 2005 ) and Head Finalization ( Isozaki et al. , 2010b ) to preprocess English data .
We used Enju 2 .4 .2 ( Miyao and Tsujii , 2005 ) and Head Finalization ( Isozaki et al. , 2010b ) to preprocess English data .
194
This method enabled more accurate translations within English-Japanese translations than the conventional settings .
This method enabled more accurate translations within English-Japanese translations than with the conventional settings .
195
We have applied the following Head Finalization rules from ( Su-doh et al. , 2011 ) :
We have applied the following Head Finalization rules from ( Su-doh et al. , 2011 ) :
196
</p>
</p>
197
<p>
<p>
198
- Reverse each phrase 's word orders when the phrase does not end with a head .
- Reverse each phrase 's word orders when the phrase does not end with a head .
199
</p>
</p>
200
<p>
<p>
201
- Exclude coordination from reversing
- Exclude coordination from reversing
202
</p>
</p>
203
<p>
<p>
204
- Convert plural nouns to singular forms
- Convert plural nouns to singular forms
205
</p>
</p>
206
<p>
<p>
207
- Remove articles " a " , " an " , and " the "
- Remove articles “a” , “an” , and “the”
208
</p>
</p>
209
<p>
<p>
210
- Insert pseudo-particles _va0 , _va1 , and _va2 .
- Insert pseudo-particles _va0 , _va1 , and _va2 .
211
</p>
</p>
212
<p>
<p>
213
For the pseudo-particles , we use the following insertion rules ( arg1 and arg2 are swapped when the head verb 's voice is passive ) :
For the pseudo-particles , we use the following insertion rules ( arg1 and arg2 are swapped when the head verb 's voice is passive ) :
214
</p>
</p>
215
<p>
<p>
216
- Add _va0 after the arg1 entry of the sentence head verb
- Add _va0 after the arg1 entry of the sentence head verb
217
</p>
</p>
218
<p>
<p>
219
- Add _va1 after arg1 entries of other verbs
- Add _va1 after arg1 entries of other verbs
220
</p>
</p>
221
<p>
<p>
222
- Add _va2 after arg2 entries of all verbs
- Add _va2 after arg2 entries of all verbs
223
</p>
</p>
224
</subsubsection>
</subsubsection>
225
</subsection>
</subsection>
226
</section>
</section>
227
<section label = " Results and analysis’’>
<section label = " Results and analysis’’>
228
<p>
<p>
229
Table 2 and Table 3 show the English-Japanese and Japanese-English evaluation results .
Table 2 and Table 3 show the English-Japanese and Japanese-English evaluation results .
230
The best scores in each evaluation metrics are highlighted for each data set .
The best scores in each evaluation metrics are highlighted for each data set .
231
<subsection label = " Comparison of Word Segmentation Methods’’>
<subsection label = " Comparison of Word Segmentation Methods’’>
232
All evaluation metrics have been used in both directions between English and Japanese , to measure consistency and sufficiency of the metrics in the language pair .
All evaluation metrics have been used in both directions between English and Japanese , to measure the consistency and sufficiency of the metrics in the language pair .
233
<subsubsection label = " English to Japanese translation’’>
<subsubsection label = " English to Japanese translation’’>
234
</p>
</p>
235
<p>
<p>
236
In this case , the evaluation scores created by BLEU and RIBES are not comparative due to the differences of Japanese word definitions between the outputs of word segmentation methods .
In this case , the evaluation scores created by BLEU and RIBES are not comparative , due to the differences in the Japanese word definitions among the outputs of word segmentation methods .
237
Furthermore , the CHAR scores in BLEU and BLEU in Characters should be regarded as almost same while small changes have been introduced due to statistical errors and the differences in the methods how to treat space characters .
Furthermore , the CHAR scores in BLEU and BLEU in Characters should be regarded as almost the same , while small changes have been introduced , due to statistical errors and the differences in the methods in how to treat space characters .
238
</p>
</p>
239
<p>
<p>
240
We found that the three supervised morphological analyzers KyTea , MeCab , and JUMAN were much higher than latticelm and CAT , and were competitive .
We found that the three supervised morphological analyzers : KyTea , MeCab , and JUMAN were much higher than latticelm and CAT , and were competitive .
241
For instance , on REUTERS in Table 2 , BLEU scores were ranged from 27 .88 to 29 .53 , while latticelm was 15 .28 and CAT was 22 .10 .
For instance , on REUTERS in Table 2 , BLEU scores ranged from 27 .88 to 29 .53 , while for latticelm , the score was 15 .28 and for CAT , the score was 22 .10 .
242
</p>
</p>
243
<p>
<p>
244
The unsupervised morphological analyzer latticelm and one of heuristic methods CAT were worse than our expectations .
The unsupervised morphological analyzer , latticelm , and one of heuristic methods , CAT , performed worse than expectations .
245
These two were the worst or the second worst results in all settings .
These two results were the worst , in all of the settings .
246
</p>
</p>
247
<p>
<p>
248
The results of CHAR were counterintuitive and yet to be discussed .
The results of CHAR were counterintuitive and are yet to be discussed .
249
It was relatively much better than the supervised morphological analyzers in BLEU .
The results were better than the results for the supervised morphological analyzers in BLEU .
250
</p>
</p>
251
<p>
<p>
252
Besides , it was almost competitive in RIBES and BLUE in Characters .
It was almost competitive in RIBES and BLUE in Characters .
253
For example , CHAR achieved the best 38 .42 score in BLEU on REUTERS , but the second best KyTea was 29 .53 .
CHAR achieved the best score in BLEU on REUTERS ( 38 .42 ) , but the second-best was KyTea ( 29 .53 ) .
254
In the case of BLEU in Characters on REUTERS , CHAR achieved 38 .61 , while the worst supervised result was KyTea 's 39 .82 .
For BLEU in Characters on REUTERS , CHAR achieved 38 .61 , while the worst supervised result was KyTea 's 39 .82 .
255
</p>
</p>
256
<subsubsection>
<subsubsection>
257
<subsubsection label = " Japanese to English translations’’>
<subsubsection label = " Japanese to English translations’’>
258
<p>
<p>
259
In this case , the evaluation scores are lower than English-Japanese translations in general .
For Japanese-English translations , the evaluation scores were generally lower than for English-Japanese translations .
260
It is because Japanese-English translations are conducted without Head-Finalization .
This is because Japanese-English translations are conducted without Head-Finalization .
261
</p>
</p>
262
<p>
<p>
263
Again , the supervised morphological analyzers KyTea , MeCab , and JUMAN were competitive .
Again , the supervised morphological analyzers KyTea , MeCab , and JUMAN were competitive .
264
All supervised analyzers were better than the unsupervised and the both heuristic methods .
All supervised analyzers performed better than the unsupervised and the both heuristic methods .
265
</p>
</p>
266
<p>
<p>
267
On the other hand , the unsupervised morphological analyzer latticelm and one of heuristic methods CAT were competitive to the supervised analyzers in RIBES .
Conversely , the unsupervised morphological analyzer latticelm and one of heuristic methods CAT performed competitively with the supervised analyzers in RIBES .
268
For example , latticelm was 62 .51 and KyTea was 62 .90 on REUTERS .
latticelm was 62 .51 and KyTea was 62 .90 on REUTERS .
269
</p>
</p>
270
<p>
<p>
271
In this case , CHAR was not competitive to the supervised analyzers in total .
In this case , CHAR was not competitive to the supervised analyzers in total .
272
The results were the worst scores in BLEU and RIBES on REUTERS and JENAAD+REUTERS . The only one exception was in the case of the best 56 .55 BLEU in Characters on REUTERS .
The results for CHAR were the lowest scores in BLEU and RIBES on REUTERS and JENAAD+REUTERS , with the exception of the best 56 .55 BLEU in Characters on REUTERS .
273
</p>
</p>
274
</subsubsection>
</subsubsection>
275
<subsubsection label = " Discussions’’>
<subsubsection label = " Discussions’’>
276
<p>
<p>
277
We found the results of the supervised morphological analyzers are better in both English-Japanese and Japanese-English experiments .
We found that the results of the supervised morphological analyzers were better in both English-Japanese and Japanese-English experiments .
278
And the differences in the word definition of KyTea , MeCab , and JUMAN were not remarkable , especially in English-Japanese translations , although the word definition of KyTea is much shorter than MeCab and JUMAN .
Furthermore , the differences in the word definition of KyTea , MeCab , and JUMAN were not substantial , especially for English-Japanese translations , although the word definition of KyTea is much shorter than for MeCab and JUMAN .
279
This result implies that phrase-based SMT can output sufficiently reasonable word / phrase alignments that can treat different word definitions in most cases .
This result implies that phrase-based SMT can output sufficiently reasonable word / phrase alignments that can treat different word definitions , in most cases .
280
</p>
</p>
281
<p>
<p>
282
On the other hand , the unsupervised morphological analyzer latticelm and one of our heuristic methods CAT were very much worse than the supervised morphological analyzers .
On the other hand , the unsupervised morphological analyzer latticelm and one of our heuristic methods CAT performed much poorer than the supervised morphological analyzers .
283
</p>
</p>
284
<p>
<p>
285
The experiments demonstrated an unexpected result for CHAR .
The experiments demonstrated an unexpected result for CHAR .
286
It was good at English-Japanese but not at Japanese-English translations .
It excelled with English-Japanese translations , but not with Japanese-English translations .
287
We consider the possible reasons for this result :
We consider the possible reasons for this result in the following list :
288
</p>
</p>
289
<p>
<p>
290
- The Head Finalization of English-Japanese lead better phrase alignments .
- The Head Finalization of English-Japanese lead better phrase alignments .
291
</p>
</p>
292
<p>
<p>
293
- Since CHAR treat a character as a word , the best combination of its phrase alignments were the best suited for the SMT decoding .
- Since CHAR treats a character as a word , the best combination of its phrase alignments were the best suited for the SMT decoding .
294
</p>
</p>
295
<p>
<p>
296
On the other hand , we observed the following issues from our error analysis :
On the other hand , we observed the following issues from our error analysis :
297
</p>
</p>
298
<p>
<p>
299
- Uncommon named entities were almost wrongly translated .
- Uncommon named entities were almost wrongly translated .
300
( For example , チェコ Czech was produced instead of チェコスロバキア Czechoslovakia . )
( For example , チェコ Czech was produced instead of チェコスロバキア Czechoslovakia . )
301
</p>
</p>
302
<p>
<p>
303
- Long sentences were translated worse than the other word segmentation outputs .
- Long sentences were not translated as well as other word segmentation outputs .
304
</p>
</p>
305
<p>
<p>
306
The reasons of the CHAR results are yet to be analyzed in details .
The reasons for the CHAR results are yet to be analyzed in detail .
307
However , this result indicates that there is a possibility of better word segmentation than popular supervised morphological analyzers and CHAR word segmentation .
However , this result indicates that there is a possibility of better word segmentation than popular supervised morphological analyzers and CHAR word segmentation .
308
We are planning to conduct further investigation in future .
We are planning to conduct further investigations in the future .
309
</p>
</p>
310
</subsubsection>
</subsubsection>
311
</subsection>
</subsection>
312
<subsection label = " Comparison of Evaluation Metrics’>
<subsection label = " Comparison of Evaluation Metrics’’>
313
<p>
<p>
314
The current evaluation metrics we pursued in this paper were not sufficient to discuss more accurately about the relative advantages and disadvantages of word segmentation , since they did not produce consistent scores as explained below :
The current evaluation metrics that we pursued in this paper were insufficient to discuss the relative advantages and disadvantages of word segmentation in detail , since the scores that were produced were inconsistent , as explained below :
315
</p>
</p>
316
<p>
<p>
317
- There were many contradictory figures among evaluation metrics .
- There were many contradictory figures among evaluation metrics .
318
There was a case that BLEU was high , while other metrics were low .
There was a case that BLEU was high , while other metrics were low .
319
Moreover , there is also a case that RIBES and BLEU in Characters were incompatible with each other .
Moreover , there is also a case in which RIBES and BLEU in Characters were incompatible with each other .
320
For example , on WIKIPEDIA in Table 2 , while CHAR was relatively the highest and greatly better than the supervised morphological analyzers in RIBES , MeCab achieved the best score and notably better than CHAR in BLEU in Characters .
For example , on WIKIPEDIA in Table 2 , while CHAR was the highest , and performed better than the supervised morphological analyzers in RIBES , MeCab achieved the best score and notably better than CHAR in BLEU in Characters .
321
</p>
</p>
322
<p>
<p>
323
- If we compare every column in a row , there were tendencies that the best and the worst corpora were the same for every evaluation metrics .
- If we compare every column in a row , there were tendencies that the best and the worst corpora were the same for every evaluation metrics .
324
In Table 2 , REUTERS was the best and WIKIPEDIA was the worst in terms of BLEU , but also JENAAD+REUTERS was the best and WIKIPEDIA was the worst in terms of RIBES .
In Table 2 , REUTERS was the best and WIKIPEDIA was the worst in terms of BLEU , but also JENAAD+REUTERS was the best and WIKIPEDIA was the worst in terms of RIBES .
325
</p>
</p>
326
<p>
<p>
327
- Even when we compare every row in a column , there were no tendencies .
- Even when we compare every row in a column , there were no tendencies .
328
For instance , in terms of BLEU in Characters , CHAR , JUMAN , and MeCab achieved the best scores in Table 3 .
For instance , in terms of BLEU in Characters , CHAR , JUMAN , and MeCab achieved the best scores in Table 3 .
329
</p>
</p>
330
</subsection>
</subsection>
331
</section>
</section>
332
<section label = " Conclusion’’>
<section label = " Conclusion’’>
333
<p>
<p>
334
This work focused on how the difference of word segmentation affects SMT outputs , the quality of the unsupervised word segmentation on SMT , and the meta-evaluation of the current evaluation metrics .
This work focused on how the differences in word segmentation affected SMT outputs , the quality of the unsupervised word segmentation on SMT , and the meta-evaluation of the current evaluation metrics .
335
</p>
</p>
336
<p>
<p>
337
In summary , we found that the representative morphological analyzers were competitive and much better than both unsupervised analyzer and one of our heuristic methods .
In summary , we found that the representative morphological analyzers were competitive and much better than both the unsupervised analyzer and one of our heuristic methods .
338
After all , a heuristic word segmentation method CHAR achieved relatively good word-based BLEU scores and competitive character-based BLEU results , compared to the supervised analyzers .
Nevertheless , a heuristic word segmentation method CHAR achieved relatively good word-based BLEU scores and competitive character-based BLEU results , compared to the supervised analyzers .
339
Additionally , as we could not always obtain consistent scores from the current evaluation metrics , they were not sufficient to discuss more accurately about the relative advantages and disadvantages of word segmentation .
Additionally , as we could not always obtain consistent scores from the current evaluation metrics , the data was insufficient for discussing the relative advantages and disadvantages of word segmentation , with accuracy .
340
We also suggested it is possible to implement more optimized word segmentation on SMT .
We have also suggested that it is possible to implement more optimized word segmentation on SMT .
341
</p>
</p>
342
</document>
</document>
