0
<document>
<document>
1
<title>
<title>
2
Face Retrieval Improvement by Learning Visual Consistency
Face Retrieval Improvement by the Learning of Visual Consistency
3
</title>
</title>
4
<abstract>
<abstract>
5
<p>
<p>
6
Searching persons is one of the essential tasks required by users for image and video search engines .
Searching for images of people is one of the essential tasks required by users for image and video search engines .
7
However , the current search engines have limited capabilities for this task since they usually rely on texts associated with image and video which are likely to return many irrelevant results .
However , the current search engines have limited capabilities for this task since they usually rely on texts associated with image and video , which are likely to return many irrelevant results .
8
In this paper , we propose a method to effectively retrieve relevant faces for one person by learning visual consistency from results retrieved from text correlation based search engines .
We propose a method to effectively retrieve relevant faces for one person by learning visual consistency from results retrieved from text correlation based search engines .
9
This problem is challenging because ( i ) no any label is provided leading to be difficult to use supervised-based ranking methods .
This problem is challenging because ( i ) there is no label provided making it difficult to use supervised-based ranking methods .
10
( ii ) current face recognition techniques are still unmatured with wild-face databases even with supervised learning methods .
( ii ) current face recognition techniques are still immature with wild-face databases even with supervised learning methods .
11
In the proposed method , we treat the problem as a classification problem which input faces are classified as 'personX' ( the queried person ) or 'non-personX' and the faces are ranked based on their relevant score that is inferred from the classifier 's probability output .
In the proposed method , we treat this problem as a classification problem in which input faces are classified as 'person-X' ( the queried person ) or 'non-person-X' , and the faces are ranked based on their relevant score inferred from the classifier 's probability output .
12
In order to train this classifier , we use a bagging-based framework to combine results from multiple weak classifiers which are trained using different subsets .
To train this classifier , we use a bagging-based framework to combine results from multiple weak classifiers , which are trained using different subsets .
13
These training subsets are extracted and labeled automatically from the rank list produced from the classifier trained from the previous step .
These training subsets are extracted and labeled automatically from the rank list produced from the classifier trained from the previous step .
14
In addition , outliers detection methods are used to produce the rank list for initialization .
In addition , outlier detection methods are used to produce the rank list for initialization .
15
Experimental results on various face sets retrieved from the caption of news photos show that the retrieval performance is improved after each iteration leading the final performance outperforms the baseline algorithms .
Experimental results on various face sets retrieved from the captions of news photos show that the retrieval performance improved after each iteration with the final performance outperforming the baseline algorithms .
16
</p>
</p>
17
<section label = �gINTRODUCTION�h>
<section label = �gINTRODUCTION�h>
18
<p>
<p>
19
With the rapid growing of digital technology , large image and video databases are available easier than ever to users .
With the rapid growth of digital technology , large image and video databases are more available than ever to users .
20
Therefore , effective and efficient tools are strongly needed for indexing and retrieving based on visual contents .
Therefore , effective and efficient tools are needed for indexing and retrieving based on visual contents .
21
One of the typical examples for this application is to search a specific person by providing his or her name .
A typical example for this application is searching for a specific person by providing his or her name .
22
Usually , most of current search engines use text associated with images or videos as a significant clue to return the results .
Usually , most current search engines use the texts associated with images or videos as significant clues for returning results .
23
However , since it is not necessary faces and names appear simultaneously and are aligned ( as shown in Figure \REF ) , the main drawback of this approach is existence of many irrelevant results that makes the retrieval performance very low .
However , other un-queried faces and names appear simultaneously and are aligned ( as shown in Figure \REF ) , which significantly lowers retrieval performance .
24
Therefore it is necessary to improve the retrieval performance by taking into account visual information from the retrieved faces .
Therefore , it is necessary to improve the retrieval performance by taking into account the visual information from the retrieved faces .
25
This problem is challenging due to the following reasons :
This problem is challenging due to the following reasons :
26
</p>
</p>
27
<p>
<p>
28
-Large variations in face appearance due to pose changes , illumination conditions , occlusions and facial expressions make face recognition difficult even with state of the art techniques \CITE .
-Large variations in face appearance due to pose changes , illumination conditions , occlusions , and facial expressions make face recognition difficult even with state of the art techniques \CITE .
29
</p>
</p>
30
<p>
<p>
31
-The fact the retrieved face set consists of faces of several persons while no any label is given makes supervised learning methods as well as unsupervised learning methods such as \MATH -means inapplicable .
-The fact the retrieved face set consists of faces of several people with no label makes supervised learning methods as well as unsupervised learning methods such as , \MATH -means , inapplicable .
32
</p>
</p>
33
<p>
<p>
34
In this paper , we propose a method to solve the mentioned problem .
We propose a method to solve the above-mentioned problem .
35
The main idea is to learn visual consistency assumed to exist among the results returned from current text-based search engines .
The main idea is to assume that there is visual consistency among the results returned from current text-based search engines .
36
The method consists of two stages .
This method consists of two stages .
37
In the first stage , we explore local density of faces to identify potential candidates for relevant faces .
In the first stage , we explore local density of faces to identify potential candidates for relevant faces .
38
This stage is stemmed from the observation that faces relevant to the queried person tend to form dense clusters while irrelevant faces are very sparse since they look different from each other .
This stage is based on the observation that facial images of the queried person tend to form dense clusters while irrelevant facial images are sparse since they look different from each other .
39
We use an outliers detection method for this purpose .
We use an outlier detection method for this purpose .
40
The output is a rank list in which faces having larger number of neighbors within a distance are predicted as relevant ones and therefore are put on the top .
The output is a rank list in which faces with larger number of neighbors within a certain distance are considered as relevant and are therefore put at the top of the list . //[What do you mean by �gneighbors�h ? Do you mean the un-queried faces ? ]
41
Since the above ranking method is based on the number of neighbors , it is sensitive to the chosen distance .
Since the above ranking method is based on the number of neighbors , it is sensitive to the specified distance .
42
It is necessary to use the second stage to improve the rank list .
A second stage is necessary to improve this rank list .
43
We model this problem as a classification problem which input faces are classified as personX ( the queried person ) or non-personX ( the irrelevant person ) .
We model this problem as a classification problem in which input faces are classified as person-X ( the queried person ) or non-person-X ( the irrelevant person ) .
44
The faces are ranked based on their relevant score that is inferred from the classifier 's probability output .
The faces are ranked based on their relevancy score that is inferred from the classifier 's probability output .
45
Since annotation data is not available , the rank list from the previous step is used to assign labels for a subset of faces .
Since annotation data is not available , the rank list from the previous step is used to assign labels for a subset of faces .
46
This subset then is used to train a classifier using a supervised method such as support vector machines ( SVM ) .
This subset then is used to train a classifier using supervised methods such as support vector machines ( SVM ) .
47
The trained classifier is used to re-rank faces in the original input set again .
The trained classifier is used to re-rank faces in the original input set .
48
This step is repeated a number of times to get the final rank list .
This step is repeated a number of times to get the final rank list .
49
Since automatically assigning labels from the rank list is not reliable , the trained classifiers are weak .
Since automatically assigning labels from the rank list is not reliable , the trained classifiers are weak .
50
In order to get the final strong classifier , we employ the idea of ensemble learning \CITE in which weak classifiers trained on different subsets are combined to improve stability and classification accuracy of single classifiers .
In order to get the final strong classifier , we use the idea of ensemble learning \CITE in which weak classifiers trained on different subsets are combined to improve the stability and classification accuracy of single classifiers .
51
</p>
</p>
52
<p>
<p>
53
This stage is effective for improving the rank list due to the following reasons :
This stage is effective for improving the rank list for the following reasons :
54
</p>
</p>
55
<p>
<p>
56
-Supervised learning methods such as SVM have strong theoretical background in finding optimal decision boundary even with existence of noisy data .
-Supervised learning methods such , as SVMs , provide a strong theoretical background in finding optimal decision boundary even with existence of noisy data .
57
Furthermore , with recent studies \CITE SVM classifiers can provide probability outputs that are suitable for ranking .
Furthermore , recent studies suggest that \CITE SVM classifiers provide probability outputs that are suitable for ranking .
58
</p>
</p>
59
<p>
<p>
60
-Bagging framework helps to leverage noises in the unsupervised labeling process .
-Bagging framework helps to leverage noises in the unsupervised labeling process .
61
</p>
</p>
62
<p>
<p>
63
Our contribution is two-fold :
Our contribution is two-fold :
64
</p>
</p>
65
<p>
<p>
66
-We propose a general framework to boost the face retrieval performance from the results retrieved from text correlation based search engines by learning visual consistency .
-We propose a general framework to boost the face retrieval performance from results retrieved from text correlation-based search engines by the learning of visual consistency .
67
It integrates seamlessly current existing data mining methods such as outliers detection , supervised learning and unsupervised learning based on bagging for a practical problem .
It seamlessly integrates current data mining methods such as outlier detection , supervised learning , and unsupervised learning based on bagging for a practical problem . //[What or who is �glearning�h visual consistency ? Are the search engines learning ? ]
68
Our framework requires few parameters and works stably .
Our framework requires few parameters and works stably .
69
</p>
</p>
70
<p>
<p>
71
-We demonstrate feasibility of using tolerance of supervised learning methods when working with noisy datasets combined with ensemble learning to improve the final performance .
-We demonstrate the feasibility of using tolerance of supervised learning methods when working with noisy datasets combined with ensemble learning to improve the final performance .
72
</p>
</p>
73
<subsection label = �gRelated Work�h>
<subsection label = �gRelated Work�h>
74
<p>
<p>
75
There are several approaches proposed for general object classification rather than for face retrieval .
There are several more proposed approaches for general object classification than for those for face retrieval .
76
For example , as described in \CITE , objects are retrieved by an image search engine and then are re-ranked by learning visual consistencies from the retrieved objects .
For example , as described in \CITE , objects are retrieved by an image search engine and then are re-ranked by the learning of visual consistencies from the retrieved objects .
77
Compared to the problem of face retrieval based recognition , the problem of object classification is easier since classification of different object types such as airplane and non-airplane only needs to handle inter-variations between different categories while discriminating personA and personB requires to handle both intra-variations and inter-variations of the same category .
Compared to the problem of face-based recognition , the problem of object classification is easier since classification of different object types such as airplane and non-airplane only needs to handle inter-variations between different categories , while discriminating between person-A and person-B requires handling of both intra-variations and inter-variations of the same category .
78
Furthermore , in order to work in unsupervised mode , these approaches need a method to collect negative samples ( e.g. non-airplane ) which are inapplicable in our problem .
Furthermore , in order to work in unsupervised mode , these approaches need a method to collect negative samples ( e.g. non-airplane ) , which are inapplicable to our problem .
79
</p>
</p>
80
<p>
<p>
81
Working closely to our problem , in \cite{Ozkan06CVPR} , a graph based approach was proposed \CITEin which a graph is formed by faces as nodes and weights of edges linked between nodes are the similarity of faces .
A graph-based approach was proposed by \CITE , in which a graph is formed by faces as nodes , and the weights of edges linked between nodes are the similarity of faces , is closely related to our problem .
82
By assuming that the number of faces of the queried person are larger than that of other persons , and these faces tend to form the most similar subset among the set of retrieved faces , this problem is considered equal to the problem of finding the densest subgraph of a full graph whose solution is available .
Assuming that the number of faces of the queried person is larger than that of others and that these faces tend to form the most similar subset among the set of retrieved faces , this problem is considered equal to the problem of finding the densest subgraph of a full graph with an available solution . //[Do graphs have solutions ? They just provide information .]
83
Although , experimental results showed effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person .
Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person .
84
Furthermore , choosing an optimal threshold to convert the initial graph into a binary graph is difficult and rather ad hoc due to the curse of dimensionality .
Furthermore , choosing an optimal threshold to convert the initial graph into a binary graph is difficult and rather ad hoc due to dimensionality .
85
In another work \CITE , a clustering-based approach was proposed to associate names and faces in news photos .
In another work \CITE , a clustering-based approach was proposed for associating names and faces in news photos .
86
To solve the problem of ambiguity between several names and one face , a modified \MATH -means clustering process was used in which faces are assigned to the closest cluster ( each cluster corresponding to one name ) after a number of iterations .
To solve the problem of ambiguity between several names and one face , a modified \MATH -means clustering process was used in which faces are assigned to the closest cluster ( each cluster corresponding to one name ) after a number of iterations .
87
Although the result was impressive , it is not easy to apply for our problem since a large number of irrelevant faces ( more than 12% ) are eliminated manually before doing clustering .
Although the result was impressive , it is not easy to apply it to our problem since a large number of irrelevant faces ( more than 12% ) are eliminated manually before performing clustering .
88
</p>
</p>
89
<p>
<p>
90
This paper is organized as follows : Section \REF introduces our proposed framework .
This paper is organized as follows : Section \REF introduces our proposed framework .
91
Section \REF introduce briefly typical outliers detection methods .
Section \REF briefly introduces typical outlier detection methods .
92
Experiments and results are described in section \REF .
Experiments and results are described in section \REF .
93
Finally , section \REF concludes the paper .
Finally , section \REF concludes the paper .
94
</p>
</p>
95
</subsection>
</subsection>
96
</section>
</section>
97
<section label = �gPROPOSED FRAMEWORK�h>
<section label = �gPROPOSED FRAMEWORK�h>
98
<p>
<p>
99
Given a set of faces returned by any text-based correlation search engine , our method performs a ranking process summarized as follows :
Given a set of faces returned by any text-based correlation search engine , our method is used to perform a ranking process summarized as follows :
100
</p>
</p>
101
<p>
<p>
102
-Step 1 : Detect eye positions , and then perform face normalizations .
-Step 1 : Detect eye positions , and then perform face normalizations .
103
</p>
</p>
104
<p>
<p>
105
-Step 2 : Compute an eigenface space and project the input faces into this subspace .
-Step 2 : Compute an eigenface space and project the input faces into this subspace .
106
</p>
</p>
107
<p>
<p>
108
-Step 3 : Estimate ranks of faces using an outliers detection method mentioned in \REF .
-Step 3 : Estimate ranks of faces using an outlier detection method mentioned in \REF .
109
</p>
</p>
110
<p>
<p>
111
-Step 4 : Train a ensemble classifier \MATH using this rank list by Bag-Rank-SVM .
-Step 4 : Train an ensemble classifier \MATH using this rank list by Bag-Rank-SVM .
112
</p>
</p>
113
<p>
<p>
114
-Step 5 : Use the classifier \MATH to estimate the probability of faces in the original set .
-Step 5 : Use the classifier \MATH to estimate the probability of faces in the original set .
115
Rank these faces using their probability score .
Rank these faces using their probability scores .
116
</p>
</p>
117
<p>
<p>
118
-Step 6 : Repeat steps from 4 and 5 $T$ times and return ranked faces produced by the last classifier \MATH to users .
-Step 6 : Repeat steps 4 and 5 $T$ times and return ranked faces produced by the last classifier \MATH to users .
119
</p>
</p>
120
<p>
<p>
121
Steps from 1 and 2 are typical for any face processing system and described in details in \REF .
Steps 1 and 2 are typical for any face processing system and described in detail in \REF .
122
Step 3 used to find initial ranks for faces is described in \REF .
Step 3 used to find initial ranks for faces described in \REF .
123
We use a simple outliers detection method for this step .
We used a simple outlier detection method for this step .
124
</p>
</p>
125
<p>
<p>
126
The Bag-Rank-SVM algorithm is described as follows :
The Bag-Rank-SVM algorithm is described as follows :
127
</p>
</p>
128
<p>
<p>
129
-Step 1 : Select a set \MATH including \MATH top ranked faces and then randomly select a subset \MATH from \MATH .
-Step 1 : Select a set \MATH including \MATH top ranked faces and then randomly select a subset \MATH from \MATH .
130
Label faces in \MATH as positive samples .
Label faces in \MATH as positive samples .
131
</p>
</p>
132
<p>
<p>
133
-Step 2 : Select a set \MATH including \MATH bottom ranked faces and then randomly select a subset \MATH from \MATH .
-Step 2 : Select a set \MATH including \MATH bottom ranked faces and then randomly select a subset \MATH from \MATH .
134
Label faces in \MATH as negative samples .
Label faces in \MATH as negative samples .
135
</p>
</p>
136
<p>
<p>
137
-Step 3 : Use \MATH and \MATH to train a weak classifier \MATH using LibSVM \CITE with probability outputs .
-Step 3 : Use \MATH and \MATH to train a weak classifier \MATH using LibSVM \CITE with probability outputs .
138
</p>
</p>
139
<p>
<p>
140
-Step 4 : Repeat steps from Step 1 to Step 3 \MATH times .
-Step 4 : Repeat steps Step 1 to Step 3 \MATH times .
141
</p>
</p>
142
<p>
<p>
143
-Step 5 : Return \MATH .
-Step 5 : Return \MATH .
144
</p>
</p>
145
<p>
<p>
146
Since it is not guaranteed top \MATH and bottom \MATH of faces in the rank list are correctly correspondent to faces of the queried person \MATH and faces of non person \MATH as shown in Figure \REF , selecting randomly subsets to train weak classifiers and then combining these classifiers might help to reduce risk of using noisy training sets .
Since it is not guaranteed that the top \MATH and bottom \MATH of faces in the rank list correctly correspond to the faces of the queried person-\MATH and faces of non person-\MATH as shown in Figure \REF , randomly selecting subsets to train weak classifiers , and then combining these classifiers might help reduce the risk of using noisy training sets .
147
</p>
</p>
148
</section>
</section>
149
<section label = �gOUTLIERS DETECTION METHODS�h>
<section label = �gOUTLIER DETECTION METHODS�h>
150
<p>
<p>
151
In our framework , outliers detection methods are used to initialize the rank list that is then used to label a subset of samples for training SVM classifiers .
In our framework , outlier detection methods are used to initialize the rank list that is then used to label a subset of samples for training SVM classifiers .
152
We introduce here two common outliers detection methods including distance-based outliers detection( DBO ) \CITE and local outliers factor based method ( LOF ) \CITE .
We introduce two common outlier detection methods , distance-based outlier detection ( DBO ) \CITE and local outlier factor-based method ( LOF ) \CITE .
153
</p>
</p>
154
<subsection label = �gDistance-based Outliers Detection ( DBO )�h>
<subsection label = �gDistance-based Outlier Detection ( DBO )�h>
155
<p>
<p>
156
Adapting the definition \CITE , given a set of objects \MATH , an object \MATH is considered as an outliers if there are fewer than \MATH neighboring objects in \MATH lying within a distance \MATH .
Adapting the definition from Knorr \CITE , given a set of objects \MATH , an object \MATH is considered as an outlier if there are fewer than \MATH neighboring objects in \MATH lying within a distance \MATH .
157
The outliers detection process is summarized as follows :
This outlier detection process is summarized as follows :
158
</p>
</p>
159
<p>
<p>
160
-Step 1 : Compute the distance between every pair of data objects .
-Step 1 : Compute the distance between every pair of data objects .
161
</p>
</p>
162
<p>
<p>
163
-Step 2 : For each object , compute \MATH which is the number of neighboring objects lying within a distance \MATH .
-Step 2 : For each object , compute \MATH , which is the number of neighboring objects lying within a distance \MATH .
164
</p>
</p>
165
<p>
<p>
166
-Step 3 : Rank objects based on their scores \MATH .
-Step 3 : Rank objects based on their scores \MATH .
167
</p>
</p>
168
<p>
<p>
169
In our experiments , the distance between two objects is Euclidean distance between two faces and is computed in the eigen-subspace ( described in section \REF ) .
In our experiments , the distance between two objects is the Euclidean distance between two faces and is computed in the eigen-subspace ( described in section \REF ) .
170
Figure \REF shows two examples of good and bad performance using this method for ranking relevant faces .
Figure \REF shows two examples of good and bad performances using this method for ranking relevant faces .
171
</p>
</p>
172
</subsection>
</subsection>
173
<subsection label = �gLocal Outliers Factor Based Detection ( LOF )�h>
<subsection label = �gLocal Outlier Factor-Based Detection ( LOF )�h>
174
<p>
<p>
175
According to the method described in \CITE , the local outliers factor of an object \MATH is computed by the following steps and then used to rank faces :
According to the method described in \CITE , the local outlier factor of an object \MATH is computed by the following steps and then used to rank faces :
176
</p>
</p>
177
<p>
<p>
178
-Step 1 : For each data object \MATH compute \MATH ( the distance to the \MATH nearest neighbor ) and \MATH ( all points in a \MATH sphere ) .
-Step 1 : For each data object \MATH compute the \MATH ( the distance to the \MATH nearest neighbor ) and \MATH ( all points in a \MATH sphere ) .
179
</p>
</p>
180
<p>
<p>
181
- Step 2 : Compute reachability distance for each data object \MATH with respect to data object \MATH as : \MATH , where \MATH is distance from data object \MATH to data object \MATH .
- Step 2 : Compute the reachability distance for each data object \MATH with respect to data object \MATH as : \MATH , where \MATH is the distance from data object \MATH to data object \MATH .
182
</p>
</p>
183
<p>
<p>
184
-Step 3 : Compute local reachability density of data object \MATH as inverse of the average reachability distance based on the \MATH ( minimum number of data objects ) nearest neighbors of data object \MATH .
-Step 3 : Compute local reachability density of data object \MATH as inverse of the average reachability distance based on the \MATH ( minimum number of data objects ) of the nearest neighbors to data object \MATH .
185
</p>
</p>
186
<p>
<p>
187
-Step 4 : Compute LOF of data object \MATH as average of the ratios of the local reachability density of data object \MATH and local reachability density of \MATH nearest neighbors .
-Step 4 : Compute LOF of data object \MATH as the average of the ratios of the local reachability density of data object \MATH and local reachability density of \MATH of nearest neighbors .
188
</p>
</p>
189
</subsection>
</subsection>
190
</section>
</section>
191
<section label = �gEXPERIMENTS�h>
<section label = �gEXPERIMENTS�h>
192
<subsection label = �gDataset�h>
<subsection label = �gDataset�h>
193
<p>
<p>
194
We used the dataset described in \CITE for our experiments .
We used the dataset described in \CITE for our experiments .
195
This dataset consists of approximately half a million news pictures and captions from Yahoo News over a period of roughly two years .
This dataset consisted of approximately half a million news pictures and captions from Yahoo News over a period of roughly two years .
196
Using a robust face detector , 44 , 773 faces were detected and normalized to the size of 86\MATH86 pixels .
Using a robust face detector , 44 , 773 faces were detected and normalized to the size of 86\MATH86 pixels .
197
After eliminating faces whose facial features are poorly detected by a rectification process and faces whose associated names are not extracted properly from corresponding captions , 30 , 281 faces were kept .
After eliminating faces whose facial features were poorly detected by a rectification process and faces whose associated names were not extracted properly from the corresponding captions , 30 , 281 faces were kept .
198
Figure \REF shows an example of a news photo and its caption .
Figure \REF shows an example of a news photo and its caption .
199
</p>
</p>
200
<p>
<p>
201
We selected sixteen celebrities who are government leaders such as George W . Bush ( US ) , Vladimir Putin ( Russia ) , Ziang Jemin ( China ) , Tony Blair ( UK ) , Junichiro Koizumi ( Japan ) , Roh Moo-hyun ( Korea ) , Abdullah Gul ( Turkey ) , and other key persons such as John Paul II ( the Former Pope ) , Kofi Annan and Hans Blix ( UN ) . These persons are selected since their appearances are highly frequent in the dataset \CITE .
We selected sixteen government leaders including George W . Bush ( US ) , Vladimir Putin ( Russia ) , Ziang Jemin ( China ) , Tony Blair ( UK ) , Junichiro Koizumi ( Japan ) , Roh Moo-hyun ( Korea ) , Abdullah Gul ( Turkey ) , and other key individuals such as John Paul II ( the Former Pope ) and Kofi Annan and Hans Blix ( UN ) since their images appeared frequently in the dataset \CITE .
202
For each person , variations of his name are collected . For example , George W . Bush , President Bush , U . S . President , etc are variations of U . S . President Bush .
For each person , variations of his name were collected . For example , George W . Bush , President Bush , U . S . President , etc are variations of U . S . President Bush .
203
We indexed image captions and then used this index to retrieve faces associated with the captions containing names of the queried person .
We indexed image captions and then used this index to retrieve faces associated with the captions containing names of the queried person .
204
The faces retrieved from different names of each person are merged into a set used for our ranking process .
The faces retrieved from different names of each person were merged into a set used for our ranking process .
205
Figure \REF shows faces retrieved when searching Mr . Kofi Annan .
Figure \REF shows faces retrieved when searching Mr . Kofi Annan .
206
Figure \REF shows the distribution of retrieved faces from this method and the corresponding number of relevant faces for these ten persons .
Figure \REF shows the distribution of retrieved faces from this method and the corresponding number of relevant faces for these ten individuals .
207
In total , 3 , 907 faces are retrieved in which 2 , 094 faces are relevant .
In total , 3 , 907 faces were retrieved in which 2 , 094 faces were relevant .
208
On average , the precision is 52.49% .
On average , the precision was 52.49% . //[precision / accuracy ? ]
209
</p>
</p>
210
</subsection>
</subsection>
211
<subsection label = �gFace Processing�h>
<subsection label = �gFace Processing�h>
212
<p>
<p>
213
We used an eye detector to detect eye positions of detected faces .
We used an eye detector to detect eye positions of detected faces .
214
These eye positions were used to align faces to a predefined canonical pose .
These eye positions were used to align faces to a predefined canonical pose .
215
To compensate for illumination effects , the subtraction of the bestfit brightness plane followed by histogram equalization was applied .
To compensate for illumination effects , the subtraction of the best-fit brightness plane followed by histogram equalization was applied .
216
This normalization process is shown in Figure \REF .
This normalization process is shown in Figure \REF .
217
</p>
</p>
218
<p>
<p>
219
We then used PCA \CITE to reduce the number of dimensions of the feature vector for face representation .
We then used principle component analysis \CITE to reduce the number of dimensions of the feature vector for face representation .
220
Eigenfaces were computed from the original face set returned by the text based query method .
Eigenfaces were computed from the original face set returned by the text-based query method .
221
The number of eigenfaces was selected so that 97% of the total energy are retained \CITE .
A number of eigenfaces was selected so that 97% of the total energy was retained \CITE . //[What is that number ? ]
222
</subsection>
</subsection>
223
<subsection label = �gResults�h>
<subsection label = �gResults�h>
224
</subsection>
</subsection>
225
<subsection label = �gEvaluation Criteria�h>
<subsection label = �gEvaluation Criteria�h>
226
<p>
<p>
227
We evaluated the retrieval performance with measures that are popularly used in information retrieval such as precision , recall and average precision .
We evaluated the retrieval performance with measures that are commonly used in information retrieval such as precision , recall , and average precision .
228
Given a queried person , assuming that \MATH is the total number of faces returned , \MATH is the number of relevant faces , \MATH is the number of relevant faces , we calculate recall and precision as follows :
Given a queried person , assuming that \MATH is the total number of faces returned , \MATH is the number of relevant faces , \MATH is the number of relevant faces , we calculated recall and precision as follows : //[Nrel and Nhit are exactly the same here . They should be different .]
229
</p>
</p>
230
<p>
<p>
231
Precision and recall only evaluate the quality of an unordered set of retrieved faces .
Precision and recall only evaluate the quality of an unordered set of retrieved faces .
232
To evaluate ranked lists , the average precision is used .
To evaluate ranked lists , average precision is used .
233
The average precision is computed by taking average of the interpolated precision measured at the 11 recall levels of 0.0 , 0.1 , 0.2 , ... , 1.0 .
The average precision is computed by taking the average of the interpolated precision measured at the 11 recall levels of 0.0 , 0.1 , 0.2 , ... , 1.0 .
234
The interpolated precision \MATH at a certain recall level \MATH is defined as the highest precision found for any recall level \MATH :
The interpolated precision \MATH at a certain recall level \MATH is defined as the highest precision found for any recall level \MATH :
235
</p>
</p>
236
<p>
<p>
237
In addition , to evaluate performance of multiple queries , we used mean average precision that is the mean of average precisions computed from queries .
In addition , to evaluate the performance of multiple queries , we used mean average precision , which is the mean of average precisions computed from queries .
238
</p>
</p>
239
</subsection>
</subsection>
240
<subsection label = �gPerformance of Baseline Methods�h>
<subsection label = �gPerformance of Baseline Methods�h>
241
<p>
<p>
242
We show in Figure \REF the retrieval performance of outliers detection methods and the baseline method using text correlation .
We show in Figure \REF the retrieval performance of the outlier detection methods and the baseline method using text correlation .
243
In the baseline method , faces are sorted by the time that the associated news article is published .
In the baseline method , faces were sorted by the time the associated news article was published .
244
It indicates that DBO-based method outperforms the others .
It indicated that the DBO-based method outperformed the others .
245
The baseline method performs the worst .
The baseline method performed the worst .
246
LOF-based method tends to be less sensitive when the threshold is changed .
The LOF-based method tends to be less sensitive when the threshold is changed .
247
This suggests that the input face sets are quite dense .
This suggests that the input face sets were quite dense .
248
</p>
</p>
249
</subsection>
</subsection>
250
<subsection label = �gPerformance of the Proposed Method�h>
<subsection label = �gPerformance of the Proposed Method�h>
251
<p>
<p>
252
We studied effect of choosing number of times \MATH in the Bag-Rank-SVM algorithm .
We studied the effect of choosing the number of times \MATH appeared in the Bag-Rank-SVM algorithm .
253
We used DBO as the method for making the initial rank list from which 30 training subsets were generated and used for training SVM classifiers using linear kernel with probability output .
We used DBO as the method for making the initial rank list from which 30 training subsets were generated and used for training SVM classifiers using linear kernels with probability output .
254
To select one subset , we set \MATH and \MATH which means 20% of highest ranked faces are used for \MATH and 30% of lowest ranked faces are used for \MATH .
To select one subset , we set \MATH and \MATH which means 20% of the highest ranked faces were used for \MATH and 30% of the lowest ranked faces were used for \MATH .
255
The subsets \MATH and \MATH are generated by randomly selecting with replacement 70% samples of \MATH amd \MATH .
The subsets \MATH and \MATH were generated by randomly selecting with replacement 70% samples of \MATH and \MATH .[�gWith replacement�h does not make sense here . I am not sure what you want to say .]
256
</p>
</p>
257
<p>
<p>
258
Figure \REF shows performance of single classifiers and ensemble classifiers .
Figure \REF shows the performance of single and ensemble classifiers .
259
It suggests that the performance does not change significantly after 5 iterations .
It suggests that the performance does not change significantly after five iterations .
260
In addition , the performance of the ranking process is improved when using the ensemble classifier .
In addition , the performance of the ranking process improved when the ensemble classifier was used .
261
</p>
</p>
262
<p>
<p>
263
We set the number of iterations for the Bag-Rank-SVM algorithm being 5 and set the number of iterations of the outer loop $T=30$ to see how much the final performance changes .
We set the number of iterations for the Bag-Rank-SVM algorithm at five and set the number of iterations of the outer loop $T=30$ to see how much the final performance changes .
264
As shown in Figure \REF , the performance does not change so much after 5 iterations .
As shown in Figure \REF , the performance did not change much after five iterations .
265
From these experiments , \MATH and \MATH are suitable values for the proposed method .
From these experiments , \MATH and \MATH are suitable values for the proposed method .
266
</p>
</p>
267
<p>
<p>
268
The performance of different methods shown in Figure \REF indicates that our proposed method outperforms the distance-based outliers detection method and has comparable performance with the supervised method using 5% annotation data .
The performance of different methods shown in Figure \REF indicates that our proposed method outperformed the distance-based outlier detection method and performed comparable to the supervised method using 5% annotation data .
269
As shown in Figure \REF , \REF , \REF , our proposed method produces better results in terms of average precision in which relevant faces are put on the top of the returned list .
As shown in Figures \REF , \REF , \REF , our proposed method produced better results in terms of average precision in which relevant faces were put at the top of the returned list .
270
</p>
</p>
271
</subsection>
</subsection>
272
</section>
</section>
273
<section label = �gCONCLUSION�h>
<section label = �gCONCLUSION�h>
274
<p>
<p>
275
We present a method to effectively rank faces retrieved by text-based correlation methods when searching a specific person .
We presented a method for effectively ranking faces retrieved using text-based correlation methods when searching for a specific person .
276
Using the rank list estimated from the previous steps , we automatically select a subset of positive and negative samples to train a classifier using SVM with probability outputs .
Using the rank list estimated from the previous steps , we automatically selected a subset of positive and negative samples to train a classifier using SVM with probability outputs . //[Since this is the conclusion , you might want to be more specific on what �gthe previous steps�h are . ]
277
This classifier is used to rank input faces for the next step .
This classifier was used to rank input faces for the next step .
278
Since labels of training sets are still noisy , the classified trained by these datasets are weak .
Since the labels of training sets were still noisy , the classifiers trained from these datasets were weak .
279
By combining multiple weak classifiers in a bagging framework , the final strong classifier is constructed and produce good results .
By combining multiple weak classifiers in a bagging framework , we constructed the final strong classifier , which produced good results .
280
To get initial rank for the first step , we propose to use common outliers detection method .
To obtain the initial rank for the first step , we proposed using a common outlier detection method .
281
Experiments on a large number of persons with thousands of retrieved images show effectiveness of the proposed method .
Experiments on a large number of persons with thousands of retrieved images showed the effectiveness of the proposed method .
282
</p>
</p>
283
</section>
</section>
284
</document>
</document>
