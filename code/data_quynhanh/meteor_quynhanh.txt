Alignment 1
While word segmentation is a necessary step to process languages like Chinese and Japanese , its effects on Statistical Machine Translation ( SMT ) have not been discussed intensively in such languages .
While word segmentation is necessary for processing the Chinese and Japanese languages , its effects on Statistical Machine Translation ( SMT ) have not yet been thoroughly discussed for such languages .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			5:1			0		1.0
6:2			8:1			3		1.0
8:1			11:1			0		1.0
9:1			12:1			0		1.0
10:1			13:1			0		1.0
11:1			9:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0
25:1			26:1			0		1.0
27:1			27:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0
31:1			32:1			0		1.0

Alignment 2
In this paper , we investigate the effects of word segmentation methods on SMT , by comparing evaluation results of translation outputs while varying word segmentation methods .
In this paper , we investigate the effects of word segmentation methods on SMT , by comparing the evaluation results of the translation outputs , while varying word segmentation methods .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
25:1			22:1			0		1.0
26:1			23:1			0		1.0
27:1			24:1			0		1.0
28:1			25:1			0		1.0
29:1			26:1			0		1.0
30:1			27:1			0		1.0

Alignment 3
Additionally , meta-evaluations of evaluation metrics are also provided to investigate validity of the metrics .
Additionally , meta-evaluations of evaluation metrics are also provided to investigate the validity of the metrics .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0

Alignment 4
The experiments revealed that supervised morphological analyzers were competitive , and considerably better than an unsupervised analyzer and a heuristic segmentation method .
The experimental results confirmed that supervised morphological analyzers were competitive with , and performed considerably better than an unsupervised analyzer and a heuristic segmentation method .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0

Alignment 5
However , a character-based segmentation has achieved 10 .27 positive and 1 .95 negative differences in word-based and character-based BLEU , depending on corpus sizes and domains .
However , a character-based segmentation achieved 10 .27 positive and 1 .95 negative differences in word-based and character-based BLEU , depending on the corpus sizes and domains .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0

Alignment 6
For this result we discuss the problem of the comparability of evaluation metrics and the possibility of better word segmentation than popular supervised morphological analyzers .
In conclusion , we discuss the problem of the comparability of evaluation metrics , and consider ways of improving word segmentation more than popular supervised morphological analyzers .
Line2Start:Length	Line1Start:Length	Module		Score
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
14:1			13:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			2		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0

Alignment 7
Several natural languages like Chinese and Japanese do not have to put spaces between words in their written forms .
Several languages , including Chinese and Japanese , do not require spaces between words , in their written forms .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			2:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 8
In order to process such languages , we need to tokenize each sentence .
In order to process such languages , we need to tokenize each sentence .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 9
This process is called word segmentation .
This process is called word segmentation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0

Alignment 10
Since the process is fundamental and indispensable , we need to explore how word segmentation affects Natural Language Processing applications .
Since word segmentation is a fundamental process , and is therefore indispensable , it is important that we explore how word segmentation affects Natural Language Processing applications .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			13:1			0		1.0
2:1			14:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			2:1			0		1.0
8:1			5:1			0		1.0
11:1			6:1			0		1.0
12:1			7:1			0		1.0
14:2			9:1			3		1.0
17:1			8:1			0		1.0
18:1			11:1			0		1.0
19:1			12:1			0		1.0
22:1			15:1			0		1.0
23:1			16:1			0		1.0
24:1			17:1			0		1.0
25:1			18:1			0		1.0
26:1			19:1			0		1.0
27:1			20:1			0		1.0

Alignment 11
Therefore , we investigate how Japanese word segmentation affects on SMT between English and Japanese , by comparing various word segmentation methods and evaluation metrics .
Thus , we investigate how Japanese word segmentation affects SMT between English and Japanese , by comparing various word segmentation methods and evaluation metrics .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0

Alignment 12
The word segmentation methods includes both standard Japanese morphological analyzers and several heuristic methods .
The word segmentation methods include both standard Japanese morphological analyzers and several heuristic methods .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			1		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 13
We also examine an unsupervised morphological analyzer and its results .
In addition , we examine an unsupervised morphological analyzer , and its results .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			3		1.0
4:1			2:1			0		1.0
5:1			3:1			0		1.0
6:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			0		1.0

Alignment 14
In addition , we focus on the meta-evaluation of the current evaluation metrics and find whether the metrics are consistent or not , when we vary word segmentation methods .
We focus on the meta-evaluation of the current evaluation metrics and determine whether the metrics are consistent or not , when we vary word segmentation methods .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			4:1			0		1.0
2:1			5:1			0		1.0
3:1			6:1			0		1.0
4:1			7:1			0		1.0
5:1			8:1			0		1.0
6:1			9:1			0		1.0
7:1			10:1			0		1.0
8:1			11:1			0		1.0
9:1			12:1			0		1.0
10:1			13:1			0		1.0
11:1			14:1			2		1.0
12:1			15:1			0		1.0
13:1			16:1			0		1.0
14:1			17:1			0		1.0
15:1			18:1			0		1.0
16:1			19:1			0		1.0
17:1			20:1			0		1.0
18:1			21:1			0		1.0
19:1			22:1			0		1.0
20:1			23:1			0		1.0
21:1			24:1			0		1.0
22:1			25:1			0		1.0
23:1			26:1			0		1.0
24:1			27:1			0		1.0
25:1			28:1			0		1.0
26:1			29:1			0		1.0

Alignment 15
Al-Haj and Lavie ( 2012 ) compared 12 heuristic word segmentation methods based on outputs of a standard Arabic POS tagger , and found the optimum combination in terms of BLEU on English-Arabic SMT .
Al-Haj and Lavie ( 2012 ) compared 12 heuristic word segmentation methods based on the outputs of a standard Arabic POS tagger , and found the optimum combination in terms of BLEU on English-Arabic SMT .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0

Alignment 16
They acquired the 2 .3 score improvement from the worst to the best combinations .
They acquired a 2 .3 score improvement in comparing the worst to best combinations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 17
Wang et al.
Wang et al.
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0

Alignment 18
( 2010 ) suggested a new short unit word segmentation standard in Chinese which defines a more frequent string subset as a word .
( 2010 ) suggested a new short unit word segmentation standard in Chinese , which defines a more frequent string subset as a word .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0

Alignment 19
For instance , They separated one word " 全球化 globalization " into two words " 全球 global " and " 化 -lization " .
For instance , one word “全球化 globalization” was separated into two words “全球 global” and “化 -lization” .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			5:1			0		1.0
4:1			6:1			0		1.0
8:1			4:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
14:1			18:1			0		1.0
17:1			23:1			0		1.0

Alignment 20
By this standard , they obtained 1 .0 BLEU score improvement within Chinese-Japanese SMT .
By this standard , they obtained 1 .0 BLEU score improvement within Chinese-Japanese SMT .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 21
Though , they have not discussed about BLEU is a good metric for such an evaluation of word segmentation .
However , it has not yet been discussed whether BLEU is a good metric for such an evaluation of word segmentation .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
3:1			2:2			3		1.0
4:1			4:1			0		1.0
7:1			5:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0

Alignment 22
In addition , comparison of morphological analyzers are necessary because different analyzers produce different outputs to SMT .
In addition , comparing morphological analyzers is necessary , because different analyzers produce different outputs to SMT .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:2			3		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			2		1.0
7:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 23
Therefore , we conduct several translation tasks between English and Japanese .
We therefore conduct several translation tasks between English and Japanese .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0

Alignment 24
We measure the qualities of Japanese morphological analyzers and compare them with other word segmentation methods .
We measure the qualities of Japanese morphological analyzers and compare them with other word segmentation methods .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 25
We also investigate consistencies of evaluation metrics by comparing results .
We also investigate consistencies of evaluation metrics by comparing the results .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0

Alignment 26
This work aims to empirically compare representative word segmentation methods in terms of SMT quality .
This work aims at empirically comparing representative word segmentation methods in terms of the SMT quality .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:2			2:2			3		1.0
4:1			4:1			0		1.0
5:1			5:1			1		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0

Alignment 27
The following experiments are designed in order to answer these questions :
The following experiments are designed in order to answer these questions :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 28
- How a variety of word segmentation methods ( supervised morphological analysis , unsupervised segmentation , and heuristic methods ) affect SMT evaluation metrics , depending on corpus sizes and domains .
- How a variety of word segmentation methods ( supervised morphological analysis , unsupervised segmentation , and heuristic methods ) affects the SMT evaluation metrics , depending on the corpus sizes and domains .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			1		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
33:1			31:1			0		1.0

Alignment 29
- Whether or not SMT evaluation metrics provide a consistent measure while varying word segmentation methods .
- Whether or not SMT evaluation metrics provide a consistent measure , while varying word segmentation methods .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0

Alignment 30
We setup word segmentation methods , corpora , and evaluation metrics as three parameters of our experiments to see the effects of Japanese word segmentation on SMT .
We set up word segmentation methods , corpora , and evaluation metrics , as the three parameters for our experiments , in order to observe the effects of Japanese word segmentation on SMT .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			19:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
23:1			17:1			0		1.0
24:1			18:1			3		1.0
26:1			20:1			0		1.0
27:1			21:1			0		1.0
28:1			22:1			0		1.0
29:1			23:1			0		1.0
30:1			24:1			0		1.0
31:1			25:1			0		1.0
32:1			26:1			0		1.0
33:1			27:1			0		1.0

Alignment 31
As shown in Table 1 , the following word segmentation methods output delimiters ( " | " represents a delimiter ) for a given input character sequence .
As shown in Table 1 , the following word segmentation methods output delimiters ( “|” represents a delimiter ) for a given input character sequence .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0
24:1			26:1			0		1.0
25:1			27:1			0		1.0

Alignment 32
The most popular method for Japanese word segmentation is to apply a morphological analyzer to obtain morpheme-based segmentation .
The most popular method for Japanese word segmentation is to apply a morphological analyzer to obtain morpheme-based segmentation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 33
It is , however , not clear which analyzer works better for the SMT task than the other analyzers .
It is ; however , unclear as to which analyzer works better for the SMT task .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:2			3		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			19:1			0		1.0

Alignment 34
Therefore , we use four representative morphological analyzers and compare them :
Therefore , we use four representative morphological analyzers and compare them :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 35
- KyTea predicts word segmentation delimiters by pointwise prediction ( Neubig et al. , 2011 ) , using linear Support Vector Machine or logistic regression .
- KyTea predicts word segmentation delimiters by pointwise prediction ( Neubig et al. , 2011 ) , using linear Support Vector Machine or logistic regression .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 36
- MeCab regards word segmentation as a sequence labeling problem .
- MeCab regards word segmentation as a sequence labeling problem .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 37
It uses Conditional Random Field for learning ( Kudo et al. , 2004 ) .
It uses Conditional Random Field for learning ( Kudo et al. , 2004 ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 38
- JUMAN also regards word segmentation as a sequence labeling , but it decides the minimum cost paths without machine learning , from segmentation and association costs in human annotated lexicons and automatically generated Web lexicons .
- JUMAN also regards word segmentation as a sequence labeling problem , but it decides the minimum cost paths without machine learning , from segmentation and association costs in human annotated lexicons and automatically generated Web lexicons .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
37:1			36:1			0		1.0

Alignment 39
The accuracy of supervised morphological analyzers KyTea , MeCab , and JUMAN is reported to be over 98\% for news text .
The accuracy of supervised morphological analyzers KyTea , MeCab , and JUMAN is reported to be over 98% for news texts .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			1		1.0
21:1			21:1			0		1.0

Alignment 40
On the other hand , the unsupervised method latticelm achieved 66 .6% accuracy ( Mochihashi et al. , 2009 ) for human annotated news text , while the method does not have any answers of word definitions .
On the other hand , the unsupervised method , latticelm , achieved 66 .6% accuracy ( Mochihashi et al. , 2009 ) for human annotated news texts , while the method does not have any answers for word definitions .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			17:1			0		1.0
9:1			8:1			0		1.0
10:1			25:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			1		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
33:1			31:1			0		1.0
34:1			32:1			0		1.0
35:1			33:1			0		1.0
37:1			35:1			0		1.0
38:1			36:1			0		1.0
39:1			37:1			0		1.0

Alignment 41
Therefore , it is not possible to compare such a result with the supervised results . Even though , it is fair to compare it with SMT contribution point of view .
Therefore , it is not possible to compare its result with the supervised results , even though it is fair to compare it from the SMT contribution point-of-view .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			18:1			0		1.0
16:1			17:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
28:1			15:1			0		1.0

Alignment 42
Furthermore , their policies about word segmentation definitions are very much different .
Furthermore , their policies concerning word segmentation definitions vary significantly .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			3		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			11:1			3		1.0
9:1			10:1			3		1.0
10:1			12:1			0		1.0

Alignment 43
While MeCab can change its definitions by external lexicons and JUMAN has its own internal standard , KyTea is based on the short unit standard of Balanced Corpus of Contemporary Written Japanese , which is considered one of the shortest definitions of Japanese words .
While MeCab can change its definitions by external lexicons , and JUMAN has its own internal standard , KyTea is based on the short unit standard of the Balanced Corpus of Contemporary Written Japanese , which is considered to have one of the shortest definitions of Japanese words .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			32:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			38:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
33:1			31:1			0		1.0
35:1			33:1			0		1.0
36:1			34:1			0		1.0
37:1			35:1			0		1.0
40:1			36:1			0		1.0
41:1			37:1			0		1.0
43:1			39:1			0		1.0
44:1			40:1			0		1.0
45:1			41:1			0		1.0
46:1			42:1			0		1.0
47:1			43:1			0		1.0
48:1			44:1			0		1.0

Alignment 44
For example , if we are given a string " 見れば( if someone see ) " , MeCab separates it into two words " 見れ | ば " and JUMAN keep the same string , but KyTea outputs it as three words " 見 | れ | ば " where every character is a word .
For example , if we are given a string , “見れば( if someone sees )” , MeCab separates it into two words , “見れ | ば” and JUMAN retains the same string , but KyTea outputs it as three words , “見 | れ | ば” where every character is a word .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			34:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			1		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
24:1			25:1			0		1.0
26:1			28:1			0		1.0
27:1			29:1			0		1.0
28:1			30:1			2		1.0
29:1			31:1			0		1.0
30:1			32:1			0		1.0
31:1			33:1			0		1.0
33:1			35:1			0		1.0
34:1			36:1			0		1.0
35:1			37:1			0		1.0
36:1			38:1			0		1.0
37:1			39:1			0		1.0
38:1			40:1			0		1.0
39:1			41:1			0		1.0
42:1			44:1			0		1.0
43:1			45:1			0		1.0
44:1			46:1			0		1.0
46:1			49:1			0		1.0
47:1			50:1			0		1.0
48:1			51:1			0		1.0
49:1			52:1			0		1.0
50:1			53:1			0		1.0
51:1			54:1			0		1.0
52:1			55:1			0		1.0

Alignment 45
In the case of latticelm , as it has no supervised definition of words , it uses the expectation maximized length of words for every word depending on training data .
For latticelm , since it has no supervised definition of words , it uses the expectation maximized length of words for every word , depending on the training data .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			4:1			0		1.0
2:1			5:1			0		1.0
4:1			7:1			0		1.0
5:1			8:1			0		1.0
6:1			9:1			0		1.0
7:1			10:1			0		1.0
8:1			11:1			0		1.0
9:1			12:1			0		1.0
10:1			13:1			0		1.0
11:1			14:1			0		1.0
12:1			15:1			0		1.0
13:1			16:1			0		1.0
14:1			17:1			0		1.0
15:1			18:1			0		1.0
16:1			19:1			0		1.0
17:1			20:1			0		1.0
18:1			21:1			0		1.0
19:1			22:1			0		1.0
20:1			23:1			0		1.0
21:1			24:1			0		1.0
22:1			25:1			0		1.0
24:1			26:1			0		1.0
25:1			27:1			0		1.0
26:1			1:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0

Alignment 46
We also investigate such morphological analysis accuracy and word definition problems in our experiments .
In our experiments , we further investigate such morphological analysis accuracies and word definition problems .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			12:1			0		1.0
2:1			13:1			0		1.0
5:1			1:1			3		1.0
6:1			2:1			0		1.0
7:1			3:1			0		1.0
8:1			4:1			0		1.0
9:1			5:1			0		1.0
10:1			6:1			1		1.0
11:1			7:1			0		1.0
12:1			8:1			0		1.0
13:1			9:1			0		1.0
14:1			10:1			0		1.0
15:1			14:1			0		1.0

Alignment 47
Chang et al.
Chang et al.
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0

Alignment 48
( 2008 ) suggested that word segmentation consistency and granularity can be important factors for SMT .
( 2008 ) suggested that word segmentation consistency and granularity can be important factors for SMT .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 49
Therefore , we introduce two heuristic methods for Japanese word segmentation .
Therefore , we introduce two heuristic methods for Japanese word segmentation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 50
One is segmentation by character category ( CAT ) , and the other is segmentation by characters ( CHAR ) .
One method is segmentation by character category ( CAT ) , and the other is segmentation by characters ( CHAR ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0

Alignment 51
CAT puts a word boundary when character categories change .
CAT places a word boundary when character categories change .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			2		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 52
Character categories in Japanese include : Kanji ( Chinese character ) , Hiragana , Katakana , Latin alphabet , numeral digit , multi-byte alphabet , multi-byte digit , and other tokens .
Character categories in Japanese include : Kanji ( Chinese character ) , Hiragana , Katakana , Latin alphabet , numeral digit , multi-byte alphabet , multi-byte digit , and other tokens .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0

Alignment 53
The CHAR method considers every Unicode character as a word as proposed by Xu et al.
The CHAR method considers every Unicode character as a word , as proposed by Xu et al.
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0

Alignment 54
( 2004 ) .
( 2004 ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0

Alignment 55
We use two news corpora : Reuters corpora ( REUTERS ) and Japanese-English News Article Alignment Data ( JENAAD ) ( Utiyama and Isahara , 2003 ) .
We use two news corpora : Reuters corpora ( REUTERS ) and Japanese-English News Article Alignment Data ( JENAAD ) ( Utiyama and Isahara , 2003 ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0

Alignment 56
Another corpus we use in the experiments is a Wikipedia corpus , Japanese-English Bilingual Corpus of Wikipedia 's Kyoto Articles 2 .01 ( WIKIPEDIA ) .
Another corpus we use in the experiments is a Wikipedia corpus : the Japanese-English Bilingual Corpus of Wikipedia 's Kyoto Articles 2 .01 ( WIKIPEDIA ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0

Alignment 57
From these corpora , we prepared three data sets as explained below .
From these corpora , we prepared three data sets , as explained below .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0

Alignment 58
In the case of REUTERS , we have used all 56 ,282 sentences .
For REUTERS , we used all 56 ,282 sentences .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			4:1			0		1.0
2:1			5:1			0		1.0
3:1			6:1			0		1.0
4:1			8:1			0		1.0
5:1			9:1			0		1.0
6:1			10:1			0		1.0
7:1			11:1			0		1.0
8:1			12:1			0		1.0
9:1			13:1			0		1.0

Alignment 59
Then , we split the data into three parts : the first 1 ,000 as the test , the next 500 as the development , and the rest 55 ,282 as the training data .
Then , we split the data into three parts : the first 1 ,000 as the test , the next 500 as the development , and the remaining 55 ,282 as the training data .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			2		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0

Alignment 60
In this data , we have combined JENAAD and REUTERS news corpora to get one news corpus .
For this data , we combined the JENAAD and REUTERS news corpora to acquire one news corpus .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			2		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 61
We have used all 56 ,282 and 150 ,000 sentences respectively .
We used all 56 ,282 and 150 ,000 sentences , respectively .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 62
For each corpus , we divide it into the first 1 ,000 , the next 500 , and the rest for test , development , and training .
For each corpus , we divided the sentences into the first 1 ,000 for testing , the next 500 for development , and the remaining for training .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			1		1.0
6:1			18:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			20:1			0		1.0
14:1			21:1			1		1.0
15:1			22:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
20:1			23:1			0		1.0
21:1			24:1			0		1.0
22:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0

Alignment 63
We have gathered 2000 , 1000 , and 203 ,782 sentences for test , development , and training , respectively , in total .
In total , we gathered 2000 , 1000 , and 203 ,782 sentences for test , development , and training , respectively .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			22:1			0		1.0
2:1			20:1			0		1.0
4:1			2:1			0		1.0
5:1			3:1			0		1.0
6:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			23:1			0		1.0

Alignment 64
Firstly , since the WIKIPEDIA corpus is a multi-category XML dataset , we have sorted them by the DOCID in the ascending order and by the document categories LTT , EPR , FML , BDS , CLT , BLD , GNM , SCL , ROD , SNT , PNM , HST , RLW , and SAT .
Since the WIKIPEDIA corpus is a multi-category XML dataset , we sorted them by the DOCID in ascending order , and by the document categories : LTT , EPR , FML , BDS , CLT , BLD , GNM , SCL , ROD , SNT , PNM , HST , RLW , and SAT .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			3:1			0		1.0
2:1			4:1			0		1.0
3:1			5:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			14:1			0		1.0
12:1			15:1			0		1.0
13:1			16:1			0		1.0
14:1			17:1			0		1.0
15:1			18:1			0		1.0
16:1			19:1			0		1.0
17:1			21:1			0		1.0
18:1			22:1			0		1.0
19:1			1:1			0		1.0
20:1			23:1			0		1.0
21:1			24:1			0		1.0
22:1			25:1			0		1.0
23:1			26:1			0		1.0
24:1			27:1			0		1.0
26:1			28:1			0		1.0
27:1			29:1			0		1.0
28:1			30:1			0		1.0
29:1			31:1			0		1.0
30:1			32:1			0		1.0
31:1			33:1			0		1.0
32:1			34:1			0		1.0
33:1			35:1			0		1.0
34:1			36:1			0		1.0
35:1			37:1			0		1.0
36:1			38:1			0		1.0
37:1			39:1			0		1.0
38:1			40:1			0		1.0
39:1			41:1			0		1.0
40:1			42:1			0		1.0
41:1			43:1			0		1.0
42:1			44:1			0		1.0
43:1			45:1			0		1.0
44:1			46:1			0		1.0
45:1			47:1			0		1.0
46:1			48:1			0		1.0
47:1			49:1			0		1.0
48:1			50:1			0		1.0
49:1			51:1			0		1.0
50:1			52:1			0		1.0
51:1			53:1			0		1.0
52:1			54:1			0		1.0
53:1			55:1			0		1.0
54:1			56:1			0		1.0

Alignment 65
Secondly , we parsed it by xml .etree .ElementTree .parse of Python 2 .7 .2 , and obtained 477 ,036 sentence pairs without parsing errors .
Next , we parsed it by xml .etree .ElementTree .parse of Python 2 .7 .2 , and obtained 477 ,036 sentence pairs without parsing errors .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 66
Thirdly , sentence pairs that include a character " | " in English or Japanese are removed because it caused a problem with Moses .
Then , sentence pairs that include a character “|” in English or Japanese were removed , because it caused a problem with Moses .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			2		1.0
14:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0

Alignment 67
Finally , we obtained 477 ,012 sentence pairs in total .
Finally , we obtained 477 ,012 sentence pairs in total .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 68
In order to adjust the balance of the domains , we have sampled the data twice : First we extract the first line for every 477 lines .
In order to adjust the balance of the domains , we sampled the data twice : First , we extracted the first line for every 477 lines .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			1		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0

Alignment 69
After this , we have merged the remaining 476 ,012 lines and from this extract the first line for every 952 lines .
Then , we merged the remaining 476 ,012 lines , and from this extract , we extracted the first line for every 952 lines .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			5:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0

Alignment 70
Finally , we have obtained 1 ,000 test , 500 development , and 475 ,512 training data .
Finally , we obtained 1 ,000 test , 500 development , and 475 ,512 training data .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0

Alignment 71
We have launched two word-based evaluation methods : BLEU ( Papineni et al. , 2002 ) with 4-gram setting and RIBES ( Isozaki et al. , 2010a ) , which has been reported to have a much higher correlation to human evaluation than BLEU within English-Japanese translation tasks ( Sudoh et al. , 2011 ) .
We have launched two word-based evaluation methods : BLEU ( Papineni et al. , 2002 ) with 4-gram setting and RIBES ( Isozaki et al. , 2010a ) , which has been reported to have a much higher correlation to human evaluation than BLEU within English-Japanese translation tasks ( Sudoh et al. , 2011 ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0
49:1			49:1			0		1.0
50:1			50:1			0		1.0
51:1			51:1			0		1.0
52:1			52:1			0		1.0
53:1			53:1			0		1.0
54:1			54:1			0		1.0
55:1			55:1			0		1.0

Alignment 72
Currently , the most popular way to evaluate Statistical Machine Translation is to use word-based evaluation metrics such as BLEU and RIBES .
Currently , the most popular way to evaluate SMT is to use word-based evaluation metrics , such as BLEU and RIBES .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0

Alignment 73
However , these word-based evaluation metrics have a problem on independency of word segmentation evaluations .
However , these word-based evaluation metrics have a problem on independency of word segmentation evaluations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 74
If we do not have segmented reference and test data , we cannot evaluate outputs by word-based evaluation metrics .
If we do not have segmented reference and test data , we cannot evaluate the outputs by word-based evaluation metrics .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0

Alignment 75
For example , in the case of English-Japanese translations , we must tokenize reference data to evaluate SMT outputs .
For example , for English-Japanese translations , we must tokenize reference data to evaluate SMT outputs .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			7:1			0		1.0
5:1			8:1			0		1.0
6:1			9:1			0		1.0
7:1			10:1			0		1.0
8:1			11:1			0		1.0
9:1			12:1			0		1.0
10:1			13:1			0		1.0
11:1			14:1			0		1.0
12:1			15:1			0		1.0
13:1			16:1			0		1.0
14:1			17:1			0		1.0
15:1			18:1			0		1.0
16:1			19:1			0		1.0

Alignment 76
On the other hand , in the case of Japanese-English translations , we must tokenize test data to evaluate the outputs .
On the other hand , for Japanese-English translations , we must tokenize test data to evaluate the outputs .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			9:1			0		1.0
7:1			10:1			0		1.0
8:1			11:1			0		1.0
9:1			12:1			0		1.0
10:1			13:1			0		1.0
11:1			14:1			0		1.0
12:1			15:1			0		1.0
13:1			16:1			0		1.0
14:1			17:1			0		1.0
15:1			18:1			0		1.0
16:1			19:1			0		1.0
17:1			20:1			0		1.0
18:1			21:1			0		1.0

Alignment 77
As a result , we need to tokenize every sentence by word segmentation before evaluation , and it is hard to independently evaluate the effects of word segmentation on training data .
As a result , we need to tokenize every sentence by word segmentation before evaluation , and it is therefore difficult to independently evaluate the effects of word segmentation on training data .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
20:2			19:2			3		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0

Alignment 78
It is also possible to detokenize SMT outputs first , and then tokenize them by the shared word segmentation .
It is also possible to detokenize SMT outputs first , and then tokenize them by the shared word segmentation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 79
However , our preliminary experiments showed that the results obtained with this method were not independent from word segmentation of training data .
However , our preliminary experiments indicated that the results obtained with this method were not independent from word segmentation of the training data .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:2			5:2			3		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0

Alignment 80
And the best results were obtained when we use the same word segmentation as the training data .
The best results were obtained when we used the same word segmentation as the training data .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:2			8:2			3		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0

Alignment 81
Hence , this problem remains if we keep our word-based evaluations .
Hence , if we keep our word-based evaluations , this problem remains .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			5:1			0		1.0
3:1			6:1			0		1.0
4:1			7:1			0		1.0
5:1			8:1			0		1.0
6:1			9:1			0		1.0
7:1			10:1			0		1.0
9:1			2:1			0		1.0
10:1			3:1			0		1.0
11:1			4:1			0		1.0
12:1			11:1			0		1.0

Alignment 82
In order to manage such a problem , we use one character-based metric BLEU in Characters ( De-noual and Lepage , 2005 ) with 4-gram .
In order to manage this issue , we used one character-based metric BLEU in Characters ( De-noual and Lepage , 2005 ) with 4-gram .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			6:1			3		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			1		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0

Alignment 83
As this method evaluates the character-level information , outputs are not required to be segmented and it is free from word segmentation variations .
As this method evaluates the character-level information , outputs are not required to be segmented , and it is free from word segmentation variations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0

Alignment 84
We have conducted English and Japanese machine translation in both directions by the following steps :
We have conducted English and Japanese machine translation in both directions , following the steps below :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			13:1			0		1.0
13:1			12:1			0		1.0
14:1			14:1			0		1.0
16:1			15:1			0		1.0

Alignment 85
1Apply the Head-Finalization ( Isozaki et al. , 2010b ) to English text in the case of English-Japanese translation .
1 .Apply the Head-Finalization ( Isozaki et al. , 2010b ) to English text in the case of English-Japanese translation .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0

Alignment 86
2Run Japanese word segmentation methods and a normalization script which was introduced by the NTCIR-9 PATMT task .
2 .Run Japanese word segmentation methods and a normalization script , which was introduced by the NTCIR-9 PATMT task .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0

Alignment 87
3Tokenize and lowercase English text by Moses' tokenizer and lowercase scripts .
3 .Tokenize and lowercase English texts by Moses' tokenizer and lowercase scripts .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			1		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0

Alignment 88
4Create language models from target languages' training data , with SRILM 1 .5 .12 .
4 .Create language models from target languages' training data , with SRILM 1 .5 .12 .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0

Alignment 89
5Create translation models with Giza++ 1 .0 .5 ( 2011-09-24 ) .
5 .Create translation models with Giza++ 1 .0 .5 ( 2011-09-24 ) .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0

Alignment 90
6Decode source test data with Moses ( 2010-08-13 ) .
6 .Decode source test data with Moses ( 2010-08-13 ) .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0

Alignment 91
7Compute evaluation scores of the outputs .
7 .Compute evaluation scores of the outputs .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0

Alignment 92
We used Enju 2 .4 .2 ( Miyao and Tsujii , 2005 ) and Head Finalization ( Isozaki et al. , 2010b ) to preprocess English data .
We used Enju 2 .4 .2 ( Miyao and Tsujii , 2005 ) and Head Finalization ( Isozaki et al. , 2010b ) to preprocess English data .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0

Alignment 93
This method enabled more accurate translations within English-Japanese translations than the conventional settings .
This method enabled more accurate translations within English-Japanese translations than with the conventional settings .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0

Alignment 94
We have applied the following Head Finalization rules from ( Su-doh et al. , 2011 ) :
We have applied the following Head Finalization rules from ( Su-doh et al. , 2011 ) :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 95
- Reverse each phrase 's word orders when the phrase does not end with a head .
- Reverse each phrase 's word orders when the phrase does not end with a head .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 96
- Exclude coordination from reversing
- Exclude coordination from reversing
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0

Alignment 97
- Convert plural nouns to singular forms
- Convert plural nouns to singular forms
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0

Alignment 98
- Remove articles " a " , " an " , and " the "
- Remove articles “a” , “an” , and “the”
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			6:1			0		1.0
6:1			10:1			0		1.0
7:1			11:1			0		1.0

Alignment 99
- Insert pseudo-particles _va0 , _va1 , and _va2 .
- Insert pseudo-particles _va0 , _va1 , and _va2 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 100
For the pseudo-particles , we use the following insertion rules ( arg1 and arg2 are swapped when the head verb 's voice is passive ) :
For the pseudo-particles , we use the following insertion rules ( arg1 and arg2 are swapped when the head verb 's voice is passive ) :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 101
- Add _va0 after the arg1 entry of the sentence head verb
- Add _va0 after the arg1 entry of the sentence head verb
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 102
- Add _va1 after arg1 entries of other verbs
- Add _va1 after arg1 entries of other verbs
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 103
- Add _va2 after arg2 entries of all verbs
- Add _va2 after arg2 entries of all verbs
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 104
Table 2 and Table 3 show the English-Japanese and Japanese-English evaluation results .
Table 2 and Table 3 show the English-Japanese and Japanese-English evaluation results .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 105
The best scores in each evaluation metrics are highlighted for each data set .
The best scores in each evaluation metrics are highlighted for each data set .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 106
All evaluation metrics have been used in both directions between English and Japanese , to measure consistency and sufficiency of the metrics in the language pair .
All evaluation metrics have been used in both directions between English and Japanese , to measure the consistency and sufficiency of the metrics in the language pair .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0

Alignment 107
In this case , the evaluation scores created by BLEU and RIBES are not comparative due to the differences of Japanese word definitions between the outputs of word segmentation methods .
In this case , the evaluation scores created by BLEU and RIBES are not comparative , due to the differences in the Japanese word definitions among the outputs of word segmentation methods .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:2			18:2			3		1.0
21:1			24:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:2			23:1			3		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0

Alignment 108
Furthermore , the CHAR scores in BLEU and BLEU in Characters should be regarded as almost same while small changes have been introduced due to statistical errors and the differences in the methods how to treat space characters .
Furthermore , the CHAR scores in BLEU and BLEU in Characters should be regarded as almost the same , while small changes have been introduced , due to statistical errors and the differences in the methods in how to treat space characters .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			31:1			0		1.0
17:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
26:1			23:1			0		1.0
27:1			24:1			0		1.0
28:1			25:1			0		1.0
29:1			26:1			0		1.0
30:1			27:1			0		1.0
31:1			28:1			0		1.0
32:1			29:1			0		1.0
33:1			30:1			0		1.0
35:1			32:1			0		1.0
37:1			33:1			0		1.0
38:1			34:1			0		1.0
39:1			35:1			0		1.0
40:1			36:1			0		1.0
41:1			37:1			0		1.0
42:1			38:1			0		1.0

Alignment 109
We found that the three supervised morphological analyzers KyTea , MeCab , and JUMAN were much higher than latticelm and CAT , and were competitive .
We found that the three supervised morphological analyzers : KyTea , MeCab , and JUMAN were much higher than latticelm and CAT , and were competitive .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0

Alignment 110
For instance , on REUTERS in Table 2 , BLEU scores were ranged from 27 .88 to 29 .53 , while latticelm was 15 .28 and CAT was 22 .10 .
For instance , on REUTERS in Table 2 , BLEU scores ranged from 27 .88 to 29 .53 , while for latticelm , the score was 15 .28 and for CAT , the score was 22 .10 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
21:1			21:1			0		1.0
25:1			22:1			0		1.0
26:1			23:1			0		1.0
27:1			24:1			0		1.0
28:1			25:1			0		1.0
30:1			26:1			0		1.0
34:1			27:1			0		1.0
35:1			28:1			0		1.0
36:1			29:1			0		1.0
37:1			30:1			0		1.0

Alignment 111
The unsupervised morphological analyzer latticelm and one of heuristic methods CAT were worse than our expectations .
The unsupervised morphological analyzer , latticelm , and one of heuristic methods , CAT , performed worse than expectations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
13:1			10:1			0		1.0
16:1			12:1			0		1.0
17:1			13:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0

Alignment 112
These two were the worst or the second worst results in all settings .
These two results were the worst , in all of the settings .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			9:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
7:1			10:1			0		1.0
8:1			11:1			0		1.0
10:1			6:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0

Alignment 113
The results of CHAR were counterintuitive and yet to be discussed .
The results of CHAR were counterintuitive and are yet to be discussed .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0

Alignment 114
It was relatively much better than the supervised morphological analyzers in BLEU .
The results were better than the results for the supervised morphological analyzers in BLEU .
Line2Start:Length	Line1Start:Length	Module		Score
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0

Alignment 115
Besides , it was almost competitive in RIBES and BLUE in Characters .
It was almost competitive in RIBES and BLUE in Characters .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			3:1			0		1.0
2:1			4:1			0		1.0
3:1			5:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0

Alignment 116
For example , CHAR achieved the best 38 .42 score in BLEU on REUTERS , but the second best KyTea was 29 .53 .
CHAR achieved the best score in BLEU on REUTERS ( 38 .42 ) , but the second-best was KyTea ( 29 .53 ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			3:1			0		1.0
1:1			4:1			0		1.0
2:1			5:1			0		1.0
3:1			6:1			0		1.0
4:1			9:1			0		1.0
5:1			10:1			0		1.0
6:1			11:1			0		1.0
7:1			12:1			0		1.0
8:1			13:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
17:1			20:1			0		1.0
18:1			19:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 117
In the case of BLEU in Characters on REUTERS , CHAR achieved 38 .61 , while the worst supervised result was KyTea 's 39 .82 .
For BLEU in Characters on REUTERS , CHAR achieved 38 .61 , while the worst supervised result was KyTea 's 39 .82 .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			4:1			0		1.0
2:1			5:1			0		1.0
3:1			6:1			0		1.0
4:1			7:1			0		1.0
5:1			8:1			0		1.0
6:1			9:1			0		1.0
7:1			10:1			0		1.0
8:1			11:1			0		1.0
9:1			12:1			0		1.0
10:1			13:1			0		1.0
11:1			14:1			0		1.0
12:1			15:1			0		1.0
13:1			16:1			0		1.0
14:1			17:1			0		1.0
15:1			18:1			0		1.0
16:1			19:1			0		1.0
17:1			20:1			0		1.0
18:1			21:1			0		1.0
19:1			22:1			0		1.0
20:1			23:1			0		1.0
21:1			24:1			0		1.0
22:1			25:1			0		1.0

Alignment 118
In this case , the evaluation scores are lower than English-Japanese translations in general .
For Japanese-English translations , the evaluation scores were generally lower than for English-Japanese translations .
Line2Start:Length	Line1Start:Length	Module		Score
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			2		1.0
8:1			12:2			3		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			14:1			0		1.0

Alignment 119
It is because Japanese-English translations are conducted without Head-Finalization .
This is because Japanese-English translations are conducted without Head-Finalization .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 120
Again , the supervised morphological analyzers KyTea , MeCab , and JUMAN were competitive .
Again , the supervised morphological analyzers KyTea , MeCab , and JUMAN were competitive .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 121
All supervised analyzers were better than the unsupervised and the both heuristic methods .
All supervised analyzers performed better than the unsupervised and the both heuristic methods .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 122
On the other hand , the unsupervised morphological analyzer latticelm and one of heuristic methods CAT were competitive to the supervised analyzers in RIBES .
Conversely , the unsupervised morphological analyzer latticelm and one of heuristic methods CAT performed competitively with the supervised analyzers in RIBES .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			4:1			0		1.0
2:1			5:1			0		1.0
3:1			6:1			0		1.0
4:1			7:1			0		1.0
5:1			8:1			0		1.0
6:1			9:1			0		1.0
7:1			10:1			0		1.0
8:1			11:1			0		1.0
9:1			12:1			0		1.0
10:1			13:1			0		1.0
11:1			14:1			0		1.0
12:1			15:1			0		1.0
16:1			19:1			0		1.0
17:1			20:1			0		1.0
18:1			21:1			0		1.0
19:1			22:1			0		1.0
20:1			23:1			0		1.0
21:1			24:1			0		1.0

Alignment 123
For example , latticelm was 62 .51 and KyTea was 62 .90 on REUTERS .
latticelm was 62 .51 and KyTea was 62 .90 on REUTERS .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			3:1			0		1.0
1:1			4:1			0		1.0
2:1			5:1			0		1.0
3:1			6:1			0		1.0
4:1			7:1			0		1.0
5:1			8:1			0		1.0
6:1			9:1			0		1.0
7:1			10:1			0		1.0
8:1			11:1			0		1.0
9:1			12:1			0		1.0
10:1			13:1			0		1.0
11:1			14:1			0		1.0

Alignment 124
In this case , CHAR was not competitive to the supervised analyzers in total .
In this case , CHAR was not competitive to the supervised analyzers in total .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 125
The results were the worst scores in BLEU and RIBES on REUTERS and JENAAD+REUTERS . The only one exception was in the case of the best 56 .55 BLEU in Characters on REUTERS .
The results for CHAR were the lowest scores in BLEU and RIBES on REUTERS and JENAAD+REUTERS , with the exception of the best 56 .55 BLEU in Characters on REUTERS .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
4:1			2:1			0		1.0
5:1			3:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
18:1			21:1			0		1.0
19:1			18:1			0		1.0
20:1			23:1			0		1.0
21:1			24:1			0		1.0
22:1			25:1			0		1.0
23:1			26:1			0		1.0
24:1			27:1			0		1.0
25:1			28:1			0		1.0
26:1			29:1			0		1.0
27:1			30:1			0		1.0
28:1			31:1			0		1.0
29:1			32:1			0		1.0
30:1			33:1			0		1.0

Alignment 126
We found the results of the supervised morphological analyzers are better in both English-Japanese and Japanese-English experiments .
We found that the results of the supervised morphological analyzers were better in both English-Japanese and Japanese-English experiments .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			2		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0

Alignment 127
And the differences in the word definition of KyTea , MeCab , and JUMAN were not remarkable , especially in English-Japanese translations , although the word definition of KyTea is much shorter than MeCab and JUMAN .
Furthermore , the differences in the word definition of KyTea , MeCab , and JUMAN were not substantial , especially for English-Japanese translations , although the word definition of KyTea is much shorter than for MeCab and JUMAN .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			22:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			3		1.0
18:1			17:1			0		1.0
19:2			18:2			3		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
35:1			33:1			0		1.0
36:1			34:1			0		1.0
37:1			35:1			0		1.0
38:1			36:1			0		1.0

Alignment 128
This result implies that phrase-based SMT can output sufficiently reasonable word / phrase alignments that can treat different word definitions in most cases .
This result implies that phrase-based SMT can output sufficiently reasonable word / phrase alignments that can treat different word definitions , in most cases .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0

Alignment 129
On the other hand , the unsupervised morphological analyzer latticelm and one of our heuristic methods CAT were very much worse than the supervised morphological analyzers .
On the other hand , the unsupervised morphological analyzer latticelm and one of our heuristic methods CAT performed much poorer than the supervised morphological analyzers .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
18:1			19:1			0		1.0
19:2			20:2			3		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0

Alignment 130
The experiments demonstrated an unexpected result for CHAR .
The experiments demonstrated an unexpected result for CHAR .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 131
It was good at English-Japanese but not at Japanese-English translations .
It excelled with English-Japanese translations , but not with Japanese-English translations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
3:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0

Alignment 132
We consider the possible reasons for this result :
We consider the possible reasons for this result in the following list :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
12:1			8:1			0		1.0

Alignment 133
- The Head Finalization of English-Japanese lead better phrase alignments .
- The Head Finalization of English-Japanese lead better phrase alignments .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 134
- Since CHAR treat a character as a word , the best combination of its phrase alignments were the best suited for the SMT decoding .
- Since CHAR treats a character as a word , the best combination of its phrase alignments were the best suited for the SMT decoding .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			1		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 135
On the other hand , we observed the following issues from our error analysis :
On the other hand , we observed the following issues from our error analysis :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 136
- Uncommon named entities were almost wrongly translated .
- Uncommon named entities were almost wrongly translated .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 137
( For example , チェコ Czech was produced instead of チェコスロバキア Czechoslovakia . )
( For example , チェコ Czech was produced instead of チェコスロバキア Czechoslovakia . )
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 138
- Long sentences were translated worse than the other word segmentation outputs .
- Long sentences were not translated as well as other word segmentation outputs .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			6:1			3		1.0
5:1			4:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0

Alignment 139
The reasons of the CHAR results are yet to be analyzed in details .
The reasons for the CHAR results are yet to be analyzed in detail .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:2			1:2			3		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			1		1.0
13:1			13:1			0		1.0

Alignment 140
However , this result indicates that there is a possibility of better word segmentation than popular supervised morphological analyzers and CHAR word segmentation .
However , this result indicates that there is a possibility of better word segmentation than popular supervised morphological analyzers and CHAR word segmentation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 141
We are planning to conduct further investigation in future .
We are planning to conduct further investigations in the future .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			1		1.0
7:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0

Alignment 142
The current evaluation metrics we pursued in this paper were not sufficient to discuss more accurately about the relative advantages and disadvantages of word segmentation , since they did not produce consistent scores as explained below :
The current evaluation metrics that we pursued in this paper were insufficient to discuss the relative advantages and disadvantages of word segmentation in detail , since the scores that were produced were inconsistent , as explained below :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:2			3		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			17:1			0		1.0
15:1			18:1			0		1.0
16:1			19:1			0		1.0
17:1			20:1			0		1.0
18:1			21:1			0		1.0
19:1			22:1			0		1.0
20:1			23:1			0		1.0
21:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
27:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
37:1			36:1			0		1.0

Alignment 143
- There were many contradictory figures among evaluation metrics .
- There were many contradictory figures among evaluation metrics .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 144
There was a case that BLEU was high , while other metrics were low .
There was a case that BLEU was high , while other metrics were low .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 145
Moreover , there is also a case that RIBES and BLEU in Characters were incompatible with each other .
Moreover , there is also a case in which RIBES and BLEU in Characters were incompatible with each other .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0

Alignment 146
For example , on WIKIPEDIA in Table 2 , while CHAR was relatively the highest and greatly better than the supervised morphological analyzers in RIBES , MeCab achieved the best score and notably better than CHAR in BLEU in Characters .
For example , on WIKIPEDIA in Table 2 , while CHAR was the highest , and performed better than the supervised morphological analyzers in RIBES , MeCab achieved the best score and notably better than CHAR in BLEU in Characters .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			25:1			0		1.0
15:1			15:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0

Alignment 147
- If we compare every column in a row , there were tendencies that the best and the worst corpora were the same for every evaluation metrics .
- If we compare every column in a row , there were tendencies that the best and the worst corpora were the same for every evaluation metrics .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0

Alignment 148
In Table 2 , REUTERS was the best and WIKIPEDIA was the worst in terms of BLEU , but also JENAAD+REUTERS was the best and WIKIPEDIA was the worst in terms of RIBES .
In Table 2 , REUTERS was the best and WIKIPEDIA was the worst in terms of BLEU , but also JENAAD+REUTERS was the best and WIKIPEDIA was the worst in terms of RIBES .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0

Alignment 149
- Even when we compare every row in a column , there were no tendencies .
- Even when we compare every row in a column , there were no tendencies .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 150
For instance , in terms of BLEU in Characters , CHAR , JUMAN , and MeCab achieved the best scores in Table 3 .
For instance , in terms of BLEU in Characters , CHAR , JUMAN , and MeCab achieved the best scores in Table 3 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 151
This work focused on how the difference of word segmentation affects SMT outputs , the quality of the unsupervised word segmentation on SMT , and the meta-evaluation of the current evaluation metrics .
This work focused on how the differences in word segmentation affected SMT outputs , the quality of the unsupervised word segmentation on SMT , and the meta-evaluation of the current evaluation metrics .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			28:1			0		1.0
6:1			5:2			3		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			1		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0

Alignment 152
In summary , we found that the representative morphological analyzers were competitive and much better than both unsupervised analyzer and one of our heuristic methods .
In summary , we found that the representative morphological analyzers were competitive and much better than both the unsupervised analyzer and one of our heuristic methods .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0

Alignment 153
After all , a heuristic word segmentation method CHAR achieved relatively good word-based BLEU scores and competitive character-based BLEU results , compared to the supervised analyzers .
Nevertheless , a heuristic word segmentation method CHAR achieved relatively good word-based BLEU scores and competitive character-based BLEU results , compared to the supervised analyzers .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0

Alignment 154
Additionally , as we could not always obtain consistent scores from the current evaluation metrics , they were not sufficient to discuss more accurately about the relative advantages and disadvantages of word segmentation .
Additionally , as we could not always obtain consistent scores from the current evaluation metrics , the data was insufficient for discussing the relative advantages and disadvantages of word segmentation , with accuracy .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			25:1			0		1.0
18:1			16:2			3		1.0
19:2			18:3			3		1.0
21:1			21:1			1		1.0
23:1			26:1			0		1.0
24:1			27:1			0		1.0
25:1			28:1			0		1.0
26:1			29:1			0		1.0
27:1			30:1			0		1.0
28:1			31:1			0		1.0
29:1			32:1			0		1.0
33:1			33:1			0		1.0

Alignment 155
We also suggested it is possible to implement more optimized word segmentation on SMT .
We have also suggested that it is possible to implement more optimized word segmentation on SMT .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			0		1.0
5:1			3:1			0		1.0
6:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0

Alignment 156
On Contribution of Syntactic Dependencies to Word Sense Disambiguation
On Contribution of Syntactic Dependencies to Word Sense Disambiguation
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 157
Traditionally , many researchers have addressed word sense disambiguation ( WSD ) as an independent classification problem for each word .
Traditionally , many researchers have addressed word sense disambiguation ( WSD ) as an independent classification problem for each word .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 158
However , problems with their approaches are the disregard of the interdependencies of word senses , and the limited applicability to those word senses for which training instances are served .
However , the problem with these approaches , is that they disregard the interdependencies of word senses , and that it is limited in its applicability to the word senses for which training instances are served .**[<-This sentence is a bit confusing]
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			7:1			0		1.0
3:1			2:1			1		1.0
4:1			3:1			0		1.0
6:1			5:1			0		1.0
7:1			15:1			0		1.0
8:1			6:1			2		1.0
11:1			8:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
18:1			16:1			0		1.0
19:3			25:1			3		1.0
22:1			18:1			0		1.0
25:1			19:1			0		1.0
26:1			20:1			0		1.0
27:1			17:1			0		1.0
28:1			22:1			0		1.0
29:1			23:1			0		1.0
30:1			24:1			0		1.0
32:1			26:1			0		1.0
33:1			27:1			0		1.0
34:1			28:1			0		1.0
35:1			29:1			0		1.0

Alignment 159
In this paper , we propose a supervised WSD model based on the syntactic dependencies of word senses .
In this paper , we propose a supervised WSD model based on the syntactic dependencies of word senses .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 160
Particularly , we assume that there exist strong dependencies between the sense of a syntactic head and those of its dependents .
In particular , we assume that strong dependencies between the sense of a syntactic head and those of its dependents exist .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			6:1			0		1.0
21:1			21:1			0		1.0

Alignment 161
We describe these dependencies on the tree-structured conditional random fields ( T-CRFs ) , and obtain the most appropriate assignment of senses optimized over the sentence .
We describe these dependencies on the tree-structured conditional random fields ( T-CRFs ) , and obtain the most appropriate assignment of senses optimized over the sentence .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 162
Also , we define these sense dependencies in combination with various coarse-grained sense tag sets , so that our model can even work for words that do not appear in the training data , and these combined features help relieve the data sparseness problem .
Furthermore , we define these sense dependencies in combination with various coarse-grained sense tag sets , so that our model can also work for words that do not appear in the training data ; these combined features help relieve the data sparseness problem .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:2			20:2			3		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
34:1			35:1			0		1.0
35:1			36:1			0		1.0
36:1			37:1			0		1.0
37:1			38:1			0		1.0
38:1			39:1			0		1.0
39:1			40:1			0		1.0
40:1			41:1			0		1.0
41:1			42:1			0		1.0
42:1			43:1			0		1.0
43:1			44:1			0		1.0

Alignment 163
In experiments , we show the appropriateness of considering the sense dependencies , as well as the advantage of the combination of fine- and coarse-grained tag sets .
In experiments , we display the appropriateness of considering the sense dependencies , as well as the advantage of [having ? Using ?] the combination of fine- and coarse-grained tag sets .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			2		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
23:1			19:1			0		1.0
24:1			20:1			0		1.0
25:1			21:1			0		1.0
26:1			22:1			0		1.0
27:1			23:1			0		1.0
28:1			24:1			0		1.0
29:1			25:1			0		1.0
30:1			26:1			0		1.0
31:1			27:1			0		1.0

Alignment 164
The performance of our model is shown to be comparable to those of state-of-the-art WSD systems .
The performance of our model is shown to be comparable to those of state-of-the-art WSD systems .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 165
We also present an in-depth analysis on the effectiveness of the sense dependency features with intuitive examples .
We also present an in-depth analysis of the effectiveness of the sense dependency features by using intuitive examples .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:2			5:2			3		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0

Alignment 166
Word sense disambiguation ( WSD ) is one of the fundamental problems in computational linguistics .
Word sense disambiguation ( WSD ) is one of the most fundamental problems in computational linguistics .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0

Alignment 167
The task of WSD is to resolve the inherent polysemy of words by determining the appropriate sense( s ) for each polysemous word in a given text .
The task of WSD is to resolve the inherent polysemy of words by determining the appropriate sense( s ) for each polysemous word in a given text .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0

Alignment 168
It is considered to be an intermediate , but necessary step toward many NLP applications including machine translation and information extraction , which require the knowledge of word senses to achieve better performance .
It is considered to be an intermediate , but necessary step for many NLP applications , including machine translation and information extraction , which[what does " which " refer to ? Machine translation ? Information extraction , or both ? Clarify] require the knowledge of word senses to perform better .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
26:1			22:1			0		1.0
41:1			23:1			0		1.0
42:1			24:1			0		1.0
43:1			25:1			0		1.0
44:1			26:1			0		1.0
45:1			27:1			0		1.0
46:1			28:1			0		1.0
47:1			29:1			0		1.0
48:1			32:1			1		1.0
49:1			31:1			0		1.0
50:1			33:1			0		1.0

Alignment 169
One major obstacle to large-scale and precise WSD is the data sparseness problem caused by the fine-grainedness of the sense distinction .
One major obstacle for large-scale and precise WSD is solving the data sparseness problem caused by the fine-grained nature of sense distinction .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:2			2:2			3		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
19:1			17:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0

Alignment 170
In order to resolve this problem , several semi-supervised approaches have been explored in recent years .
In recent years in order to resolve this problem , several semi-supervised approaches have been explored .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			14:1			0		1.0
2:1			15:1			0		1.0
3:1			13:1			0		1.0
4:1			1:1			0		1.0
5:1			2:1			0		1.0
6:1			3:1			0		1.0
7:1			4:1			0		1.0
8:1			5:1			0		1.0
9:1			6:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			16:1			0		1.0

Alignment 171
Some researchers have addressed directly the scarcity of the training data , and explored the methods to obtain more tagged instances , by the co-training and self-training .
Some researchers have addressed the scarcity of the training data directly , and have explored the methods to obtain more tagged instances , by co-training and self-training .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			4:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0

Alignment 172
Other researchers have employed useful global information , such as the domain information extracted from unannotated corpora .
Other researchers have employed useful global information , such as the domain information extracted from unannotated corpora .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 173
Although the use of the global information has succeeded in dramatically increase the performance of WSD , there are much room left to examine the effectiveness of local or syntactic information .
Although the use of global information has succeeded in dramatically increasing the performance of WSD , there is much room left to examine the effectiveness of local or syntactic information .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:2			11:2			3		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			2		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0

Alignment 174
One of such information yet to be explored is the interdependencies of word senses .
One such information yet to be explored , is the interdependency of word senses .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			1		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 175
Although the use of local and syntactic information has been common in WSD , traditional approaches to WSD are based on the individual classification framework for each word , in which each word 's sense is treated independently , regardless of any interdependencies nor cooccurrences of word senses .
Although the use of local and syntactic information has been common in WSD , traditional approaches to WSD are based on the individual classification framework for each word ; each word 's sense is treated independently , regardless of any interdependencies or cooccurrences of word senses .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
29:1			31:1			0		1.0
30:1			32:1			0		1.0
31:1			33:1			0		1.0
32:1			34:1			0		1.0
33:1			35:1			0		1.0
34:1			36:1			0		1.0
35:1			37:1			0		1.0
36:1			38:1			0		1.0
37:1			39:1			0		1.0
38:1			40:1			0		1.0
39:1			41:1			0		1.0
40:1			42:1			0		1.0
41:1			43:1			3		1.0
42:1			44:1			0		1.0
43:1			45:1			0		1.0
44:1			46:1			0		1.0
45:1			47:1			0		1.0
46:1			48:1			0		1.0

Alignment 176
As a result , the resulting sense assignment may not semantically consistent over the sentence .
In turn , the resulting sense assignment may not be semantically consistent over the sentence .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 177
To solve this problem is of great interest from both practical and theoretical perspectives .
To solve this problem is of great interest from both a practical and theoretical viewpoint .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
15:1			14:1			0		1.0

Alignment 178
In this thesis , we present a WSD model that naturally handles all content words in a sentence .
In this thesis , we present a WSD model that naturally handles all content words in a sentence .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 179
We focus on the use of the interdependency of word senses , so that we can directly address the issue of semantic ambiguity of a whole sentence arose from the interaction of each word 's sense ambiguity .
We focus on using the interdependency of word senses , so that we can directly address the issue of semantic ambiguity in a whole sentence that arose from the interaction of each word 's sense ambiguity . **[ <- this part is confusing .]
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:2			2:4			3		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0
24:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0
31:1			32:1			0		1.0
32:1			33:1			0		1.0
33:1			34:1			0		1.0
34:1			35:1			0		1.0
35:1			36:1			0		1.0
36:1			37:1			0		1.0

Alignment 180
Specifically , we assume that there exist strong sense dependencies between a syntactic head and its dependents in the dependency tree , rather than between neighboring words in the sentence .
Specifically , we assume that are strong sense dependencies between a syntactic head , and its dependents in the dependency tree , rather than between neighboring words of a sentence .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			6:1			2		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			21:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:2			26:2			3		1.0
28:2			28:2			3		1.0
30:1			30:1			0		1.0

Alignment 181
We confirm the appropriateness of this assumption by showing the superiority of the tree-structured models over the linear-chain models .
We confirm the validity of this assumption , by showing the superiority of the tree-structured models over the linear-chain models .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0

Alignment 182
Furthermore , we combine these sense dependency features with various coarse-grained sense tag sets .
Furthermore , we combine these sense dependency features with various coarse-grained sense tag sets .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 183
This is to relieve the data sparseness problem caused by the explosion of the number of features , which is roughly squared by the combination of two word senses .
This is to relieve the data sparseness problem caused by the explosion in the number of features , which is roughly squared by the combination of two word senses .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:2			11:2			3		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0

Alignment 184
The combined features also enable our model to work even for those words that do not appear in the training data , which the traditional individual classifiers cannot handle .
The combined features also enable our model to work , even for words that do not appear in the training data , which traditional individual classifiers cannot handle .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0

Alignment 185
As a machine learning method , we adopt the tree-structured conditional random fields ( T-CRFs ) .
As a machine learning method , we adopt the tree-structured conditional random fields ( T-CRFs ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 186
We solve WSD as a labeling problem to a sentence described as a dependency tree , where the vertices correspond to words and the edges correspond to the sense dependencies .
We solve WSD as a labeling problem to a sentence described as a dependency tree , where the vertices correspond to the words , and the edges correspond to the sense dependencies .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			27:1			0		1.0
22:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0

Alignment 187
In this model , the intensities of the sense dependencies are described as the weights of edge features .
In this model , the intensities of the sense dependencies are described as the weights of edge features .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 188
T-CRFs also enable us to incorporate various sense tag sets all together in a simple framework .
T-CRFs also enable us to incorporate various sense tag sets all together into a simple framework .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 189
In our experiments , three interesting results are found : the interdependency of word senses contribute to the improvement of WSD models , the combined features with coarse-grained sense tags work effectively , and the tree-structured model outperforms the linear-chain model .
In our experiments , three interesting results are found : the interdependency of word senses contribute to the improvement of WSD models , the combined features with coarse-grained sense tags work effectively , and the tree-structured model outperforms the linear-chain model .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0

Alignment 190
These results are confirmed on three data sets ( the SemCor corpus and the Senseval-2 and -3 English all-words task test sets ) and on two sense inventories ( WordNet synsets and supersenses ) .
These results are confirmed on three data sets ( the SemCor corpus and the Senseval-2 and -3 English all-words task test sets ) , and on two sense inventories ( WordNet synsets and supersenses ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0

Alignment 191
Our final model is shown to perform comparably with state-of-the-art WSD systems .
Our final model is shown to perform comparably to state-of-the-art WSD systems .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 192
The rest of the paper is organized as follows : In Section 2 , we describe background topics related to WSD .
The rest of the paper is organized as follows : In Section 2 , we describe background topics related to WSD .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 193
In Section 3 , we describe current problems of WSD , and related works .
In Section 3 , we describe current problems of WSD , and related works .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 194
In Section 4 , we describe our model with intuitive examples , and the machine learning method we use .
In Section 4 , we describe our model with intuitive examples , and we describe the machine learning method that we use .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			0		1.0

Alignment 195
In Section 5 , 6 , and 7 , we present our experimental setup and results , and an in-depth analysis on the contribution of the sense dependency features .
In Section 5 , 6 , and 7 , we present our experimental setup , the results , and an in-depth analysis on the contribution of the sense dependency features .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			16:1			0		1.0
15:1			25:1			0		1.0
16:1			15:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0

Alignment 196
Finally , in Section 8 , we present concluding remarks .
Finally , in Section 8 , we present our concluding remarks .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0

Alignment 197
The WordNet is a broad-coverage machine-readable dictionary ( MRD ) for English , which contains about 150 ,000 words .
The WordNet is a broad-coverage machine-readable dictionary ( MRD ) for English , containing about 150 ,000 words .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:2			3		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0

Alignment 198
It also serves as an ontology , in which various kinds of meta data , relations among words and senses , and well-organized hierarchical classification of word senses are defined .
WordNet also serves as an ontology of various kinds of meta data , relations among words and senses , and a well-organized hierarchical classification of word senses that are defined .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			25:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0

Alignment 199
In this paper , we always refer to the WordNet version 2 .0 unless otherwise noted .
In this paper , we always refer to the WordNet version 2 .0 unless otherwise noted .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 200
The statistical information of the WordNet 2 .0 is shown in Table 1 and 2 .
The statistical information of the WordNet 2 .0 is shown in Table 1 and 2 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 201
In the WordNet , nouns and verbs are organized in hierarchical structures with IS-A ( hypernym-hyponym ) relationships among words , as shown in Figure 1 .
As shown in Figure 1 , in WordNet , nouns and verbs are organized into hierarchical structures with IS-A ( hypernym-hyponym ) relationships among words , .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			22:1			0		1.0
2:1			23:1			0		1.0
3:1			24:1			0		1.0
4:1			25:1			0		1.0
6:1			9:1			0		1.0
7:1			2:1			0		1.0
8:1			3:1			0		1.0
9:1			4:1			0		1.0
10:1			5:1			0		1.0
11:1			6:1			0		1.0
12:1			7:1			0		1.0
13:1			8:1			0		1.0
15:1			10:1			0		1.0
16:1			11:1			0		1.0
17:1			12:1			0		1.0
18:1			13:1			0		1.0
19:1			14:1			0		1.0
20:1			15:1			0		1.0
21:1			16:1			0		1.0
22:1			17:1			0		1.0
23:1			18:1			0		1.0
24:1			19:1			0		1.0
25:1			20:1			0		1.0
26:1			26:1			0		1.0

Alignment 202
Nouns have a far deeper structure than verbs , while that of verbs is transversely developed .
Nouns have a far deeper structure than verbs do , while that the structure of verbs is transversely developed .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0

Alignment 203
All nouns and verbs except some top-level concepts are classified into primitive groups called supersenses , which we describe later .
All nouns and verbs , with the exception of some top-level concepts , are classified into primitive groups called supersenses , which we will describe later .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:4			4:1			3		1.0
9:1			5:1			0		1.0
10:1			6:1			0		1.0
11:1			7:1			0		1.0
13:1			8:1			0		1.0
14:1			9:1			0		1.0
15:1			10:1			0		1.0
16:1			11:1			0		1.0
17:1			12:1			0		1.0
18:1			13:1			0		1.0
19:1			14:1			0		1.0
20:1			15:1			0		1.0
21:1			16:1			0		1.0
22:1			17:1			0		1.0
24:1			18:1			0		1.0
25:1			19:1			0		1.0
26:1			20:1			0		1.0

Alignment 204
Figure 1 shows the WordNet hierarchical structure for the first sense ( financial bank ) of a noun bank , where each line shows a synset with the list of words headed by its supersense label , and an arrow denotes that two synsets are in an IS-A relation .
Figure 1 shows the WordNet hierarchical structure for the first sense ( financial bank ) of a noun bank , where each line indicates a synset with the list of words headed by its supersense label ; an arrow denotes that the two synsets are in an IS-A relation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			2		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
37:1			38:1			0		1.0
38:1			39:1			0		1.0
39:1			40:1			0		1.0
40:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0
49:1			49:1			0		1.0

Alignment 205
The synset {group#1 , grouping#1} is a broad semantic category that governs the supersense noun group .
The synset {group#1 , grouping#1} is a broad semantic category that governs the supersense group noun .group .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			15:1			0		1.0
15:1			14:1			0		1.0
17:1			16:1			0		1.0

Alignment 206
The lower synsets {social group#1} , {organization#1 , organisation#3} , and {institution#1 , establishment#2} are the more specific synsets , which in this paper we call the first , second , and third general synsets .
The lower synsets {social group#1} , {organization#1 , organisation#3} , and {institution#1 , establishment#2} are the more specific synsets , which in this paper we call the first , second , and third general synsets .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0

Alignment 207
Note that since the organizations of adjectives and adverbs are far different from those of nouns and verbs , we use this hierarchical information for only nouns and verbs .
Note that since the organizations of adjectives and adverbs are very different from those of nouns and verbs , we use this hierarchical information for only nouns and verbs .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:2			10:2			3		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0

Alignment 208
A supersense is a coarse-grained semantic category , with which each noun or verb synset in WordNet is associated .
A supersense is a coarse-grained semantic category , with which each noun or verb synset in WordNet is associated .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 209
Noun and verb synsets are associated with 26 and 15 categories , respectively .
Noun and verb synsets are associated with 26 and 15 categories , respectively .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 210
The coarse-grained sets of sense labels are easily recognizable , and enable us to build a high-performance and robust tagger with small training data .
The coarse-grained sets of sense labels are easily recognizable , and enable us to build a high-performance and robust tagger with small training data .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 211
Hence , we can expect them to act as a good smoothing feature for WSD , which would make up for the sparseness of features associated with finer-grained senses .
Hence , we can expect them to act as a good smoothing feature for WSD , which would make up for the problem of the sparseness of features , commonly associated with finer-grained senses .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
25:1			22:1			0		1.0
26:1			23:1			0		1.0
27:1			24:1			0		1.0
30:1			25:1			0		1.0
31:1			26:1			0		1.0
32:1			27:1			0		1.0
33:1			28:1			0		1.0
34:1			29:1			0		1.0

Alignment 212
The effectiveness of using supersenses for WSD has recently been shown by several researchers ( e.g. , , and ) .
The effectiveness of using supersenses for WSD has recently been shown by several researchers ( e.g. , , and ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 213
The lists of supersenses are shown below .
The lists of supersenses are shown below .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 214
- Noun supersense : act , animal , artifact , attribute , body , cognition , communication , event , feeling , food , group , location , motive , object , quantity , phenomenon , plant , possession , process , person , relation , shape , state , substance , time , Tops
- Noun supersense : act , animal , artifact , attribute , body , cognition , communication , event , feeling , food , group , location , motive , object , quantity , phenomenon , plant , possession , process , person , relation , shape , state , substance , time , Tops
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0
49:1			49:1			0		1.0
50:1			50:1			0		1.0
51:1			51:1			0		1.0
52:1			52:1			0		1.0
53:1			53:1			0		1.0
54:1			54:1			0		1.0

Alignment 215
- Verb supersense : body , change , cognition , communication , competition , consumption , contact , creation , emotion , perception , possession , social , stative , weather
- Verb supersense : body , change , cognition , communication , competition , consumption , contact , creation , emotion , perception , possession , social , stative , weather
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0

Alignment 216
Since the data sparsity has been a significant problem in WSD , the sense frequency information is necessary to achieve good performance .
Since data sparsity has been a significant issue in WSD , the sense frequency information is necessary in achieving a good performance .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			3		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:2			18:2			3		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 217
In this section , we introduce two kinds of the sense frequency information .
In this section , we introduce two kinds of sense frequency information .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0

Alignment 218
A sense ranking is the ranking of a sense of a word in the WordNet .
A sense ranking is the ranking of a sense of a word in the WordNet .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 219
Since senses of a word are ordered according to frequency , the sense ranking acts as a useful feature offering a preference for frequent senses .
Since senses of a word are ordered according to frequency , the sense ranking acts as a useful feature that offers a preference for frequent senses .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
20:1			19:1			1		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0

Alignment 220
It is also important as a back-off feature , which enables our model to output the first ( most frequent ) sense when no other features are active for that word .
It is also important as a back-off feature , which enables our model to output the first ( most frequent ) sense when no other features are active for that word .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0

Alignment 221
The first sense classifier is known as a strong baseline in WSD , which can be even considered to be a good alternative to WSD .
The first sense classifier is known as a strong baseline in WSD , which can even be considered as a good alternative to WSD .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			16:1			0		1.0
16:1			15:1			0		1.0
17:2			17:3			3		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0

Alignment 222
In our experiment , our first sense classifier achieved the accuracies 65 .3% for the Senseval-2 English all-words task data , and 63 .4% for the Senseval-3 English all-words task data .
In our experiment , our first sense classifier achieved the accuracies 65 .3% for the Senseval-2 English all-words task data , and 63 .4% for the Senseval-3 English all-words task data .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0

Alignment 223
Since the sense ranking in the WordNet is based on the word frequency in the SemCor , this baseline performs far better on the SemCor : 75 .9% for the brown1 section and 74 .3% for the brown2 section .
Since the sense ranking in the WordNet is based on the word frequency in the SemCor , this baseline performs far better on the SemCor : 75 .9% for the brown1 section and 74 .3% for the brown2 section .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0

Alignment 224
Alternatively , we can consider incorporating the first sense of each word as a feature .
Alternatively , we can consider incorporating the first sense of each word as a feature .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 225
Instead of uniformly predicting the distribution of sense frequencies according to their sense ranking , it can capture the conditional probability of each sense over the first sense .
Instead of uniformly predicting the distribution of sense frequencies according to their sense ranking , it can capture the conditional probability of each sense over the first sense .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 226
It is considered to be a good feature that reflects the sense frequency information when sufficient training data is available for every sense .
When sufficient training data is available for every sense this method is considered to be a good feature that reflects the sense frequency information .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			15:1			0		1.0
2:1			16:1			0		1.0
3:1			17:1			0		1.0
4:1			18:1			0		1.0
5:1			19:1			0		1.0
6:1			20:1			0		1.0
7:1			21:1			0		1.0
8:1			22:1			0		1.0
11:1			1:1			0		1.0
12:1			2:1			0		1.0
13:1			3:1			0		1.0
14:1			4:1			0		1.0
15:1			5:1			0		1.0
16:1			6:1			0		1.0
17:1			7:1			0		1.0
18:1			8:1			0		1.0
19:1			9:1			0		1.0
20:1			10:1			0		1.0
21:1			11:1			0		1.0
22:1			12:1			0		1.0
23:1			13:1			0		1.0
24:1			23:1			0		1.0

Alignment 227
For this reason , we use this first sense feature instead of the ranking feature , for the supersense-based evaluation .
For such a reason , we use this first sense feature instead of the ranking feature , for the supersense-based evaluation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0

Alignment 228
For the unsupervised WSD , the use of sense dependencies has been a common method .
For the unsupervised WSD , the use of sense dependencies has been a common method .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 229
introduces an unsupervised graph-based algorithm , and showed a significant superiority of the sequence labeling model over the individual label assignment .
introduces an unsupervised graph-based algorithm , and shows a significant improvement over the sequence labeling model over the individual label assignment .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			1		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 230
built a model based on various word semantic similarity measures and graph centrality algorithms , which also used the graph structure incorporating the word-sense dependencies .
built a model based on various word semantic similarity measures , and graph centrality algorithms , which also used the graph structure that incorporates the word-sense dependencies .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:2			21:1			3		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0

Alignment 231
Thus , the effectiveness of sense dependencies for the unsupervised WSD has been shown by several researches .
Thus , the effectiveness of sense dependencies for unsupervised WSD has been shown by several researches .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0

Alignment 232
On the other hand , the traditional approach to the supervised WSD is to solve an independent classification problem for each word .
On the contrary , the traditional approach to supervised WSD is to solve an independent classification problem for each word .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:2			3		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0

Alignment 233
This approach has been developed along with the researches based on the lexical sample task in the Sensevals .
This approach has been developed along with research based on the lexical sample task in the Sensevals .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			8:1			1		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0

Alignment 234
However , as we described in Section 1 , this approach cannot deal with the interdependencies among word senses , and may output a semantically inconsistent assignment of senses .
However , as described in Section 1 , this approach cannot handle the interdependencies among word senses , and may output a semantically inconsistent assignment of senses .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:2			3		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0
24:1			26:1			0		1.0
25:1			27:1			0		1.0
26:1			28:1			0		1.0
27:1			29:1			0		1.0

Alignment 235
Recently , with the growing interest on the all-words task , a few supervised WSD systems have incorporated the sense dependencies .
Recently , with the growing interest in the all-words task , a few supervised WSD systems have incorporated the sense dependencies .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 236
SenseLearner and SuperSenseLearner incorporate sequencial sense dependencies into the supervised WSD frameworks .
SenseLearner and SuperSenseLearner incorporate sequential sense dependencies into the supervised WSD frameworks .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 237
They no longer treat each word sense individually , assuming the sense dependencies between adjacent words .
They no longer treat each word sense individually , assuming the sense dependencies between adjacent words .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 238
also took a sequencial tagging approach for the disambiguation of WordNet supersenses .
also took a sequential tagging approach for the disambiguation of WordNet supersenses . [<-This sentence is a bit confusing]
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 239
However , the dependencies they considered are rather simple ones between the adjacent words , and between either WordNet synsets or supersenses .
The dependencies that they considered , however , are rather simple ones between the adjacent words , and between either WordNet synsets or supersenses .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			1:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0

Alignment 240
Note additionally that they do not mention how and how much they contribute to the improvement of supervised WSD .
Note additionally , that they do not mention the means or the quality of contribution in improving supervised WSD .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:2			7:1			3		1.0
11:1			14:1			0		1.0
13:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 241
One interesting model related is the exponential family model proposed by , which captures the occurrences and co-occurrences of words and senses in a joint probability distribution .
The exponential family model proposed by , captures the occurrences and co-occurrences of words and senses in a joint probability distribution .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			6:1			0		1.0
2:1			7:1			0		1.0
3:1			8:1			0		1.0
4:1			9:1			0		1.0
5:1			10:1			0		1.0
6:1			11:1			0		1.0
7:1			13:1			0		1.0
8:1			14:1			0		1.0
9:1			15:1			0		1.0
10:1			16:1			0		1.0
11:1			17:1			0		1.0
12:1			18:1			0		1.0
13:1			19:1			0		1.0
14:1			20:1			0		1.0
15:1			21:1			0		1.0
16:1			22:1			0		1.0
17:1			23:1			0		1.0
18:1			24:1			0		1.0
19:1			25:1			0		1.0
20:1			26:1			0		1.0
21:1			27:1			0		1.0

Alignment 242
Although they focused on the use of the co-occurrences of word senses rather than the dependencies , they clarified the contribution of sense co-occurrences to the supervised WSD .
Although they focused on the use of the co-occurrences of word senses rather than that of dependencies , they clarified the contribution of sense co-occurrences to the supervised WSD .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
15:1			21:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0

Alignment 243
In this context , it is of an interest if the sense dependencies on a syntactic structure , rather than on a linear chain , works effectively or not .
In this context , it is of interest to note whether the sense dependencies on a syntactic structure , rather than on a linear chain , works effectively or not .**[why ?]
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			8:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0

Alignment 244
To the extent of our knowledge , there exists no model that considers the interdependencies of word senses on a syntactic tree .
To the extent of our knowledge , there exists no model that considers the interdependencies of word senses on a syntactic tree .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 245
Also , despite the approaches described above , the contribution of sense dependencies for the supervised WSD has not explicitly examined thus far .
Furthermore , despite the approaches described above , the contribution of sense dependencies for the supervised WSD has not been explicitly examined thus far .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0

Alignment 246
These questions are clarified by our research .
These questions are clarified by our research .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 247
In Section 1 , we presented one of the most significant problems in WSD - the data sparsity .
In Section 1 , we presented one of the most significant issues in WSD - the data sparsity problem .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			3		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
19:1			18:1			0		1.0

Alignment 248
This problem may even be magnified when we consider the interdependencies of word senses , since the number of features is roughly squared by the combination of two word senses .
This problem may even be magnified , when taking into consideration the interdependencies of word senses , since the number of features is roughly squared by the combination of two word senses .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			14:1			0		1.0
7:1			6:1			0		1.0
10:1			8:1			3		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0

Alignment 249
In order to relieve this problem , we use the hierarchical information in the WordNet , including the superordinate words and supersenses , which we describe in Section 2 .1 and 2 .2 .
In order to relieve this problem , we use the hierarchical information in the WordNet , including the superordinate words and supersenses , as described in Section 2 .1 and 2 .2 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
24:1			25:1			1		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0
31:1			32:1			0		1.0
32:1			33:1			0		1.0

Alignment 250
The use of the hierarchical information has been motivated by several researches .
The use of hierarchical information has been motivated by several different researches .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 251
For example , a WSD system by , which was ranked second in the Senseval-3 , consists of two models : the first model applied to words seen in the training data , and the second model that performs a generalized disambiguation process for words unseen in the data by using the hierarchical information in the WordNet .
For example , a WSD system by , ranked second in the Senseval-3 , consists of two models : the first model applied to words seen in the training data , and the second model performs a generalized disambiguation process for words unseen in the data , by using the hierarchical information in the WordNet .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0
24:1			26:1			0		1.0
25:1			27:1			0		1.0
26:1			28:1			0		1.0
27:1			29:1			0		1.0
28:1			30:1			0		1.0
29:1			31:1			0		1.0
30:1			32:1			0		1.0
31:1			33:1			0		1.0
32:1			34:1			0		1.0
33:1			35:1			0		1.0
34:1			36:1			0		1.0
35:1			38:1			0		1.0
36:1			39:1			0		1.0
37:1			40:1			0		1.0
38:1			41:1			0		1.0
39:1			42:1			0		1.0
40:1			43:1			0		1.0
41:1			44:1			0		1.0
42:1			45:1			0		1.0
43:1			46:1			0		1.0
44:1			47:1			0		1.0
45:1			48:1			0		1.0
47:1			49:1			0		1.0
48:1			50:1			0		1.0
49:1			51:1			0		1.0
50:1			52:1			0		1.0
51:1			53:1			0		1.0
52:1			54:1			0		1.0
53:1			55:1			0		1.0
54:1			56:1			0		1.0
55:1			57:1			0		1.0

Alignment 252
The fine granularity of the WordNet synsets is not just a major obstacle to high-performance WSD , but is sometimes too fine-grained even for a human to disambiguate .
The fine granularity of the WordNet synsets is not just a major obstacle in achieving a high-performance WSD , but is sometimes too fine-grained even for a human to disambiguate .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0

Alignment 253
This is reflected in the low inter-annotator agreement of sense tagging ( typically around 70% ) , which implies that WSD models are unlikely to perform better than this accuracy .
This is reflected in the low inter-annotator agreement of sense tagging ( typically around 70% ) , which implies that WSD models would be unlikely to perform better than the accuracy achieved .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:2			22:1			3		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
30:1			29:1			0		1.0
32:1			30:1			0		1.0

Alignment 254
Also , this fine-grainedness is reported to be not appropriate for many NLP applications .
Also , this fine-grained nature is reported to be inappropriate for many NLP applications .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:2			3		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 255
For example , reported that coarse-grained sense distinctions are sufficient for several NLP applications .
For example , reported that coarse-grained sense distinctions are sufficient for several NLP applications .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 256
Especially , the use of the supersenses has recently been investigated by , and receiving much attention in the WSD field .
In particular , the use of the supersenses has recently been investigated by , and has received much attention in the WSD field .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			2		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0

Alignment 257
In this case , the inter-annotator agreements are turned out to reach around 90% .
In this case , the inter-annotator agreements have reached nearly90% .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			8:3			3		1.0
8:1			11:1			1		1.0
10:1			14:1			0		1.0

Alignment 258
For this reason , we use as our sense inventory the WordNet supersenses as well as the synsets .
For this reason , we use the WordNet supersenses , as well as the synsets as our sense inventory .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			10:1			0		1.0
7:1			11:1			0		1.0
8:1			12:1			0		1.0
10:1			13:1			0		1.0
11:1			14:1			0		1.0
12:1			15:1			0		1.0
13:1			16:1			0		1.0
14:1			17:1			0		1.0
15:1			6:1			0		1.0
16:1			7:1			0		1.0
17:1			8:1			0		1.0
18:1			9:1			0		1.0
19:1			18:1			0		1.0

Alignment 259
In Section 3 , we described two problems in the WSD field .
In Section 3 , we described two problems in the WSD field .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 260
One is the independent classification of each word 's sense regardless of the sense dependencies among words .
One problem is the independent classification of each word 's sense , regardless of the sense dependencies among words .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0

Alignment 261
The other is the scarcity of the training data arose from the fine granularity of the sense distinction .
The other problem is the scarcity of the training data that arose from the fine granularity of the sense distinction .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0

Alignment 262
We address these problems by the combination of two methods .
We address these problems by combining two methods .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:3			3		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0

Alignment 263
The first is the use of the syntactic dependencies of word senses on a dependency tree .
The first [method ?] is the use of the syntactic dependencies of word senses on a dependency tree .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
4:1			2:1			0		1.0
5:1			3:1			0		1.0
6:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0

Alignment 264
Particularly , we assume that there exist strong dependencies of word senses between a head and its dependents in the dependency tree , rather than between neighboring words in the sentence .
In particular , we assume that there are strong dependencies of word senses between a head and its dependents in the dependency tree , rather than between neighboring words in the sentence .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			2		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0

Alignment 265
Even though some models so far have considered the dependencies between adjacent words , no one has focused on the syntactic dependencies of word senses .
Even though some models so far have considered the dependencies between adjacent words , no one has focused on the syntactic dependencies of word senses .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 266
Thus , to the extent of our knowledge , our model is the first WSD model that incorporates the sense dependencies based on a syntactic tree .
Thus , to the extent of our knowledge , our model is the first WSD model that incorporates the sense dependencies based on a syntactic tree .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 267
The second is the combination of various coarse-grained sense tag sets with the WordNet synsets .
The second [method ?] combines various coarse-grained sense tag sets with the WordNet synsets .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0

Alignment 268
This enables our model to work for unseen words in the training data , and is expected to relieve the data sparseness problem .
This enables our model to work for unseen words in the training data , and is expected to relieve the data sparseness problem .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 269
In our experiment , these tag sets are used in two ways .
In our experiment , these tag sets are used in two ways .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 270
One way is to use them directly as the sense inventory instead of a finer sense inventory .
One way directly uses them as the sense inventory , instead of as a finer sense inventory .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			6:1			0		1.0
3:1			4:1			1		1.0
4:1			5:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 271
In our supersense-based model , we use the supersenses as the sense inventory , and each word sense is disambiguated at the granularity level of this tag set .
In our supersense-based model , we use the supersenses as the sense inventory , and each word sense is disambiguated at the granularity level of this tag set .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 272
This method serves us much more training instances for each coarser sense , while we can no longer distinguish finer senses .
This method serves us many more training instances for each coarser sense , while we can no longer distinguish finer senses .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 273
The other is to use them in combination with finer sense tag sets .
The other way uses them**[<-define " them " ] in combination with finer sense tag sets .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
6:1			5:1			0		1.0
9:1			6:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0

Alignment 274
In our synset-based model , three coarse-grained label sets are incorporated in combination with the fine-grained WordNet synsets .
In our synset-based model , three coarse-grained label sets are incorporated in combination with the fine-grained WordNet synsets .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 275
Although the sense disambiguation is still based on the finer senses , the coarser sense tags will help the discrimination of the finer senses , serving generalized information for each fine-grained sense .
Although sense disambiguation is still based on the finer senses , the coarser sense tags will help the discrimination of the finer senses , thereby serving generalized information for each fine-grained sense .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0

Alignment 276
This approach has been taken in several hierarchical WSD methods , but never combined with the sense dependencies as we use .
This approach has been taken in several hierarchical WSD methods , but has never been combined with the sense dependencies in a way that have used them .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
13:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
24:2			20:1			3		1.0
27:1			21:1			0		1.0

Alignment 277
The process of WSD is summarized as below .
The process of WSD is summarized below .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0

Alignment 278
At the beginning , we parse target sentences with a dependency parser , and compact the outputted trees in order to capture informative dependencies among words , as described in Section 4 .3 .
At the beginning , we parse target sentences with a dependency parser , and compact the outputted trees in order to capture informative dependencies among words , as described in Section 4 .3 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0

Alignment 279
Then , the WSD task is regarded as a labeling task on the tree structures .
Then , the WSD task is regarded as a labeling task on the tree structures .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 280
By using T-CRFs , we can model this as the maximization of the probability of word sense trees , given scores for vertices and edges .
By using T-CRFs , we can model this as the maximization of the probability of word sense trees , given the scores for vertices and edges .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0

Alignment 281
In the training phase , all vertex features and edge features are extracted using the gold-standard senses , and the weight vectors for them are optimized over the training data .
In the training phase , all vertex features and edge features are extracted using the gold-standard senses , and the weight vectors are optimized over the training data .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0
24:1			26:1			0		1.0
25:1			27:1			0		1.0
26:1			28:1			0		1.0
27:1			29:1			0		1.0
28:1			30:1			0		1.0

Alignment 282
Finally , in the testing phase , all possible combinations of senses are evaluated for each sentence , and the most probable sense assignment is selected by evaluating the equation 3 .
Finally , in the testing phase , all possible combinations of senses are evaluated for each sentence , and the most probable sense assignment is selected by evaluating the equation 3 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0

Alignment 283
Conditional Random Fields ( CRFs ) are graph-based probabilistic discriminative models proposed by .
Conditional Random Fields ( CRFs ) are graph-based probabilistic discriminative models proposed by .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 284
CRFs are the state-of-the-art methods for sequence labeling problems in many NLP tasks .
CRFs are state-of-the-art methods for sequence labeling problems in many NLP tasks .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0

Alignment 285
CRFs construct a conditional model / MATH from a set of paired observations and label sequences .
CRFs construct a conditional model / MATH from a set of paired observations and label sequences .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 286
The conditional probability of a label sequence / MATH conditioned on a data sequence / MATH is given by / MATH , where / MATH and / MATH are the feature vectors for an edge and a vertex , / MATH and / MATH are the weight vectors for them , / MATH and / MATH are the set of components of / MATH associated with an edge / MATH and a vertex / MATH , and / MATH is the partition function which constrains the sum of all the probabilities to be 1 .
The conditional probability of a label sequence / MATH conditioned on a data sequence / MATH is given by / MATH , where / MATH and / MATH are the feature vectors for an edge and a vertex , / MATH and / MATH are the weight vectors , / MATH and / MATH are the set of components of / MATH associated with an edge / MATH and a vertex / MATH , and / MATH is the partition function that constrains the sum of all the probabilities to be 1 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			50:1			0		1.0
49:1			51:1			0		1.0
50:1			52:1			0		1.0
51:1			53:1			0		1.0
52:1			54:1			0		1.0
53:1			55:1			0		1.0
54:1			56:1			0		1.0
55:1			57:1			0		1.0
56:1			58:1			0		1.0
57:1			59:1			0		1.0
58:1			60:1			0		1.0
59:1			61:1			0		1.0
60:1			62:1			0		1.0
61:1			63:1			0		1.0
62:1			64:1			0		1.0
63:1			65:1			0		1.0
64:1			66:1			0		1.0
65:1			67:1			0		1.0
66:1			68:1			0		1.0
67:1			69:1			0		1.0
68:1			70:1			0		1.0
69:1			71:1			0		1.0
70:1			72:1			0		1.0
71:1			73:1			0		1.0
72:1			74:1			0		1.0
73:1			75:1			0		1.0
74:1			76:1			0		1.0
75:1			77:1			0		1.0
76:1			78:1			0		1.0
77:1			79:1			0		1.0
78:1			80:1			0		1.0
79:1			81:1			0		1.0
80:2			82:2			3		1.0
82:1			84:1			0		1.0
83:1			85:1			0		1.0
84:1			86:1			0		1.0
85:1			87:1			0		1.0
86:1			88:1			0		1.0
87:1			89:1			0		1.0
88:1			90:1			0		1.0
89:1			91:1			0		1.0
90:1			92:1			0		1.0
91:1			93:1			0		1.0
92:1			94:1			0		1.0

Alignment 287
Tree-structured CRFs ( T-CRFs ) are different from widely used linear-chain CRFs in that the random variables are organized in a tree structure ( acyclic graph ) .
Tree-structured CRFs ( T-CRFs ) are different from widely used linear-chain CRFs , in that the random variables are organized in a tree structure ( acyclic graph ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0

Alignment 288
Hence , we can consider them appropriate for modeling the syntactic dependencies of word senses , which cannot be represented by linear structures .
Hence , we can consider them relevant in modeling the syntactic dependencies of word senses , which cannot be represented by linear structures .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			3		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 289
In this model , the optimal label assignment / MATH for an observation sequence / MATH is then calculated by / MATH , where / MATH denotes a vertex corresponding to a word while / MATH denotes the vertex corresponding to its parent in the dependency tree .
In this model , the optimal label assignment / MATH for an observation sequence / MATH is then calculated by / MATH , where / MATH denotes a vertex corresponding to a word , while / MATH denotes the vertex corresponding to its parent in the dependency tree .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
37:1			36:1			0		1.0
38:1			37:1			0		1.0
39:1			38:1			0		1.0
40:1			39:1			0		1.0
41:1			40:1			0		1.0
42:1			41:1			0		1.0
43:1			42:1			0		1.0
44:1			43:1			0		1.0
45:1			44:1			0		1.0
46:1			45:1			0		1.0
47:1			46:1			0		1.0
48:1			47:1			0		1.0

Alignment 290
If we interpret / MATH as the vertex associated with the preceding word in a sentence , it reduces to a linear-chain CRF .
If we interpret / MATH as the vertex associated with the preceding word in a sentence , it delineates into a linear-chain CRF .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 291
Although T-CRFs are relatively new models , they have already been applied to several NLP tasks , such as semantic role labeling and semantic annotation , proving to be useful in modeling the semantic structure of a text .
Although T-CRFs are relatively new models , they have already been applied to several NLP tasks , such as semantic role labeling and semantic annotation , proving to be useful in modeling the semantic structure of a text .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0

Alignment 292
Our model is the first application of T-CRFs to WSD .
Our model is the first application of T-CRFs to WSD .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 293
In this section , we introduce a method to build graph structures on which CRFs are constructed .
In this section , we introduce the method of building graph structures on which CRFs are constructed .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:2			6:2			3		1.0
8:2			8:2			3		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 294
First , we describe how to construct a tree used in the tree-structured model .
First , we describe how to construct a tree used in the tree-structured model .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 295
Let us consider the synset-level disambiguation of the following sentence .
Let us consider the synset-level disambiguation of the following sentence .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 296
( i ) - The man destroys confidence in banks .
( i ) - The man destroys confidence in banks .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 297
At the beginning , we parse this sentence with the Sagae and Tsujii 's dependency parser , which outputs parsed trees in the CoNLL-X dependency format .
In the beginning , we parse this sentence with Sagae and Tsujii 's dependency parser , which outputs parsed trees in the CoNLL-X dependency format .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0

Alignment 298
The left-hand side of Figure 2 shows the parsed tree for Sentence ( i ) , where each child-parent edge denotes a directed dependency of words , and the labels on the edges denote the dependency types .
The left-hand side of Figure 2 shows the parsed tree for Sentence ( i ) , where each child-parent edge denotes a directed dependency of words , and the labels on the edges denote the dependency types .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0

Alignment 299
This dependency tree describes dependencies among all words in a sentence , including content words and function words .
This dependency tree describes dependencies among all words in a sentence , including content words and function words .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 300
However , some of these dependencies are not informative for our WSD task , because our task does not focus on the disambiguation function words .
However , some of these dependencies are not informative for our WSD task , because our task does not focus on the disambiguation function words .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 301
For example , on the right-hand side of Figure 2 , the dependencies among confidence-in-bank are splitted into the two dependencies confidence-in and in-bank ; Hence our model cannot capture the direct dependency between confidence and bank .
For example , on the right-hand side of Figure 2 , the dependencies among confidence-in-bank are split into the two dependencies confidence-in and in-bank ; hence our model cannot capture the direct dependency between confidence and bank .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			1		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0

Alignment 302
One way to resolve this problem is to use higher-order ( semi-Markov ) dependencies , but this may drastically increase the computational cost .
One way to resolve this problem is to use higher-order ( semi-Markov ) dependencies , but this may drastically increase the computational cost .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 303
For this reason , for the synset-based model , we convert the outputted dependency tree into a tree of content words , as exemplified on the right-hand side of Figure 2 .
Thus , for the synset-based model , we convert the outputted dependency tree into a tree of content words , as exemplified on the right-hand side of Figure 2 .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			3:1			0		1.0
2:1			4:1			0		1.0
3:1			5:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0
24:1			26:1			0		1.0
25:1			27:1			0		1.0
26:1			28:1			0		1.0
27:1			29:1			0		1.0
28:1			30:1			0		1.0
29:1			31:1			0		1.0

Alignment 304
In this process , the function words are removed from the tree , and their parent and child vertices are directly connected with the dependency labels of the uppermost edge in the original tree .
In this process , the function words are removed from the tree , and their parent and child vertices are directly connected with the dependency labels of the uppermost edge in the original tree .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0

Alignment 305
Then , on the right-hand side of Figure 2 , we can see that the dependency between confidence and bank is now described as a direct edge .
Then , on the right-hand side of Figure 2 , the dependency between confidence and bank is now described as a direct edge .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			14:1			0		1.0
11:1			15:1			0		1.0
12:1			16:1			0		1.0
13:1			17:1			0		1.0
14:1			18:1			0		1.0
15:1			19:1			0		1.0
16:1			20:1			0		1.0
17:1			21:1			0		1.0
18:1			22:1			0		1.0
19:1			23:1			0		1.0
20:1			24:1			0		1.0
21:1			25:1			0		1.0
22:1			26:1			0		1.0
23:1			27:1			0		1.0

Alignment 306
Thus , by the compaction of the trees , our model can capture more useful dependencies among word senses .
By the compaction of the trees , therefore , our model can capture more useful dependencies among word senses .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			3:1			0		1.0
2:1			4:1			0		1.0
3:1			5:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			1:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 307
Note that for the supersense-based model , we further convert the tree into a tree of nouns and verbs , because supersenses are defined for only these two parts of speech .
For the supersense-based model , we further convert the tree into a tree of nouns and verbs , because supersenses are defined for only these two parts of speech .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			3:1			0		1.0
2:1			4:1			0		1.0
3:1			5:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0
24:1			26:1			0		1.0
25:1			27:1			0		1.0
26:1			28:1			0		1.0
27:1			29:1			0		1.0
28:1			30:1			0		1.0
29:1			31:1			0		1.0

Alignment 308
The inclusion of removed words and dependency relation labels are performed in the same manner as in the synset-based model , and the tree on the right hand side of Figure 2 in this case remains unchanged because the sentence does not contain any adjectives nor adverbs .
The inclusion of removed words and dependency relation labels are performed in the same manner as in the synset-based model ; the tree on the right hand side of Figure 2 in this case remains unchanged , because the sentence does not contain any adjectives nor adverbs .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0
31:1			32:1			0		1.0
32:1			33:1			0		1.0
33:1			34:1			0		1.0
34:1			35:1			0		1.0
35:1			36:1			0		1.0
36:1			20:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0

Alignment 309
For the linear-chain models , we do not need to parse a sentence .
For the linear-chain models , parsing a sentence is unnecessary .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			10:1			1		1.0
6:1			11:1			0		1.0
7:1			12:1			0		1.0
8:2			6:3			3		1.0
10:1			13:1			0		1.0

Alignment 310
At first , we connect every adjacent words with an edge , and build a linear chain .
At first , we connect every adjacent words with an edge , and build a linear chain .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 311
Next , as the same reason for the tree-structured case , we remove from the graph those words that we do not need to disambiguate , in order to capture the direct dependencies between content words ( or nouns and verbs in the supersense-based model ) .
Next , as the same reason as for the tree-structured case , we remove those words that we do not need to disambiguate from the graph , in order to capture the direct dependencies between content words ( or nouns and verbs in the supersense-based model ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:4			20:4			3		1.0
21:1			28:1			0		1.0
22:1			24:1			0		1.0
23:1			13:1			0		1.0
24:1			14:1			0		1.0
25:1			15:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
37:1			36:1			0		1.0
38:1			37:1			0		1.0
39:1			38:1			0		1.0
40:1			39:1			0		1.0
41:1			40:1			0		1.0
42:1			41:1			0		1.0
43:1			42:1			0		1.0
44:1			43:1			0		1.0
45:1			44:1			0		1.0
46:1			45:1			0		1.0
47:1			46:1			0		1.0

Alignment 312
Thus , the process of the tree compaction is performed in the same manner , as described in Figure 3 .
Thus , the process of the tree compaction[ ? ?] is performed in the same manner , as described in Figure 3 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0

Alignment 313
In this section , let us present an intuitive illustration of how our model works .
In this section , let us present an intuitive illustration of how our model works .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 314
Here , we focus on three words destroy , confidence , and bank in Sentence ( i ) , and for simplicity consider only two major senses for each word as described in Table 3 , so that the number of possible sense assignments is in this case / MATH .
Here , we focus on three words : destroy , confidence , and bank in Sentence ( I ) . For simplicity , we consider only two major senses for each word as described in Table 3 , so that the number of possible sense assignments is / MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
18:1			17:1			0		1.0
19:1			50:1			0		1.0
21:1			21:1			0		1.0
22:1			18:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
33:1			31:1			0		1.0
34:1			32:1			0		1.0
35:1			33:1			0		1.0
36:1			34:1			0		1.0
37:1			35:1			0		1.0
38:1			36:1			0		1.0
39:1			37:1			0		1.0
40:1			38:1			0		1.0
41:1			39:1			0		1.0
42:1			40:1			0		1.0
43:1			41:1			0		1.0
44:1			42:1			0		1.0
45:1			43:1			0		1.0
46:1			44:1			0		1.0
47:1			48:1			0		1.0
48:1			49:1			0		1.0

Alignment 315
After an appropriate compaction of the dependency tree , relationships among destroy , confidence , and bank , are represented as direct connections .
After an appropriate compaction of the dependency tree , relationships among destroy , confidence , and bank , are represented as direct connections .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 316
Now , our objective is to determine the correct assignment of senses to these words , given the trained weight vector for features .
Now , our objective is to determine the correct assignment of senses to these words , given the trained weight vector for features .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 317
We conduct this by evaluating the scores for all possible assignment of senses .
We conduct this by evaluating the scores for all possible assignment of senses .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 318
Let us start from the dependency between confidence and bank .
Let us start from the dependency between confidence and bank .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 319
The first intuition would be that confidence( n )#2 is strongly related to a group or an institution ( financial bank ) but not related to natural landscape ( river bank ) , while confidence( n )#1 depends mostly on persons and not on other entities .
The first intuition would be that confidence( n )#2 is strongly related to a group or an institution ( financial bank ) , but is unrelated to a natural landscape ( river bank ) , while confidence( n )#1 depends mostly on persons and not on other entities .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			32:1			0		1.0
23:1			22:1			0		1.0
25:2			23:3			3		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
33:1			31:1			0		1.0
35:1			33:1			0		1.0
36:1			34:1			0		1.0
37:1			35:1			0		1.0
38:1			36:1			0		1.0
39:1			37:1			0		1.0
40:1			38:1			0		1.0
41:1			39:1			0		1.0
42:1			40:1			0		1.0
43:1			41:1			0		1.0
44:1			42:1			0		1.0
45:1			43:1			0		1.0
46:1			44:1			0		1.0
47:1			45:1			0		1.0
48:1			46:1			0		1.0

Alignment 320
Because bank does not have a " person " meaning , the weight of confidence( n )#2-bank( n )#1 is expected to be higher than other possible sense bigrams .
Because bank does not have a " person " meaning , the weight of confidence( n )#2-bank( n )#1 is expected to be higher than for other possible sense bigrams .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0

Alignment 321
A similar argument can be made for the dependency between destroy and confidence .
A similar argument can be made for the dependency between destroy and confidence .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 322
We can assume that destroy( v )#1 is usually associated with real objects , whereas destroy( v )#2 can take either a real entity or an abstract thing as its direct object .
We can assume that destroy( v )#1 is usually associated with real objects , whereas destroy( v )#2 can take either a real entity or an abstract thing as its direct object .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0

Alignment 323
Given confidence does not have an " object " meaning , the weights of destroy( v )#2-confidence( n )#1 and destroy( v )#2-confidence( n )#2 would be the largest among others .
Given confidence does not have an " object " meaning , the weights of destroy( v )#2-confidence( n )#1 and destroy( v )#2-confidence( n )#2 would be the largest [largest what ?] among others .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
32:1			29:1			0		1.0
33:1			30:1			0		1.0
34:1			31:1			0		1.0

Alignment 324
Finally , given all scores for these sense dependencies , we can evaluate the overall score for the sentence , and see / MATHdestroy( v )#2 , confidence( n )#2 , bank( n )#1 / MATH is the most probable assignment of senses .
Finally , given all scores for these sense dependencies , we can evaluate the overall score for the sentence , and see / MATHdestroy( v )#2 , confidence( n )#2 , bank( n )#1 / MATH is the most probable assignment of senses .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0

Alignment 325
Practically , specific bigrams of synsets such as confidence( n )#2-bank( n )#1 and destroy( v )#2-confidence( n )#2 may not appear in the training data .
Practically , specific bigrams of synsets such as confidence( n )#2-bank( n )#1 and destroy( v )#2-confidence( n )#2 may not appear in the training data .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 326
In this case , sense bigrams combined with coarser sense labels work effectively .
In this case , sense bigrams combined with coarser sense labels work effectively .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 327
For example , if there exist synset bigrams such as destroy( v )#2-affection( n )#1 in the training data , the model can still perform the disambiguation process properly by considering a generalized synset-supersense bigram destroy( v )#2-noun .feeling .
For example , if there are synset bigrams such as destroy( v )#2-affection( n )#1 in the training data , the model can still perform the disambiguation process properly by considering a generalized synset-supersense bigram destroy( v )#2-noun .feeling .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			2		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0

Alignment 328
The detailed description of sense bigrams are given in Section 4 .7 .
The detailed description of sense bigrams are provided in Section 4 .7 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 329
Using the information in the WordNet , we make use of four sense labels for each word : a synset / MATH , two general synsets / MATH and / MATH , and a supersense / MATH , which we introduced in Section 2 .
Using the information in the WordNet , we make use of four sense labels for each word : a synset / MATH , two general synsets / MATH and / MATH , and a supersense / MATH , which we introduced in Section 2 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0

Alignment 330
These labels represent word senses at various levels , and to be combined with the vertex and edge features .
These labels represent word senses at various levels , and are to be combined with the vertex and edge features .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0

Alignment 331
We hereinafter distinguish each sense label by putting one of the prefixes WS , G1 , G2 , and SS , as in WS :bank#1 and SS :noun .group .
We hereafter distinguish each sense label by putting one of the prefixes WS , G1 , G2 , and SS , as in WS :bank#1 and SS :noun .group .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			2		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0

Alignment 332
The examples of these sense labels are shown in Table 4 .
The examples of these sense labels are shown in Table 4 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 333
In our model , we combine the synset and supersense labels with the vertex features , and all four sense labels with the edge features .
In our model , we combine the synset and supersense labels with the vertex features , and all four sense labels with the edge features .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 334
We denote the set of sense labels for vertex features by / MATH , and the one for edge features by / MATH .
We denote the set of sense labels for vertex features by / MATH , and the one for edge features by / MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 335
Each of these sense labels is combined with the contextual information in the vertex features , whereas all possible combinations of two sense labels comprise the edge features .
Each of these sense labels is combined with the contextual information in the vertex features , whereas all possible combinations of two sense labels comprise the edge features .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 336
We implement as vertex features a set of typical contextual features widely used in a lot of supervised WSD models .
We implement as vertex features a set of typical contextual features widely used in many supervised WSD models .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0

Alignment 337
Most of these features are those used by with the exception of the syntactic features .
Most of these features are those used by with the exception of the syntactic features .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 338
In order to see whether the sense dependency features are certainly effective or not , we include as vertex features the word forms , lemmas , and parts of speech of both the parent and the child words in the dependency tree .
In order to see the efficiency of sense dependency features , we include as vertex features the word forms , lemmas , and parts of speech of both the parent and the child words in the dependency tree .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			5:1			0		1.0
6:1			30:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			14:1			0		1.0
11:1			15:1			0		1.0
12:1			16:1			0		1.0
13:1			17:1			0		1.0
14:1			18:1			0		1.0
15:1			19:1			0		1.0
16:1			20:1			0		1.0
17:1			21:1			0		1.0
18:1			22:1			0		1.0
19:1			23:1			0		1.0
20:1			24:1			0		1.0
21:1			25:1			0		1.0
22:1			26:1			0		1.0
23:1			27:1			0		1.0
24:1			28:1			0		1.0
25:1			29:1			0		1.0
27:1			31:1			0		1.0
28:1			32:1			0		1.0
29:1			33:1			0		1.0
30:1			34:1			0		1.0
31:1			35:1			0		1.0
32:1			36:1			0		1.0
33:1			37:1			0		1.0
34:1			38:1			0		1.0
35:1			39:1			0		1.0
36:1			40:1			0		1.0
37:1			41:1			0		1.0
38:1			42:1			0		1.0

Alignment 339
These features provide the syntactic information of the parent and child words , but are not semantically disambiguated .
These features provide the syntactic information of the parent and child words , but are not semantically disambiguated .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 340
Therefore , if the sense bigram features work effectively over these features , it clearly shows that there exist instances that cannot be disambiguated without considering the interdependency of word senses .
Therefore , if the sense bigram features work effectively over these features , it clearly shows that there exist instances that cannot be disambiguated without considering the interdependency of word senses .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0

Alignment 341
The list of vertex features also includes the information of both the preceding and following words , which in the linear-chain model plays the same role as the parent and child information in the tree-structured model .
The list of vertex features also includes the information of both the preceding and following words , which in the linear-chain model plays the same role as the parent and child information in the tree-structured model .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0

Alignment 342
Below is the list of contextual information used for the vertex features in the synset-based model .
Below is the list of contextual information used for the vertex features in the synset-based model .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 343
We refer to these features as / MATH .
We refer to these features as / MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 344
- Word form ( WF ) : word form as it appears in a text .
- Word form ( WF ) : word form as it appears in a text .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 345
- Global context ( GC ) : bag-of-words within a 60-word window .
- Global context ( GC ) : bag-of-words within a 60-word window .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 346
- Local PoS ( LP ) : / MATH , / MATH , / MATH , / MATH , / MATH , / MATH , and / MATH , where / MATH in / MATH denotes the relative position to the target word .
- Local PoS ( LP ) : / MATH , / MATH , / MATH , / MATH , / MATH , / MATH , and / MATH , where / MATH in / MATH denotes the relative position to the target word .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0

Alignment 347
- Local context ( LC ) : / MATH , / MATH , / MATH , / MATH , / MATH , / MATH , / MATH , / MATH , / MATH , / MATH , / MATH , and / MATH , where / MATH denotes the word at the relative position / MATH , and / MATH the n-gram from the relative position / MATH to / MATH .
- Local context ( LC ) : / MATH , / MATH , / MATH , / MATH , / MATH , / MATH , / MATH , / MATH , / MATH , / MATH , / MATH , and / MATH , where / MATH denotes the word at the relative position / MATH , and / MATH the n-gram from the relative position / MATH to / MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0
49:1			49:1			0		1.0
50:1			50:1			0		1.0
51:1			51:1			0		1.0
52:1			52:1			0		1.0
53:1			53:1			0		1.0
54:1			54:1			0		1.0
55:1			55:1			0		1.0
56:1			56:1			0		1.0
57:1			57:1			0		1.0
58:1			58:1			0		1.0
59:1			59:1			0		1.0
60:1			60:1			0		1.0
61:1			61:1			0		1.0
62:1			62:1			0		1.0
63:1			63:1			0		1.0
64:1			64:1			0		1.0
65:1			65:1			0		1.0
66:1			66:1			0		1.0
67:1			67:1			0		1.0
68:1			68:1			0		1.0
69:1			69:1			0		1.0
70:1			70:1			0		1.0
71:1			71:1			0		1.0

Alignment 348
- Syntactic context ( SC ) : word forms , lemmas , and parts of speech of the parent and child words .
- Syntactic context ( SC ) : word forms , lemmas , and parts of speech of the parent and child words .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 349
Using this contextual information and the set of vertex labels / MATH , we construct a set of features on a vertex / MATH by / MATH .
Using this contextual information , and the set of vertex labels / MATH , we construct a set of features on a vertex / MATH by / MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			12:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0

Alignment 350
Additionally , we include the sense ranking feature ( see Section 2 .3 for detail ) .
Additionally , we include the sense ranking feature ( see Section 2 .3 for detail ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 351
Note that this feature is not combined with any sense labels nor contextual information .
Note that this feature is not combined with any sense label nor with any contextual information .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			1		1.0
11:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0

Alignment 352
For the supersense-based model , we use vertex features based on , which includes some features from the named entity recognition literature such as the word shape features along with the standard feature set for WSD .
For the supersense-based model , we use vertex features based on , which include some features from the named entity recognition literature , including the word shape features , along with the standard feature set for WSD .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			1		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
37:1			36:1			0		1.0

Alignment 353
As the sense frequency information , we use the first sense feature .
As the sense frequency information , we use the first sense feature .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 354
Unlike in the synset-based model , we do not incorporate the syntactic information of the parent and child words , since it has been reported not to improve the performance .
Unlike in the synset-based model , we do not incorporate the syntactic information of the parent and child words , since it has not been reported to improve the performance .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:4			22:2			3		1.0
25:1			24:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0

Alignment 355
We design a set of edge features that represents the inter-word sense dependencies .
We design a set of edge features that represents the inter-word sense dependencies .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 356
For each edge , we define the sense bigram features / MATH .
For each edge , we define the sense bigram features / MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 357
Moreover , in addition to these simple bigrams , we define two kinds of combined bigrams : the sense bigrams with dependency relation labels ( e.g. WS :confidence#2-( NMOD )-WS :bank#1 ) , and the sense bigrams with removed words in between ( e.g. WS :confidence#2-in-WS :bank#1 ) .
Moreover , in addition to these simple bigrams , we define two kinds of combined bigrams : the sense bigrams with dependency relation labels ( e.g. WS :confidence#2-( NMOD )-WS :bank#1 ) , and the sense bigrams with removed words in between ( e.g. WS :confidence#2-in-WS :bank#1 ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0

Alignment 358
Consequently , the number of features for each edge is / MATH .
Consequently , the number of features for each edge is / MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 359
In this section , we introduce corpora we use for the evaluation .
In this section , we introduce corpora that we have used for the evaluation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			7:1			0		1.0
9:2			8:1			3		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0

Alignment 360
SemCor is a corpus , in which all content words are annotated with the WordNet synsets , and consists of balanced 352 files from the Brown Corpus .
SemCor is a corpus in which all content words are annotated with the WordNet synsets , and consists of balanced 352 files from the Brown Corpus .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0

Alignment 361
It is divided into three parts : brown1 , brown2 , and brownv sections .
It is divided into three parts : brown1 , brown2 , and brownv sections .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 362
In brown1 and brown2 , all content words ( nouns , verbs , adjectives , and adverbs ) are semantically annotated , while in brownv only verbs are annotated .
In brown1 and brown2 , all content words ( nouns , verbs , adjectives , and adverbs ) are semantically annotated , while in brownv only verbs are annotated .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0

Alignment 363
Also , we use two data sets from the Senseval ( International Workshop on Evaluating Word Sense Disambiguation Systems ) exercises : the Senseval-2 English all-words task test set , consisting of three articles from the Wall Street Journal , and the Senseval-3 English all-words task test set , consisting of two articles from the Wall Street Journal and a fiction excerpt from the unannotated portion of the Brown corpus .
Also , we use two data sets from the Senseval ( International Workshop on Evaluating Word Sense Disambiguation Systems ) exercises : the Senseval-2 English all-words task test set , consisting of three articles from the Wall Street Journal , and the Senseval-3 English all-words task test set , consisting of two articles from the Wall Street Journal and a fiction excerpt from the unannotated portion of the Brown corpus .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0
49:1			49:1			0		1.0
50:1			50:1			0		1.0
51:1			51:1			0		1.0
52:1			52:1			0		1.0
53:1			53:1			0		1.0
54:1			54:1			0		1.0
55:1			55:1			0		1.0
56:1			56:1			0		1.0
57:1			57:1			0		1.0
58:1			58:1			0		1.0
59:1			59:1			0		1.0
60:1			60:1			0		1.0
61:1			61:1			0		1.0
62:1			62:1			0		1.0
63:1			63:1			0		1.0
64:1			64:1			0		1.0
65:1			65:1			0		1.0
66:1			66:1			0		1.0
67:1			67:1			0		1.0
68:1			68:1			0		1.0
69:1			69:1			0		1.0
70:1			70:1			0		1.0

Alignment 364
As the data sets for evaluation , we use the brown1 and brown2 sections ( denoted as SEM ) of SemCor , and the Senseval-2 and -3 all-words task test sets ( denoted as SE2 and SE3 , respectively ) .
As the data sets for evaluation , we use the brown1 and brown2 sections ( denoted as SEM ) of SemCor , and the Senseval-2 and -3 all-words task test sets ( denoted as SE2 and SE3 , respectively ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0

Alignment 365
We use the converted versions annotated with WordNet 2 .0 synsets .
We use the converted versions annotated with WordNet 2 .0 synsets .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 366
Note that these data sets are different from the originals in that multi-word expressions are already segmented .
These data sets are different from the originals because multi-word expressions are already segmented .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			3:1			0		1.0
2:1			4:1			0		1.0
3:1			5:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
9:1			12:1			0		1.0
10:1			13:1			0		1.0
11:1			14:1			0		1.0
12:1			15:1			0		1.0
13:1			16:1			0		1.0
14:1			17:1			0		1.0

Alignment 367
However , on the other hand , our model cannot output any answers to multi-word expressions that have no directly corresponding WordNet synsets , because we treat expression as one unit in the process of WSD .
However , our model cannot output any answers to multi-word expressions that have no directly corresponding WordNet synsets , because we treat expression as one unit in the process of WSD .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			7:1			0		1.0
3:1			8:1			0		1.0
4:1			9:1			0		1.0
5:1			10:1			0		1.0
6:1			11:1			0		1.0
7:1			12:1			0		1.0
8:1			13:1			0		1.0
9:1			14:1			0		1.0
10:1			15:1			0		1.0
11:1			16:1			0		1.0
12:1			17:1			0		1.0
13:1			18:1			0		1.0
14:1			19:1			0		1.0
15:1			20:1			0		1.0
16:1			21:1			0		1.0
17:1			22:1			0		1.0
18:1			23:1			0		1.0
19:1			24:1			0		1.0
20:1			25:1			0		1.0
21:1			26:1			0		1.0
22:1			27:1			0		1.0
23:1			28:1			0		1.0
24:1			29:1			0		1.0
25:1			30:1			0		1.0
26:1			31:1			0		1.0
27:1			32:1			0		1.0
28:1			33:1			0		1.0
29:1			34:1			0		1.0
30:1			35:1			0		1.0
31:1			36:1			0		1.0

Alignment 368
For example , the multi-word expression tear-filled is treated as one instance but not tagged with any WordNet synsets in the converted corpus , while in the original corpus it is tagged with two WordNet synsets for tear and filled .
For example , the multi-word expression tear-filled is treated as one instance , but are untagged with any WordNet synsets in the converted corpus , while in the original corpus it[define " it " ] is tagged with two WordNet synsets for tear and filled .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			23:1			0		1.0
13:1			12:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
32:1			29:1			0		1.0
35:1			30:1			0		1.0
36:1			31:1			0		1.0
37:1			32:1			0		1.0
38:1			33:1			0		1.0
39:1			34:1			0		1.0
40:1			35:1			0		1.0
41:1			36:1			0		1.0
42:1			37:1			0		1.0
43:1			38:1			0		1.0
44:1			39:1			0		1.0
45:1			40:1			0		1.0

Alignment 369
For this reason , we exclude such instances beforehand , and evaluate our models focused on expressions that have corresponding synsets in the WordNet .
For this reason , we exclude such instances beforehand , and evaluate our models focused on expressions that have corresponding synsets in the WordNet .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 370
The resulting statistics of the data sets are shown in Table 5 .
The resulting statistics of the data sets are shown in Table 5 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 371
The evaluation of our model is performed by splitting these corpora into training , development , and test sets .
The evaluation of our model is performed by splitting these corpora into training , development , and test sets .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 372
At first , all files in SEM are sorted according to their file names and distributed into five data sets in order ( denoted as SEM-A , SEM-B , SEM-C , SEM-D , and SEM-E ) , so that each set has almost the same distribution of domains .
At first , all files in SEM are sorted according to their file names and distributed into five data sets in order ( denoted as SEM-A , SEM-B , SEM-C , SEM-D , and SEM-E ) , so that each set has almost the same distribution of domains .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0

Alignment 373
Furthermore , each of these five data sets is again split into two sets : SEM-A1 , SEM-A2 , / MATH , SEM-E1 , and SEM-E2 , also according to the order of file names .
Furthermore , each of these five data sets is again split into two sets : SEM-A1 , SEM-A2 , / MATH , SEM-E1 , and SEM-E2 , also according to the order of file names .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0

Alignment 374
Our evaluation is based on a 5-fold cross validation scheme .
Our evaluation is based on a 5-fold cross validation scheme .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 375
In the training phase , four sets ( e.g. SEM-A , SEM-B , SEM-C , SEM-D ) in the SEM are used for training .
In the training phase , four sets ( e.g. SEM-A , SEM-B , SEM-C , SEM-D ) in the SEM are used for training .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 376
Next , for the evaluation on SemCor , one half of the rest ( e.g. SEM-E1 ) is used for development and the other half ( e.g. SEM-E2 ) is used for evaluation .
Next , for the evaluation on SemCor , one half of the rest ( e.g. SEM-E1 ) is used for development and the other half ( e.g. SEM-E2 ) is used for evaluation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0

Alignment 377
For the evaluation on the Senseval data sets , all instances of the rest ( e.g. SEM-E ) is used for development and one of the Senseval data sets ( SE2 or SE3 ) is used for evaluation .
For the evaluation on the Senseval data sets , all instances of the rest ( e.g. SEM-E ) are used for development , and one of the Senseval data sets ( SE2 or SE3 ) is used for evaluation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:2			18:2			3		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
37:1			36:1			0		1.0
38:1			37:1			0		1.0
39:1			38:1			0		1.0

Alignment 378
Lastly , for the comparison with state-of-the-art models , our model is trained on the whole set of SEM , and SE2 and SE3 are used for development and evaluation respectively .
Lastly , for the comparison with state-of-the-art models , our model is trained on the whole set of SEM , and SE2 and SE3 are used for development and evaluation respectively .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0

Alignment 379
All sentences are parsed by the Sagae and Tsujii 's dependency parser , and the T-CRF model is trained by using Amis .
All sentences are parsed by the Sagae and Tsujii 's dependency parser , and the T-CRF model is trained by using Amis .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 380
During the development phase , we tune the Gaussian parameter / MATH for the / MATH regularization term .
During the development phase , we tune the Gaussian parameter / MATH for the / MATH regularization term .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 381
As the evaluation measure , we use the standard recall measure , which is equivalent to the precision as we output answers to all instances .
As the evaluation measure , we use the standard recall measure , which is equivalent to the precision as we output answers to all instances . **[This section is a bit monotonous]
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 382
The synset-based evaluation is performed based on the WordNet synsets .
The synset-based evaluation is performed based on the WordNet synsets .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 383
We evaluate the outputs of our system for all instances that are semantically tagged in the data sets .
We evaluate the outputs of our system for all instances that are semantically tagged in the data sets .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 384
Each target word is either a noun , verb , adjective , or adverb .
Each target word is either a noun , verb , adjective , or adverb .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 385
For the supersense-based evaluation , we follow most of the experimental setup in .
For the supersense-based evaluation , we follow most of the experimental setup in .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 386
As they noted , in the WordNet , there is semantically inconsistent labeling of supersenses such that top level synsets are tagged as the supersense noun .Tops rather than the specific supersense they govern .
As noted , in the WordNet , the labeling of supersensesis semantically inconsistent , and top level synsets are tagged as the supersense noun .Tops[ ? ?] rather than the specific supersense they govern .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			29:1			0		1.0
8:1			12:1			0		1.0
9:1			13:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0

Alignment 387
For example , nouns such as peach and plum are tagged as noun .plant but their hypernym plant itself belongs to noun .Tops .
For example , nouns such as peach and plum are tagged as noun .plant but their hypernym plant itself belongs to noun .Tops .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 388
For this reason , we adopted the modification of noun supersenses in the same way as , substituting noun .Tops labels with more specific supersense labels when possible , and left some general nouns with noun .TopsoteNouns which are left with noun .Tops are : entity , thing , anything , something , nothing , object , living thing , organism , benthos , heterotroph , life , and biont . .
For this reason , we adopted the modification of noun supersenses in the same way as , substituting noun .Tops labels with more specific supersense labels when possible , and left some general nouns with noun .TopsoteNouns , which are left with noun .Tops are : entity , thing , anything , something , nothing , object , living thing , organism , benthos , heterotroph , life , and biont . .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			67:1			0		1.0
38:1			37:1			0		1.0
39:1			38:1			0		1.0
40:1			39:1			0		1.0
41:1			40:1			0		1.0
42:1			41:1			0		1.0
43:1			42:1			0		1.0
44:1			43:1			0		1.0
45:1			44:1			0		1.0
46:1			45:1			0		1.0
47:1			46:1			0		1.0
48:1			47:1			0		1.0
49:1			48:1			0		1.0
50:1			49:1			0		1.0
51:1			50:1			0		1.0
52:1			51:1			0		1.0
53:1			52:1			0		1.0
54:1			53:1			0		1.0
55:1			54:1			0		1.0
56:1			55:1			0		1.0
57:1			56:1			0		1.0
58:1			57:1			0		1.0
59:1			58:1			0		1.0
60:1			59:1			0		1.0
61:1			60:1			0		1.0
62:1			61:1			0		1.0
63:1			62:1			0		1.0
64:1			63:1			0		1.0
65:1			64:1			0		1.0
66:1			65:1			0		1.0
67:1			66:1			0		1.0
69:1			68:1			0		1.0
70:1			69:1			0		1.0
71:1			70:1			0		1.0
72:1			71:1			0		1.0

Alignment 389
The evaluation is based on these modified labels .
The evaluation is based on these modified labels .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 390
We ignore the adjective and adverb instances in the evaluation .
We ignore the adjective and adverb instances in the evaluation .**[This section is a bit confusing . Maybe break up the longer sentences to clarify]
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
16:1			10:1			0		1.0

Alignment 391
Table 6 is the list of models we use for the evaluation , where FS and SR correspond to the first sense and sense ranking features respectively , and non-dependency denotes models that do not incorporate sense dependency features ( i.e.
Table 6 is the list of models that we use for the evaluation , where FS and SR correspond to the first sense and sense ranking features respectively , and non-dependency denotes models that do not incorporate sense dependency features ( i.e.
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			32:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
37:1			36:1			0		1.0
38:1			37:1			0		1.0
39:1			38:1			0		1.0
40:1			39:1			0		1.0
41:1			40:1			0		1.0

Alignment 392
only the vertex features ) .
only the vertex features ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0

Alignment 393
In this section , we focus on the contribution of the sense dependencies .
In this section , we focus on the contribution of the sense dependencies .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 394
Table 7 shows the comparisons between the tree-structured models with sense dependencies ( dependency models ) and the models without sense dependencies ( non-dependency models ) .
Table 7 shows the comparisons between the tree-structured models with sense dependencies ( dependency models ) and the models without sense dependencies ( non-dependency models ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 395
In this section , each figure shows the mean recall ( equivalent to the precisions ) averaged over the five trials of the cross validation , the " Diff . " rows show the differences between the dependency models and the non-dependency models , and / MATH and / MATH denote the statistical significance of / MATH and / MATH respectively .
Each figure displays the mean recall ( equivalent to the precisions ) averaged over the five trials of the cross validation , the " Diff . " rows show the differences between the dependency models and the non-dependency models , and / MATH and / MATH denote the statistical significance of / MATH and / MATH respectively .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			5:1			0		1.0
2:1			6:1			2		1.0
3:1			7:1			0		1.0
4:1			8:1			0		1.0
5:1			9:1			0		1.0
6:1			10:1			0		1.0
7:1			11:1			0		1.0
8:1			12:1			0		1.0
9:1			13:1			0		1.0
10:1			14:1			0		1.0
11:1			15:1			0		1.0
12:1			16:1			0		1.0
13:1			17:1			0		1.0
14:1			18:1			0		1.0
15:1			19:1			0		1.0
16:1			20:1			0		1.0
17:1			21:1			0		1.0
18:1			22:1			0		1.0
19:1			23:1			0		1.0
20:1			24:1			0		1.0
21:1			25:1			0		1.0
22:1			26:1			0		1.0
23:1			27:1			0		1.0
24:1			28:1			0		1.0
25:1			29:1			0		1.0
26:1			30:1			0		1.0
27:1			31:1			0		1.0
28:1			32:1			0		1.0
29:1			33:1			0		1.0
30:1			34:1			0		1.0
31:1			35:1			0		1.0
32:1			36:1			0		1.0
33:1			37:1			0		1.0
34:1			38:1			0		1.0
35:1			39:1			0		1.0
36:1			40:1			0		1.0
37:1			41:1			0		1.0
38:1			42:1			0		1.0
39:1			43:1			0		1.0
40:1			44:1			0		1.0
41:1			45:1			0		1.0
42:1			46:1			0		1.0
43:1			47:1			0		1.0
44:1			48:1			0		1.0
45:1			49:1			0		1.0
46:1			50:1			0		1.0
47:1			51:1			0		1.0
48:1			52:1			0		1.0
49:1			53:1			0		1.0
50:1			54:1			0		1.0
51:1			55:1			0		1.0
52:1			56:1			0		1.0
53:1			57:1			0		1.0
54:1			58:1			0		1.0
55:1			59:1			0		1.0
56:1			60:1			0		1.0
57:1			61:1			0		1.0

Alignment 396
We can see from Table 7 that with the sense frequency information , the tree-structured models ( statistically ) significantly outperformed the non-dependency models on all the data sets .
From Table 7 , it can be seen that with the sense frequency information , the tree-structured models ( statistically ) significantly outperformed the non-dependency models on all the data sets .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			4:1			0		1.0
2:1			5:1			0		1.0
5:1			1:1			0		1.0
6:2			2:1			3		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0

Alignment 397
These improvements seem small in terms of figures ; However , considering for instance the No-Dep-SS-FS model outperforms the Baseline-SS-FS model only by 0 .37% on SEM , the further improvement of 0 .21% is considerable because this means our dependency model could handle 57% more instances over the first sense baseline .
These improvements seem insignificant in figures ; however , considering that for instance the No-Dep-SS-FS model outperforms the Baseline-SS-FS model by only 0 .37% on SEM , the further improvement of 0 .21% is substantial , because it indicates that our dependency model could handle 57% more instances over the first sense baseline .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			3		1.0
4:1			4:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			22:1			0		1.0
21:1			21:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0
31:1			32:1			0		1.0
32:1			33:1			0		1.0
33:1			34:1			0		1.0
34:1			35:1			3		1.0
36:2			36:2			3		1.0
40:1			39:1			0		1.0
41:1			40:1			0		1.0
42:1			41:1			0		1.0
43:1			42:1			0		1.0
44:1			43:1			0		1.0
45:1			44:1			0		1.0
46:1			45:1			0		1.0
47:1			46:1			0		1.0
48:1			47:1			0		1.0
49:1			48:1			0		1.0
50:1			49:1			0		1.0
51:1			50:1			0		1.0
52:1			51:1			0		1.0
53:1			52:1			0		1.0

Alignment 398
Note that , without the sense frequency information , the synset-based tree-structured model ( Tree-WS ) performed poorer than the non-dependency model ( NoDep-WS ) on all the data sets , whereas the supersense-based model ( Tree-SS ) exhibited the robustness regardless of the existence of the sense frequency information .
Note that , without the sense frequency information , the synset-based tree-structured model ( Tree-WS ) performed worse than the non-dependency model ( NoDep-WS ) on all the data sets , whereas the supersense-based model ( Tree-SS ) exhibited the robustness [of ...] regardless of the existence of the sense frequency information .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:2			17:2			3		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
43:1			41:1			0		1.0
44:1			42:1			0		1.0
45:1			43:1			0		1.0
46:1			44:1			0		1.0
47:1			45:1			0		1.0
48:1			46:1			0		1.0
49:1			47:1			0		1.0
50:1			48:1			0		1.0
51:1			49:1			0		1.0
52:1			50:1			0		1.0

Alignment 399
These results suggest that for the synset-based model , in which most synsets do not have enough instances in the training data , the combination with sense-frequency information is necessary in order to avoid the data sparseness problem .
These results suggest that for the synset-based model , in which most synsets do not have enough instances in the training data , the combination with sense-frequency information is necessary in order to avoid the data sparseness problem .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0

Alignment 400
Similarly , Table 8 shows the comparisons between the linear-chain dependency models and the non-dependency models .
Similarly , Table 8 shows the comparisons between the linear-chain dependency models and the non-dependency models .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 401
In the supersense-based evaluation , although the differences are slightly smaller than in the tree-structured models , we confirmed that the sense dependencies with the first sense features work effectively , with the overall improvements of 0 .29% , 0 .20% , and 0 .30% for the three data sets .
In the supersense-based evaluation , although the differences are slightly smaller than in the tree-structured models , we confirmed that the sense dependencies with the first sense features work effectively , with the overall improvements of 0 .29% , 0 .20% , and 0 .30% for the three data sets .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0
49:1			49:1			0		1.0
50:1			50:1			0		1.0

Alignment 402
However , without the first sense features , no statistically significant improvement nor deterioration is observed .
However , without the first sense features , no statistically significant improvement nor deterioration is observed .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 403
In the synset-based evaluation , the overall trend is almost same as in the tree-structured case .
In the synset-based evaluation , the overall trend is almost same as in the tree-structured case .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 404
However , by the incorporation of the sense dependencies , the improvements with the sense ranking features are even smaller , and the deteriorations without them are even larger than in the tree-structured case .
Nonetheless , by the incorporation of the sense dependencies , the improvements with the sense ranking features was even less , and the deteriorations without them[define " them " ] were even more than in the tree-structured case .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			2		1.0
18:2			18:2			3		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
27:1			25:1			0		1.0
30:2			26:2			3		1.0
32:2			28:2			3		1.0
34:1			30:1			0		1.0
35:1			31:1			0		1.0
36:1			32:1			0		1.0
37:1			33:1			0		1.0
38:1			34:1			0		1.0

Alignment 405
These results seem to suggest that the sense dependencies on the tree structures are more robust than those on the linear chains .
These results seem to suggest that the sense dependencies on the tree structures are more robust than those on the linear chains .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 406
In this section , let us focus on the difference between the tree-structured models and the linear-chain models .
In this section , let us focus on the difference between the tree-structured models and the linear-chain models .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 407
In the results shown in Table 9 , although some of the differences are marginal , we can see that the tree-structured models outperformed the linear-chain models , focusing on the statistically significant differences .
In the results shown in Table 9 , although some of the differences are marginal , we can see that the tree-structured models outperformed the linear-chain models , focusing on the statistically significant differences .**[<-This is a confusing sentence]
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0

Alignment 408
These results suggest that although both the dependency trees and the linear chains capture useful dependencies of word senses , the dependencies on the tree structures capture more important information .
Thus , although both the dependency trees and the linear chains capture useful dependencies of word senses , the dependencies on the tree structures capture more important information .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			19:1			0		1.0
2:1			4:1			0		1.0
3:1			5:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0
24:1			26:1			0		1.0
25:1			27:1			0		1.0
26:1			28:1			0		1.0
27:1			29:1			0		1.0
28:1			30:1			0		1.0

Alignment 409
Table 10 shows the contributions of the coarse-grained labels .
Table 10 shows the contributions of the coarse-grained labels .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 410
Whereas Tree-WS-SR and Tree-WS use all four sense labels for the edge features ( / MATH ) , Tree-WS-SR' and Tree-WS' only use the synset labels ( / MATH ) , so that we can see the contribution of the coarse-grained sense labels .
Whereas Tree-WS-SR and Tree-WS use all four sense labels for the edge features ( / MATH ) , Tree-WS-SR' and Tree-WS' only use the synset labels ( / MATH ) . Thus , we can see the contribution of the coarse-grained sense labels .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			43:1			0		1.0
32:1			30:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0

Alignment 411
Although the improvements are marginal , we can see that the coarse-grained sense labels did consistently improve the performance on all the data sets , relieving the data sparseness problem .
Although the improvements are marginal , we can see that the coarse-grained sense labels consistently did improve the performance on all the data sets , relieving the data sparseness problem .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			15:1			0		1.0
15:1			14:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0

Alignment 412
Since synset-based models can directly be used as supersense taggers by a simple conversion of senses , we compared the performance of the synset-based model with that of the supersense-based model .
Since synset-based models can directly be used as supersense taggers by a simple conversion of senses , we compared the performance of the synset-based model with that of the supersense-based model .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0

Alignment 413
Interestingly , when evaluated at the supersense level , the synset-based models considerably outperformed the supersense-based models , with the overall improvements of 0 .69% with the sense frequency information and 1 .41% without it , as shown in Table fcomp-ws-ss-tree .
Interestingly , when evaluated at the supersense level , the synset-based models considerably outperformed the supersense-based models , with an overall improvements of 0 .69% with the sense frequency information and 1 .41% without it , as shown in Table fcomp-ws-ss-tree .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0

Alignment 414
These results suggest that even though the granularity of the supersenses is sufficient for many NLP tasks , they are too coarse-grained to capture enough information for WSD models ; Therefore , even for the supersense-based disambiguation , we can improve the performance by considering finer-grained senses .
Thus , even though the granularity of the supersenses is sufficient for many NLP tasks , they are too coarse-grained to capture enough information for WSD models ; therefore , for the supersense-based disambiguation , we can improve the performance by considering finer-grained senses .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			31:1			0		1.0
2:1			4:1			0		1.0
3:1			5:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0
24:1			26:1			0		1.0
25:1			27:1			0		1.0
26:1			28:1			0		1.0
27:1			29:1			0		1.0
29:1			37:1			0		1.0
30:1			33:1			0		1.0
31:1			34:1			0		1.0
32:1			35:1			0		1.0
33:1			36:1			0		1.0
35:1			38:1			0		1.0
36:1			39:1			0		1.0
37:1			40:1			0		1.0
38:1			41:1			0		1.0
39:1			42:1			0		1.0
40:1			43:1			0		1.0
41:1			44:1			0		1.0
42:1			45:1			0		1.0
43:1			46:1			0		1.0
44:1			47:1			0		1.0

Alignment 415
Table 12 shows the comparison of our model with the state-of-the-art WSD systems .
Table 12 shows the comparison of our model with the state-of-the-art WSD systems .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 416
The evaluation here is performed with the Senseval official scorer .
The evaluation here is performed with the Senseval official scorer .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 417
Our model Tree-WS-SR outperformed the two best systems in the Senseval-3 ( Gambl and SenseLearner ) , but lagged behind PNNL by 1 .6% .
Our model Tree-WS-SR outperformed the two best systems in the Senseval-3 ( Gambl and SenseLearner ) , but lagged behind PNNL by 1 .6% .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 418
However , considering that all systems in Table 12 except for Simil-Prime utilize other sense-annotated corpora in addition to SemCor , such as the Senseval data sets or example sentences in the WordNet , and our model cannot handle multi-word expressions that do not exist in the WordNet as noted in Section 5 .1 , we can conclude that the performance of our T-CRF model is comparable to that of state-of-the-art WSD systems .
However , taking into consideration that all systems in Table 12 except for Simil-Prime utilize other sense-annotated corpora in addition to SemCor , such as the Senseval data sets or example sentences in the WordNet , and that our model cannot handle multi-word expressions that do not exist in the WordNet as noted in Section 5 .1 , we can conclude that the performance of our T-CRF model is comparable to that of state-of-the-art WSD systems . **[This is a long sentence- shorten .]
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:3			2:1			3		1.0
5:1			3:1			0		1.0
6:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
33:1			31:1			0		1.0
34:1			32:1			0		1.0
35:1			33:1			0		1.0
36:1			34:1			0		1.0
37:1			68:1			0		1.0
38:1			35:1			0		1.0
39:1			36:1			0		1.0
40:1			37:1			0		1.0
41:1			38:1			0		1.0
42:1			39:1			0		1.0
43:1			40:1			0		1.0
44:1			41:1			0		1.0
45:1			42:1			0		1.0
46:1			43:1			0		1.0
47:1			44:1			0		1.0
48:1			45:1			0		1.0
49:1			46:1			0		1.0
50:1			47:1			0		1.0
51:1			48:1			0		1.0
52:1			49:1			0		1.0
53:1			50:1			0		1.0
54:1			51:1			0		1.0
55:1			52:1			0		1.0
56:1			53:1			0		1.0
57:1			54:1			0		1.0
58:1			55:1			0		1.0
59:1			56:1			0		1.0
60:1			57:1			0		1.0
61:1			58:1			0		1.0
62:1			59:1			0		1.0
63:1			60:1			0		1.0
64:1			61:1			0		1.0
65:1			62:1			0		1.0
66:1			63:1			0		1.0
67:1			64:1			0		1.0
68:1			65:1			0		1.0
69:1			66:1			0		1.0
70:1			67:1			0		1.0
72:1			69:1			0		1.0
73:1			70:1			0		1.0
74:1			71:1			0		1.0
75:1			72:1			0		1.0
76:1			73:1			0		1.0

Alignment 419
Table 13 shows the list of the 15 largest-weighted sense dependency features in the tree-structured , synset-based model ( Tree-WS ) .
Table 13 shows the list of the 15 largest-weighted sense dependency features in the tree-structured , synset-based model ( Tree-WS ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 420
The list includes features associated with verb-noun relations ( e.g. SS :verb .consumption-SS :noun .food ) and noun-noun relations ( e.g. SS :noun .communication-SS :noun .communication ) , which we will describe in detail with several examples .
The list includes features associated with verb-noun relations ( e.g. SS :verb .consumption-SS :noun .food ) and noun-noun relations ( e.g. SS :noun .communication-SS :noun .communication ) , which we will describe in detail with several examples .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0

Alignment 421
Hereinafter , / MATH denotes / MATH in Equation 3 , and / MATH denotes the exponential of / MATH .
Hereinafter , / MATH denotes / MATH in Equation 3 , and / MATH denotes the exponential of / MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 422
We call a feature either with a positive lambda or with an alpha larger than 1 as an excitatory feature , while that either with a negative lambda or an alpha smaller than 1 as an inhibitory feature .
We call a feature either with a positive lambda or with an alpha larger than 1 as an excitatory feature , and those features with either with a negative lambda or an alpha smaller than 1 as an inhibitory feature .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
24:1			24:1			0		1.0
25:1			23:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
33:1			31:1			0		1.0
34:1			32:1			0		1.0
35:1			33:1			0		1.0
36:1			34:1			0		1.0
37:1			35:1			0		1.0
38:1			36:1			0		1.0
39:1			37:1			0		1.0
40:1			38:1			0		1.0

Alignment 423
Also , Table 14 shows the 15 largest-weighted sense dependency features in the linear-chain , synset-based model .
Also , Table 14 shows the 15 largest-weighted sense dependency features in the linear-chain , synset-based model .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 424
When compared to the outputs of the tree-structured model , we can see that the linear-chain model captures more successive noun-noun dependencies , while the tree-structured model captures more adjective-noun and verb-object dependencies .
When compared to the outputs of the tree-structured model , we can see that the linear-chain model captures more successive noun-noun dependencies , while the tree-structured model captures more adjective-noun and verb-object dependencies .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0

Alignment 425
Thus , although the difference of the recalls is small , we can assume that the sense dependency features in the tree-structured model and those in the linear-chain model have different contributions to the results .
Thus , although the difference of the recalls is small , we can assume that the sense dependency features in the tree-structured model , and those in the linear-chain model have different contributions to the results .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0

Alignment 426
The simultaneous use of both is of an interest from practical and semantical perspectives ; However , since it makes our model no longer a tree , the implementation is not straightforward .
The simultaneous use of both is of an interest from practical and semantical perspectives ; however , since it makes our model no longer a tree , the implementation is not straightforward .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0

Alignment 427
Hence , this is left as one of our future works .
Hence , this is left as one of our future works .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 428
In this section , we present instance-based analyses based on the first 100 instances for which the answer of the dependency model Tree-WS-SR differs from that of the non-dependency model NoDep-WS-SR in the first trial on SemCor .
In this section , we present an instance-based analyses based on the first 100 instances for which the answer of the dependency model Tree-WS-SR differs from that of the non-dependency model NoDep-WS-SR in the first trial on SemCor .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
37:1			36:1			0		1.0
38:1			37:1			0		1.0

Alignment 429
We extracted only the largest-weighted edge feature for each instance , assuming that this feature had the largest contribution to the result .
We extracted only the largest-weighted edge feature for each instance , assuming that this feature had the largest contribution to the result .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 430
These instances consist of 54 positive instances , for which Tree-WS-SR output the correct answer while NoDep-WS-SR did not , and 46 negative instances , for which Tree-WS-SR did not output the correct answer while NoDep-WS-SR did .
These instances consist of 54 positive instances , for which Tree-WS-SR output the correct answer while NoDep-WS-SR did not , and 46 negative instances , for which Tree-WS-SR did not output the correct answer while NoDep-WS-SR did .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0

Alignment 431
Table 15 and 16 shows the count of each edge type for these instances .
Table 15 and 16 show the count of each edge type for these instances .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			1		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 432
For both positive and negative instances , the verb-noun dependencies are the dominant dependencies , corresponding to 48% of all the instances .
For both positive and negative instances , the verb-noun dependencies are the dominant dependencies , corresponding to 48% of all the instances .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 433
One noteworthy point is that more number of noun-noun dependencies are found in the positive instances than in the negative instances , which might suggest that noun-noun dependencies are particularly likely to capture useful dependencies and contribute to positive instances .
One noteworthy point is that more number of noun-noun dependencies are found in the positive instances than in the negative instances , further suggesting that noun-noun dependencies are particularly likely to capture useful dependencies and contribute to positive instances .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
23:1			24:1			1		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0
31:1			32:1			0		1.0
32:1			33:1			0		1.0
33:1			34:1			0		1.0
34:1			35:1			0		1.0
35:1			36:1			0		1.0
36:1			37:1			0		1.0
37:1			38:1			0		1.0
38:1			39:1			0		1.0
39:1			40:1			0		1.0

Alignment 434
First of all , let us present two instances in which the verb-noun dependencies worked effectively .
First of all , let us present two instances in which the verb-noun dependencies worked effectively .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 435
The first sentence is
The first sentence is :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0

Alignment 436
From this earth , then , while it was still virgin God took dust and fashioned the man , the beginning of humanity .
From this earth , then , while it was still virgin God took dust and fashioned the man , the beginning of humanity .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 437
The verb take has surprisingly as many as 42 senses in the WordNet .
Surprisingly , the verb take has as many as 42 senses in the WordNet .
Line2Start:Length	Line1Start:Length	Module		Score
3:1			1:1			0		1.0
4:1			2:1			0		1.0
5:1			3:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0

Alignment 438
But , fortunatelly , the first six senses belong to different supersenses , and our dependency model succeeded in outputting the correct sense take#4 ( SS :verb .contact , take physically ) by making use of the strong dependency SS :verb .contact-SS :noun .substance ( / MATH ) , given dust#1 belongs to noun .substance .
But fortunately , the first six senses belong to different supersenses , and our dependency model succeeded in outputting the correct sense take#4 ( SS :verb .contact , take physically ) by making use of the strong dependency SS :verb .contact-SS :noun .substance ( / MATH ) , given dust#1 belongs to noun .substance .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0
31:1			32:1			0		1.0
32:1			33:1			0		1.0
33:1			34:1			0		1.0
34:1			35:1			0		1.0
35:1			36:1			0		1.0
36:1			37:1			0		1.0
37:1			38:1			0		1.0
38:1			39:1			0		1.0
39:1			40:1			0		1.0
40:1			41:1			0		1.0
41:1			42:1			0		1.0
42:1			43:1			0		1.0
43:1			44:1			0		1.0
44:1			45:1			0		1.0
45:1			46:1			0		1.0
46:1			47:1			0		1.0
47:1			48:1			0		1.0
48:1			49:1			0		1.0
49:1			50:1			0		1.0
50:1			51:1			0		1.0
51:1			52:1			0		1.0
52:1			53:1			0		1.0
53:1			54:1			0		1.0
54:1			55:1			0		1.0

Alignment 439
The second instance is also a positive instance from the SEM-A data set .
The second instance is also a positive instance from the SEM-A data set .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 440
For a serious young man who plays golf with a serious intensity , Palmer has such an inherent sense of humor that it relieves the strain and keeps his nerves from jangling like banjo strings .
For a serious young man who plays golf with a serious intensity , Palmer has such an inherent sense of humor that it relieves the strain and keeps his nerves from jangling like banjo strings .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0

Alignment 441
Here , has is an ambiguous verb that has 19 senses in the WordNet .
Here , has is an ambiguous verb that has 19 senses in the WordNet .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 442
The correct sense here is have( v )#2 ( SS :verb .stative , have as a feature ) .
The correct sense here is have( v )#2 ( SS :verb .stative , have as a feature ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 443
Given sense of humor#1 belongs to the supersense noun .attribute , the correct sense was output by the strong verb-object dependency G1 :have( v )#2-( OBJ )-SS :noun .attribute ( / MATH ) .
Given sense of humor#1 belongs to the supersense noun .attribute , the correct sense was output by the strong verb-object dependency G1 :have( v )#2-( OBJ )-SS :noun .attribute ( / MATH ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0

Alignment 444
While this verb-object dependency had a large excitatory weight , the corresponding verb-subject dependency had an inhibitory weight ( G1 :have( v )#2-( SBJ )-SS :noun .attribute ( / MATH ) ) , which means the dependency relationlabel also contributed to the result .
While this verb-object dependency had a large excitatory weight , the corresponding verb-subject dependency had an inhibitory weight ( G1 :have( v )#2-( SBJ )-SS :noun .attribute ( / MATH ) ) , which indicates that the dependency relationlabel also contributed to the result .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
36:1			35:1			0		1.0
37:1			36:1			0		1.0
38:1			37:1			0		1.0
39:1			38:1			0		1.0
40:1			39:1			0		1.0
41:1			40:1			0		1.0
42:1			41:1			0		1.0
43:1			42:1			0		1.0
44:1			43:1			0		1.0

Alignment 445
Note also that this long dependency cannot be described by linear-chain models .
Note also that this long dependency cannot be described by linear-chain models .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 446
Next , let us show a typical negative example , where a verb-subject dependency worked inappropriately .
Next , let us show a typical negative example , where a verb-subject dependency worked inappropriately .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 447
The repeated efforts in Christian history to describe death as altogether the consequence of human sin show that these two aspects of death cannot be separated .
The repeated efforts in Christian history to describe death as altogether the consequence of human sin show that these two aspects of death cannot be separated .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 448
The correct sense for show here is show#2 ( verb .cognition , establish the validity ) , but the model output show#3 ( verb .communication , prove evidence for ) affected by the long dependency WS :testify( v )#2-( SBJ )-SS :noun .act ( / MATH ) between efforts and show .
The correct sense for show here is show#2 ( verb .cognition , establish the validity ) , but the model output show#3 ( verb .communication , prove evidence for ) affected by the long dependency WS :testify( v )#2-( SBJ )-SS :noun .act ( / MATH ) between efforts and show .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0
49:1			49:1			0		1.0
50:1			50:1			0		1.0
51:1			51:1			0		1.0

Alignment 449
This subject information seems to be not adequate for the disambiguation of show .
This subject information seems to be inadequate for the disambiguation of show .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:2			3		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0

Alignment 450
Next we focus on the noun-noun dependencies .
Next we focus on the noun-noun dependencies .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 451
The first example is a negative instance .
The first example is a negative instance .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 452
Philadelphia permitted him to seek a better connection after he had refused to reconsider his decision to end his career as a player .
Philadelphia permitted him to seek a better connection after he had refused to reconsider his decision to end his career as a player .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 453
The noun career has two meanings : the particular occupation for which you are trained ( career#1 ) and the general progression of your working or professional life ( career#2 ) .
The noun career has two meanings : the particular occupation for which you are trained ( career#1 ) and the general progression of your working or professional life ( career#2 ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0

Alignment 454
From the phrase career as a player , we can assume that the correct sense of career can be either of two senses , and possibly there is a preference for career#2 , as captured by the largest-weighted dependency WS :career%1%2-( NMOD )-SS :noun .person ( / MATH ) between career and player .
From the phrase career as a player , we can assume that the correct sense of career can be either of two senses , with the possibility that there is a preference for career#2 , as captured by the largest-weighted dependency WS :career%1%2-( NMOD )-SS :noun .person ( / MATH ) between career and player .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:3			25:1			3		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
33:1			31:1			0		1.0
34:1			32:1			0		1.0
35:1			33:1			0		1.0
36:1			34:1			0		1.0
37:1			35:1			0		1.0
38:1			36:1			0		1.0
39:1			37:1			0		1.0
40:1			38:1			0		1.0
41:1			39:1			0		1.0
42:1			40:1			0		1.0
43:1			41:1			0		1.0
44:1			42:1			0		1.0
45:1			43:1			0		1.0
46:1			44:1			0		1.0
47:1			45:1			0		1.0
48:1			46:1			0		1.0
49:1			47:1			0		1.0
50:1			48:1			0		1.0
51:1			49:1			0		1.0
52:1			50:1			0		1.0
53:1			51:1			0		1.0
54:1			52:1			0		1.0
55:1			53:1			0		1.0

Alignment 455
Although there was originally the preference for the correct sense career#1 by the sense frequency features , the noun-noun dependency thus contributed to the wrong answer career#2 .
Although there was originally the preference for the correct sense career#1 by the sense frequency features , the noun-noun dependency thus contributed to the wrong answer career#2 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0

Alignment 456
The determining clue for this instance seems to be the verb-object dependency end-career , which was not captured by our model .
The determining clue for this instance seems to be the verb-object dependency end-career , which was not captured by our model .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 457
Among the ten positive instances of the noun-noun dependencies , four instances were contributed by the noun-of-noun dependencies .
Among the ten positive instances of the noun-noun dependencies , four instances were contributed by the noun-of-noun dependencies .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 458
Since dependencies of this type were not observed in the negative instances at all , they seem to particularly contribute to the positive instances .
Since dependencies of this type were not observed in the negative instances , they seem to particularly contribute to the positive instances .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0

Alignment 459
Let us consider the following example .
Let us consider the following example .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0

Alignment 460
The embarrassment of these theories over the naturalness of death is an illustration of the thesis that death cannot be only a punishment , for some termination seems necessary in a life that is lived within the natural order of time and change .
The embarrassment of these theories over the naturalness of death is an illustration of the thesis that death cannot be only a punishment , for some termination seems necessary in a life that is lived within the natural order of time and change .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0

Alignment 461
Although the correct sense time#5 ( noun .Tops , the continuum of experience in which events pass from the future through the present to the past ) is not a frequent sense , our model correctly output the correct sense by using the dependency SS :noun .object-of-WS :time%1%5 ( / MATH ) , given natural order#1 belongs to the supersense noun .object .
Although the correct sense time#5 ( noun .Tops , the continuum of experience in which events pass from the future through the present to the past ) is not a frequent sense , our model correctly output the correct sense by using the dependency SS :noun .object-of-WS :time%1%5 ( / MATH ) , given natural order#1 belongs to the supersense noun .object .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0
49:1			49:1			0		1.0
50:1			50:1			0		1.0
51:1			51:1			0		1.0
52:1			52:1			0		1.0
53:1			53:1			0		1.0
54:1			54:1			0		1.0
55:1			55:1			0		1.0
56:1			56:1			0		1.0
57:1			57:1			0		1.0
58:1			58:1			0		1.0
59:1			59:1			0		1.0
60:1			60:1			0		1.0
61:1			61:1			0		1.0
62:1			62:1			0		1.0

Alignment 462
Another interesting result observed is that the noun-noun dependencies in coordination relations work remarkably strongly .
Through our result , we observed that the noun-noun dependencies in coordination relations work remarkably well .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			2:1			0		1.0
5:1			3:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
16:1			15:1			0		1.0

Alignment 463
In the following sentence , three words nails , levels , and T squares are in a coordination relation .
In the following sentence , three words nails , levels , and T squares are in a coordination relation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 464
He also bought a huge square of pegboard for hanging up his tools , and lumber for his workbench , sandpaper and glue and assorted nails , levels and T squares and plumb lines and several gadgets that he had no idea how touse or what they were for .
He also bought a huge square of pegboard for hanging up his tools , and lumber for his workbench , sandpaper and glue and assorted nails , levels and T squares and plumb lines and several gadgets that he had no idea how touse or what they were for .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0
49:1			49:1			0		1.0

Alignment 465
Here , the correct sense for nail is nail#2 ( noun .artifact , a thin pointed piece of metal ) and that for level is level#5 ( noun .artifact , indicator of the horizontal ) .
Here , the correct sense for nail is nail#2 ( noun .artifact , a thin pointed piece of metal ) , and that for level is level#5 ( noun .artifact , indicator of the horizontal ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			29:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0

Alignment 466
The relatively low frequency of these senses prevent our model from outputting the correct senses in an ordinal way .
The relatively low frequency of these senses prevent our model from outputting the correct senses in an ordinal way .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 467
However , the dependency model could capture the fact that two words in a coordination relation are quite likely to belong to the same semantic group ( SS :noun .artifact-( COORD )-SS :noun .artifact ( / MATH ) ) , and hence succeeded in the correct disambiguation of these three words .
However , the dependency model could capture the fact that two words in a coordination relation are quite likely to belong to the same semantic group ( SS :noun .artifact-( COORD )-SS :noun .artifact ( / MATH ) ) , and hence succeeded in the correct disambiguation of these three words .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0
49:1			49:1			0		1.0
50:1			50:1			0		1.0
51:1			51:1			0		1.0

Alignment 468
More generally , we have observed that the coordination features for an edge that connects the same supersense all have positive weights .
More generally , we have observed that the coordination features for an edge that connects the same supersense all have positive weights .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 469
In this paper , we proposed a novel approach to the all-words WSD , focusing on the use of syntactic dependencies of word senses , and investigated the contribution of these dependencies to WSD .
In this paper , we proposed a novel approach for the all-words WSD , focusing on the use of syntactic dependencies of word senses , and investigated the contribution of these dependencies to WSD .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0

Alignment 470
Our proposals were twofold : to apply tree-structured CRFs to the dependency trees , and to use the combined bigrams of fine- and coarse-grained senses as edge features .
Our proposals were twofold : to apply tree-structured CRFs to the dependency trees , and to use the combined bigrams of fine- and coarse-grained senses as edge features .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 471
In our experiments , the sense dependency features were shown to work effectively for WSD , with 0 .29% , 0 .64% , and 0 .30% improvements of recalls for SemCor , Senseval-2 , and Senseval-3 data sets respectively .
In our experiments , the sense dependency features were shown to work effectively for WSD , with a 0 .29% , 0 .64% , and 0 .30% improvement of recalls for SemCor , Senseval-2 , and Senseval-3 data sets , respectively .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			1		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
37:1			36:1			0		1.0
38:1			37:1			0		1.0
40:1			38:1			0		1.0
41:1			39:1			0		1.0

Alignment 472
Despite the small improvements in terms of overall figures , these improvements indeed correspond to 25%-57% improvements over the first sense baseline .
Despite the small improvements in overall figures , these improvements indeed correspond to 25%-57% improvements over the first sense baseline .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0

Alignment 473
The dependency tree structures was shown to be appropriate for modeling the dependencies of word senses , by the results that the tree-structured models outperformed the linear-chain models .
The dependency tree structures were shown to be appropriate in modeling the dependencies of word senses , because the results of the tree-structured models outperformed the [results of ?] linear-chain models .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			2		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
29:1			26:1			0		1.0
30:1			27:1			0		1.0
31:1			28:1			0		1.0

Alignment 474
In the analysis section , we presented an in-depth analysis of the observed instances , and saw that the noun-noun dependencies particularly contribute to the positive instances .
In the analysis section , we presented an in-depth analysis of the observed instances , and observed that the noun-noun dependencies particularly contribute to the positive instances .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0

Alignment 475
Also , the combination of coarse-grained tag sets with the sense dependency features were proved to be effective .
In addition , the combination of coarse-grained tag sets with the sense dependency features were proved to be effective .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0

Alignment 476
However , our experiments on the other hand showed that even when combined with the coarse-grained tag sets , the sense dependency features do not improve the performance unless combined with proper sense frequency information , due to the data sparseness problem .
However , our experiments showed that even when combined with the coarse-grained tag sets , the sense dependency features do not improve the performance , unless combined with proper sense frequency information . This is due to the data sparseness problem .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			8:1			0		1.0
5:1			9:1			0		1.0
6:1			10:1			0		1.0
7:1			11:1			0		1.0
8:1			12:1			0		1.0
9:1			13:1			0		1.0
10:1			14:1			0		1.0
11:1			15:1			0		1.0
12:1			16:1			0		1.0
13:1			17:1			0		1.0
14:1			18:1			0		1.0
15:1			19:1			0		1.0
16:1			20:1			0		1.0
17:1			21:1			0		1.0
18:1			22:1			0		1.0
19:1			23:1			0		1.0
20:1			24:1			0		1.0
21:1			25:1			0		1.0
22:1			26:1			0		1.0
23:1			27:1			0		1.0
24:1			35:1			0		1.0
25:1			28:1			0		1.0
26:1			29:1			0		1.0
27:1			30:1			0		1.0
28:1			31:1			0		1.0
29:1			32:1			0		1.0
30:1			33:1			0		1.0
31:1			34:1			0		1.0
32:1			42:1			0		1.0
35:1			36:1			0		1.0
36:1			37:1			0		1.0
37:1			38:1			0		1.0
38:1			39:1			0		1.0
39:1			40:1			0		1.0
40:1			41:1			0		1.0

Alignment 477
The supersense-based WSD models , on the contrary , exhibited the robustness regardless of the existence of the sense frequency information , while they are defeated by the synset-based models in recalls .
The supersense-based WSD models , on the contrary , exhibited the robustness [of ...] regardless of the existence of the sense frequency information , while they are defeated by the synset-based models in recalls .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
33:1			31:1			0		1.0
34:1			32:1			0		1.0

Alignment 478
These results show the importance of fine-grained and coarse-grained sense information , and that the combination of both enables us to build a precise and robust WSD system .
These results show the importance of fine-grained and coarse-grained sense information , and show that the combination of both enables us to build a more precise and robust WSD system .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0

Alignment 479
The performance of our tree-structured model was comparable to that of the state-of-the-art WSD systems .
The performance of our tree-structured model was comparable to that of the state-of-the-art WSD systems .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 480
Although our model was based on a simple framework and trained only on the SemCor corpus , the results we gained were promising , suggesting that our model still has a great potential for improvement .
Although our model was based on a simple framework , and was trained only on the SemCor corpus , the results that we gained were promising . They suggested that our model still has a great potential for improvement .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			23:1			0		1.0
10:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
22:1			19:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0
28:2			24:2			3		1.0
30:1			26:1			0		1.0
31:1			27:1			0		1.0
32:1			28:1			0		1.0
33:1			29:1			0		1.0
34:1			30:1			0		1.0
35:1			31:1			0		1.0
36:1			32:1			0		1.0
37:1			33:1			0		1.0
38:1			34:1			0		1.0
39:1			35:1			0		1.0

Alignment 481
Our next interest is to combine our framework with the recently-developed semi-supervised frameworks .
Our next interest is to combine our framework with the recently-developed semi-supervised frameworks .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 482
The combination of the local and syntactic dependencies with the global information is expected to further the WSD research .
The combination of the local and syntactic dependencies with the global information is expected to further the WSD research .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 483
Exploiting Motion Patterns for Action Recognition with Depth Sequences
Exploiting Motion Patterns for Action Recognition with Depth Sequences
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 484
Dense trajectory-based approaches on 2D video have been demontrated state of the art at action recognition since it can capture most discriminative motion patterns .
Dense trajectory-based approaches have been used to recognize actions in 2D video because they can capture most discriminative motion patterns .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			6:1			0		1.0
4:1			7:1			0		1.0
6:2			15:1			3		1.0
8:2			14:1			3		1.0
10:1			4:1			0		1.0
11:1			5:1			0		1.0
14:1			18:1			0		1.0
15:1			19:1			0		1.0
16:1			20:1			0		1.0
17:1			21:1			0		1.0
18:1			22:1			0		1.0
19:1			23:1			0		1.0
20:1			24:1			0		1.0

Alignment 485
However , there are not many studies related to exploiting the discriminative motion patterns in depth video .
However , there are not many studies related to exploiting discriminative motion patterns in depth video .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0

Alignment 486
In this work , we extend the dense trajectory-based approach on depth video and show its effectiveness for action recognition .
In this study , we extend the dense trajectory-based approach to depth video and show its effectiveness at recognizing actions .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			2		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
18:1			19:1			3		1.0
20:1			20:1			0		1.0

Alignment 487
To achieve an effective extension , we extract dense trajectories on 2D videos transformed from depth video .
In particular , dense trajectories are extracted from depth video .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			5:1			0		1.0
3:1			8:1			0		1.0
4:1			9:1			0		1.0
7:1			14:1			0		1.0
8:1			15:1			0		1.0
9:1			16:1			0		1.0
10:1			17:1			0		1.0

Alignment 488
The 2D videos are formed from views which can capture the discriminative motion patterns similar to observing actions from different directions .
These 2D videos are formed from views which capture the discriminative motion patterns similar to observing actions from different directions .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0

Alignment 489
We evaluate this approach on framework of action recognition using the benchmark MSR Action 3D , MSR Gesture 3D and 3D Action Pairs datasets .
We evaluate this approach to action recognition on the benchmark MSR Action 3D , MSR Gesture 3D and 3D Action Pairs datasets .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:2			6:2			3		1.0
6:1			8:1			0		1.0
7:1			4:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0

Alignment 490
Evaluation results show that our proposed approach is effective for action recognition on depth video and outperforms the state-of-the-art approaches .
The results of the evaluation indicate that our approach is effective at recognizing actions in depth video and outperforms other state-of-the-art approaches .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
3:1			17:1			0		1.0
5:1			2:1			2		1.0
6:1			3:1			0		1.0
7:1			4:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
12:1			11:1			3		1.0
13:2			10:1			3		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0

Alignment 491
Action recognition in videos has been one of the active research fields in the computer vision </CITE> , due to its wide applications in areas like surveillance , video retrieval , human-computer interaction , and smart environments .
The recognition of actions depicted in videos is an active topic of research in the computer vision field </CITE> , and it has a diverse range of applications in areas like surveillance , video retrieval , human-computer interaction , and smart environments .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			7:1			0		1.0
5:1			2:1			0		1.0
6:1			3:1			0		1.0
7:1			4:2			3		1.0
8:2			8:2			3		1.0
12:1			10:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			34:1			0		1.0
27:1			22:1			0		1.0
28:1			23:1			0		1.0
29:1			24:1			0		1.0
30:1			25:1			0		1.0
31:1			26:1			0		1.0
32:1			27:1			0		1.0
33:1			28:1			0		1.0
34:1			29:1			0		1.0
35:1			30:1			0		1.0
36:1			31:1			0		1.0
37:1			32:1			0		1.0
38:1			33:1			0		1.0
40:1			35:1			0		1.0
41:1			36:1			0		1.0
42:1			37:1			0		1.0

Alignment 492
Due to the diversity and complexity of actions , as well as complicated environment ( e.g background clutter and illumination variation ) , action recognition is still a challenging problem .
As a result of the diversity and complexity of actions , as well as the complicated nature of most environments ( e.g. , background clutter and illumination variation ) , action recognition is still a challenging problem .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			27:1			0		1.0
4:1			2:1			0		1.0
5:1			3:1			0		1.0
6:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
15:1			12:1			0		1.0
19:1			13:1			1		1.0
20:1			14:1			0		1.0
22:1			22:1			0		1.0
23:1			16:1			0		1.0
24:1			17:1			0		1.0
25:1			18:1			0		1.0
26:1			19:1			0		1.0
27:1			20:1			0		1.0
28:1			21:1			0		1.0
30:1			23:1			0		1.0
31:1			24:1			0		1.0
32:1			25:1			0		1.0
33:1			26:1			0		1.0
35:1			28:1			0		1.0
36:1			29:1			0		1.0
37:1			30:1			0		1.0

Alignment 493
Recent approaches can be divided into three major categories : silhouette-based </CITE> , salient point-based </CITE> and trajectory-based </CITE> .
Recent approaches can be divided into three major categories : silhouette-based </CITE> , salient point-based </CITE> and trajectory-based </CITE> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 494
All approaches basically try to capture motion information that appears in videos , since the motion is crucial information for presenting actions .
All of these approaches basically try to capture motion information appearing in videos , since it is crucial information for presenting actions .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
3:1			1:1			0		1.0
4:1			2:1			0		1.0
5:1			3:1			0		1.0
6:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			9:1			1		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 495
Based on recent works </CITE> , exploiting discriminative motion patterns has been demonstrated successful at action recognition .
Recent studies </CITE> have shown that exploiting discriminative motion patterns is a successful means of action recognition .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			3:1			2		1.0
2:1			4:1			0		1.0
3:2			12:1			3		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:2			3		1.0
12:1			13:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 496
Most existing studies mainly have investigate on video sequences captured by traditional 2D cameras .
Most of the existing studies deal with video sequences captured by traditional 2D cameras .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
3:1			1:1			0		1.0
4:1			2:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 497
Although , there are many improvements on motion pattern-based approach for action recognition in the domain of 2D video </CITE> , the mentioned challenges ( e.g. background clutter , illumination variation ) are still difficult to handle .
Although , there have been many improvements to the motion pattern-based approach for 2D video </CITE> , the above - mentioned challenges ( e.g. background clutter and illumination variation ) are still difficult to meet .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:2			3:1			3		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			35:1			0		1.0
8:1			14:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			17:1			0		1.0
14:1			18:1			0		1.0
15:1			19:1			0		1.0
16:1			20:1			0		1.0
17:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0
24:1			26:1			0		1.0
25:1			27:1			0		1.0
27:1			29:1			0		1.0
28:1			30:1			0		1.0
29:1			31:1			0		1.0
30:1			32:1			0		1.0
31:1			33:1			0		1.0
32:1			34:1			0		1.0
35:1			37:1			0		1.0

Alignment 498
With the development of new RGB-D cameras , e.g. Kinect camera , capturing RGB images as well as together with depth maps has become more easily in real time .
Meanwhile , the advent of RGB-D cameras , e.g. , the Kinect camera , has made it easier to capture depth maps together with RGB images in real time .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			3		1.0
4:1			3:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			22:1			0		1.0
16:2			24:2			3		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			18:1			0		1.0
23:1			19:1			0		1.0
24:1			13:1			0		1.0
25:1			14:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0

Alignment 499
The depth maps can enrich information for cues , such as body shape and motion information .
The depth maps enrich the information available as cues , such as the shape of body and its motions .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			4:1			0		1.0
5:1			5:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
13:1			12:1			0		1.0
15:1			11:1			0		1.0
16:1			13:1			0		1.0
19:1			16:1			0		1.0

Alignment 500
In addition , depth information is less sensitive to the challenges RGB information usually deals with .
In addition , the depth information in these maps is less sensitive to the problems affecting RGB information .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			9:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
9:1			5:1			0		1.0
10:1			6:1			0		1.0
11:1			7:1			0		1.0
12:1			8:1			0		1.0
13:2			10:1			3		1.0
16:1			11:1			0		1.0
17:1			12:1			0		1.0
18:1			16:1			0		1.0

Alignment 501
Due to these advantages , recent research trend concentrates on exploiting depth maps for action recognition </CITE> .
Because of these advantages , recent research has concentrated on exploiting depth maps for action recognition </CITE> .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			8:1			1		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 502
However , to the best of our knowledge , none success is related to combining discriminative motion pattern-based approach , the state-of-the-art on 2D video , on in depth video .
However , to the best of our knowledge , none have succeeded in developing a discriminative motion pattern-based approach , the state-of-the-art for 2D video , for depth video .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			10:1			3		1.0
12:1			27:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0

Alignment 503
In this paper , we investigate this approach with on depth sequences .
In this paper , we investigate this approach for depth sequences .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0

Alignment 504
Key idea of motion pattern-based approach is to capture discriminative trajectories in video .
The key idea of the motion pattern-based approach is to capture discriminative trajectories in video .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
5:1			3:1			0		1.0
6:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0

Alignment 505
Therefore , in order to effectively exploit this approach on depth video , it is necessary to extract the trajectories from depth video .
Therefore , to effectively exploit this approach on depth video , it is necessary to extract trajectories from depth video .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			4:1			0		1.0
3:1			5:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			19:1			0		1.0
17:1			20:1			0		1.0
18:1			21:1			0		1.0
19:1			22:1			0		1.0
20:1			23:1			0		1.0

Alignment 506
To do that , a straightforward method is to consider depth value as intensity value , extract trajectories on the 2D video , and apply standard motion analysis technique for 2D data .
To do that , a straightforward method is to consider the depth value as an intensity value , extract trajectories from the 2D video , and apply standard motion analysis techniques for 2D data .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			1		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
33:1			31:1			0		1.0
34:1			32:1			0		1.0

Alignment 507
Unfortunately , the method will lead to inherent limitation of the 2D trajectory-based approaches , and results in couple of confused motion patterns which cannot be distinguished by observing 2D videos from one view .
Unfortunately , this method will expose the inherent limitations of the 2D trajectory-based approaches and will result in confused motion patterns that cannot be distinguished by observing 2D videos from one view .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			2:1			0		1.0
7:1			7:1			0		1.0
8:2			8:2			3		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			15:1			0		1.0
15:2			5:1			3		1.0
17:1			17:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:2			23:2			3		1.0
23:1			25:1			0		1.0
24:1			26:1			0		1.0
25:1			27:1			0		1.0
26:1			28:1			0		1.0
27:1			29:1			0		1.0
28:1			30:1			0		1.0
29:1			31:1			0		1.0
30:1			32:1			0		1.0
31:1			33:1			0		1.0
32:1			34:1			0		1.0

Alignment 508
For example , forward punch and hammer may be confused actions , if we view them from front , since they contain indistinguishable front view movements respectively : ``lift arm up'' and ``stretch out'' .
For example , a forward punch and hammer may be confused if we view them from the front because they contain ``lift arm up'' and ``stretch out'' movements that are indistinguishable when viewed from the front .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
17:1			17:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			28:1			0		1.0
22:1			29:1			0		1.0
23:1			30:1			0		1.0
24:1			31:1			0		1.0
25:1			32:1			0		1.0
26:1			33:1			0		1.0
27:1			25:1			0		1.0
30:1			22:1			0		1.0
35:1			23:1			0		1.0
36:1			34:1			0		1.0

Alignment 509
However , if we properly use the depth information in motion pattern analysis , it is possible to extract discriminative motion patterns which is inaccessible from one fixed view but available from multiple different view directions .
However , if we properly use the depth information in the motion pattern analysis , it is possible to extract discriminative motion patterns which are inaccessible from one fixed view but discernible from different views .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			2		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
32:1			31:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			1		1.0
35:1			36:1			0		1.0

Alignment 510
To deal with such cases , we consider getting more information on such actions from various directions .
To deal with such cases , we try to get more information on such actions from various directions .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
9:1			8:1			1		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0

Alignment 511
Information achieved from the view directions can provide clearer cues to discriminate such actions .
Information from different views can provide clearer cues to discriminate such actions .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			2:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0

Alignment 512
To collect such information from depth video , we propose a method to virtually project depth maps to multiple view images , as shown in figure </fig> .
To collect such information from depth video , we propose a method that virtually projects depth maps onto multiple view images , as shown in Figure </fig> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			1		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0

Alignment 513
2D videos which are formed by the projections are easily obtained from depth data .
2D videos can be easily obtained from the projections .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			8:1			2		1.0
4:1			9:1			0		1.0
5:1			10:1			0		1.0
6:1			11:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			14:1			0		1.0

Alignment 514
Motion features are then calculated to generate corresponding projection representations .
Motion features are then calculated to generate corresponding projection representations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 515
Finally , depth video representation is formed by fusing the projection representations .
Finally , a depth video representation is formed by fusing the projection representations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0

Alignment 516
In our experiments , we adopt dense trajectory-based approach </CITE> to exploit discriminative motion patterns since that is the state-of-the-art approach for action recognition on domain of 2D videos .
In our experiments , we use a dense trajectory-based approach </CITE> that exploits discriminative motion patterns; this is the state-of-the-art approach for recognizing actions depicted in 2D videos .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			10:2			3		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			16:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			23:1			3		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0

Alignment 517
To evaluate the effectiveness of proposed method , we conduct experiments on MSR Action 3D dataset , MSR Gesture 3D dataset , and 3D Action Pairs dataset .
To evaluate the effectiveness of the proposed method , we conducted experiments on the MSR Action 3D dataset , MSR Gesture 3D dataset , and 3D Action Pairs dataset .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			1		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0

Alignment 518
Experimental results show that our proposed method is shown to outperform the state-of-the-art methods at action recognition using depth data .
The results show that our method outperforms other state-of-the-art methods at recognizing actions using depth data .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			6:1			0		1.0
8:1			12:1			0		1.0
9:1			13:1			0		1.0
10:1			14:1			0		1.0
11:1			16:1			3		1.0
13:1			17:1			0		1.0
14:1			18:1			0		1.0
15:1			19:1			0		1.0
16:1			20:1			0		1.0

Alignment 519
Our key contributions of this paper are as follows : (1) we propose an effective method to exploit trajectories in depth video , (2) we perform comprehensive experiments on the challenging benchmark dataset and indicate that our proposed method is the best compared with the state-of-the-art depth-based methods .
Our key contributions are as follows : (1) we propose an effective method to exploit trajectories in depth video , and (2) we perform comprehensive experiments on a challenging benchmark dataset and indicate that our method is the best of the state-of-the-art depth-based methods .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			6:1			0		1.0
4:1			7:1			0		1.0
5:1			8:1			0		1.0
6:1			9:1			0		1.0
7:1			10:1			0		1.0
8:1			11:1			0		1.0
9:1			12:1			0		1.0
10:1			13:1			0		1.0
11:1			14:1			0		1.0
12:1			15:1			0		1.0
13:1			16:1			0		1.0
14:1			17:1			0		1.0
15:1			18:1			0		1.0
16:1			19:1			0		1.0
17:1			20:1			0		1.0
18:1			21:1			0		1.0
19:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0
24:1			26:1			0		1.0
25:1			27:1			0		1.0
26:1			28:1			0		1.0
28:1			30:1			0		1.0
29:1			31:1			0		1.0
30:1			32:1			0		1.0
31:1			33:1			0		1.0
32:1			34:1			0		1.0
33:1			35:1			0		1.0
34:1			36:1			0		1.0
35:1			38:1			0		1.0
36:1			39:1			0		1.0
37:1			40:1			0		1.0
38:1			41:1			0		1.0
39:1			3:1			0		1.0
40:1			44:1			0		1.0
41:1			45:1			0		1.0
42:1			46:1			0		1.0
43:1			47:1			0		1.0
44:1			48:1			0		1.0

Alignment 520
After a brief review of the related work in Section , our action recognition framework is presented in Section .
After a brief review of the related work in Section , our action recognition framework is presented in Section .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 521
The proposed method is described in Section .
The proposed method is described in Section .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 522
Section presents the experimental settings and results .
Section describes the experimental settings and results .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 523
In section </ref> we provide some concerned discussions .
We discuss the results in section .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			7:1			1		1.0
5:1			1:1			0		1.0
6:1			8:1			0		1.0

Alignment 524
The summaries of our work are given in Section .
A summary of our work is given in Section .
Line2Start:Length	Line1Start:Length	Module		Score
1:2			1:2			3		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			2		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 525
In terms of action recognition in 2D video , there are three popular approaches used in several action recognition systems , including silhouette-based , salient point-based and trajectory-based .
There are three popular approaches to action recognition in 2D video : silhouette-based , salient point-based and trajectory-based .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			10:1			0		1.0
2:1			11:1			0		1.0
3:1			12:1			0		1.0
4:1			13:1			0		1.0
5:2			2:2			3		1.0
7:1			4:1			0		1.0
8:1			5:1			0		1.0
9:1			6:1			0		1.0
10:1			7:1			0		1.0
12:1			22:1			0		1.0
13:1			23:1			0		1.0
14:1			24:1			0		1.0
15:1			25:1			0		1.0
16:1			26:1			0		1.0
17:1			27:1			0		1.0
18:1			28:1			0		1.0

Alignment 526
The silhouette-based approach , as described in </CITE> , is powerful since it encodes a great deal of information in a sequence of images .
The silhouette-based approach , as described in </CITE> , is powerful since it encodes a great deal of information in a sequence of images .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 527
However , it is sensitive to pose changes , noise , and occlusions .
However , it is sensitive to pose changes , noise , and occlusions .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 528
Besides , it depends on the accuracy of localization , background subtraction , or tracking for exactly extracting region of interest .
In addition , it depends on the accuracy of the localization , background subtraction , and tracking when extracting the region of interest .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
16:1			14:1			0		1.0
18:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0

Alignment 529
Another approach based on salient points , generates a compact video representation and accepts background clutter , occlusions and scale changes .
Another approach , based on salient points , generates a compact video representation and can deal with background clutter , occlusions , and scale changes .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0
22:1			18:1			0		1.0
23:1			19:1			0		1.0
24:1			20:1			0		1.0
25:1			21:1			0		1.0

Alignment 530
The effectiveness of this approach is also showed in several works </CITE> .
This approach has been shown to be effective in several studies </CITE> .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			4:1			0		1.0
2:2			5:1			3		1.0
5:3			1:1			3		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			2		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 531
However , in case of recognizing complicated motions , the salient point-based approach has to deal with several challenges ; due to the lack of a relationship among salient points .
However , in the case of recognizing complicated motions , the salient point-based approach has to deal with several challenges due to the lack of relationships among the salient points .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			22:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:2			3		1.0
26:1			27:1			0		1.0
27:2			28:2			3		1.0
30:1			30:1			0		1.0

Alignment 532
In recent studies </CITE> , the trajectory-based approach captures motion patterns in video .
Recent studies </CITE> have used the trajectory-based approach to capture motion patterns in video .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			2:1			0		1.0
2:1			3:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			8:1			1		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0

Alignment 533
Although the motion patterns provide even very complicated , structured motion , which are perceived easily by human subject , as shown by Johansson </CITE> .
Although motion patterns are very complicated , structured motion can be easily perceived by humans , as has been shown by Johansson </CITE> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			13:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
11:1			15:1			0		1.0
12:1			14:1			0		1.0
13:1			16:1			0		1.0
14:1			17:1			1		1.0
15:1			19:1			0		1.0
16:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0

Alignment 534
Most recent and effective methods exploiting depth information are categorized into two major directions .
The most recent methods of exploiting depth information can be categorized into two major types .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			8:1			2		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
15:1			14:1			0		1.0

Alignment 535
The first one is to adapt 2D techniques based methods for depth data .
The first one is to adapt 2D techniques to depth data .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0

Alignment 536
The second one is to propose 3D techniques for directly exploiting depth data .
The second one is to devise 3D techniques for directly exploiting depth data .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 537
For the first direction , X.Yang et al. </CITE> propose the Depth Motion Maps ( DMM ) which is alble to capture global activities in depth sequences .
Regarding the first direction , X.Yang et al. </CITE> propose Depth Motion Maps ( DMMs ) to capture global activities in depth sequences .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
15:1			16:1			0		1.0
16:1			20:1			0		1.0
17:1			21:1			0		1.0
18:1			22:1			0		1.0
19:1			23:1			0		1.0
20:1			24:1			0		1.0
21:1			25:1			0		1.0
22:1			26:1			0		1.0
23:1			27:1			0		1.0

Alignment 538
The DMM are generated by stacking motion energy of depth maps projected to three orthogonal Cartesian planes .
DMMs are generated by stacking the motion energy of depth maps projected on three orthogonal Cartesian planes .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:2			12:2			3		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 539
And the Histogram of Oriented Gradients ( HOG ) </CITE> are computed from the DMM to represent an action video .
A Histogram of Oriented Gradients ( HOG ) </CITE> is computed from the DMMs to represent an action video .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			2		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0

Alignment 540
The approach can accumulate more silhouette information from the projections .
The approach can accumulate more silhouette information from the projections .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 541
However , as silhouette extraction is not trivial due to objectuve challenges , such as occlusion , data quality , the effectiveness of the approach is significantly affected .
However , silhouette extraction is not a trivial task due to problems such as occlusion and poor data quality .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			28:1			0		1.0

Alignment 542
Another approach proposed by L Xia and J.K Aggarwal </CITE> presents a filtering method to extract spatio-temporal interest points from depth videos ( DSTIPs ) .
Another approach , proposed by L. Xia and J.K. Aggarwal </CITE> , is to use filtering to extract spatio-temporal interest points from depth videos ( DSTIPs ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
12:1			10:1			3		1.0
15:1			12:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0

Alignment 543
In this approach , they extend a work of Dollar et al. </CITE> to adapt for depth data .
It is an extension of the work of Dollar et al. </CITE> to depth data .
Line2Start:Length	Line1Start:Length	Module		Score
2:3			5:1			3		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			16:1			0		1.0
14:1			17:1			0		1.0
15:1			18:1			0		1.0

Alignment 544
Firstly , 2D and 1D filters ( e.g. Gaussian and Gabor filters ) are applied respectively on to the spatial dimensions and temporal dimension in depth video .
First , 2D and 1D filters ( e.g. Gaussian and Gabor filters ) are respectively applied to the spatial dimensions and temporal dimension of the depth video .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			1		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			15:1			0		1.0
15:1			14:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0

Alignment 545
A correction function then is used to suppress points as depth noises .
A correction function is used to suppress points that are depth noise .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			1		1.0
12:1			12:1			0		1.0

Alignment 546
Finally , points with the largest responses by this filtering method will be selected as the DSTIPs for each video .
The points with the largest responses resulting from this filtering are selected as the DSTIPs for each video .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			11:2			3		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0

Alignment 547
Besides , a depth cuboid similarity feature ( DCSF ) is proposed to describe a 3D cuboid around the DSTIPs with supporting size to be adaptable to the depth .
In addition , a depth cuboid similarity feature ( DCSF ) is used to describe a 3D cuboid around the DSTIPs with supporting size to be adaptable to the depth .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0

Alignment 548
This work has demonstrated the effectiveness of 2D techniques applied for depth data .
That study demonstrated the effectiveness of using 2D techniques on depth data .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			2		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			9:1			2		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0

Alignment 549
Nevertheless , the authors have not solved inherent limitations of the 2D techniques .
Nevertheless , the authors did not overcome the inherent limitations of the 2D techniques .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			3		1.0
5:1			5:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0

Alignment 550
Therefore , this approach has to deal with the challenges as mentioned in 2D video data .
That is , this approach still faces the challenges mentioned in the introduction .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			4:2			3		1.0
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
13:1			16:1			0		1.0

Alignment 551
For the second direction , </CITE> uses a bag of 3D points to characterize a set of salient postures .
Regarding the second direction , </CITE> uses a bag of 3D points to characterize a set of salient postures .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 552
The 3D points are extracted on the contours the planar projections of the 3D depth map .
The 3D points are extracted from the contours of planar projections of the 3D depth map .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 553
And then , about 1% 3D points are sampled to calculate feature .
About 1% of the 3D points are sampled to calculate a feature .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 554
Unlike </CITE> , works </CITE> use occupancy patterns to represent features in action videos .
Unlike </CITE> , the methods described in </CITE> use occupancy patterns to represent features in action videos .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
7:1			4:1			0		1.0
8:1			5:1			0		1.0
9:1			6:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0

Alignment 555
A.W. Vieira et al. </CITE> proposed a new feature descriptor , called Space-Time Occupancy Patterns ( STOP ) .
A.W. Vieira et al. </CITE> proposed a new feature descriptor , called Space-Time Occupancy Patterns ( STOP ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 556
This descriptor is formed by sparse cells divided by the sequence of depth maps in a 4D space-time grid .
This descriptor is formed from the sparse cells of a 4D space-time grid dividing up a sequence of depth maps .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			9:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
9:1			15:1			0		1.0
10:1			16:1			0		1.0
11:1			17:1			0		1.0
12:1			18:1			0		1.0
13:2			7:1			3		1.0
16:1			10:1			0		1.0
17:1			11:1			0		1.0
18:1			12:1			0		1.0
19:1			13:1			0		1.0
20:1			19:1			0		1.0

Alignment 557
The values of the sparse cells are determined by points inside to be on the silhouettes or moving parts of the body .
The points inside the sparse cells are typically on the silhouette or on the moving parts of an object .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			9:1			0		1.0
2:1			10:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			13:1			0		1.0
9:1			14:1			0		1.0
10:1			15:1			1		1.0
11:1			16:1			0		1.0
13:1			20:1			0		1.0
14:1			17:1			0		1.0
15:1			18:1			0		1.0
16:1			19:1			0		1.0
19:1			22:1			0		1.0

Alignment 558
J. Wang et al. </CITE> presented semi-local features , called Random Occupancy Pattern ( ROP ) features , from randomly sampled 4D sub-volumes with different sizes and different locations .
J. Wang et al. </CITE> created semi-local features , called Random Occupancy Pattern ( ROP ) features , from randomly sampled 4D sub-volumes of different sizes and at different locations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:2			23:2			3		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0

Alignment 559
The random sampling is performed under a weighted scheme to effectively explore the large dense sampling space .
The random sampling is performed according to a weighted scheme in order to effectively explore the large dense sampling space .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0

Alignment 560
Besides , authors also apply a sparse coding approach to robustly encode these features .
The authors also used sparse coding to robustly encode these features .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			2		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			9:1			0		1.0
7:1			10:1			0		1.0
8:1			11:1			0		1.0
9:1			12:1			0		1.0
10:1			13:1			0		1.0
11:1			14:1			0		1.0

Alignment 561
The work by J. Wang et al. </CITE> designed a feature , to describe the local ``depth appearance'' for each joint , named Local Occupancy Patterns ( LOP ) .
J. Wang et al. </CITE> designed features , named Local Occupancy Patterns ( LOPs ) , to describe the local ``depth appearance'' of each joint of the body .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			3:1			0		1.0
1:1			4:1			0		1.0
2:1			5:1			0		1.0
3:1			6:1			0		1.0
4:1			7:1			0		1.0
5:1			8:1			0		1.0
7:1			21:1			0		1.0
8:1			22:1			0		1.0
9:1			23:1			0		1.0
10:1			24:1			0		1.0
11:1			25:1			0		1.0
12:1			26:1			0		1.0
14:1			28:1			0		1.0
15:1			11:1			0		1.0
16:1			12:1			0		1.0
17:1			13:1			0		1.0
18:1			14:1			0		1.0
19:1			15:1			0		1.0
20:1			16:1			0		1.0
21:1			17:1			0		1.0
22:2			18:2			3		1.0
24:1			20:1			0		1.0
28:1			29:1			0		1.0

Alignment 562
The LOP features are computed based on 3D point cloud around a particular joint .
LOP features are computed on the basis of a 3D point cloud around a particular joint .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			1:1			0		1.0
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:4			5:2			3		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0

Alignment 563
Moreover , they concatenate the LOP features with skeleton information-based features and apply Short Fourier Transform to obtain the Fourier Temporal Pyramid features at each joint .
Moreover , they concatenate the LOP features with skeleton information-based features and apply a Short Fourier Transform to obtain Fourier Temporal Pyramid features at each joint .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 564
The Fourier features are utilized in a novel actionlet ensemble model to represent each action video .
The Fourier features are utilized in a novel actionlet ensemble model to represent each action in the video .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0

Alignment 565
Recently , Oreifej and Liu </CITE> presented a new descriptor for depth maps , named Histogram of Oriented 4D Surface Normals ( HON4D ) .
Recently , Oreifej and Liu </CITE> presented a new descriptor for depth maps , named Histogram of Oriented 4D Surface Normals ( HON4D ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 566
To construct the HON4D , firstly , the 4D normal vectors are computed from the depth sequence .
To construct the HON4D , 4D normal vectors are first computed from the depth sequence .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			8:1			0		1.0
6:1			9:1			0		1.0
7:1			10:1			0		1.0
8:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0

Alignment 567
At the next step , the 4D normal vectors is distributed into spatio-temporal cells .
Next , these 4D normal vectors are distributed into spatio-temporal cells .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			4:1			0		1.0
3:1			6:1			0		1.0
4:1			7:1			0		1.0
5:1			8:1			0		1.0
6:1			9:1			2		1.0
7:1			10:1			0		1.0
8:1			11:1			0		1.0
9:1			12:1			0		1.0
10:1			13:1			0		1.0
11:1			14:1			0		1.0

Alignment 568
To quantize the 4D normal vectors , the 4D space is quantized by using vertices of a regular polychoron .
To quantize the 4D normal vectors , the 4D space is quantized by using the vertices of a regular polychoron .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0

Alignment 569
The quantization , then , is refined by additional projectors to make the 4D normal vectors in each cell denser and more discriminative .
The quantization is refined by additional projectors to make the 4D normal vectors in each cell denser and more discriminative .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			5:1			0		1.0
3:1			6:1			0		1.0
4:1			7:1			0		1.0
5:1			8:1			0		1.0
6:1			9:1			0		1.0
7:1			10:1			0		1.0
8:1			11:1			0		1.0
9:1			12:1			0		1.0
10:1			13:1			0		1.0
11:1			14:1			0		1.0
12:1			15:1			0		1.0
13:1			16:1			0		1.0
14:1			17:1			0		1.0
15:1			18:1			0		1.0
16:1			19:1			0		1.0
17:1			20:1			0		1.0
18:1			21:1			0		1.0
19:1			22:1			0		1.0
20:1			23:1			0		1.0

Alignment 570
Afterwards , the HON4D features in cells are concatenated to represent a depth action video .
Afterwards , the HON4D features in the cells are concatenated to make depth video depicting actions .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
12:1			12:1			0		1.0
13:1			14:1			0		1.0
16:1			15:1			0		1.0

Alignment 571
In general , the works </CITE> have shown the effectiveness of the approaches to directly exploit 3D data for human action recognition .
A number of studies </CITE> have shown the effectiveness of approaches that directly exploit 3D data for human action recognition .
Line2Start:Length	Line1Start:Length	Module		Score
3:1			4:1			2		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			12:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0

Alignment 572
However , constraints existed in these approaches , such as human segmentation in </CITE> , or human location in </CITE> , have partially limited their applicability on practical applications .
However , constraints , such as segmentation of the human body in </CITE> , or the location of the body in </CITE> , have somewhat limited their applicability .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			7:1			0		1.0
4:1			8:1			0		1.0
5:1			9:1			0		1.0
6:1			11:1			0		1.0
9:1			10:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
16:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			29:1			0		1.0

Alignment 573
Inspired by results of Shotton et al. </CITE> and L. Xia et al. </CITE> , the works in </CITE> developed skeleton-based methods from sequence of depth maps .
Inspired by the results of Shotton et al. </CITE> and L. Xia et al. </CITE> , some studies </CITE> have developed skeleton-based methods from sequences of depth maps .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			15:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
17:1			16:1			2		1.0
18:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			1		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0

Alignment 574
</CITE> proposed an EigenJoints-based action recognition system using a Naive-Bayes-Nearest-Neighbor classifier .
</CITE> proposed an EigenJoints-based action recognition system using a Naive-Bayes-Nearest-Neighbor classifier .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 575
The system is able to capture the characteristics of posture , motion and offset information of frames .
The system is able to capture the characteristics of posture , motion and offset of the frames .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 576
In addition , non-quantization of descriptors and distance computation in this work are showed effective for action recognition .
In addition , non-quantization of descriptors and distance computations have proved to be effective for action recognition .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			1		1.0
9:3			12:1			3		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0

Alignment 577
In work of J. Luo et al. </CITE> to better represent the 3D joint features a new discriminative dictionary learning algorithm ( DL-GSGC ) was proposed that .
J. Luo et al. </CITE> proposed a new discriminative dictionary learning algorithm ( DL-GSGC ) to better represent 3D joint features .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			3:1			0		1.0
1:1			4:1			0		1.0
2:1			5:1			0		1.0
3:1			6:1			0		1.0
4:1			7:1			0		1.0
5:1			25:1			0		1.0
6:1			15:1			0		1.0
7:1			16:1			0		1.0
8:1			17:1			0		1.0
9:1			18:1			0		1.0
10:1			19:1			0		1.0
11:1			20:1			0		1.0
12:1			21:1			0		1.0
13:1			22:1			0		1.0
14:1			23:1			0		1.0
15:1			8:1			0		1.0
16:1			9:1			0		1.0
17:1			10:1			0		1.0
18:1			12:1			0		1.0
19:1			13:1			0		1.0
20:1			14:1			0		1.0
21:1			27:1			0		1.0

Alignment 578
incorporated both group sparsity and geometry constraints .
This algorithm incorporates both group sparsity and geometric constraints .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			0:1			1		1.0
3:1			1:1			0		1.0
4:1			2:1			0		1.0
5:1			3:1			0		1.0
6:1			4:1			0		1.0
7:1			5:1			3		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0

Alignment 579
Besides , to keep temporal information , a temporal pyramid matching method was used on each sequence of depth maps .
In addition , to keep temporal information , a temporal pyramid matching method can be used on each sequence of depth maps .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
14:1			12:1			2		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0

Alignment 580
Actually , most skeleton information-based approaches has achieved the state-of-the-art performance on benchmark datasets .
Most of the skeleton information-based approaches have state-of-the-art performance on benchmark datasets .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			8:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			2		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0

Alignment 581
However , due to depending on skeleton information , these approaches have to deal with limitations when skeleton information is not available or incorrect .
However , their dependence on skeleton information is a detriment when such information is not available or incorrect .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			4:1			1		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
10:1			16:1			0		1.0
12:1			18:1			0		1.0
13:1			19:1			0		1.0
14:1			20:1			0		1.0
15:1			21:1			0		1.0
16:1			22:1			0		1.0
17:1			23:1			0		1.0
18:1			24:1			0		1.0

Alignment 582
Different from the previous approaches , we use a dense trajectory-based approach for action recognition .
Different from the previous studies , we take a dense trajectory-based approach to action recognition .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:2			12:2			3		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 583
We do not require to segment human body , like </CITE> .
We do not require the human body to be segmented , unlike the methods in </CITE> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			4:1			0		1.0
10:1			8:1			0		1.0
15:1			10:1			0		1.0
16:1			11:1			0		1.0

Alignment 584
In addition skeleton extraction as in </CITE> is not required in our work .
Moreover , unlike the methods in </CITE> , no skeleton has to be extracted .
Line2Start:Length	Line1Start:Length	Module		Score
5:1			5:1			0		1.0
6:1			6:1			0		1.0
9:1			2:1			0		1.0
10:2			7:1			3		1.0
13:1			3:1			1		1.0
14:1			13:1			0		1.0

Alignment 585
We investigate the benefit of generating 2D transformed videos from depth data , as mentioned in </CITE> .
We investigate the benefit of generating 2D transformed videos from depth data , as mentioned in </CITE> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 586
Moreover , we leverage the effectiveness of trajectory feature to represent an action video .
Moreover , we leverage the trajectory feature to represent actions in video .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:2			12:1			3		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0

Alignment 587
To the best of our knowledge , no work has previously been proposed to adapt the dense trajectory-based approach to human action recognition in depth video .
To the best of our knowledge , no study has previously proposed to adapt the dense trajectory-based approach to human action recognition in depth video .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			2		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0

Alignment 588
We conduct evaluations on recognition accuracy in depth video using dense trajectories proposed by H. Wang et al. </CITE> .
We evaluated the recognition accuracy of our method on depth video using the dense trajectories proposed by H. Wang et al. </CITE> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			2:1			1		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
8:1			3:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			0		1.0

Alignment 589
In this section , we present a unified action recognition framework on depth data.
Here , we present a unified action recognition framework for depth data.
Line2Start:Length	Line1Start:Length	Module		Score
1:1			3:1			0		1.0
2:1			4:1			0		1.0
3:1			5:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:2			10:2			3		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0

Alignment 590
We extract discriminative motion patterns from multiple views and then apply a bag-of-words ( BoW ) model to compute feature vectors for the feature fusion scheme .
We extract discriminative motion patterns from multiple views and apply a bag-of-words ( BoW ) model to them to compute feature vectors for the feature fusion scheme .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0

Alignment 591
The motivation of using a bag-of-words model to action recognition is to handle a variable number of motion patterns produced by arbitrary movements from various subjects .
The motivation behind using the bag-of-words model is that it can handle a variable number of motion patterns produced by arbitrary movements from various subjects .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			3:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			10:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0

Alignment 592
The fused feature vectors computed from a bag-of-words model are input of classifiers in training and testing phases .
The fused feature vectors computed from the bag-of-words model are then input to the classifiers in the training and testing phases .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			10:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0

Alignment 593
Following subsections provide concise descriptions about processes in our framework .
The following steps are concise descriptions of the processes in our framework .
Line2Start:Length	Line1Start:Length	Module		Score
4:1			3:1			0		1.0
5:1			4:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0

Alignment 594
Projection : In this step , key problem is to find appropriate action representation to effectively captures discriminative motion patterns .
Projection : In this step , the problem is to find an action representation that effectively captures discriminative motion patterns .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 595
Currently , capturing the motion patterns has not been achieved specific successes on 3D data in comparison with 2D data .
Currently , capturing motion patterns in 3D data has had less success than in 2D data .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			15:1			0		1.0
6:1			13:1			0		1.0
7:1			14:1			0		1.0
8:1			6:1			0		1.0
12:1			16:2			3		1.0
14:1			18:1			0		1.0
15:1			19:1			0		1.0
16:1			20:1			0		1.0

Alignment 596
Therefore , at this step , we try to present each 3D action through a combination of 2D actions .
Therefore , in this step , we try to represent each 3D action as a combination of 2D actions .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			2		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 597
To do that , M depth maps are projected onto N view planes to obtain corresponding 2D action videos .
To do that , M depth maps are projected onto N view planes to obtain corresponding 2D action videos .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 598
After the projection , each 2D motion video is abstracted by several local motion patterns .
After the projection , each 2D motion video is abstracted by using several local motion patterns .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0

Alignment 599
Feature Extraction : In order to capture discriminative motion patterns on the 2D videos , we adopt the trajectory based approach .
Feature Extraction : Here , we use a trajectory-based approach to capture discriminative motion patterns in the 2D videos .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			14:1			0		1.0
5:1			15:1			0		1.0
9:1			20:1			0		1.0
10:1			5:1			0		1.0
11:1			6:1			0		1.0
12:1			7:1			0		1.0
13:1			8:1			0		1.0
14:1			9:1			0		1.0
16:1			11:1			0		1.0
17:1			12:1			0		1.0
18:1			13:1			0		1.0
19:1			21:1			0		1.0

Alignment 600
With this approach , we can keep away from the challenges from human body segmentation as well as skeleton extraction .
With this approach , we can avoid problems related to segmentation of the human body as well as skeleton extraction .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			10:2			3		1.0
10:1			14:1			0		1.0
12:1			9:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 601
Trajectory-aligned descriptors are then calculated on the extracted trajectories to build N ``bags of motion patterns'' corresponding to N views .
Trajectory-aligned descriptors are then calculated on the extracted trajectories in order to build N ``bags of motion patterns'' corresponding to N views .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0

Alignment 602
Clustering : The clustering step is to convert a ``bag of motion patterns'' from dataset to a ``bag of quantized motion patterns'' .
Clustering : The clustering step converts the ``bag of motion patterns'' from the dataset into a ``bag of quantized motion patterns'' .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
13:1			14:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0

Alignment 603
A quantized motion pattern can be considered as a representative of several similar motion patterns .
A quantized motion pattern can be considered to be representative of several similar motion patterns .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:3			6:2			3		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 604
A standard clustering method ( e.g. k-means ) can be applied over all the motion patterns .
A standard clustering method ( e.g. k-means ) can be applied to all the motion patterns .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 605
Quantized motion patterns are then defined as the centers of the learned clusters .
Quantized motion patterns are then defined as the centers of the learned clusters .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 606
The number of the clusters is the size of ``bag of quantized motion patterns'' .
The number of clusters is the size of the ``bag of quantized motion patterns'' .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			3:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 607
Quantization and Fusion : To represent an action with captured motion patterns , we map each “ motion pattern “ to a certain `` quantized motion pattern '' through the matching process .
Quantization and Fusion : To represent an action with captured motion patterns , we map each “ motion pattern “ to a certain `` quantized motion pattern '' through the matching process .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0

Alignment 608
Afterwards , the histogram of the quantized motion patterns is generated to represent action on a corresponding view .
Afterwards , a histogram of the quantized motion patterns is generated to represent the action in the corresponding view .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			15:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			2:1			0		1.0
14:1			13:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0

Alignment 609
After that , the histograms generated from all views are concatenated to form a larger feature vector as input to classifiers .
After that , the histograms generated from all views are concatenated to form a larger feature vector as input to the classifiers .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0

Alignment 610
Since each individual feature vector has the same meaning , the feature fusion can guarantee the effectiveness to represent action .
Since each individual feature vector has the same meaning , the feature fusion can guarantee the effectiveness of the action representation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
19:1			19:1			0		1.0
21:1			20:1			0		1.0

Alignment 611
Training and Testing : After the final feature representations are generated , we separate them into two histogram databases for training and testing phases .
Training and Testing : After the final feature representations are generated , we separate them into two histogram databases for the training and testing phases .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0

Alignment 612
We use a machine learning method such as Support Vector Machine ( SVM ) for classification .
We use a machine learning method such as Support Vector Machine ( SVM ) to make the classification .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
16:2			14:2			3		1.0
18:1			16:1			0		1.0

Alignment 613
In practice , we use the precomputed-kernel technique with the histogram intersection kernel for this process .
In practice , we use the precomputed-kernel technique with the histogram intersection kernel for this process .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 614
Besides , we perform the one-vs-all strategy for multi-class classification .
In addition , we employ the one-vs-all strategy for multi-class classification .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0

Alignment 615
Our proposed trajectory-based approach is compared with the state-of-the-art methods for human action recognition on depth data .
We compared our trajectory-based approach with state-of-the-art methods for recognizing human actions with depth data .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			5:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			6:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			13:1			3		1.0
10:1			11:1			0		1.0
11:1			12:1			1		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0

Alignment 616
Actually , our approach does not count skeleton extraction , which is used as an important factor in some works , such as </CITE> .
Our approach does not use skeleton extraction , which is an important part of some methods , such as </CITE> .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			3:1			0		1.0
2:1			4:1			0		1.0
3:1			5:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			14:1			0		1.0
11:1			15:1			0		1.0
14:1			18:1			0		1.0
16:1			20:1			0		1.0
17:1			21:1			0		1.0
18:1			22:1			0		1.0
19:1			23:1			0		1.0
20:1			24:1			0		1.0

Alignment 617
In fact , extracting skeleton exactly is still an completely unsolved problem , due to the challenges , such as cluttered background , hardware quality , camera motion , so on .
In fact , extracting a skeleton exactly is still an unsolved problem because of challenges such as cluttered backgrounds , poor hardware quality , and camera motion .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:2			13:2			3		1.0
14:1			16:1			0		1.0
15:1			18:1			0		1.0
16:1			19:1			0		1.0
17:1			20:1			0		1.0
18:1			21:1			1		1.0
19:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			31:1			0		1.0

Alignment 618
As mentioned in section </Ref> , to support the aim , we decompose each 3D action to a set of 2D actions and leverage the trajectory-based approach to effectively capture the discriminative motion patterns .
As mentioned in section </Ref> , we decompose each 3D action into a set of 2D actions and leverage the trajectory-based approach to capture the discriminative motion patterns .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			11:1			0		1.0
7:1			12:1			0		1.0
8:1			13:1			0		1.0
9:1			14:1			0		1.0
10:1			15:1			0		1.0
12:1			17:1			0		1.0
13:1			18:1			0		1.0
14:1			19:1			0		1.0
15:1			20:1			0		1.0
16:1			21:1			0		1.0
17:1			22:1			0		1.0
18:1			23:1			0		1.0
19:1			24:1			0		1.0
20:1			25:1			0		1.0
21:1			26:1			0		1.0
22:1			27:1			0		1.0
23:1			29:1			0		1.0
24:1			30:1			0		1.0
25:1			31:1			0		1.0
26:1			32:1			0		1.0
27:1			33:1			0		1.0
28:1			34:1			0		1.0

Alignment 619
In this section , we provide a description of our proposed method to obtain 2D videos from various views .
In this section , we describe our method to obtain 2D videos from various views .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			7:2			3		1.0
6:1			9:1			0		1.0
7:1			11:1			0		1.0
8:1			12:1			0		1.0
9:1			13:1			0		1.0
10:1			14:1			0		1.0
11:1			15:1			0		1.0
12:1			16:1			0		1.0
13:1			17:1			0		1.0
14:1			18:1			0		1.0
15:1			19:1			0		1.0

Alignment 620
In addition , we briefly present the dense trajectory-based feature proposed by H. Wang et al.
In addition , we briefly present the dense trajectory-based feature proposed by H. Wang et al.
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 621
As mentioned in section </CITE> , we decompose each 3D action into a set of 2D actions and leverage the trajectory-based approach to capture the discriminative motion patterns .
As mentioned in section </CITE> , we decompose each 3D action into a set of 2D actions and leverage the trajectory-based approach to capture the discriminative motion patterns .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 622
In this section , we describe our method to obtain 2D videos from various views .
In this section , we describe our method to obtain 2D videos from various views .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 623
In addition , we briefly present the dense trajectory-based feature proposed by H. Wang et al. </CITE> , which has been demonstrated state-of-the-art at action recognition .
In addition , we briefly present the dense trajectory-based feature proposed by H. Wang et al. </CITE> , which has state-of-the-art performance in action recognition .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			22:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0

Alignment 624
Related parts , such as : dense sampling , tracking , and feature descriptors are also referred to .
Related aspects including dense sampling , tracking , and feature descriptors are also referred to .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
3:1			6:1			0		1.0
4:1			7:1			0		1.0
5:1			8:1			0		1.0
6:1			9:1			0		1.0
7:1			10:1			0		1.0
8:1			11:1			0		1.0
9:1			12:1			0		1.0
10:1			13:1			0		1.0
11:1			14:1			0		1.0
12:1			15:1			0		1.0
13:1			16:1			0		1.0
14:1			17:1			0		1.0
15:1			18:1			0		1.0

Alignment 625
Point </Eq> is the projection of point </Eq> along the view direction </Eq> onto the view plane </Eq> , which has state-of-the-art performance in action recognition .
Point </Eq> is the projection of point </Eq> along the view direction </Eq> onto the view plane </Eq> , which has state-of-the-art performance in action recognition .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 626
Our proposed method to obtain discriminative motion patterns for human action recognition on depth video is as follow .
Our method to obtain discriminative motion patterns for recognizing human actions in depth video is as follows .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			11:1			3		1.0
9:1			9:1			0		1.0
10:2			10:1			3		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			1		1.0
17:1			18:1			0		1.0

Alignment 627
At first , 2D motion videos are formed from the sequence of depth maps , as illustrated in figure </fig> .
First , 2D motion videos are formed from a sequence of depth maps , as illustrated in Figure </fig> .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0

Alignment 628
At this step , to obtain a 2D motion video from a view direction </Eq> , corresponding to a view plane </Eq> , in each depth map </Eq> , each point </Eq> is projected to </Eq> on the view plane </Eq> see in figure </Fig> by :
In this step , to obtain a 2D motion video from a view </Eq> , corresponding to a view plane </Eq> , in each depth map </Eq> , each point </Eq> is projected to </Eq> on the view plane </Eq> ( see Figure </Fig> ) as follows :
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0
31:1			32:1			0		1.0
32:1			33:1			0		1.0
33:1			34:1			0		1.0
34:1			35:1			0		1.0
35:1			36:1			0		1.0
36:1			37:1			0		1.0
37:1			38:1			0		1.0
38:1			39:1			0		1.0
39:1			40:1			0		1.0
41:1			41:1			0		1.0
43:1			44:1			0		1.0
47:1			46:1			0		1.0

Alignment 629
where , And the intensity value </Eq> at the projected point </Eq> is calculated by :
where , The intensity value </Eq> at the projected point </Eq> is calculated as :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
14:1			15:1			0		1.0

Alignment 630
So , given a set of points </Eq> , we have a projection </Eq> .
Thus , given a set of points </Eq> , we have a projection </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 631
Therefore , a set of the projections obtained from a given sequence of M depth maps under a view direction </Eq> is formed to a corresponding 2D motion video </Eq> .
Therefore , a set of the projections obtained from a given sequence of M depth maps for the view direction </Eq> is formed into a corresponding 2D motion video </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0

Alignment 632
Each 2D video can be regarded as a 2D motion representation of corresponding action in depth video .
Each 2D video can be regarded as a 2D motion representation of the corresponding action in the depth video .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0

Alignment 633
In particular , we choose three 2D motion representations to present action on three view directions : front , side , and top in 3D space , corresponding to three view planes , respectively : </Eq> , </Eq> and </Eq> .
In particular , we use three 2D motion representations of action in three view directions : the front , side , and top in 3D space , corresponding to three view planes : </Eq> , </Eq> and </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			11:1			0		1.0
11:1			23:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			34:1			0		1.0
33:1			35:1			0		1.0
34:1			36:1			0		1.0
35:1			37:1			0		1.0
36:1			38:1			0		1.0
37:1			39:1			0		1.0
38:1			40:1			0		1.0

Alignment 634
With these view directions , the corresponding projections are respectively :
The corresponding projections in these view directions are :
Line2Start:Length	Line1Start:Length	Module		Score
1:1			6:1			0		1.0
2:1			7:1			0		1.0
4:1			1:1			0		1.0
5:1			2:1			0		1.0
6:1			3:1			0		1.0
7:1			8:1			0		1.0
8:1			10:1			0		1.0

Alignment 635
And the corresponding intensity values in the three projections are , respectively :
The corresponding intensity values of the three projections are :
Line2Start:Length	Line1Start:Length	Module		Score
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:2			4:2			3		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			12:1			0		1.0

Alignment 636
Essentially there are points we can observe from a certain view , but from other views in is impossible .
Essentially , there are points we can observe from a certain view , but not from other views .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			18:1			3		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			19:1			0		1.0

Alignment 637
Indeed , considering an example as shown in figure </Fig> , two points </Eq> have the corresponding projections </Eq> along a view direction </Eq> :
Indeed , considering the example shown in Figure </Fig> , two points </Eq> have the corresponding projections </Eq> along the view direction </Eq> :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:2			3:2			3		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:2			19:2			3		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0

Alignment 638
However , if we observe two points </Eq> , </Eq> along a view direction </Eq> , their projection is only point </Eq> :
However , if we observe </Eq> and </Eq> along the view direction </Eq> , their projection is only </Eq> :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			7:1			0		1.0
7:1			9:1			0		1.0
8:2			10:2			3		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			21:1			0		1.0
19:1			22:1			0		1.0

Alignment 639
In such cases , we cannot observe points ( i.e. , point </Eq> ) hidden by other point ( i.e. point </Eq> ) along a certain view direction ( i.e. , view direction </Eq> ) .
In such cases , we cannot observe points ( i.e. , point </Eq> ) hidden by others ( i.e. , point </Eq> ) along a certain view direction ( i.e. , view direction </Eq> ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			1		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			30:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0

Alignment 640
Therefore , the corresponding intensity value </Eq> at the projected point </Eq> is calculated by :
Therefore , the corresponding intensity value </Eq> at the projected point </Eq> is :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			15:1			0		1.0

Alignment 641
Where </Eq> are parameters of the plane </Eq> . And </Eq> is the coordinate of </Eq> .
Here , </Eq> are parameters of the plane </Eq> , and </Eq> is the coordinate of </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0

Alignment 642
Points </Eq> </Eq> are respectively the projection of points </Eq> , </Eq> along a view direction </Eq> onto a view plane </Eq> .
Points </Eq> and </Eq> are respectively the projections of </Eq> and </Eq> along the view direction </Eq> onto the view plane </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			1		1.0
8:1			7:1			0		1.0
9:1			9:1			0		1.0
11:1			11:1			0		1.0
12:2			12:2			3		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 643
Point </Eq> is the projection of points </Eq> , </Eq> along a view direction </Eq> onto the view plane </Eq> .
</Eq> is the projection of </Eq> and </Eq> along the view direction </Eq> onto the view plane </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			1:1			0		1.0
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			7:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			16:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0

Alignment 644
In this case , the intensity value of point </Eq> is calculated by distance from point </Eq> to the view plane </Eq> .
In this case , the intensity value of </Eq> is calculated using the distance from </Eq> to </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
12:1			18:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			21:1			0		1.0
18:1			22:1			0		1.0

Alignment 645
Considering equations , they are obviously the distance equations between a point and a plane .
Equations are obviously distance equations between a point and a plane .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			4:1			0		1.0
2:1			5:1			0		1.0
3:1			7:1			0		1.0
4:1			8:1			0		1.0
5:1			9:1			0		1.0
6:1			10:1			0		1.0
7:1			11:1			0		1.0
8:1			12:1			0		1.0
9:1			13:1			0		1.0
10:1			14:1			0		1.0
11:1			15:1			0		1.0

Alignment 646
Therefore , equation can be presented by :
Therefore , equation can be represented as :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			2		1.0
7:1			7:1			0		1.0

Alignment 647
Where , </Eq> is the distance between point </Eq> and plane </Eq> .
Here , </Eq> is the distance between the point </Eq> and the plane </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0

Alignment 648
In addition , figure </Fig> shows that is greater than .
In addition , Figure </Fig> shows that is greater than .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 649
The evaluation has provided an important conclusion presented by the following equation :
The evaluation leads to an important conclusion in the form of the following equation :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0

Alignment 650
More generally , if there are N points belong to a line parallel to the view direction </Eq> , the intensity value at the projected point on plane </Eq> is calculated by :
More generally , if there are N points on a line parallel to the view direction </Eq> , the intensity value at the projected point on plane </Eq> is :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			26:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			32:1			0		1.0

Alignment 651
Trajectories provide a compact representation of motion information in video .
Trajectories provide a compact representation of motion information in video .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 652
Trajectories from intensity videos can be used for multimedia event detection ( MED ) , video mining , action classification , and so on .
Trajectories from intensity videos can be used for multimedia event detection ( MED ) , video mining , action classification , and so on .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 653
Trajectory extraction crucially depends on both processes : sampling and tracking .
Trajectory extraction crucially depends on the sampling and tracking processes .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			6:1			0		1.0
10:1			11:1			0		1.0

Alignment 654
Some methods , such as </CITE> , used KLT tracker </CITE> or </CITE> matched SIFT descriptors between consecutive frames to obtain feature trajectories .
Some methods , such as </CITE> , use KLT tracker </CITE> or matched SIFT descriptors </CITE> between consecutive frames to obtain feature trajectories .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			1		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			12:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 655
Recently , the dense trajectory-based motion feature proposed by </CITE> has achieved the state of the art performance on MED systems , such as segment-based system </CITE> on TRECVID MED 2010 , 2011 or AXES </CITE> , and BBNVISER </CITE> on TRECVID MED 2012 .
Recently , the dense trajectory-based motion feature proposed by </CITE> has achieved high levels of performances on MED systems , including the segment-based system </CITE> on TRECVID MED 2010 and 2011 , AXES </CITE> , and BBNVISER </CITE> on TRECVID MED 2012 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
14:1			14:1			0		1.0
15:1			17:1			1		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
21:1			12:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0
24:1			26:1			0		1.0
25:1			27:1			0		1.0
26:1			28:1			0		1.0
27:1			29:1			0		1.0
28:1			30:1			0		1.0
29:1			37:1			0		1.0
30:1			32:1			0		1.0
31:1			31:1			0		1.0
32:1			34:1			0		1.0
33:1			35:1			0		1.0
34:1			36:1			0		1.0
36:1			38:1			0		1.0
37:1			39:1			0		1.0
38:1			40:1			0		1.0
39:1			41:1			0		1.0
40:1			42:1			0		1.0
41:1			43:1			0		1.0
42:1			44:1			0		1.0

Alignment 656
The sampling is performed at multiple scales with a factor of </Eq> .
The sampling is performed at multiple scales with a factor of </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 657
Then , tracking is performed to form trajectories .
Tracking is then performed to form trajectories .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0

Alignment 658
At each scale , in frame t , each point </Eq> is tracked to point </Eq> in next frame </Eq> by : where </Eq> denotes the dense optical flow field , </Eq> is the kernel of median filtering , and </Eq> is the rounded position of </Eq> .
At each scale , in frame t , each point </Eq> is tracked to point </Eq> in the next frame </Eq> by using : where </Eq> denotes the dense optical flow field , </Eq> is the kernel of median filtering , and </Eq> is the rounded position of </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			42:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
33:1			31:1			0		1.0
34:1			32:1			0		1.0
35:1			33:1			0		1.0
36:1			34:1			0		1.0
37:1			35:1			0		1.0
38:1			36:1			0		1.0
39:1			37:1			0		1.0
40:1			38:1			0		1.0
41:1			39:1			0		1.0
42:1			40:1			0		1.0
43:1			41:1			0		1.0
45:1			43:1			0		1.0
46:1			44:1			0		1.0
47:1			45:1			0		1.0
48:1			46:1			0		1.0
49:1			47:1			0		1.0

Alignment 659
The algorithm of </CITE> adopts dense optical flow .
The algorithm presented in </CITE> uses dense optical flows .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
4:1			3:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			1		1.0
9:1			8:1			0		1.0

Alignment 660
And to avoid a drifting problem , a suitable value of trajectory length is set to 15 frames .
To avoid drifting , it sets a suitable trajectory length of 15 frames .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			2:1			0		1.0
2:1			4:1			0		1.0
3:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			11:1			0		1.0
9:1			12:1			0		1.0
10:1			10:1			0		1.0
11:1			16:1			0		1.0
12:1			17:1			0		1.0
13:1			18:1			0		1.0

Alignment 661
Besides trajectories with sudden changes are removed .
It also removes trajectories with sudden changes .
Line2Start:Length	Line1Start:Length	Module		Score
3:1			1:1			0		1.0
4:1			2:1			0		1.0
5:1			3:1			0		1.0
6:1			4:1			0		1.0
7:1			7:1			0		1.0

Alignment 662
After extracting trajectories , two kinds of descriptors : a trajectory shape descriptor and a trajectory-aligned descriptor , can be adopted .
Once the trajectories have been extracted , two kinds of descriptor , i.e. , a trajectory shape descriptor and a trajectory-aligned descriptor , can be used .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			2:1			0		1.0
6:1			3:1			0		1.0
7:1			4:1			0		1.0
8:1			5:1			0		1.0
9:1			6:1			0		1.0
10:1			16:1			0		1.0
11:1			17:1			0		1.0
14:1			9:1			0		1.0
15:1			10:1			0		1.0
16:1			11:1			0		1.0
17:1			12:1			0		1.0
18:1			13:1			0		1.0
19:1			14:1			0		1.0
20:1			15:1			0		1.0
23:1			18:1			0		1.0
24:1			19:1			0		1.0
26:1			21:1			0		1.0

Alignment 663
In our experiments , we only use trajectory-aligned descriptors including the HOG </CITE> , the Histogram of Optical Flow ( HOF ) </CITE> , and the Motion Boundary Histogram ( MBH ) </CITE> .
In our experiments , we only used trajectory-aligned descriptors , including the HOG </CITE> , the Histogram of Optical Flow ( HOF ) </CITE> , and the Motion Boundary Histogram ( MBH ) </CITE> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			1		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			23:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0

Alignment 664
HOG captures local appearance information , while HOF and MBH encode local motion patterns .
HOG captures local appearance information , while HOF and MBH encode local motion patterns .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 665
The descriptors are computed within a space-time volume </Eq> spatial pixels and </Eq> temporal frames ) around the trajectory .
The descriptors are computed within a space-time volume </Eq> spatial pixels and </Eq> temporal frames ) around the trajectory .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 666
This volume is divided into a 3D grid ( spatially </Eq> grid and temporally </Eq> segments ) .
This volume is divided into a 3D grid ( spatially into </Eq> grid and temporally into </Eq> segments ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0

Alignment 667
The default settings of these parameters are </Eq> = 32 pixels , </Eq> = 15 frames , </Eq> = 2 , and </Eq> = 3 .
The default settings of these parameters are </Eq> = 32 pixels , </Eq> = 15 frames , </Eq> = 2 , and </Eq> = 3 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 668
According to authors in </CITE> , all the three descriptors have shown the effectiveness for action recognition on intensity video .
According to the authors of </CITE> , all three descriptors are capable of recognizing actions in intensity video .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			7:1			0		1.0
3:1			2:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			3		1.0
12:2			16:1			3		1.0
15:1			3:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0

Alignment 669
The experimental settings for these descriptors are based on an empirical study showed in </CITE> .
The experimental settings for these descriptors are based on an empirical study </CITE> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0

Alignment 670
In our work , we also conduct experiments on all the three descriptors to wholly evaluate their effectiveness on depth video .
We also conducted experiments on all the three descriptors to evaluate their effectiveness on depth video .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			5:1			0		1.0
2:1			6:1			1		1.0
3:1			7:1			0		1.0
4:1			8:1			0		1.0
5:1			9:1			0		1.0
6:1			10:1			0		1.0
7:1			11:1			0		1.0
8:1			12:1			0		1.0
9:1			13:1			0		1.0
10:1			15:1			0		1.0
11:1			16:1			0		1.0
12:1			17:1			0		1.0
13:1			18:1			0		1.0
14:1			19:1			0		1.0
15:1			20:1			0		1.0
16:1			21:1			0		1.0

Alignment 671
This section presents the experimental results related to our proposed approach on MSR Action 3D dataset , MSR Gesture 3D dataset , and 3D Action Pairs dataset .
This section presents the experimental results of our approach for the MSR Action 3D dataset , MSR Gesture 3D dataset , and 3D Action Pairs dataset .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			8:1			0		1.0
8:1			10:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0

Alignment 672
Our aim is to clear up the following issues :
Our aim is to clear up the following issues :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 673
(1) Recognition accuracy in case of single view;
(1) Recognition accuracy in case of single view;
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 674
(2) The role of compensating information from multiple views;
(2) The role of compensating information from multiple views;
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 675
(3) Comparison with the state-of-the-art approaches .
(3) Comparison with state-of-the-art approaches .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0

Alignment 676
For analysis , we concentrate on MSR Action 3D dataset to explain experimental results . For MSR Gesture 3D dataset and 3D Action Pairs dataset , we only show the final results .
We will concentrate on the MSR Action 3D dataset when explaining the experimental results and show only the final results for the MSR Gesture 3D dataset and 3D Action Pairs dataset .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			4:1			0		1.0
3:1			5:1			0		1.0
4:1			29:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
10:1			10:2			3		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			20:1			0		1.0
15:1			28:1			0		1.0
16:1			27:1			0		1.0
18:1			30:1			0		1.0
19:1			31:1			0		1.0
22:1			16:1			0		1.0
23:1			17:1			0		1.0
24:1			18:1			0		1.0
25:1			19:1			0		1.0
27:1			21:1			0		1.0
28:1			22:1			0		1.0
29:1			23:1			0		1.0
30:1			24:1			0		1.0
31:1			14:1			0		1.0

Alignment 677
All experimental results are reported under the settings mentioned in section .
All experimental results are reported for the settings described in section .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 678
In comparison with the state-of-the-art approaches , our reported result is calculated on concatenating action representations from the combinations of three views : front , side and top .
Unlike the state-of-the-art approaches , our reported results are for concatenating action representations from combinations of three views : front , side and top .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			3:1			0		1.0
2:1			4:1			0		1.0
3:1			5:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:2			9:2			3		1.0
10:1			13:1			0		1.0
11:1			14:1			0		1.0
12:1			15:1			0		1.0
13:1			16:1			0		1.0
14:1			18:1			0		1.0
15:1			19:1			0		1.0
16:1			20:1			0		1.0
17:1			21:1			0		1.0
18:1			22:1			0		1.0
19:1			23:1			0		1.0
20:1			24:1			0		1.0
21:1			25:1			0		1.0
22:1			26:1			0		1.0
23:1			27:1			0		1.0
24:1			28:1			0		1.0

Alignment 679
All the results are compared in terms of recognition accuracy .
All the results are compared in terms of recognition accuracy .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 680
The best performance is highlighted in bold .
The best performance is highlighted in bold .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 681
In this section , we provide the detail of parameters used in each step of our 3D action recognition framework .
Here , we detail the parameters used in each step of our 3D action recognition framework .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			3:1			0		1.0
2:1			4:1			0		1.0
3:1			7:1			0		1.0
4:1			6:1			0		1.0
5:1			9:1			0		1.0
6:1			10:1			0		1.0
7:1			11:1			0		1.0
8:1			12:1			0		1.0
9:1			13:1			0		1.0
10:1			14:1			0		1.0
11:1			15:1			0		1.0
12:1			16:1			0		1.0
13:1			17:1			0		1.0
14:1			18:1			0		1.0
15:1			19:1			0		1.0
16:1			20:1			0		1.0

Alignment 682
Projection : Our aim at this step is to select the best views to effectively capture most discriminative motion patterns .
Projection : Our aim in this step is to select the best views to capture the most discriminative motion patterns .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 683
In our experiments , we conduct projections on views : front , side , and top , which have been demonstrated effective in works </CITE> .
We make projections from front , side , and top views : these views have been demonstrated to be effective in other studies </CITE> .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			6:1			0		1.0
4:1			10:1			0		1.0
5:1			11:1			0		1.0
6:1			12:1			0		1.0
7:1			13:1			0		1.0
8:1			14:1			0		1.0
9:1			15:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
14:1			18:1			0		1.0
15:1			19:1			0		1.0
16:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
22:1			23:1			2		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0

Alignment 684
Results obtained from the projections are three 2D motion videos .
The projections are then used to make three 2D motion videos .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			4:1			0		1.0
2:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0

Alignment 685
Feature Extraction : We use the application available online to extract dense trajectories and calculate aligned-descriptors ( i.e. , MBH , HOG and HOF ) for each 2D motion video .
Feature Extraction : We use an application available online to extract trajectory - aligned descriptors ( i.e. , MBH , HOG and HOF ) for each 2D motion video .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:2			5:2			3		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0

Alignment 686
Experimental results reported in section attach to the MBH descriptor .
The experimental results reported in section are for the MBH descriptor .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0

Alignment 687
The HOG , HOF descriptors will be mentioned in the section .
The HOG and HOF descriptors are described in section .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:2			3		1.0
7:1			8:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0

Alignment 688
Clustering : Purpose of this step is to learn a visual vocabulary or codebook .
Clustering : The purpose of this step is to learn a visual vocabulary or codebook .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0

Alignment 689
Corresponding to three views : front , side and top , we create three codebooks ( i.e. three bags of quantized motion patterns ) .
We create three codebooks ( i.e. three bags of quantized motion patterns ) corresponding to the front , side , and top views .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			12:1			0		1.0
2:1			13:1			0		1.0
3:1			14:1			0		1.0
4:1			15:1			0		1.0
5:1			16:1			0		1.0
6:1			17:1			0		1.0
7:1			18:1			0		1.0
8:1			19:1			0		1.0
9:1			20:1			0		1.0
10:1			21:1			0		1.0
11:1			22:1			0		1.0
12:1			23:1			0		1.0
14:1			1:1			0		1.0
16:1			5:1			0		1.0
17:1			6:1			0		1.0
18:1			7:1			0		1.0
19:1			10:1			0		1.0
20:1			8:1			0		1.0
21:1			9:1			0		1.0
22:1			3:1			0		1.0
23:1			24:1			0		1.0

Alignment 690
In addition , due to purpose of a stable and unified framework on all benchmark datasets , we cluster extracted motion features to 2000 codewords ( i.e. 2000 quantized motion patterns ) for each codebook .
In addition , to ensure a unified framework on all benchmark datasets , we cluster the extracted motion features around 2000 codewords ( i.e. 2000 quantized motion patterns ) for each codebook .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			4:1			0		1.0
5:1			7:1			0		1.0
6:1			10:1			0		1.0
7:1			11:1			0		1.0
8:1			12:1			0		1.0
9:1			13:1			0		1.0
10:1			14:1			0		1.0
11:1			15:1			0		1.0
12:1			16:1			0		1.0
13:1			17:1			0		1.0
14:1			18:1			0		1.0
16:1			19:1			0		1.0
17:1			20:1			0		1.0
18:1			21:1			0		1.0
20:1			23:1			0		1.0
21:1			24:1			0		1.0
22:1			25:1			0		1.0
23:1			26:1			0		1.0
24:1			27:1			0		1.0
25:1			28:1			0		1.0
26:1			29:1			0		1.0
27:1			30:1			0		1.0
28:1			31:1			0		1.0
29:1			32:1			0		1.0
30:1			33:1			0		1.0
31:1			34:1			0		1.0
32:1			35:1			0		1.0

Alignment 691
The k-means algorithm with Euclidean distance is applied at this step .
The k-means algorithm with the Euclidean distance is used in this step .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			2		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0

Alignment 692
Quantization and Fusion : Two popular strategies used to quantize extracted features are hard-assignment and soft-assignment .
Quantization and Fusion : Two popular strategies for quantizing extracted features are hard-assignment and soft-assignment .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			9:1			1		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0

Alignment 693
To guarantee the efficiency of our framework , we apply the hard-assignment strategy to quantize dense trajectory motion features extracted at step Feature Extraction .
To guarantee the efficiency of our framework , we use the hard-assignment strategy to quantize the dense trajectory motion features extracted in step Feature Extraction .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			2		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0

Alignment 694
With this strategy , each feature vector can be assigned to a codeword using Euclidean distance or rejected as an outlier .
With this strategy , each feature vector can be assigned to a codeword or be rejected as an outlier by using the Euclidean distance .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
20:1			13:1			0		1.0
22:1			14:1			0		1.0
23:1			15:1			0		1.0
24:1			21:1			0		1.0

Alignment 695
Results of the quantization step is to generatee 2D motion representations corresponding to selected views .
The results of the quantization step are 2D motion representations corresponding to the selected views .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			2		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 696
After that , these 2D motion representations are concatenated to form final motion representation for corresponding depth video .
After that , these 2D motion representations are concatenated to form the final motion representation for the corresponding depth video .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0

Alignment 697
The final representations are then separated into two histogram databases for training and testing phases .
The final representations are then separated into two histogram databases for the training and testing phases .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0

Alignment 698
Training and Testing : Most recent works used SVM classifier refer to the libSVM library </CITE> published online by author .
Training and Testing : Most of the recent methods using SVM classifiers refer to the libSVM library </CITE> published online .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
7:1			5:1			0		1.0
9:1			7:1			1		1.0
10:1			8:1			0		1.0
11:1			9:1			1		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			20:1			0		1.0

Alignment 699
In our framework , we use the libSVM library with histogram intersection kernel :
In our framework , we use the libSVM library with the histogram intersection kernel :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0

Alignment 700
The one-vs-all strategy is used for classifiers in both phrases of training and testing .
The one-vs-all strategy is used for classifiers in both training and testing .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0

Alignment 701
Predicted value of each action is defined as the maximum score obtained from all the classifiers .
The predicted value of each action is defined as the maximum score obtained from all the classifiers .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0

Alignment 702
This score shows that a human action is confused with another or not .
This score indicates whether a human action is confused with another or not .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			2		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 703
This dataset </CITE> contains 20 actions , as shown in figure </Fig> .
This dataset </CITE> contains 20 actions , as shown in Figure </Fig> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 704
Actions are performed by ten subjects for two or three times in the context of game console interaction .
Actions were performed two or three times by ten subjects in the context of game console interaction .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			2		1.0
2:1			2:1			0		1.0
3:1			7:1			0		1.0
4:1			8:1			0		1.0
5:1			9:1			0		1.0
6:1			10:1			0		1.0
7:1			3:1			0		1.0
8:1			4:1			0		1.0
9:1			5:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0

Alignment 705
In total , there are 567 sequences of depth maps .
In total , there were 567 sequences of depth maps .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			2		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 706
The depth maps are shot at frame rate of 15 fps .
The depth maps were shot at a frame rate of 15 fps .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			2		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0

Alignment 707
The size of the depth map is </Eq> to ensure processing efficiency .
The size of the depth map was </Eq> to ensure processing efficiency .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			2		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 708
The three action subsets used in the experiments .
The three action subsets used in the experiments .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 709
In order to conduct a fair comparison , we use the same experimental settings as </CITE> .
In order to conduct a fair comparison , we used the same experimental settings as in </CITE> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:2			9:2			3		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0

Alignment 710
In the settings , the dataset is divided into three action subsets .
In these settings , the dataset is divided into three action subsets .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 711
Each subset has 8 actions .
Each subset has eight actions .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			2		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0

Alignment 712
The two subsets AS1 and AS2 present that grouped actions have similar movements .
The AS1 and AS2 subsets are such that grouped actions have similar movements .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			3:1			0		1.0
2:1			4:1			0		1.0
3:1			5:1			0		1.0
4:1			2:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 713
The subset AS3 groups complex actions together .
The AS3 subset groups complex actions together .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			2:1			0		1.0
2:1			1:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 714
For instance , action hammer seems to be confused with action forward punch in AS1 or similar movements between action hand catch and side boxing in AS2 .
For instance , the hammer action seems to be confused with the forward punch action in AS1 , and the hand catch and side boxing actions are similar movements in AS2 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			4:1			0		1.0
5:1			3:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			10:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:2			19:1			3		1.0
27:1			16:1			0		1.0
28:1			17:1			0		1.0
29:1			25:1			0		1.0
30:1			26:1			0		1.0
31:1			27:1			0		1.0

Alignment 715
As for each subset , we select half of the subjects as training and the rest as testing ( i.e. cross subject test ) .
For each subset , we selected half of the subjects for training and the rest for testing ( i.e. , a cross subjects test ) .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			1		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			1:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			1		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0

Alignment 716
In this part , we evaluate the dense trajectory-based approach for action recognition under observing actions from single views .
In this part , we evaluate the dense trajectory-based approach on single views .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			17:1			0		1.0
12:1			18:1			0		1.0
13:1			19:1			0		1.0

Alignment 717
A straightforward view is front view .
A straightforward view is the front .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			6:1			0		1.0

Alignment 718
In order to obtain action presentation on front view from depth video , a simple way is to consider depth value as intensity value .
A simple way to obtain an action representation of the front view from the depth video is to consider the depth value as an intensity value .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			14:1			0		1.0
2:1			15:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
6:1			4:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
14:1			10:1			0		1.0
15:1			11:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0

Alignment 719
Table </tab> shows three confusion matrices corresponding to evaluations on three action subsets of MSR Action 3D dataset .
Table </tab> shows three confusion matrices corresponding to evaluations on three action subsets of the MSR Action 3D dataset .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0

Alignment 720
Considering results reported in table </tab> , two subsets AS1 , AS2 contain many confused actions as mentioned in the dataset description . For example , hammer (a03) and forward punch (a05) in AS1 , or side-boxing (a12) and hand catch (a04) in AS2 .
The results reported in the table </tab> indicate that AS1 , AS2 subsets contain many confusable actions , e.g. , hammer (a03) and forward punch (a05) in AS1 , or side-boxing (a12) and hand catch (a04) in AS2 , as is mentioned in the dataset description .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			19:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			8:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			1		1.0
16:1			15:1			0		1.0
17:1			6:1			0		1.0
19:1			25:1			0		1.0
20:1			26:1			0		1.0
21:1			27:1			0		1.0
22:1			28:1			0		1.0
23:1			29:1			0		1.0
24:1			30:1			0		1.0
25:1			31:1			0		1.0
26:1			32:1			0		1.0
27:1			33:1			0		1.0
28:1			34:1			0		1.0
29:1			35:1			0		1.0
30:1			36:1			0		1.0
31:1			37:1			0		1.0
32:1			38:1			0		1.0
33:1			39:1			0		1.0
34:1			40:1			0		1.0
35:1			41:1			0		1.0
36:1			42:1			0		1.0
37:1			43:1			0		1.0
39:1			16:1			0		1.0
41:1			17:1			0		1.0
42:1			18:1			0		1.0
44:1			20:1			0		1.0
45:1			21:1			0		1.0
46:1			22:1			0		1.0

Alignment 721
The main cause is due to similar movements of actions in the same view direction .
The main cause is the similar movements of the actions in the same view direction .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 722
That is reason why we need compensating motion information from other views ( e.g. , side view and top view ) .
That is why we need compensating motion information from other views ( e.g. , the side view and/or top view ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 723
This section presents our experiments on action recognition using information from multiple views .
This section presents our experiments on action recognition using information from multiple views .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 724
Action representations in a depth sequence is fused by concatenating the feature vectors computed from corresponding views .
The action representations in a depth sequence are fused by concatenating the feature vectors computed from the corresponding views .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			2		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0

Alignment 725
We report the experimental results on three action subsets and the average of the three subsets .
We report the experimental results on three action subsets and the average of the three subsets .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 726
Figure </Fig> shows a comparison between the intensity representations from front , side and top and their fused representation .
Figure </Fig> compares intensity representations from the front , side and top and their fused representation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			7:1			0		1.0
4:1			8:1			0		1.0
5:1			9:1			0		1.0
6:1			6:1			0		1.0
7:1			10:1			0		1.0
8:1			11:1			0		1.0
9:1			12:1			0		1.0
10:1			13:1			0		1.0
11:1			14:1			0		1.0
12:1			15:1			0		1.0
13:1			16:1			0		1.0
14:1			17:1			0		1.0
15:1			18:1			0		1.0
16:1			19:1			0		1.0

Alignment 727
The average recognition accuracy of the fusion , which is 96.67% accuracy is better than the individual intensity representations on the three action subsets .
The average recognition accuracy of the fusion ( 96.67%) is better than those of the individual intensity representations on the three action subsets .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
9:1			12:1			0		1.0
10:1			13:1			0		1.0
11:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0

Alignment 728
These results demonstrate the effectiveness of leveraging depth information from multiple views .
These results demonstrate the effectiveness of leveraging depth information from multiple views .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 729
Results in figure </Fig> show the role of views to our approach .
The results in Figure </Fig> show the role of views in our approach .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:2			8:2			3		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0

Alignment 730
Experimental results confirm that action representations from front view achieve the best accuracy .
They confirm that action representations from the front view achieve the best accuracy .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 731
Obviously , the presentation from front view is an indispensable component for combination .
Obviously , a front view representation is an indispensable component of a combination .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			5:1			0		1.0
4:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 732
Therefore , for the rest , we perform experiments on view combinations with front view . We creaate additional combinations front and side , front and top .
Therefore , in what follows , all view combinations that we describe will include a front view , i.e. , front and side or front and top .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
5:1			5:1			0		1.0
7:1			10:1			0		1.0
8:1			11:1			0		1.0
10:1			6:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			23:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0

Alignment 733
Figure </Fig> shows the performance of the view combinations .
Figure </Fig> shows the performance of the view combinations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 734
Interestingly , the achieved performance ( 96.95% ) from the combination of front and top beats the performance based on combining all the three views ( 96.67\% ) as well as the combination of front and side ( 93.94\% ) in terms of average accuracy .
Interestingly , t the front and top combination ( 96.95\% ) beats combining all three views ( 96.67\% ) as well as front and side combination ( 93.94\% ) in terms of average accuracy .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			12:1			0		1.0
5:1			13:1			0		1.0
6:1			14:1			0		1.0
7:1			10:1			0		1.0
8:1			5:1			0		1.0
10:1			7:1			0		1.0
11:1			15:1			0		1.0
12:1			20:1			0		1.0
13:1			21:1			0		1.0
14:1			23:1			0		1.0
15:1			24:1			0		1.0
16:1			25:1			0		1.0
17:1			26:1			0		1.0
18:1			27:1			0		1.0
19:1			28:1			0		1.0
20:1			29:1			0		1.0
21:1			30:1			0		1.0
22:1			34:1			0		1.0
23:1			35:1			0		1.0
24:1			36:1			0		1.0
25:1			32:1			0		1.0
26:1			37:1			0		1.0
27:1			38:1			0		1.0
28:1			39:1			0		1.0
29:1			40:1			0		1.0
30:1			41:1			0		1.0
31:1			42:1			0		1.0
32:1			43:1			0		1.0
33:1			44:1			0		1.0
34:1			45:1			0		1.0

Alignment 735
In addition , based on experimental results presented in figure </Fig> indicates two interesting points .
In addition , the results in this figure </Fig> indicate two interesting points .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			6:1			0		1.0
5:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			1		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0

Alignment 736
Firstly , compensating information from various views can cause unexpected risks , due to erroneous information from certain views .
Firstly , compensating information from various views can cause unexpected risks , due to erroneous information from certain views .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 737
Indeed , consider two actions : high arm wave and two hand wave
Indeed , consider two actions : high arm wave and two hand wave .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 738
although both contain ``wave arm'' movement , we easily recognize them from front and top views due to number of performed movements .
Although both contain the ``wave arm'' movement , we can easily distinguish them from the number of performed movements apparent in the front and top views .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			2		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
15:1			18:1			0		1.0
16:1			19:1			0		1.0
17:1			20:1			0		1.0
18:1			21:1			0		1.0
22:1			12:1			0		1.0
23:1			13:1			0		1.0
24:1			14:1			0		1.0
25:1			15:1			0		1.0
26:1			22:1			0		1.0

Alignment 739
However , if we observe the two actions from side view , a half of body is hidden ( see figure </Fig> ) .
However , if we observe the two actions from the side view , half of the body is hidden ( see Figure </Fig> ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0

Alignment 740
Therefore we confuse movements performed on the two actions . In this case , merging information from side view into the combination of front and top view causes to decrease the performance of the recognition system .
In this case , it becomes easy to confuse movements of the two actions , and merging information from the side view into the front and top view combination actually causes the performance of the recognition system to decrease .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			10:1			0		1.0
1:1			11:1			0		1.0
2:1			12:1			0		1.0
3:1			13:1			0		1.0
7:1			28:1			0		1.0
8:1			2:1			0		1.0
9:1			3:1			0		1.0
10:1			22:1			0		1.0
11:1			6:1			0		1.0
12:1			7:1			0		1.0
13:1			8:1			0		1.0
15:1			24:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			33:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			0		1.0
23:1			20:1			0		1.0
24:1			23:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			21:1			0		1.0
30:1			27:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
38:1			29:1			0		1.0
39:1			9:1			0		1.0

Alignment 741
Secondly , the experimental results have provided a good choice to decrease computational cost but still ensures a convincing performance .
Secondly , the experimental results indicate a good way to decrease computational cost but still ensure convincing performance .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:2			3		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0

Alignment 742
Looking at figure </Fig> , we can see that the performances of two combinations , i.e. , ( front & top ) and ( front & side & top ) , are comparable .
Looking at figure </Fig> , we can see that the performances of two combinations , i.e. , ( front & top ) and ( front & side & top ) , are comparable .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0

Alignment 743
In some cases , such as in action subsets 2 , 3 , and average , combination of front and top provide better performances .
In some cases , such as in action subsets 2 , 3 , and average , the front and top combination has better performance .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			16:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			1		1.0
24:1			24:1			0		1.0

Alignment 744
Obviously , if we eliminate unnecessary views , we can improve the efficiency of our system but still achieve competitive results .
Obviously , if we eliminate unnecessary views , we can improve the efficiency of our system but still achieve competitive results .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 745
These interesting points confirm that information combination from multiple views is better than only from single views .
These points confirm that information from multiple views is better than information from only single views .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
12:1			14:1			0		1.0
13:1			13:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0

Alignment 746
In addition , the points can lead to looking for optimal solution of combining views .
In addition , they suggest that there is an optimal way of combining views .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
7:1			5:1			3		1.0
9:1			10:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0

Alignment 747
This is a promising challenge to overcome and build an effective and efficient recognition system .
These are promising results for building an effective and efficient recognition system .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			3:1			0		1.0
5:1			8:1			1		1.0
6:1			9:1			0		1.0
7:1			10:1			0		1.0
8:1			11:1			0		1.0
9:1			12:1			0		1.0
10:1			13:1			0		1.0
11:1			14:1			0		1.0
12:1			15:1			0		1.0

Alignment 748
Table </tab> shows evaluation results of our proposed approach compared to the state-of-the-art approaches on three action subsets of MSR Action 3D dataset ( seeing table </tab> ) .
Table </tab> compares the results of our approach with those of the state-of-the-art approaches on three action subsets of the MSR Action 3D dataset ( see Table </tab> ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			11:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			8:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			1		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0

Alignment 749
The compared approaches use various feature representations , such as silhouette features </CITE> , skeletal joint features like </CITE> , local occupancy patterns </CITE> , normal orientation features </CITE> , and cuboid similarity features </CITE> .
The compared approaches use various feature representations , such as silhouette features </CITE> , skeletal joint features like </CITE> , local occupancy patterns </CITE> , normal orientation features </CITE> , and cuboid similarity features </CITE> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0

Alignment 750
Under the same setting ( i.e. cross subjects test ) , the result table </tab> indicates that our approach achieves the highest accuracy .
For the same setting ( i.e. , a cross subjects test ) , the table </tab> indicates that our approach achieves the highest accuracy .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0

Alignment 751
The Gesture3D dataset </CITE> is a hand gesture dataset of depth sequences captured by a depth camera .
The Gesture3D dataset </CITE> is a hand gesture dataset of depth sequences captured by a depth camera .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 752
This dataset contains a set of 12 gestures defined by American Sign Language ( ASL ) as shown in figure </Fig> .
This dataset contains a set of 12 gestures defined by American Sign Language ( ASL ) ( see Figure </Fig> ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
17:1			19:1			2		1.0
19:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 753
In this dataset , ten subjects perform each gesture two or three times .
In this dataset , ten subjects performed each gesture two or three times .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			1		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 754
In total , the dataset contains 333 depth sequences .
In total , the dataset contains 333 depth sequences .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 755
The main challenge in this dataset is about self-occlusion .
The main challenge here is self-occlusion .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			6:1			0		1.0
5:1			8:1			0		1.0
6:1			9:1			0		1.0

Alignment 756
We follow the experimental settings in </CITE> ( i.e. , the leave-one-subject-out cross-validation ) to evaluate our approach .
We used the experimental settings in </CITE> ( i.e. , the leave-one-subject-out cross-validation ) to evaluate our approach .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 757
The results are described in table </tab> , where our approach outperforms all previous approaches .
The results are in Table </tab> , from which it is clear that our approach outperformed the previous approaches .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			4:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
8:1			8:1			3		1.0
13:1			9:1			0		1.0
14:1			10:1			0		1.0
15:1			11:1			1		1.0
16:2			12:2			3		1.0
18:1			14:1			0		1.0
19:1			15:1			0		1.0

Alignment 758
The 3D Action Pairs dataset </CITE> is a new type of action dataset .
The 3D Action Pairs dataset </CITE> is a new type of action dataset .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 759
The dataset contains pairs of actions , such that within each pair , the motion and the shape cues are similar , but their correlations vary .
The dataset contains pairs of actions , such that within each pair , the motion and shape cues are similar , but their correlations vary .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0

Alignment 760
It is useful to evaluate how well the approaches capture the prominent cues jointly in depth sequences .
It is useful for evaluating how well the approaches capture the prominent cues jointly in depth sequences .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:2			3:2			3		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 761
There are six pairs of actions see figure </Fig> .
There are six pairs of actions ( see figure </Fig> ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
11:1			9:1			0		1.0

Alignment 762
Each action is performed three times by ten subjects .
Each action was performed three times by ten subjects .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			2		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 763
Actions from the first five subjects are used for testing , and the rest for training .
Actions from the first five subjects were used for testing , the rest for training .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:2			6:2			3		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0

Alignment 764
We compare our performance with the HON4D approach </CITE> , which achieved the best performance on this dataset up to date .
We compared our method with the HON4D approach </CITE> , which so far has had the best performance on this dataset .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			1		1.0
2:1			2:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:2			19:2			3		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			21:1			0		1.0

Alignment 765
We summarize results in table </tab> , and show the confusion matrices in table </tab> .
Table </tab> summarizes the results , and Table </tab> shows the confusion matrices .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			5:1			0		1.0
4:1			2:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
8:1			14:1			0		1.0
9:1			8:1			1		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			15:1			0		1.0

Alignment 766
It is clear that our approach significantly outperforms the state-of-the-art approach for which suffered from confusion appeared within action pairs .
It is clear that our approach significantly outperformed the state-of-the-art approach , which suffered from confusion within the action pairs .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			1		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 767
According to </CITE> , MBH is the best feature descriptor for dense trajectories on intensity videos .
According to </CITE> , MBH is the best feature descriptor for dense trajectories on intensity videos .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 768
Therefore , in previous experiments , we only use MBH descriptor to represent motion information .
Therefore , in the previous experiments , we only used the MBH descriptor to represent the motion information .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			1		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0

Alignment 769
Due to the difference between depth data and intensity data , we conduct other experiments to investigate the impact of feature descriptors with replacing MBH with HOG and HOF .
Due to the difference between the depth data and intensity data , we conducted other experiments to investigate the impact of feature descriptors by replacing MBH with HOG and HOF .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			17:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			1		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0

Alignment 770
We report the average recognition accuracies of the approach using different descriptors from three views ( i.e. front , side , and top ) in table </tab> .
Table </tab> lists the average recognition accuracies of the approach using different descriptors from three views ( i.e. front , side , and top ) .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			26:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			27:1			0		1.0

Alignment 771
Experimental results verify that the MBH descriptor is still the best trajectory-aligned descriptor in comparison with the HOG , HOF descriptors on the experimental datasets .
The experimental results verify that the MBH descriptor is still the best trajectory-aligned descriptor on the experimental datasets .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			23:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			21:1			0		1.0
15:1			22:1			0		1.0
17:1			24:1			0		1.0
18:1			25:1			0		1.0

Alignment 772
However , using HOG or HOF also gives competitive performances .
However , HOG and HOF do give competitive performance .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			3:1			0		1.0
4:1			5:1			0		1.0
5:1			4:1			3		1.0
6:1			7:1			1		1.0
7:1			8:1			0		1.0
8:1			9:1			1		1.0
9:1			10:1			0		1.0

Alignment 773
In addition , extracting HOG , HOF is less expensive than extracting MBH .
In addition , extracting HOG or HOF is less expensive than extracting MBH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 774
These advantages provide a promising way for building effective and efficient systems .
These advantages are promising for building effective and efficient systems .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			4:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0

Alignment 775
We proposed a novel approach to effectively exploit discriminative motion patterns for human action recognition using depth sequences in this work .
We proposed a novel approach to effectively exploit discriminative motion patterns for human action recognition using depth sequences .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			21:1			0		1.0

Alignment 776
The motion patterns based on trajectories jointly encodes local motion and appearance cues .
The motion patterns based on trajectories jointly encode local motion and appearance cues .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			1		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 777
In order to deal with confused actions due to similar movements , compensating information from different view directions is proposed .
Compensating information from different view directions is used to deal with actions that can be confused due to their having similar movements .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			13:1			0		1.0
2:1			14:1			0		1.0
3:1			15:1			0		1.0
4:1			16:1			0		1.0
5:1			17:1			0		1.0
6:1			18:1			0		1.0
8:1			2:1			0		1.0
9:1			3:1			0		1.0
10:1			4:1			0		1.0
11:1			6:1			0		1.0
15:1			5:1			0		1.0
16:1			7:1			0		1.0
17:1			8:1			0		1.0
20:1			9:1			0		1.0
21:1			10:1			0		1.0
22:1			20:1			0		1.0

Alignment 778
In addition , we also provide an analysis about the role of single views in merging information with aim to obtain the best combination .
We conducted an analysis of the role of single views in merging information with the aim of obtaining the best combination of views .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			6:1			0		1.0
3:1			7:1			0		1.0
5:1			9:1			0		1.0
6:1			10:1			0		1.0
7:1			11:1			0		1.0
8:1			12:1			0		1.0
9:1			13:1			0		1.0
10:1			14:1			0		1.0
11:1			15:1			0		1.0
12:1			16:1			0		1.0
13:1			17:1			0		1.0
15:1			18:1			0		1.0
16:2			19:2			3		1.0
18:1			21:1			0		1.0
19:1			22:1			0		1.0
20:1			23:1			0		1.0
23:1			24:1			0		1.0

Alignment 779
We have evaluated our proposed approach extensively on three challenging benchmark datasets and shown that it significantly outperforms the state-of-the-art .
In addition , we extensively evaluated our approach on three challenging benchmark datasets and found that it significantly outperformed state-of-the-art methods .
Line2Start:Length	Line1Start:Length	Module		Score
4:1			6:1			0		1.0
5:1			2:1			0		1.0
6:1			3:1			0		1.0
7:1			5:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			1		1.0
19:1			19:1			0		1.0
21:1			20:1			0		1.0

Alignment 780
Our motion pattern-based approach with compensating information from separate motion representations shows promising results .
Our motion pattern-based approach with compensating information from separate motion representations shows promising results .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 781
This also suggests the importance of discriminative motion patterns for human action recognition on depth sequences .
Our study also suggests the importance of discriminative motion patterns for recognizing human actions in depth sequences .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			12:1			3		1.0
12:1			10:1			0		1.0
13:2			11:1			3		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0

Alignment 782
Therefore , exploiting depth-based motion trajectories can be beneficial for action recognition systems using depth cameras .
Therefore , depth-based motion trajectories can be beneficial for action recognition systems using depth cameras .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0

Alignment 783
This is also an interesting idea for our future work .
This is an interesting idea for us to pursue in our future work .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			0		1.0

Alignment 784
Utilizing State - of - the - art Parsers to Diagnose Problems in Treebank Annotation for a Less Resourced Language
Utilizing State - of - the - art Parsers to Diagnose Problems in Treebank Annotation for a Less Resourced Language
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 785
The recent success of statistical parsing methods has made treebanks become important resources for building good parsers .
The recent success of statistical parsing methods has made treebanks become important resources for building good parsers .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 786
However , constructing high - quality annotated treebanks is a challenging task .
However , constructing high - quality annotated treebanks is a challenging task .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 787
We utilized two publicly available parsers , Berkeley and MST parsers , for feedback on improving the quality of part - of - speech tagging for the Vietnamese Treebank .
We utilized two publicly available parsers , Berkeley and MST parsers , for feedback on improving the quality of part - of - speech tagging for the Vietnamese Treebank .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0

Alignment 788
Analysis of the treebank and parsing errors revealed how problems with the Vietnamese Treebank influenced the parsing results and real difficulties of Vietnamese parsing that required further improvements to existing parsing technologies .
Analysis of the treebank and parsing errors revealed how problems with the Vietnamese Treebank influenced the parsing results and real difficulties with Vietnamese parsing that required further improvements to existing parsing technologies .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0

Alignment 789
Treebanks , corpora annotated with syntactic structures , have become more and more important for language processing .
Treebanks , i .e . , corpora annotated with syntactic structures , have become more and more important for language processing .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
6:1			2:1			0		1.0
7:1			3:1			0		1.0
8:1			4:1			0		1.0
9:1			5:1			0		1.0
10:1			6:1			0		1.0
11:1			7:1			0		1.0
12:1			8:1			0		1.0
13:1			9:1			0		1.0
14:1			10:1			0		1.0
15:1			11:1			0		1.0
16:1			12:1			0		1.0
17:1			13:1			0		1.0
18:1			14:1			0		1.0
19:1			15:1			0		1.0
20:1			16:1			0		1.0
21:1			17:1			0		1.0

Alignment 790
The Vietnamese Treebank ( VTB ) has been built as part of the national project ``Vietnamese language and speech processing ( VLSP )'' to strengthen automatic processing of the Vietnamese language \cite .
The Vietnamese Treebank ( VTB ) has been built as part of the national project for ``Vietnamese language and speech processing ( VLSP )'' to strengthen automatic processing of the Vietnamese language \cite .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0

Alignment 791
However , when we trained the Berkeley parser \cite in our preliminary experiment with VTB and evaluated it using the corpus , the parser only achieved an F - score of 72 .1\% .
However , when we trained the Berkeley parser \cite in our preliminary experiment with VTB and evaluated it using the corpus , the parser only achieved an F - score of 72 .1\% .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0

Alignment 792
This percentage was far lower than the state - of - the - art performance reported for the Berkeley parser on the English Penn Treebank of 90 .2\% \cite .
This percentage was far lower than the state - of - the - art performance reported for the Berkeley parser on the English Penn Treebank of 90 .2\% \cite .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0

Alignment 793
There are two possible reasons for this .
There are two possible reasons for this .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 794
First , the quality of VTB was not good enough to construct a good parser that included the quality of the annotation scheme , the annotation guidelines , and the annotation process .
First , the quality of VTB was not good enough to construct a good parser that included the quality of the annotation scheme , the annotation guidelines , and the annotation process .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0

Alignment 795
Second , parsing Vietnamese is a difficult problem on its own , and we need to seek new solutions to this .
Second , parsing Vietnamese is a difficult problem on its own , and we need to seek new solutions to this .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 796
Nguyen et al . \cite proposed methods of improving the annotations of word segmentation ( WS ) for VTB .
Nguyen et al . \cite proposed methods of improving the annotations of word segmentation ( WS ) for VTB .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 797
They also evaluated different word segmentation criteria in two applications , i .e . , machine translation and text classification .
They also evaluated different word segmentation criteria in two applications , i .e . , machine translation and text classification .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 798
This paper focuses on improving the quality of parts - of - speech ( POS ) annotations by using state - of - the - art parsers to provide feedback for this process .
This paper focuses on improving the quality of parts - of - speech ( POS ) annotations by using state - of - the - art parsers to provide feedback for this process .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0

Alignment 799
The difficulties with Vietnamese POS tagging have been recognized by many researchers \cite .
The difficulties with Vietnamese POS tagging have been recognized by many researchers \cite .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 800
There is little consensus as to the methodology for classifying words .
There is little consensus as to the methodology for classifying words .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 801
Polysemous words , i .e . , words with the same surface form but having different meanings and grammar functions , are very popular in the Vietnamese language .
Polysemous words , i .e . , words with the same surface form but having different meanings and grammar functions , are very popular in the Vietnamese language .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 802
For example , the word \textviet can be a noun that means \emph , or an adjective that means \emph depending on the context .
For example , the word \textviet can be a noun that means \emph , or an adjective that means \emph depending on the context .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 803
This characteristic makes it difficult to tag POSs for Vietnamese , either manually or automatically .
This characteristic makes it difficult to tag POSs for Vietnamese , either manually or automatically .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 804
The rest of this paper is organized as follows : a brief introduction to VTB and its annotation schemes are provided in Section \ref .
The rest of this paper is organized as follows : a brief introduction to VTB and its annotation schemes are provided in Section \ref .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 805
Then , previous work is summarized in Section \ref .
Then , previous work is summarized in Section \ref .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 806
Section \ref describes our methods of detecting and correcting inconsistencies in POSs in the VTB corpus .
Section \ref describes our methods of detecting and correcting inconsistencies in POSs in the VTB corpus .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 807
Evaluations of these methods are described in Section \ref .
Evaluations of these methods are described in Section \ref .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 808
Finally , Section \ref explains our evaluations of the Berkeley parser and MST parser on different versions of the VTB corpus , which were created by using detected inconsistencies .
Finally , Section \ref explains our evaluations of the Berkeley parser and maximum spanning tree ( MST ) parser on different versions of the VTB corpus , which were created by using detected inconsistencies .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
16:1			12:1			0		1.0
18:1			13:1			0		1.0
19:1			14:1			0		1.0
20:1			15:1			0		1.0
21:1			16:1			0		1.0
22:1			17:1			0		1.0
23:1			18:1			0		1.0
24:1			19:1			0		1.0
25:1			20:1			0		1.0
26:1			21:1			0		1.0
27:1			22:1			0		1.0
28:1			23:1			0		1.0
29:1			24:1			0		1.0
30:1			25:1			0		1.0
31:1			26:1			0		1.0
32:1			27:1			0		1.0
33:1			28:1			0		1.0
34:1			29:1			0		1.0

Alignment 809
These results from evaluations are considered to be a way of measuring the effect of automatically detected and corrected inconsistencies .
These results from evaluations are considered to be a way of measuring the effect of automatically detected and corrected inconsistencies .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 810
We could observe difficulties with Vietnamese that affected the quality of parsers by analyzing the results from parsing .
We could observe difficulties with Vietnamese that affected the quality of parsers by analyzing the results from parsing .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 811
Our experiences in using state - of - the - art parsers for treebank annotation , which are presented in this paper , should not only benefit the Vietnamese language , but also other languages with similar characteristics .
Our experiences in using state - of - the - art parsers for treebank annotation , which are presented in this paper , should not only benefit the Vietnamese language , but also other languages with similar characteristics .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0

Alignment 812
The VTB corpus contains 10 .433 sentences ( 274 .266 tokens ) , semi - manually annotated with three layers of WS , POS tagging , and bracketing .
The VTB corpus contains 10 .433 sentences ( 274 .266 tokens ) , semi - manually annotated with three layers of WS , POS tagging , and bracketing .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 813
The first annotation is produced for each annotation layer by using automatic tools . Then , the annotators revise these data .
The first annotation is produced for each annotation layer by using automatic tools . Then , the annotators revise these data .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 814
The WS and POS annotation schemes were introduced by Nguyen et al . \cite .
The WS and POS annotation schemes were introduced by Nguyen et al . \cite .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 815
This section briefly introduces POS tag sets and a bracketing annotation scheme .
This section briefly introduces POS tag sets and a bracketing annotation scheme .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 816
VTB specifies the 18 different POS tags summarized in Table \ref \cite .
VTB specifies the 18 different POS tags summarized in Table \ref \cite .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 817
Each unit in this table goes with several example words .
Each unit in this table goes with several example words .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 818
English translations of these words are included in braces .
English translations of these words are included in braces .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 819
However , as we could not find any appropriate English translations for some words , these empty translations have been denoted by asterisks ( * ) .
However , as we could not find any appropriate English translations for some words , these empty translations have been denoted by asterisks ( * ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 820
The VTB corpus is annotated with three syntactic tag types : constituency tags , functional tags , and null - element tags .
The VTB corpus is annotated with three syntactic tag types : constituency tags , functional tags , and null - element tags .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 821
There are 18 constituency tags in VTB . The functional tags are used to enrich information for syntactic trees , such as where functional tag ``SUB'' is combined with constituency tag ``NP'' , which is presented as ``NP - SUB'' to indicate this noun phrase is a subject .
There are 18 constituency tags in VTB . The functional tags are used to enrich information for syntactic trees , such as where functional tag ``SUB'' is combined with constituency tag ``NP'' , which is presented as ``NP - SUB'' to indicate this noun phrase is a subject .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0

Alignment 822
There are 17 functional tags in VTB . The head word of a phrase is annotated with functional tag ``H'' .
There are 17 functional tags in VTB . The head word of a phrase is annotated with functional tag ``H'' .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 823
The phrase structures of Vietnamese include three positions : \emph , \emph , and \emph \cite .
The phrase structures of Vietnamese include three positions : \emph , \emph , and \emph \cite .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 824
The head word of the phrase is in the <head> position .
The head word of the phrase is in the <head> position .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 825
The words that are in the <pre - head> and <post - head> positions are modifiers of the head word .
The words that are in the <pre - head> and <post - head> positions are modifiers of the head word .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 826
There are special types of nouns in Vietnamese that we have called Nc - nouns in this paper .
There are special types of nouns in Vietnamese that we have called Nc - nouns in this paper .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 827
Nc - nouns can be classifier nouns ( Nc ) , or common nouns ( N ) depending on their modifiers .
Nc - nouns can be classifier nouns ( Nc ) , or common nouns ( N ) depending on their modifiers .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 828
For example , the Nc - noun \emph is a classifier noun if its modifier is the word \textviet , which means a specific fish , similar to \emph in English ) .
For example , the Nc - noun \emph is a classifier noun if its modifier is the word \textviet , which means a specific fish , similar to \emph in English ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0

Alignment 829
However , the Nc - noun \emph is a common noun if its modifier is the word \textviet , which means \emph in English ) .
However , the Nc - noun \emph is a common noun if its modifier is the word \textviet , which means \emph in English ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 830
We found that Nc - nouns always appeared in the head positions of noun phrases by investigating the VTB corpus .
We found that Nc - nouns always appeared in the head positions of noun phrases by investigating the VTB corpus .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 831
There is currently little consensus as to what the methodology is for annotating Nc - nouns \cite .
There is currently little consensus as to what the methodology is for annotating Nc - nouns \cite .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 832
Nguyen et al . \shortcite described methods of detecting and correcting WS inconsistencies in the VTB corpus .
Nguyen et al . \shortcite described methods of detecting and correcting WS inconsistencies in the VTB corpus .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 833
These methods focused on two types of WS inconsistencies in variation and structure , which are defined below .
These methods focused on two types of WS inconsistencies in variation and structure , which are defined below .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 834
\emph are sequences of tokens that have more than one way of being segmented in the corpus .
\emph are sequences of tokens that have more than one way of being segmented in the corpus .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 835
\emph occur when different sequences have similar structures , and thus should be split in the same way , but are segmented in different ways in the corpus .
\emph occur when different sequences have similar structures , and thus should be split in the same way , but are segmented in different ways in the corpus .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 836
Nguyen et al . \shortcite pointed out three typical cases of structural inconsistencies that were analyzed as classifier nouns ( Nc ) , affixes ( S ) , and special characters .
Nguyen et al . \shortcite pointed out three typical cases of structural inconsistencies that were analyzed as classifier nouns ( Nc ) , affixes ( S ) , and special characters .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0

Alignment 837
Nguyen et al .\shortcite analyzed N - gram sequences and phrase structures to detect WS inconsistencies .
Nguyen et al .\shortcite analyzed N - gram sequences and phrase structures to detect WS inconsistencies .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 838
Then , the detected WS inconsistencies were classified into several patterns of inconsistencies , parts of which were manually fixed to improve the quality of the corpus .
Then , the detected WS inconsistencies were classified into several patterns of inconsistencies , parts of which were manually fixed to improve the quality of the corpus .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0

Alignment 839
The rest were used to create different versions of the VTB corpus .
The rest were used to create different versions of the VTB corpus .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 840
These data sets were evaluated on automatic WS and its applications to text classification and English - Vietnamese statistical machine translations to find appropriate criteria for automatic WS and its applications .
These data sets were evaluated on automatic WS and its applications to text classification and English - Vietnamese statistical machine translations to find appropriate criteria for automatic WS and its applications .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0

Alignment 841
Their experiments revealed that the VAR\_FREQ data set achieved excellent results in these applications .
Their experiments revealed that the VAR\_FREQ data set achieved excellent results in these applications .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 842
The VAR\_FREQ data set was the original VTB corpus with manually corrected structural inconsistencies in special characters and selected segmentations with higher frequencies in all detected variations .
The VAR\_FREQ data set was the original VTB corpus with manually corrected structural inconsistencies in special characters and selected segmentations with higher frequencies in all detected variations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0

Alignment 843
Therefore , we used the VAR\_FREQ data set in our experiments .
Therefore , we used the VAR\_FREQ data set in our experiments .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 844
We propose two kinds of methods of detecting and correcting inconsistencies .
We propose two kinds of methods of detecting and correcting inconsistencies .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 845
They correspond to two different types of POS inconsistencies that we call multi - POS inconsistencies ( MI ) and Nc inconsistencies ( NcI ) , which are defined as follows .
They correspond to two different types of POS inconsistencies that we call multi - POS inconsistencies ( MI ) and Nc inconsistencies ( NcI ) , which are defined as follows .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0

Alignment 846
\emph are words that are not Nc - nouns and have more than one POS tag at each position in each phrase category .
\emph are words that are not Nc - nouns and have more than one POS tag at each position in each phrase category .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 847
\emph are sequences of Nc - nouns and modifiers , in which Nc - nouns have more than one way of being annotated as POSs in the VTB corpus .
\emph are sequences of Nc - nouns and modifiers , in which Nc - nouns have more than one way of being annotated as POSs in the VTB corpus .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0

Alignment 848
We separated the POS inconsistencies into these two types of inconsistencies because Nc - nouns are special types of words in Vietnamese .
We separated the inconsistencies with POSs into these two types of inconsistencies because Nc - nouns are special types of words in Vietnamese .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0

Alignment 849
The methods of detecting and correcting Nc inconsistencies were language - specific methods developed based on the characteristics of Vietnamese .
The methods of detecting and correcting Nc inconsistencies were language - specific methods developed based on the characteristics of Vietnamese .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 850
However , as the methods for MI are rather general , they can be applied to other languages .
However , as the methods for MI are rather general , they can be applied to other languages .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 851
\emph
\emph
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0

Alignment 852
Our main problem was to distinguish multi - POS inconsistencies from polysemous words , since polysemous words should not be considered inconsistent for annotations .
Our main problem was to distinguish multi - POS inconsistencies from polysemous words , since polysemous words should not be considered inconsistent for annotations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 853
Our method was based on the position of words in phrases and phrase categories .
Our method was based on the position of words in phrases and phrase categories .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 854
This idea resulted from the observation that polysemous words have many POS tags; however , each word usually has only one true POS tag at each position in each phrase category .
This idea resulted from the observation that polysemous words have many POS tags; however , each word usually has only one true POS tag at each position in each phrase category .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0

Alignment 855
For example , when a phrase category is a verb phrase , the word \emph in the pre - head position of the verb phrase \emph should be a modal , but the word \emph in the head position should be a verb .
For example , when a phrase category is a verb phrase , the word \emph in the pre - head position of the verb phrase \emph should be a modal , but the word \emph in the head position should be a verb .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0

Alignment 856
Further , the word \emph in the head position of a noun phrase \emph should be a noun , but the word \emph in the head position of the verb phrase \emph should be a verb .
Further , the word \emph in the head position of a noun phrase \emph should be a noun , but the word \emph in the head position of the verb phrase \emph should be a verb .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0

Alignment 857
This may be more frequent in Vietnamese because it is not an inflectional language i .e . , the word form does not change according to tenses , word categories ( e .g . , nouns , verbs , and adjectives ) , or number ( singular and plural ) .
This may be more frequent in Vietnamese because it is not an inflectional language i .e . , the word form does not change according to tenses , word categories ( e .g . , nouns , verbs , and adjectives ) , or number ( singular and plural ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0
49:1			49:1			0		1.0
50:1			50:1			0		1.0

Alignment 858
The method involved three steps .
The method involved three steps .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0

Alignment 859
First , we extracted words in the same position for each phrase category .
First , we extracted words in the same position for each phrase category .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 860
Second , we counted the number of different POS tags of each word .
Second , we counted the number of different POS tags of each word .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 861
Words that had more than one POS tag were determined to be multi - POS inconsistencies .
Words that had more than one POS tag were determined to be multi - POS inconsistencies .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 862
For example , in the following two preposition phrases , \textviet , the words \textviet appear at the head positions of both phrases , but they are annotated with different POS tags , i .e . , preposition ( E ) and conjunction ( C ) .
For example , in the following two preposition phrases , \textviet , the words \textviet appear at the head positions of both phrases , but they are annotated with different POS tags , i .e . , preposition ( E ) and conjunction ( C ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0

Alignment 863
Therefore , they are multi - POS inconsistencies according to our method .
Therefore , they are multi - POS inconsistencies according to our method .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 864
It should be noted that this method was applied to words that were direct children of a phrase . Embedded phrases , such as \textviet , were considered separately .
It should be noted that this method was applied to words that were direct children of a phrase . Embedded phrases , such as \textviet , were considered separately .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0

Alignment 865
A multi - POS inconsistency detected with the MI\_DM method is denoted by \emph , where \emph is a POS tag of word \emph , \emph is the frequency of POS tag \emph and AC involves applying the condition of \emph .
A multi - POS inconsistency detected with the MI\_DM method is denoted by \emph , where \emph is a POS tag of word \emph , \emph is the frequency of POS tag \emph and AC involves applying the condition of \emph .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0

Alignment 866
Our method of correcting the POS tag for POS inconsistency \emph involves two steps .
Our method of correcting the POS tag for POS inconsistency \emph involves two steps .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 867
First , we select the POS tag with the highest frequency of all POS tags of \emph ( \emph ) . Second , we replace POS tags \emph of all instances \emph satisfying condition \emph with POS tag \emph .
First , we select the POS tag with the highest frequency of all POS tags of \emph ( \emph ) . Second , we replace POS tags \emph of all instances \emph satisfying condition \emph with POS tag \emph .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0

Alignment 868
For multi POS inconsistencies , AC of word \emph is its phrase category and position in the phrase .
The AC of word \emph for multi - POS inconsistencies is its phrase category and position in the phrase .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			5:1			0		1.0
2:1			6:1			0		1.0
3:1			7:1			0		1.0
4:1			8:1			0		1.0
6:1			1:1			0		1.0
8:1			2:1			0		1.0
9:1			3:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0

Alignment 869
For example , \textviet is a multi - POS inconsistency in the pre - head position of a noun phrase .
For example , \textviet is a multi - POS inconsistency in the pre - head position of a noun phrase .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 870
The frequency of POS tag ``L'' is 27 and the frequency of POS tag ``P'' is 2 .
The frequency of POS tag ``L'' is 27 and the frequency of POS tag ``P'' is two .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			2		1.0
17:1			17:1			0		1.0

Alignment 871
Therefore , ``L'' is the POS tag that was selected by the MI\_CM method .
Therefore , ``L'' is the POS tag that was selected by the MI\_CM method .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 872
We replace all POS tags \emph of instances \textviet in the pre - head positions of noun phrases with POS tag ``L'' .
We replace all POS tags \emph of instances \textviet in the pre - head positions of noun phrases with POS tag ``L'' .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 873
As mentioned in Section \ref , an Nc - noun can be annotated with POS tag ``Nc'' or ``N'' depending on the modifier that follows that Nc - noun .
As mentioned in Section \ref , an Nc - noun can be annotated with POS tag ``Nc'' or ``N'' depending on the modifier that follows that Nc - noun .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0

Alignment 874
Analyzing the VTB corpus revealed that Nc - nouns had two characteristics .
Analyzing the VTB corpus revealed that Nc - nouns had two characteristics .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 875
First , an Nc - noun that is followed by the same word is usually annotated with the same POS tag . Second , an Nc - noun that is followed by a phrase or nothing at each occurrence is annotated with the same POS tag .
First , an Nc - noun that is followed by the same word is usually annotated with the same POS tag . Second , an Nc - noun that is followed by a phrase or nothing at each occurrence is annotated with the same POS tag .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0

Alignment 876
Based on these two cases , we propose two methods of detecting Nc inconsistencies , which we have called NcI\_DM1 and NcI\_DM2 . They are described below .
Based on these two cases , we propose two methods of detecting Nc inconsistencies , which we have called NcI\_DM1 and NcI\_DM2 . They are described below .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0

Alignment 877
\emph : We counted Nc - nouns in VTB that had two or more ways of POS annotation , satisfying the condition that Nc - nouns are followed by a phrase or nothing .
\emph : We counted Nc - nouns in VTB that had two or more ways of being annotated as POSs , satisfying the condition that Nc - nouns are followed by a phrase or nothing .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
17:1			17:1			1		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
33:1			31:1			0		1.0
34:1			32:1			0		1.0
35:1			33:1			0		1.0

Alignment 878
For example , the Nc - noun \emph in \emph is followed by nothing or it is followed by a prepositional phrase as in \textviet .
For example , the Nc - noun \emph in \emph is followed by nothing or it is followed by a prepositional phrase as in \textviet .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 879
\emph : We counted two - gram sequences beginning with an Nc - noun in VTB that had two or more ways of POS annotation of the Nc - noun , satisfying the conditions that two tokens were all in the same phrase and they all had the same depth in a phrase .
\emph : We counted two - gram sequences beginning with an Nc - noun in VTB that had two or more ways of being annotated as POSs of the Nc - noun , satisfying the conditions that two tokens were all in the same phrase and they all had the same depth in a phrase .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
24:1			24:1			1		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
33:1			31:1			0		1.0
34:1			32:1			0		1.0
35:1			33:1			0		1.0
36:1			34:1			0		1.0
37:1			35:1			0		1.0
38:1			36:1			0		1.0
39:1			37:1			0		1.0
40:1			38:1			0		1.0
41:1			39:1			0		1.0
42:1			40:1			0		1.0
43:1			41:1			0		1.0
44:1			42:1			0		1.0
45:1			43:1			0		1.0
46:1			44:1			0		1.0
47:1			45:1			0		1.0
48:1			46:1			0		1.0
49:1			47:1			0		1.0
50:1			48:1			0		1.0
51:1			49:1			0		1.0
52:1			50:1			0		1.0
53:1			51:1			0		1.0
54:1			52:1			0		1.0
55:1			53:1			0		1.0

Alignment 880
For example , the Nc - noun \emph in the two - gram \textviet was sometimes annotated ``Nc'' , and sometimes annotated ``N'' in VTB; in addition , as \emph and \textviet in the structure \textviet were in the same phrase and had the same depth , \emph was an Nc inconsistency .
For example , the Nc - noun \emph in the two - gram \textviet was sometimes annotated ``Nc'' , and sometimes annotated ``N'' in VTB; in addition , as \emph and \textviet in the structure \textviet were in the same phrase and had the same depth , \emph was an Nc inconsistency .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0
49:1			49:1			0		1.0
50:1			50:1			0		1.0
51:1			51:1			0		1.0
52:1			52:1			0		1.0

Alignment 881
We denoted Nc inconsistencies with \emph similarly to multi - POS inconsistencies .
We denoted Nc inconsistencies with \emph similarly to multi - POS inconsistencies .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 882
We also replaced the POS tag of Nc - nouns with the highest frequency tag .
We also replaced the POS tag of Nc - nouns with the highest frequency tag .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 883
The only differences were the applying conditions which varied according to the previous two cases of Nc inconsistencies .
The only differences were the conditions of application that varied according to the previous two cases of Nc inconsistencies .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			6:1			0		1.0
7:1			5:1			3		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0

Alignment 884
For Nc inconsistencies detected by the NcI\_DM1 method , AC is defined as follows : \emph is an Nc - noun that is followed by nothing or a phrase .
For Nc inconsistencies detected by the NcI\_DM1 method , AC is defined as follows : \emph is an Nc - noun that is followed by nothing or a phrase .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0

Alignment 885
For Nc inconsistencies detected by the NcI\_DM2 method , AC is defined as follows : \emph a Nc - noun that must be followed by a word , \emph .
For Nc inconsistencies detected by the NcI\_DM2 method , AC is defined as follows : \emph a Nc - noun that must be followed by a word , \emph .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0

Alignment 886
We detected and corrected multi - POS inconsistencies and Nc inconsistencies based on the two data sets of ORG and VAR\_FREQ .
We detected and corrected multi - POS inconsistencies and Nc inconsistencies based on the two data sets of ORG and VAR\_FREQ .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 887
The ORG data set was the original VTB corpus and VAR\_FREQ was the original corpus with modifications to WS annotation .
The ORG data set was the original VTB corpus and VAR\_FREQ was the original corpus with modifications to WS annotation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 888
This setting was made similar to that used by Nguyen et al . \shortcite to enable comparison .
This setting was made similar to that used by Nguyen et al . \shortcite to enable comparison .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 889
There are a total of 128 ,871 phrases in the VTB corpus .
There are a total of 128 ,871 phrases in the VTB corpus .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 890
The top five types of phrases are noun phrases ( NPs ) ( representing 49 .6\% of the total number of phrases ) , verb phrases ( VPs ) , prepositional phrases ( PP ) , adjectival phrases ( ADJPs ) , and quantity phrases ( QP ) , representing 99 .1\% of the total number of phrases in the VTB corpus .
The top five types of phrases are noun phrases ( NPs ) ( representing 49 .6\% of the total number of phrases ) , verb phrases ( VPs ) , prepositional phrases ( PP ) , adjectival phrases ( ADJPs ) , and quantity phrases ( QP ) , representing 99 .1\% of the total number of phrases in the VTB corpus .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0
49:1			49:1			0		1.0
50:1			50:1			0		1.0
51:1			51:1			0		1.0
52:1			52:1			0		1.0
53:1			53:1			0		1.0
54:1			54:1			0		1.0
55:1			55:1			0		1.0
56:1			56:1			0		1.0
57:1			57:1			0		1.0
58:1			58:1			0		1.0
59:1			59:1			0		1.0
60:1			60:1			0		1.0
61:1			61:1			0		1.0
62:1			62:1			0		1.0

Alignment 891
We analyzed the VTB corpus based on these five types of phrases .
We analyzed the VTB corpus based on these five types of phrases .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 892
Tables \ref and \ref show overall statistics for multi - POS inconsistencies and Nc inconsistencies for each phrase category .
Tables \ref and \ref summarize the overall statistics for multi - POS inconsistencies and Nc inconsistencies for each phrase category .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0

Alignment 893
The second and third columns in these tables indicate the numbers of inconsistencies and their instances that were detected in the ORG data set .
The second and third columns in these tables indicate the numbers of inconsistencies and their instances that were detected in the ORG data set .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 894
The fourth and fifth columns indicate the numbers of inconsistencies and their instances that were detected in the VAR\_FREQ data set . The rows in Table \ref indicate the number of Nc inconsistencies and the number of instances detected with the NcI\_DM1 and NcI\_DM2 methods .
The fourth and fifth columns indicate the numbers of inconsistencies and their instances that were detected in the VAR\_FREQ data set . The rows in Table \ref indicate the number of Nc inconsistencies and the number of instances detected with the NcI\_DM1 and NcI\_DM2 methods .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0

Alignment 895
According to Table \ref , most of the multi - POS inconsistencies occurred in noun phrases , representing more than 72\% of the total number of multi - POS inconsistencies .
According to Table \ref , most of the multi - POS inconsistencies occurred in noun phrases , representing more than 72\% of the total number of multi - POS inconsistencies .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0

Alignment 896
All Nc inconsistencies in Table \ref are also in noun phrases .
All Nc inconsistencies in Table \ref are also in noun phrases .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 897
There are two possible reasons for this .
There are two possible reasons for this .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 898
First , noun phrases represent the majority of phrases in VTB ( represent 49 .6\% of the total number of phrases in the VTB corpus ) .
First , noun phrases represent the majority of phrases in VTB ( represent 49 .6\% of the total number of phrases in the VTB corpus ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 899
Second , nouns are sub - divided into many other types ( common nouns ( N ) , classifier nouns ( Nc ) , proper nouns ( Np ) , and unit nouns ( Nu ) ) ( mentioned in Section \ref , which may confuse annotators in annotating POS tags for nouns .
Second , nouns are sub - divided into many other types ( common nouns ( N ) , classifier nouns ( Nc ) , proper nouns ( Np ) , and unit nouns ( Nu ) ) ( mentioned in Section \ref , which may confuse annotators in annotating POS tags for nouns .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0
49:1			49:1			0		1.0
50:1			50:1			0		1.0
51:1			51:1			0		1.0
52:1			52:1			0		1.0
53:1			53:1			0		1.0

Alignment 900
In addition , the high number of Nc inconsistencies in Table \ref indicate that it is difficult to distinguish between Nc and other types of nouns .
In addition , the high number of Nc inconsistencies in Table \ref indicate that it is difficult to distinguish between Nc and other types of nouns .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 901
Therefore , we need to have clearer annotation guidelines for this .
Therefore , we need to have clearer annotation guidelines for this .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 902
We estimated the accuracy with which our methods detected and corrected inconsistencies in POS tagging by manually inspecting inconsistent annotations .
We estimated the accuracy with which our methods detected and corrected inconsistencies in POS tagging by manually inspecting inconsistent annotations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 903
We manually inspected the two data sets of ORG\_EVAL and ORG\_POS\_EVAL .
We manually inspected the two data sets of ORG\_EVAL and ORG\_POS\_EVAL .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 904
For ORG\_EVAL , we randomly selected 100 sentences which contained instances of POS inconsistencies in the ORG data set .
We randomly selected 100 sentences in ORG\_EVAL , which contained instances of POS inconsistencies in the ORG data set .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			4:1			0		1.0
2:1			5:1			0		1.0
3:1			6:1			0		1.0
4:1			7:1			0		1.0
6:1			1:1			0		1.0
7:1			2:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 905
ORG\_EVAL contained 459 instances of 157 POS inconsistencies .
ORG\_EVAL contained 459 instances of 157 POS inconsistencies .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 906
ORG\_POS\_EVAL was the ORG\_EVAL data set with corrections made to multi - POS inconsistencies and Nc inconsistencies with our methods of correction above .
ORG\_POS\_EVAL was the ORG\_EVAL data set with corrections made to multi - POS inconsistencies and Nc inconsistencies with our methods of correction above .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 907
We manually checked POS inconsistencies and found that 153 cases out of 157 POS inconsistencies ( 97 .5\% ) were actual inconsistencies .
We manually checked POS inconsistencies and found that 153 cases out of 157 POS inconsistencies ( 97 .5\% ) were actual inconsistencies .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 908
There were four cases that our method detected as multi - POS inconsistencies , but they were actually ambiguities in Vietnamese POS tagging .
There were four cases that our method detected as multi - POS inconsistencies , but they were actually ambiguities in Vietnamese POS tagging .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 909
They were polysemous words whose meanings and POS tags depended on surrounding words , but did not depend on their positions in phrases .
They were polysemous words whose meanings and POS tags depended on surrounding words , but did not depend on their positions in phrases .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 910
For example , the word \textviet in the post - head positions of the verb phrases VP1 and VP2 below , can be a noun that means\emph in English , or it can be an adjective that means \emph , depending on the preceding verb .
For example , the word \textviet in the post - head positions of the verb phrases VP1 and VP2 below , can be a noun that means\emph in English , or it can be an adjective that means \emph , depending on the preceding verb .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0

Alignment 911
We analyzed the detected POS inconsistencies to find the reasons for inconsistent POS annotations .
We analyzed the detected POS inconsistencies to find the reasons for inconsistent POS annotations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 912
We classified the detected POS inconsistencies according to pairs of their POS tags .
We classified the detected POS inconsistencies according to pairs of POS tags .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0

Alignment 913
There were a total of 85 patterns of pairs of POS tags . Table \ref lists the top five confusing patterns ( PoPOS ) , their counts of inconsistencies ( counts ) , and examples .
There were a total of 85 patterns of pairs of POS tags . Table \ref lists the top five confusing patterns ( PoPOS ) , their counts of inconsistencies ( counts ) , and examples .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0

Alignment 914
It also seemed to be extremely confusing for the annotators to distinguish types of nouns ( Nc and N , and N and Np ) and distinguish nouns from other types of words ( such as verbs , adjectives , and pronouns ) .
It also seemed to be extremely confusing for the annotators to distinguish types of nouns ( Nc and N , and N and Np ) and distinguish nouns from other types of words ( such as verbs , adjectives , and pronouns ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0

Alignment 915
We investigated POS inconsistencies and the annotation guidelines \cite to find why common nouns were sometimes tagged as classifier nouns and vice versa , and verbs were sometimes tagged as common nouns and vice versa .
We investigated POS inconsistencies and the annotation guidelines \cite to find why common nouns were sometimes tagged as classifier nouns and vice versa , and verbs were sometimes tagged as common nouns and vice versa .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0

Alignment 916
We found that these POS inconsistencies belonged to polysemous words that were difficult to tag .
We found that these POS inconsistencies belonged to polysemous words that were difficult to tag .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 917
The difficulties with tagging polysemous words were due to four main reasons :
The difficulties with tagging polysemous words were due to four main reasons :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 918
( 1 ) The POS of a polysemous word changes according to the function of that polysemous word in each phrase category or changes according to the meaning of surrounding words .
( 1 ) The POS of a polysemous word changes according to the function of that polysemous word in each phrase category or changes according to the meaning of surrounding words .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0

Alignment 919
Although polysemous words are annotated with different POS tags , they do not change their word form .
Although polysemous words are annotated with different POS tags , they do not change their word form .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 920
( 2 ) The way polysemous words are tagged according to their context is not completely clear in the POS tagging guidelines .
( 2 ) The way polysemous words are tagged according to their context is not completely clear in the POS tagging guidelines .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 921
( 3 ) Annotators referred to a dictionary that had been built as part of the VLSP project \cite ( VLSP dictionary ) to annotate the VTB corpus .
( 3 ) Annotators referred to a dictionary that had been built as part of the VLSP project \cite ( VLSP dictionary ) to annotate the VTB corpus .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 922
However , this dictionary lacked various words and did not cover all contexts for the words .
However , this dictionary lacked various words and did not cover all contexts for the words .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 923
For example , \textviet in Vietnamese is an adjective when it is the head word of an adjectival phrase , but \textviet is an adverb when it is the modifier of a quantifier noun ( such as \textviet .
For example , \textviet in Vietnamese is an adjective when it is the head word of an adjectival phrase , but \textviet is an adverb when it is the modifier of a quantifier noun ( such as \textviet .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0

Alignment 924
However , the VLSP dictionary only considered \textviet to be an adjective ( \textviet ) .
However , the VLSP dictionary only considered \textviet to be an adjective ( \textviet ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 925
No cases where \textviet was an adverb were mentioned in this dictionary .
No cases where \textviet was an adverb were mentioned in this dictionary .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 926
( 4 ) There are several overlapping but conflicting instructions across the annotation guidelines for different layers of the treebank .
( 4 ) There are several overlapping but conflicting instructions across the annotation guidelines for different layers of the treebank .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 927
For example , the combinations of affixes and words they modify to create compound words are clear in the WS guidelines , but POS tagging guidelines treat affixes as words and they are annotated as POS tags ``S'' .
For example , the combinations of affixes and words they modify to create compound words are clear in the WS guidelines , but POS tagging guidelines treat affixes as words and they are annotated as POS tags ``S'' .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0

Alignment 928
For words modifying quantifier nouns , such as \textviet , the POS tagging guidelines treat them as adjectives , but the bracketing guidelines treat them as adverbs .
For words modifying quantifier nouns , such as \textviet , the POS tagging guidelines treat them as adjectives , but the bracketing guidelines treat them as adverbs .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0

Alignment 929
Therefore , our method detected multi - POS inconsistencies as \textviet , \emph at the pre - head positions of noun phrases .
Therefore , our method detected multi - POS inconsistencies as \textviet , \emph at the pre - head positions of noun phrases .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 930
Since the frequencies of the adjective tags were greater than those of adverb tags ( fA > fR ) , these words were automatically assigned to adjective POS tags ( A ) according to our method of correction .
Since the frequencies of the adjective tags were greater than those of adverb tags ( fA > fR ) , these words were automatically assigned to adjective POS tags ( A ) according to our method of correction .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0

Alignment 931
These were POS inconsistencies that our method of correction could not be applied to , because the frequency of incorrect POS tags was higher than that of actual POS tags .
These were POS inconsistencies that our method of correction could not be applied to , because the frequency of incorrect POS tags was higher than that of actual POS tags .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0

Alignment 932
We carried out experiments to evaluate two popular parsers , a syntactic parser and a dependency parser , on different versions of the VTB corpus .
We carried out experiments to evaluate two popular parsers , a syntactic parser and a dependency parser , on different versions of the VTB corpus .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 933
Some of these data sets were made the same as the data settings for WS in Nguyen et al . \shortcite .
Some of these data sets were made the same as the data settings for WS in Nguyen et al . \shortcite .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 934
The other data sets contained changes in POS annotations following our methods of correcting inconsistencies presented in Section \ref .
The other data sets contained changes in POS annotations following our methods of correcting inconsistencies presented in Section \ref .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 935
We could observe how the problems with WS and POS tagging influenced the quality of Vietnamese parsing by analyzing the parsing results .
We could observe how the problems with WS and POS tagging influenced the quality of Vietnamese parsing by analyzing the parsing results .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 936
Data . Nine configurations of the VTB corpus were created as follows :
Data . Nine configurations of the VTB corpus were created as follows :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 937
ORG : The original VTB corpus .
ORG : The original VTB corpus .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0

Alignment 938
BASE , STRUCT\_AFFIX , STRUCT\_NC , VAR\_SPLIT , VAR\_COMB , and VAR\_FREQ correspond to different settings for WS described in Nguyen et al .\shortcite .
BASE , STRUCT\_AFFIX , STRUCT\_NC , VAR\_SPLIT , VAR\_COMB , and VAR\_FREQ correspond to different settings for WS described in Nguyen et al .\shortcite .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 939
ORG\_POS : The ORG data set with corrections for multi - POS inconsistencies and Nc inconsistencies by using the methods in Section \ref and \ref .
ORG\_POS : The ORG data set with corrections for multi - POS inconsistencies and Nc inconsistencies by using the methods in Section \ref and \ref .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 940
VAR\_FREQ\_POS : The VAR\_FREQ data set with corrections for multi - POS inconsistencies and Nc inconsistencies by using the methods in Section \ref and \ref .
VAR\_FREQ\_POS : The VAR\_FREQ data set with corrections for multi - POS inconsistencies and Nc inconsistencies by using the methods in Section \ref and \ref .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 941
Each of the nine data sets was randomly split into two subsets for training and testing our parser models .
Each of the nine data sets was randomly split into two subsets for training and testing our parser models .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 942
The training set contained 9 ,443 sentences , and the testing set contained 1 ,000 sentences .
The training set contained 9 ,443 sentences , and the testing set contained 1 ,000 sentences .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 943
Tools
Tools
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0

Alignment 944
We used the Berkeley parser \cite to evaluate the syntactic parser on VTB .
We used the Berkeley parser \cite to evaluate the syntactic parser on VTB .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 945
This parser has been used in experiments in English , German , and Chinese and achieved an F1 of 90 .2\% on the English Penn Treebank .
This parser has been used in experiments in English , German , and Chinese and achieved an F1 of 90 .2\% on the English Penn Treebank .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 946
We used the conversion tool built by Johansson et al . \shortcite to convert VTB into dependency trees .
We used the conversion tool built by Johansson et al . \shortcite to convert VTB into dependency trees .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 947
We used the MST parser to evaluate the dependency parsing on VTB .
We used the MST parser to evaluate the dependency of parsing on VTB .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0

Alignment 948
This parser was evaluated on the English Penn Treebank \cite and 13 other languages \cite .
This parser was evaluated on the English Penn Treebank \cite and 13 other languages \cite .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 949
Its accuracy achieved 90 .7\% on the English Penn Treebank .
Its accuracy achieved 90 .7\% on the English Penn Treebank .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 950
We made use of the bracket scoring program EVALB , which was built by Sekine et al . ( 1997 ) , to evaluate the performance of the Berkeley parser .
We made use of the bracket scoring program EVALB , which was built by Sekine et al . ( 1997 ) , to evaluate the performance of the Berkeley parser .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0

Alignment 951
As an evaluation tool was included in the MST parser tool , we used it to evaluate the MST parser .
As an evaluation tool was included in the MST parser tool , we used it to evaluate the MST parser .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 952
The bracketing F - measures of the Berkeley parser on nine configurations of the VTB corpus are listed in Table \ref .
The bracketing F - measures of the Berkeley parser on nine configurations of the VTB corpus are listed in Table \ref .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 953
The dependency of the MST parser on nine configurations of the VTB corpus are shown in Table \ref .
The dependency of the MST parser on the accuracies of nine configurations of the VTB corpus are summarized in Table \ref .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0

Alignment 954
These results indicate that the quality of the treebank strongly affected the quality of the parsers .
These results indicate that the quality of the treebank strongly affected the quality of the parsers .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 955
According to Table \ref , all modifications to WS inconsistencies improved the performance of the Berkeley parser except for STRUCT\_NC and VAR\_SPLIT .
According to Table \ref , all modifications to WS inconsistencies improved the performance of the Berkeley parser except for STRUCT\_NC and VAR\_SPLIT .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 956
More importantly , the ORG\_POS model achieved better results than the ORG model , and the VAR\_FREQ\_POS model achieved better results than the VAR\_FREQ model , which indicates that the modifications to POS inconsistencies improved the performance of the Berkeley parser .
More importantly , the ORG\_POS model achieved better results than the ORG model , and the VAR\_FREQ\_POS model achieved better results than the VAR\_FREQ model , which indicates that the modifications to POS inconsistencies improved the performance of the Berkeley parser .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0

Alignment 957
The VAR\_FREQ\_POS model scored 1 .11 points higher than ORG , which is a significant improvement .
The VAR\_FREQ\_POS model scored 1 .11 points higher than ORG , which is a significant improvement .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 958
Dependency accuracies of the MST parser in Table \ref shown that all modifications to POS inconsistencies improved the performance of the MST parser .
The dependency of the MST parser on accuracies in Table \ref indicates that all modifications to POS inconsistencies improved the performance of the MST parser .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			1:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			2		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0

Alignment 959
All modifications of WS inconsistencies also improved the performance of the MST parser except for STRUCT\_NC .
All modifications to WS inconsistencies also improved the performance of the MST parser except for STRUCT\_NC .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 960
The VAR\_FREQ\_POS model scored 7 .36 points higher than ORG , which is a significant improvement .
The VAR\_FREQ\_POS model scored 7 .36 points higher than ORG , which is a significant improvement .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 961
The results for the Berkeley parser and MST parser trained on the POS - modified versions of VTB were better than those trained on the original VTB corpus , but they were still much lower than the performance of the same parsers on the English language .
The results for the Berkeley parser and MST parser trained on the POS - modified versions of VTB were better than those trained on the original VTB corpus , but they were still much lower than the performance of the same parsers on the English language .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0

Alignment 962
We analyzed error based on the output data of the best parsing results ( VAR\_FREQ\_POS ) for the Berkeley parser , and found that the unmatched annotations between gold and test data were caused by ambiguous POS sequences in the VTB corpus .
We analyzed error based on the output data of the best parsing results ( VAR\_FREQ\_POS ) for the Berkeley parser , and found that the unmatched annotations between gold and test data were caused by ambiguous POS sequences in the VTB corpus .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0

Alignment 963
An ambiguous POS sequence is a sequence of POS tags that has two or more constituency tags .
An ambiguous POS sequence is a sequence of POS tags that has two or more constituency tags .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 964
For example , there are the verb phrases \emph and the adjectival phrase \emph in the training data of VAR\_FREQ\_POS .
For example , there are the verb phrases \emph and the adjectival phrase \emph in the training data of VAR\_FREQ\_POS .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 965
As these two phrases have the same POS sequence \emph , \emph is an ambiguous POS sequence , and VP and ADJP are confusing constituency tags ( CCTs ) .
As these two phrases have the same POS sequence \emph , \emph is an ambiguous POS sequence , and VP and ADJP are confusing constituency tags ( CCTs ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0

Alignment 966
We found 42 ,373 occurrences of 213 ambiguous POS sequences ( representing 37 .02\% of all phrases ) in the training data of VAR\_FREQ\_POS .
We found 42 ,373 occurrences of 213 ambiguous POS sequences ( representing 37 .02\% of all phrases ) in the training data of VAR\_FREQ\_POS .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 967
We also found 1 ,065 occurrences of 13 ambiguous POS sequences in the parsing results for VAR\_FREQ\_POS .
We also found 1 ,065 occurrences of 13 ambiguous POS sequences in the parsing results for VAR\_FREQ\_POS .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 968
Some examples of ambiguous POS sequences , their CCTs , and the number of occurrences of each CCT in the training data of VAR\_FREQ\_POS are listed in Table \ref .
Some examples of ambiguous POS sequences , their CCTs , and the number of occurrences of each CCT in the training data of VAR\_FREQ\_POS are listed in Table \ref .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0

Alignment 969
We classified the detected ambiguous POS sequences according to pairs of different CCTs to find the reasons for ambiguity in each pair .
We classified the detected ambiguous POS sequences according to pairs of different CCTs to find the reasons for ambiguity in each pair .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 970
There were a total of 42 pairs of CCTs , whose top three pairs , along with their counts of types of ambiguous POS sequences , and examples of ambiguous POS sequences are listed in Table \ref .
There were a total of 42 pairs of CCTs , whose top three pairs , along with their counts of types of ambiguous POS sequences , and examples of ambiguous POS sequences are listed in Table \ref .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0

Alignment 971
We extracted different POS tags at each position of each phrase category for each pair of CCTs , based on the ambiguous POS sequences .
We extracted different POS tags at each position of each phrase category for each pair of CCTs , based on the ambiguous POS sequences .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 972
For example , the third row in Table \ref has ``R A V'' and ``A V N'' , which are two ambiguous POS sequences that were sometimes annotated as VP and sometimes annotated as ADJP .
For example , the third row in Table \ref has ``R A V'' and ``A V N'' , which are two ambiguous POS sequences that were sometimes annotated as VP and sometimes annotated as ADJP .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0

Alignment 973
The different POS tags that were extracted from the pre - head positions of VPs based on these two POS sequences were ``R , A'' and ``R'' was the POS tag that was extracted from the pre - head positions of ADJPs based on these two POS sequences .
The different POS tags that were extracted from the pre - head positions of VPs based on these two POS sequences were ``R , A'' and ``R'' was the POS tag that was extracted from the pre - head positions of ADJPs based on these two POS sequences .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0

Alignment 974
These POS tags are important clues to finding reasons for ambiguities in POS sequences .
These POS tags are important clues to finding reasons for ambiguities in POS sequences .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 975
Table \ref summarizes the extracted POS tags at pre - head positions for the top three pairs of CCTs .
Table \ref summarizes the extracted POS tags at pre - head positions for the top three pairs of CCTs .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 976
For example , the POS tags in row NP - VP and column 1 are in the pre - head positions of NPs and the POS tags in row NP - VP and column 2 are in the pre - head positions of VP .
For example , the POS tags in row NP - VP and column 1 are in the pre - head positions of NPs and the POS tags in row NP - VP and column 2 are in the pre - head positions of VP .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0

Alignment 977
By comparing these results with the structures of the pre - head positions of phrase categories in the VTB bracketing guidelines \cite , we found many cases that were not annotated according to instructions in the VTB bracketing guidelines , such as those according to Table \ref , where an adjective ( A ) is in the pre - head position of VP , but according to the VTB bracketing guidelines , the structure of the pre - head position of VB only includes adverb ( R ) .
By comparing these results with the structures of the pre - head positions of phrase categories in the VTB bracketing guidelines \cite , we found many cases that were not annotated according to instructions in the VTB bracketing guidelines , such as those according to Table \ref , where an adjective ( A ) is in the pre - head position of VP , but according to the VTB bracketing guidelines , the structure of the pre - head position of VB only includes an adverb ( R ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0
49:1			49:1			0		1.0
50:1			50:1			0		1.0
51:1			51:1			0		1.0
52:1			52:1			0		1.0
53:1			53:1			0		1.0
54:1			54:1			0		1.0
55:1			55:1			0		1.0
56:1			56:1			0		1.0
57:1			57:1			0		1.0
58:1			58:1			0		1.0
59:1			59:1			0		1.0
60:1			60:1			0		1.0
61:1			61:1			0		1.0
62:1			62:1			0		1.0
63:1			63:1			0		1.0
64:1			64:1			0		1.0
65:1			65:1			0		1.0
66:1			66:1			0		1.0
67:1			67:1			0		1.0
68:1			68:1			0		1.0
69:1			69:1			0		1.0
70:1			70:1			0		1.0
71:1			71:1			0		1.0
72:1			72:1			0		1.0
73:1			73:1			0		1.0
74:1			74:1			0		1.0
75:1			75:1			0		1.0
76:1			76:1			0		1.0
77:1			77:1			0		1.0
78:1			78:1			0		1.0
79:1			79:1			0		1.0
80:1			80:1			0		1.0
81:1			81:1			0		1.0
82:1			82:1			0		1.0
83:1			83:1			0		1.0
85:1			84:1			0		1.0
86:1			85:1			0		1.0
87:1			86:1			0		1.0
88:1			87:1			0		1.0
89:1			88:1			0		1.0

Alignment 978
We investigated cases that had not been annotated according to the guidelines , and found two possible reasons that caused ambiguous POS sequences .
We investigated cases that had not been annotated according to the guidelines , and found two possible reasons that caused ambiguous POS sequences .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 979
First , although our methods improved the quality of the VTB corpus , some POS annotation errors remained in the VTB corpus .
First , although our methods improved the quality of the VTB corpus , some errors in POS annotations remained in the VTB corpus .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			16:1			0		1.0
15:1			18:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			1		1.0
18:1			17:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0

Alignment 980
These POS annotation errors were cases to which our methods could not be applied ( mentioned in Section \ref ) .
These errors in POS annotations were cases to which our methods could not be applied ( mentioned in Section \ref ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			3:1			0		1.0
3:1			1:1			0		1.0
4:1			2:1			1		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0

Alignment 981
Second , there were ambiguities in POS sequences caused by Vietnamese characteristics , such as the adjectival phrase \textviet and the noun phrase \emph that had the same POS sequence of ``R N A'' .
Second , there were ambiguities in POS sequences caused by Vietnamese characteristics , such as the adjectival phrase \textviet and the noun phrase \emph that had the same POS sequence of ``R N A'' .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0

Alignment 982
Therefore , POS annotation errors need to be eliminated from the VTB corpus to further improve its quality and that of the Vietnamese parser .
Therefore , POS annotation errors need to be eliminated from the VTB corpus to further improve its quality and that of the Vietnamese parser .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 983
We not only need to eliminate overlapping and conflicting instructions , which were mentioned in Section \ref , from the guidelines , but we also have to complete annotation instructions for cases that have not been treated ( or not been clearly treated ) in the guidelines .
We not only need to eliminate overlapping and conflicting instructions , which were mentioned in Section \ref , from the guidelines , but we also have to complete annotation instructions for cases that have not been treated ( or not been clearly treated ) in the guidelines .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0

Alignment 984
We may also need to improve POS tag set because adverbs modifying adjectives , nouns , and verbs are all presently tagged as ``R'' , which caused ambiguous POS sequences , such as the ambiguous POS sequence ``R N A'' mentioned above .
We may also need to improve POS tag set because adverbs modifying adjectives , nouns , and verbs are all presently tagged as ``R'' , which caused ambiguous POS sequences , such as the ambiguous POS sequence ``R N A'' mentioned above .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0

Alignment 985
If we use different POS tags for the adverb \textviet , which modifies the adjective \textviet , and the adverb \textviet , which modifies the noun \textviet , we can eliminate ambiguous POS sequences in these cases .
If we use different POS tags for the adverb \textviet , which modifies the adjective \textviet , and the adverb \textviet , which modifies the noun \textviet , we can eliminate ambiguous POS sequences in these cases .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0

Alignment 986
We proposed several methods of improving the quality of the VTB corpus .
We proposed several methods of improving the quality of the VTB corpus .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 987
Our manual evaluation revealed that our methods improved the quality of the VTB corpus by 6 .5\% with correct POS tags .
Our manual evaluation revealed that our methods improved the quality of the VTB corpus by 6 .5\% with correct POS tags .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 988
Analysis of inconsistencies and the annotation guidelines suggested that :
Analysis of inconsistencies and the annotation guidelines suggested that :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 989
( 1 ) better instructions should be added to the VTB guidelines to help annotators to distinguish difficult POS tags ,
( 1 ) better instructions should be added to the VTB guidelines to help annotators to distinguish difficult POS tags ,
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 990
( 2 ) overlapping and conflicting instructions should be eliminated from the VTB guidelines ,
( 2 ) overlapping and conflicting instructions should be eliminated from the VTB guidelines ,
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 991
and ( 3 ) annotations that referred to dictionaries should be avoided .
and ( 3 ) annotations that referred to dictionaries should be avoided .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 992
To the best of our knowledge , this paper is the first report on evaluating state - of - the - art parsers used on the Vietnamese language .
To the best of our knowledge , this paper is the first report on evaluating state - of - the - art parsers used on the Vietnamese language .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 993
The results obtained from evaluating these two parsers were used as feedback to improve the quality of treebank annotations .
The results obtained from evaluating these two parsers were used as feedback to improve the quality of treebank annotations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 994
We also thoroughly analyzed the parsing output , which revealed challenging issues in treebank annotations and in the Vietnamese parsing problem itself .
We also thoroughly analyzed the parsing output , which revealed challenging issues in treebank annotations and in the Vietnamese parsing problem itself .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 995
On the failure of Spatial Verification
Overcoming Spatial Verification Failure
Line2Start:Length	Line1Start:Length	Module		Score
1:1			4:1			0		1.0
2:1			5:1			0		1.0

Alignment 996
This paper proposes an object-centric boosting technique for visual instance search with more precise than existing ones .
An object-centric boosting technique for visual instance search that is more precise than existing ones is proposed .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			4:1			0		1.0
2:1			5:1			0		1.0
3:1			6:1			0		1.0
4:1			7:1			0		1.0
5:1			8:1			0		1.0
6:1			9:1			0		1.0
7:1			10:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:2			2:1			3		1.0
17:1			17:1			0		1.0

Alignment 997
A hybrid method is applied to solve the problem of lacking confidence when using standard spatial verification methods .
A hybrid method is applied to solve the problem of lacking confidence when using standard spatial verification methods .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 998
We classify pairs of verified visual words into three categories discriminative , weak relevant and context inferred pairs based on the relation with .
We classify pairs of verified visual words into three categories — discriminative , weak relevant , and context - inferred — on the basis of the relation of these words to the object proposal location .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
19:1			16:1			0		1.0
21:4			18:2			3		1.0
25:1			20:1			0		1.0
26:1			21:1			0		1.0
35:1			23:1			0		1.0

Alignment 999
In this paper , we use a Deformable Parts Model ( DPM ) detector to demonstrate .
In this work , we use a deformable parts model ( DPM ) detector to demonstrate the proposed technique .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
19:1			16:1			0		1.0

Alignment 1000
Three corresponding weighting functions are also proposed to compute final similarity score between query topic and shot video .
Three corresponding weighting functions are also proposed to compute the final similarity score between query topic and shot video .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0

Alignment 1001
We evaluate our method over datasets of TRECVID Instance Search . The experiments show that our method give a better performance on many kinds of query objects . It improve about 29.9% and 22.3% comparing to standard BOW and spatial verification model , respectively .
We evaluate our method using TRECVID Instance Search data sets and find that it performs better than conventional methods on many kinds of query objects , with improvements of about 29.9% and 22.3% compared to standard BOW and the spatial verification model , respectively .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
10:1			38:1			0		1.0
12:1			14:1			0		1.0
14:1			20:1			1		1.0
15:1			19:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0
24:1			26:1			0		1.0
25:1			42:1			0		1.0
28:1			6:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0
31:1			32:1			0		1.0
32:1			33:1			0		1.0
33:1			34:1			1		1.0
34:1			35:1			0		1.0
35:1			36:1			0		1.0
36:1			37:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0

Alignment 1002
This work is to address the problem of instance search or object retrieval in video databases including hundreds of thousands of shots made up of millions of frames .
The objective of this work is to address the problem of instance search or object retrieval in video databases that include hundreds of thousands of shots made up of millions of frames .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			26:1			0		1.0
4:1			1:1			0		1.0
5:1			2:1			0		1.0
6:1			3:1			0		1.0
7:1			4:1			0		1.0
8:1			5:1			0		1.0
9:1			6:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:2			16:1			3		1.0
21:1			17:1			0		1.0
22:1			18:1			0		1.0
23:1			19:1			0		1.0
24:1			20:1			0		1.0
25:1			21:1			0		1.0
26:1			22:1			0		1.0
27:1			23:1			0		1.0
28:1			24:1			0		1.0
29:1			25:1			0		1.0
31:1			27:1			0		1.0
32:1			28:1			0		1.0

Alignment 1003
The term instance search ( INS ) is defined formally by TRECVID \cite : finding video segments of a certain specific object , place or person , given a visual examples from video collection .
The term instance search ( INS ) is defined formally by TRECVID \cite as “finding video segments of a certain specific object , place , or person after being given visual examples from a video collection” .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			26:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
29:1			27:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			28:1			0		1.0
34:1			32:1			0		1.0
36:1			34:1			0		1.0

Alignment 1004
In practice , INS has many applications such as archive video search , law enforcement , brand-logo protection , personal video organization , surveillance .
In practice , INS has many applications , including archive video searching , law enforcement , brand-logo protection , personal video organization , and surveillance .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			22:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			1		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0

Alignment 1005
Most of the state of the art approaches follow the original bag-of-visual-word ( BOW ) model that has been first introduced by Sivic in case of video retrieval \cite .
Most of the conventional approaches follow the original bag-of-visual-word ( BOW ) model first introduced by Sivic in a case involving video retrieval \cite .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			7:1			0		1.0
5:1			8:1			0		1.0
6:1			9:1			0		1.0
7:1			10:1			0		1.0
8:1			11:1			0		1.0
9:1			12:1			0		1.0
10:1			13:1			0		1.0
11:1			14:1			0		1.0
12:1			15:1			0		1.0
13:1			19:1			0		1.0
14:1			20:1			0		1.0
15:1			21:1			0		1.0
16:1			22:1			0		1.0
17:1			23:1			0		1.0
19:1			24:1			0		1.0
21:1			26:1			0		1.0
22:1			27:1			0		1.0
23:1			28:1			0		1.0
24:1			29:1			0		1.0

Alignment 1006
This model relies on the key assumption that two similar image will share significant amount of local patches which can be matched against each other .
This model relies on the key assumption that two similar images will share a significant amount of local patches that can be matched against each other .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			1		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:2			18:2			3		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0

Alignment 1007
Using sparse feature detectors ( e.g. DoG \cite , Hessian Affine \cite , MSER \cite ) are very efficient to find regions of rich textured objects such as buildings , paintings , advertising poster , etc .
Using sparse feature detectors ( e.g. , DoG \cite , Hessian affine \cite , MSER \cite ) is very efficient in terms of finding regions of richly textured objects such as buildings , paintings , and advertising .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			34:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:2			16:2			3		1.0
19:1			18:1			0		1.0
22:1			22:1			0		1.0
23:1			19:2			3		1.0
24:1			21:1			0		1.0
26:1			23:1			1		1.0
27:1			24:1			0		1.0
28:1			25:1			0		1.0
29:1			26:1			0		1.0
30:1			27:1			0		1.0
31:1			28:1			0		1.0
32:1			29:1			0		1.0
33:1			30:1			0		1.0
34:1			31:1			0		1.0
36:1			32:1			0		1.0
37:1			36:1			0		1.0

Alignment 1008
As reported \cite , \cite , \cite , the mean average precision ( mAP ) evaluated on standard benchmarks such as Oxford buildings , Paris buildings is approaching to 90 percent .
As reported \cite , \cite , \cite , the mean average precision ( mAP ) evaluated on standard benchmarks such as Oxford buildings and Paris buildings is approaching 90 percent .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0

Alignment 1009
Therefore , searching on this kind of object is to some extent solved problem .
Therefore , searching this kind of object is to some extent a solved problem .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 1010
For small and fairly texture objects typical feature detectors collect not enough local information , thus invadate the BOW's assumption .
For small and fairly textured objects , however , conventional feature detectors cannot collect enough local information , thus invalidating the BOW's assumption .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			1		1.0
5:1			5:1			0		1.0
9:1			6:1			3		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			10:1			3		1.0
13:1			9:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			0		1.0
23:1			20:1			0		1.0

Alignment 1011
Therefore , the standard BOW and its improvements including spatial re-ranking \cite and query expansion \cite will encounter a lot of difficulties derived from noisy background and complex capturing conditions .
Therefore , the standard BOW and its improvements , including spatial re-ranking \cite and query expansion \cite , are poised to encounter a lot of difficulties stemming from noisy backgrounds and complex capturing conditions .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
18:1			16:2			3		1.0
22:1			18:1			0		1.0
23:1			19:1			0		1.0
24:1			20:1			0		1.0
25:1			21:1			0		1.0
26:2			22:2			3		1.0
28:1			24:1			0		1.0
29:1			25:1			1		1.0
30:1			26:1			0		1.0
31:1			27:1			0		1.0
32:1			28:1			0		1.0
33:1			29:1			0		1.0
34:1			30:1			0		1.0

Alignment 1012
After years of exploration in TRECVID competition , most of the state of the art INS systems \cite are based on BOW model but
After years of exploration in TRECVID competition , most INS systems currently in use \cite are based on the BOW model .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			15:1			0		1.0
10:1			16:1			0		1.0
14:1			17:1			0		1.0
15:1			18:1			0		1.0
16:1			19:1			0		1.0
17:1			20:1			0		1.0
18:1			10:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0

Alignment 1013
reported very low in mAP due to many different types of query object . Hence , there still has a lot of potential challenges to solve .
However , these have been reported to be very low in mAP due to the many different types of query object , so there are still many challenges that remain to be addressed .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			15:1			0		1.0
5:1			0:1			0		1.0
6:1			24:1			0		1.0
8:1			1:1			0		1.0
9:1			2:1			0		1.0
10:1			3:1			0		1.0
11:1			4:1			0		1.0
12:1			5:1			0		1.0
13:1			6:1			0		1.0
15:1			7:1			0		1.0
16:1			8:1			0		1.0
17:1			9:1			0		1.0
18:1			10:1			0		1.0
19:1			11:1			0		1.0
20:1			12:1			0		1.0
23:1			16:1			0		1.0
25:1			17:1			0		1.0
27:1			23:1			0		1.0
33:1			13:1			0		1.0

Alignment 1014
In this paper , we aim at improving the accuracy of the instance search system which focuses on many kinds of realistic objects .
In this paper , we aim at improving the accuracy of an instance search system that focuses on many different realistic objects .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:2			15:2			3		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			3		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0

Alignment 1015
Many that have been successfully applied on such as : RootSIFT feature \cite , large vocabulary \cite , soft assignment \cite , multiple detectors and features combination at late fusion[x] query-adaptive asymmetrical dissimilarities \cite , topology model for spatial verification \cite , weak geometric consistency ( WGC ) with hamming embedding ( HE ) \cite .
Several have already been successfully applied , including RootSIFT feature \cite , large vocabulary \cite , soft assignment \cite , multiple detectors and features combination at late fusion[x] query-adaptive asymmetrical dissimilarities \cite , the topology model for spatial verification \cite , and weak geometric consistency ( WGC ) with hamming embedding ( HE ) \cite .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			41:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0
24:1			26:1			0		1.0
25:1			27:1			0		1.0
26:1			28:1			0		1.0
27:1			29:1			0		1.0
28:1			30:1			0		1.0
29:1			31:1			0		1.0
30:1			32:1			0		1.0
31:1			33:1			0		1.0
32:1			34:1			0		1.0
34:1			35:1			0		1.0
35:1			36:1			0		1.0
36:1			37:1			0		1.0
37:1			38:1			0		1.0
38:1			39:1			0		1.0
39:1			40:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0
49:1			49:1			0		1.0
50:1			50:1			0		1.0
51:1			51:1			0		1.0
52:1			52:1			0		1.0
53:1			53:1			0		1.0
54:1			54:1			0		1.0
55:1			55:1			0		1.0

Alignment 1016
Spatial consistency checking is not only an important technique to improve the accuracy but also a needed step for query expansion to improve the recall of the system .
In addition to its importance as a technique to improve accuracy , spatial consistency checking is a step for query expansion to improve the recall of the system .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			14:1			3		1.0
3:2			7:1			3		1.0
6:1			15:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			12:1			0		1.0
13:1			1:1			0		1.0
14:1			2:1			0		1.0
15:1			3:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 1017
However , this approach is not efficient very much for searching different types of query .
However , this approach is not very efficient for searching different types of query .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			7:1			0		1.0
7:1			6:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0

Alignment 1018
There are three main reasons for the failure of spatial verification : ( i ) lacking of features due to viewpoint and light condition change , ( ii ) existing of confus objects which share similar parts with query object .
There are three main reasons for the failure of spatial verification : ( i ) the absence of features due to viewpoint and lighting condition changes , ( ii ) the existence of confus objects that share similar parts with the query object .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
16:1			15:1			3		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			1		1.0
24:1			23:1			0		1.0
25:1			24:1			1		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
31:1			29:1			1		1.0
32:1			30:1			0		1.0
33:1			31:1			0		1.0
34:1			32:1			0		1.0
36:1			34:1			0		1.0
37:1			35:1			0		1.0
38:1			36:1			0		1.0
39:1			37:1			0		1.0
41:1			38:1			0		1.0
42:1			39:1			0		1.0
43:1			40:1			0		1.0

Alignment 1019
These lead to lacking of high confidence visual words used for re-ranking .
These lead to a lack of high confidence visual words for re-ranking .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			1		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 1020
Figure \ref gives some examples of scenario that database frames get high similarity score after spatial checking due to the existing of many similar objects which share the same part with the query object and a noisy background .
Figure \ref gives some examples of a scenario in which database frames get a high similarity score after spatial checking due to reasons ( ii ) and ( iii ) above , namely , the existence of many similar objects that share the same part with the query object and a noisy background .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			35:1			0		1.0
7:1			6:1			0		1.0
9:1			25:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0
34:1			19:1			0		1.0
35:1			20:1			1		1.0
36:1			21:1			0		1.0
37:1			22:1			0		1.0
38:1			23:1			0		1.0
39:1			24:1			0		1.0
40:1			7:1			0		1.0
41:1			26:1			0		1.0
42:1			27:1			0		1.0
43:1			28:1			0		1.0
44:1			29:1			0		1.0
45:1			30:1			0		1.0
46:1			31:1			0		1.0
47:1			32:1			0		1.0
48:1			33:1			0		1.0
49:1			34:1			0		1.0
51:1			36:1			0		1.0
52:1			37:1			0		1.0
53:1			38:1			0		1.0

Alignment 1021
To overcome this difficulty , a typical way is to sampling in ense grid at various scales .
The typical way of addressing the above issue is to perform sampling in a dense grid on various scales .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			6:1			0		1.0
2:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			5:1			0		1.0
15:1			13:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0

Alignment 1022
Object in image will be fully covered by local patches which are aggregated to a single vector and used for spatial verification step .
in an image is fully covered by local patches that are aggregated to a single vector and used for spatial verification .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:2			3		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:2			10:2			3		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			23:1			0		1.0

Alignment 1023
Many research has recently shifted from local feature detection to use denser techniques . It can be listed out here some applications of dense feature on image classification \cite , fine-grained classification \cite , action recognition in videos \cite .
Much research has recently shifted from local feature detection to the use of denser techniques , some of the applications of which include dense feature on image classification \cite , fine-grained classification \cite , and action recognition in videos \cite .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			33:1			0		1.0
16:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
37:1			36:1			0		1.0
38:1			37:1			0		1.0
39:1			38:1			0		1.0
40:1			39:1			0		1.0

Alignment 1024
The dense method , however , need a special treatment to apply in large scale retrieval since it extracts much more patches than sparse ones . Therefore , it is not applicable for large scale data if using per-feature level storage approach .
The dense method , however , requires a special treatment for application to large - scale retrieval since it extracts many more patches than sparse ones , so it is not applicable for large - scale data if taking a per-feature level storage approach .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			2		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			32:1			0		1.0
12:1			10:1			0		1.0
13:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
33:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
37:1			36:1			0		1.0
40:1			38:1			0		1.0
41:1			39:1			0		1.0
42:1			40:1			0		1.0
43:1			41:1			0		1.0
44:1			42:1			0		1.0

Alignment 1025
Using a dense feature at the post processing stage instead of at the early stage is more reasonable .
Using a dense feature at the post - processing stage instead of at the early stage is more reasonable .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0

Alignment 1026
We use an object detector based on a dense feature like HOG to boost the confidence of a visual word .
Here , an object detector based on a dense feature such as HOG to boost the confidence of a visual word .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0

Alignment 1027
Which words satisfy both BOW and detection models is used to boost the similarity score at the end .
Whichever words satisfy both BOW and the detection models are used to boost the similarity score at the end .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			2		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0

Alignment 1028
We use DPM ( Deformable Parts Model ) \cite to demonstrate our proposed method since it is one of the state of the algorithms for object detection .
We use the deformable parts model \cite to demonstrate our proposed method since it is currently one of the best algorithms for object detection .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			22:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
20:1			23:1			0		1.0
21:1			24:1			0		1.0
22:1			25:1			0		1.0
23:1			26:1			0		1.0
24:1			27:1			0		1.0

Alignment 1029
Note that , this detector can be replaced by other detectors easily without changing structure of the system .
This detector could easily be replaced by other detectors without changing the structure of the system .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			4:1			0		1.0
2:1			5:1			3		1.0
3:1			11:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			12:1			0		1.0
10:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0

Alignment 1030
Contribution : This paper proposes a novel re ranking method such as that exploits object proposal to boost the confidence of visual words .
Contribution : In this paper , we propose a novel re - ranking method that exploits object proposal to boost the confidence of visual words .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
4:1			3:1			0		1.0
7:1			4:1			1		1.0
8:1			5:1			0		1.0
9:1			6:1			0		1.0
10:1			7:1			0		1.0
12:1			8:1			0		1.0
13:1			9:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0

Alignment 1031
The performance of the proposed approach is significantly better than that of other re ranking methods such as geometric consistency checking , multi-features late fusion technique thanks to the following contributions :
The performance of the proposed approach is significantly better than that of other re-ranking methods ( geometric consistency checking , multi-features late fusion technique ) thanks to the following contributions :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
14:1			15:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0

Alignment 1032
To our best of knowledge , this is the first time that .
To the best of our knowledge , this is the first time that .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			1:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0

Alignment 1033
We propose a new scheme of re - ranking method by combining two complementary models : BOW and object detector using dense feature .
Our new re - ranking method combines two complementary models : BOW and object detector using dense features .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			3:1			0		1.0
2:1			6:1			0		1.0
3:1			7:1			0		1.0
4:1			8:1			0		1.0
5:1			9:1			0		1.0
6:1			11:1			1		1.0
7:1			12:1			0		1.0
8:1			13:1			0		1.0
9:1			14:1			0		1.0
10:1			15:1			0		1.0
11:1			16:1			0		1.0
12:1			17:1			0		1.0
13:1			18:1			0		1.0
14:1			19:1			0		1.0
15:1			20:1			0		1.0
16:1			21:1			0		1.0
17:1			22:1			1		1.0
18:1			23:1			0		1.0

Alignment 1034
the proposed detector in our scheme small , texture-less and occluded objects .
the proposed detector in our scheme small , texture-less , and occluded objects .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0

Alignment 1035
Meanwhile , traditional BOW model is suitable for big and rich textured objects .
In contrast , conventional BOW is suitable for big and richly textured objects .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			3		1.0
4:1			3:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			1		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 1036
In the experimental section , we will prove the complementary characteristic by using a simple late fusion technique on these methods .
In the experimental section , we will demonstrate how these characteristics complement each other through use of a simple late fusion technique .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			2		1.0
9:1			19:1			0		1.0
14:1			11:2			3		1.0
17:1			13:1			0		1.0
18:1			14:1			0		1.0
19:1			15:1			0		1.0
20:1			16:1			0		1.0
21:1			17:1			0		1.0
22:1			21:1			0		1.0

Alignment 1037
We propose a new that takes into account location information of candidate object .
We propose a new that takes into account the location information of a candidate object .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0

Alignment 1038
The shared visual words on database frame are classified into four categories based on the relationship between word location and bounding box of DPM algorithm .
The shared visual words on a database frame are classified into four categories on the basis of the relationship between word location and bounding box of DPM algorithm .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:4			12:2			3		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0
26:1			23:1			0		1.0
27:1			24:1			0		1.0
28:1			25:1			0		1.0

Alignment 1039
Each class of visual word will contribute to the final score with a boosting function .
Each class of visual word will contribute to the final score with a boosting function .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 1040
Unlike idf as a global weighting , our confidence function is applied for a specific query object .
Unlike idf as a global weighting , our confidence function can be applied for a specific query object .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:2			10:1			3		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0

Alignment 1041
The rest of this paper is organized as follows .
The rest of this paper is organized as follows .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 1042
Section dicusses some previous work related to our proposed method \ref .
Related work is discussed in Section \ref .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			4:1			0		1.0
5:1			0:1			0		1.0
6:1			10:1			0		1.0
7:1			11:1			0		1.0

Alignment 1043
Details of our framework are presented in Section \ref .
The details of our framework are presented in Section \ref .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0

Alignment 1044
Section \ref and section \ref explain why we choose DPM to combine with BOW and propose a location based fusion technique for re ranking .
Sections \ref and \ref explain why we chose to combine DPM with BOW and propose a location - based fusion technique for re- ranking .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			1		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			2		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			9:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 1045
Section \ref presents our experimental results on the dataset INS2013 and INS2014 .
Section \ref presents our experimental results using two datasets ( INS2013 and INS2014 ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
8:1			8:1			1		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
14:1			12:1			0		1.0

Alignment 1046
Finally , section \ref concludes thí papers .
We conclude the paper with a brief summary in Section \ref .
Line2Start:Length	Line1Start:Length	Module		Score
10:1			3:1			0		1.0
11:1			7:1			0		1.0

Alignment 1047
BOW is an unstructured model ưhichassumes all visual word are independent in a high dimensional vector .
BOW is an unstructured model that assumes all visual words are independent in a high dimensional vector .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			1		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0

Alignment 1048
Many researches have bên taken in to account this .
Many researches have tackled .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			9:1			0		1.0

Alignment 1049
Spatial verification is one of the most effective approaches to improve the accuracy of a retrieval system .
Spatial verification is one of the most effective approaches to improve the accuracy of retrieval systems .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			1		1.0
16:1			17:1			0		1.0

Alignment 1050
It also be a prerequisite stop for other advanced methods such as query expansion .
It is also a prerequisite for other advanced methods such as query expansion .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:2			1:2			3		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0

Alignment 1051
Spatial re-ranking which check the geometric consistency on short list of about 200 to 1000 result returned from BOW model .
Spatial re-ranking , which checks the geometric consistency in a short list of about 200–1000 results , the BOW model .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			1		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:3			7:2			3		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 1052
Using RANSAC with exploiting the local shape of affine covariant region for rigid affine consistency checking is an effective method and first applied by J. Philbin \cite .
Another effective model , first applied by J. Philbin \cite , uses RANSAC to exploit the local shape of an affine covariant region for rigid affine consistency checking .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			18:1			0		1.0
4:1			21:1			0		1.0
5:1			22:1			0		1.0
6:1			23:1			0		1.0
7:1			24:1			0		1.0
8:1			25:1			0		1.0
9:1			26:1			0		1.0
12:1			1:1			0		1.0
14:1			3:1			1		1.0
15:1			4:1			0		1.0
16:1			5:1			0		1.0
17:1			6:1			0		1.0
18:1			7:1			0		1.0
19:1			17:1			0		1.0
20:1			8:1			0		1.0
21:1			9:1			0		1.0
22:1			10:1			0		1.0
23:1			11:1			0		1.0
24:1			12:1			0		1.0
25:1			13:1			0		1.0
26:1			14:1			0		1.0
27:1			15:1			0		1.0
28:1			27:1			0		1.0

Alignment 1053
Hough Pyramid Matching for spatial re-ranking a hierarchical structure to group matches thus resulting in an algorithm which is only linear in the number of putative correspondences \cite .
Hough pyramid matching for spatial re-ranking a hierarchical structure to group matches , thus resulting in an algorithm that is only linear in the number of putative correspondences \cite .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:2			17:2			3		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0

Alignment 1054
An elastic spatial checking technique is proposed to emphasizing the topology layouts of the matching points \cite .
An elastic spatial checking technique has been proposed to emphasize the topology layouts of matching points \cite .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:2			5:1			3		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			1		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 1055
Another approach is spatial ranking which proposes to incorporate spatial information at the original ranking stage for more effective .
Another approach is spatial ranking , which incorporates spatial information at the original ranking stage .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			8:1			1		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			19:1			0		1.0

Alignment 1056
Jegou et al. \cite use a Hough-like voting scheme in the space of similarity transformation between query and database image .
Jegou et al. \cite use a Hough-like voting scheme in the space of similarity transformation between query and database image .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 1057
However , this is a weak geometric consistency checking .
However , this is a weak geometric consistency checking .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 1058
Cao et al. propose to use spatial-bag-of-features the spatial ordering of visual words under various linear and circular projections \cite . Shen et al. proposed to transform query ROI by predefined scales \cite .
Cao et al. proposed using spatial-bag-of-features the spatial ordering of visual words under various linear and circular projections \cite , while Shen et al. proposed transforming query ROI by predefined scales \cite .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			24:1			0		1.0
4:1			5:1			1		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			3:2			3		1.0
25:1			25:2			3		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0
31:1			32:1			0		1.0
32:1			33:1			0		1.0

Alignment 1059
However , this method is much more computationally expensive than other systems such as BOW or WGC .
However , this latter method is much more computationally expensive than other systems such as BOW or WGC .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0

Alignment 1060
All of the above methods do not mention or give a systematic solution to handle the failure of spatial re-ranking which caused by low number of feature or confus objects which has with query object .
None of the above methods consider or provide a systematic solution to handle the failure of spatial re-ranking caused by a low number of features or by the existence of confus objects that have as a query object .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			3		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			21:1			0		1.0
19:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0
24:1			26:1			1		1.0
25:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
36:1			33:1			0		1.0
37:1			34:1			0		1.0
38:1			35:1			0		1.0

Alignment 1061
To the best of our knowledge , this is the first time solve that spatial verification problem .
To the best of our knowledge , this is the first time that the spatial verification problem has been solved .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
20:1			17:1			0		1.0

Alignment 1062
Deformable Part Models ( DPM ) is one of state-of-the-art algorithms in object detection .
The deformable parts model ( DPM ) is a state-of-the-art algorithm in object detection .
Line2Start:Length	Line1Start:Length	Module		Score
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:2			6:3			3		1.0
9:1			9:1			0		1.0
10:1			10:1			1		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 1063
The original version of DPM is very slow , thus it is difficult to apply on large-scale data .
The original version of DPM is very slow , making it difficult to apply on large-scale data .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			10:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0

Alignment 1064
However , many research try to improve the accuracy and speed of DPM such as \cite , and could be applied for detection on large-scale dataset .
However , due to research on improving the accuracy and speed of DPM \cite , and seems like it could be effective for detection on a large-scale dataset .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			5:1			0		1.0
4:1			3:1			0		1.0
5:1			23:1			0		1.0
6:2			6:2			3		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0

Alignment 1065
Moreover , combining part filters with root filter , DPM also be an implicit spatial check method for our proposed approach .
Moreover , if we combine part filters with a root filter , DPM could also function as an implicit spatial check method for our proposed approach .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
4:1			2:1			1		1.0
5:1			3:1			0		1.0
6:1			4:1			0		1.0
7:1			5:1			0		1.0
9:1			6:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
14:1			10:1			0		1.0
17:1			12:1			0		1.0
18:1			13:1			0		1.0
19:1			14:1			0		1.0
20:1			15:1			0		1.0
21:1			16:1			0		1.0
22:1			17:1			0		1.0
23:1			18:1			0		1.0
24:1			19:1			0		1.0
25:1			20:1			0		1.0
26:1			21:1			0		1.0

Alignment 1066
All systems implemented in the experiment section are based on the following settings .
All systems implemented in the experiment section are based upon the following settings .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:2			8:2			3		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 1067
Keyframes are extracted from raw videos at the rate of 5 frames per second .
Keyframes are extracted from raw video at the rate of 5 frames per second .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			1		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 1068
For feature extraction , we use Hessian affine detector \cite and SIFT descriptor \cite .
For feature extraction , we use a Hessian affine detector \cite and a SIFT descriptor \cite .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0

Alignment 1069
To improve the performance of retrieval system , RootSIFT \cite post-processing are applied with out adding storage memory and computational cost .
To improve the performance of the retrieval system , RootSIFT \cite post-processing is applied , with no additional storage memory or computational cost .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			2		1.0
13:1			12:1			0		1.0
15:1			13:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0

Alignment 1070
A large vocabulary with 1 million visual words is trained using Approximate K-Means ( AKM ) algorithm \cite .
A large vocabulary with 1 million visual words is trained using the approximate K-means ( AKM ) algorithm \cite .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0

Alignment 1071
To reduce quantization errors without adding storage memory , we use hard-assignment on database keyframes and soft-assignment on query images with three nearest neighbors .
To reduce quantization errors without adding storage memory , we use hard-assignment on database keyframes and soft-assignment on query images with three nearest neighbors .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 1072
All frames of a shot are aggregated into one high-dimensional histogram vector using average pooling .
All frames of a shot are aggregated into one high-dimensional histogram vector using average pooling .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 1073
Each query image of a topic are independently compared to all shots using asymmetrical metric \cite .
Each query image of a topic is independently compared to all shots using asymmetrical metrics \cite .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			2		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			1		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 1074
Score of the final relevance between query topic and shot are computed using average fusion of all ranking lists returned from each query example retrieval .
The final relevance score between query topic and shot are computed using the average fusion of all ranking lists returned from each query example retrieval .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			3:1			0		1.0
2:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			2:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 1075
For simplicity of notation , we only consider set of query examples and keyframes of a shot in video dataset .
For simplicity of notation , here we consider only the set of query examples and keyframes of a shot in the video dataset .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			7:1			0		1.0
8:1			6:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			0		1.0
23:1			20:1			0		1.0

Alignment 1076
Other shots are processed similarly .
Other shots are processed similarly .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0

Alignment 1077
Let </Eq> be vector BOW of the k-th query image and the j-th frame of video shot , where </Eq> is size of the codebook .
Let </Eq> be the vector BOW of the k-th query image and the j-th frame of the video shot , respectively , where </Eq> is the size of the codebook .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			23:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
22:1			18:1			0		1.0
23:1			19:1			0		1.0
24:1			20:1			0		1.0
26:1			21:1			0		1.0
27:1			22:1			0		1.0
29:1			24:1			0		1.0
30:1			25:1			0		1.0

Alignment 1078
To be build inverted index with a compact representation , we use average pooling :
To build an inverted index with a compact representation , we use average pooling :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 1079
where </Eq> is number of keyframes shot .
where </Eq> is the number of keyframes a shot .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0

Alignment 1080
Similarity score of shot with given query examples is computed by the following formula :
The similarity score of a shot with given query examples is computed by
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
5:1			3:1			0		1.0
6:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0

Alignment 1081
where </Eq> is number of query examples and </Eq> is a asymmetrical similarity score .
where </Eq> is the number of query examples and </Eq> is the asymmetrical similarity score .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:2			9:2			3		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0

Alignment 1082
Top </Eq> retrieved shots based on </Eq> similarity score are then used for re-ranking stage .
The top </Eq> retrieved shots based on the </Eq> similarity score are then used for the re-ranking .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			15:1			0		1.0

Alignment 1083
In order to verify the confidence of shared visual words between query and database frames , we propose to use an object detector with denser feature .
In order to verify the confidence of shared visual words between query and database frames , we propose using an object detector with denser features .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			19:1			1		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			1		1.0
25:1			26:1			0		1.0

Alignment 1084
that DPM is one of the state-of-the-art algorithms with part-based representation model .
that DPM is a state-of-the-art algorithm with a parts-based representation model .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:2			2:4			3		1.0
4:1			6:1			0		1.0
5:1			7:1			1		1.0
6:1			8:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0

Alignment 1085
Histogram of Gradient feature ( HOG ) and latent-SVM was originally designed to handle change of illumination condition and variations in appearance of object .
A histogram of gradient features ( HOG ) and latent-SVM were originally designed to handle changing lighting conditions and variations in the appearance of an object .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
4:1			3:1			1		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			2		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:2			3		1.0
16:1			16:1			2		1.0
17:1			17:1			1		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0

Alignment 1086
DPM take the advantage of shape information : BOW model with SIFT descriptor ( or its extension , rootSIFT ) and DPM model with HOG features both are based on the same idea computing histogram of gradient vector at a group pixel .
DPM takes advantage of shape information : The BOW model with a SIFT descriptor ( or its extension , rootSIFT ) and the DPM model with HOG features are both based on the idea of computing the histogram of a gradient vector at a group pixel .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			1		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			39:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			2:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			27:1			0		1.0
29:1			26:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
33:1			32:1			0		1.0
35:1			33:1			0		1.0
37:1			34:1			0		1.0
38:1			35:1			0		1.0
40:1			36:1			0		1.0
41:1			37:1			0		1.0
42:1			38:1			0		1.0
44:1			40:1			0		1.0
45:1			41:1			0		1.0
46:1			42:1			0		1.0

Alignment 1087
The difference is that : BOW use all of features independently while DPM algorithm groups local blocks together to represent a meaningful part .
The difference is that BOW uses all of the features independently while the DPM algorithm groups local blocks together to represent a meaningful part .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			1		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0

Alignment 1088
Moreover , feature detector used in standard BOW retrieval system is very sparse and sensitive to light condition or viewpoint while HOG feature of DPM always cover full of object .
Moreover , the feature detector used in standard BOW retrieval systems is very sparse and sensitive to lighting condition or viewpoint , while the HOG feature of DPM always covers an object in its entirety .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			1		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			1		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
22:1			20:1			0		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0
26:1			23:1			0		1.0
27:1			24:1			0		1.0
28:1			25:1			0		1.0
29:1			26:1			1		1.0
31:1			29:1			0		1.0
32:3			27:1			3		1.0
35:1			30:1			0		1.0

Alignment 1089
Figure \ref shows a comparison between Hessian Affine feature used in BOW and HOG feature used in DPM .
Figure \ref shows a comparison of the Hessian affine feature used in BOW and the HOG feature used in DPM .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:2			4:2			3		1.0
7:1			6:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0

Alignment 1090
We can see that : the distribution of Hessian Affine feature are no uniform across regions within the same image .
We can clearly see that the distribution of Hessian affine features is not uniform across regions within the same image .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
12:1			11:2			3		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 1091
In case of low contrast image , number of feature is very sparse or even no one detected .
In the case of a low contrast image , the number of features is very sparse or even completely absent .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			0		1.0
5:1			3:1			0		1.0
6:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			1		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
20:1			18:1			0		1.0

Alignment 1092
Meanwhile HOG feature of part filter can always be described in all conditions including case of low contrast .
In contrast , the HOG feature of a part filter can always be described under all conditions , including cases of low contrast .
Line2Start:Length	Line1Start:Length	Module		Score
4:1			1:1			0		1.0
5:1			2:1			0		1.0
6:1			3:1			0		1.0
8:1			4:1			0		1.0
9:1			5:1			0		1.0
10:1			6:1			0		1.0
11:1			7:1			0		1.0
12:1			8:1			0		1.0
13:1			9:1			0		1.0
15:1			11:1			0		1.0
16:1			12:1			0		1.0
18:1			13:1			0		1.0
19:1			14:1			1		1.0
20:1			15:1			0		1.0
21:1			16:1			0		1.0
22:1			17:1			0		1.0
23:1			18:1			0		1.0

Alignment 1093
BOW and DPM are two complementary methods : In fact , there is no good method for all cases .
BOW and DPM are two complementary methods : In fact , there is no one method that is superior for all cases .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
15:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			0		1.0

Alignment 1094
For query objects which have dense local features , BOW model work effectively if accompanied with a spatial re-ranking method .
For query objects that have dense local features , the BOW model is effective if accompanied with a spatial re-ranking method .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:2			3:2			3		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
13:1			12:1			1		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0

Alignment 1095
In case of small and textureless object , when lighting condition changes over time , the extracted features are sparser that makes the failure of spatial verification .
However , in the case of a small and textureless object , when the lighting condition changes over time , the extracted features are sparser , which leads to spatial verification failure .
Line2Start:Length	Line1Start:Length	Module		Score
3:1			15:1			0		1.0
4:1			1:1			0		1.0
5:1			2:1			0		1.0
7:1			3:1			0		1.0
8:1			4:1			0		1.0
9:1			5:1			0		1.0
10:1			6:1			0		1.0
11:1			7:1			0		1.0
12:1			8:1			0		1.0
13:1			22:1			0		1.0
14:1			9:1			0		1.0
15:1			10:1			0		1.0
16:1			11:1			0		1.0
17:1			12:1			0		1.0
18:1			13:1			0		1.0
19:1			14:1			0		1.0
21:1			16:1			0		1.0
22:1			17:1			0		1.0
23:1			18:1			0		1.0
24:1			19:1			0		1.0
29:1			25:1			0		1.0
30:1			26:1			0		1.0
31:1			23:1			0		1.0
32:1			27:1			0		1.0

Alignment 1096
On the other hand DPM algorithm as mentioned above can describe any object in any lighting conditions and take advantage of the shape information more effectively .
In contrast , the DPM algorithm can describe any object under any lighting condition and is more effective when it comes to taking advantage of shape information .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			2:2			3		1.0
3:1			1:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			9:1			0		1.0
7:1			10:1			0		1.0
8:1			11:1			0		1.0
9:1			12:1			0		1.0
10:2			13:2			3		1.0
12:1			15:1			0		1.0
13:1			16:1			1		1.0
14:1			17:1			0		1.0
16:1			24:1			0		1.0
17:1			25:1			1		1.0
22:2			18:2			3		1.0
24:1			20:1			0		1.0
25:1			22:1			0		1.0
26:1			23:1			0		1.0
27:1			26:1			0		1.0

Alignment 1097
However , DPM algorithms are generally suitable for detecting generic object which have discriminative curves that makes it significantly different with other ones . This characteristic of DPM algorithm give failures in object with too much texture .
However , DPM algorithms are generally suitable for detecting generic objects that have discriminative curves to show that they are significantly different from other ones , and this characteristic results in failure in objects with too much texture .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			1		1.0
11:2			11:2			3		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
17:1			15:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
28:1			25:1			0		1.0
31:2			30:2			3		1.0
33:1			32:1			1		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
37:1			36:1			0		1.0
38:1			37:1			0		1.0

Alignment 1098
In order to show of these two approaches , we use a simple late fusion technique that combines two scores using formula .
To demonstrate of these two approaches , we use a simple late fusion technique that combines two scores using an formula .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			2:2			3		1.0
2:1			4:1			0		1.0
3:1			5:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0

Alignment 1099
This method will be compared to standard spatial re-ranking in the experiment section .
This method will be compared to standard spatial re-ranking in the experiment section .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 1100
Let </Eq> be a model trained from all query examples and 100 random image crawled from Google image with "things" is the .
Let </Eq> be a model trained from all query examples and 100 random images crawled from Google Images with "things" as the .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			1		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 1101
Similarity score of query topic and in database is compute as following : where </Eq> is a keyframe of video shot .
The similarity score of the query topic and in the database is computed as where </Eq> is a keyframe of a video shot .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
5:1			3:1			0		1.0
6:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			1		1.0
13:1			10:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0

Alignment 1102
The final late fusion similarity of BOW and DPM models is computed using following average normalized formula :
The final late fusion similarity of the BOW and DPM models is computed using the following average normalized formula :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0

Alignment 1103
where </Eq> are z-score normalized value of </Eq> on top K of rank list , respectively :
where </Eq> are the z-score normalized values of </Eq> on the top K of the rank list , respectively :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			1		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0

Alignment 1104
Note that this is just a simple average fusion technique on normalized scores .We still have a room to further improve on fusion formula xx .
Note that this is just a simple average fusion technique on normalized scores , and there is still room to improve on fusion formula xx .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
16:2			14:2			3		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 1105
The value of </Eq> and </Eq> can be estimated adaptively using more information about number of visual words and ROI area given by topic examples .
The values of </Eq> and </Eq> can be estimated adaptively using more information about the number of visual words and ROI area given by topic examples .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:2			1:2			3		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0

Alignment 1106
In late fusion approach , we simply combined score values of the two methods together without using any other useful information such as shared word and bounding box detected by DPM algorithm .
In the late fusion approach , we simply combined the score values of the two methods without using any other information such as shared word or bounding box detected by DPM algorithm .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:2			24:2			3		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0

Alignment 1107
In this section we propose an integrated approach to effectively utilize this information .
In this section , we propose an integrated approach to effectively utilize this information .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0

Alignment 1108
Figure \ref describes all cases may happen to the BOW shared words and candidate's bounding box .
Figure \ref displays all the cases that may occur with the BOW shared words and the candidate's bounding box .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			2		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0

Alignment 1109
The ROI rectangle in the left image is the location of query object when put into the search engine . The object proposal region ( OPR ) rectangle on the right image is the DPM bounding box .
The ROI rectangle in the left image is the location of a query object when put in the search engine and the object proposal region ( OPR ) rectangle in the right image is the DPM bounding box .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:2			14:2			3		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
21:1			33:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
37:1			36:1			0		1.0
38:1			37:1			0		1.0

Alignment 1110
Each arrow starts from visual word of query image and ends at visual word of video frame of the database .
Each arrow starts from the visual word of a query image and ends at the visual word of a video frame the database .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			18:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
19:1			15:1			0		1.0
20:1			16:1			0		1.0
22:1			19:1			0		1.0
23:1			20:1			0		1.0

Alignment 1111
All pairs of matching points are divided into the following categories :
All pairs of matching points are divided into the following categories :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 1112
Type 1 : Outlier shared words are the wrong pair of matched points represented by red arrows .
Type 1 : Outlier shared words , which are incorrect pairings of matched points represented by red arrows .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			8:1			2		1.0
10:1			9:1			1		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0

Alignment 1113
These pairs of points will be removed by RANSAC algorithm , and the rest is the inlier pair of matching points includes three of next types .
These pairs of points will be removed by the RANSAC algorithm , and the remaining pairs are inlier pairs of matching points that fall into one of the next three types .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			15:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			2		1.0
17:1			16:1			0		1.0
18:1			17:1			1		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
26:1			23:1			0		1.0
28:1			24:1			0		1.0
29:1			22:1			0		1.0
30:1			25:1			0		1.0
31:1			26:1			0		1.0

Alignment 1114
Type 2 : discriminative points are represented by green arrows connecting words in the foreground to words inside DPM bounding box .
Type 2 : Discriminative points , which are represented by green arrows connecting words in the foreground to words inside the DPM bounding box .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0

Alignment 1115
These points satisfy both BOW model and DPM algorithm so they contribute to identify accurately query object .
These points satisfy both the BOW model and the DPM algorithm and thus contribute to the accurate identification of the query object .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
12:1			9:1			2		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
20:1			15:1			0		1.0
21:1			16:1			0		1.0
22:1			17:1			0		1.0

Alignment 1116
Therefore we choose a monotonically increasing function of number of discriminative points </Eq> .
We choose a monotonically increasing function of the number of discriminative points </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 1117
Type 3 : weakly relevant points are represented by the blue arrows connecting point in the foreground to point outside the DPM bounding box .
Type 3 : Weakly relevant points , which are represented by blue arrows connecting a point in the foreground to a point outside the DPM bounding box .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0
26:1			23:1			0		1.0
27:1			24:1			0		1.0

Alignment 1118
These points show the inconsistency between BOW model and DPM but it still contains valuable information , so we also use a monotonically increasing function of number of weakly relevant points </Eq> .
These points indicate an inconsistency between the BOW model and DPM , but they still contain valuable information , so we also use a monotonically increasing function of the number of weakly relevant points </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			2		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			3:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			16:1			0		1.0
12:1			10:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			1		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
29:1			26:1			0		1.0
30:1			27:1			0		1.0
31:1			28:1			0		1.0
32:1			29:1			0		1.0
33:1			30:1			0		1.0
34:1			31:1			0		1.0
35:1			32:1			0		1.0

Alignment 1119
However , this function increases does not as fast as function </Eq> .
This function does not increase as fast as function </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			3:1			0		1.0
2:1			5:1			0		1.0
3:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0

Alignment 1120
Type 4 : context information points are represented by black arrows connecting outside points ( background point ) of query image to points outside bounding box .
Type 4 : Context information points , which are represented by black arrows connecting outside ( background ) points of a query image to points outside the bounding box .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			17:1			0		1.0
18:1			13:1			0		1.0
19:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
27:1			24:1			0		1.0
28:1			25:1			0		1.0
29:1			26:1			0		1.0

Alignment 1121
Although the main query object to be searched in the foreground , but the features on the background sometimes gives useful information for detecting objects .
Although the main query object to be searched in the foreground , the features in the background sometimes provide useful information for detecting objects .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0

Alignment 1122
For example , the logo of a car company often located next to a car .
For example , the logo of a car company is often located next to a car .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0

Alignment 1123
Context information can contribute to the final result but not too much so weighting function of context points should be used </Eq> which increases not as fast as functions </Eq> , </Eq> .
Context information can contribute to the final result , albeit slightly , so the weighting function of context points </Eq> should be used , although these do not increase as fast as functions </Eq> , </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			30:1			0		1.0
12:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			21:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
27:1			9:1			0		1.0
29:1			25:1			0		1.0
30:1			26:1			0		1.0
31:1			27:1			0		1.0
32:1			28:1			0		1.0
33:1			29:1			0		1.0
35:1			31:1			0		1.0
36:1			32:1			0		1.0

Alignment 1124
are wrong cases removed by RANSAC algorithm . Therefore we will not consider them in the final score formula .
are incorrect cases and thus removed by the RANSAC algorithm ; we do not consider them in the final score formula .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			2		1.0
2:1			2:1			0		1.0
5:1			3:1			0		1.0
6:1			4:1			0		1.0
8:1			5:1			0		1.0
9:1			6:1			0		1.0
11:1			9:1			0		1.0
12:2			10:2			3		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0

Alignment 1125
Let </Eq> is a set of points in image which represent location of the k-th given query example .
Let </Eq> be a set of points in an image that represents the location of the k-th given query example .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			2		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:2			8:2			3		1.0
11:1			10:1			1		1.0
12:1			13:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0

Alignment 1126
where </Eq> and </Eq> are spatially verified points belong to Hessian Affine features extracted from query image and video frame which have the same word ID , respectively .
where </Eq> and </Eq> are spatially verified points belonging to the Hessian affine features extracted from the query image and video frame that have the same word ID , respectively .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:2			8:2			3		1.0
10:1			22:1			0		1.0
11:1			10:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:2			20:2			3		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0

Alignment 1127
Our goal is not to find the optimal weighting function , we prove that our new method of calculating the score associated with selecting a suitable weighting function can improve accuracy significantly compared with .
Our goal is not to find the optimal weighting function but rather to prove that our new method of calculating the score associated with selecting a suitable weighting function can improve accuracy significantly compared with .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0

Alignment 1128
The weighting functions must satisfy the following properties :
The weighting functions must satisfy the following properties :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 1129
Property 1 . for all </Eq> .
Property 1 . for all </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0

Alignment 1130
The more verified shared words the more confidence it is .
The greater the number of verified shared words , the higher the confidence is .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			5:1			0		1.0
5:1			2:1			0		1.0
6:1			3:1			0		1.0
7:1			4:1			0		1.0
12:1			7:1			0		1.0
13:1			9:1			0		1.0
14:1			10:1			0		1.0

Alignment 1131
Property 2 . </Eq> for all </Eq>
Property 2 . </Eq> for all </Eq>
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0

Alignment 1132
This feature aims of each other as well as the average score of component models and </Eq> when number of shared visual words of each type equals to 0 .
This feature aims and the average score of the component models and </Eq> when the number of shared visual words of each type equals 0 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			9:1			0		1.0
5:1			10:1			0		1.0
6:1			11:1			0		1.0
7:1			12:1			0		1.0
9:1			13:1			0		1.0
10:1			14:1			0		1.0
11:1			15:1			0		1.0
12:1			16:1			0		1.0
13:1			17:1			0		1.0
15:1			18:1			0		1.0
16:1			19:1			0		1.0
17:1			20:1			0		1.0
18:1			21:1			0		1.0
19:1			22:1			0		1.0
20:1			23:1			0		1.0
21:1			24:1			0		1.0
22:1			25:1			0		1.0
23:1			26:1			0		1.0
24:1			28:1			0		1.0
25:1			29:1			0		1.0

Alignment 1133
Therefore , in special cases if n = 0 then we are .
Therefore , in special cases , if n = 0 , we are .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0

Alignment 1134
Property 3 . </Eq> for all </Eq> .
Property 3 . </Eq> for all </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 1135
This feature : distinctive points , weak points , and distinctive point bringing context information .
This feature : distinctive points , weak points , and distinctive point bringing context information .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 1136
For ease of testing , we assume that these functions are in the same class of polynomial function .
For ease of testing , we assume that these functions are in the same class of polynomial function .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 1137
In this paper , we propose three weighting functions as follows :
In this paper , we propose three weighting functions :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			11:1			0		1.0

Alignment 1138
The final score of the proposed method becomes :
The final score of the proposed method becomes :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 1139
where </Eq> .
where </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0

Alignment 1140
In this section , a series of experiments were conducted to evaluate the proposed re-ranking method using BOW and an object detector model , where , DPM was chosen to demonstrate our idea .
In this section , we discuss the series of experiments we performed to evaluate the proposed re-ranking method using BOW and an object detector model , where DPM was chosen to demonstrate our idea .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
6:2			4:2			3		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
11:1			9:1			3		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0

Alignment 1141
First , in order to show the complementary characteristic ; we comparfed BOW and DPM with its average late fusion .
First , in order to demonstrate the complementary characteristics of BOW and DPM , its average late fusion .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:2			5:2			3		1.0
7:1			7:1			0		1.0
8:1			8:1			1		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0

Alignment 1142
Second , we compare our location-based fusion approach to other state-of-the-art techniques such as : practical spatial re-ranking \cite , Hamming Embeding and Weak Geometric Consistency \cite , multi-features fusion[x] and topology checking \cite .
Second , we compare our location-based fusion approach with other state-of-the-art techniques : practical spatial re-ranking \cite , Hamming embedding and weak geometric consistency \cite , and multi-features fusion[x] and topology checking \cite .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:2			8:2			3		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
20:1			22:1			0		1.0
24:1			26:1			0		1.0
25:1			27:1			0		1.0
26:1			30:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
30:1			31:1			0		1.0
31:1			32:1			0		1.0
32:1			33:1			0		1.0
33:1			34:1			0		1.0

Alignment 1143
Third , we examine the impact of value top </Eq> and contributions of each weighting functions on the performance of whole system .
Third , we examine the impact of value top </Eq> and the contributions of each weighting function to the performance of the system as a whole .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			17:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			1		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
22:1			21:1			0		1.0
25:1			20:1			0		1.0
26:1			22:1			0		1.0

Alignment 1144
To demonstrate advantage of the proposed method on multiple types of query , we use TRECVID Instance Search ( INS ) datasets for evaluation .
To determine the performance of the proposed method with multiple types of query , we use TRECVID Instance Search ( INS ) datasets for evaluation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0

Alignment 1145
We use the TRECVID INS [xx] benchmarks in years 2013 and 2014 which was released in the evaluation campaign organized by NIST . For experiments , we name these as INS2013 and INS2014 , respectively .
Specifically , we used the TRECVID INS [xx] benchmarks from 2013 and 2014 , which were released in the evaluation campaign organized by NIST , referred to here as INS2013 and INS2014 , respectively .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			25:1			0		1.0
2:1			26:1			0		1.0
3:1			1:1			1		1.0
4:1			2:1			0		1.0
5:1			3:1			0		1.0
6:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			33:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			2		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
25:1			27:1			2		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0
31:1			32:1			0		1.0
33:1			34:1			0		1.0
34:1			35:1			0		1.0

Alignment 1146
They share the same collection of test video with a master shot reference .
Both have the same collection of test videos with a master shot reference .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			1		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 1147
The dataset contains approximately 244 video files extracted from the BBC EastEnders program with totally 300 GB in storage and 464 hours in duration .
The dataset contains approximately 244 video files extracted from the BBC EastEnders program with a total of 300 GB in storage and a duration of 464 hours .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
23:1			23:1			0		1.0
25:1			20:1			0		1.0
26:1			21:1			0		1.0
27:1			24:1			0		1.0

Alignment 1148
Each query topic of INS2013 and INS2014 consists of several query images and corresponding masks that delimit an object , place or person entity in some example video ; locate for each topic up to the 1000 shots most likely to contain a recognizable instance of the entity .
Each query topic of INS2013 and INS2014 consists of several query images and corresponding masks that delimit an object , place , or person entity in an example video and locate for each topic up to 1000 of the shots most likely to contain a recognizable instance of the entity .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			36:1			0		1.0
37:1			45:1			0		1.0
38:1			35:1			0		1.0
39:1			37:1			0		1.0
40:1			38:1			0		1.0
41:1			39:1			0		1.0
42:1			40:1			0		1.0
43:1			41:1			0		1.0
44:1			42:1			0		1.0
45:1			43:1			0		1.0
46:1			44:1			0		1.0
48:1			46:1			0		1.0
49:1			47:1			0		1.0
50:1			48:1			0		1.0

Alignment 1149
INS datasets are challenging due to containing varieties of query types including small to big objects , rich texture to texture-less objects .
We should point out that INS datasets are quite challenging due to containing a variety of query types including small to big objects and rich texture to texture-less objects .
Line2Start:Length	Line1Start:Length	Module		Score
5:1			0:1			0		1.0
6:1			1:1			0		1.0
7:1			2:1			0		1.0
9:1			3:1			0		1.0
10:1			4:1			0		1.0
11:1			5:1			0		1.0
12:1			6:1			0		1.0
14:1			7:1			1		1.0
15:1			8:1			0		1.0
16:1			9:1			0		1.0
17:1			10:1			0		1.0
18:1			11:1			0		1.0
19:1			12:1			0		1.0
20:1			13:1			0		1.0
21:1			14:1			0		1.0
22:1			15:1			0		1.0
24:1			17:1			0		1.0
25:1			18:1			0		1.0
26:1			19:1			0		1.0
27:1			20:1			0		1.0
28:1			21:1			0		1.0
29:1			22:1			0		1.0

Alignment 1150
Evaluation protocol .
Evaluation protocol .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0

Alignment 1151
The ground truth files for each query are created manually and provided by TRECVID organization .
The ground truth files for each query are created manually and provided by the TRECVID organization .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0

Alignment 1152
To evaluate performance of each system , we use mean average precision as a standard score .
To evaluate the performance of each system , we use the mean average precision as a standard score .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0

Alignment 1153
We first , evaluate the performance of late fusion technique to prove the complementary characteristic of BOW and DPM .
First , to demonstrate the complementary characteristics of BOW and DPM , we evaluate the performance of the late fusion technique .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			2:1			0		1.0
2:1			10:1			0		1.0
3:1			11:1			2		1.0
4:1			12:1			0		1.0
5:1			13:1			0		1.0
6:2			14:2			3		1.0
8:1			16:1			0		1.0
9:1			17:1			0		1.0
10:1			18:1			0		1.0
13:1			3:1			0		1.0
14:1			4:1			0		1.0
15:1			5:1			0		1.0
16:1			6:1			0		1.0
18:1			7:1			0		1.0
19:1			8:1			0		1.0
20:1			9:1			0		1.0
21:1			19:1			0		1.0

Alignment 1154
Top 10 ,000 shots retrieved from standard BOW model are used to re-rank using DPM object detector .
The top 10 ,000 shots retrieved from the standard BOW model are used for re-ranking using the DPM object detector .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:2			10:2			3		1.0
14:1			12:1			1		1.0
15:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0

Alignment 1155
from all query example to find location of candidate object and its corresponding score value the similarity value for re-ranking .
from all query example to find the location of the candidate object and its corresponding score value , the similarity value for re-ranking .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			0		1.0
23:1			20:1			0		1.0

Alignment 1156
The score represented for a shot is the highest one of all keyframes ( equation 3 ) , BOW+DPM : average late fusion on normalized scores of BOW and DPM .
The score representing one shot is the highest one of all keyframes ( Eq.3 ) , BOW+DPM : average late fusion on normalized scores of BOW and DPM .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			1		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0
24:1			26:1			0		1.0
25:1			27:1			0		1.0
26:1			28:1			0		1.0
27:1			29:1			0		1.0
28:1			30:1			0		1.0

Alignment 1157
Figure \ref shows that , although BOW is state-of-the-art model for image retrieval , in some cases , DPM gives better result such as : 9108 , 9109 , 9114 , 9118 , 9124 , 9125 and 9128 .
Figure \ref shows that , although BOW is a state-of-the-art model for image retrieval , in some cases , DPM gives a better result : for example , 9108 , 9109 , 9114 , 9118 compared to 9124 , 9125 , 9128 , respectively .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			24:1			0		1.0
27:1			32:1			0		1.0
28:1			25:1			0		1.0
29:1			26:1			0		1.0
30:1			27:1			0		1.0
31:1			28:1			0		1.0
32:1			29:1			0		1.0
33:1			30:1			0		1.0
34:1			31:1			0		1.0
37:1			33:1			0		1.0
38:1			34:1			0		1.0
39:1			35:1			0		1.0
41:1			37:1			0		1.0
44:1			38:1			0		1.0

Alignment 1158
DPM+BOW gives approximate performance with the higher one between DPM and BOW for most of query topics .
DPM+BOW gives a performance approximately on par with the higher one between DPM and BOW for most query topics .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			3:1			0		1.0
4:1			2:1			1		1.0
7:1			4:1			0		1.0
8:1			5:1			0		1.0
9:1			6:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0

Alignment 1159
In some cases , such as 9102 , 9103 , 9123 , it is also significantly better than two baseline methods .
In some cases , e.g. , 9102 , 9103 , 9123 , it is also significantly better than the two baseline methods .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0

Alignment 1160
Therefore , the overall MAP of DPB+BOW is 28.21% and outperform both BOW and DPM ( 25.01% and 21.23% , respectively ) see Table \ref .
Therefore , the overall MAP of DPB+BOW is 28.21% , which outperforms both BOW and DPM ( 25.01% and 21.23% , respectively ; see Table \ref ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
11:1			10:1			1		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			21:1			0		1.0
27:1			25:1			0		1.0

Alignment 1161
In this section , we compared the proposed method with other state-of-the-art systems which have reported on INS2013 and INS2014 .
In this section , we compare the proposed method with other state-of-the-art systems that have been reported on INS2013 and INS2014 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			1		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:3			13:2			3		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0

Alignment 1162
Multi features in the system won on TRECVID INS 2013 competition which combine six pair of feature detectors and descriptors using asymmetrical similarity and late fusion technique [x] .
The winner of the TRECVID INS 2013 competition was the multi-features system , which combines six pairs of feature detectors and descriptors using asymmetrical similarity and late fusion technique [x] .
Line2Start:Length	Line1Start:Length	Module		Score
4:1			7:1			0		1.0
5:1			8:1			0		1.0
6:1			9:1			0		1.0
7:1			10:1			0		1.0
9:1			3:1			0		1.0
11:1			4:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			1		1.0
15:1			13:1			0		1.0
16:1			14:1			1		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0

Alignment 1163
Hamming Embedding and Weak Geometric Consistency ( HE+WCG ) votes dominant scale and orientation for fast but geometric checking .
Hamming embedding and weak geometric consistency ( HE+WCG ) dominant scale and orientation but geometric checking .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			2:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			16:1			0		1.0
14:1			17:1			0		1.0
15:1			18:1			0		1.0
16:1			19:1			0		1.0

Alignment 1164
Topology checking ( TC ) approach uses delaunay triangulation to improve the quality of visual matching . However , this method still does overcome problem spatial verification mentioned in this paper .
The topology checking ( TC ) approach uses Delaunay triangulation to improve the quality of visual matching , but it cannot overcome the problem spatial verification mentioned in this paper .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			18:1			0		1.0
21:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0

Alignment 1165
Practical spatial re-ranking ( PSC ) apply RANSAC for a representative frame to avoid verifying all images of a shot or query topic .
Practical spatial re-ranking ( PSC ) applies RANSAC for a representative frame to avoid having to verify all images of a shot or query topic .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			1		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
16:1			14:1			1		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0

Alignment 1166
Table \ref shows a comparison of the proposed method with state-of-the-art results .
Table \ref shows a comparison of the results of the proposed method and the state-of-the-art methods .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			11:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
14:1			10:1			0		1.0
16:1			12:1			0		1.0

Alignment 1167
As afore mentioned , the performance of the method is evaluated two benchmarks .
As stated above , performance is evaluated two benchmarks .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			2:1			3		1.0
3:1			3:1			0		1.0
4:1			5:1			0		1.0
5:1			9:1			0		1.0
6:1			10:1			0		1.0
7:1			11:1			0		1.0
8:1			12:1			0		1.0
9:1			13:1			0		1.0

Alignment 1168
We can see that , our approach consistently outperform other method , although we use only one pair of feature detector and descriptor .
As shown in the table , the proposed approach consistently outperforms the other methods , even though we use only one pair of feature detector and descriptor .
Line2Start:Length	Line1Start:Length	Module		Score
5:1			4:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			1		1.0
12:1			9:1			0		1.0
13:1			10:1			1		1.0
14:1			11:1			0		1.0
17:1			13:1			0		1.0
18:1			14:1			0		1.0
19:1			15:1			0		1.0
20:1			16:1			0		1.0
21:1			17:1			0		1.0
22:1			18:1			0		1.0
23:1			19:1			0		1.0
24:1			20:1			0		1.0
25:1			21:1			0		1.0
26:1			22:1			0		1.0
27:1			23:1			0		1.0

Alignment 1169
Moreover , our late fusion technique BOW+DPM also give an approximate accuracy compared to Multi-features approach with a simple average computation .
Our late fusion technique BOW+DPM also delivers an approximate accuracy compared to the multi-features approach with a simple average computation .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			3:1			0		1.0
2:1			4:1			0		1.0
3:1			5:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0

Alignment 1170
There is possibly still more room for improvement by adaptively combining BOW and DPM model .
There is still room for improvement by adaptively combining the BOW and DPM models .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			3:1			0		1.0
3:1			5:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			1		1.0
14:1			15:1			0		1.0

Alignment 1171
Although Multi-features and other spatial re-ranking methods improve performance very much , but they still do not solve the failure of spatial verification .
Although the multi-features and other spatial re-ranking methods improve performance very much , they cannot resolve the failure of spatial verification .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			13:1			0		1.0
14:2			16:2			3		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0

Alignment 1172
The result also shows that , our method is good for not only small and texture-less objects but also big and rich textured ones .
The results also show that our method is effective not only for small and texture-less objects but also for big and richly textured ones .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			1		1.0
2:1			2:1			0		1.0
3:2			3:2			3		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			2		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			10:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			1		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 1173
Ipact of parameter </Eq> .
Effect of parameter </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0

Alignment 1174
In this part , we examine the influence of value </Eq> to the final mAP when taking top </Eq> shots as the input of re-ranking stage .
Here , we briefly examine the effect of value </Eq> on the final mAP when taking top </Eq> shots as input at the re-ranking stage .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			3:1			0		1.0
2:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			22:1			0		1.0
22:1			21:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0

Alignment 1175
Figure \ref shows that when </Eq> , the accuracy of the proposed algorithm seem to be saturated with no more improvement .
Figure \ref shows that when </Eq> , the accuracy of the proposed algorithm seem to be saturated with no more improvement .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 1176
On the other hand , when </Eq> , there still have many positive shost in the bottom of the rank list returned standard BOW model .
In contrast , when </Eq> , there are still many positive shots in the bottom of the rank list returned the standard BOW model .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			2:2			3		1.0
2:1			4:1			0		1.0
3:1			5:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:2			9:2			3		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			1:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0

Alignment 1177
Even in case of the least value </Eq> , the mAP of proposed method is </Eq> and </Eq> ( for INS2013 and INS2014 , respectively ) .
Even in the case of the least value </Eq> , the mAP of the proposed method is </Eq> and </Eq> ( for INS2013 and INS2014 , respectively ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0

Alignment 1178
Contribution of each component in late fusion formula .
Contribution of each component in late fusion formula .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 1179
In this part , weighting functions by constant 1 to evaluate the influence of each component on the system performance .
Here , weighting functions by constant 1 to evaluate the effect of each component on the system performance .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			3:1			0		1.0
2:1			4:1			0		1.0
3:1			5:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0

Alignment 1180
We conduct a comparison of methods BOW and our final method with the configurations described in Table \ref . The base score mentioned in the table are the average normalized score of BOW and DPM</Eq> .
We compare the BOW methods with our final method using the configurations in Table \ref , where the base score refers to the average normalized score of BOW and DPM</Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			3:2			3		1.0
2:1			24:1			0		1.0
3:1			6:1			0		1.0
4:1			5:1			0		1.0
5:1			11:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			15:1			0		1.0
13:1			16:1			0		1.0
14:1			17:1			0		1.0
17:1			27:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			2		1.0
23:1			28:1			0		1.0
24:1			29:1			0		1.0
25:1			30:1			0		1.0
26:1			31:1			0		1.0
27:1			32:1			0		1.0
28:1			33:1			0		1.0
29:1			34:1			0		1.0
30:1			35:1			0		1.0

Alignment 1181
Table \ref shows that removing of any component of the re-ranking formula also decrease the accuracy significantly .
Table \ref shows that removing any component of the re-ranking formula decreases the accuracy significantly .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			13:1			1		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0

Alignment 1182
As a result , in the final formula .
As a result , in the final formula .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 1183
Without this component , the performance drop down significantly .
Without this component , the performance drops significantly .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			1		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0

Alignment 1184
In addition to satisf three properties as mention in Section \ref , </Eq> should not be rapidly increasing functions because .
In addition to satisfying the three properties mentioned in Section \ref , </Eq> should not be rapidly increasing functions because .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:2			7:2			3		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 1185
Therefore , square function for </Eq> .
Therefore , a square function for </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0

Alignment 1186
Similarly , the next important components are functions </Eq> respectively .
Similarly , the next most important components are functions </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			10:1			0		1.0

Alignment 1187
On the other hand , we also see that verifying pair matching shared word using RANSAC algorithm also help to improve the accuracy very much .
We can see that verifying the pair matching shared word using the RANSAC algorithm also helps to significantly improve the accuracy .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			7:1			0		1.0
3:1			8:1			0		1.0
4:1			9:1			0		1.0
5:1			1:1			0		1.0
6:1			10:1			0		1.0
7:1			11:1			0		1.0
8:1			12:1			0		1.0
9:1			13:1			0		1.0
10:1			14:1			0		1.0
12:1			15:1			0		1.0
13:1			16:1			0		1.0
14:1			17:1			0		1.0
15:1			18:1			1		1.0
16:1			19:1			0		1.0
17:1			24:1			3		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			25:1			0		1.0

Alignment 1188
This was shown in configuration Ours\_w/oRANSAC , where the same formula xx are applied without spatial verification step .
This was shown in configuration Ours\_w/oRANSAC , where the same formulae xx are applied without any spatial verification step .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			1		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0

Alignment 1189
In this paper , we address about the failure of spatial verification in instance search or /object retrieval system .
In this paper , we addressed the failure of spatial verification in instance search/object retrieval systems .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			1		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
14:1			17:1			0		1.0
15:1			18:1			1		1.0
16:1			19:1			0		1.0

Alignment 1190
A new hybrid method that takes advantage of the complementary characteristic of BOW and DPM model has been introduced to overcome this challenge .
A new hybrid method that takes advantage of the complementary characteristics of the BOW and DPM models has been introduced to overcome this challenge .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:2			10:2			3		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			1		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0

Alignment 1191
We classify pairs of verified visual words into three types based on the relationship between location of visual words and proposal region .
We classify pairs of verified visual words into three types based on the relationship between the location of visual words and the region .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0

Alignment 1192
Each of this type corresponds to a weighting function which will boost the similarity score in re-ranking step .
Each of these types corresponds to a weighting function that will boost the similarity score at the time of re-ranking .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:2			2:2			3		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:2			8:2			3		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
19:1			16:1			0		1.0
20:1			18:1			0		1.0

Alignment 1193
Our experimental results show the superiority of our method compared to other state-of-the-art approaches .
Experimental results demonstrate the superiority of our method compared to other state-of-the-art approaches .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			2:1			0		1.0
2:1			3:1			2		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0

Alignment 1194
Future work will involve exploring adaptive late fusion technique for the base score which combine the normalized BOW and DPM similarity score .
Our future work will involve exploring adaptive late fusion techniques for the base score that combine the normalized BOW and DPM similarity scores .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			1		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:2			13:2			3		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			1		1.0
23:1			22:1			0		1.0

Alignment 1195
Moreover , our scheme enables us to replace DPM byh any other object detectors without changing the structure of the system .
Our scheme enables us to replace the DPM with other object detectors without changing the structure of the system .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			3:1			0		1.0
2:1			4:1			0		1.0
3:1			5:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
7:1			8:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0

Alignment 1196
A Minimum-Delay Routing Tree Algorithm for Access-Point Communications in Wireless Mesh Networks
A Minimum-Delay Routing Tree Algorithm for Access-Point Communications in Wireless Mesh Networks
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 1197
As a scalable , flexible access network to the Internet , we have studied the design optimization and the implementation of the Wireless Internet-access Mesh NETwork ( WIMNET ) .
As a scalable , flexible access network to the Internet , we have studied the design optimization and the implementation of the Wireless Internet-access Mesh NETwork ( WIMNET ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0

Alignment 1198
WIMNET is composed of multiple access points ( APs ) that are connected with each other by wireless communications .
WIMNET is composed of multiple access points ( APs ) that are connected with each other by wireless communications .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 1199
At least one AP performs as the gateway ( GW ) to the Internet .
At least one AP performs as the gateway ( GW ) to the Internet .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 1200
Any host in the network can access to the Internet through this GW , after associating its neighbor AP and communicating with multihop wireless links between APs .
Any host in the network can access to the Internet through this GW , after associating its neighbor AP and communicating with multihop wireless links between APs .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0

Alignment 1201
The delay along the routing path degrades the performance of WIMNET .
The delay along the routing path degrades the performance of WIMNET .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 1202
To avoid the bottleneck of communications by minimizing the maximum delay , we formulate the routing tree problem for AP communications , and prove the NP-completeness of its decision version .
To avoid the bottleneck of communications by minimizing the maximum delay , we formulate the routing tree problem for AP communications , and prove the NP-completeness of its decision version .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0

Alignment 1203
Then , we propose the greedy heuristic algorithm of sequentially selecting one link that minimizes the delay of the predicted tree containing the link .
Then , we propose the greedy heuristic algorithm of sequentially selecting one link that minimizes the delay of the predicted tree containing the link .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 1204
The effectiveness of our algorithm is verified through extensive simulations in instances with 25 APs using the WIMNET simulator .
The effectiveness of our algorithm is verified through extensive simulations in instances with 25 APs using the WIMNET simulator .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 1205
Nowadays , the Internet has become widely used in our daily lives with rapid developments of inexpensive small communication devices and high-speed communication technology .
Nowadays , the Internet has become widely used in our daily lives with the rapid development of inexpensive small communication devices and high-speed communication technology .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			1		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0

Alignment 1206
A variety of information , data , and services have actually been provided through the Internet .
A variety of information , data , and services have actually been provided through the Internet .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 1207
As a result , a high-speed , flexible , and inexpensive Internet access in every place at any time has been strongly desired among users by using wireless communication devices at mobile hosts such as personal computers ( PCs ) and personal digital assistances ( PDAs ) .
As a result , a high-speed , flexible , and inexpensive Internet access has been strongly desired by those who use wireless communication devices at mobile hosts such as personal computers ( PCs ) and personal digital assistances ( PDAs ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			19:1			0		1.0
14:1			20:1			0		1.0
15:1			21:1			0		1.0
16:1			22:1			0		1.0
17:1			25:1			0		1.0
19:2			26:1			3		1.0
21:1			27:1			0		1.0
22:1			28:1			0		1.0
23:1			29:1			0		1.0
24:1			30:1			0		1.0
25:1			31:1			0		1.0
26:1			32:1			0		1.0
27:1			33:1			0		1.0
28:1			34:1			0		1.0
29:1			35:1			0		1.0
30:1			36:1			0		1.0
31:1			37:1			0		1.0
32:1			38:1			0		1.0
33:1			39:1			0		1.0
34:1			40:1			0		1.0
35:1			41:1			0		1.0
36:1			42:1			0		1.0
37:1			43:1			0		1.0
38:1			44:1			0		1.0
39:1			45:1			0		1.0
40:1			46:1			0		1.0
41:1			47:1			0		1.0

Alignment 1208
In order to meet these demands , wireless local area networks ( WLANs ) have been widely studied and deployed as the access network to the Internet .
In order to meet these demands , wireless local area networks ( WLANs ) have been widely studied and deployed as the access network to the Internet .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0

Alignment 1209
WLANs have now become available in many private and public spaces including offices , schools , homes , airports , stations , and shopping malls .
WLANs have now become available in many private and public spaces including offices , schools , homes , airports , stations , and shopping malls .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 1210
The wireless mesh network has emerged as a very attractive technology among academics and industries to flexibly and inexpensively realize a large-scale WLAN </CITE> .
An emergency technology called the wireless mesh network is considered attractive and praise by academics and industries as a flexible and inexpensice large-scale WLAN </CITE> .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			10:1			0		1.0
5:1			1:1			0		1.0
6:1			2:1			0		1.0
7:1			3:1			0		1.0
8:1			4:1			3		1.0
10:1			9:1			0		1.0
11:1			17:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			6:1			0		1.0
18:1			7:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0

Alignment 1211
The wireless mesh network is composed of multiple wireless routers that are distributed in the network field , so that it can expand the wireless coverage area by a single router that is often limited into a small space .
It is composed of multiple wireless routers distributed in the network field , so that it can expand the wireless coverage area by a single router that is often confined to a small space .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			4:1			0		1.0
2:1			5:1			0		1.0
3:1			6:1			0		1.0
4:1			7:1			0		1.0
5:1			8:1			0		1.0
6:1			9:1			0		1.0
7:1			12:1			0		1.0
8:1			13:1			0		1.0
9:1			14:1			0		1.0
10:1			15:1			0		1.0
11:1			16:1			0		1.0
12:1			17:1			0		1.0
13:1			18:1			0		1.0
14:1			19:1			0		1.0
15:1			20:1			0		1.0
16:1			21:1			0		1.0
17:1			22:1			0		1.0
18:1			23:1			0		1.0
19:1			24:1			0		1.0
20:1			25:1			0		1.0
21:1			26:1			0		1.0
22:1			27:1			0		1.0
23:1			28:1			0		1.0
24:1			29:1			0		1.0
25:1			30:1			0		1.0
26:1			31:1			0		1.0
27:1			32:1			0		1.0
28:1			33:1			0		1.0
29:1			34:1			2		1.0
31:1			36:1			0		1.0
32:1			37:1			0		1.0
33:1			38:1			0		1.0
34:1			39:1			0		1.0

Alignment 1212
In the wireless mesh network , data communications between routers are offered by multihop wireless communications , in addition to those between routers and hosts .
In the wireless mesh network , data communications between routers are offered by multihop wireless communications , in addition to those between routers and hosts .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 1213
Among several variations of the wireless mesh network , our study has focused on the network for the Internet access , called the Wireless Internet-access Mesh NETwork ( WIMNET ) for convenience .
Among several variations of the wireless mesh network , our study has focused on the network for the Internet access , called the Wireless Internet-access Mesh NETwork ( WIMNET ) for convenience .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0

Alignment 1214
WIMNET uses only access points ( APs ) as wireless routers , and realizes wireless communications between APs mainly on the MAC layer using the wireless distribution system ( WDS ) </CITE> .
WIMNET uses only access points ( APs ) as wireless routers , and realizes wireless communications between APs mainly on the MAC layer using the wireless distribution system ( WDS ) </CITE> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0

Alignment 1215
Figure 1 illustrates the overview of WIMNET .
Figure 1 illustrates the overview of WIMNET .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 1216
At least one AP in WIMNET acts as a gateway ( GW ) to the Internet .
At least one AP in WIMNET acts as a gateway ( GW ) to the Internet .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 1217
In WIMNET , each AP takes two different roles for wireless communications , specifically a wireless hub for its associated hosts and a wireless bridge for relaying packets between APs .
In WIMNET , each AP takes two different roles for wireless communications , specifically a wireless hub for its associated hosts and a wireless bridge for relaying packets between APs .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0

Alignment 1218
To reduce the radio interference between these two communications , we use different protocols with different channels ( radio frequencies ) for them .
To reduce the radio interference between these two communications , we use different protocols with different channels ( radio frequencies ) for them .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 1219
Actually , we assign the IEEE 802.11b/g protocol with 2.4GHz for the former role , which is usually available at mobile hosts , and the IEEE 802.11a protocol with 5GHz for the latter one .
Actually , we assign the IEEE 802.11b/g protocol with 2.4GHz for the former role , which is usually available at mobile hosts , and the IEEE 802.11a protocol with 5GHz for the latter one .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0

Alignment 1220
For each protocol , several non-interfered frequency channels are available .
For each protocol , several non-interfered frequency channels are available .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 1221
Using this feature , an AP can use multiple channels by equipped with multiple NICs ( Network Interface Cards ) to increase the bandwidth </CITE> .
Using this feature , an AP can use multiple channels by equipped with multiple NICs ( Network Interface Cards ) to increase the bandwidth </CITE> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 1222
For the optimal design of WIMNET , we have studied related combinatorial optimization problems and their algorithms .
For the optimal design of WIMNET , we have studied related combinatorial optimization problems and their algorithms .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 1223
In </CITE> , we defined the AP allocation problem with its heuristic algorithms .
In </CITE> , we defined the AP allocation problem with its heuristic algorithms .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 1224
In </CITE> , we studied the gateway AP selection problem .
In </CITE> , we studied the gateway AP selection problem .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 1225
In </CITE> , we studied the NIC and channel assignment problem .
In </CITE> , we studied the NIC and channel assignment problem .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 1226
As the size of WIMNET is expanded , two factors may determine its performance of communications .
As the size of WIMNET is expanded , two factors may determine its performance of communications .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 1227
The first factor is the increase of the transmission delay at wireless links between GWs and their adjacent APs .
The first factor is the increase of the transmission delay at wireless links between GWs and their adjacent APs .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 1228
In WIMNET , all the packets to/from user hosts associated with APs other than GWs , must be handled by a GW to access the Internet .
In WIMNET , all the packets to/from user hosts associated with APs other than GWs must be handled by a GW to access the Internet .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0

Alignment 1229
Thus , wireless communications around GWs can be very crowded , and one link between GW and its adjacent AP may become the bottleneck of the whole communication in WIMNET .
Thus , wireless communications around GWs can be very crowded , and one link between GW and its adjacent AP may become the bottleneck of the whole communication in WIMNET .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0

Alignment 1230
The second factor is the propagation delay due to multihop communications between an AP and GW .
The second factor is the propagation delay due to multihop communications between an AP and GW .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 1231
The increase of the hop count ( the number of hops ) in the multihop communication directly increases the delay , because packets are transmitted in a bucket brigade way .
The increase of the hop count ( the number of hops ) in the multihop communication directly increases the delay , because packets are transmitted in a bucket - brigade manner .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			2		1.0
31:1			30:1			0		1.0

Alignment 1232
It can also increase the transmission delay , because more links need to be activated .
It can also increase the transmission delay because more links need to be activated .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0

Alignment 1233
Therefore , the proper routing for communications between APs to minimize both delays is very important to improve the performance of the large-scale WIMNET .
Therefore , the proper routing for communications between APs to minimize both delays is very important to improve the performance of the large-scale WIMNET .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 1234
The routing paths for AP communications in WIMNET with a single GW becomes a spanning tree rooted at GW of the graph representing the AP network topology , because every AP must be connected with GW for the Internet access .
The routing paths for AP communications in WIMNET with a single GW becomes a spanning tree rooted at GW of the graph representing the AP network topology , because every AP must be connected with GW for the Internet access .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0

Alignment 1235
In this paper , using this graph representation , we formulate the minimum-delay routing tree problem to find optimal routing paths for AP communications in WIMNET .
In this paper , using this graph representation , we formulate the minimum-delay routing tree problem to find optimal routing paths for AP communications in WIMNET .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 1236
We prove the NPcompleteness of the decision version through reduction from the NP-complete bin packing problem </CITE> .
We prove the NPcompleteness of the decision version via a reduction from the NP-complete bin packing problem </CITE> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:2			8:1			3		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0

Alignment 1237
Then , we propose the greedy heuristic algorithm for this problem .
Then , we propose the greedy heuristic algorithm for this problem .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 1238
For the proper routing , the precise estimations of both delays become essential .
The precise estimations of both delays are essential for the proper routing .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			6:1			0		1.0
2:1			7:1			0		1.0
3:1			8:1			0		1.0
4:1			9:1			0		1.0
5:1			10:1			0		1.0
6:2			11:2			3		1.0
9:1			1:1			0		1.0
10:1			2:1			0		1.0
11:1			3:1			0		1.0
12:1			13:1			0		1.0

Alignment 1239
The propagation delay to an AP can be easily estimated by the summation of the link delays along the path between this AP and GW .
The propagation delay to an AP can be easily estimated by the summation of the link delays along the path between this AP and GW .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 1240
However , the estimation of the transmission delay of a link is hard during the tree construction in the greedy algorithm .
However , it is hard to estimate the transmission delay of a link during the tree construction in the greedy algorithm .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			11:1			0		1.0
4:1			12:1			0		1.0
6:1			2:3			3		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 1241
Although this estimation requires the sum of traffics at the link that are transmitted from all the APs along the same path as described later , this path can be known after the routing tree is completed .
Although this estimation requires the sum of traffics at the link that are transmitted from all the APs along the same path as described later , this path can be known after the routing tree is completed .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0

Alignment 1242
Therefore , before selecting one link to construct a routing tree , our algorithm predicts the remaining part of the tree using the Dijkstra shortest path algorithm with link delays , and estimates the transmission delay using the traffics along this predicted path .
Therefore , before selecting one link to construct a routing tree , our algorithm predicts the remaining part of the tree using the Dijkstra shortest path algorithm with link delays , and estimates the transmission delay using the traffics along this predicted path .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0

Alignment 1243
The effectiveness of our approach is evaluated through simulations using the WIMNET simulator </CITE> that has been developed by our group .
The effectiveness of our approach is evaluated through simulations using the WIMNET simulator </CITE> that has been developed by our group .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 1244
The rest of this paper is organized as follows : Section II defines the minimum-delay routing tree problem in WIMNET .
The rest of this paper is organized as follows : Section II defines the minimum-delay routing tree problem in WIMNET .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 1245
Section IV proves the NP-completeness of its decision version .
Section IV proves the NP-completeness of its decision version .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 1246
Section IV presents our greedy heuristic algorithm .
Section IV presents our greedy heuristic algorithm .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 1247
Section V shows evaluation results of our algorithm by simulations .
Section V shows evaluation results of our algorithm by simulations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 1248
Section VI notes some related works .
Section VI notes some related works .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0

Alignment 1249
Section VII provides the conclusion and some future works of this paper .
Section VII provides the conclusion and some future works of this paper .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 1250
In the minimum-delay routing tree problem for AP communications in WIMNET , the AP network topology , G = ( V , E ) , is given as the input with one GW to the Internet .
In the minimum-delay routing tree problem for AP communications in WIMNET , the AP network topology , G = ( V , E ) , is given as the input with one GW to the Internet .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0

Alignment 1251
A vertex in V represents an AP and an edge in E represents a wireless link between two APs .
A vertex in V represents an AP and an edge in E represents a wireless link between two APs .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 1252
Every vertex in V and every edge in E are associated with non-negative weights .
Every vertex in V and every edge in E are associated with non-negative weights .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 1253
The weight hi for the ith AP ( =APi ) represents the expected number of hosts associated with this AP .
The weight hi for the ith AP ( =APi ) represents the expected number of hosts associated with this AP .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 1254
The weight sij for the link from APi to AP j ( =linkij ) represents the bandwidth or the transmission speed .
The weight sij for the link from APi to AP j ( =linkij ) represents the bandwidth or the transmission speed .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 1255
They are estimated or observed beforehand to design WIMNET properly .
They are estimated or observed beforehand to design WIMNET properly .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 1256
Then , the traffic through each link in E is estimated from vertex weights , assuming that every host communicates the same amount of traffic to/from the Internet .
Then , the traffic through each link in E is estimated from vertex weights , assuming that every host communicates the same amount of traffic to/from the Internet .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 1257
The objective of this problem is to minimize the two delays described in Section I .
The objective of this problem is to minimize the two delays described in Section I .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 1258
The propagation delay Di prop for APi is given by the summation of link delays along the route Pi from GW to APi .
The propagation delay Di prop for APi is given by the summation of link delays along the route Pi from GW to APi .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 1259
Because the link delay is inversely proportional to the bandwidth , Di prop is given by : </Eq> ( 1 )
Because the link delay is inversely proportional to the bandwidth , Di prop is given by : </Eq> ( 1 )
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 1260
The transmission delay Di trans for the link between GW and its adjacent AP ( let APi ) is given by the transmission time of all the traffics at this bottleneck link .
The transmission delay Di trans for the link between GW and its adjacent AP ( let APi ) is given by the transmission time of all the traffics at this bottleneck link .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0

Alignment 1261
Dtrans i is given by : </Eq> ( 2 ) where AP g represents GW , and </Eq> represents the traffic of link </Eq> , which will be discussed in II-C .
Dtrans i is given by : </Eq> ( 2 ) where AP g represents GW , and </Eq> represents the traffic of link </Eq> , which will be discussed in II-C .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0

Alignment 1262
Then , the cost function E is defined to represent the minimization of the largest propagation delay and the largest transmission delay in the routing tree .
Then , the cost function E is defined to represent the minimization of the largest propagation delay and the largest transmission delay in the routing tree .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 1263
E is given by : </Eq> ( 3 ) where </Eq> and </Eq> represent constant coefficients , the function </Eq> returns the maximum value in the set S , and Ng represents the set of APs adjacent to GW .
E is given by : </Eq> ( 3 ) where </Eq> and </Eq> represent constant coefficients , the function </Eq> returns the maximum value in the set S , and Ng represents the set of APs adjacent to GW .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0

Alignment 1264
Note that </Eq> = 200 and </Eq> = 1 are used in our simulations .
Note that </Eq> = 200 and </Eq> = 1 are used in our simulations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 1265
We formulate this minimum-delay routing tree problem as a combinatorial optimization problem .
We formulate this minimum-delay routing tree problem as a combinatorial optimization problem .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 1266
Input : G = ( V , E ) : the AP network topology with </Eq> : a gateway to the Internet , hi : the expected number of hosts associated with APi for </Eq> , </Eq> : the bandwidth of </Eq> for </Eq> and </Eq> , TRs : the average sending traffic from a host , and TRr : the average receiving traffic to a host .
Input : G = ( V , E ) : the AP network topology with </Eq> : a gateway to the Internet , hi : the expected number of hosts associated with APi for </Eq> , </Eq> : the bandwidth of </Eq> for </Eq> and </Eq> , TRs : the average sending traffic from a host , and TRr : the average receiving traffic to a host .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0
49:1			49:1			0		1.0
50:1			50:1			0		1.0
51:1			51:1			0		1.0
52:1			52:1			0		1.0
53:1			53:1			0		1.0
54:1			54:1			0		1.0
55:1			55:1			0		1.0
56:1			56:1			0		1.0
57:1			57:1			0		1.0
58:1			58:1			0		1.0
59:1			59:1			0		1.0
60:1			60:1			0		1.0
61:1			61:1			0		1.0
62:1			62:1			0		1.0
63:1			63:1			0		1.0
64:1			64:1			0		1.0
65:1			65:1			0		1.0
66:1			66:1			0		1.0
67:1			67:1			0		1.0

Alignment 1267
Output : T : the routing tree .
Output : T : the routing tree .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 1268
Constraint : T must include every AP in V ( T must be a spanning tree rooted at GW ) .
Constraint : T must include every AP in V ( T must be a spanning tree rooted at GW ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 1269
Objective : to minimize the cost function E in ( 3 ) .
Objective : to minimize the cost function E in ( 3 ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 1270
The traffic of a link is given by the summation of the traffics to/from the APs along the path located on the opposite side of this link from GW in the routing tree T , because these traffics must be transmitted through this link to access the Internet in this multihop network .
The traffic of a link is given by the summation of the traffics to/from the APs along the path located on the opposite side of this link from GW in the routing tree T , because these traffics must be transmitted through this link to access the Internet in this multihop network .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0
49:1			49:1			0		1.0
50:1			50:1			0		1.0
51:1			51:1			0		1.0
52:1			52:1			0		1.0

Alignment 1271
1 ) Initialization of the traffic of </Eq> : </Eq> .
1 ) Initialization of the traffic of </Eq> : </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 1272
2 ) Calculation of the traffic of </Eq> : </Eq> and </Eq> if </Eq> is included in Pk .
2 ) Calculation of the traffic of </Eq> : </Eq> and </Eq> if </Eq> is included in Pk .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 1273
Figure 2 shows that the traffic of the link from GW to its adjacent AP is calculated by the summation of the traffics to the APs along the same path in the routing tree , because they must be transmitted by this link . tk ( k = 1 , 2 , 3 , 4 ) represents the traffic to APk .
Figure 2 shows that the traffic of the link from GW to its adjacent AP is calculated by the summation of the traffics to the APs along the same path in the routing tree , because they must be transmitted by this link . tk ( k = 1 , 2 , 3 , 4 ) represents the traffic to APk .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0
49:1			49:1			0		1.0
50:1			50:1			0		1.0
51:1			51:1			0		1.0
52:1			52:1			0		1.0
53:1			53:1			0		1.0
54:1			54:1			0		1.0
55:1			55:1			0		1.0
56:1			56:1			0		1.0
57:1			57:1			0		1.0
58:1			58:1			0		1.0
59:1			59:1			0		1.0
60:1			60:1			0		1.0
61:1			61:1			0		1.0

Alignment 1274
In this section , the NP-completeness of the decision version of the minimum-delay routing tree problem is proved through reduction from the NP-complete bin packing problem </CITE> .
In this section , the NP-completeness of the decision version of the minimum-delay routing tree problem is proved via a reduction from the NP-complete bin packing problem </CITE> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:2			18:1			3		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0

Alignment 1275
The decision version of the minimum-delay routing tree problem , Min-Tree , is defined as follows :
The decision version of the minimum-delay routing tree problem , Min-Tree , is defined as follows :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 1276
Instance : The same inputs as the minimum-delay routing tree problem in II-B and an additional constant E0 .
Instance : The same inputs as the minimum-delay routing tree problem in II-B and an additional constant E0 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 1277
Question : Is there a routing tree to satisfy E ? E0 ?
Question : Is there a routing tree to satisfy E ? E0 ?
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 1278
The bin packing problem , Bin-packing , is defined as the following decision problem :
The bin packing problem , Bin-packing , is defined as the following decision problem :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 1279
Instance : a set of M cups with water of volume </Eq> for cup i , and L bins with a constant volume B .
Instance : a set of M cups with water of volume </Eq> for cup i , and L bins with a constant volume B .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 1280
Question : Is there a way of pouring the water of all the cups into bins without spilling , such that the whole water of any cup is poured into the same bin ?
Question : Is there a way of pouring the water of all the cups into bins without spilling , such that the whole water of any cup is poured into the same bin ?
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0

Alignment 1281
Clearly , Min-Tree belongs to the class NP .
Clearly , Min-Tree belongs to the class NP .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 1282
Then , we show that an arbitrary instance of Bin-packing can be transformed into the following Min-Tree instance :
Then , we show that an arbitrary instance of Bin-packing can be transformed into the following Min-Tree instance :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 1283
Input : G = ( V , E ) : GW ( =AP0 ) is connected with the K APs ( =APi for </Eq> ) , where the K APs are connected with all of the remaining M APs ( =APi for </Eq> ) , the M APs are connected with each other , and N = 1 + K + M , as shown in Figure 3 , </Eq> for </Eq> and </Eq> for </Eq> for </Eq> and </Eq> .
Input : G = ( V , E ) : GW ( =AP0 ) is connected with the K APs ( =APi for </Eq> ) , where the K APs are connected with all of the remaining M APs ( =APi for </Eq> ) , the M APs are connected with each other , and N = 1 + K + M , as shown in Figure 3 , </Eq> for </Eq> and </Eq> for </Eq> for </Eq> and </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0
49:1			49:1			0		1.0
50:1			50:1			0		1.0
51:1			51:1			0		1.0
52:1			52:1			0		1.0
53:1			53:1			0		1.0
54:1			54:1			0		1.0
55:1			55:1			0		1.0
56:1			56:1			0		1.0
57:1			57:1			0		1.0
58:1			58:1			0		1.0
59:1			59:1			0		1.0
60:1			60:1			0		1.0
61:1			61:1			0		1.0
62:1			62:1			0		1.0
63:1			63:1			0		1.0
64:1			64:1			0		1.0
65:1			65:1			0		1.0
66:1			66:1			0		1.0
67:1			67:1			0		1.0
68:1			68:1			0		1.0
69:1			69:1			0		1.0
70:1			70:1			0		1.0
71:1			71:1			0		1.0
72:1			72:1			0		1.0
73:1			73:1			0		1.0
74:1			74:1			0		1.0
75:1			75:1			0		1.0
76:1			76:1			0		1.0
77:1			77:1			0		1.0
78:1			78:1			0		1.0
79:1			79:1			0		1.0
80:1			80:1			0		1.0

Alignment 1284
In this Min-Tree instance , the cost function E in ( 3 ) is equal to the maximum traffic among the links incident to GW .
In this Min-Tree instance , the cost function E in ( 3 ) is equal to the maximum traffic among the links incident to GW .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 1285
The traffic of such a link is given by the summation of the traffics from the APs along the route to GW in the tree .
The traffic of such a link is given by the summation of the traffics from the APs along the route to GW in the tree .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 1286
Thus , each of K routes in the tree is equivalent to one bin packing of cups .
Thus , each of K routes in the tree is equivalent to one bin packing of cups .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 1287
This proves the NP-completeness of Min-Tree .
This proves the NP-completeness of Min-Tree .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0

Alignment 1288
In this section , we propose a greedy heuristic algorithm for the minimum-delay routing tree problem for AP communications in WIMNET .
In this section , we propose a greedy heuristic algorithm for the minimum-delay routing tree problem for AP communications in WIMNET .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 1289
In WIMNET , all the traffics of the hosts for the Internet access must pass through GW .
In WIMNET , all the traffics of the hosts for the Internet access must pass through GW .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 1290
When the hosts are associated with APs other than GW , their traffics must be transmitted by one of the links between GW and its adjacent APs .
When the hosts are associated with APs other than GW , their traffics must be transmitted by one of the links between GW and its adjacent APs .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0

Alignment 1291
Because the number of such links is usually small , the minimization of the transmission delay of one link among them may increase delays of the other links .
Because the number of such links is usually small , the minimization of the transmission delay of one link among them may increase delays of the other links .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 1292
To deal with this problem , our algorithm actually seeks the minimization of the difference between the maximum transmission delay and the minimum one .
To deal with this problem , our algorithm actually seeks the minimization of the difference between the maximum transmission delay and the minimum one .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 1293
This modified cost function is given by : </Eq> ( 4 ) where min </Eq> returns the minimum value in the set S .
This modified cost function is given by : </Eq> ( 4 ) where min </Eq> returns the minimum value in the set S .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 1294
Our algorithm greedily constructs the routing tree T = ( VT , ET ) by repeating the selection of one link that minimizes the modified cost function Em if it is added into T , until every AP is included in the tree .
Our algorithm greedily constructs the routing tree T = ( VT , ET ) by repeating the selection of one link that minimizes the modified cost function Em if it is added into T , until every AP is included in the tree .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0

Alignment 1295
To estimate the transmission delay in Em accurately , the complete routing tree is predicted by expanding the current partial tree using the Dijkstra shortest path algorithm in terms of the link delay .
To estimate the transmission delay in Em accurately , the complete routing tree is predicted by expanding the current partial tree using the Dijkstra shortest path algorithm in terms of the link delay .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0

Alignment 1296
Here , we note that the ?-term in Em is calculated from the current tree T with the selected link .
Here , we note that the ?-term in Em is calculated from the current tree T with the selected link .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 1297
In the procedure , the routing tree T = ( VT , ET ) is first initialized with GW , and then , T is sequentially constructed by selecting the best link of minimizing the cost function of the predicted tree one by one , until V T = V .
In the procedure , the routing tree T = ( VT , ET ) is first initialized with GW , and then , T is sequentially constructed by selecting the best link of minimizing the cost function of the predicted tree one by one , until V T = V .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0
49:1			49:1			0		1.0
50:1			50:1			0		1.0

Alignment 1298
1 ) Calculate the delay at linkij by </Eq> .
1 ) Calculate the delay at linkij by </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 1299
2 ) Initialize the routing tree T by V T=GW and </Eq> .
2 ) Initialize the routing tree T by V T=GW and </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 1300
3 ) Construct T by repeating the selection of the link satisfying the following two conditions , until every AP in V is included in T : it connects an </Eq> and an </Eq> , and when it is included in T , Em with the tree predicted in IV-C becomes minimum .
3 ) Construct T by repeating the selection of the link satisfying the following two conditions , until every AP in V is included in T : it connects an </Eq> and an </Eq> , and when it is included in T , Em with the tree predicted in IV-C becomes minimum .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0
49:1			49:1			0		1.0
50:1			50:1			0		1.0
51:1			51:1			0		1.0
52:1			52:1			0		1.0

Alignment 1301
The complete routing tree is predicted by expanding the current partial tree T by selecting the links that connect the remaining APs using the Dijkstra shortest path algorithm .
The complete routing tree is predicted by expanding the current partial tree T by selecting the links that connect the remaining APs using the Dijkstra shortest path algorithm .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 1302
1 ) Initialize the set of the unselected APs , A , by A = V , and the decision variables , AP weight labels ( propagation delay ) and AP route labels ( previous APs in paths from GW ) , in the Dijkstra algorithm using the current partial tree T as follows :
1 ) Initialize the set of the unselected APs , A , by A = V , and the decision variables , AP weight labels ( propagation delay ) and AP route labels ( previous APs in paths from GW ) , in the Dijkstra algorithm using the current partial tree T as follows :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0
49:1			49:1			0		1.0
50:1			50:1			0		1.0
51:1			51:1			0		1.0
52:1			52:1			0		1.0
53:1			53:1			0		1.0
54:1			54:1			0		1.0

Alignment 1303
a ) for AP weight labels : set the propagation delay in 1 for any </Eq> , and set </Eq> for the remaining APs .
a ) for AP weight labels : set the propagation delay in 1 for any </Eq> , and set </Eq> for the remaining APs .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 1304
b ) for AP route labels : set the previous AP along the route from GW in T for any AP in T , and set </Eq> for the remaining APs .
b ) for AP route labels : set the previous AP along the route from GW in T for any AP in T , and set </Eq> for the remaining APs .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0

Alignment 1305
2 ) Select one AP ( let APk ) in A that has the smallest weight label .
2 ) Select one AP ( let APk ) in A that has the smallest weight label .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 1306
3 ) Remove APk from A , and terminate the procedure if </Eq> .
3 ) Remove APk from A , and terminate the procedure if </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 1307
4 ) Update the both labels of the APs adjacent to </Eq> .
4 ) Update the both labels of the APs adjacent to </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 1308
In this section , we discuss the performance improvement by our approach through network simulations using the WIMNET simulator .
In this section , we discuss the performance improvement by our approach via network simulations using the WIMNET simulator .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			3		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 1309
The WIMNET simulator simulates the least functions for wireless communications of hosts and APs required to evaluate throughputs and delays , because this simulator has bee developed for evaluations of a large-scale WIMNET with reasonable CPU time on a conventional PC .
The WIMNET simulator simulates the least functions for wireless communications of hosts and APs required to evaluate throughputs and delays , because this simulator has bee developed for evaluations of a large-scale WIMNET with reasonable CPU time on a conventional PC .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0

Alignment 1310
Thus , a sequence of functions such as host movements , communication request arrivals , and wireless link activations , are synchronized by a single global clock called a time slot .
Thus , a sequence of functions such as host movements , communication request arrivals , and wireless link activations , are synchronized by a single global clock called a time slot .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0

Alignment 1311
Within an integral multiple of time slots , a host or an AP can complete the one frame transmission and the acknowledgement reception .
Within an integral multiple of time slots , a host or an AP can complete the one frame transmission and the acknowledgement reception .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 1312
In this paper , the duration time of one time slot is set 0.2ms .
In this paper , the duration time of one time slot is set 0.2ms .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 1313
From our past experimental results , the maximum bandwidth of links between APs is set 30Mbps , and that between an AP and hosts is 20Mbps .
From our past experimental results , the maximum bandwidth of links between APs is set 30Mbps , and that between an AP and hosts is 20Mbps .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 1314
Thus , the former link is completed with two slots , and the latter is with three slots , assuming every frame size is 1 , 500bytes .
Thus , the former link is completed with two slots , and the latter is with three slots , assuming every frame size is 1 , 500bytes .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0

Alignment 1315
When two or more links within their wireless ranges may be activated at the same time slot , randomly selected only one link among them is successfully activated , and the others are inserted into waiting queues to avoid collisions , supposing DCF and RTS/CTS functions .
When two or more links within their wireless ranges are activated at the same time slot , only one link , randomly selected , is successfully activated , and the others are inserted into waiting queues to avoid collisions , assuming DCF and RTS/CTS functions .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			32:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			20:1			0		1.0
18:1			21:1			0		1.0
19:1			22:1			0		1.0
20:1			28:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			0		1.0
23:1			40:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0
31:1			9:2			3		1.0
32:1			33:1			0		1.0
33:1			34:1			0		1.0
34:1			35:1			0		1.0
35:1			36:1			0		1.0
36:1			37:1			0		1.0
37:1			38:1			0		1.0
38:1			39:1			0		1.0
41:1			42:1			0		1.0
42:1			43:1			0		1.0
43:1			44:1			0		1.0
44:1			45:1			0		1.0
45:1			46:1			0		1.0

Alignment 1316
The packets for each request are routed along the path in the routing tree T .
The packets for each request are routed along the path in the routing tree T .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 1317
Only the connection-less communication is implemented in the WIMNET simulator , where the retransmission is not considered .
Only the connection-less communication is implemented in the WIMNET simulator , where the retransmission is not considered .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 1318
First , we verify our approach using rather artificial simple instances with fixed traffic patterns .
First , we verify our approach using rather artificial simple instances with fixed traffic patterns .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 1319
1 ) Simulated Instances : In the simulated instances , 5 ? 5 ( N = 25 ) APs are regularly placed with the same interval in the field .
1 ) Simulated Instances : In the simulated instances , 5 ? 5 ( N = 25 ) APs are regularly placed with the same interval in the field .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0

Alignment 1320
Each AP can communicate with its four neighbor APs , where any link has the same maximum bandwidth .
Each AP can communicate with its four neighbor APs , where any link has the same maximum bandwidth .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 1321
The center AP is selected as the gateway to the Internet .
The center AP is selected as the gateway to the Internet .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 1322
Two types of biased fixed traffic patterns , or host distributions , in the field shown in Figures 4 and 5 are considered .
Two types of biased fixed traffic patterns , or host distributions , in the field shown in Figures 4 and 5 are considered .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 1323
A white circle in both figures represents an AP associated with 1 host .
A white circle in both figures represents an AP associated with 1 host .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 1324
A black circle represents an AP with 8 hosts in Figure 4 and with 10 hosts in Figure 5 .
A black circle represents an AP with 8 hosts in Figure 4 and with 10 hosts in Figure 5 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 1325
We have selected them so that the total number of hosts in each instance becomes about 100 for the unification of loads .
We have selected them so that the total number of hosts in each instance becomes about 100 for the unification of loads .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 1326
These simple but extreme cases are used to clarify the superiority of our combined delay approach to single delay approaches .
These simple but extreme cases are used to clarify the superiority of our combined delay approach to single delay approaches .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 1327
For each traffic pattern , we first applied our routing tree algorithm in Section IV , and then , the channel configuration algorithm in </CITE> to optimally assign the traditional NICs to Aps and the channels to the communication links used in the routing tree .
For each traffic pattern , we first applied our routing tree algorithm in Section IV , and then , the channel configuration algorithm in </CITE> to optimally assign the traditional NICs to Aps and the channels to the communication links used in the routing tree .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0

Alignment 1328
Then , we executed the WIMNET simulator using the network configuration given by these algorithms .
Then , we executed the WIMNET simulator using the network configuration given by these algorithms .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 1329
Before starting each simulation run , every host has 125 packets sending to the gateway , and the gateway has 1 ,000 packets sending to each host , where each packet has a single frame size .
Before starting each simulation run , every host has 125 packets sending to the gateway , and the gateway has 1 ,000 packets sending to each host , where each packet has a single frame size .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0

Alignment 1330
When all of the packets are received by their destinations , one simulation run is terminated .
When all of the packets are received by their destinations , one simulation run is terminated .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 1331
For the network performance , the throughput is calculated by dividing the total received packet size with the simulation time .
For the network performance , the throughput is calculated by the total received packet size divided by the simulation time .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 1332
2 ) Simulation Results : In simulations , in addition to our algorithm ( proposal ) , the algorithm considering only the propagation delay ( comp1 ) , which has often been used in routing , and the algorithm considering only the transmission delay ( comp2 ) , are executed for comparisons .
2 ) Simulation Results : In simulations , in addition to our algorithm ( proposal ) , the algorithm considering only the propagation delay ( comp1 ) , which has often been used in routing , and the algorithm considering only the transmission delay ( comp2 ) , are executed for comparisons .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0
49:1			49:1			0		1.0
50:1			50:1			0		1.0
51:1			51:1			0		1.0
52:1			52:1			0		1.0

Alignment 1333
Figure 6 and 7 illustrate the routing trees obtained by three algorithms for traffic patterns 1 and 2 , respectively .
Figure 6 and 7 illustrate the routing trees obtained by three algorithms for traffic patterns 1 and 2 , respectively .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 1334
For both patterns , proposal and comp1 find trees with the shortest path for any AP , whereas comp2 does not find such a tree for traffic pattern 2 .
For both patterns , proposal and comp1 find trees with the shortest path for any AP , whereas comp2 does not find such a tree for traffic pattern 2 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0

Alignment 1335
Figures 8 and 9 show changes of throughputs when the number of additional NICs at Aps increases .
Figures 8 and 9 show changes of throughputs when the number of additional NICs at Aps increases .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 1336
When every AP is assigned only one NIC , the throughout is similar among them .
When every AP is assigned only one NIC , the throughout is similar among them .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 1337
The reason is that the bandwidth of the single channel shared among the links around GW , becomes the bottleneck of whole communications in WIMNET , where the gateway must handle every traffic from/to the Internet .
The reason is that the bandwidth of the single channel shared among the links around GW becomes the bottleneck of whole communications in WIMNET , where the gateway must handle every traffic from/to the Internet .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0
31:1			32:1			0		1.0
32:1			33:1			0		1.0
33:1			34:1			0		1.0
34:1			35:1			0		1.0
35:1			36:1			0		1.0

Alignment 1338
However , the throughput is improved by utilizing multiple channels even when a small number of additional NICs are used .
However , the throughput is improved by utilizing multiple channels even when a small number of additional NICs are used .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 1339
This improvement becomes best for proposal , where the routing tree gives the shortest path for any AP , and disperses traffics more equally among the bottleneck links .
This improvement becomes best for proposal , where the routing tree gives the shortest path for any AP , and disperses traffics more equally among the bottleneck links .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 1340
Then , we investigate the effectiveness of our approach with three different gateway positions in Figure 10 under random traffic patterns .
Then , we investigate the effectiveness of our approach with three different gateway positions in Figure 10 under random traffic patterns .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 1341
In these simulations , the number of associated hosts for each AP is randomly selected between 1 and 7 hosts for each of 50 runs where the total number of hosts in the field is always 100 .
In these simulations , the number of associated hosts for each AP is randomly selected between 1 and 7 hosts for each of 50 runs where the total number of hosts in the field is always 100 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0

Alignment 1342
Figure 11 shows changes of their average throughputs with the increase of additional NICs for three gateway positions .
Figure 11 shows changes of their average throughputs with the increase of additional NICs for three gateway positions .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 1343
When 13 Aps are added , the throughputs become saturated .
When 13 Aps are added , the throughputs become saturated .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 1344
This maximum throughput is about 120Mbps for the center GW , 90Mbps for the edge-center GW , and 60Mbps for the corner GW .
This maximum throughput is about 120Mbps for the center GW , 90Mbps for the edge-center GW , and 60Mbps for the corner GW .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 1345
These results are coincident with their rough estimations that can be given by sums of adjacent Aps .
These results are coincident with their rough estimations that can be given by sums of adjacent Aps .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 1346
This fact justifies our routing algorithm for these random instances .
This fact justifies our routing algorithm for these random instances .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 1347
Several works have been reported for routings of point-to-point communications in wireless mesh networks .
Several works have been reported for routings of point-to-point communications in wireless mesh networks .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 1348
Unfortunately , the realization of this synchronous wireless mesh network is very hard , and the superiority of the performance is actually not clear to the conventional asynchronous one including this paper .
Unfortunately , the realization of this synchronous wireless mesh network is very hard , and the superiority of the performance is actually not clear to the conventional asynchronous one including this paper .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0

Alignment 1349
Besides , it assumes that every AP has the same number of associated hosts and assigned NICs , which is different from out more practical assumption in this paper .
Besides , it assumes that every AP has the same number of associated hosts and assigned NICs , which is different from out more practical assumption in this paper .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0

Alignment 1350
ETT represents the average transmission time that can be calculated from the loss rate and the bandwidth of the link .
ETT represents the average transmission time that can be calculated from the loss rate and the bandwidth of the link .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 1351
WCETT is given by the summation of ETT along the route and the maximum of the summation of ETT for the links using the same channel .
WCETT is given by the summation of ETT along the route and the maximum of the summation of ETT for the links using the same channel .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 1352
This paper has presented the formulation of the minimum-delay routing problem for access-point communications in the wireless Internet-access mesh network ( WIMNET ) , and proved the NP-completeness of its decision version .
This paper has presented the formulation of the minimum-delay routing problem for access-point communications in the wireless Internet-access mesh network ( WIMNET ) , and proved the NP-completeness of its decision version .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0

Alignment 1353
Then , it has proposed the greedy heuristic algorithm with repetitions of complete tree predictions .
Then , it has proposed the greedy heuristic algorithm with repetitions of complete tree predictions .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 1354
The effectiveness of our approach is verified through simulations using the WIMNET simulator .
The effectiveness of our approach is verified through simulations using the WIMNET simulator .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 1355
The significant performance improvements with a small number of additional NICs are observed using proper routing trees found by our algorithm .
The significant performance improvements with a small number of additional NICs are observed using proper routing trees found by our algorithm .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 1356
In future works , our algorithm will be evaluated under non-uniform link bandwidths and/or dynamic traffic changes in simulations .
In future works , our algorithm will be evaluated under non-uniform link bandwidths and/or dynamic traffic changes in simulations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 1357
Besides , to justify our approach in the real world , the performance of WIMNET will be investigated after implementing real APs with multiple NICs .
Besides , to justify our approach in the real world , the performance of WIMNET will be investigated after implementing real APs with multiple NICs .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 1358
Quality Measurement for Transmitted Audio Data Using Distribution of Sub-band Signals
Quality Measurement for Transmitted Audio Data Using Distribution of Sub-band Signals
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 1359
Recently , the remarkable progress of network technology has increased the requirement for transmission of high quality multimedia data .
Recently , the remarkable progress of network technology has increased the requirement for transmission of high quality multimedia data .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 1360
By the trend , it has been issued to investigate an efficient methodology for quality measurement of transmitted multimedia data .
By the trend , it has been issued to investigate an efficient methodology for quality measurement of transmitted multimedia data .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 1361
In this paper , we propose a new audio quality measurement technique to substitute for a typical quality measurement tool , RMSE (Root Mean Squared Error) .
In this paper , we propose a new audio quality measurement technique to substitute for a typical quality measurement tool , RMSE (Root Mean Squared Error) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 1362
The proposed method modifies the variance of sub-band signals to perform the estimation of audio quality at the transmitter , the receiver is able to estimate the quality distortion of transmitted audio data by calculating the distance between the variance and the reference value representing the characteristics of sub-band signals , so called EVE (Estimated Variance Error) .
The proposed method modifies the variance of sub-band signals to perform the estimation of audio quality at the transmitter , the receiver is able to estimate the quality distortion of transmitted audio data by calculating the distance between the variance and the reference value representing the characteristics of sub-band signals , so called EVE (Estimated Variance Error) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0
49:1			49:1			0		1.0
50:1			50:1			0		1.0
51:1			51:1			0		1.0
52:1			52:1			0		1.0
53:1			53:1			0		1.0
54:1			54:1			0		1.0
55:1			55:1			0		1.0
56:1			56:1			0		1.0
57:1			57:1			0		1.0

Alignment 1363
The proposed is as no reference technique , it does not require the original data to measure the audio quality .
The proposed is not a reference technique , so it does not require the original data to measure the audio quality .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0

Alignment 1364
On the Gaussian noise channel with several standard deviations , we prove that the proposed scheme has good performance , and it is a novel alternative to RMSE .
On the Gaussian noise channel with several standard deviations , we prove that the proposed scheme has good performance , and it is a novel alternative to RMSE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 1365
With the rapid growth of the Internet , most consumers have requested for service providers to transmit the multimedia data with high quality .
With the rapid growth of the Internet , most consumers have requested for service providers to transmit the multimedia data with high quality .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 1366
It encourages the researchers to develop the compression technology such as MPEG ( Motion Pictures Experts Group ) and JPEG ( Joint Photographic Experts Group ) / JPEG-2000 , the network environment to guarantee the QoS ( Quality of Services ) , and so on .
It encourages the researchers to develop the compression technology such as MPEG ( Motion Pictures Experts Group ) and JPEG ( Joint Photographic Experts Group ) / JPEG-2000 , the network environment to guarantee the QoS ( Quality of Services ) , and so on .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0

Alignment 1367
Although the wellconstructed network environment is most important to satisfy the demands of consumers , it costs enormous expense since it is primarily based on the physical layer of OSI ( Open Systems Interconnection ) seven layers .
Although the wellconstructed network environment is most important to satisfy the demands of consumers , it is costly since it is primarily based on the physical layer of OSI ( Open Systems Interconnection ) seven layers .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			21:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0
31:1			32:1			0		1.0
32:1			33:1			0		1.0
33:1			34:1			0		1.0
34:1			35:1			0		1.0
35:1			36:1			0		1.0
36:1			37:1			0		1.0

Alignment 1368
For that reason , recently , it has become a new issue to research schemes for quality measurement of multimedia data on the application layer .
For that reason , recently , it has become a new issue to research schemes for quality measurement of multimedia data on the application layer .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 1369
It is a good methodology to solve the cost problem .
It is a good methodology to solve the cost problem .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 1370
Several quality measurement techniques of multimedia data have introduced by </CITE> .
Several quality measurement techniques of multimedia data have introduced by </CITE> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 1371
R .Reibman </CITE> proposed the quality monitoring techniques of video .
R .Reibman </CITE> proposed the quality monitoring techniques of video .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 1372
Compared with other researches , he introduced an especial method .
Compared with other studies , he introduced an especial method .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			3		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 1373
The proposed algorithm on </CITE> measures the quality distortion from the video bit-stream instead of the samples .
The proposed algorithm on </CITE> measures the quality distortion from the video bit-stream instead of the samples .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 1374
Through the simulations , he claimed that his proposed algorithm using bit error is related on the real quality of video .
Through the simulations , he claimed that his proposed algorithm using bit error is related to the real quality of video .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 1375
In </CITE> , they estimate the quality distortion of audio and still image by using fragile watermarking .
In </CITE> , they estimate the quality distortion of audios and still images by using fragile watermarking .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			1		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			1		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 1376
The proposed embeds watermark information into frequency components , which is obtained by DCT ( Discrete Cosine Transform ) or DWT ( Discrete Wavelet Transform ) .
The method embeds watermark information into frequency components , which can be obtained by DCT ( Discrete Cosine Transform ) or DWT ( Discrete Wavelet Transform ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:2			10:1			3		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0

Alignment 1377
The measurement tool estimates the quality distortion from correct or incorrect extracted watermark bits .
The measurement tool estimates the quality distortion from correct or incorrect extracted watermark bits .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 1378
Even if the fragile watermark is broken proportional to channel error ratio , the embedded watermark could be easily distorted by unintentional error such as compressions .
Even if the fragile watermark is broken proportionally to channel error ratio , the embedded watermark could be easily distorted by such unintentional errors as compressions .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			1		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			23:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			1		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 1379
Moreover it is difficult to decide a feature to embed watermark , which is sensitive to quality distortion .
Moreover it is difficult to decide a feature to embed watermark , which is sensitive to quality distortion .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 1380
In this paper , we propose a new audio quality measurement technique .
In this paper , we propose a new audio quality measurement technique .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 1381
The proposed uses the distribution of sub-band signals , which is obtained by DWT .
It uses the distribution of sub-band signals , which is obtained by DWT .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0

Alignment 1382
At the transmitter , we alter the variance of sub-band signals into the constant value .
At the transmitter , we alter the variance of sub-band signals into the constant value .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 1383
The receiver , audio quality monitor , calculates the variance error from the constant value .
The receiver monitors the audio quality by calculating the variance error from the constant value .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
7:1			7:1			1		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 1384
We denominate it as EVE ( Estimated Variance Error ) .
We denominate it as EVE ( Estimated Variance Error ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 1385
In general , since the variance moves according to changing of signals , we could estimate the quality distortion through checking the distance of variance .
In general , since the variance moves according to the changing of signals , we could estimate the quality distortion by checking the distance of variance .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			21:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
21:1			20:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0

Alignment 1386
And , modifying the specific sub-band signals can decrease the distortion caused by the process of transmitter since modifying the variance of whole sub-band signals is waste of resource .
And , modifying the specific sub-band signals can decrease the distortion caused by the process of transmission since modifying the variance of whole sub-band signals is a waste of resource .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0

Alignment 1387
Besides , it allows us to select the optimal sub-band , which is most sensitive to noise .
Besides , it allows us to select the optimal sub-band , which is most sensitive to noise .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 1388
Note that a quality measurement system should be able to estimate the quantity of noise from the transmitted multimedia data .
Note that a quality measurement system should be able to estimate the quantity of noise from the transmitted multimedia data .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 1389
Moreover , the proposed is no reference quality measurement technique , that is , it does not require the original audio data on the receiver .
Moreover , the proposed is no reference quality measurement technique ; that is , it does not require the original audio data on the receiver .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 1390
In section II , we describe our quality measurement technique using the distribution of sub-band signals in more detail .
In section II , we describe our quality measurement technique using the distribution of sub-band signals in more detail .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 1391
Section III shows the simulation results .
Section III shows the simulation results .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0

Alignment 1392
To demonstrate the efficiency of the proposed method , we compare the result with RMSE ( Root Mean Square Error ) on Gaussian noise channel .
To demonstrate the efficiency of the proposed method , we compare the result with RMSE ( Root Mean Square Error ) on the Gaussian noise channel .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0

Alignment 1393
Finally , we conclude this paper in section IV .
Finally , we conclude this paper in section IV .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 1394
In transmitting the multimedia data through wired / wireless network , the quality is almost dependent on channel noise .
In transmitting the multimedia data through wired / wireless network , the quality is almost dependent on channel noise .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 1395
Especially , if the characteristic of channel is represented by a kind of additive noise , RMSE ( Root Mean Squared Error ) can be used as a good quality measurement tool .
Especially , if the characteristic of channel is represented by a kind of additive noise , RMSE ( Root Mean Squared Error ) can be used as a good quality measurement tool .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0

Alignment 1396
RMSE can be redefined by the difference of variance between the original data and the transmitted data .
RMSE can be redefined by the difference of variance between the original data and the transmitted data .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 1397
It is proved in appendix .
It is proved in the appendix .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0

Alignment 1398
In this paper , we propose a quality measurement technique for transmitted audio data using the variance of sub-band signals , which is obtained by DWT ( Discrete Wavelet Transform ) .
In this paper , we propose a quality measurement technique for transmitted audio data using the variance of sub-band signals , which is obtained by DWT ( Discrete Wavelet Transform ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0

Alignment 1399
Fig . 1 shows the proposed quality measurement system .
Fig . 1 shows the proposed quality measurement system .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 1400
The proposed method modifies the variance of sub-band signals into constant value , so called reference value , and estimates the quality distortion from the distance between the variance of transmitted audio data and the constant value .
The method modifies the variance of sub-band signals into constant value , or reference value and estimates the quality distortion from the distance between the variance of transmitted audio data and the constant value .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			18:1			0		1.0
16:1			19:1			0		1.0
17:1			20:1			0		1.0
18:1			21:1			0		1.0
19:1			22:1			0		1.0
20:1			23:1			0		1.0
21:1			24:1			0		1.0
22:1			25:1			0		1.0
23:1			26:1			0		1.0
24:1			27:1			0		1.0
25:1			28:1			0		1.0
26:1			29:1			0		1.0
27:1			30:1			0		1.0
28:1			31:1			0		1.0
29:1			32:1			0		1.0
30:1			33:1			0		1.0
31:1			34:1			0		1.0
32:1			35:1			0		1.0
33:1			36:1			0		1.0
34:1			37:1			0		1.0

Alignment 1401
The reason of employing the sub-band signals for modifying the variance is that altering the whole frequency band signals has an influence on the distortion of audio quality .
The reason of employing the sub-band signals for modifying the variance is that altering the whole frequency band signals has an influence on the distortion of audio quality .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 1402
Fig . 2 shows the main idea of proposed scheme .
Fig . 2 shows the main idea of the proposed scheme .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0

Alignment 1403
For the sake of simplicity , let’s assume that the sub-band signals is a random variable , X , with uniform distribution as shown in Fig . 2-(a) .
For the sake of simplicity , let’s assume that the sub-band signals is a random variable , X , with a uniform distribution as shown in Fig . 2-(a) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0

Alignment 1404
The distribution is modified according to reference value .
The distribution is modified according to the reference value .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0

Alignment 1405
For bigger reference value , the sub-band signals are modified to make their distribution concentrate on the mean value as shown in Fig . 2-(b) .
For bigger reference values , the sub-band signals are modified to make their distribution concentrate on the mean value as shown in Fig . 2-(b) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			1		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 1406
On the other hand , for smaller reference value , the distribution becomes more distance from the mean value as shown in Fig . 2-(c) .
On the other hand , for smaller reference values , the distribution becomes more distant from the mean value as shown in Fig . 2-(c) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			1		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			3		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 1407
The variance of random variable X with uniform distribution , </Eq> , is as follows .
The variance of random variable X with uniform distribution , </Eq> , is as follows .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 1408
That is , if we know the characteristics of signals , the reference value can be determined as constant value .
That is , if we know the characteristics of signals , the reference value can be determined as constant value .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 1409
The quality measurement is quite easily performed , as the quality distortion can be estimated just by calculating the distance of variance from reference value .
The quality measurement is quite easily performed , as the quality distortion can be estimated just by calculating the distance of variance from the reference value .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0

Alignment 1410
It means that the proposed can measure the audio quality without the original data .
It means that the method can measure the audio quality without the original data .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 1411
It is greatly correlated with RMSE .
It is greatly correlated with RMSE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0

Alignment 1412
Therefore , we designate the estimated RMSE as EVE ( Estimated Variance Error )
Therefore , we designate the estimated RMSE as EVE ( Estimated Variance Error )
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 1413
To measure the audio quality at the transmission side , we modify the variance of sub-band signals of original data into reference value .
To measure the quality of the transmission audio , we modify the variance of sub-band signals of original data into reference values .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			4:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			3:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			1		1.0
22:1			23:1			0		1.0

Alignment 1414
The original signal is decomposed into several sub-band signals by using DWT .
The original signal is decomposed into several sub-band signals by using DWT .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 1415
Fig . 3 shows the procedure of modifying the variance of original audio data into reference value .
Fig . 3 shows the procedure of modifying the variance of original audio data into reference values .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			1		1.0
17:1			17:1			0		1.0

Alignment 1416
Let’s consider only the simple system decomposed into two channel .
Let’s consider only the simple system decomposed into two channels .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			1		1.0
10:1			10:1			0		1.0

Alignment 1417
Firstly , the original signal </Eq> where , N is the number of audio samples) is divided into M small frames , </Eq> , where , M is the number of frame) .
Firstly , the original signal </Eq> where , N is the number of audio samples) is divided into M small frames , </Eq> , where , M is the number of frame) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0

Alignment 1418
The signal of each frame is converted onto normalized range [ -1 , 1 ] .
The signal of each frame is converted onto normalized range [ -1 , 1 ] .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 1419
The normalized j-th sample of i-th frame , </Eq> , is obtained by </Eq>
The normalized j-th sample of i-th frame , </Eq> , is obtained by </Eq>
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 1420
Where , max is the maximum value and min is the minimum value that an audio sample can have .
Where , max is the maximum value and min is the minimum value that an audio sample can have .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 1421
And then , each frame is decomposed into low frequency and high frequency band signals by analysis filter bank , HL(z) and HH(z) .
And then , each frame is decomposed into low frequency and high frequency band signals by analysis filter bank , HL(z) and HH(z) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 1422
To alter the variance of sub-band signals , one specific sub-band signals are selected .
To alter the variance of sub-band signals , one specific sub-band signals are selected .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 1423
Note that , it is more reasonable that the high frequency band is selected , since its signals are more sensitive than the low frequency band signals to noise .
Note that , it is more reasonable that the high frequency band is selected since its signals are more sensitive than the low frequency band signals to noise .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0

Alignment 1424
If the sub-band signals are divided into more and more small frames , the distortion caused by modifying the variance can be decreased .
If the sub-band signals are divided into smaller frames , the distortion caused by modifying the variance can be decreased .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			10:1			2		1.0
8:1			11:1			0		1.0
9:1			12:1			0		1.0
10:1			13:1			0		1.0
11:1			14:1			0		1.0
12:1			15:1			0		1.0
13:1			16:1			0		1.0
14:1			17:1			0		1.0
15:1			18:1			0		1.0
16:1			19:1			0		1.0
17:1			20:1			0		1.0
18:1			21:1			0		1.0
19:1			22:1			0		1.0
20:1			23:1			0		1.0

Alignment 1425
However , some modified sub-band signals belong to certain frame can invade into other neighbor frames .
However , some modified sub-band signals that belong to certain frame can invade other neighbor frames .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 1426
For that reason , the sub-band signals are modified by an exponential function , sign </Eq> .
For that reason , the sub-band signals are modified by an exponential function , sign </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 1427
The exponential function can cope with interference between altered sub-band signals .
The exponential function can cope with interference between altered sub-band signals .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 1428
Fig . 4 shows that that the exponential function is able to prevent by exponential function in terms of k the modified sub-band signals from getting over the range [- 1 , 1] .
Fig . 4 shows that that the exponential function is able to prevent by exponential function in terms of k the modified sub-band signals from getting over the range [- 1 , 1] .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0

Alignment 1429
If the modified sub-band signals are denoted by random variable Y , the variance of Y , </Eq> , is obtained by </Eq> (3)
If the modified sub-band signals are denoted by random variable Y , the variance of Y , </Eq> , is obtained by </Eq> (3)
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 1430
It means that we can alter the variance by controlling k .
It means that we can alter the variance by controlling k .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 1431
The variation of variance according to k is shown in Fig . 5 .
The variation of variance according to k is shown in Fig . 5 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 1432
The selected sub-band signals are modified by the exponential function , and the variance become reference value , r , where , r could be determined by the characteristics of signals .
The selected sub-band signals are modified by the exponential function , and the variance become the reference value , r , where , r could be determined by the characteristics of signals .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			27:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0

Alignment 1433
For example , as shown in section II , the case of uniform distribution has the reference value of 1/3 .
For example , as shown in section II , the case of uniform distribution has the reference value of 1/3 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 1434
Now , the variance of specific sub-band signals in every frame is equal to the same as reference value .
Now , the variance of specific the sub-band signals in every frame is equal to the reference value .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0

Alignment 1435
Whole sub-band signals including some part of modified sub-band signals are transformed into the modified signals , </Eq> , passing through reconstruction filter bank , GL(z) and GH(z) .
The whole sub-band signals including some part of the modified sub-band signals are transformed into the modified signals , </Eq> , passing through reconstruction filter bank , GL(z) and GH(z) .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0

Alignment 1436
Finally , the reconstructed audio signal , </Eq> , is denormalized onto original range and it is transmitted to receiver .
Finally , the reconstructed audio signal , </Eq> , is denormalized onto original range and it is transmitted to the receiver .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0

Alignment 1437
The denormalized j-th sample of ith frame , </Eq> , is obtained by </Eq> (4)
The denormalized j-th sample of ith frame , </Eq> , is obtained by </Eq> (4)
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 1438
Fig . 6 shows the proposed audio quality measurement process .
Fig . 6 shows the proposed audio quality measurement process .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 1439
It is quite simple since the quality of transmitted audio signal can be estimated just by checking the difference between the variance of the sub-band signals and the reference value , r .
It is quite simple since the quality of transmitted audio signal can be estimated just by checking the difference between the variance of the sub-band signals and the reference value , r .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0

Alignment 1440
Similar to the process of transmitter , audio signal passing the noise channel </Eq> , is divided into M small frames , </Eq> .
Similar to the process of transmission , audio signal passing the noise channel </Eq> is divided into M small frames , </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0

Alignment 1441
The signal of each frame is converted onto normalized range [-1 , 1] .
The signal of each frame is converted onto the normalized range [-1 , 1] .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0

Alignment 1442
And then , each frame signal is decomposed into sub-band signals by using the same analysis filter bank as used in transmitter .
Then , each frame signal is decomposed into sub-band signals by using the same analysis filter bank as used in the transmitter .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 1443
In the same sub-band as transmitter of each frame , the quality of transmitted audio signal is determined as the estimated variance error , so called EVE .
In these sub-band signals , the quality of transmitted audio signal is determined as the estimated variance error , so called EVE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			3:1			0		1.0
4:1			9:1			0		1.0
5:1			10:1			0		1.0
6:1			11:1			0		1.0
7:1			12:1			0		1.0
8:1			13:1			0		1.0
9:1			14:1			0		1.0
10:1			15:1			0		1.0
11:1			16:1			0		1.0
12:1			17:1			0		1.0
13:1			18:1			0		1.0
14:1			19:1			0		1.0
15:1			20:1			0		1.0
16:1			21:1			0		1.0
17:1			22:1			0		1.0
18:1			23:1			0		1.0
19:1			24:1			0		1.0
20:1			25:1			0		1.0
21:1			26:1			0		1.0
22:1			27:1			0		1.0

Alignment 1444
The EVE of i-th frame , </Eq> , is calculated by </Eq> (5)
The EVE of i-th frame , </Eq> , is calculated by </Eq> (5)
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 1445
Note that the proposed audio quality measurement system does not require the original data .
Note that the proposed audio quality measurement system does not require the original data .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 1446
The simulations are carried out on mono pop , rock , and classic music with 16-bits/sample and sampling rate of 44.1 KHz , respectively .
The simulations are carried out on mono pop , rock , and classic music with 16-bits/sample and sampling rate of 44.1 KHz , respectively .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 1447
For sub-band decomposition , packet 5/3 - tap biorthogonal perfect reconstruction filter bank </CITE> is applied recursively to low and high frequency band signal .
For sub-band decomposition , the packet 5/3 - tap biorthogonal perfect reconstruction filter bank </CITE> is applied recursively to low and high frequency band signals .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			1		1.0
25:1			24:1			0		1.0

Alignment 1448
Here , original audio signal is decomposed into eight sub-bands ( three multi-resolution levels ) .
Here , the original audio signal is decomposed into eight sub-bands on three multi-resolution levels .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			15:1			0		1.0

Alignment 1449
The filter bank can be implemented by fast operation algorithm , called lifting </CITE> .
The filter bank can be implemented by a fast operation algorithm called lifting </CITE> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 1450
The frequency ranges of each sub-band are listed in table 1 .
The frequency ranges of each sub-band are listed in table 1 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 1451
One frame consists of 4.644 sec ( 204,800 sam-ples ) in time domain .
One frame consists of 4.644 sec ( 204,800 sam-ples ) in the time domain .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0

Alignment 1452
To evaluate the proposed quality measurement method , we perform the simulation comparing with RMSE , E , by using cross correlation .
To evaluate the proposed quality measurement method , we perform the simulation comparing with RMSE , E , by using cross correlation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 1453
Where , </Eq> denotes the cross correlation of i-th frame .
Where </Eq> denotes the cross correlation of i-th frame .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0

Alignment 1454
And the simulation is carried out on Gaussian noise channel , which has the mean of zero , and the standard deviation from 100 to 1,000 .
The simulation is carried out on the Gaussian noise channel , which has the mean of zero , and the standard deviation from 100 to 1,000 .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			1:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 1455
As the high frequency band is more sensitive than low frequency band to noise .
As a high frequency band is more sensitive than a low frequency band to noise ,
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:2			1:2			3		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0

Alignment 1456
We experimentally select the 5th-band as optimal sub-band to modify the variance .
we experimentally select the 5th-band as the optimal sub-band to modify the variance .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0

Alignment 1457
The maximum and minimum value for converting onto normalized range is respectively determined as 32,767 and -32,768 , since the range of audio signal quantized by 16-bits is from 32,767 to -32 ,768 .
The maximum and minimum values for converting onto the normalized range is respectively determined as 32,767 and -32,768 , since the range of audio signals quantized by 16-bits is from 32,767 to -32 ,768 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			1		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			19:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			1		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0

Alignment 1458
As mentioned in section II , if the characteristics of signals could be known , we can calculate the reference value , r .
As mentioned in section II , if the characteristics of signals could be known , we can calculate the reference value r .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0

Alignment 1459
In general , because the high frequency band has Laplacian distribution , the variance of normalized sub-band signals is nearby zero ( That is , the distribution is concentrated on the mean value ) .
In general , because the high frequency band has Laplacian distribution , the variance of normalized sub-band signals is close to zero ( That is , the distribution is concentrated on the mean value ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			3		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0

Alignment 1460
For that reason , we determine r as 0.0001 .
For that reason , we determine r as 0.0001 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 1461
Table 2 shows the audio quality after altering the variance of subband signals .
Table 2 shows the audio quality after altering the variance of the subband signals .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0

Alignment 1462
Since the proposed method uses only specific frequency resource , the modified audio data has little quality distortion .
Since the proposed method uses one specific frequency resource , the modified audio data has little quality distortion .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 1463
The simulation results after Gaussian noise addition is shown in Fig . 7 , in terms of several standard deviations .
The simulation results after Gaussian noise addition is shown in Fig . 7 , in terms of several standard deviations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 1464
The quality measurement is performed frame by frame .
The quality measurement is performed frame by frame .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 1465
To compare with RMSE , we indicate the real range , not normalized range ( Actually , the quality is represented from zero to one in the proposed audio quality measurement system ) .
To compare with RMSE , we indicate the real range , not the normalized range ( Actually , the quality is represented from zero to one in the proposed audio quality measurement system ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			26:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0

Alignment 1466
The circle dot denotes the result of RMSE , the squared dot is EVE , and the triangle dot is in case of no Gaussian noise .
The circle dot denotes the result of RMSE , the squared dot is EVE , and the triangle dot is in case of no Gaussian noise .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 1467
EVE shows the modality , which is proportional to RMSE .
EVE shows the modality , which is proportional to RMSE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 1468
It means , the same as RMSE , EVE could estimate the quality distortion according to the strength of error .
It means , like RMSE , EVE could estimate the quality distortion according to the strength of the error .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			4:1			2		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			3:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0

Alignment 1469
As shown in Fig . 8 , the proposed system is high correlated with RMSE and table 3 represents the cross correlation between RMSE and EVE .
As shown in Fig . 8 , the proposed system is high correlated with RMSE and table 3 represents the cross correlation between RMSE and EVE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 1470
Moreover , the proposed method is no reference technique , i.e. , it does not require the original data for audio quality measurement .
Moreover , the proposed method is not a reference technique , i.e. , it does not require the original data for audio quality measurement .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:2			5:2			3		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0

Alignment 1471
In this paper , we proposed a new quality measurement technique for transmitted audio data by calculating the variance of intentionally modified sub-band signal .
In this paper , we proposed a new quality measurement technique for transmitted audio data by calculating the variance of intentionally modified sub-band signal .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 1472
Through the simulations , we proved that the proposed enables to estimate the quality distortion , not requiring the original data at the receiver .
Through the simulations , we proved that the proposed enables to estimate the quality distortion , not requiring the original data at the receiver .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 1473
As results , the proposed is a good alternative to the traditional quality measurement tool , RMSE .
As a results , the proposed is a good alternative to the traditional quality measurement tool , RMSE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0

Alignment 1474
Using SOM based Graph Clustering for Extracting Main Ideas from Documents
Using SOM based Graph Clustering for Extracting Main Ideas from Documents
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 1475
In this paper , we would like to present a graph clustering system for grouping the similar documents and extracting the main ideas in documents .
In this paper , we would like to present a graph clustering system for grouping the similar documents and extracting the main ideas in documents .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 1476
To cluster the documents , we need a model for representing the documents .
To cluster the documents , we need a model for representing the documents .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 1477
The traditional approaches used a word set based model or a vector based model for representing the documents .
The traditional approaches used a word set based model or a vector based model for representing the documents .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 1478
These models discard the important structural information of documents such as word position , the semantic relations of words in document …
These models discard the important structural information of documents such as word position , the semantic relations of words in document …
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 1479
Recently , some research works using the graph for representing the documents have been appeared .
Recently , some research works using the graph for representing the documents have been appeared .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 1480
We use the graph to becreated by analyzing the co-occurrence and position of two words in a section of document .
We use the graph to becreated by analyzing the co-occurrence and position of two words in a section of document .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 1481
After representing the documents by using graph , we used self organizing map ( SOM ) with two dimensional output layer for grouping the graphs .
After representing the documents by using graph , we used self organizing map ( SOM ) with two dimensional output layer for grouping the graphs .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 1482
One of the advantages of SOM is to cluster the data without specifying the number of clusters .
One of the advantages of SOM is to cluster the data without specifying the number of clusters .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 1483
Besides , two-dimensional SOM output layer can be put on the computer display and it can help to access the similar documents on the computer display .
Besides , two-dimensional SOM output layer can be put on the computer display and it can help to access the similar documents on the computer display .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 1484
We use the graph distance based on the maximum common sub-graph ( mcs ) which is discovered by maximal frequent sub-graph algorithm and the updated operation of neurons on SOM ouput layer based on the weighted means graphs and the genetic algorithm .
We use the graph distance based on the maximum common sub-graph ( mcs ) which is discovered by maximal frequent sub-graph algorithm and the updated operation of neurons on SOM ouput layer based on the weighted means graphs and the genetic algorithm .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0

Alignment 1485
In this paper , we would like to present the research results of a system for clustering the documents and extracting the main ideas in documents .
In this paper , we would like to present the research results of a system for clustering documents and extracting their main ideas .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:2			21:2			3		1.0
22:1			23:1			0		1.0
23:1			26:1			0		1.0

Alignment 1486
To cluster the documents , we need a model for representing the documents .
To cluster documents , we need a model for representing the documents .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0

Alignment 1487
In the previous approaches , a word set based model or a vector based model were used for representing the documents .
In previous approaches , a word - set - based model or a vector - based model were used for representing the documents .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0

Alignment 1488
These models discard the important information such as position , the semantic relation of words .
These models , however , discard the important information such as position and the semantic relation of words .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			9:1			0		1.0
5:1			2:1			0		1.0
6:1			3:1			0		1.0
7:1			4:1			0		1.0
8:1			5:1			0		1.0
9:1			6:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0

Alignment 1489
Recently , some research works using the graph for representing the document have beeen appeared </CITE> .
Recent studies use graphs as an alternative , and we apply this model to representing documents </CITE> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			1		1.0
7:1			1:1			0		1.0
14:1			9:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0

Alignment 1490
After using the graph model for representing the documents , we need to develop a system for clustering the graphs .
Prevous approaches to text clustering rely on word - set - based or vector - based models to represent documents .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			12:1			0		1.0
4:1			17:1			0		1.0
5:2			11:1			3		1.0
17:2			6:1			3		1.0
19:1			8:1			0		1.0
20:1			20:1			0		1.0

Alignment 1491
We use SOM neural network for clustering the graphs and extracting the main ideas from the documents .
The SOM neural network clustering methodology ,
Line2Start:Length	Line1Start:Length	Module		Score
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			6:1			0		1.0

Alignment 1492
SOM neural network has been developed by T . Kohonen since 1980 and it has been used for clustering </CITE> .
developed by Kohonen since 1980 , is utilized to cluster the graphs </CITE> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			5:1			0		1.0
1:1			6:1			0		1.0
2:1			9:1			0		1.0
3:1			10:1			0		1.0
4:1			11:1			0		1.0
6:1			14:2			3		1.0
7:1			16:1			2		1.0
12:1			19:1			0		1.0
13:1			20:1			0		1.0

Alignment 1493
One of the strong points of the SOM neural network is the capability of data clustering without defining number of clusters .
SOM is superior in its capability of clustering data without having to define the number of clusters .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			7:1			0		1.0
1:1			10:1			0		1.0
5:1			12:1			0		1.0
6:1			13:1			0		1.0
7:1			15:1			0		1.0
8:1			14:1			0		1.0
9:1			16:1			0		1.0
11:2			17:1			3		1.0
13:1			2:1			0		1.0
14:1			18:1			0		1.0
15:1			19:1			0		1.0
16:1			20:1			0		1.0
17:1			21:1			0		1.0

Alignment 1494
This capability is very important and better than the traditional clustering algorithms such as kmeans .
This capability is very important and better than the traditional clustering algorithms such as the kmeans .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0

Alignment 1495
Besides , SOM can put the documents on a document map and help to access the content of similar documents .
Besides , SOM can put the documents on a document map and help to access the content of similar texts .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			3		1.0
20:1			20:1			0		1.0

Alignment 1496
We study the method for calculating the distance between two graphs based on the maximal common sub-graph .
We study the method for calculating the distance between two graphs based on the maximal common subgraph ,
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 1497
We use the maximal frequent sub-graph discovery algorithm for discover-ing the maximal common sub-graph .
which is determined by the maximal frequent subgraph
Line2Start:Length	Line1Start:Length	Module		Score
4:1			2:1			0		1.0
5:1			3:1			0		1.0
6:1			4:1			0		1.0

Alignment 1498
The maximal common sub-graph is calculated by using the maximal frequent subgraph with 100% support .
discovery algorithm with 100% support .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			12:1			0		1.0
3:1			13:1			0		1.0
4:1			14:1			0		1.0
5:1			15:1			0		1.0

Alignment 1499
The method of adjustment of the weighted graph on the nodes of SOM output layer is based on the weighted means graph and genetic algorithm .
The method of adjustment of the weighted graph on the nodes of SOM output layer is based on the weighted means graph and genetic algorithm .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 1500
The remainder of this paper is organized as follows :
The remainder of this paper is organized as follows :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 1501
2 ) Using graph model for representing the documents
2 ) Using graph model for representing the documents
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 1502
3 ) SOM neural network
3 ) SOM neural network
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0

Alignment 1503
4 ) Using SOM for clustering graphs and extracting main ideas from documents
4 ) Using SOM for clustering graphs and extracting main ideas from documents
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 1504
5 ) Experiment and discussions
5 ) Experiment and discussions
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0

Alignment 1505
6 ) Conclusion and future work
and 6 ) Conclusion and future work
Line2Start:Length	Line1Start:Length	Module		Score
1:1			0:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0

Alignment 1506
We introduce two approaches of using graph for document representation .
We introduce two approaches of using graph for document representation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 1507
The first one is the approach of J. Tomita et al.</CITE> .
The first approach , developed by Tomita et al.</CITE>
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			5:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0

Alignment 1508
They used subject graph for representing document .
uses subject graphs for representing documents .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			1:1			1		1.0
1:1			2:1			0		1.0
2:1			3:1			1		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			1		1.0
6:1			7:1			0		1.0

Alignment 1509
In this approach , the graph is created by following steps :
In this approach , the graph is created by the following steps :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0

Alignment 1510
− Extracting the frequent terms in the document .
− Extracting the frequent terms in the document .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 1511
− Calculating the significance from the co-occurrence frequency of two terms in a unit of document such as sentence , paragraph … .
− Calculating the significance from the co-occurrence frequency of the two terms in a unit of document such as sentence , paragraph … .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0

Alignment 1512
If the co-occurrence frequency of two terms is greater than a threshold , we create an edge to connect these terms .
If the co-occurrence frequency of two terms is greater than a threshold , we create an edge to connect these terms .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 1513
An example of subject graph for document representation is shown in figure 1 .
An example of the subject graph for document representation is shown in figure 1 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0

Alignment 1514
The second one is the approach of Adam Schenker and Mark Last </CITE> .
The second one is the approach developed by Adam Schenker and Mark Last </CITE> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0

Alignment 1515
In this approach , each term appearing in the document , except for stop words such as “ a ” , “ the ” , “ of ” , “ and ” , “ or ” … which contain little information becomes a node in the graph representing the document .
In this approach , each term appearing in the document , becomes a node , except for stop words such as “ a ” , “ the ” , “ of ” , “ and ” , and “ or ” which contain little information .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			41:1			0		1.0
12:1			42:1			0		1.0
13:1			43:1			0		1.0
14:1			32:1			0		1.0
15:1			11:1			0		1.0
16:1			12:1			0		1.0
17:1			13:1			0		1.0
18:1			14:1			0		1.0
19:1			15:1			0		1.0
20:1			16:1			0		1.0
21:1			17:1			0		1.0
22:1			18:1			0		1.0
23:1			19:1			0		1.0
24:1			20:1			0		1.0
25:1			21:1			0		1.0
26:1			22:1			0		1.0
27:1			23:1			0		1.0
28:1			24:1			0		1.0
29:1			25:1			0		1.0
30:1			26:1			0		1.0
31:1			27:1			0		1.0
32:1			28:1			0		1.0
33:1			29:1			0		1.0
34:1			30:1			0		1.0
35:1			31:1			0		1.0
38:1			33:1			0		1.0
39:1			34:1			0		1.0
40:1			35:1			0		1.0
41:1			37:1			0		1.0
42:1			38:1			0		1.0
43:1			39:1			0		1.0
44:1			40:1			0		1.0
45:1			50:1			0		1.0

Alignment 1516
This is accomplished by labeling each node with the term it represents .
This is accomplished by labeling each node with the term it represents .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 1517
They create only a single node for each word even if a word appears more than once in the text .
Each word is represented by only a single node even when the word appears more than once in the text .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			8:1			0		1.0
5:1			2:1			0		1.0
6:1			3:1			0		1.0
7:1			4:1			0		1.0
8:1			5:1			0		1.0
9:1			9:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 1518
Thus each node in the graph represents a unique word .
Thus each node in the graph represents a unique word .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 1519
This node is labeled with an unique term .
For example , this is labeled with an unique term .
Line2Start:Length	Line1Start:Length	Module		Score
4:1			2:1			0		1.0
5:1			3:1			0		1.0
6:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0

Alignment 1520
Second , if word a immediately precedes word b , somewhere in a section s of the document , then there is a directed edge from the node corresponding to a to the node corresponding to b with the label s .
In the graph-based model , the authors create the graph by representing each word , except stop words, in the document as one unique node in the graph , regardless of how many times it appears in the text . The direction from one node to another corresponds to the relative positions of the words , and is illustrated by a directed edge starting from the node representing the preceding word .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			16:1			0		1.0
4:1			1:1			0		1.0
5:1			26:1			0		1.0
8:1			32:1			0		1.0
11:1			28:1			2		1.0
13:1			3:1			0		1.0
14:1			9:1			0		1.0
18:1			11:1			0		1.0
19:1			38:1			0		1.0
20:1			17:1			0		1.0
24:1			27:1			0		1.0
28:1			18:1			0		1.0
30:1			15:1			0		1.0
34:2			21:1			3		1.0
39:1			41:1			0		1.0
42:1			25:1			0		1.0
44:1			33:1			0		1.0
45:1			29:1			0		1.0
47:1			34:1			1		1.0
48:1			35:1			0		1.0
54:1			7:1			1		1.0
60:1			4:1			0		1.0
61:1			23:1			0		1.0
62:1			24:1			0		1.0
69:1			6:1			1		1.0

Alignment 1521
Section they have defined are as title , which contains the text related to the document ‘s title and any provided keywords; link , which is text appearing in hyperlink on the document; and text , which comprises any of the readable text in the document .
The edges are then labeled according to the section that contains the words . These sections include title , link or the clickable hyperlinks , and the remaining called text . Nodes corresponding infrequent words are excluded from the graph .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			4:1			0		1.0
6:1			13:1			0		1.0
7:1			14:1			0		1.0
9:2			8:2			3		1.0
11:1			10:1			0		1.0
13:1			46:1			0		1.0
17:1			6:1			0		1.0
18:1			7:1			0		1.0
19:1			22:1			0		1.0
21:1			31:1			0		1.0
24:1			23:1			0		1.0
25:1			18:1			0		1.0
26:1			40:1			0		1.0
29:1			11:1			0		1.0
35:1			1:2			3		1.0
38:1			44:1			0		1.0

Alignment 1522
An example of directed graph representation is given in figure 2 .
An example of directed graph representation is given in figure 2 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 1523
The oval indicates nodes and their corresponding term labels , the edges are labeled according the title ( TI ) , link ( L ) or text ( TX ) .
The oval indicates nodes and their corresponding term labels , the edges are labeled according the title ( TI ) , link ( L ) or text ( TX ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0

Alignment 1524
We also use a semantic edge called TS ( text similarity ) for connecting two similar terms .
We also use a semantic edge called TS ( text similarity ) for connecting two similar terms .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 1525
For example board and plank are two similar meaning terms , they mean a piece of wood .
For example , " board " and " plank " both means " a piece of wood " .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			10:1			0		1.0
4:1			2:1			0		1.0
6:1			3:1			0		1.0
8:1			4:1			0		1.0
10:1			5:2			3		1.0
11:1			11:2			3		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
18:1			17:1			0		1.0

Alignment 1526
We used Wordnet for measuring word similarity </CITE> .
We used Wordnet for measuring word similarity </CITE> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 1527
The second approach is richer than the first approach .
The second approach is superior to the first .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:2			5:1			3		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			9:1			0		1.0

Alignment 1528
Suppose that we have two sentences .
Suppose that we have two sentences :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0

Alignment 1529
The first sentence is “ Cat eats mouse ” , the second one is “ Mouse eats cat ” .
" Cats eat mice " and " Mice eats cats " .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			5:1			1		1.0
2:1			6:1			1		1.0
3:1			7:1			2		1.0
8:1			16:1			0		1.0
9:1			17:1			1		1.0
11:1			19:1			0		1.0

Alignment 1530
In the first approach , two sentences are the same meaning because it does not care the position of words in sentence .
The first approach fails to distinguish the meanings of these sentences beacuse it ignores the positions of the words ,
Line2Start:Length	Line1Start:Length	Module		Score
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:2			13:2			3		1.0
6:1			1:1			0		1.0
8:1			18:1			0		1.0
10:1			6:1			0		1.0
12:1			12:1			0		1.0
14:1			16:1			0		1.0
15:2			17:1			3		1.0
17:1			8:1			0		1.0
18:1			19:1			0		1.0
19:1			4:1			0		1.0

Alignment 1531
But in second approach , these sentences are not the same meaning .
while according to the second approach ,
Line2Start:Length	Line1Start:Length	Module		Score
3:1			9:1			0		1.0
4:1			2:1			0		1.0
5:1			3:1			0		1.0
6:1			4:1			0		1.0

Alignment 1532
This is true , because the position of words is expressed in the representation model .
the word positions matter and are expressed in the representation model .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			5:1			0		1.0
1:1			7:2			3		1.0
5:2			9:2			3		1.0
7:1			11:1			0		1.0
8:1			12:1			0		1.0
9:1			13:1			0		1.0
10:1			14:1			0		1.0
11:1			15:1			0		1.0

Alignment 1533
We used the second approach for representing the document in our proposed system .
We used the second approach for representing the document in our proposed system .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 1534
SOM has been developed by T Kohonen </CITE> .
SOM has been developed by T Kohonen </CITE> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 1535
After learning phase , the SOM will create a mapping between the high dimension objects of training set with a smaller dimension clusters .
After the learning phase , SOM will be used to create a mapping between the high dimension objects of training set with a smaller dimension clusters .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			4:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0
26:1			23:1			0		1.0

Alignment 1536
In our system , we use the 2D SOM , because it is suitable for placing 2D SOM output layer on the computer display .
In our system , we use the 2D SOM , because it is suitable for placing 2D SOM output layer on the computer display .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 1537
In SOM neural network structure , there is a weight expressing the measure of a link between the input and the output .
In SOM neural network structure , there is a weight expressing the measure of a link between the input and the output .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 1538
The learning process will adjust these weights based on the training data set .
The learning process will adjust these weights based on the training data set .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 1539
The result of this learning process will create the clusters of similar documents in the nodes of SOM output layer .
The result of this learning process will create the clusters of similar documents in the nodes of SOM output layer .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 1540
The learning pattern will belong to the cluster with minimum distance to this cluster .
The learning pattern will belong to the cluster with minimum distance to this cluster .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 1541
The traditional learning algorithm of SOM neural network is listed as follows :
The traditional learning algorithm of SOM neural network is listed as follows :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 1542
Step 1 : Randomly initialize the weight of SOM output layer
Step 1 : Randomly initialize the weight of SOM output layer
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 1543
Initialize N c( t ) ( the radius of neighboring area ) and set time t=1
Initialize N c( t ) ( the radius of neighboring area ) and set time t=1
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 1544
Step 2 : Present an input vector v( t ) and normalize the input vector v( t )
Step 2 : Present an input vector v( t ) and normalize the input vector v( t )
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 1545
Calculate the Euclidean distance ( dE ) from input vector v( t ) to all weight vectors of all nodes in SOM output layer and choose the neuron with the minimum distance from input vector v( t ) to the weight vector ( winner ) as follows :
Calculate the Euclidean distance ( dE ) from input vector v( t ) to all weight vectors of all nodes in SOM output layer and choose the neuron with the minimum distance from input vector v( t ) to the weight vector ( winner ) as follows :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0

Alignment 1546
Where i , j is the valid index which is established base on the size of SOM output layer .
Where i , j is the valid index which is established base on the size of SOM output layer .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 1547
Step 3 : Update the weight of nodes in the neighboring area of winner ( ic , jc ) by using the following formula :
Step 3 : Update the weight of nodes in the neighboring area of winner ( ic , jc ) by using the following formula :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 1548
Where γ is a constant determining the learning rate 0 ≤ γ ≤ 1 and </Eq>
Where γ is a constant determining the learning rate 0 ≤ γ ≤ 1 and </Eq>
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 1549
Step 4 : Update t = t + 1 , present next input vector and go back to step 2 until satisfying the convergence criteria or exceeding the maximum number of iterations .
Step 4 : Update t = t + 1 , present next input vector and go back to step 2 until satisfying the convergence criteria or exceeding the maximum number of iterations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0

Alignment 1550
A graph G = ( V ,E ) , consists of a set of vertices </Eq> , and a set of edges </Eq> .
A graph G = ( V ,E ) , consists of a set of vertices </Eq> , and a set of edges </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 1551
Let Lv and LE be the set of vertex and edge labels , respectively , and let V : </Eq> be the labeling functions that assign labels to each vertex and edge .
Let Lv and LE be the set of vertex and edge labels , respectively , and let V : </Eq> be the labeling functions that assign labels to each vertex and edge .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0

Alignment 1552
The size of a graph G , denoted </Eq> is the cardinality of the edge set ( i.e. , </Eq> ) .
The size of a graph G , denoted </Eq> is the cardinality of the edge set ( i.e. , </Eq> ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 1553
A graph G1 = ( V1 ,E1 ) is a sub-graph of another graph G2 = ( V2 ,E2 ) , denoted </Eq> , if there exists a 1-1 mapping </Eq> , such that </Eq> implies </Eq> .
A graph G1 = ( V1 ,E1 ) is a sub-graph of another graph G2 = ( V2 ,E2 ) , denoted </Eq> , if there exists a 1-1 mapping </Eq> , such that </Eq> implies </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0

Alignment 1554
Further , f preserves vertex labels , i.e. , </Eq> , and preserves edge labels , i.e. ,</Eq> .
Further , f preserves vertex labels , i.e. , </Eq> , and preserves edge labels , i.e. ,</Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 1555
f is also called a sub-graph isomorphism from G1 to G2 .
f is also called a sub-graph isomorphism from G1 to G2 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 1556
If </Eq> , we also say that G2 is a super-graph of G1 .
If </Eq> , we also say that G2 is a super-graph of G1 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 1557
Note also that two graphs G1 and G2 are isomorphic </Eq> .
Note also that two graphs G1 and G2 are isomorphic </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 1558
Let D be a set of graphs , then we write </Eq> .
Let D be a set of graphs , then we write </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 1559
G is said to be a maximal common sub-graph of </Eq> , and </Eq> , such that </Eq> .
G is said to be a maximal common sub-graph of </Eq> , and </Eq> , such that </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 1560
Let D be a database ( a set ) of graphs .
Let D be a database ( a set ) of graphs .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 1561
The support of a graph G in D denoted </Eq> is ratio of number of graphs of D containing graph G and </Eq> .
The support of a graph G in D denoted </Eq> is ratio of number of graphs of D containing graph G and </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 1562
Graph G is called frequent if </Eq> , where minsup is a user-specified minimum support threshold .
Graph G is called frequent if </Eq> , where minsup is a user-specified minimum support threshold .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 1563
Let </Eq> be the set of frequent graphs of D for a given support minsup .
Let </Eq> be the set of frequent graphs of D for a given support minsup .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 1564
A graph </Eq> is said to be maximal frequent graph if there exists no graph </Eq> such that </Eq> </CITE> .
A graph </Eq> is said to be maximal frequent graph if there exists no graph </Eq> such that </Eq> </CITE> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 1565
The input data of a SOM is a set of graph representing the documents .
The input data of a SOM is a set of graphs representing the documents .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			1		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 1566
After training SOM , the input graphs will be grouped into nodes on the SOM output layer </CITE> .
After the SOM is being trained , the input graphs will be grouped into nodes on the SOM output layer </CITE> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			13:1			0		1.0
2:1			14:1			0		1.0
6:1			3:1			0		1.0
7:1			4:1			0		1.0
8:1			5:1			0		1.0
9:1			6:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
17:1			2:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0

Alignment 1567
Each neuron on the SOM layer output is a weighted graph .
Each neuron on the SOM layer output is a weighted graph .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 1568
This graph is initialized based on the input value of SOM neural network .
This graph is initialized based on the input value of SOM neural network .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 1569
C . Distance between two graphs H Bunke </CITE> proposed a formula for calculating the distance between two graphs .
C . Distance between two graphs H Bunke </CITE> proposed a formula for calculating the distance between two graphs .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 1570
Given graph G1 and G2 , the distance of two graphs G1 and G2 denoted as d( G1 ,G2 ) is calculated as follows :
Given graph G1 and G2 , the distance of two graphs G1 and G2 denoted as d( G1 ,G2 ) is calculated as follows :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 1571
Where “ mcs ” is the maximal common graph and </Eq> is the size of graph G ( number of vertices and edges of graph G ) .
Where “ mcs ” is the maximal common graph and </Eq> is the size of graph G ( number of vertices and edges of graph G ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0

Alignment 1572
Consider figure 3.a and 3.b as follows :
Consider figure 3.a and 3.b as follows :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 1573
Figure ( 3.a ) is graph G1 , and figure ( 3.b ) is graph G2 , figure ( 3.c ) is the maximal common graph of graph G1 and G2 .
Figure ( 3.a ) is graph G1 , and figure ( 3.b ) is graph G2 , figure ( 3.c ) is the maximal common graph of graph G1 and G2 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0

Alignment 1574
The distance of graph G1 and G2 is : </Eq>
The distance of graph G1 and G2 is : </Eq>
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 1575
We compute mcs( ) by using SPIN – an algorithm for mining the maximal frequent sub-graph in graph mining </CITE> .
We compute mcs( ) by using SPIN – an algorithm for mining the maximal frequent sub-graph in graph mining </CITE> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 1576
SPIN takes two graphs as input and mines for maximal frequent sub-graphs with 100% support .
SPIN takes two graphs as input and mines for maximal frequent sub-graphs with 100% support .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 1577
The maximal frequent sub-graph with maximal size is used to compute the size of the maximal common sub-graph in formula ( 2 ) .
The maximal frequent sub-graph with maximal size is used to compute the size of the maximal common sub-graph in formula ( 2 ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 1578
In the training process of SOM neural network , we need to adjust the weight of neurons laying in the neighboring area of winning neuron .
In the training process of SOM neural network , we need to adjust the weight of neurons laying in the neighboring area of the winning neurons .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			1		1.0
26:1			25:1			0		1.0

Alignment 1579
When using the SOM neural network for clustering the graph , each node in the SOM layer output is a graph , we call this kind of graph as weighted graph .
When using the SOM neural network for clustering the graph , each node in the SOM layer output is a graph , and we call this kind of graph as weighted graph .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0

Alignment 1580
To adjust the weighted graph , H. Bunke </CITE> used the weighted means graph of a pair of weighted graphs .
To adjust the weighted graph , H. Bunke </CITE> used the weighted means graph of a pair of weighted graphs .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 1581
Given two graph G1 and G2 , the graph G denotes weighted means graph of weighted graph G1 and graph G2 if there is a number </CITE> such as </Eq> , we have :
Given two graph G1 and G2 , the graph G denotes weighted means graph of weighted graph G1 and graph G2 if there is a number </CITE> such as </Eq> , we have :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0

Alignment 1582
And </Eq> ( 4 )
And </Eq> ( 4 )
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0

Alignment 1583
From formulas ( 3 ) and ( 4 ) , we have </Eq>
From formulas ( 3 ) and ( 4 ) , we have </Eq>
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 1584
To adjust the weight of nodes of SOM output layer , we use formula ( 1 ) .
To adjust the weight of nodes of SOM output layer , we use formula ( 1 ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 1585
We can write formula ( 1 ) as follows : </Eq> ( 5 ) and </Eq> ( 6 )
We can write formula ( 1 ) as follows : </Eq> ( 5 ) and </Eq> ( 6 )
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 1586
If we replace G1 by x , G by ynew and G2 by yold , the operator ” - ” by the distance between two graphs , the formula ( 5 ) and ( 6 ) will be formula ( 7 ) and ( 8 ) as follows : </Eq> ( 7 ) and </Eq> ( 8 )
If we replace G1 by x , G by ynew and G2 by yold , the operator ” - ” by the distance between two graphs , the formula ( 5 ) and ( 6 ) will be formula ( 7 ) and ( 8 ) as follows : </Eq> ( 7 ) and </Eq> ( 8 )
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0
49:1			49:1			0		1.0
50:1			50:1			0		1.0
51:1			51:1			0		1.0
52:1			52:1			0		1.0
53:1			53:1			0		1.0
54:1			54:1			0		1.0
55:1			55:1			0		1.0
56:1			56:1			0		1.0
57:1			57:1			0		1.0

Alignment 1587
If </Eq> , the formulas ( 7 ) and ( 8 ) will be formula ( 3 ) , ( 4 ) and graph G is the weighted means graph of graph G1 and graph G2 </CITE> .
If </Eq> , the formulas ( 7 ) and ( 8 ) will be formula ( 3 ) , ( 4 ) and graph G is the weighted means graph of graph G1 and graph G2 </CITE> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0

Alignment 1588
From formulas ( 7 ) and ( 8 ) , we have formula ( 9 ) as follows : </Eq>
From formulas ( 7 ) and ( 8 ) , we have formula ( 9 ) as follows : </Eq>
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 1589
We used the genetic algorithm </CITE> for seeking the weighted means graph of two weight graphs G1 and G2 with the following steps :
We used the genetic algorithm </CITE> for seeking the weighted means graph of two weight graphs G1 and G2 with the following steps :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 1590
1 ) Overview of the genetic algorithm Genetic Algorithms ( GA ) are programs that simulate the logic of Darwinian selection .
1 ) Overview of the genetic algorithm Genetic Algorithms ( GA ) are programs that simulate the logic of Darwinian selection .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 1591
GA is a algorithm which makes it easy to search a large search space .
GA is a algorithm which makes it easy to search a large search space .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 1592
The general algorithm is as follows :
The general algorithm is as follows :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0

Alignment 1593
Generate initial population .
Generate initial population .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0

Alignment 1594
Assign fitness function to all individuals of population
Assign fitness function to all individuals of population
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 1595
Generation = 1
Generation = 1
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0

Alignment 1596
REPEAT Select individuals from population of current generation
REPEAT Select individuals from population of current generation
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 1597
Create new off-springs with crossover operation
Create new off-springs with crossover operation
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0

Alignment 1598
Create new off-springs with mutation operation
Create new off-springs with mutation operation
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0

Alignment 1599
Compute new fitness for all individuals
Compute new fitness for all individuals
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0

Alignment 1600
Delete all the unfit individuals to give space to new off-springs
Delete all the unfit individuals to give space to new off-springs
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 1601
Check if best solution is found
Check if best solution is found
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0

Alignment 1602
generation = generation + 1
generation = generation + 1
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0

Alignment 1603
UNTIL best solution is found or generation >= MaxLoop
UNTIL best solution is found or generation >= MaxLoop
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 1604
The Maxloop is user defined constant and determine the maximal generation pf genetic algorithm .
The Maxloop is user defined constant and determine the maximal generation pf genetic algorithm .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 1605
2 ) Initilalizing the population
2 ) Initilalizing the population
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0

Alignment 1606
The graph is represented by an adjacency matrix , the vertex set of graph is </Eq> .
The graph is represented by an adjacency matrix , the vertex set of graphs is </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			1		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 1607
The chromosome is a set of graph candidates of weighted means graphs ( set of matrices ) .
The chromosome is a set of graphs candidates of weighted means graphs ( set of matrices ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			1		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 1608
Set of initial graphs are initialized randomly based of graph G1 and G2 .
Set of initial graphs are initialized randomly based of graph G1 and G2 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 1609
Crossover operation in this case will be the crossover of two matrices .
Crossover operation in this case will be the crossover of two matrices .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 1610
The details of crossover operation are as follows :
The details of crossover operation are as follows :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 1611
a ) Before crossover : </Eq>
a ) Before crossover : </Eq>
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0

Alignment 1612
b ) After crossover : </Eq>
b ) After crossover : </Eq>
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0

Alignment 1613
3 ) Mutation operation
3 ) Mutation operation
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0

Alignment 1614
− Select random positions i ,j in matrix representing the selected chromosome .
− Select random positions i ,j in matrix representing the selected chromosome .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 1615
− Determine the random value of 0 or 1 ( add or delete the edge of graph )
− Determine the random value of 0 or 1 ( add or delete the edge of graph )
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 1616
− Assign this random value to aij and aji
− Assign this random value to aij and aji
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 1617
4 ) Firness function
4 ) Fitness function
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			3:1			0		1.0

Alignment 1618
Maximize the following function :
Maximize the following function :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0

Alignment 1619
The less value of this function gives the more fitness value of chromosome .
The less value of this function gives the more fitness value of chromosome .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 1620
5 ) GA parameters
5 ) GA parameters
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0

Alignment 1621
We used the following GA parameters : GA population size .
We used the following GA parameters : GA population size .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 1622
Main ideas of documents are the sentences containing as much as the words determined by the order of occurrence on the weighted graphs .
Main ideas of documents are the sentences containing as many words determined by the order of occurrence on the weighted graphs .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0

Alignment 1623
Main idea is created based on the weighted graph representing a group of similar documents .
Main idea is created based on the weighted graph representing a group of similar documents .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 1624
A typical weighted graph of SOM output layer is shown in figure 4 .
A typical weighted graph of SOM output layer is shown in figure 4 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 1625
The Precision , Recall and F-measure are used for evaluating the result of clustering .
The Precision , Recall and F-measure are used for evaluating the result of clustering .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 1626
The clustering to be created by human experts is called manual clustering .
The clustering to be created by human experts is called manual clustering .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 1627
We compare the clustering result of documents to be created by our system with the result of manual clustering .
We compare the clustering result of documents to be created by our system with the result of manual clustering .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 1628
Consider a set of n documents , Let m be the number of clusters to be created from n documents by manual clustering .
Consider a set of n documents , Let m be the number of clusters to be created from n documents by manual clustering .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 1629
Methods Let k be the number of clusters in the clustering result to be created by our system .
Methods Let k be the number of clusters in the clustering result to be created by our system .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 1630
In evaluation process , we have m ≤ k .
In the evaluation process , we have m ≤ k .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0

Alignment 1631
To evaluate the system , we use Precision , Recall and Fmeasure and calculate them by two methods .
To evaluate the system , we use Precision , Recall and Fmeasure and calculate them by two methods .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 1632
Let </Eq> in figure 5 , cluster mi to be created by manual clustering is A∪B; this cluster contains a+b documents , The cluster ki to be created by our system is A∪C; this cluster contains a + c documents .
Let </Eq> in figure 5 , cluster mi to be created by manual clustering is A∪B; this cluster contains a+b documents . The cluster ki to be created by our system is A∪C; this cluster contains a + c documents .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			40:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0

Alignment 1633
Two above clusters have an intersection A which contains common documents of two clusters .
Two above clusters have an intersection A which contains common documents of two clusters .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 1634
The Precision is a measure of the number of documents that match those in the manual clustering against the number of documents in the system cluster .
The Precision is a measure of the number of documents that match those in the manual clustering against the number of documents in the system cluster .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 1635
If P=1 then all documents in cluster ki are in cluster mi </Eq>
If P=1 then all documents in cluster ki are in cluster mi </Eq>
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 1636
The Recall between two cluster mi and cluster ki denoted as R ( recall ) and is calculated by formula ( 11 ) .
The Recall between two cluster mi and cluster ki denoted as R ( recall ) and is calculated by formula ( 11 ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 1637
If R =1 then all documents in cluster mi are in cluster ki </Eq>( 11 )
If R =1 then all documents in cluster mi are in cluster ki </Eq>( 11 )
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 1638
The Precision and Recall can be combined to F-Measure .
The Precision and Recall can be combined to F-Measure .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 1639
The F-Measure is calculated by formula ( 12 ) : </Eq> ( 12 )
The F-Measure is calculated by formula ( 12 ) : </Eq> ( 12 )
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 1640
High value of α gives more influence to recall while low value gives it to precision .
High value of α gives more influence to recall while low value gives it to precision .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 1641
A common value of α in formula ( 12 ) is 0.5 .
A common value of α in formula ( 12 ) is 0.5 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 1642
This formula can be written as : </Eq> ( 13 )
This formula can be written as : </Eq> ( 13 )
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 1643
Brew C. </CITE> propose a method to evaluate the clustering result as follows .
Brew C. </CITE> propose a method to evaluate the clustering result as follows .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 1644
For each cluster in the clustering result to be created by system , we calculate the F-measure comparing with all clusters to be created by manual method .
For each cluster in the clustering result to be created by system , we calculate the F-measure comparing with all clusters to be created by manual method .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0

Alignment 1645
Then we select the maximal value of F-measure for this cluster ( each column in table 1 and table 2 ) .
Then we select the maximal value of F-measure for this cluster ( each column in table 1 and table 2 ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 1646
The process is repeated for the remain system clusters .
The process is repeated for the remain system clusters .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 1647
High value of the total of F-measure gives the accuracy of clustering system .
High value of the total of F-measure gives the accuracy of clustering system .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 1648
The test set contains 500 scientific documents belonging to 5 different topics such as database , data mining , computer network , web programming , artificial intelligence .
The test set contains 500 scientific documents belonging to 5 different topics such as database , data mining , computer network , web programming , and artificial intelligence .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0

Alignment 1649
Each topic has 100 documents .
Each topic has 100 documents .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0

Alignment 1650
The size of SOM output layer is 8x8; The repeated cycle of training algorithm is 5 ,000; The cycle of adjusting the radius of neighboring area is 50 .
The size of SOM output layer is 8x8; The repeated cycle of training algorithm is 5 ,000; The cycle of adjusting the radius of neighboring area is 50 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 1651
The directed graph is used for representing the documents .
The directed graph is used for representing the documents .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 1652
1 ) Method of clustering the vectors
1 ) Method of clustering the vectors
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0

Alignment 1653
Result : Method of manual clustering has 5 clusters , each cluster has 100 documents .
Result : The method of manual clustering has 5 clusters , each of which has 100 documents .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0

Alignment 1654
In this experiment , we used the vector model for representing the documents .
In this experiment , we used the vector model for representing the documents .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 1655
Number of result clusters is 8 .
The number of result clusters is 8 .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0

Alignment 1656
Comparing the results created by vector clustering and result created by manual clustering .
We comparing the results created by vector clustering and those created by manual clustering .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0

Alignment 1657
We use formulas </CITE> for calculating the Precision , Recall , F-measure .
We use formulas </CITE> for calculating the Precision , Recall , F-measure .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 1658
Table 2 provides the results of calculation .
Table 2 provides the results of calculation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 1659
The sum of maximal value of F-measure for vector clustering is 0.32 + 0.34 + 0.54 + 0.43 + 0.43 = 2.06
The sum of maximal value of F-measure for vector clustering is 0.32 + 0.34 + 0.54 + 0.43 + 0.43 = 2.06
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 1660
2 ) Method of clustering the graphs
2 ) Method of clustering the graphs
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0

Alignment 1661
In this experiment , we use graph model for representing the documents .
In this experiment , we use the graph model for representing the documents .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0

Alignment 1662
Number of result clusters is 6 .
The number of result clusters is 6 .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0

Alignment 1663
Comparing the results created by graph clustering and result created by manual clustering .
We comparing the results created by graph clustering and those created by manual clustering .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0

Alignment 1664
We use formulas </CITE> for calculating the Precision , Recall , F-measure .
We use formulas </CITE> for calculating the Precision , Recall , F-measure .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 1665
Table 2 provides the results of calculation .
Table 2 provides the results of calculation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 1666
Discussion : We test our proposed solution with many data sets and calculate the sum of max value of F-measure , we hold that the sum of max of F-Measure for graph cluster is higher PC Man than the sum of max of F-measure for vector clustering .
Discussion : We test our proposed solution with many data sets and calculate the sum of max value of F-measure , we hold that the sum of max of F-Measure for graph cluster is higher PC Man than the sum of max of F-measure for vector clustering .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0

Alignment 1667
This result encourages us to continue developing the method of using the graph for representing the documents .
This result encourages us to continue developing the method of using the graph for representing the documents .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 1668
The sum of maximal value of F-measure for graph clustering is 0.54+0.32+0.68+0.56+0.54=2.64
The sum of maximal value of F-measure for graph clustering is 0.54+0.32+0.68+0.56+0.54=2.64
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 1669
Comparing to the vector based clustering algorithm , our proposed algorithm still remains the core parts of the SOM learning algorithm .
Comparing to the vector - based clustering algorithm , our proposed algorithm still remains the core parts of the SOM learning algorithm .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0

Alignment 1670
Our proposed algorithm only changes the formula of calculation the distance between the input patterns and the weighted graphs and the adjustment way of weighted graphs .
Our proposed algorithm only changes the formula of calculating the distance between the input patterns and the weighted graphs and the adjustment way of weighted graphs .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			1		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 1671
The time complexity of our proposed algorithm focuses on the time complexity of calculation the distance between two graphs and the calculation of weighted means graph based on the genetic algorithm .
The time complexity of our proposed algorithm focuses on the time complexity of calculation the distance between two graphs and the calculation of weighted means graph based on the genetic algorithm .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0

Alignment 1672
Figure 6 provides the chart to compare the average processing time of two algorithms with test set containing 100 , 150 , 200 , 250 , 300 , 350 ,400 , 450 , 500 documents .
Figure 6 provides the chart to compare the average processing time of two algorithms with test set containing 100 , 150 , 200 , 250 , 300 , 350 ,400 , 450 , 500 documents .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0

Alignment 1673
The computer to be used for testing is PC Pentium 4 , 3GB with 500 M byte RAM .
The computer to be used for testing is PC Pentium 4 , 3GB with 500 M byte RAM .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 1674
The value in this chart in figure 6 holds that our proposed algorithm has average processing time estimated 1.7 times higher than the vector based clustering algorithm .
The value in this chart in figure 6 holds that our proposed algorithm has average processing time estimated 1.7 times higher than the vector based clustering algorithm .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0

Alignment 1675
However , as we mentioned above the accuracy of our proposed methods is higher than the vector based clustering graph .
However , as we mentioned above the accuracy of our proposed methods is higher than the vector based clustering graph .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 1676
Moreover , it also open a new way to improve the quality of document clustering by using the SOM neural network .
Moreover , it also open a new way to improve the quality of document clustering by using the SOM neural network .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 1677
In this paper , we would like to present the result of building a graph based clustering system by using the SOM neural networks .
In this paper , we present the result of building a graph - based clustering system by using the SOM neural networks .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			8:1			0		1.0
6:1			9:1			0		1.0
7:1			10:1			0		1.0
8:1			11:1			0		1.0
9:1			12:1			0		1.0
10:1			13:1			0		1.0
11:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0

Alignment 1678
We use the graph model for representing the documents .
We use the graph model for representing the documents .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 1679
The graph model can represent the structural information of documents such as semantic relation of words , position of words in documents , concepts implicit present in documents .
The graph model can represent the structural information of documents such as the semantic relation of words , the position of words in documents , and concepts implicitly present in documents .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
26:1			23:1			0		1.0
27:1			24:1			1		1.0
28:1			25:1			0		1.0
29:1			26:1			0		1.0
30:1			27:1			0		1.0
31:1			28:1			0		1.0

Alignment 1680
After clustering the document , on the SOM output layer are the weighted graph .
After clustering the document , on the SOM output layer are the weighted graph .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 1681
These weighted graph contain the words which help to choose the main ideas form set of documents .
These weighted graph contain the words which help to choose the main ideas form a of documents .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 1682
We choose the maximal common sub-graph to calculate the distance between graphs .
We choose the maximal common sub-graph to calculate the distance between graphs .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 1683
The approach of maximal frequent sub-graph with 100% support is used to find the maximal common sub-graph .
The approach of maximal frequent sub-graph with 100% support is used to find the maximal common sub-graph .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 1684
To adjust the weighted graphs on the nodes of SOM output layer , we use the weighted means graph concept and genetic algorithms .
To adjust the weighted graphs on the nodes of the SOM output layer , we use the weighted means graph concept and genetic algorithms .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0

Alignment 1685
We test our propose methods on the corpus of Vietnamese articles and analyze the results .
We test our proposed methods on the corpus of Vietnamese articles and analyze the results .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			1		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 1686
We continue to do the research in calculating the distance between graphs and the way to reduce the time complexity of our proposed algorithm .
We continue to do the research in calculating the distance between graphs and the way to reduce the time complexity of our proposed algorithm .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 1687
We also study the capability of using the conceptual graph for representing documents and enhancing the richness of document representation model .
We also study the capability of using the conceptual graph for representing documents and enhancing the richness of document representation model .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 1688
Acknowledgment
Acknowledgment
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0

Alignment 1689
The authors would like to express our thanks to Ministry of Science and Technology for financial support to Fundamental research project numbered 202806 and the valuable comments of reviewers .
The authors would like to express our thanks to Ministry of Science and Technology for financial support to Fundamental research project numbered 202806 and the valuable comments of reviewers .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0

Alignment 1690
Two-stage Incremental Working Set Selection for Fast Support Vector Training on Large Datasets
Two-stage Incremental Working Set Selection for Fast Support Vector Training on Large Datasets
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 1691
We propose iSVM - an incremental algorithm that achieves high speed in training support vector machines ( SVMs ) on large datasets .
We propose iSVM - an incremental algorithm that achieves high speed in training support vector machines ( SVMs ) on large datasets .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 1692
In the common decomposition framework , iSVM starts with a minimum working set ( WS ) , and then iteratively selects one training example to update the WS in each optimization loop .
In the common decomposition framework , iSVM starts with a minimum working set ( WS ) , and then iteratively selects one training example to update the WS in each optimization loop .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0

Alignment 1693
iSVM employs a two-stage strategy in processing the training data .
iSVM employs a two-stage strategy in processing the training data .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 1694
In the first stage , the most prominent vector among randomly sampled data is added to the WS .
In the first stage , the most prominent vector among randomly sampled data is added to the WS .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 1695
This stage results in an approximate SVM solution .
This stage results in an approximate SVM solution .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 1696
The second stage uses temporal solutions to scan through the whole training data once again to find the remaining support vectors ( SVs ) .
The second stage uses temporal solutions to scan through the whole training data once again to find the remaining support vectors ( SVs ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 1697
We show that iSVM is especially efficient for training SVMs on applications where data size is much larger than number of SVs .
We show that iSVM is especially efficient for training SVMs on applications where data size is much larger than number of SVs .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 1698
On the KDD-CUP 1999 network intrusion detection dataset with nearly five millions training examples , iSVM takes less than one hour to train an SVM with 94% testing accuracy , compared to seven hours with LibSVM – one of the state-of-the-art SVM implementations .
On the KDD-CUP 1999 network intrusion detection dataset with nearly five millions training examples , iSVM takes less than one hour to train an SVM with 94% testing accuracy , compared to seven hours with LibSVM – one of the state-of-the-art SVM implementations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0

Alignment 1699
We also provide analysis and experimental comparisons between iSVM and the related algorithms .
We also provide analysis and experimental comparisons between iSVM and the related algorithms .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 1700
In recent years support vector machine ( SVM ) \CITE has been successfully applied in various machine learning applications .
In recent years support vector machine ( SVM ) \CITE has been successfully applied in various machine learning applications .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 1701
However , scalability still remains one of biggest challenges for SVM in particular and kernel-based methods in general .
However , scalability still remains one of biggest challenges for SVM in particular and kernel-based methods in general .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 1702
It is due to the fact that training an SVM requires solving a quadratic programming ( QP ) problem in which , for the worst case , the complexity becomes </Eq> for time and </Eq> for memory requirement , where l is the number of training examples \CITE .
It is due to the fact that training an SVM requires solving a quadratic programming ( QP ) problem in which , for the worst case , the complexity becomes </Eq> for time and </Eq> for memory requirement , where l is the number of training examples \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0

Alignment 1703
There have been number of approaches to scalability problem of SVM training .
There have been a number of approaches to scalability problem of SVM training .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0

Alignment 1704
Among them decomposition is the most widely implemented method in various SVM software and libraries , e.g. LibSVM \CITE , SVM light \CITE , CoreSVM \CITE , HeroSVM \CITE , and SimpleSVM \CITE .
Among them , decomposition is the most widely implemented method in various SVM software and libraries , e.g. LibSVM \CITE , SVM light \CITE , CoreSVM \CITE , HeroSVM \CITE , and SimpleSVM \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			29:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0

Alignment 1705
The main idea of decomposition algorithms is to divide training data into two sets : an active working set ( WS ) whose coefficients can be updated , and an inactive set whose coefficients are temporally fixed \CITE .
The main idea of decomposition algorithms is to divide training data into two sets : an active working set ( WS ) whose coefficients can be updated , and an inactive set whose coefficients are temporally fixed \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0

Alignment 1706
The extreme case of this decomposition approach is the Sequential Minimal Optimization ( SMO ) algorithm \CITE that does optimization on a set of only two examples .
The extreme case of this decomposition approach is the Sequential Minimal Optimization ( SMO ) algorithm \CITE that does optimization on a set of only two examples .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0

Alignment 1707
For each optimization loop , SMO scans through the whole training data to find a good pair of vectors , and then updates coefficients of the two selected vectors analytically .
For each optimization loop , SMO scans through the whole training data to find a good pair of vectors , and then updates coefficients of the two selected vectors analytically .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0

Alignment 1708
In order to find a good pair in the next iteration , it is required to update the violation of optimality criteria of all training vectors .
In order to find a good pair in the next iteration , it is required to update the violation of optimality criteria of all training vectors .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 1709
It is very expensive for applications where the number of updates ( training data ) is huge .
It is very expensive for applications where the number of updates ( training data ) is huge .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 1710
In this paper , we introduce a two-stage incremental WS selection method in training SVMs .
In this paper , we introduce a two-stage incremental WS selection method in training SVMs .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 1711
The proposed algorithm starts from finding an initial SVM solution on a minimum WS ( two vectors from opposite classes in a two-class classification task ) .
The proposed algorithm starts from finding an initial SVM solution on a minimum WS ( two vectors from opposite classes in a two-class classification task ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 1712
It then iteratively selects one training vector to update the WS .
It then iteratively selects one training vector to update the WS .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 1713
The selection of new vectors is divided into two stages .
The selection of new vectors is divided into two stages .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 1714
In the first stage , only the most prominent vector among a fixed number of sampling data is added to the WS while all others remain in the training data .
In the first stage , only the most prominent vector among a fixed number of sampling data is added to the WS while all others remain in the training data .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0

Alignment 1715
From the second stage , all training examples are checked once again .
From the second stage , all training examples are checked once again .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 1716
For both stages , each optimality violated vector is used to update the WS and find a new SVM solution .
For both stages , each optimality violated vector is used to update the WS and find a new SVM solution .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 1717
We show that with this two-stage WS selection strategy the proposed iSVM has a linear time complexity in number of training examples and cubic in number of SVs .
We show that with this two-stage WS selection strategy , the proposed iSVM has a linear time complexity in number of training examples and cubic in number of SVs .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0

Alignment 1718
Experiments on large benchmark datasets show that iSVM is very fast when working on applications where number of SVs is much smaller than number of training data .
Experiments on large benchmark datasets show that iSVM is very fast when working on applications where number of SVs is much smaller than number of training data .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0

Alignment 1719
On the KDD-CUP 1999 network intrusion detection dataset with nearly five millions training examples iSVM takes less than one hour to train a SVM with 94% testing accuracy .
On the KDD-CUP 1999 network intrusion detection dataset with nearly five millions training examples , iSVM takes less than one hour to train a SVM with 94% testing accuracy .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0

Alignment 1720
With LibSVM \CITE – one of the state-of-the-art SMO implementations , it takes seven hours .
With LibSVM \CITE – one of the state-of-the-art SMO implementations , it takes seven hours .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 1721
The rest part of this paper is organized as follows .
The rest of this paper is organized as follows .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0

Alignment 1722
In Section II we briefly describe SVM training problem and decomposition algorithms for solving it .
In Section II , we briefly describe SVM training problems and decomposition algorithms for solving them .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			1		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
16:1			15:1			0		1.0

Alignment 1723
We introduce iSVM and its complexity analysis in section III .
We introduce iSVM and its complexity analysis in section III .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 1724
In section IV we discuss relations between iSVM and related SVM training algorithms .
In section IV , we discuss the relations between iSVM and related SVM training algorithms .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0

Alignment 1725
Experiments for evaluating iSVM and comparison with other algorithms are reported in section V .
Experiments for evaluating iSVM and comparison with other algorithms are reported in section V .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 1726
Section VI is for conclusion .
Section VI is for conclusion .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0

Alignment 1727
In support vector learning \CITE , we are given a set of l training examples </Eq> with labels </Eq> .
In support vector learning \CITE , we are given a set of l training examples </Eq> with labels </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 1728
The main task of training an SVM is to solve the following optimization problem :
The main task of training an SVM is to solve the following optimization problem :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 1729
( 1 ) where </Eq> is a kernel function calculating dot product between two vector </Eq> and </Eq> in some feature space ; C is a parameter penalizing each " noisy " example in the given training data .
( 1 ) where </Eq> is a kernel function calculating dot product between two vector </Eq> and </Eq> in some feature space ; C is a parameter penalizing each " noisy " example in the given training data .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0

Alignment 1730
The optimal coefficients </Eq> will form a decision function :
The optimal coefficients </Eq> will form a decision function :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 1731
( 2 ) Problem ( 1 ) involves l variables </Eq> and </Eq> parameters </Eq> .
( 2 ) Problem ( 1 ) involves l variables </Eq> and </Eq> parameters </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 1732
The </Eq> number of parameters </Eq> quickly exceeds memory capacity of a normal computer when the number of training examples gets larger than , say , 100 ,000 .
The </Eq> number of parameters </Eq> quickly exceeds memory capacity of a normal computer when the number of training examples gets larger than , say , 100 ,000 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 1733
This over demanding in memory requirement causes the main difficulty in training SVMs .
This over demanding in memory requirement causes the main difficulty in training SVMs .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 1734
The main idea of decomposition algorithms , e.g. \CITE , is to break down the QP problem ( 1 ) of size l into a series of much smaller QPs , and iteratively perform optimization on these sub-problems .
The main idea of decomposition algorithms , e.g. \CITE , is to break down the QP problem ( 1 ) of size l into a series of much smaller QPs , and iteratively perform optimization on these sub-problems .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0

Alignment 1735
In each iteration decomposition algorithms divide l training examples into two categories : a set of active vectors W that corresponding coefficients </Eq> can be updated and a set of inactive vectors that corresponding coefficients are temporally fixed .
In each iteration , decomposition algorithms divide l training examples into two categories : a set of active vectors W corresponding coefficients </Eq> can be updated , and a set of inactive vectors corresponding coefficients are temporally fixed .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0

Alignment 1736
Active vectors are updated by some optimization method to minimize objective function L on W .
Active vectors are updated by some optimization method to minimize objective function L on W .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 1737
After that fixed vectors are checked and used for updating the working set W . Optimization loop will stop when all optimality conditions are satisfied .
After that fixed vectors are checked and used for updating the working set W . Optimization loop will stop when all optimality conditions are satisfied .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 1738
The extreme case of the decomposition method is the Sequential Minimal Optimization ( SMO ) algorithm \CITE that optimizes a set of only two vectors .
The extreme case of the decomposition method is the Sequential Minimal Optimization ( SMO ) algorithm \CITE that optimizes a set of only two vectors .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 1739
The power of SMO resides in the fact that updating scheme could be done analytically . Call </Eq> and </Eq> be chosen vectors , then the best new values of </Eq> and </Eq> in terms of reducing best the objective function L in ( 1 ) are ( ignoring the box constraint </Eq> ) :
The power of SMO resides in the fact that updating scheme could be done analytically . Call </Eq> and </Eq> be chosen vectors , then the best new values of </Eq> and </Eq> in terms of reducing best the objective function L in ( 1 ) are ( ignoring the box constraint </Eq> ) :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0
49:1			49:1			0		1.0
50:1			50:1			0		1.0
51:1			51:1			0		1.0
52:1			52:1			0		1.0
53:1			53:1			0		1.0
54:1			54:1			0		1.0

Alignment 1740
Input : Training data </Eq> Initialize a feasible solution
Input : Training data </Eq> Initialize a feasible solution
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 1741
Set iteration t = 0
Set iteration t = 0
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0

Alignment 1742
While StoppingCondition is not satisfied
While StoppingCondition is not satisfied
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0

Alignment 1743
Select a pair of vectors </Eq>
Select a pair of vectors </Eq>
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0

Alignment 1744
Update </Eq> analytically
Update </Eq> analytically
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0

Alignment 1745
Update violation states </Eq>
Update violation states </Eq>
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0

Alignment 1746
Set t = t + 1
Set t = t + 1
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0

Alignment 1747
Endwhile
Endwhile
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0

Alignment 1748
Output : Coefficients ( 3 ) </Eq> .
Output : Coefficients ( 3 ) </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 1749
This updating scheme leads to the reduction of objective function L an amount of ( 4 )
This updating scheme leads to the reduction of objective function L an amount of ( 4 )
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 1750
Based on this reduction rate different heuristics have been proposed to select the best pair of vectors </Eq> with a reasonable cost </Eq> .
Based on this reduction rate , different heuristics have been proposed to select the best pair of vectors </Eq> with a reasonable cost </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0

Alignment 1751
The analytical solution property of SMO makes it become a core optimizer for many SVM implementations .
The analytical solution property of SMO makes it become a core optimizer for many SVM implementations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 1752
In TABLE I we describe main procedures in an SMO implementation .
In TABLE I we describe main procedures in an SMO implementation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 1753
The most expensive procedure of the SMO is updating violation of optimality criteria </Eq> of all training vectors in step 5 .
The most expensive procedure of the SMO is updating violation of optimality criteria </Eq> of all training vectors in step 5 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 1754
This calculation is used to select the best pair of vectors in the next iteration; and it is required for every training example .
This calculation is used to select the best pair of vectors in the next iteration , and it is required for every training example .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0

Alignment 1755
Step 5 becomes very expensive when the number of updates ( or training data ) is huge . Moreover , as only SVs ( training vectors </Eq> with corresponding coefficients </Eq> will contribute to form the final decision function ( 2 ) , step 5 of SMO can be very inefficient when many training examples are not SVs .
Step 5 becomes very expensive when the number of updates ( or training data ) is huge . Moreover , as only SVs ( training vectors </Eq> with corresponding coefficients </Eq> will contribute to form the final decision function ( 2 ) , step 5 of SMO can be very inefficient when many training examples are not SVs .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0
49:1			49:1			0		1.0
50:1			50:1			0		1.0
51:1			51:1			0		1.0
52:1			52:1			0		1.0
53:1			53:1			0		1.0
54:1			54:1			0		1.0
55:1			55:1			0		1.0
56:1			56:1			0		1.0
57:1			57:1			0		1.0
58:1			58:1			0		1.0

Alignment 1756
To improve the efficiency shrinking technique \CITE can be applied to remove non-support vectors .
To improve the efficiency , shrinking technique \CITE can be applied to remove non-support vectors .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0

Alignment 1757
However , there has been no way to determine whether a training example is a SV or not from the beginning .
However , there has been no way to determine whether a training example is a SV or not from the beginning .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 1758
In this section we introduce an incremental strategy for selecting SVs .
In this section , we introduce an incremental strategy for selecting SVs .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0

Alignment 1759
The main idea is using temporal SVM solutions to determine good candidates of SVs and optimization process is performed only on a small set of selected candidates .
The main idea is temporal SVM solutions can be used to determine good candidates of SVs , and optimization process is performed only on a small set of selected candidates .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0
26:1			23:1			0		1.0
27:1			24:1			0		1.0
28:1			25:1			0		1.0
29:1			26:1			0		1.0
30:1			27:1			0		1.0

Alignment 1760
The following subsections describe in detailed the main steps of our proposed algorithm iSVM in TABLE II .
The following subsections describe in detail the main steps of our proposed algorithm iSVM in TABLE II .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			1		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 1761
Input : Training data </Eq>
Input : Training data </Eq>
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0

Alignment 1762
Select the first working set </Eq> .
Select the first working set </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0

Alignment 1763
Find the first temporal solution </Eq> .
Find the first temporal solution </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0

Alignment 1764
Set </Eq>
Set </Eq>
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0

Alignment 1765
Set iteration t = 0
Set iteration t = 0
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0

Alignment 1766
While StoppingCondition is not satisfied
While StoppingCondition is not satisfied
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0

Alignment 1767
Select one vector </Eq> in T
Select one vector </Eq> in T
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0

Alignment 1768
Update </Eq>
Update </Eq>
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0

Alignment 1769
Find new solution </Eq> on </Eq>
Find new solution </Eq> on </Eq>
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0

Alignment 1770
Set t = t + 1
Set t = t + 1
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0

Alignment 1771
Endwhile
Endwhile
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0

Alignment 1772
Output : Coefficients </Eq>
Output : Coefficients </Eq>
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0

Alignment 1773
As SMO is used for optimization on the selected working set </Eq> in step 0 and step 5 , a minimum set of two vectors are selected to build the first working set </Eq> . For a two-class classification task , this is simply selecting any two training vectors from two opposite classes ( in our implementation they are first vectors belonging to the positive and negative classes in the given training data ) .
As SMO is used for optimization on the selected working set </Eq> in step 0 and step 5 , a minimum set of two vectors are selected to build the first working set </Eq> . For a two-class classification task , this is simply selecting any two training vectors from two opposite classes ( in our implementation they are first vectors belonging to the positive and negative classes in the given training data ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0
49:1			49:1			0		1.0
50:1			50:1			0		1.0
51:1			51:1			0		1.0
52:1			52:1			0		1.0
53:1			53:1			0		1.0
54:1			54:1			0		1.0
55:1			55:1			0		1.0
56:1			56:1			0		1.0
57:1			57:1			0		1.0
58:1			58:1			0		1.0
59:1			59:1			0		1.0
60:1			60:1			0		1.0
61:1			61:1			0		1.0
62:1			62:1			0		1.0
63:1			63:1			0		1.0
64:1			64:1			0		1.0
65:1			65:1			0		1.0
66:1			66:1			0		1.0
67:1			67:1			0		1.0
68:1			68:1			0		1.0
69:1			69:1			0		1.0
70:1			70:1			0		1.0
71:1			71:1			0		1.0
72:1			72:1			0		1.0
73:1			73:1			0		1.0
74:1			74:1			0		1.0

Alignment 1774
Compared with previously proposed methods , this initialization step is simpler .
Compared with previously proposed methods , this initialization step is simpler .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 1775
In \CITE the authors suggested to select randomly a set of p training instances , where p is a training parameter .
In \CITE the authors suggested to select randomly a set of p training instances , where p is a training parameter .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 1776
In \CITE , two closest vectors were recommended to form the first working set ( for the best reduction rate in ( 4 ) ) .
In \CITE , two closest vectors were recommended to form the first working set ( for the best reduction rate in ( 4 ) ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 1777
However , our preliminary experiments indicated that the result of iSVM does not depend much on this initialization scheme .
However , our preliminary experiments indicated that the result of iSVM does not depend much on this initialization scheme .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 1778
There have been different schemes proposed to update the WS in the common decomposition frame work .
There have been different schemes proposed to update the WS in the common decomposition frame work .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 1779
In fact , this is a distinctive step for each algorithm .
In fact , this is a distinctive step for each algorithm .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 1780
Different updating strategies will produce different results in terms of convergence speed and final solution .
Different updating strategies will produce different results in terms of convergence speed and final solution .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 1781
In iSVM we propose a two-stage process for expanding and updating the WS .
In iSVM we propose a two-stage process for expanding and updating the WS .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 1782
In the first stage , iSVM tries to find a good approximation of SVM solution as quickly as possible .
In the first stage , iSVM tries to find a good approximation of SVM solution as quickly as possible .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 1783
It then scans through the whole training data once again to examine all remaining vectors one-by-one .
It then scans through the whole training data once again to examine all the remaining vectors one-by-one .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0

Alignment 1784
Potential SVs will be used to update the WS and find a new and better SVM .
Potential SVs will be used to update the WS and find a new and better SVM .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 1785
1 ) Re-sampling Selection : In support vector learning , if we know in advance which training example will be SV , we can remove all non-support vectors without changing the optimal solution .
1 ) Re-sampling Selection : In support vector learning , if we know in advance which training example will be SV , we can remove all non-support vectors without changing the optimal solution .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0

Alignment 1786
An effective non-support vector removal strategy will guarantee an efficient algorithm .
An effective non-support vector removal strategy will guarantee an efficient algorithm .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 1787
We do this by a twostage data processing procedure .
We do this by a twostage data processing procedure .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 1788
In the first stage , step 3 of iSVM examines only a small number training examples and selects the most prominent vector to add to the WS .
In the first stage , step 3 of iSVM examines only a small number training examples and selects the most prominent vector to add to the WS .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0

Alignment 1789
The selection is based on violation of optimality criteria of a training vector with respect to a temporal solution found in previous iteration .
The selection is based on violation of optimality criteria of a training vector with respect to a temporal solution found in previous iteration .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 1790
At iteration t , </Eq> is selected based on the following criterion : ( 6 ) is the temporal solution </Eq> at iteration t .
At iteration t , </Eq> is selected based on the following criterion : ( 6 ) is the temporal solution </Eq> at iteration t .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 1791
The selection heuristic ( 5 ) is exactly the maximal violating heuristic that has been used by SMO \CITE and other early decomposition implementations .
The selection heuristic ( 5 ) is exactly the maximal violating heuristic that has been used by SMO \CITE and other early decomposition implementations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 1792
The difference is that SMO updates all </Eq> and then scans through all of them to select the best pair .
The difference is that SMO updates all </Eq> and then scans through all of them to select the best pair .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 1793
iSVM uses temporal solutions St to examine a fixed number of training examples .
iSVM uses temporal solutions St to examine a fixed number of training examples .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 1794
Difference in complexity between the two strategies will be analyzed in more detail in subsection D .
Difference in complexity between the two strategies will be analyzed in more detail in subsection D .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 1795
In the first stage , only the most prominent ( in terms of optimality violation ) vector is removed from T , all other vectors remain in the training data .
In the first stage , only the most prominent ( in terms of optimality violation ) vector is removed from T while all other vectors remain in the training data .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0

Alignment 1796
They can be re-examined in the next iterations and/or in the second phase .
They can be re-examined in the next iterations and/or in the second phase .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 1797
There are two reasons for the re-examination .
There are two reasons for the re-examination .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 1798
Firstly , only the best vector is added to the WS , not every temporally violated vector .
Firstly , only the best vector is added to the WS , not every temporally violated vector .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 1799
The second reason is that temporal solutions are still not close enough to the optimal solution ( as only a small number of vectors are examined ) .
Secondly , temporal solutions are still not close enough to the optimal solution ( as only a small number of vectors are examined ) .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			5:1			0		1.0
3:1			6:1			0		1.0
4:1			7:1			0		1.0
5:1			8:1			0		1.0
6:1			9:1			0		1.0
7:1			10:1			0		1.0
8:1			11:1			0		1.0
9:1			12:1			0		1.0
10:1			13:1			0		1.0
11:1			14:1			0		1.0
12:1			15:1			0		1.0
13:1			16:1			0		1.0
14:1			17:1			0		1.0
15:1			18:1			0		1.0
16:1			19:1			0		1.0
17:1			20:1			0		1.0
18:1			21:1			0		1.0
19:1			22:1			0		1.0
20:1			23:1			0		1.0
21:1			24:1			0		1.0
22:1			25:1			0		1.0
23:1			26:1			0		1.0
24:1			27:1			0		1.0

Alignment 1800
Removing training examples from very beginning might mistakenly remove the true SVs .
Removing training examples from the very beginning might result in the mistaken removal of the true SVs .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
11:1			7:1			1		1.0
12:1			8:1			1		1.0
14:1			9:1			0		1.0
15:1			10:1			0		1.0
16:1			11:1			0		1.0
17:1			12:1			0		1.0

Alignment 1801
The first stage will finish when we are sure at some extend that </Eq> is a good approximation .
The first stage will finish when we are sure to some extent that </Eq> is a good approximation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			10:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 1802
In iSVM , we use the following heuristics for ending the first stage : i ) None of N randomly selected vectors violates optimality criteria , or ii ) Size of </Eq> is bigger than a predefined number ( 1 ,000 in our experiments ) , or iii ) All training vectors are examined once in average .
In iSVM , we use the following heuristics for ending the first stage : i ) None of N randomly selected vectors violates optimality criteria , or ii ) Size of </Eq> is bigger than a predefined number ( 1 ,000 in our experiments ) , or iii ) All training vectors are examined once in average .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0
49:1			49:1			0		1.0
50:1			50:1			0		1.0
51:1			51:1			0		1.0
52:1			52:1			0		1.0
53:1			53:1			0		1.0
54:1			54:1			0		1.0
55:1			55:1			0		1.0
56:1			56:1			0		1.0
57:1			57:1			0		1.0

Alignment 1803
The first condition has been used in various situations including kernel matrix approximation \CITE and CoreSVM \CITE .
The first condition has been used in various situations , including kernel matrix approximation \CITE and CoreSVM \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0

Alignment 1804
This heuristic is based on the fact that with a sample size of N = 59 , we still can catch one among 5% most violating vectors \CITE .
This heuristic is based on the fact that with a sample size of N = 59 , we still can catch one among 5% most violating vectors \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 1805
The second and third conditions mean that the temporal solution will be considered stable and close enough to the optimal solution when a big number of training examples are examined .
The second and third conditions mean that the temporal solution will be considered stable and close enough to the optimal solution when a big number of training examples are examined .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0

Alignment 1806
After a good approximation has been achieved we can switch to the second stage to remove non-support vectors without much affect to the final solution .
After a good approximation has been achieved , we can switch to the second stage to remove non-support vectors without affecting much the final solution .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 1807
2 ) Final Scanning : Based on the assumption that phase one produces a good approximate solution , phase two examines all training examples remaining in T one-by-one .
2 ) Final Scanning : Based on the assumption that phase one produces a good approximate solution , phase two examines all the training examples remaining in T one-by-one .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0

Alignment 1808
If vector </Eq> violates optimality criteria with respect to temporal solution </Eq> then it is immediately used to update </Eq> to form a new solution .
If vector </Eq> violates optimality criteria with respect to temporal solution </Eq> , then it is immediately used to update </Eq> to form a new solution .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0

Alignment 1809
Otherwise , it is removed from training data T .
Otherwise , it is removed from training data T .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 1810
The algorithm will stop when all training examples in T are examined .
The algorithm will stop when all training examples in T are examined .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 1811
The SMO is used to minimize the objective function L on the selected set of vectors </Eq> .
The SMO is used to minimize the objective function L on the selected set of vectors </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 1812
It is very efficient because </Eq> is usually much smaller than the whole training data .
It is very efficient because </Eq> is usually much smaller than the whole training data .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 1813
Moreover , SMO can start optimization on Wt from </Eq> - the optimal solution on </Eq> in previous iteration .
Moreover , SMO can start optimization on Wt from </Eq> - the optimal solution on </Eq> in previous iteration .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 1814
The difference is only about one newly added vector .
The difference is only about one newly added vector .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 1815
This makes SMO converge very fast .
This makes SMO converge very fast .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0

Alignment 1816
In this section we analyze the computational complexity of the proposed iSVM algorithm .
In this section we analyze the computational complexity of the proposed iSVM algorithm .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 1817
At each iteration t , step 3 takes time </Eq> to examine one training example .
At each iteration t , step 3 takes time </Eq> to examine one training example .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 1818
In the first phase , each training example is examined at most once ( when the stopping condition iii ) is applied ) .
In the first phase , each training example is examined at most once ( when the stopping condition iii ) is applied ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 1819
The second phase scans training data once more .
The second phase scans the training data once more .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0

Alignment 1820
Thus , each training example is examined at most twice .
Thus , each training example is examined at most twice .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 1821
Totally step 3 takes time </Eq> .
Totally step 3 takes time </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0

Alignment 1822
Theoretically solving a QP problem of size </Eq> in step 3 takes time </Eq> .
Theoretically solving a QP problem of size </Eq> in step 3 takes time </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 1823
However , solution </Eq> at iteration t – 1 is used as an initial point , then step 5 requires only time </Eq> per iteration ( in fact it can be done in </Eq> by an efficient updating procedure \CITE ) .
However , solution </Eq> at iteration t – 1 is used as an initial point , then step 5 requires only time </Eq> per iteration ( in fact , it can be done in </Eq> by an efficient updating procedure \CITE ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
37:1			36:1			0		1.0
38:1			37:1			0		1.0
39:1			38:1			0		1.0
40:1			39:1			0		1.0
41:1			40:1			0		1.0
42:1			41:1			0		1.0

Alignment 1824
Totally step 5 takes time </Eq> .
Totally , step 5 takes time </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0

Alignment 1825
From the second phase the shrinking technique is applied ( a non support vector in </Eq> is replaced by a new vector found by step 3 ) , then size of the final working set approximates the number of final support vectors .
From the second phase , the shrinking technique is applied ( a non support vector in </Eq> is replaced by a new vector found by step 3 ) , then size of the final working set approximates the number of final support vectors .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			27:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
37:1			36:1			0		1.0
38:1			37:1			0		1.0
39:1			38:1			0		1.0
40:1			39:1			0		1.0
41:1			40:1			0		1.0
42:1			41:1			0		1.0
43:1			42:1			0		1.0

Alignment 1826
In total , the time complexity of iSVM is </Eq> , which is linear with number of training examples l and cubic with number of support vectors .
In total , the time complexity of iSVM is </Eq> , which is linear with number of training examples l and cubic with number of support vectors .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0

Alignment 1827
Time complexity of the SMO algorithm described in TABLE I is </Eq> where </Eq> is the number of SMO iterations .
Time complexity of the SMO algorithm described in TABLE I is </Eq> where </Eq> is the number of SMO iterations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 1828
In iSVM , SMO is used to solve the QP on a small set of selective training examples .
In iSVM , SMO is used to solve the QP on a small set of selective training examples .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 1829
From the complexity analysis above we can see that iSVM has advantage over the traditional SMO implementation when number of final SVs is much smaller than data size .
From the complexity analysis above , we can see that iSVM has an advantage over the traditional SMO implementation when the number of the SVs is much smaller than the data size .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			0		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0
26:1			23:1			0		1.0
27:1			24:1			0		1.0
28:1			25:1			0		1.0
30:1			26:1			0		1.0
31:1			27:1			0		1.0
32:1			28:1			0		1.0

Alignment 1830
iSVM belongs to the decomposition family of SVM training algorithms .
iSVM belongs to the decomposition family of SVM training algorithms .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 1831
In this section we discuss properties of iSVM and its relation to conventional methods .
In this section , we discuss properties of iSVM and its relation to conventional methods .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0

Alignment 1832
In the initialization step , iSVM selects any two vectors from opposite classes ( for a two-class classification task ) .
In the initialization step , iSVM selects any two vectors from opposite classes ( for a two-class classification task ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 1833
Based on calculation ( 2 ) , a closer pair of vectors will produce a better reduction in objective function L .
Based on calculation ( 2 ) , a closer pair of vectors will produce a better reduction in objective function L .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 1834
However , our preliminary experiments indicate that final solutions are not affected much by this initialization scheme which has been used by CoreSVM \CITE or SimpleSVM \CITE .
However , our preliminary experiments indicate that final solutions are not affected much by this initialization scheme which has been used by CoreSVM \CITE or SimpleSVM \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0

Alignment 1835
Other initialization strategies include selecting randomly a set of p vectors \CITE , or using all training data from the beginning \CITE .
Other initialization strategies include selecting randomly a set of p vectors \CITE , or using all training data from the beginning \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 1836
For updating the working set , several algorithms share the same way of adding only one vector to the WS in each optimization loop , e.g. SimpleSVM \CITE , CoreSVM \CITE .
For updating the working set , several algorithms share the same way of adding only one vector to the WS in each optimization loop , e.g. SimpleSVM \CITE , CoreSVM \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0

Alignment 1837
Different selection criteria have been proposed , including optimality violation \CITE , probabilistic estimation \CITE .
Different selection criteria have been proposed , including optimality violation \CITE , probabilistic estimation \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 1838
iSVM differs from others in its two-stage strategy .
iSVM differs from others in its two-stage strategy .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 1839
In the first stage , temporal solutions are not good enough to justify which training example is surely an SV or not , so iSVM re examines them in the second phase .
In the first stage , temporal solutions are not good enough to justify which training example is surely an SV or not , so iSVM re examines them in the second phase .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0

Alignment 1840
Note that the working set grows from a minimum size , thus the first phase runs very fast because size of the working set </Eq> is small and only the best among N examined vectors is added to the working set .
Note that the working set grows from a minimum size ; thus , the first phase runs very fast because the size of the working set </Eq> is small and only the best among N examined vectors is added to the working set .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			11:1			0		1.0
12:1			10:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			38:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
33:1			31:1			0		1.0
34:1			32:1			0		1.0
35:1			33:1			0		1.0
36:1			34:1			0		1.0
37:1			35:1			0		1.0
38:1			36:1			0		1.0
39:1			37:1			0		1.0
41:1			39:1			0		1.0
42:1			40:1			0		1.0
43:1			41:1			0		1.0

Alignment 1841
It is not clearly described in \CITE and \CITE that training examples are re-examined or not .
It is not clearly described in \CITE and \CITE that training examples are re-examined or not .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 1842
If they are removed from T too early from beginning then it is with high probability that many good training examples ( or SVs ) might be removed .
If they are removed from T too early from beginning , then it is highly likely many good training examples ( or SVs ) might be removed .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			14:1			1		1.0
15:1			15:2			3		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0

Alignment 1843
In contrast , if they are remaining in T all the time and re-examined many times then the computation is not efficient .
In contrast , if they remain in T all the time and re-examined many times , then the computation is not efficient .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			6:1			1		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 1844
Comparing with other approximation methods , iSVM uses a rather simple stopping condition .
Comparing with other approximation methods , iSVM uses a rather simple stopping condition .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 1845
In our point of view , CoreSVM uses a looser condition : none of N sampled training data violates the optimality condition with respect to temporal solution at iteration </Eq> .
In our point of view , CoreSVM uses a looser condition : none of N sampled training data violates the optimality condition with respect to temporal solution at iteration </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0

Alignment 1846
In the experiment section we will show that using this stopping condition will lead to trained SVMs with smaller number of SVs , faster training time , but bigger variation in predictive performance .
In the experiment section , we will show that using this stopping condition will lead to trained SVMs with smaller number of SVs , faster training time , but bigger variation in predictive performance .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0

Alignment 1847
In this section we describe our experiments to evaluate iSVM and comparisons with other SVM training algorithms .
In this section , we describe our experiments to evaluate iSVM and comparisons with other SVM training algorithms .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0

Alignment 1848
We select four datasets from different domains : web page categorization from UCI machine learning repository ( " Web " ) , text-decoding used in IJCNN 2001 conference competition ( " IJCNN" ) , extended USPS hand written digit recognition data for discriminating '0' and '1' ( " zero-one" ) , and KDD-CUP 1999 network intrusion detection datasets used in the KDD 1999 conference competition ( " KDD-CUP99" ) .
We select four datasets from different domains : web page categorization from UCI machine learning repository ( " Web " ) , text-decoding used in IJCNN 2001 conference competition ( " IJCNN" ) , extended USPS hand written digit recognition data for discriminating '0' and '1' ( " zero-one" ) , and KDD-CUP 1999 network intrusion detection datasets used in the KDD 1999 conference competition ( " KDD-CUP99" ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0
49:1			49:1			0		1.0
50:1			50:1			0		1.0
51:1			51:1			0		1.0
52:1			52:1			0		1.0
53:1			53:1			0		1.0
54:1			54:1			0		1.0
55:1			55:1			0		1.0
56:1			56:1			0		1.0
57:1			57:1			0		1.0
58:1			58:1			0		1.0
59:1			59:1			0		1.0
60:1			60:1			0		1.0
61:1			61:1			0		1.0
62:1			62:1			0		1.0
63:1			63:1			0		1.0
64:1			64:1			0		1.0
65:1			65:1			0		1.0
66:1			66:1			0		1.0
67:1			67:1			0		1.0
68:1			68:1			0		1.0
69:1			69:1			0		1.0

Alignment 1849
All of the datasets summarized in TABLE III have nearly or more than 50 ,000 training examples .
All of the datasets summarized in TABLE III have nearly or more than 50 ,000 training examples .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 1850
All of our experiments were conducted on a PC Windows machine with a 3GHz CPU and 2GB RAM memory .
All of our experiments were conducted on a PC Windows machine with a 3GHz CPU and 2GB RAM memory .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 1851
In the first experiment , we compare training performance of iSVM with LibSVM \CITE – one of the best SMO implementation , CoreSVM \CITE – a recent proposed algorithm that has achieved a remarkable performance on the KDD-CUP 1999 dataset .
In the first experiment , we compare training performance of iSVM with LibSVM \CITE – one of the best SMO implementation , CoreSVM \CITE – a recent proposed algorithm that has achieved a remarkable performance on the KDD-CUP 1999 dataset .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0

Alignment 1852
Comparison criteria include training time , number of support vector , testing accuracy .
Comparison criteria include training time , number of support vector , and testing accuracy .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0

Alignment 1853
Parameters were chosen for achieving good accuracy on testing data : Gaussian kernel </Eq> with </Eq> for " Web " , </Eq> for " IJCNN " , </Eq> for " USPS zero-one " , </Eq> for " KDD-CUP" .
Parameters were chosen for achieving good accuracy on testing data : Gaussian kernel </Eq> with </Eq> for " Web " , </Eq> for " IJCNN " , </Eq> for " USPS zero-one " , </Eq> for " KDD-CUP" .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0

Alignment 1854
As both iSVM and CoreSVM \CITE use probabilistic trick to speedup training process in step 3 training results are random variables .
As both iSVM and CoreSVM \CITE use probabilistic trick to speedup in step 3 training results are random variables .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0

Alignment 1855
We conduct this experiment ten times and estimate statistics of these variables ( for CoreSVM we randomly mix the original data ten times and run training program on these mixed data ) .
We conduct this experiment ten times and estimate statistics of these variables ( for CoreSVM we randomly mix the original data ten times and run training program on these mixed data ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0

Alignment 1856
From experimental data reported in TABLE IV we can see that iSVM runs much faster than LibSVM on the " zero-one " and " KDD-CUP99 " where the number of SVs is much smaller than number of training data ( 0.45% and 0.01% correspondingly ) .
From experimental data reported in TABLE IV we can see that iSVM runs much faster than LibSVM on the " zero-one " and " KDD-CUP99 " where the number of SVs is much smaller than number of training data ( 0.45% and 0.01% correspondingly ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0

Alignment 1857
This shows the advantage of the two-stage incremental WS selection strategy .
This shows the advantage of the two-stage incremental WS selection strategy .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 1858
On the KDD-CUP 1999 data CoreSVM has an incredible training time : two seconds in average for training on a nearly five millions training examples .
On the KDD-CUP 1999 data , CoreSVM has an incredible training time : two seconds in average for training on a nearly five millions training examples .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0

Alignment 1859
In the next experiment we investigate and analyze more to show that iSVM with an early stopping condition can also achieve this training time performance .
In the next experiment , we investigate and analyze more to show that iSVM with an early stopping condition can also achieve this training time performance .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0

Alignment 1860
However the cost is big variation of trained machines .
However , the cost is the huge variation of trained machines .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0

Alignment 1861
In the second experiment we try iSVM with different stopping conditions on the KDD-CUP 1999 dataset .
In the second experiment , we try iSVM with different stopping conditions on the KDD-CUP 1999 dataset .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0

Alignment 1862
The first one is right after the first stage finished , or when there is no vector out of 59 randomly selected training data violates temporal optimality conditions .
The first one is right after the first stage finished , or when there is no vector out of 59 randomly selected training data violates the temporal optimality conditions .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0

Alignment 1863
Other stopping conditions are based on the total number of examined examples ( by the second stage ) : 10% , 20% , 40% and 80% of the whole data .
Other stopping conditions are based on the total number of examined examples ( by the second stage ) : 10% , 20% , 40% and 80% of the whole data .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0

Alignment 1864
This experiment is also conducted ten times to have estimation of training times and testing accuracies .
This experiment is also conducted ten times to have estimation of training times and testing accuracies .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 1865
As we can see in Figure 2 , with an early stopping condition iSVM runs faster but produces SVMs with higher variation in predictive accuracy ) .
As we can see in Figure 2 , with an early stopping condition , iSVM runs faster but produces SVMs with higher variation in predictive accuracy ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0

Alignment 1866
Especially , the first stage finishes after a very small number of iterations ( 32 in average ) .
Especially , the first stage finishes after a very small number of iterations ( 32 in average ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 1867
It means that the trained machines are determined by a maximum of only 1900 training examples , corresponding to 0.04% of the whole data .
It means that the trained machines are determined by a maximum of only 1900 training examples , corresponding to 0.04% of the whole data .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 1868
This number explains why iSVM takes only 2.8 seconds to train on the KDD-CUP 1999 data with nearly five million records .
This number explains why iSVM takes only 2.8 seconds to train on the KDD-CUP 1999 data with nearly five million records .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 1869
In our point of view the same phenomenon happens for CoreSVM .
From our point of view , the same phenomenon happens for CoreSVM .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0

Alignment 1870
The big variation of the trained machine indicates that i ) is a too loose stopping condition for the KDD-CUP 1999 data case .
The huge variation of the trained machine indicates that i ) is a too loose stopping condition for the KDD-CUP 1999 data case .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 1871
We draw variations in predictive accuracy and average training time of iSVM and CoreSVM in Figure 2 for a comparison .
We draw variations in predictive accuracy and average training time of iSVM and CoreSVM in Figure 2 for comparison .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0

Alignment 1872
Note that there has been different approaches tackling the KDD-CUP 1999 problem .
Note that there has been different approaches tackling the KDD-CUP 1999 problem .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 1873
In TABLE V we describe performances produced by different methods , including data random sampling , active SVM learning \CITE , clustering-based \CITE , CoreSVM \CITE , LibSVM \CITE , and iSVM .
In TABLE V we describe performances produced by different methods , including data random sampling , active SVM learning \CITE , clustering-based \CITE , CoreSVM \CITE , LibSVM \CITE , and iSVM .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0

Alignment 1874
iSVM achieves superior generalization performance and faster than SMO , random selection , cluster-based , and active learning .
iSVM achieves superior generalization performance and faster than SMO , random selection , cluster-based , and active learning .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 1875
We have introduced a new incremental algorithm for training SVMs .
We have introduced a new incremental algorithm for training SVMs .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 1876
iSVM differs from other methods in its twostage strategy to process training data . The first phase aims at finding a good approximate SVM solution as quickly as possible .
iSVM differs from other methods in its twostage strategy to process training data . The first phase aims at finding a good approximate SVM solution as quickly as possible .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0

Alignment 1877
The second phase uses temporal solutions to find out the remaining SVs .
The second phase uses temporal solutions to find out the remaining SVs .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 1878
Analysis and experimental result indicate that iSVM has advantage over conventional SMO implementation on applications where number of training examples is much larger than number of SVs .
The analysis and the experimental result indicate that iSVM has advantage over conventional SMO implementation on applications where number of training examples is much larger than number of SVs .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
4:1			2:1			0		1.0
5:1			3:1			0		1.0
6:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0

Alignment 1879
Training SVMs with large number of SVs is our research issue in the future .
Training SVMs with large number of SVs is our research issue in the future .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 1880
Requirements Engineering in a Model-based Methodology for Embedded Automotive Software
Requirements Engineering in a Model-based Methodology for Embedded Automotive Software
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 1881
This paper resumes the requirements engineering in a model-based methodology for embedded automotive software .
This paper examines the requirements engineering in a model-based methodology for embedded automotive software .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 1882
The methodology relies on two standard languages : EAST-ADL for automotive architecture description and SysML for systems modeling .
The methodology relies on two standard languages : EAST-ADL for automotive architecture description and SysML for systems modeling .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 1883
The requirements engineering in the methodology describes phases of elicitation , modeling , traceability , verification and validation .
The requirements engineering in the methodology describes phases of elicitation , modeling , traceability , verification and validation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 1884
It is illustrated by applying on a case study – the knock controller – a part of the engine management system .
It is illustrated by applying in a case study of the knock controller – a part of the engine management system .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 1885
Modern car is now equipped with more and more functionalities dependent on embedded electronics , ranging from powertrain and chassis control to body comfort and infotainment .
Modern car is now equipped with more and more functionalities dependent on embedded electronics , ranging from powertrain and chassis control to body comfort and infotainment .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 1886
These functionalities are distributed over a networked Electronic Control Units ( ECU ) .
These functionalities are distributed over a networked Electronic Control Units ( ECU ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 1887
The size and complexity of software for these embedded electronics increase rapidly with its cost raising from 10% of the overall cost in 1970 to 40% in 2010 .
The size and complexity of software for these embedded electronics increase rapidly with its cost rising from 10% of the overall cost in 1970 to 40% in 2010 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			2		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 1888
Actually , 90% of innovations in the automotive industry concerns embedded electronics and 80% among them are software \CITE .
Actually , 90% of innovations in the automotive industry concern embedded electronics and 80% among them are software \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			1		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 1889
A big challenge in developing automotive software concerns the quality .
A big challenge in developing automotive software concerns its quality .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:2			8:2			3		1.0
10:1			10:1			0		1.0

Alignment 1890
Automotive system are safety-critical systems where failures may cause severe damages or loss , so software errors led directly to car recalls .
Automotive systems are safety-critical systems whose failures may cause severe damage or loss , so software errors led directly to car recalls .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			1		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:2			10:2			3		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 1891
According to the report \CITE , one-third of the recalls in recent year is caused by software errors .
According to the report \CITE , one-third of the recalls in recent years are caused by software errors .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			1		1.0
13:2			13:2			3		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 1892
More efforts are needed on software’s verification and testing .
More effort is needed on software’s verification and testing .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			1:2			3		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 1893
Another challenge concerns the reduction the time of development .
Another challenge concerns the reduction the development time .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			8:1			0		1.0
7:1			6:1			0		1.0
8:1			9:1			0		1.0

Alignment 1894
The automotive market is shared by manufacturers , suppliers and tool vendors , and all needs shorten processes which favor the exchangeability among them and the reuse of software in different product lines .
The automotive market is shared by manufacturers , suppliers and tool vendors , and all need shorten processes which favor the exchangeability among them and the reuse of software in different product lines .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			1		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0

Alignment 1895
They also need to follow requirements along the development , from the specification to design and code , to anticipate and communicate its changes throughout teams .
They also need to follow requirements along the development , from the specification to the design and the code , to anticipate and communicate its changes throughout the team .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
28:1			25:1			1		1.0
29:1			26:1			0		1.0

Alignment 1896
New paradigm in software development is born in this context to face these challenges .
A new paradigm software development is formed in this context to face these challenges .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 1897
In Europe , automotive actors tried to cooperate on a common base for software development .
In Europe , automotive actors cooperated to establish mutual communication standardized for software development .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			6:1			0		1.0
7:1			11:1			2		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0

Alignment 1898
The result of this corporation is EAST-ADL \CITE , a recently defined standard .
The recent result of this corporation is EAST-ADL \CITE
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			9:2			3		1.0
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0

Alignment 1899
EAST-ADL is an architecture description language dedicated to automotive software .
an architecture description language dedicated to automotive software .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			2:1			0		1.0
1:1			3:1			0		1.0
2:1			4:1			0		1.0
3:1			5:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0

Alignment 1900
It provides a mean to describe the functionality of a vehicle , from high level requirement to implementation details .
It provides a means to describe the functionality of a vehicle , from high level requirements to implementation details .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			1		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			1		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 1901
It focuses on structural aspect , leaving behavioral aspect for existing tools . EASTADL is based on Unified Modeling Language 2 \CITE but has automotive-specific constructs and semantics in order to make system models unambiguous , consistent and exchangeable .
It focuses on structural aspects , leaving behavioral aspects for existing tools . EASTADL is based on Unified Modeling Language 2 \CITE but has automotive-specific constructs and semantics in order to make system models unambiguous , consistent and exchangeable .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			1		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			1		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0

Alignment 1902
Model-based development ( MBD ) is a preferred approach for automotive software because it improves the specification , design , and implementation phases .
Model-based development ( MBD ) is a preferred approach for automotive software because it improves the specification , design , and implementation phases .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 1903
MBD benefits from the Systems Modeling Language ( SysML ) \CITE , another recently defined by Object Management Group ( OMG ) .
MBD benefits from the Systems Modeling Language ( SysML ) \CITE , another recently defined by Object Management Group ( OMG ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 1904
SysML gives a means to early represent into models the requirements and physical parametric of automotive systems .
SysML is used to model the requirements and physical parameters of automotive systems .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			3		1.0
3:1			4:1			0		1.0
4:1			8:1			1		1.0
5:1			9:1			0		1.0
6:1			10:1			0		1.0
7:1			11:1			0		1.0
8:1			12:1			0		1.0
10:1			14:1			0		1.0
11:1			15:1			0		1.0
12:1			16:1			0		1.0
13:1			17:1			0		1.0

Alignment 1905
SysML has also the capacities of facilitate the design and verification .
SysML has also the capacities of facilitating the design and verification .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:2			6:2			3		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 1906
The research project MeMVaTEx \CITE addresses a modelbased methodology that emphasizes the requirements validation and traceability .
MeMVaTEx research project \CITE develops a modelbased methodology that emphasizes the requirements validation and traceability .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			3:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			4:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0

Alignment 1907
The methodology invests two languages : EAST-ADL for automotive architecture description and SysML for system modeling .
The methodology investigates two languages : EAST-ADL for automotive architecture description and SysML for system modeling .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 1908
The methodology describes step-by-step process with appropriate tools supporting each step .
The methodology describes a step-by-step process with appropriate tools supporting each step .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0

Alignment 1909
It aims to give a seamless solution for industrial use .
It aims to give a seamless solution for industrial use .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 1910
An automotive case study – the engine knock controller – a part of the Engine Management System ( EMS ) is used to illustrated the methodology .
An automotive case study shows that the engine knock controller – a part of the Engine Management System ( EMS ) - is used to illustrated the methodology .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0

Alignment 1911
This paper shows the requirements engineering in the methodology .
This paper shows the requirements engineering in the methodology .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 1912
It describes phases of elicitation , modeling and traceability , verification and validation , and accompanied tools .
It describes phases of elicitation , modeling and traceability , verification and validation , and accompanied tools .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 1913
The methodology concerns other aspects like safety , real-time , variability , or model transformation that will not be addressed here .
The methodology concerns other aspects such as safety , real-time , variability , or model transformation that will not be addressed here .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0

Alignment 1914
Our related works \CITE can be found on the Web site .
Our related works \CITE can be found on the website .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			10:1			2		1.0
10:1			11:1			0		1.0

Alignment 1915
The remainder of the paper is organized as follows : Section II and Section III resume the two languages EASTADL and SysML for architecture description and system modeling .
The remainder of the paper is organized as follows : Section II and Section III discuss how EASTADL and SysML are used architecture description and system modeling .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0

Alignment 1916
Section IV describes the knock phenomenon and controller .
Section IV describes the knock phenomenon and controller .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 1917
Section V presents the requirements engineering by phases of elicitation , modeling and traceability , verification and validation .
Section V presents the requirements engineering in three main phases : elicitation , modeling and traceability , verification and validation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
9:1			7:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0

Alignment 1918
We give framework tool for the engineering and some experiences from using these tools .
We describe the framework used for engineering tools and with using these tools .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			5:1			0		1.0
3:1			2:1			0		1.0
5:1			4:1			0		1.0
6:1			6:1			0		1.0
8:1			7:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0

Alignment 1919
Section VI concludes the paper .
Section VI concludes the paper .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0

Alignment 1920
EAST-ADL \CITE stands for Electronic Architecture and Software Tools-Architecture Description Language .
EAST-ADL \CITE stands for Electronic Architecture and Software Tools-Architecture Description Language .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 1921
The language is defined in the Embedded Electronic Architecture ( EEA ) project , one of many project from Information Technology for European Advancement ( ITEA ) .
The language is defined in the Embedded Electronic Architecture ( EEA ) project , one of many project initiated by Information Technology for European Advancement ( ITEA ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0

Alignment 1922
Important car manufactures , suppliers , tool vendors , and research institutes in Europe take part in this project to give birth EAST-ADL .
Important car manufactures , suppliers , tool vendors , and research institutes in Europe take part in this project to give birth to EAST-ADL .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0

Alignment 1923
This language is intended to support the development of automotive embedded software , by capturing all the related engineering information , including software , hardware , and its environment .
This language is intended to support the development of automotive embedded software by capturing all the related engineering information , including software , hardware , and its environment .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0

Alignment 1924
The language EAST-ADL reflects different views and details of the architecture and is structured in five abstraction layers as illustrated in Figure 1 .
EAST-ADL reflects different views and details of the architecture and is structured in five abstraction layers as illustrated in Figure 1 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			2:1			0		1.0
1:1			3:1			0		1.0
2:1			4:1			0		1.0
3:1			5:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0

Alignment 1925
These layers are :
These layers are :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0

Alignment 1926
- Vehicle level ( VL ) describes electronic features in driver’s point of view .
- Vehicle level ( VL ) describes electronic features from the driver’s point of view .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0

Alignment 1927
- Analysis level ( AL ) gives abstract functional definition of features in system context .
- Analysis level ( AL ) gives abstract functional definition of features in system context .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 1928
- Design level gives ( DL ) detailed functional definition of software including elementary decomposition .
- Design level gives ( DL ) detailed functional definition of software including elementary decomposition .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 1929
- Implementation level ( IL ) describes reusable code and system configuration for hardware deployment .
- Implementation level ( IL ) describes reusable code and system configuration for hardware deployment .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 1930
- Operational level ( OL ) supports final binary software deployment .
- Operational level ( OL ) supports final binary software deployment .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 1931
EAST-ADL has just revised in the project ATESST \CITE .
EAST-ADL has just been revised in the ATESST project \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			7:1			0		1.0
8:1			6:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0

Alignment 1932
Version 2 of EAST-ADL now links directly to AUTomotive Open System Architecture ( AUTOSAR ) , another initiative from automotive industry which standardizes software architecture and interfaces for ECUs .
Version 2 of EAST-ADL now links directly to AUTomotive Open System Architecture ( AUTOSAR ) , another initiative from the automotive industry which standardizes software architecture and interfaces for ECUs .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0

Alignment 1933
Essentially , AUTOSAR’s scope concerns the last two Implementation and Operational levels of the EAST-ADL .
Essentially , AUTOSAR’s scope concerns the last two Implementation and Operational levels of the EAST-ADL .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 1934
The project ATESST3 tries to the harmonize EAST-ADL 2 and AUTOSAR with summaries can be found in \CITE .
The project ATESST3 tries to the harmonize EAST-ADL 2 and AUTOSAR with summaries can be found in \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 1935
Since its adoption in 1997 by Object Management Group ( OMG ) to the last version UML 2 \CITE in 2007 , UML is successfully used by software engineers for modeling their software .
Since its adoption in 1997 by Object Management Group ( OMG ) to the last version called UML 2 \CITE in 2007 , UML is successfully used by software engineers for modeling their software .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0

Alignment 1936
Web applications and banking transactions benefits particularly from UML .
Web applications and banking transactions benefits particularly from UML .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 1937
However , UML lacks important elements to be used by system engineers to modeling their systems , e.g. , no means exists for modeling requirements , physical constraints among components , or internal transactions between subsystems .
However , UML lacks important elements to be used by system engineers to modeling their systems , such as a means for modeling requirements , physical constraints among components , or internal transactions between subsystems .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
20:1			20:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0
31:1			32:1			0		1.0
32:1			33:1			0		1.0
33:1			34:1			0		1.0
34:1			35:1			0		1.0
35:1			36:1			0		1.0

Alignment 1938
Many specific profiles were invented , giving partly solutions for some problems .
Many specific profiles were invented , giving partly solutions for some problems .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 1939
System Modeling Language ( SysML ) is an OMG standard , developed with objective to fill the semantic gap between systems , software , and other engineering disciplines .
System Modeling Language ( SysML ) is an OMG standard , developed to fill the semantic gap between systems , software , and other engineering disciplines .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0
24:1			26:1			0		1.0
25:1			27:1			0		1.0
26:1			28:1			0		1.0

Alignment 1940
By definition , OMG SysML enables system engineers in different domains to analyze , specify , design , and verify their complex systems , enhancing systems quality .
By definition , OMG SysML enables system engineers in different domains to analyze , specify , design , and verify their complex systems , enhancing systems quality .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0

Alignment 1941
Technically , SysML reuses a subset of UML 2 , adding new diagrams and modifying others .
Technically , SysML reuses a subset of UML 2 , adding new diagrams and modifying others .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 1942
It includes diagrams that can be used to specify system requirements , behavior , structure , and parametric relationships , known as the four pillars of SysML .
It includes diagrams that can be used to specify system requirements , behavior , structure , and parametric relationships , known as the four pillars of SysML .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0

Alignment 1943
Of the four pillars , only requirements and parametric diagrams are entirely new .
Of the four pillars , only requirements and parametric diagrams are entirely new .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 1944
The Figure 2 gives the complete SysML diagrams .
Figure 2 illustrates the complete SysML diagrams .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			1:1			0		1.0
1:1			2:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0

Alignment 1945
More descriptions and applications of SysML diagrams can be found in \CITE .
More descriptions and applications of SysML diagrams can be found in \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 1946
The project MeMVaTEx pays particular attention on the requirement diagram .
The project MeMVaTEx pays particular attention to the requirement diagram .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:2			5:2			3		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 1947
This diagram represent text requirement in the model .
This diagram represents text requirements in the model .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			1		1.0
3:1			3:1			0		1.0
4:1			4:1			1		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 1948
A requirement may have links to other requirements or to modeling actefacts via a set of four new stereotyped dependencies ( see Figure 3 ) .
A requirement may have links to other requirements or to modeling actefacts via a set of four new stereotyped dependencies ( see Figure 3 ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 1949
- " derive " indicates the derivation of requirement from other requirements .
- " derive " indicates the derivation of requirement from other requirements .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 1950
- " refine " indicates that an element is a refinement of a textual requirement .
- " refine " indicates that an element is a refinement of a textual requirement .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 1951
- " satisfy " shows the satisfaction of requirement by design .
- " satisfy " shows the satisfaction of requirement by design .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 1952
- " verify " shows the link from a test case to the requirement it verifies .
- " verify " shows the link from a test case to the requirement it verifies .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 1953
With these new stereotypes , engineers can follow forward and backward any requirement from the the phase of specification , how it is broken into sub-requirements , which design blocks satisfy requirement or which parts of code are concerned .
With these new stereotypes , engineers can keep track of any requirement from the the phase of specification in terms of how it is broken into sub-requirements and which design blocks satisfy requirement or which parts of code are concerned .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
9:1			35:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			9:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
37:1			36:1			0		1.0
38:1			37:1			0		1.0
39:1			38:1			0		1.0
40:1			39:1			0		1.0

Alignment 1954
With thousands of requirements may change during the development of an ordinary automotive project \CITE , the new capacity of SysML helps keeping the requirements traceability .
With thousands of requirements may change during the development of an ordinary automotive project \CITE , the new capacity of SysML helps maintaining requirements traceability .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:2			3		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0

Alignment 1955
New SysML stereotype introduces the link requirementtest case that is crucial for the requirements verification and validation because strict regulations in the automotive domain like IEC 61508 \CITE or the future ISO 26262 \CITE now impose that each requirement must be tested by test case .
New SysML stereotypes introduce the link between requirements and test cases that are crucial for requirements verification and validation because under strict regulations such as IEC 61508 \CITE and the upcoming ISO 26262 \CITE , each requirement must be tested by test cases .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			1		1.0
3:1			3:1			1		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			13:1			0		1.0
8:1			15:1			0		1.0
9:1			43:1			0		1.0
10:2			44:1			3		1.0
12:1			9:1			2		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			38:1			1		1.0
16:1			14:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			3		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
35:1			37:1			0		1.0
37:1			39:1			0		1.0
38:1			40:1			0		1.0
39:1			41:1			0		1.0
40:1			42:1			0		1.0
42:1			7:1			1		1.0
43:1			45:1			0		1.0

Alignment 1956
In SysML , a test case is intended to be used as a general mechanism to represent any of the standard verification methods for inspection , analysis , demonstration , or test .
A test case is a general mechanism to represent any of the standard vertification methods for inspection , analysis , demonstration , or testing .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			31:1			0		1.0
2:1			5:1			0		1.0
3:1			6:1			0		1.0
4:1			12:1			0		1.0
5:1			13:1			0		1.0
6:1			14:1			0		1.0
7:1			15:1			0		1.0
8:1			16:1			0		1.0
9:1			17:1			0		1.0
10:1			18:1			0		1.0
11:1			19:1			0		1.0
12:1			20:1			0		1.0
14:1			22:1			0		1.0
15:1			23:1			0		1.0
16:1			24:1			0		1.0
17:1			25:1			0		1.0
18:1			26:1			0		1.0
19:1			27:1			0		1.0
20:1			28:1			0		1.0
21:1			29:1			0		1.0
22:1			30:1			0		1.0
23:1			3:2			3		1.0
24:1			32:1			0		1.0

Alignment 1957
SysML has the capability for representing test cases and attaching them to their related requirements or use cases .
SysML can represent test cases and link them to their corresponding requirements or use cases .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			5:1			1		1.0
3:1			6:1			0		1.0
4:1			7:1			0		1.0
5:1			8:1			0		1.0
7:1			10:1			0		1.0
8:1			11:1			0		1.0
9:1			12:1			0		1.0
10:1			13:1			3		1.0
11:1			14:1			0		1.0
12:1			15:1			0		1.0
13:1			16:1			0		1.0
14:1			17:1			0		1.0
15:1			18:1			0		1.0

Alignment 1958
A test case can be an operation or a behavioral model ( Interaction , State Machine , Sequence or Activity Diagram ) .
A test case model , sus as Interaction , Slate Machine , Sequence , and Activity Diagram , can be either operational or behavioral .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			10:1			0		1.0
7:1			12:1			0		1.0
8:1			13:1			0		1.0
10:1			15:1			0		1.0
11:1			16:1			0		1.0
12:1			17:1			0		1.0
15:1			19:1			0		1.0
16:1			20:1			0		1.0
18:1			3:1			0		1.0
19:1			4:1			0		1.0
21:1			6:1			1		1.0
22:1			7:1			0		1.0
23:1			9:1			0		1.0
24:1			22:1			0		1.0

Alignment 1959
These new capacities of SysML will be detailed through the case study in Section V .
These new capacities of SysML will be detailed through the case study in Section V .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 1960
In a four-stroke gasoline engine , air and vaporized fuel are drawn in in the first stroke ( intake ) .
In a four-stroke gasoline engine , air and vaporized fuel are drawn in in the first stroke ( intake ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 1961
In the second stroke , fuel vapor and air are compressed and ignited ( compression ) .
In the second stroke , fuel vapor and air are compressed and ignited ( compression ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 1962
Fuel combusts and piston is pushed downwards in the third stroke ( combustion ) and exhaust is driven out in the last stroke ( exhaust ) .
Fuel combusts and piston is pushed downwards in the third stroke ( combustion ) and exhaust is driven out in the last stroke ( exhaust ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 1963
The cycle can be seen in the left of the Figure 4 .
The cycle can be seen in the left of the Figure 4 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 1964
In practice , ignition usually occurs before the end of the second stroke in order to maximizing power and fuel economy and minimize exhaust emission .
In practice , ignition usually occurs before the end of the second stroke in order to maximize power fuel economy and minimize exhaust emission .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			1		1.0
17:1			17:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0

Alignment 1965
Under some circumstances , when the temperature and pressure of the unburned air/fuel mixture exceeds a critical level , a second auto-ignition occurs as shown in the right of the Figure 4 .
When the temperature and pressure of the unburned air/fuel mixture exceeds a critical level , a second auto-ignition occurs as shown in the right picture in Figure 4 .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			5:1			0		1.0
2:1			6:1			0		1.0
3:1			7:1			0		1.0
4:1			8:1			0		1.0
5:1			9:1			0		1.0
6:1			10:1			0		1.0
7:1			11:1			0		1.0
8:1			12:1			0		1.0
9:1			13:1			0		1.0
10:1			14:1			0		1.0
11:1			15:1			0		1.0
12:1			16:1			0		1.0
13:1			17:1			0		1.0
14:1			18:1			0		1.0
15:1			19:1			0		1.0
16:1			20:1			0		1.0
17:1			21:1			0		1.0
18:1			22:1			0		1.0
19:1			23:1			0		1.0
20:1			24:1			0		1.0
21:1			25:1			0		1.0
22:1			26:1			0		1.0
23:1			27:1			0		1.0
26:1			30:1			0		1.0
27:1			31:1			0		1.0
28:1			32:1			0		1.0

Alignment 1966
The two-flame crossing produces a shock wave with rapid increase in cylinder pressure .
The two-flame crossing produces a shock wave with rapid increase in cylinder pressure .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 1967
The impulse caused by the shock wave excites a resonance in the cylinder at a characteristic frequency .
The impulse caused by the shock wave excites a resonance in the cylinder at a characteristic frequency .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 1968
Damages to piston , ring , and exhaust valves can result if sustained heavy knock occurs .
Damages to piston , ring , and exhaust valves could ensue if sustained heavy knock occurs .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			3		1.0
10:1			10:1			2		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 1969
An appropriate anti-knock control , represented in Figure 5 , is applied to each cylinder at every engine cycle from low engine speed up to the highest engine speed .
An appropriate anti-knock control , represented in Figure 5 , is applied to each cylinder at every engine cycle at any predetermined speed .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
22:1			28:1			0		1.0
23:1			29:1			0		1.0

Alignment 1970
A knock control system consists of one or several noise sensors , and a controller which acquire the noise through the sensors , and computes the correction during the combustion phases of the cylinders .
A knock control system consists of noise sensors that monitor the noise level , and a controller that computers corrections based on the feeback from noise sensors during the in-cylinder combustion process .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			9:1			0		1.0
7:1			10:1			0		1.0
10:1			17:1			0		1.0
11:1			18:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
18:1			24:1			1		1.0
22:1			20:1			0		1.0
26:1			21:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
30:1			29:1			0		1.0
32:1			34:1			0		1.0

Alignment 1971
The controller can detect knocks using spectral analysis techniques \CITE . The controller decide to advance or retard the ignition to correct .
Spectral analysis techniques are used to allow the engine controller \CITE to detect knocks and advance or retard the ignition .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			7:1			0		1.0
2:1			8:1			0		1.0
5:1			14:1			0		1.0
9:1			1:1			0		1.0
10:1			9:1			0		1.0
11:1			20:1			0		1.0
12:1			3:1			0		1.0
13:1			4:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			10:1			0		1.0

Alignment 1972
We use the V-model in the Figure 6 to illustrate the requirements engineering phase by phase .
We use the V-model in the Figure 6 to illustrate the requirements engineering phase by phase .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 1973
It begins with the requirement elicitation from the specification document .
It begins with the requirements elicitation from the specification .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			1		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			10:1			0		1.0

Alignment 1974
Then requirement are represented in models from architecture level to design level down to the code .
Then requirements are represented in models from architecture level to design level down to the code .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			1		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 1975
Verification and validation ( V&V ) are present along the requirement engineering , showing V&V activities in each phase and for each requirement .
Verification and validation ( V&V ) are present along the requirements engineering , showing V&V activities in each phase and for each requirement .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			1		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 1976
This phase consists of a list of requirements that can be exploited during the next phases .
This phase consists of a list of requirements that can be exploited during the next phases .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 1977
System engineers , safety experts , and time are needed to build a complete and consistent list of requirement .
System engineers , safety experts , and time are needed to build a complete and consistent list of requirements .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			1		1.0
19:1			19:1			0		1.0

Alignment 1978
Most of project’s failure is due to insufficient attentions in this phase , as reported in \CITE .
Most of the project’s failure is due to insufficient attentions in this phase , as reported in \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0

Alignment 1979
In MeMVaTEx project , requirements are classified by EAST-ADL levels .
In the MeMVaTEx project , requirements are classified by EAST-ADL levels .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0

Alignment 1980
At each level , requirements are numbered and structured in functional ( F ) and non-functional ( NF ) .
At each level , requirements are numbered and structured in functional ( F ) and non-functional ( NF ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 1981
Nonfunctional requirement are classified by categories such as performance ( P ) , safety ( S ) and availability ( A ) .
Nonfunctional requirements are classified by categories such as performance ( P ) , safety ( S ) and availability ( A ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			1		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 1982
Note that the respects of regulation in automotive domain introduce safety requirements at each level , resulting more complexity in the design and test .
Note that the respects of regulation in automotive domains introduce safety requirements at each level , resulting more complexity in the design and test .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			1		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 1983
It also led us to extent the SysML Requirement stereotype to a particular MeMVaTEx Requirement stereotype
It also led us to extend SysML Requirement stereotype to a particular MeMVaTEx Requirements stereotype
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			1		1.0
14:1			15:1			0		1.0

Alignment 1984
Table I gives some examples of requirements of the knock controller .
Table I gives examples of requirements of the knock controller .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0

Alignment 1985
Requirements are actually stored in tabular applications like Word or Excel .
Requirements are actually stored in tabular applications such as Word or Excel .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0

Alignment 1986
The SysML Requirement stereotype as defined by the standard contains a description Text , an identifier ( Id ) and links to other requirements , design element , and test case for each requirement ( see Figure 7 , left ) .
The SysML Requirement stereotype as defined by the standard contains a description Text , an identifier ( Id ) and links to other requirements , design elements , and test cases for each requirement ( see Figure 7 , left ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			1		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:2			30:2			3		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0

Alignment 1987
When taking into accounts other aspects of analysis , verification , and validation , this definition is not detailed enough .
When taking into accounts other aspects of analysis , verification , and validation , this definition is not detailed enough .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 1988
In order to better support the requirements engineering , we have interest in extending this SysML Requirement stereotype by adding new fields .
In order to better support the requirements engineering , we have interest in extending this SysML Requirement stereotype by adding new fields .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 1989
These fields are described in details in \CITE .
These fields are described in detail in \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			1		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 1990
We call the new stereotype called MeMVaTEx Requirement ( see Figure 7 , right ) .
We call the new stereotype MeMVaTEx Requirement ( see Figure 7 , right ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0

Alignment 1991
This phase consists of selecting requirements from an upper level and links it to one or many requirements from the lower levels using one of four stereotypes defined above .
This phase consists of selecting requirements from an upper level and links them to one or many requirements from the lower levels using one of the four stereotypes defined above .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0

Alignment 1992
Doing that correctly guarantees the bidirectional traceability from requirement to design and code .
Doing that correctly guarantees the bidirectional traceability from requirements to design and code .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			1		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 1993
We show an example of requirement modeling from the Vehicle level to design level in Figure 8 .
We show an example of requirement modeling from the Vehicle level to design level in Figure 8 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 1994
Requirements are classified by EAST-ADL 2 levels .
Requirements are classified by EAST-ADL 2 levels .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 1995
In the diagram , the requirements traceability from Vehicle Level to Design Level is shown : AL-F-12 is a functional requirement at the Analysis Level .
In the diagram , the requirements traceability from Vehicle Level to Design Level is shown : AL-F-12 is a functional requirement at the Analysis Level .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 1996
It is derived from the requirement VL-F-9 at Vehicle Level , and then refined to DLF-7 at Design Level .
It is derived from the requirement VL-F-9 at Vehicle Level , and then refined to DLF-7 at Design Level .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 1997
The three requirements are respectively satisfied by KnockCorrection , EngineControl , and ThresholdCalculation blocks
The three requirements are respectively satisfied by KnockCorrection , EngineControl , and ThresholdCalculation blocks
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 1998
The basic design of KnockFunction block is sketched in a Block Definition Diagram in the Figure 9 .
The basic design of KnockFunction block is sketched in a Block Definition Diagram in the Figure 9 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 1999
It show blocks involved and its item flows .
It show blocks involved and its item flows .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 2000
Each block in the KnockFunction can be detailed by using Internal Diagram Block ( IBD ) .
Each block in the KnockFunction can be detailed by using Internal Diagram Block ( IBD ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 2001
The V&V is an important phase in software development .
The V&V is an important phase in software development .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 2002
V&V activities concern two aspects :
V&V activities concern two aspects :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0

Alignment 2003
- Verification of the realization , i.e. did we build the product right?
- Verification of the realization , i.e. " Did we build the product right? "
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0

Alignment 2004
It is the analysis of the works that have been done , generally document analysis , code inspection and review , unit and integration testing .
It is the analysis of the works that have been done , including general document analysis , code inspection and review , unit and integration testing .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
13:1			12:1			1		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0

Alignment 2005
- Validation of the application , i.e. did we build the right product?
- Validation of the application , i.e. " Did we build the right product? "
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0

Alignment 2006
This is a test phase whose objective is to show that intended services are fulfilled . This test phase is realized on the product .
This is a test phase whose objective is to show that intended services are fulfilled . This test phase is realized on the product .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 2007
In MeMVaTEx project , it is needed that V&V activities must link to and test each requirement as requested by safety regulations .
In the MeMVaTEx project , it is needed that V&V activities must link to and test each requirement as requested by safety regulations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0

Alignment 2008
We show a test case , represented by an activity diagram in the Figure 10 , planned for the requirement like DL-NF-1 “The capture must end when the Knock Acquisition Window Duration has elapsed " .
For example , the test case represented by an activity diagram in Figure 10 is intended to test such requirement as .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			5:1			0		1.0
3:1			12:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
19:1			19:1			0		1.0
21:1			35:1			0		1.0

Alignment 2009
In this case , the internal structure of the capturing block and how it works may be known by the tester .
In this case , the internal structure of the capturing block and the way it works may be known to the tester .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:2			12:1			3		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0

Alignment 2010
This kind of test is called white-box testing .
This kind of test is called white-box testing .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 2011
There are also functional requirements such as AL-F-10 “Knock control function shall know the piston position in order to measure and correct the knock on the right cylinder ."
There are also functional requirements such as the AL-F-10 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			13:1			0		1.0
8:1			7:1			0		1.0

Alignment 2012
In this case , tester may have no knowledge of the internal structure of the knock control block .
In this case , the tester may have no knowledge of the internal structure of the knock control block .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0

Alignment 2013
This kind of test is known as black-box testing .
This kind of test is known as black-box testing .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 2014
Input data is sent to the structure and the output is compared to expected output , giving the verdict .
Input data are sent to the structure and the output are compared to the expected output to giving the verdict .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			2		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			2		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			17:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
17:1			16:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0

Alignment 2015
This test can be resumed in the Figure 11 .
This test in Figure 11 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			5:1			0		1.0
3:1			7:1			0		1.0
4:1			8:1			0		1.0
5:1			9:1			0		1.0

Alignment 2016
Tools are listed in refer to the V-model .
Tools are listed in reference to the V-model .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:2			4:2			3		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 2017
On the left branch , requirement management ( RM ) tools like Telelogic DOORS \CITE , IBM RequisitePro \CITE , or TNI Reqtify \CITE are used in projects with large number of requirement .
On the left branch , requirements management ( RM ) tools like Telelogic DOORS \CITE , IBM RequisitePro \CITE , or TNI Reqtify \CITE are used in projects with a large number of requirements .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			1		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			1		1.0
34:1			33:1			0		1.0

Alignment 2018
They have the capacities of managing and tracing requirement and support team’s corporation .
They have the capacities managing tracing requirement , and support the team’s corporation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			5:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 2019
Major modeling tools such as Telelogic Rhapsody \CITE , IBM Rational \CITE , or ARTiSAN Studio \CITE support UML/SysML and have the capacities to import specific profiles . It can also export models into an interchangeable format .
Major modeling tools such as Telelogic Rhapsody \CITE , IBM Rational \CITE , or ARTiSAN Studio \CITE support UML/SysML and have the capacities to import specific profiles . It can also export models into an interchangeable format .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0

Alignment 2020
Simulink is a prime tool at the implementation level .
Simulink is a prime tool at the implementation level .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 2021
Simulink gives the most details descriptions of a functional block .
Simulink gives the most details descriptions of a functional block .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 2022
Simulink and its tool suite can generate code and test cases , and verify the design by simulation .
Simulink and its tool suite can generate code and test cases , and verify the design by simulation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 2023
On the right branch , the validation can be reinforced by running software on simulator ( software-in-the-loop , SIL ) or by injecting code on dedicated hardware then running simulation ( hardware-in-the-loop , HIL ) \CITE .
On the right branch , the validation can be reinforced by running software on simulator ( software-in-the-loop , SIL ) or by injecting code on dedicated hardware then running simulation ( hardware-in-the-loop , HIL ) \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0

Alignment 2024
Finally , a prototype testing validates the product .
Finally , a prototype testing validates the product .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 2025
The validation is enterprise and proprietary solution
The validation is an enterprise and proprietary solution .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0

Alignment 2026
In the MeMVaTEx project , there are about many hundreds requirements for the knock controller .
In the MeMVaTEx project , there are about many hundreds of requirements for the knock controller .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0

Alignment 2027
It can be managed using only Office applications like Word and Excel .
It can be managed using only Office applications like Word and Excel .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 2028
The use of RM like Reqtify or DOORS is planned for future use when the number of requirements is big enough .
The use of RM such as Reqtify or DOORS is planned for future use when the number of requirements is big enough .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0

Alignment 2029
Modeling is done using ARTiSAN Studio .
Modeling is done using ARTiSAN Studio .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0

Alignment 2030
For particular purpose , we need EAST-ADL profile and MARTE \CITE , an-other UML profile for real-time modeling .
For this particular purpose , we need the EAST-ADL profile and MARTE \CITE , an-other UML profile for real-time modeling .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0

Alignment 2031
These profiles are imported into ARTiSAN Studio .
These profiles are imported into ARTiSAN Studio .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 2032
ARTiSAN can connect to RM tools to import requirements from or export traceability or requirement tables as seen in Figure 13 .
ARTiSAN can be connected to RM tools to import requirements and export traceability or requirement tables as seen in Figure 13 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			2:1			1		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 2033
At implementation level , ARTiSAN introduces an integration with Simulink models that will give systems engineers the ability to define and simulate function block diagrams in Simulink and export them into a SysML model in ARTiSAN for ongoing development and maintenance .
At the implementation level , ARTiSAN introduces an integration with Simulink models that will give systems engineers the ability to define and simulate function block diagrams in Simulink and export them into a SysML model in ARTiSAN for ongoing development and maintenance .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
37:1			36:1			0		1.0
38:1			37:1			0		1.0
39:1			38:1			0		1.0
40:1			39:1			0		1.0
41:1			40:1			0		1.0
42:1			41:1			0		1.0

Alignment 2034
For now , test cases are generated manually and the use of many validation tools is under consideration .
For now , test cases are generated manually and the use of many validation tools is under consideration .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 2035
Actual context in developing software for embedded electronics raises challenges of managing the complexity of software while still guaranteeing the quality and productivity .
The actual context in developing software for embedded electronics raises challenges of managing the complexity of software while still guaranteeing the quality and productivity .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0

Alignment 2036
Automotive industry introduces many standards as a base from which automotive actors will compete on implementing software using proper process and methodology .
The automotive industry introduces many standards as a base from which automotive actors will compete on implementing software using proper processes and methodologies .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			1		1.0
21:1			20:1			0		1.0
22:1			21:1			1		1.0
23:1			22:1			0		1.0

Alignment 2037
This paper presents requirements engineering in a model-based methodology proposed by the project MeMVaTEx .
This paper presents requirements engineering in a model-based methodology proposed by the MeMVaTEx project .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			13:1			0		1.0
13:1			12:1			0		1.0
14:1			14:1			0		1.0

Alignment 2038
in order facilitate the requirements validation and traceability .
In order to facilitate the requirements validation and traceability .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0

Alignment 2039
The methodology is structured by EAST-ADL abstraction levels and benefits from the systems modeling SysML .
The methodology is structured by EAST-ADL abstraction levels and benefits from the SysML systems modeling .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			14:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			15:1			0		1.0

Alignment 2040
By a case study , we show the engineering of requirement through different phases and suggest tools for each phase .
By conducting a case study , we demonstrate the engineering of requirements through different phases and suggest tools for each phase .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			2		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			1		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0

Alignment 2041
Software using these standards is planned to be implemented in real car from 2010 \CITE .
Software using these standards is planned to be implemented in real cars from 2010 \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			1		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 2042
Processes and tools for software may change or emerge by then .
Processes and tools for software may change or emerge by then .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 2043
MeMVaTEx methodology is not definitive but open for changes and evolution before a seamless solution is reached .
MeMVaTEx methodology is not definitive but open for changes and evolution before a seamless solution is reached .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 2044
﻿<document>
﻿<document>
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0

Alignment 2045
Incorporating Statistical Background Model and Joint Probabilistic Data Association Filter into Motorcycle Tracking
Incorporating Statistical Background Model and Joint Probabilistic Data Association Filter into Motorcycle Tracking
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 2046
Multi - target tracking is an attractive research field due to its widespread application areas and challenges .
Multi - target tracking is an attractive research field due to its widespread application areas and challenges .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 2047
Every point tracking method includes two mechanisms : object detection and data association .
Every point tracking method includes two mechanisms : object detection and data association .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 2048
This paper is a combination between a statistical background modeling method for foreground object detection and Joint Probabilistic Data Association filter ( JPDAF ) in the context of motorcycle tracking .
This paper is a combination between a statistical background modeling method for foreground object detection and Joint Probabilistic Data Association filter ( JPDAF ) in the context of motorcycle tracking .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0

Alignment 2049
A major limitation of JPDAF is its inability to adapt to changes in the number of targets , but in this work , it is modified so that we can successfully apply JPDAF with known number of targets at each time instant .
A major limitation of JPDAF is its inability to adapt to changes in the number of targets , but in this work , it is modified so that we can successfully apply JPDAF with known number of targets at each time instant .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0

Alignment 2050
The experimental system works well with the number of targets less than 10 / frame and be able to self-evolve with gradual and " once-off " background changes .
The experimental system works well with the number of targets less than 10 / frame and be able to self-evolve with gradual and " once-off " background changes .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 2051
Motion understanding is an essential function of human vision .
Motion understanding is an essential function of human vision .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 2052
Consequently , object tracking takes the crucial role in computer vision .
Consequently , object tracking takes the crucial role in computer vision .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 2053
Multi - target tracking has widespread applications in both military ( air defense , air traffic control , ocean surveillance ) and civilian areas ( for automatical surveillance demands in public or secret places ) , especially when human labour becomes more and more expensive .
Multi - target tracking has widespread applications in both military ( air defense , air traffic control , ocean surveillance ) and civilian areas ( for automatical surveillance demands in public or secret places ) , especially when human labour becomes more and more expensive .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0

Alignment 2054
Object tracking , in general , is a challenging problem .
Object tracking , in general , is a challenging problem .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 2055
Its complexities arise due to the following factors : loss of information caused by projection from 3D to 2D space , complex object motions , complex object shapes , partial and full object occlusions , scene illumination changes , and realtime processing requirements .
Its complexities arise due to the following factors : loss of information caused by projection from 3D to 2D space , complex object motions , complex object shapes , partial and full object occlusions , scene illumination changes , and realtime processing requirements .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0

Alignment 2056
There are three main categories of object tracking </CITE> : point tracking , kernel tracking , and silhouette tracking .
There are three main categories of object tracking </CITE> : point tracking , kernel tracking , and silhouette tracking .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 2057
While kernel and silhouette tracking concern object shapes , point tracking considers an object as a
While kernel and silhouette tracking concern object shapes , point tracking considers an object as a
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 2058
point and just focuses on its position and motion , which can be represented by state vector .
point and just focuses on its position and motion , which can be represented by state vector .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 2059
Filtering is a class of methods that is suited for solving the dynamic state estimation problems of point tracking .
Filtering is a class of methods that is suited for solving the dynamic state estimation problems of point tracking .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 2060
In multi-target tracking , we have a task of finding a correspondence between the current targets and measurements , named data association .
In multi-target tracking , we have a task of finding a correspondence between the current targets and measurements , named data association .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 2061
Data association is a complicated problem especially in the presence of occlusions , misdetections , entries , and exits of objects .
Data association is a complicated problem especially in the presence of occlusions , misdetections , entries , and exits of objects .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 2062
There are many statistical techniques for data association </CITE> , among them , Joint Probabilistic Data Association ( JPDA) is the method that aims to find a correspondence between measurements and objects at the current time step based on enumerating all possible associations and computing the association probabilities , it is a widely used technique for data association ( </CITE> , </CITE> ) .
There are many statistical techniques for data association </CITE> , among them , Joint Probabilistic Data Association ( JPDA) is the method that aims to find a correspondence between measurements and objects at the current time step based on enumerating all possible associations and computing the association probabilities . It is a widely used technique for data association ( </CITE> , </CITE> ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			63:1			0		1.0
50:1			50:1			0		1.0
51:1			51:1			0		1.0
52:1			52:1			0		1.0
53:1			53:1			0		1.0
54:1			54:1			0		1.0
55:1			55:1			0		1.0
56:1			56:1			0		1.0
57:1			57:1			0		1.0
58:1			58:1			0		1.0
59:1			59:1			0		1.0
60:1			60:1			0		1.0
61:1			61:1			0		1.0
62:1			62:1			0		1.0

Alignment 2063
However , to have a good JPDA filter ( JPDAF ) , it is required to have accurate measurements , that means we need to have good object detection results .
However , to have a good JPDA filter ( JPDAF ) , it is required to have accurate measurements . That means we need to have good object detection results .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			30:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0

Alignment 2064
Every tracking method requires an object detection mechanism , there are those which just need the detection at the first time objects appear , while the others need it in every frame , point tracking belongs to this type .
Every tracking method requires an object detection mechanism . There are those which just need the detection at the first time objects appear , while the others need it in every frame . Point tracking belongs to this type .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			39:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0

Alignment 2065
One effective way for foreground object detection is to give an accurate background model .
One effective way for foreground object detection is to give an accurate background model .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 2066
Recently , L . Li et al proposed a foreground object detection method by statistical modeling of complex backgrounds </CITE> .
Recently , L . Li et al proposed a foreground object detection method by statistical modeling of complex backgrounds </CITE> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 2067
This work used a Bayesian framework for incorporating three type of features : spectral , spatial and temporal features into a representation of complex background containing both stationary and nonstationary objects .
This work used a Bayesian framework for incorporating three types of features , i.e. , spatial and temporal features into a representation of complex background containing both stationary and nonstationary objects .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:2			9:2			3		1.0
11:1			11:1			0		1.0
12:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0

Alignment 2068
With the statistics of background features , the method is able to : represent the appearances of both static and dynamic background pixels , self-evolve to gradual as well as sudden " once - off " background changes .
With the statistics of background features , the method is able to represent the appearances of both static and dynamic background pixels and self - evolve to gradual as well as sudden " once - off " background changes .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
24:1			33:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
37:1			36:1			0		1.0
38:1			37:1			0		1.0
39:1			38:1			0		1.0

Alignment 2069
Taking advantage of the excellent object detection results from this method , this paper employs JPDAF for vehicle tracking in the motorcycle lane .
Taking advantage of the excellent object detection results from this method , this paper employs JPDAF for vehicle tracking in the motorcycle lane .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 2070
A major limitation of JPDAF is its inability to adapt to changes in the number of targets , because it is confused between a measurement originated from a new object appearance and a false alarm .
A major limitation of JPDAF is its inability to adapt to changes in the number of targets , because it is confused between a measurement originated from a new object appearance and a false alarm .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0

Alignment 2071
However , in the context of motorcycle surveillance , we has proposed a strategy to detect new objects entering and objects leaving the observation area , so that we can successfully apply JPDAF with known number of targets at each time instant .
However , in the context of motorcycle surveillance , we has proposed a strategy to detect new objects entering and objects leaving the observation area , so that we can successfully apply JPDAF with known number of targets at each time instant .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0

Alignment 2072
The experimental system has good results with the number of targets less than 10 / frame , including of detecting and tracking the wrong-wayed motorcycles .
The experimental system has good results with the number of targets less than 10 / frame , including results detecting and tracking the wrong-wayed motorcycles .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 2073
Motorcycle tracking in particular and traffic tracking in generral , is an interesting but challenging application .
Motorcycle tracking in particular and traffic tracking in generral is an interesting but challenging application .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0

Alignment 2074
Its main difficulties can be enumerated as: the severely occlusions when traffic density is high ( especially in rush hours ) , the shadows of big vehicles , and the real-time processing demand of a traffic surveillance system .
Its main difficulties can be enumerated as the severely occlusions when traffic density is high ( especially in rush hours ) , the shadows of big vehicles , and the real-time processing demand of a traffic surveillance system .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0

Alignment 2075
This paper is the next step ( after </CITE> ) of the effort finding the most satisfied approach for automatical traffic surveillance in big cities of Vietnam .
This paper is the next step ( after </CITE> ) to find the most satisfying approach for automatical traffic surveillance in big cities of Vietnam .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:2			13:1			3		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			1		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0
24:1			26:1			0		1.0
25:1			27:1			0		1.0

Alignment 2076
The remains of this paper is organized as follow : section II is the main ideas for statistical modeling of complex background proposed in </CITE> , section III reviews the background of JPDAF , a complete algorithm and experimented results on simulated data of JPDAF are presented at the end of this section , section IV is the combination of statistical background model and the modified JPDAF so that they can be applied in the motorcycle tracking situation , the experimental results of this combination are submitted in section V , and the conclusion is after all others .
The rest of this paper is organized as Section II is the main ideas for statistical modeling of complex background proposed in </CITE> . Section III reviews the background of JPDAF , a complete algorithm and experimented results on simulated data of JPDAF are presented at the end of this section , section IV is the combination of statistical background model and the modified JPDAF so that they can be applied in the motorcycle tracking situation . The experimental results of this combination are submitted in section V , and section VI presents our conclusion .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			2		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			98:1			0		1.0
25:1			27:1			0		1.0
26:1			28:1			0		1.0
27:1			29:1			0		1.0
28:1			30:1			0		1.0
29:1			31:1			0		1.0
30:1			32:1			0		1.0
31:1			33:1			0		1.0
32:1			34:1			0		1.0
33:1			35:1			0		1.0
34:1			36:1			0		1.0
35:1			37:1			0		1.0
36:1			38:1			0		1.0
37:1			39:1			0		1.0
38:1			40:1			0		1.0
39:1			41:1			0		1.0
40:1			42:1			0		1.0
41:1			43:1			0		1.0
42:1			44:1			0		1.0
43:1			45:1			0		1.0
44:1			46:1			0		1.0
45:1			47:1			0		1.0
46:1			48:1			0		1.0
47:1			49:1			0		1.0
48:1			50:1			0		1.0
49:1			51:1			0		1.0
50:1			52:1			0		1.0
51:1			53:1			0		1.0
52:1			54:1			0		1.0
53:1			55:1			0		1.0
54:1			56:1			0		1.0
55:1			57:1			0		1.0
56:1			58:1			0		1.0
57:1			59:1			0		1.0
58:1			60:1			0		1.0
59:1			61:1			0		1.0
60:1			62:1			0		1.0
61:1			63:1			0		1.0
62:1			64:1			0		1.0
63:1			65:1			0		1.0
64:1			66:1			0		1.0
65:1			67:1			0		1.0
66:1			68:1			0		1.0
67:1			69:1			0		1.0
68:1			70:1			0		1.0
69:1			71:1			0		1.0
70:1			72:1			0		1.0
71:1			73:1			0		1.0
72:1			74:1			0		1.0
73:1			75:1			0		1.0
74:1			76:1			0		1.0
75:1			77:1			0		1.0
78:1			80:1			0		1.0
79:1			81:1			0		1.0
80:1			82:1			0		1.0
81:1			83:1			0		1.0
82:1			84:1			0		1.0
83:1			85:1			0		1.0
84:1			86:1			0		1.0
85:1			87:1			0		1.0
86:1			88:1			0		1.0
87:1			89:1			0		1.0
88:1			90:1			0		1.0
89:1			91:1			0		1.0
90:1			10:1			0		1.0
94:1			93:1			0		1.0

Alignment 2077
Let </Eq> be a pixel in a video frame at time </Eq> with its Decartes co-ordinate , </Eq> be the feature vector extracted at </Eq> .
Let </Eq> be a pixel in a video frame at time </Eq> with its Decartes co-ordinate , </Eq> be the feature vector extracted at </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 2078
Then using Bayes formula we can determine the probability that </Eq> belongs to background given </Eq> as follow : </Eq> ( 1 ) where </Eq> implies that </Eq> belongs to background .
Then using the Bayes formula , we can determine the probability that </Eq> belongs to a background given </Eq> as follow : </Eq> ( 1 ) where </Eq> implies that </Eq> belongs to the background .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
6:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0
26:1			23:1			0		1.0
27:1			24:1			0		1.0
28:1			25:1			0		1.0
29:1			26:1			0		1.0
30:1			27:1			0		1.0
31:1			28:1			0		1.0
32:1			29:1			0		1.0
34:1			30:1			0		1.0
35:1			31:1			0		1.0

Alignment 2079
Similarly , the probability that </Eq> belongs to a foreground object given </Eq> is : </Eq> ( 2 ) where </Eq> refers that </Eq> is a foreground point .
Similarly , the probability that </Eq> belongs to a foreground object given </Eq> is : </Eq> ( 2 ) where </Eq> refers that </Eq> is a foreground point .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 2080
According to Bayesian decision rule , </Eq> will be classified as background point if : </Eq> ( 3 )
According to Bayesian decision rule , </Eq> will be classified as a background point if : </Eq> ( 3 )
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0

Alignment 2081
Undergoing some transformations , ( 3 ) is equivalent to : </Eq> ( 4 ) where </Eq> is the probability that </Eq> is classified as background , </Eq> is the probability that </Eq> is observed at </Eq> , and </Eq> is the probability that </Eq> is observed when </Eq> has already been classified as background .
Undergoing some transformations , ( 3 ) is equivalent to : </Eq> ( 4 ) where </Eq> is the probability that </Eq> is classified as the background , </Eq> is the probability that </Eq> is observed at </Eq> , and </Eq> is the probability that </Eq> is observed when </Eq> has already been classified as the background .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			41:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
37:1			36:1			0		1.0
38:1			37:1			0		1.0
39:1			38:1			0		1.0
40:1			39:1			0		1.0
41:1			40:1			0		1.0
43:1			42:1			0		1.0
44:1			43:1			0		1.0
45:1			44:1			0		1.0
46:1			45:1			0		1.0
47:1			46:1			0		1.0
48:1			47:1			0		1.0
49:1			48:1			0		1.0
50:1			49:1			0		1.0
51:1			50:1			0		1.0
52:1			51:1			0		1.0
53:1			52:1			0		1.0
54:1			53:1			0		1.0
56:1			54:1			0		1.0
57:1			55:1			0		1.0

Alignment 2082
Thus , we can use </Eq> , </Eq> and </Eq> , which will be modeled and estimated based on statistics in subsection B and C , to judge whether a point comes from background or foreground .
Thus , we can use </Eq> , </Eq> and </Eq> , which will be modeled and estimated based on statistics in subsection B and C , to judge whether a point comes from a background or a foreground .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
37:1			35:1			0		1.0
38:1			36:1			0		1.0

Alignment 2083
To estimate </Eq> , </Eq> and </Eq> , we need a data structure to take into account the statistical information relevant to feature vector </Eq> at </Eq> over a sequence of frames .
To estimate </Eq> , </Eq> and </Eq> , we need a data structure to take into account the statistical information relevant to feature vector </Eq> at </Eq> over a sequence of frames .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0

Alignment 2084
Each feature type at </Eq> has a table of statistics defined as : </Eq> ( 5 ) where </Eq> grasps the </Eq> at time </Eq> based on the classification results at </Eq> up to time </Eq> , and </Eq> takes note the statistics of the </Eq> feature vectors which have the highest frequencies at </Eq> , each </Eq> contains : </Eq> ( 6 ) where </Eq> is the dimension of </Eq> .
Each feature type at </Eq> has a table of statistics defined as : </Eq> ( 5 ) where </Eq> grasps the </Eq> at time </Eq> based on the classification results at </Eq> up to time </Eq> , and </Eq> takes note the statistics of the </Eq> feature vectors which have the highest frequencies at </Eq> , each </Eq> contains : </Eq> ( 6 ) where </Eq> is the dimension of </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0
49:1			49:1			0		1.0
50:1			50:1			0		1.0
51:1			51:1			0		1.0
52:1			52:1			0		1.0
53:1			53:1			0		1.0
54:1			54:1			0		1.0
55:1			55:1			0		1.0
56:1			56:1			0		1.0
57:1			57:1			0		1.0
58:1			58:1			0		1.0
59:1			59:1			0		1.0
60:1			60:1			0		1.0
61:1			61:1			0		1.0
62:1			62:1			0		1.0
63:1			63:1			0		1.0
64:1			64:1			0		1.0
65:1			65:1			0		1.0
66:1			66:1			0		1.0
67:1			67:1			0		1.0
68:1			68:1			0		1.0
69:1			69:1			0		1.0
70:1			70:1			0		1.0
71:1			71:1			0		1.0

Alignment 2085
In table </Eq> , the </Eq> are kept sorting in descending order with respect to </Eq> , the frequence of </Eq> .
In table </Eq> , the </Eq> are kept sorting in descending order with respect to </Eq> , the frequence of </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 2086
Then , the first </Eq> members in </Eq> will be used to estimate </Eq> , </Eq> and </Eq> in subsection C .
Then , the first </Eq> members in </Eq> will be used to estimate </Eq> , </Eq> and </Eq> in subsection C .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 2087
Another important issue in background modeling is feature selection .
Another important issue in background modeling is feature selection .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 2088
Herein , three types of features : spectral , spatial and temporal features are combined for complex background modeling .
Three types of features (namely spectral, spatial and temporal features) are combined for complex background modeling.
Line2Start:Length	Line1Start:Length	Module		Score
1:1			3:1			0		1.0
2:1			4:1			0		1.0
3:1			5:1			0		1.0
6:1			9:1			0		1.0
7:1			10:1			0		1.0
8:1			11:1			0		1.0
10:1			13:1			0		1.0
11:1			14:1			0		1.0
12:1			15:1			0		1.0
13:1			16:1			0		1.0
14:1			17:1			0		1.0

Alignment 2089
1 ) Feature selection for static background pixels : due to the constancy in shape and appearance of a pixel comes from a static background object , spectral and spatial features , in this case are its color and gradient , are exploited .
1 ) Feature selection for static background pixels : due to the constancy in shape and appearance of a pixel coming from a static background object , spectral and spatial features , in this case being its color and gradient , are exploited .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			1		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			3		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0

Alignment 2090
Let </Eq> be the color vector and </Eq> be the gradient vector of a pixel </Eq> , then we respectively need two tables </Eq> and </Eq> to make them learned .
Let </Eq> be the color vector and </Eq> be the gradient vector of a pixel </Eq> , then we respectively need two tables </Eq> and </Eq> to make them learned .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0

Alignment 2091
Because two types of features are used , the decision rule in ( 4 ) must be modified with the assumption that color and gradient vectors are independent : </Eq> ( 7 )
Because two types of features are used , the decision rule in ( 4 ) must be modified with the assumption that color and gradient vectors are independent : </Eq> ( 7 )
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0

Alignment 2092
With color and gradient features , we need a quantization measure that is less sensitive to illumination changes , so a normalized distance measure based on the inner product of two vectors is adopted </CITE> : </Eq> ( 8 ) where </Eq> , </Eq> and </Eq> are identified with each other if </Eq> .
With color and gradient features , we need a quantization measure that is less sensitive to illumination changes , so a normalized distance measure based on the inner product of two vectors is adopted </CITE> : </Eq> ( 8 ) where </Eq> , </Eq> and </Eq> are identified with each other if </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0
49:1			49:1			0		1.0
50:1			50:1			0		1.0
51:1			51:1			0		1.0
52:1			52:1			0		1.0
53:1			53:1			0		1.0

Alignment 2093
2 ) Feature selection for dynamic background pixels : as for a dynamic background object , its motion is usually in a small range ( so that it is still referred to background ) and has a period : waving tree branches and their shadows for example .
2 ) Feature selection for dynamic background pixels : as for a dynamic background object , its motion is usually in a small range ( so that it is still referred as a background ) and has a period, for example, waving tree branches and their shadows .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
32:1			36:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
39:1			45:1			0		1.0
41:1			39:1			0		1.0
42:1			40:1			0		1.0
43:1			41:1			0		1.0
44:1			42:1			0		1.0
45:1			43:1			0		1.0
46:1			44:1			0		1.0
47:1			47:1			0		1.0

Alignment 2094
Hence , the color co-occurrence feature is used to take advantage of these properties .
Hence , the color co-occurrence feature is used to take advantage of these properties .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 2095
Let </Eq> and </Eq> be the color features at time </Eq> and </Eq> at pixel </Eq> , then the color co-occurrence vector at time </Eq> and pixel </Eq> is
Let </Eq> and </Eq> be the color features at time </Eq> and </Eq> at pixel </Eq> , then the color co-occurrence vector at time </Eq> and pixel </Eq> is
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 2096
defined as </Eq> .
defined as </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0

Alignment 2097
In this case , another distance measure is used : </Eq> ( 9 )
In this case , another distance measure is used : </Eq> ( 9 )
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 2098
So far , we have already had a data structure for statistics , now for the procedure of feature learning .
So far , we have already had a data structure for statistics , now for the procedure of feature learning .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 2099
There are two kinds of background changes , so we will have different learning strategy for each one .
There are two kinds of background changes , so we will have different learning strategy for each one .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 2100
1 ) Gradual background changes : once we have the classification result at pixel </Eq> ( subsection D ) and time </Eq> , its statistics at the next time instant will be updated as follow : </Eq> ( 10 ) where </Eq> , </Eq> is the learning rate .
1 ) Gradual background changes : once we have the classification result at pixel </Eq> ( subsection D ) and time </Eq> , its statistics at the next time instant will be updated as follows : </Eq> ( 10 ) where </Eq> , </Eq> is the learning rate .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			1		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0

Alignment 2101
If </Eq> is classified as background point at time </Eq> , then </Eq> , else </Eq> .
If </Eq> is classified as background point at time </Eq> , then </Eq> , else </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 2102
If the input feature vector </Eq> is identified with </Eq> then </Eq> , otherwise , </Eq> .
If the input feature vector </Eq> is identified with </Eq> then </Eq> , otherwise , </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 2103
Besides , if there is no </Eq> in table </Eq> identified with </Eq> , the last component in </Eq> will be replaced by new one : </Eq> ( 11 )
Besides , if there is no </Eq> in table </Eq> identified with </Eq> , the last component in </Eq> will be replaced by new one : </Eq> ( 11 )
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0

Alignment 2104
2 ) " Once - off " background changes : an " once - off " background change occurs when there is a suddenly change in illumination , or a moving foreground object stopping and becoming a background instance , that means when background becomes foreground suddenly or vice versa .
2 ) " Once - off " background changes : an " once - off " background change occurs when there is a suddenly change in illumination , or when a moving foreground object stops and becomes a background instance, or when a background becomes a foreground suddenly .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			42:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			1		1.0
35:1			34:1			0		1.0
36:1			44:1			0		1.0
37:1			36:1			0		1.0
38:1			37:1			0		1.0
40:1			47:1			0		1.0
43:1			43:1			0		1.0
46:1			45:1			0		1.0
47:1			46:1			0		1.0
48:1			50:1			0		1.0

Alignment 2105
When this happens , we have : </Eq> ( 12 )
When this happens , we have : </Eq> ( 12 )
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 2106
Or </Eq> ( 13 ) where M is a high percentage threshold ( 80 % ~ 90 % ) .
Or </Eq> ( 13 ) where M is a high percentage threshold ( 80 % ~ 90 % ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 2107
Thus , ( 13 ) can be considered as a condition to check if an " once - off " background change is happening .
Thus , ( 13 ) can be considered as a condition to check if an " once - off " background change is happening .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 2108
In that case , the statistics of foreground should be turned to background statistics : </Eq> ( 14 ) for </Eq> .
In that case , the statistics of the foreground should be turned to background statistics : </Eq> ( 14 ) for </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0

Alignment 2109
This learning process is also proved that </Eq> will converge to 1 as long as the background features are observed frequently </CITE> .
This learning process is also proved that </Eq> will converge to 1 as long as the background features are observed frequently </CITE> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 2110
1 ) Change detection : In order to have a proper feature selection as mentioned in C , we need to know whether a pixel is static or dynamic .
1 ) Change detection : In order to have a proper feature selection as mentioned in C , we need to know whether a pixel is static or dynamic .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0

Alignment 2111
Therefore , color - based background differencing and interframe differencing methods are applied to detect changes .
Therefore , color - based background differencing and interframe differencing methods are applied to detect changes .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 2112
Background differencing calculates the difference between background </Eq> and input frame , while interframe differencing performs the same work on consecutive frames .
Background differencing calculates the difference between background </Eq> and input frame , while interframe differencing performs the same work on consecutive frames .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 2113
Let </Eq> and </Eq> be the background difference and interframe difference respectively .
Let </Eq> and </Eq> be the background difference and interframe difference respectively .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 2114
If </Eq> and </Eq> , pixel </Eq> is referred to nonchange background point .
If </Eq> and </Eq> , pixel </Eq> is referred to nonchange background point .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 2115
If </Eq> , </Eq> is classified as dynamic point , then color co - occurrence features are used for background / foreground classification , otherwise , </Eq> is a static point , so color and gradient features are used in the next step .
If </Eq> , </Eq> is classified as dynamic point , then color co - occurrence features are used for background / foreground classification , otherwise , </Eq> is a static point , so color and gradient features are used in the next step .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0

Alignment 2116
2 ) Background / Foreground classification : Let </Eq> be the input feature at pixel </Eq> and time </Eq> .
2 ) Background / Foreground classification : Let </Eq> be the input feature at pixel </Eq> and time </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 2117
The probabilities are estimated as follow : </Eq> ( 15 ) where </Eq> , </Eq> is the set of </Eq> that are identified with </Eq> : </Eq> ( 16 )
The probabilities are estimated as follow : </Eq> ( 15 ) where </Eq> , </Eq> is the set of </Eq> that are identified with </Eq> : </Eq> ( 16 )
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0

Alignment 2118
If there is no </Eq> identified with </Eq> , </Eq> and </Eq> .
If there is no </Eq> identified with </Eq> , </Eq> and </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 2119
As saying above , if </Eq> is a static pixel , we will have </Eq> and </Eq> , thus , </Eq> and </Eq> are used as their tables of statistics .
As saying above , if </Eq> is a static pixel , we will have </Eq> and </Eq> , thus , </Eq> and </Eq> are used as their tables of statistics .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0

Alignment 2120
After calculating the probabilities as ( 15 ) , ( 7 ) is used to classified </Eq> as background or foreground .
After calculating the probabilities as ( 15 ) , ( 7 ) is used to classified </Eq> as background or foreground .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 2121
Note that in this case : </Eq> .
Note that in this case : </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 2122
Similarly , if </Eq> is a dynamic pixel , </Eq> and ( 4 ) is used as the classification criterion .
Similarly , if </Eq> is a dynamic pixel , </Eq> and ( 4 ) is used as the classification criterion .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 2123
3 ) Foreground object segmentation : after finishing background / foreground classification for all pixels , an " oil spreading " algorithm is applied to find connected regions of foreground pixels .
3 ) Foreground object segmentation : after finishing the background / foreground classification for all pixels , an " oil spreading " algorithm is applied to find connected regions of foreground pixels .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0

Alignment 2124
Then some Heuristic technologies are used to separate objects sticking each other due to shades .
Then some Heuristic technologies are used to separate objects sticking to each other due to shades .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0

Alignment 2125
To make the background differencing in change detection step more accurate , the background image should be regularly updated .
To make the background differencing in the change detection step more accurate , the background image should be regularly updated .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0

Alignment 2126
Let </Eq> and </Eq> be the background and input frame at </Eq> and time </Eq> .
Let </Eq> and </Eq> be the background and input frame at </Eq> and time </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 2127
If </Eq> is referred to a nonchange background point , the background at </Eq> is updated as : </Eq> ( 17 ) where </Eq> .
If </Eq> is referred to a nonchange background point , the background at </Eq> is updated as : </Eq> ( 17 ) where </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 2128
Otherwise , if </Eq> classified as a background point ( static or dynamic ) , the background at </Eq> is replaced by the new one : </Eq> ( 18 )
Otherwise , if </Eq> classified as a background point ( static or dynamic ) , the background at </Eq> is replaced by the new one : </Eq> ( 18 )
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0

Alignment 2129
Figure 1 presents the complete algorithm of foreground object detection .
Figure 1 presents the complete algorithm of foreground object detection .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 2130
Let </Eq> be the number of objects at time </Eq> , and </Eq> be the number of measurements received .
Let </Eq> be the number of objects at time </Eq> , and </Eq> be the number of measurements received .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 2131
The set of objects and measurements at time t can be respectively denoted as : </Eq> ( 19 ) </Eq> ( 20 )
The set of objects and measurements at time t can be respectively denoted as : </Eq> ( 19 ) </Eq> ( 20 )
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 2132
Let </Eq> , </Eq> denote the joint association event between objects and measurements , where </Eq> is the particular event which assigns measurement </Eq> to object </Eq> .
Let </Eq> , </Eq> denote the joint association event between objects and measurements , where </Eq> is the particular event which assigns measurement </Eq> to object </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0

Alignment 2133
The joint association event probability is : </Eq> ( 21 ) where </Eq> is the sequence of measurements up to time </Eq> , </Eq> is the normalization constant .
The joint association event probability is : </Eq> ( 21 ) where </Eq> is the sequence of measurements up to time </Eq> , </Eq> is the normalization constant .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 2134
The first term </Eq> is the likelihood function of the measurements , given by : </Eq> ( 22 ) where </Eq> is the number of false alarms , </Eq> is the probability of number of false alarms , which is usually Poisson distributed , </Eq> is the likelihood that measurement </Eq> is originated from target </Eq> .
The first term </Eq> is the likelihood function of the measurements , given by : </Eq> ( 22 ) where </Eq> is the number of false alarms , </Eq> is the probability of number of false alarms , which is usually Poisson distributed , </Eq> is the likelihood that measurement </Eq> is originated from target </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0
49:1			49:1			0		1.0
50:1			50:1			0		1.0
51:1			51:1			0		1.0
52:1			52:1			0		1.0
53:1			53:1			0		1.0
54:1			54:1			0		1.0
55:1			55:1			0		1.0
56:1			56:1			0		1.0

Alignment 2135
The second term </Eq> is the prior probability of a joint association event , given by : </Eq> ( 23 ) where </Eq> is the probability of detection of an object with the assumption that target detection occurs independently over time with known probability .
The second term </Eq> is the prior probability of a joint association event , given by : </Eq> ( 23 ) where </Eq> is the probability of detection of an object with the assumption that target detection occurs independently over time with known probability .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0

Alignment 2136
Thus , the probability of a joint association event is : </Eq> ( 24 )
Thus , the probability of a joint association event is : </Eq> ( 24 )
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 2137
The state estimation of object </Eq> is : </Eq> ( 25 )
The state estimation of object </Eq> is : </Eq> ( 25 )
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 2138
Let the association probability for a particular association between measurement </Eq> and object </Eq> be defined by : </Eq> ( 26 )
Let the association probability for a particular association between measurement </Eq> and object </Eq> be defined by : </Eq> ( 26 )
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 2139
Hence , ( 25 ) becomes : </Eq> ( 27 ) where </Eq> is the state estimation from Kalman filter </CITE> with the assumption on association between measurement </Eq> and object </Eq> .
Hence , ( 25 ) becomes : </Eq> ( 27 ) where </Eq> is the state estimation from Kalman filter </CITE> with the assumption on association between measurement </Eq> and object </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0

Alignment 2140
Note that : </Eq> , and in fact , it is difficult to propose a model for exactly estimating </Eq> in ( 26 ) as the theory , so we want to normalize </Eq> so that </Eq> before using in ( 27 ) .
Note that : </Eq> , and in fact , it is difficult to propose a model for exactly estimating </Eq> in ( 26 ) as the theory , so we want to normalize </Eq> so that </Eq> before using in ( 27 ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0

Alignment 2141
Hence : </Eq> ( 28 ) and ( 27 ) becomes : </Eq> ( 29 )
Hence : </Eq> ( 28 ) and ( 27 ) becomes : </Eq> ( 29 )
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 2142
Figure 2 below is the complete algorithm of JPDAF at each time instant </Eq> .
Figure 2 below is the complete algorithm of JPDAF at each time instant </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 2143
Figure 3 is the experimental results of JPDAF performed on simulated data of 8 targets in 100 time steps .
Figure 3 is the experimental results of JPDAF performed on simulated data of 8 targets in 100 time steps .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 2144
The left one of each image pair is the simulated data and the right one is the estimated track of each target .
The left one of each image pair is the simulated data and the right one is the estimated track of each target .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 2145
Targets ’ positions are initialized in the area of [ 0 . . 500 ] x [ 0 . .50 ] , false alarms are taken randomly in the area of [ 0 . . 200 ] x [ 0 . .200 ] , </Eq> = 0 . 98 , </Eq> .
Targets ’ positions are initialized in the area of [ 0 . . 500 ] x [ 0 . .50 ] , false alarms are taken randomly in the area of [ 0 . . 200 ] x [ 0 . .200 ] , </Eq> = 0 . 98 , </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0
49:1			49:1			0		1.0
50:1			50:1			0		1.0
51:1			51:1			0		1.0

Alignment 2146
Statistical background model is applied to detect moving objects in the motorcycle lane with the parameters in Table 1 .
Statistical background model is applied to detect moving objects in the motorcycle lane with the parameters in Table 1 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 2147
The color and gradient vectors are obtained by quantizing their domains to 256 resolution levels , while for color cooccurrence vectors , the number of quantized levels is 32 , </Eq> = 0 . 005 is used for the distance measure in ( 8 ) while </Eq> = 2 is used for ( 9 ) .
The color and gradient vectors are obtained by quantizing their domains to 256 resolution levels , while for color cooccurrence vectors , the number of quantized levels is 32 , </Eq> = 0 . 005 is used for the distance measure in ( 8 ) while </Eq> = 2 is used for ( 9 ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0
49:1			49:1			0		1.0
50:1			50:1			0		1.0
51:1			51:1			0		1.0
52:1			52:1			0		1.0
53:1			53:1			0		1.0
54:1			54:1			0		1.0
55:1			55:1			0		1.0

Alignment 2148
Using the measurements achieved from detection stage , JPDAF performs data association between the current measurements and targets .
Using the measurements achieved from the detection stage , JPDAF performs data association between the current measurements and targets .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0

Alignment 2149
At each time </Eq> , basing on the accuracy of detection results , we can propose a strategy to detect new objects entering the observation area .
At each time </Eq> , based on the accuracy of detection results , we can propose a strategy to detect new objects entering the observation area .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			1		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 2150
If : </Eq> so that </Eq> ( 30 ) where </Eq> and </Eq> are respectively the Decartes coordinates of object </Eq> at time </Eq> and measurement </Eq> at time </Eq> is a small positive number .
If : </Eq> so that </Eq> ( 30 ) where </Eq> and </Eq> are respectively the Decartes coordinates of object </Eq> at time </Eq> and measurement </Eq> at time </Eq> is a small positive number .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0

Alignment 2151
Then </Eq> is considered as a measurement originated from a new object .
Then </Eq> is considered as a measurement originated from a new object .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 2152
That means if a measurement is not " too close " with any target at the last time instant , it is implied that a new target has occurred .
That means if a measurement is not " too close " with any target at the last time instant , it is implied that a new target has occurred .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0

Alignment 2153
Besides , if an object is at the end of the observation area and it is not a new object or it is misdetected more than 3 time instant , it will be removed .
Besides , if an object is at the end of the observation area and it is not a new object or it is misdetected more than 3 time instant , it will be removed .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0

Alignment 2154
To increase the accuracy of JPDAF , beside the spatial distance , the information of color histogram should be incorporated into the likelihood </Eq> in ( 22 ) .
To increase the accuracy of JPDAF , beside the spatial distance , the information of color histogram should be incorporated into the likelihood </Eq> in ( 22 ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 2155
Hence , Bhattachayya distance is employed to calculate the " distance " between the reference color model </Eq> and the candidate color model </Eq> of each target , ( details in </CITE> ) : </Eq> ( 31 ) where reference color model of a target is chosen as its last state and the candidate color model is its current measurement .
Hence , Bhattachayya distance is employed to calculate the " distance " between the reference color model </Eq> and the candidate color model </Eq> of each target , ( details in </CITE> ) : </Eq> ( 31 ) where reference color model of a target is chosen as its last state and the candidate color model is its current measurement .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0
49:1			49:1			0		1.0
50:1			50:1			0		1.0
51:1			51:1			0		1.0
52:1			52:1			0		1.0
53:1			53:1			0		1.0
54:1			54:1			0		1.0
55:1			55:1			0		1.0
56:1			56:1			0		1.0
57:1			57:1			0		1.0
58:1			58:1			0		1.0
59:1			59:1			0		1.0
60:1			60:1			0		1.0

Alignment 2156
Moreover , for increasing the accuracy , the reference and candidate model are divided into two sub - regions ( Figure 4 ) , then the color likelihood of a candidate model is produced : </Eq> ( 32 )
Moreover , for increasing the accuracy , the reference and candidate model are divided into two sub - regions ( Figure 4 ) , then the color likelihood of a candidate model is produced : </Eq> ( 32 )
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0

Alignment 2157
Let </Eq> be the spatial distance likelihood </Eq> which attained by Kalman filter between measurement </Eq> and target </Eq> </CITE> , then the likelihood </Eq> in ( 24 ) is defined as : </Eq> ( 33 ) where </Eq> because spatial distance information has a higher priority than color in this context .
Let </Eq> be the spatial distance likelihood </Eq> which attained by Kalman filter between measurement </Eq> and target </Eq> </CITE> , then the likelihood </Eq> in ( 24 ) is defined as : </Eq> ( 33 ) where </Eq> because spatial distance information has a higher priority than color in this context .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0
49:1			49:1			0		1.0
50:1			50:1			0		1.0
51:1			51:1			0		1.0
52:1			52:1			0		1.0

Alignment 2158
In our application , we chose </Eq> .
In our application , we chose </Eq> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 2159
The below is some results of object detection ( Figure 5 ( a ) ) , the left image of each pair is the input frame and the right one is the detection result .
The below is some results of object detection ( Figure 5 ( a ) ) . The left image of each pair is the input frame and the right one is the detection result .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			34:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0

Alignment 2160
The experimental sequences are taken from the motorcycle lane in a cloudy weather and the illumination changes are easily seen , but the detection algorithm still works very well .
The experimental sequences are taken from the motorcycle lane in a cloudy weather and the illumination changes are easily seen , but the detection algorithm still works very well .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0

Alignment 2161
The background is learned rapidly , figure 5 ( b ) is a learned background after 60 frames , together with the statistics of background features , the results of background / foreground classification step is very accurate , there are almost no misclassified background point .
The background is learned rapidly . Figure 5 ( b ) is a learned background after 60 frames . Together with the statistics of background features , the results of background / foreground classification step is very accurate , and there are almost no misclassified background point .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			46:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
40:1			39:1			0		1.0
41:1			40:1			0		1.0
42:1			41:1			0		1.0
43:1			42:1			0		1.0
44:1			43:1			0		1.0
45:1			44:1			0		1.0
46:1			45:1			0		1.0

Alignment 2162
But the difficulty is in the segmentation step , when the object density at the end of the observation area is high , many occlusions usually occurs and the segmentation step will usually make mistakes ( Figure 6 ) .
But the difficulty is in the segmentation step , when the object density at the end of the observation area is high , many occlusions usually occurs and the segmentation step will usually make mistakes ( Figure 6 ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0

Alignment 2163
Figure 5 ( c ) is an example of " once - off " background change , there was a motorbike stopping close to the pavement for a while and it became background soon after that .
Figure 5 ( c ) is an example of " once - off " background change during which there was a motorbike stopping close to the pavement for a while and it became background soon after that .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
37:1			36:1			0		1.0

Alignment 2164
Table II is the quantitative results of object detection .
Table II is the quantitative results of object detection .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 2165
The system was tested on ten sequences which has the object density < 10 objects / frame , each sequence has an average length of 10 seconds and uses the first 30 frames ( 1 second ) for initial background learning ( " + 30 " in Length column ) .
The system was tested on ten sequences which has the object density < 10 objects / frame , each sequence has an average length of 10 seconds and uses the first 30 frames ( 1 second ) for initial background learning ( " + 30 " in Length column ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0
49:1			49:1			0		1.0
50:1			50:1			0		1.0

Alignment 2166
The precision rate = 100 % demonstrated that there is no background object which is classified as foreground , and the mistake percentages in the recall rate is caused by the incorrect segmentation .
The precision rate = 100 % demonstrated that there is no background object which is classified as foreground , and the mistake percentages in the recall rate is caused by the incorrect segmentation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0

Alignment 2167
The results of JPDAF depends on the object detection results , if objects are correctly detected , the tracking algorithm will works very well .
The results of JPDAF depends on the object detection results : if objects are correctly detected , the tracking algorithm will works very well .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 2168
In general , this system works well with a reasonable number of targets / frame ( < 10 targets / frame) .
In general , this system works well with a reasonable number of targets / frame ( < 10 targets / frame) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 2169
With the strategy for detecting objects entering and exiting the observation area , the JPDAF can also detect and track the motorcycles driven in wrong direction .
With the strategy for detecting objects entering and exiting the observation area , the JPDAF can also detect and track the motorcycles driven in wrong direction .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 2170
Figure 7 shows some tracking results , including of the tracking of wrong - wayed motorcycle ( Figure 7 ( d ) , object 10 ) .
Figure 7 shows some tracking results , including of the tracking of wrong - wayed motorcycle ( Figure 7 ( d ) , object 10 ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 2171
Table III shows the statistics of full correct tracks in the ten sequences above ( the mis - tracked objects in any frame are not counted) .
Table III shows the statistics of full correct tracks in the ten sequences above ( the mis - tracked objects in any frame are not counted) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 2172
Since JPDAF is an NP-hard problem ( the number of possible joint association events at each time instant </Eq> is </Eq> , the computation cost of JPDAF is one of its major weak points .
Since JPDAF is an NP-hard problem ( the number of possible joint association events at each time instant </Eq> is </Eq> , the computation cost of JPDAF is one of its major weak points .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0

Alignment 2173
All of these experiments are deployed on a Pentium IV 2 . 4 Ghz , 512 MB RAM , due to the high cost of object detection and tracking algorithm , the processing rate is 2s / frame with the frame size is 360 x 240 and the sequence rate is 30 frames / s .
All of these experiments are deployed on a Pentium IV 2 . 4 Ghz , 512 MB RAM , and due to the high cost of object detection and tracking algorithm , the processing rate is 2s / frame with the frame size is 360 x 240 and the sequence rate is 30 frames / s .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			46:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
37:1			36:1			0		1.0
38:1			37:1			0		1.0
39:1			38:1			0		1.0
40:1			39:1			0		1.0
41:1			40:1			0		1.0
42:1			41:1			0		1.0
43:1			42:1			0		1.0
44:1			43:1			0		1.0
45:1			44:1			0		1.0
46:1			45:1			0		1.0
48:1			47:1			0		1.0
49:1			48:1			0		1.0
50:1			49:1			0		1.0
51:1			50:1			0		1.0
52:1			51:1			0		1.0
53:1			52:1			0		1.0
54:1			53:1			0		1.0
55:1			54:1			0		1.0
56:1			55:1			0		1.0

Alignment 2174
This paper is a next step on the way searching an efficient approach for a motorcycle surveillance system after using Particle filter in </CITE> .
This paper is a next step on the way searching an efficient approach for a motorcycle surveillance system after using Particle filter in </CITE> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 2175
Some improvements have been achieved in object detection step which has more accurate results in the whole observation area and the ability to efficiently adapt to illumination changes and " once - off " changes .
Some improvements have been achieved in object detection step which has more accurate results in the whole observation area and the ability to efficiently adapt to illumination changes and " once - off " changes .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0

Alignment 2176
However , occlusions have not been strictly handled and the computation cost is one of the major limitations .
However , occlusions have not been strictly handled and the computation cost is one of the major limitations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 2177
In the future , we hope thatmany new multi - target tracking methods will be applied in this context and the best selection will be produced .
In the future , we hope thatmany new multi - target tracking methods will be applied in this context, and the best selection will be produced .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 2178
Comparing Diﬀerent Criteria for Vietnamese Word Segmentation
Comparing Diﬀerent Criteria for Vietnamese Word Segmentation
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0

Alignment 2179
The success of corpus based methods has made syntactically annotated corpora important resources for natural language processing .
Syntactically annotated corpora have become important resources for natural language processing , due in part to the success of corpus-based methods .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			9:1			0		1.0
2:1			10:1			0		1.0
3:2			6:1			3		1.0
5:1			11:1			0		1.0
6:1			12:1			0		1.0
7:1			13:1			0		1.0
8:1			14:1			0		1.0
9:1			15:1			0		1.0
10:1			16:1			0		1.0
17:1			1:1			0		1.0
18:1			2:1			0		1.0
20:1			5:1			0		1.0
21:1			17:1			0		1.0

Alignment 2180
Since words are often considered as the primitive units of language structures , the annotation of word segmentation forms the basis of these corpora .
Since words are often considered as primitive units of language structures , the annotation of word segmentation forms the basis of these corpora .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0

Alignment 2181
This is also a concern of Vietnamese Treebank ( VTB ) , the first and the only publicly available syntactically annotated corpus so far for the Vietnamese language .
This is also a concern for the Vietnamese Treebank ( VTB ) , which is the first and only publicly available syntactically annotated corpus thus far for the Vietnamese language .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			24:1			0		1.0
6:1			15:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:2			22:2			3		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0

Alignment 2182
Although word segmentation is straight-forward for space-delimited languages like English , this is not true for languages like Vietnamese of which no standard criterion for word segmentation exists .
Although word segmentation is straight-forward for space-delimited languages like English , this is not the case for languages like Vietnamese for which a standard criterion for word segmentation does not exist .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:2			14:1			3		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:2			19:2			3		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
30:1			27:1			1		1.0
31:1			28:1			0		1.0

Alignment 2183
This work explores the challenges of Vietnamese word segmentation through the detection and correction of inconsistency for VTB .
This work explores the challenges of Vietnamese word segmentation through the detection and correction of inconsistency for VTB .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 2184
Then , by combining and splitting the inconsistent annotations detected , we could observe the influence of different word segmentation criteria on automatic word segmentation , and the applications of word segmentation , including text classification and English-Vietnamese statistical machine translation .
Then , by combining and splitting the inconsistent annotations that were detected , we are able to observe the influence of different word segmentation criteria on automatic word segmentation , and the applications of word segmentation , including text classification and English-Vietnamese statistical machine translation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:3			12:1			3		1.0
17:1			13:1			0		1.0
18:1			14:1			0		1.0
19:1			15:1			0		1.0
20:1			16:1			0		1.0
21:1			17:1			0		1.0
22:1			18:1			0		1.0
23:1			19:1			0		1.0
24:1			20:1			0		1.0
25:1			21:1			0		1.0
26:1			22:1			0		1.0
27:1			23:1			0		1.0
28:1			24:1			0		1.0
29:1			25:1			0		1.0
30:1			26:1			0		1.0
31:1			27:1			0		1.0
32:1			28:1			0		1.0
33:1			29:1			0		1.0
34:1			30:1			0		1.0
35:1			31:1			0		1.0
36:1			32:1			0		1.0
37:1			33:1			0		1.0
38:1			34:1			0		1.0
39:1			35:1			0		1.0
40:1			36:1			0		1.0
41:1			37:1			0		1.0
42:1			38:1			0		1.0
43:1			39:1			0		1.0
44:1			40:1			0		1.0
45:1			41:1			0		1.0

Alignment 2185
The analysis and experimental results showed that our methods improved the quality of VTB , which positively affected the performance of its applications .
The analysis and experimental results showed that our methods improved the quality of VTB , which positively affected the performance of its applications .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 2186
Treebanks , corpora annotated with syntactic structures , have become more and more important for language processing .
Treebanks , which are corpora annotated with syntactic structures , have become more and more important for language processing .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
4:1			2:1			0		1.0
5:1			3:1			0		1.0
6:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0

Alignment 2187
To strengthen the automatic processing of the Vietnamese language , the Vietnamese treebank ( VTB ) has been built as a part of the national project , " Vietnamese language and speech processing ( VLSP ) " ( Nguyen et al. , 2009b ) .
In order to strengthen the automatic processing of the Vietnamese language , the Vietnamese Treebank ( VTB ) has been built as a part of the national project , " Vietnamese language and speech processing ( VLSP ) " ( Nguyen et al. , 2009b ) .
Line2Start:Length	Line1Start:Length	Module		Score
3:1			1:1			0		1.0
4:1			2:1			0		1.0
5:1			3:1			0		1.0
6:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
33:1			31:1			0		1.0
34:1			32:1			0		1.0
35:1			33:1			0		1.0
36:1			34:1			0		1.0
37:1			35:1			0		1.0
38:1			36:1			0		1.0
39:1			37:1			0		1.0
40:1			38:1			0		1.0
41:1			39:1			0		1.0
42:1			40:1			0		1.0
43:1			41:1			0		1.0
44:1			42:1			0		1.0
45:1			43:1			0		1.0
46:1			44:1			0		1.0

Alignment 2188
However , in our preliminary experiment with VTB , when we trained the Berkeley parser ( Petrov et al. , 2006 ) and evaluated it using the corpus , the parser achieved only 65.8% in F-score .
However , in our preliminary experiment with VTB , when we trained the Berkeley parser ( Petrov et al. , 2006 ) and evaluated it by using the corpus , the parser achieved only 65.8% in F-score .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
37:1			36:1			0		1.0

Alignment 2189
This performance is far lower than the state-of-the-art performance reported for Berkeley Parser on English Penn Treebank , 90.3% in F-score ( Petrov et al. , 2006 ) .
This score is far lower than the state-of-the-art performance reported for the Berkeley Parser on the English Penn Treebank , which reported 90.3% in F-score ( Petrov et al. , 2006 ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
22:1			18:1			0		1.0
23:1			19:1			0		1.0
24:1			20:1			0		1.0
25:1			21:1			0		1.0
26:1			22:1			0		1.0
27:1			23:1			0		1.0
28:1			24:1			0		1.0
29:1			25:1			0		1.0
30:1			26:1			0		1.0
31:1			27:1			0		1.0
32:1			28:1			0		1.0

Alignment 2190
There are two possible reasons for this .
There are two possible reasons to explain this outcome .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:2			4:2			3		1.0
7:1			6:1			0		1.0
9:1			7:1			0		1.0

Alignment 2191
First , the quality of VTB is not good enough to build a good a parser , including the quality of the annotation scheme , the annotation guidelines , and the annotation process .
One reason for this outcome is the quality of VTB , including the quality of the annotation scheme , the annotation guidelines , and the annotation process .
Line2Start:Length	Line1Start:Length	Module		Score
5:1			6:1			0		1.0
6:1			2:1			0		1.0
7:1			3:1			0		1.0
8:1			4:1			0		1.0
9:1			5:1			0		1.0
10:1			16:1			0		1.0
11:1			17:1			0		1.0
12:1			18:1			0		1.0
13:1			19:1			0		1.0
14:1			20:1			0		1.0
15:1			21:1			0		1.0
16:1			22:1			0		1.0
17:1			23:1			0		1.0
18:1			24:1			0		1.0
19:1			25:1			0		1.0
20:1			26:1			0		1.0
21:1			27:1			0		1.0
22:1			28:1			0		1.0
23:1			29:1			0		1.0
24:1			30:1			0		1.0
25:1			31:1			0		1.0
26:1			32:1			0		1.0
27:1			33:1			0		1.0

Alignment 2192
Second , parsing Vietnamese is a difficult problem by its own ; and we need to seek new solutions to the problem .
The second reason is the difficulty of parsing Vietnamese; we need to seek new solutions to address this problem .
Line2Start:Length	Line1Start:Length	Module		Score
3:1			4:1			0		1.0
4:1			20:1			0		1.0
5:2			7:1			3		1.0
7:1			2:1			0		1.0
9:1			13:1			0		1.0
10:1			14:1			0		1.0
11:1			15:1			0		1.0
12:1			16:1			0		1.0
13:1			17:1			0		1.0
14:1			18:1			0		1.0
15:1			19:1			0		1.0
18:1			21:1			0		1.0
19:1			22:1			0		1.0

Alignment 2193
VTB is annotated with three layers : word segmentation , POS tagging , and bracketing .
VTB is annotated with three layers : word segmentation , POS tagging , and bracketing .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 2194
This paper focuses on the word segmentation issues since the most basic unit of a Treebank is word ( Di Sciullo and Edwin , 1987 ) , and defining “ What are words ? “ is the first problem that a treebank has to solve ( Xia , 2000b ,a; Sornlertlamvanich et al. , 1997 , 1999 ) .
This paper focuses on the word segmentation , since the most basic unit of a treebank are words ( Di Sciullo and Edwin , 1987 ) , and defining " words " is the first step ( Xia , 2000b ,a; Sornlertlamvanich et al. , 1997 , 1999 ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			55:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			41:1			0		1.0
16:1			31:1			0		1.0
17:1			32:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
32:1			35:1			0		1.0
33:1			36:1			0		1.0
34:1			37:1			0		1.0
36:1			45:1			0		1.0
37:1			46:1			0		1.0
38:1			47:1			0		1.0
39:1			48:1			0		1.0
40:1			49:1			0		1.0
41:1			50:1			0		1.0
42:1			51:1			0		1.0
43:1			52:1			0		1.0
44:1			53:1			0		1.0
45:1			54:1			0		1.0
47:1			56:1			0		1.0
48:1			57:1			0		1.0
49:1			58:1			0		1.0

Alignment 2195
For languages like English , answering this question is almost trivial , because the blank spaces denote word delimiters .
For languages like English , defining " words " is almost trivial , because the blank spaces denote word delimiters .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0

Alignment 2196
However , for an isolating language like Vietnamese , where blank spaces play a role of syllable delimiters , " What are words? " is not a trivial question .
However , for an isolating language like Vietnamese , for which blank spaces play a role of syllable delimiters , " What are words? " is not a trivial question .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:2			9:1			3		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0

Alignment 2197
For example , the sentence " Học sinh học sinh học ( students learn biology ) </CITE> " is composed of three words , " học sinh ( student ) " , " học ( learn ) , " and " sinh học ( biology ) " .
For example , the sentence " Học sinh học sinh học ( students learn biology ) </CITE> " is composed of three words , " học sinh ( student ) " , " học ( learn ) , " and " sinh học ( biology ) " .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0

Alignment 2198
Word segmentation is expected to break down the sentence at the boundaries of these words , not to split " học sinh ( student ) " and " sinh học ( biology ) . "
Word segmentation is expected to break down the sentence at the boundaries of these words , instead of splitting " học sinh ( student ) " and " sinh học ( biology ) . "
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			3		1.0
17:2			17:2			3		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0

Alignment 2199
Note that the terminology " word segmentation " also refers to the task of extracting words statistically without concerning a gold-standard for segmentation , as in ( Ha , 2003; Le et al. , 2010 ) .
Note that the terminology " word segmentation " also refers to the task of extracting words statistically without concerning a gold-standard for segmentation , as in ( Ha , 2003; Le et al. , 2010 ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0

Alignment 2200
In such context , the extracted words are more appropriate for building a dictionary than for corpus-based language processing , which are out of the focus of this paper .
In such a context , the extracted words are more appropriate for building a dictionary , rather than for corpus-based language processing , which are outside of the scope of this paper .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			19:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0
25:2			22:2			3		1.0
27:1			24:1			0		1.0
29:1			26:1			0		1.0
30:1			27:1			0		1.0
31:1			28:1			0		1.0
32:1			29:1			0		1.0

Alignment 2201
Establishing a gold standard for Vietnamese word segmentation faces some difficulties coming from the characteristics of the language .
Because of the discussed characteristics of the language , there are challenges in establishing a gold standard for Vietnamese word segmentation .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			13:1			0		1.0
4:1			14:1			0		1.0
5:1			15:1			0		1.0
6:1			16:1			0		1.0
7:1			17:1			0		1.0
14:1			1:1			0		1.0
15:1			2:1			0		1.0
16:1			3:1			0		1.0
17:1			4:1			0		1.0
18:1			5:1			0		1.0
19:1			6:1			0		1.0
20:1			7:1			0		1.0
21:1			18:1			0		1.0

Alignment 2202
The difficulties of Vietnamese word segmentation have been recognized by many researchers ( Ha , 2003; Nguyen et al. , 2004 , 2006; Le et al. , 2010 ) .
The difficulties in Vietnamese word segmentation have been recognized by many researchers ( Ha , 2003; Nguyen et al. , 2004 , 2006; Le et al. , 2010 ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:2			1:2			3		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0

Alignment 2203
Although most people agree that the Vietnamese language has two types of words : single and compound , there is little consensus on how to segment a sentence into words .
Although most people agree that the Vietnamese language has two types of words : single and compound , there is little consensus as to the methodology for segmenting a sentence into words .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
23:1			24:1			0		1.0
27:1			25:1			1		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0

Alignment 2204
The disagreement is not only because of the different functions of blank spaces as mentioned above but also because Vietnamese is not an inflectional language like English or Japanese where morphological forms can be useful clues for word segmentation .
The disagreement occurs not only because of the different functions of blank spaces ( as mentioned above ) , but also because Vietnamese is not an inflectional language , as is the case for English or Japanese , for which morphological forms can provide useful clues for word segmentation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			3		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0
26:1			23:1			0		1.0
27:1			24:1			0		1.0
29:4			25:1			3		1.0
33:1			36:1			0		1.0
34:1			26:1			0		1.0
35:1			27:1			0		1.0
36:1			28:1			0		1.0
38:2			29:1			3		1.0
40:1			30:1			0		1.0
41:1			31:1			0		1.0
42:1			32:1			0		1.0
44:1			34:1			0		1.0
45:1			35:1			0		1.0
47:1			37:1			0		1.0
48:1			38:1			0		1.0
49:1			39:1			0		1.0

Alignment 2205
While the similar problems also happen with Chinese word segmentation ( Xia , 2000b ) , Vietnamese word segmentation may be more difficult because the modern Vietnamese writing system is based on Latin characters , which represents the pronunciation , but not the meaning of words .
While similar problems also occur with Chinese word segmentation ( Xia , 2000b ) , Vietnamese word segmentation may be more difficult , because the modern Vietnamese writing system is based on Latin characters , which represent the pronunciation , but not the meaning of words .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			2		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			39:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:2			36:2			3		1.0
38:1			38:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0

Alignment 2206
All these characteristics make it diﬃcult to perform word segmentation for Vietnamese both manually and automatically , and have resulted in different criteria for word segmenation .
All of these characteristics make it diﬃcult to perform word segmentation for Vietnamese , both manually and automatically , and have thus resulted in different criteria for word segmentation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
22:1			19:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0
26:1			23:1			0		1.0
27:1			24:1			0		1.0
29:1			26:1			0		1.0

Alignment 2207
However , so far , there have been few studies on the challenges in word segmentation , and the comparison of different word segmentation criteria .
However , so far , there have been few studies on the challenges in word segmentation , and the comparison of different word segmentation criteria .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 2208
In this paper , a brief introduction of the Vietnamese treebank VTB and its annotation scheme are given in Section 2 .
In this paper , a brief introduction of the Vietnamese Treebank VTB and its annotation scheme are provided in Section 2 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 2209
Then , we described our methods for the detection and correction of the problematic annotations in the VTB corpus ( Section 4.2 ) .
Then , we described our methods for the detection and correction of the problematic annotations in the VTB corpus ( Section 4.2 ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 2210
We classified the problematic annotations into several patterns of inconsistency , part of which were manually fixed to improve the quality of the corpus .
We classified the problematic annotations into several patterns of inconsistency , part of which were manually fixed to improve the quality of the corpus .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 2211
The rest , which can be considered as the most difficult and controversial casess of word segmentation , were used to create different versions of the VTB corpus , representing different word segmentation criteria .
The rest , which can be considered as the most difficult and controversial instances of word segmentation , were used to create different versions of the VTB corpus , representing different word segmentation criteria .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0

Alignment 2212
Finally , we evaluated these criteria in automatic word segmentation , and its application in text classification and English-Vietnamese statistical machine translation , in Section 4 .
Finally , we evaluated these criteria in automatic word segmentation , and its application in text classification and English-Vietnamese statistical machine translation , in Section 4 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 2213
This study is not only beneficial for the development of computational processing technologies for Vietnamese , a language spoken by over 90 million people , but also for the similar languages such as Thai , Laos , and so on .
This study is not only beneficial for the development of computational processing technologies for Vietnamese , a language spoken by over 90 million people , but also for similar languages such as Thai , Laos , and so on .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0
31:1			32:1			0		1.0
32:1			33:1			0		1.0
33:1			34:1			0		1.0
34:1			35:1			0		1.0
35:1			36:1			0		1.0
36:1			37:1			0		1.0
37:1			38:1			0		1.0
38:1			39:1			0		1.0
39:1			40:1			0		1.0

Alignment 2214
This study also promotes the computational linguistic studies on how to transfer methods developed for a popular language , like English , to a language that has not yet intensively studied .
This study also promotes the computational linguistic studies on how to transfer methods developed for a popular language , like English , to a language that has not yet been intensively studied .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0

Alignment 2215
Word segmentation in VTB aims to found a standard for word segmentation in a context of multi-level language processing .
Word segmentation in VTB aims at establishing a standard for word segmentation in a context of multi-level language processing .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:2			4:2			3		1.0
6:1			6:1			2		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 2216
VTB specifies 12 types of units that should be identified as words ( Table 1 ) ( Nguyen et al. , a ) , which can be divided into three groups : single , compound , and special " words . "
VTB specifies 12 types of units that should be identified as words ( Table 1 ) ( Nguyen et al. , a ) , which can be divided up into three groups : single , compound , and special " words . "
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
37:1			36:1			0		1.0
38:1			37:1			0		1.0
39:1			38:1			0		1.0
40:1			39:1			0		1.0
41:1			40:1			0		1.0
42:1			41:1			0		1.0

Alignment 2217
Single words contain only one token .
Single words contain only one token .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0

Alignment 2218
The terminology tokens refers to text spans separated with each other by blank spaces .
The terminology tokens refers to text spans that are separated from each other by blank spaces .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
9:1			7:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0

Alignment 2219
Compound words have two or more tokens , and are divided into four types : compound words composed by semantic coordination ( semantic-coordinated compound ) , compound words composed by semantic subordination ( semantic-subordinated compound ) , compound words with aﬃx , and reduplicated words .
Compound words have two or more tokens , and are divided into four types : compound words composed by semantic coordination ( semantic-coordinated compound ) , compound words composed by semantic subordination ( semantic-subordinated compound ) , compound words with an aﬃx , and reduplicated words .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
41:1			40:1			0		1.0
42:1			41:1			0		1.0
43:1			42:1			0		1.0
44:1			43:1			0		1.0
45:1			44:1			0		1.0
46:1			45:1			0		1.0

Alignment 2220
Special " words " can be idioms , locutions , proper names , date times , numbers , symbols , sentence marks , foreign words , or abbreviations .
Special " words " include idioms , locutions , proper names , date times , numbers , symbols , sentence marks , foreign words , or abbreviations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0

Alignment 2221
The segmentation of these types of words forms a basis for the POS tagging , with 18 different POS tags shown in Table 2 ( Nguyen et al. , c ) .
The segmentation of these types of words forms a basis for the POS tagging , with 18 different POS tags , as shown in Table 2 ( Nguyen et al. , c ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
33:1			31:1			0		1.0

Alignment 2222
Each unit in Table 1 goes with several example words of which English translations are given in parentheses .
Each unit in Table 1 goes with several example words; English translations are provided in parentheses .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0

Alignment 2223
Besides , we added a translation for each token , when possible , so that the readers unfamiliar with Vietnamese can have an intuitive idea of how the compound words are formed .
Furthermore , we added a translation for each token , where possible , so that readers who are unfamiliar with Vietnamese can have an intuitive idea as to how the compound words are formed .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:2			10:2			3		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			16:1			0		1.0
17:1			30:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:3			25:2			3		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
33:1			31:1			0		1.0
34:1			32:1			0		1.0

Alignment 2224
The subscript of a token translation is the index of that token in the compound word .
The subscript of a token translation is the index of that token in the compound word .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 2225
However , for some tokens , we could not find any appropriate English translation , so we give it an empty translation , marked with an asterisk .
However , for some tokens , we could not find any appropriate English translation , so we gave it an empty translation , marked with an asterisk .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			2		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0

Alignment 2226
Note that a Vietnamese word or a token in context can have other meanings , in addition to the given translations .
Note that a Vietnamese word or a token in context can have other meanings , in addition to the given translations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 2227
A special type of words in Vietnamese is noun , denoted by the part-of-speech Nc in Table 2 .
A classifier noun , denoted by the part-of-speech Nc in Table 2 , is a special type of word in Vietnamese .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			8:1			0		1.0
3:1			9:1			0		1.0
4:1			10:1			0		1.0
5:1			11:1			0		1.0
6:1			12:1			0		1.0
7:1			13:1			0		1.0
8:1			14:1			0		1.0
9:1			15:1			0		1.0
10:1			16:1			0		1.0
11:1			17:1			0		1.0
13:1			7:1			0		1.0
15:1			1:1			0		1.0
16:1			2:1			0		1.0
17:1			3:1			0		1.0
18:1			4:1			1		1.0
19:1			5:1			0		1.0
20:1			6:1			0		1.0
21:1			18:1			0		1.0

Alignment 2228
Classifier nouns are specific to several Southeast Asian languages , like Vietnamese and Thai .
Classifier nouns are specific to several Southeast Asian languages , like Vietnamese and Thai .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 2229
One of the functions of classifier nouns is to express the definiteness .
One of the functions of classifier nouns is to express the definiteness .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 2230
For example , the common noun " bàn " means tables in general , while " cái bàn " means a specific table , similar to the table in English .
For example , the common noun " bàn " generally means tables , while " cái bàn " means a specific table , similar to the table in English .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			11:2			3		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0

Alignment 2231
In this section , we analyzed the VTB corpus to know whether the difficulties in Vietnamese word segmentation a ff ected the quality of VTB annotations .
In this section , we analyzed the VTB corpus to determine whether the difficulties in Vietnamese word segmentation affected the quality of VTB annotations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0
24:1			26:1			0		1.0

Alignment 2232
The analysis results revealed several types of inconsistent annotations , which are also the most problematic cases of Vietnamese word segmentation .
The analysis revealed several types of inconsistent annotations , which are also problematic for Vietnamese word segmentation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			15:1			0		1.0
14:1			18:1			0		1.0
15:1			19:1			0		1.0
16:1			20:1			0		1.0
17:1			21:1			0		1.0

Alignment 2233
Our analysis is based on two types of inconsistency : variation and structural inconsistency , whose definitions and details are given below .
Our analysis is based on two types of inconsistencies : variation and structural inconsistency , which are defined below .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			1		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			3		1.0
16:1			19:1			0		1.0
17:1			16:1			3		1.0
18:1			21:1			0		1.0
19:1			22:1			0		1.0

Alignment 2234
Variation inconsistency : is a sequence of tokens , which has more than one way of segmentation in the corpus .
Variation inconsistency : is a sequence of tokens , which has more than one way of segmentation in the corpus .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 2235
For example , " con gái/girl " can remain as one word , or be segmented into two words , " con " and " gái " .
For example , " con gái/girl " can remain as one word , or be segmented into two words , " con " and " gái " .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0

Alignment 2236
A variation can be an annotation inconsistency , or an ambiguity in Vietnamese .
A variation can be an annotation inconsistency , or an ambiguity in Vietnamese .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 2237
While ambiguity cases reflect the difficulty of the language , annotation inconsistencies are usually caused by the confusion in the decision of annotators , which should be eliminated in annotation .
While ambiguity cases reflect the difficulty of the language , annotation inconsistencies are usually caused by the confusion in the decision of annotators , which should be eliminated in annotation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0

Alignment 2238
We use the term variation instance to refer a single occurrence of a variation .
We use the term variation instance to refer to a single occurrence of a variation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0

Alignment 2239
Structural inconsistency : happens when di ff erent sequences have similar structures , thus should be splitted in the same way , but are segmented in different ways in the corpus .
Structural inconsistency : happens when different sequences have similar structures , and thus should be split in the same way , but are segmented in different ways in the corpus .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			1		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0

Alignment 2240
For example , " con gái/girl " and " con trai/boy " have similar structures : a combination of a classifier noun and a common noun , Nc + N , so when " con gái/girl " is splitted , and " con trai/boy " is not , it is considered as a structural inconsistency of Nc .
For example , " con gái/girl " and " con trai/boy " have similar structures : a combination of a classifier noun and a common noun , Nc + N , so when " con gái/girl " is split , and " con trai/boy " is not , it is considered as a structural inconsistency of Nc .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			1		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0
49:1			49:1			0		1.0
50:1			50:1			0		1.0
51:1			51:1			0		1.0
52:1			52:1			0		1.0
53:1			53:1			0		1.0
54:1			54:1			0		1.0
55:1			55:1			0		1.0
56:1			56:1			0		1.0
57:1			57:1			0		1.0

Alignment 2241
It is likely that structural inconsistency in word segmentation level makes the higher levels of processing , POS tagging and bracketing , become more complicated .
It is likely that structural inconsistency at the word segmentation level complicates the higher levels of processing , including POS tagging and bracketing .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			11:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:2			23:2			3		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			25:1			0		1.0

Alignment 2242
The detection method for variation inconsistency is based on N-gram sequences and the phrase structures in VTB treebank , following the definition of variation inconsistency above .
The detection method for variation inconsistency is based on N-gram sequences and the phrase structures in the VTB , following the definition for variation inconsistency , above .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0

Alignment 2243
In details , we counted N-gram sequences of different lengths in VTB that have two or more ways of word segmentation , satisfying one of the following two conditions :
In detail , we counted N-gram sequences of different lengths in VTB that have two or more ways of word segmentation , satisfying one of the following two conditions :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			1		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0

Alignment 2244
N tokens are all in the same phrase , and all have the same depth in phrase .
N tokens are all in the same phrase , and all have the same depth in phrase .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 2245
For example , the 3-gram " nhà tình nghĩa ( house of gratitude ) " in this structure " ( NP ( Nc-H căn ) ( N nhà ) ( A tình nghĩa ) ) , " OR N tokens are all in the same phrase , and some tokens can appear in an embedded phrase , which contains only one word .
For example , the 3-gram " nhà tình nghĩa ( house of gratitude ) " in this structure " ( NP ( Nc-H căn ) ( N nhà ) ( A tình nghĩa ) ) , " OR N tokens are all in the same phrase , and some tokens can appear in an embedded phrase , which contains only one word .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0
49:1			49:1			0		1.0
50:1			50:1			0		1.0
51:1			51:1			0		1.0
52:1			52:1			0		1.0
53:1			53:1			0		1.0
54:1			54:1			0		1.0
55:1			55:1			0		1.0
56:1			56:1			0		1.0
57:1			57:1			0		1.0
58:1			58:1			0		1.0
59:1			59:1			0		1.0
60:1			60:1			0		1.0
61:1			61:1			0		1.0
62:1			62:1			0		1.0

Alignment 2246
For example , " nhà tình nghĩa " in this structure " ( NP ( Nc-H căn ) ( N nhà ) ( ADJP ( A tình nghĩa ) ) ) , " where the ADJP contains only one word .
For example , " nhà tình nghĩa " in this structure " ( NP ( Nc-H căn ) ( N nhà ) ( ADJP ( A tình nghĩa ) ) ) , " where the ADJP contains only one word .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0

Alignment 2247
Table 3 shows the overall statistics of the variation inconsistency detected by the above method .
Table 3 shows the overall statistics of the variation inconsistency detected by the method described above .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			14:1			0		1.0
15:1			13:1			0		1.0
16:1			15:1			0		1.0

Alignment 2248
Most of the diﬃcult cases of word segmentation lie in two-token variations , occupying the majority of variations ( 92.9% ) .
Most of the diﬃcult cases of word segmentation occur in two-token variations , occupying the majority of variations ( 92.9% ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 2249
This ratio of 2-gram variations is much higher than the evarage ratio of two-token words in Vietnamese reported in ( Nguyen et al. , 2009a ) , which is 80% percent .
This ratio of 2-gram variations is much higher than the average ratio of two-token words in Vietnamese , as reported in ( Nguyen et al. , 2009a ) , which is 80% .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			31:1			0		1.0

Alignment 2250
Variations that have lengths of three and four tokens occupy 6.1% and 1.0% , respectively .
Variations that have lengths of three and four tokens occupy 6.1% and 1.0% , respectively .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 2251
We estimated the precision of our method by randomly selected 130 2-gram variation instances extracted from the above method described , and manually checked whether they are true inconsistency .
We estimated the precision of our method by randomly selecting 130 2-gram variation instances , extracted from the method described above , and manually checked whether the inconsistencies are true .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			1		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			17:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			29:1			0		1.0

Alignment 2252
We found that 129 cases occupying 99.2% of all extracted 2-grams are true inconsistencies .
We found that 129 cases occupying 99.2% of all extracted 2-grams are true inconsistencies .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 2253
Only one instance is an ambiguous sequence giá c , which is one word when it means price , and two words giá/price c /all in đàu có giá c /all have ( their own ) price .
Only one instance of inconsistency was an ambiguous sequence giá c , which is one word when it means price , and two words giá/price c /all in đàu có giá c /all have ( their own ) price .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
5:1			3:1			2		1.0
6:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
33:1			31:1			0		1.0
34:1			32:1			0		1.0
35:1			33:1			0		1.0
36:1			34:1			0		1.0
37:1			35:1			0		1.0
38:1			36:1			0		1.0
39:1			37:1			0		1.0

Alignment 2254
The precision of our method is high so we can use the extracted variations to study the insights of word segmentation problem .
The precision for our method is high , so we can use the extracted variations to provide insights on the word segmentation problem .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
17:1			17:1			0		1.0
19:1			16:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0

Alignment 2255
We further analyzed the 2-gram variations to know what types of 2-grams were most confusing to annotators .
We further analyzed the 2-gram variations to understand what types of 2-grams were most confusing for annotators .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 2256
The analysis results showed that compound nouns , compound verbs , and compound adjectives are the top diffcult cases of word segmentation .
The analysis revealed that compound nouns , compound verbs , and compound adjectives are the most difficult cases of word segmentation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			3:1			3		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0

Alignment 2257
We classified the 2-gram variations according to their POS sequences in case the tokens in the 2-gram are splitted .
We classified the 2-gram variations according to their POS sequences in case the tokens in the 2-gram are split .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			1		1.0
19:1			19:1			0		1.0

Alignment 2258
There are 54 patterns of POS sequence , of which .
There are a total of 54 patterns of POS sequences .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
4:1			8:1			0		1.0
5:1			2:1			0		1.0
6:1			3:1			0		1.0
7:1			4:1			0		1.0
8:1			5:1			0		1.0
9:1			6:1			1		1.0
10:1			10:1			0		1.0

Alignment 2259
Top 10 confusing patterns , a long with their counts of 2-gram variations , and examples are shown in Table 4 .
The top 10 confusing patterns , their counts of 2-gram variations , and examples are depicted in Table 4 .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			2		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0

Alignment 2260
Table 5 and Table 6 show the POS patterns which a specific POS tag , appearing at the beginning or ending of the sequence .
Table 5 and Table 6 show the POS patterns that are a specific POS tag , appearing at the beginning or ending of the sequence .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0

Alignment 2261
Investigating the inconsistent 2-grams extracted , we found that most of them are compound words , according to the VTB guidelines ( Section 2 ) .
Investigating the inconsistent 2-grams extracted , we found that most of them are compound words , according to the VTB guidelines ( Section 2 ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 2262
One of the reasons why the compound words are sometimes splitted , is because the tokens in those compound words have their own meanings , which seem to contribute to the whole meaning of the compounds .
One of the reasons why the compound words are sometimes split , is because the tokens in those compound words have their own meanings , which seem to contribute to the overall meaning of the compounds .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			1		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			3		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0

Alignment 2263
This can be seen through the examples given in Table 4 , where the meanings of tokens are given with a subscript .
This can be seen through the examples provided in Table 4 , where the meanings of tokens are given with a subscript .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:2			6:2			3		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 2264
This problem seems to have caused a lot of trouble for the annotators of VTB .
This scenario has proven to be problematic for the annotators of VTB .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			5:2			3		1.0
4:1			3:1			0		1.0
7:1			10:1			0		1.0
8:1			11:1			0		1.0
9:1			12:1			0		1.0
10:1			13:1			0		1.0
11:1			14:1			0		1.0
12:1			15:1			0		1.0

Alignment 2265
Furthermore , observing the POS patterns in Table 5 and Table 6 , we can see the potential of structural inconsistency , in particular for closed-set POS tags .
Furthermore , by observing the POS patterns in Table 5 and Table 6 , we can see the potential for structural inconsistency , particularly for closed-set POS tags .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			24:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:2			22:2			3		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 2266
Among them , classifier nouns ( Nc ) and affixes ( S ) are two typical cases of structural inconsistency , which will be used in several settings of our experiments .
Among them , classifier nouns ( Nc ) and affixes ( S ) are two typical cases of structural inconsistency , which will be used in several settings for our experiments .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0

Alignment 2267
The same aﬃx or classifier noun can modify different nouns , so when they are sometimes splitted and sometimes combined in the variations , we can conclude that classifier nouns and affixes involve in-structural inconsistency .
The same aﬃx or classifier noun can modify different nouns , so when they are sometimes split and combined in the variations , we can conclude that classifier nouns and affixes involve in-structural inconsistencies .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			1		1.0
17:1			17:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0
31:1			32:1			0		1.0
32:1			33:1			0		1.0
33:1			34:1			1		1.0
34:1			35:1			0		1.0

Alignment 2268
In the following section , we presents our detection method for structural inconsistency for classifier nouns and affixes .
In the following section , we present our detection method for structural inconsistency for classifier nouns and affixes .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			1		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 2269
The detection method for structural inconsistency of classifier nouns and affixes is simple .
The detection method for structural inconsistency of classifier nouns and affixes is simple .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 2270
First , we collected all affixes and classifier nouns in the VTB corpus . Then extracted 2-grams containing these affixes or classifier nouns , which also are the structural inconsistencies .
We collected all affixes and classifier nouns in the VTB corpus , and then extracted 2-grams containing these affixes or classifier nouns , which are also structural inconsistencies .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			3:1			0		1.0
2:1			4:1			0		1.0
3:1			5:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			1:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			26:1			0		1.0
25:1			25:1			0		1.0
26:1			28:1			0		1.0
27:1			29:1			0		1.0
28:1			30:1			0		1.0

Alignment 2271
For example , since " con " is tagged as a classifier noun in VTB , we extracted all 2-grams of " con " including both " con gái/girl " and " con trai/boy " .
For example , since " con " is tagged as a classifier noun in VTB , we extracted all 2-grams of " con " including both " con gái/girl " and " con trai/boy " .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0

Alignment 2272
Note that even though the sequence , " con trai " is always splitted into two words throughout the corpus , it can still be an inconsistency , if we consider similar structures such as " con gái " .
Even though the sequence , " con trai " is always split into two words throughout the corpus , it can still be an inconsistency , if we consider similar structures such as " con gái " .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			3:1			0		1.0
2:1			4:1			0		1.0
3:1			5:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			1		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0
24:1			26:1			0		1.0
25:1			27:1			0		1.0
26:1			28:1			0		1.0
27:1			29:1			0		1.0
28:1			30:1			0		1.0
29:1			31:1			0		1.0
30:1			32:1			0		1.0
31:1			33:1			0		1.0
32:1			34:1			0		1.0
33:1			35:1			0		1.0
34:1			36:1			0		1.0
35:1			37:1			0		1.0
36:1			38:1			0		1.0
37:1			39:1			0		1.0

Alignment 2273
In other words , by this method , we extract sequences that may be consistent at the surface level , but are not consistent , if we consider the higher analysis levels , POS tagging .
In other words , by this method , we extract sequences that may be consistent at the surface level , but are not consistent , if we consider the higher analysis levels , POS tagging .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0

Alignment 2274
According to the VTB POS-tagging annotation guidelines ( Nguyen et al. , c ) , classifier nouns should be separated from the words they modify .
According to the VTB POS-tagging annotation guidelines ( Nguyen et al. , c ) , classifier nouns should be separated from the words that they modify .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0

Alignment 2275
However , in practice it is confusing when the classifier noun can be standalone as a single word .
However , in practice , it is confusing when the classifier noun can be standalone as a single word .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0

Alignment 2276
For example a classifier noun , e.g. , " con " in " con trai ( boy ) " , or " con gái ( girl ) " , can also be a simple word , which means " I ( first person pronoun used by a child when talking to his/her parents ) " , or part of a complex noun " con cái ( children ) " .
For example a classifier noun , e.g. , " con " in " con trai ( boy ) " , or " con gái ( girl ) " , can also be a simple word , which means " I ( first person pronoun used by a child when talking to his/her parents ) " , or part of a complex noun " con cái ( children ) " .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0
49:1			49:1			0		1.0
50:1			50:1			0		1.0
51:1			51:1			0		1.0
52:1			52:1			0		1.0
53:1			53:1			0		1.0
54:1			54:1			0		1.0
55:1			55:1			0		1.0
56:1			56:1			0		1.0
57:1			57:1			0		1.0
58:1			58:1			0		1.0
59:1			59:1			0		1.0
60:1			60:1			0		1.0
61:1			61:1			0		1.0
62:1			62:1			0		1.0
63:1			63:1			0		1.0
64:1			64:1			0		1.0
65:1			65:1			0		1.0
66:1			66:1			0		1.0
67:1			67:1			0		1.0
68:1			68:1			0		1.0
69:1			69:1			0		1.0

Alignment 2277
Therefore , in our experiments , we want to evaluate the " splitting " and " combining " of these difficult cases , to see whether the solution is fruitful for applications of the corpus .
Therefore , in our experiments , we want to evaluate the " splitting " and " combining " of these cases , in order to see whether the solution is successful for applications of the corpus .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:2			29:2			3		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0

Alignment 2278
Examing the variations extracted by the variation inconsistency detection , we found that there are cases when a special character like percentage % in " 30% " , is splitted or combined with " 30 " .
By examining the variations extracted by the variation inconsistency detection , we found that there are cases when a special character like a percentage ( % ) in " 30% " , is split or combined with " 30 " .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
23:1			21:1			0		1.0
25:1			22:1			0		1.0
27:1			23:1			0		1.0
28:1			24:1			0		1.0
29:1			25:1			0		1.0
30:1			26:1			0		1.0
31:1			27:1			0		1.0
32:1			28:1			0		1.0
33:1			29:1			1		1.0
34:1			30:1			0		1.0
35:1			31:1			0		1.0
36:1			32:1			0		1.0
37:1			33:1			0		1.0
38:1			34:1			0		1.0
39:1			35:1			0		1.0
40:1			36:1			0		1.0

Alignment 2279
Such inconsistent annotations are manually fixed based on their textual context .
Such inconsistent annotations are manually fixed based on their textual context .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 2280
Checking structural inconsistency of these special characters , including percentage % , hyphen - , and so on , we found quite a significant amount of inconsistent annotations .
By checking structural inconsistencies of these special characters , including percentages ( % ) , hyphens ( - ) , and other symbols , we found quite a significant number of inconsistent annotations .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			1		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			1		1.0
12:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			1		1.0
17:1			13:1			0		1.0
19:1			14:1			0		1.0
20:1			15:1			0		1.0
23:1			18:1			0		1.0
24:1			19:1			0		1.0
25:1			20:1			0		1.0
26:1			21:1			0		1.0
27:4			22:4			3		1.0
31:1			26:1			0		1.0
32:1			27:1			0		1.0
33:1			28:1			0		1.0

Alignment 2281
For example , the character % in " 30% " is splitted , but is combined with the number in " 50 % " , which is considered as a structural inconsistency .
For example , the character , % , in " 30% " is split , but is combined with a number in " 50 % " , which is considered to be a structural inconsistency .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			12:1			0		1.0
6:1			5:1			0		1.0
7:1			24:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			1		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			29:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
27:5			27:2			3		1.0
33:1			30:1			0		1.0
34:1			31:1			0		1.0
35:1			32:1			0		1.0

Alignment 2282
Note that although it can be argued that whether " N% " can be splitted into two words or combined in one word is dependent on the blank space in between N and " % " .
Note that it can be argued that splitting " N% " into two words or combined in one word is dependent on the blank space in-between N and " % " .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			14:1			1		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			15:1			0		1.0
12:1			16:1			0		1.0
13:1			17:1			0		1.0
14:1			18:1			0		1.0
15:1			19:1			0		1.0
16:1			20:1			0		1.0
17:1			21:1			0		1.0
18:1			22:1			0		1.0
19:1			23:1			0		1.0
20:1			24:1			0		1.0
21:1			25:1			0		1.0
22:1			26:1			0		1.0
23:1			27:1			0		1.0
24:1			28:1			0		1.0
26:1			31:1			0		1.0
27:1			32:1			0		1.0
28:1			33:1			0		1.0
29:1			34:1			0		1.0
30:1			35:1			0		1.0
31:1			36:1			0		1.0

Alignment 2283
It does matter higher-levels of annotation such as POS tagging, because we may need one or two different POS tags for different ways of annotation .
Higher-levels of annotation such as POS tagging is significant , because we may need one or two different POS tags for the different methods of annotation .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			4:1			0		1.0
2:1			5:1			0		1.0
3:1			6:1			0		1.0
4:1			7:1			0		1.0
5:1			8:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			3		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0

Alignment 2284
Therefore , we think it is better to carefully preprocess text and segment these special characters in a consistent way .
Therefore , we think that it is better to carefully preprocess text and segment these special characters in a consistent way .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0

Alignment 2285
To improve the quality of VTB corpus , we extracted the probably problematic sequences using patterns of the special characters , and manually fixed this type of inconsistency .
To improve the quality of the VTB corpus , we extracted the problematic sequences using patterns of the special characters , and manually fixed this type of inconsistency .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			17:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 2286
Automatically modification is diﬃcult , since we must check the semantics of the special characters in their contexts .
Automatically modification is diﬃcult , since we must check the semantics of the special characters in their contexts .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 2287
For example , hyphens in date expressions like " 5-4-1975 " , which means the date , "April , 1975 ," are combined with the numbers .
For example , hyphens in date expressions like " 5-4-1975 " , which refers to the date , "the fifth of April , 1975 ," are combined with the numbers .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:3			13:2			3		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
22:1			18:1			0		1.0
23:1			19:1			0		1.0
24:1			20:1			0		1.0
25:1			21:1			0		1.0
26:1			22:1			0		1.0
27:1			23:1			0		1.0
28:1			24:1			0		1.0
29:1			25:1			0		1.0
30:1			26:1			0		1.0

Alignment 2288
However , when the hypen has a meaning of " ( from ) to " or " around ... or " , as in " 2-3 giờ sáng " , meaning " around 2 or 3 o’clock in the morning " , we decided to separate it from the surrounding numbers .
However , when the hyphen indicates " ( from ) to " or " around ... or " , as in " 2-3 giờ sáng " , meaning " around 2 or 3 o’clock in the morning " , we decided to separate it from the surrounding numbers .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
6:1			9:1			0		1.0
7:1			10:1			0		1.0
8:1			11:1			0		1.0
9:1			12:1			0		1.0
10:1			13:1			0		1.0
11:1			14:1			0		1.0
12:1			15:1			0		1.0
13:1			16:1			0		1.0
14:1			17:1			0		1.0
15:1			18:1			0		1.0
16:1			19:1			0		1.0
17:1			20:1			0		1.0
18:1			21:1			0		1.0
19:1			22:1			0		1.0
20:1			23:1			0		1.0
21:1			24:1			0		1.0
22:1			25:1			0		1.0
23:1			26:1			0		1.0
24:1			27:1			0		1.0
25:1			28:1			0		1.0
26:1			29:1			0		1.0
27:1			30:1			0		1.0
28:1			31:1			0		1.0
29:1			32:1			0		1.0
30:1			33:1			0		1.0
31:1			34:1			0		1.0
32:1			35:1			0		1.0
33:1			36:1			0		1.0
34:1			37:1			0		1.0
35:1			38:1			0		1.0
36:1			39:1			0		1.0
37:1			40:1			0		1.0
38:1			41:1			0		1.0
39:1			42:1			0		1.0
40:1			43:1			0		1.0
41:1			44:1			0		1.0
42:1			45:1			0		1.0
43:1			46:1			0		1.0
44:1			47:1			0		1.0
45:1			48:1			0		1.0
46:1			49:1			0		1.0
47:1			50:1			0		1.0
48:1			51:1			0		1.0

Alignment 2289
As a result , we have fixed 685 inconsistent annotations of 21 special characters in VTB .
As a result , we have fixed 685 inconsistent annotations of 21 special characters in VTB .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 2290
The variation inconsistency and structural inconsistency found in Section 3 above can also be seen as representatives of different word segmentation criteria for Vietnamese .
The variation inconsistency and structural inconsistency found in Section 3 can also be seen as representatives of different word segmentation criteria for Vietnamese .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0

Alignment 2291
We organized the inconsistency detected in seven configurations of the original VTB corpus .
We organized the inconsistency detected in seven configurations of the original VTB corpus .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 2292
Then , by using these data sets , we could observe the influence of the different word segmentation criteria on three tasks : automatic word segmentation , text classification , and English-Vietnamese statistical machine translation .
Then , by using these data sets , we could observe the influence of the different word segmentation criteria on three tasks : automatic word segmentation , text classification , and English-Vietnamese statistical machine translation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0

Alignment 2293
Seven data sets corresponding to different segmentation criteria are organized as follows .
Seven data sets corresponding to different segmentation criteria are organized as follows .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 2294
ORG : The original VTB corpus .
ORG : The original VTB corpus .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0

Alignment 2295
BASE : The original VTB corpus + Manual modification of special characters done in Section 3.3 .
BASE : The original VTB corpus + Manual modification of special characters done in Section 3.3 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 2296
VAR_SPLIT : BASE + split all variations detected in Section 3.1 .
VAR_SPLIT : BASE + split all variations detected in Section 3.1 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 2297
VAR_COMB : BASE + combine all variations detected in Section 3.1 .
VAR_COMB : BASE + combine all variations detected in Section 3.1 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 2298
VAR_FREQ : BASE + select the segmentation with higher frequency among all variations detected in Section 3.1 .
VAR_FREQ : BASE + select the segmentation with higher frequency among all variations detected in Section 3.1 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 2299
STRUCT_NC : BASE + combine all classifier nouns detected in Section 3.2 with the words they modify .
STRUCT_NC : BASE + combine all classifier nouns detected in Section 3.2 with the words they modify .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 2300
STRUCT_AFFIX : BASE + combine all suﬃxes detected in Section 3.2 with the words they modify .
STRUCT_AFFIX : BASE + combine all suﬃxes detected in Section 3.2 with the words they modify .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 2301
These data sets are used in our experiments , as illustrated in Figure 1 .
These data sets are used in our experiments , as illustrated in Figure 1 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 2302
The names of the data sets are also used to label our experimental configurations .
The names of the data sets are also used to label our experimental configurations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 2303
In this section , we briefly describe the task settings and the methods used for word segmentation ( WS ) , text classification ( TC ) , and English-Vietnamese statistical machine translation ( SMT ) .
In this section , we briefly describe the task settings and the methods used for word segmentation ( WS ) , text classification ( TC ) , and English-Vietnamese statistical machine translation ( SMT ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0

Alignment 2304
We used YamCha ( Kudo and Matsumoto , 2003 ) , a multi-purpose chunking tool , to train our word segmentation models .
We used YamCha ( Kudo and Matsumoto , 2003 ) , a multi-purpose chunking tool , to train our word segmentation models .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 2305
The core of YamCha is the Support Vector Machine ( SVM ) machine learning method , which has been proved to be effective in NLP tasks .
The core of YamCha is the Support Vector Machine ( SVM ) machine learning method , which has been proven to be effective for NLP tasks .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			2		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 2306
For the Vietnamese word segmentation problem , each token is labeled with standard B , I , or O labels , corresponding to beginning , inside , and outside positions , respectively .
For the Vietnamese word segmentation problem , each token is labeled with standard B , I , or O labels , corresponding to the beginning , inside , and outside positions , respectively .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0

Alignment 2307
Label of each token is determined based on the lexical features of two preceding words , and two following words of that token .
The label of each token is determined based on the lexical features of two preceding words , and the two following words of that token .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0

Alignment 2308
Since Vietnamese language is not inflectional , we cannot utilize inflection features for word segmentation .
Since the Vietnamese language is not inflectional , we cannot utilize inflection features for word segmentation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0

Alignment 2309
Each of the seven data sets is splitted into two subsets for training and testing our WS models .
Each of the seven data sets is split into two subsets for training and testing our WS models .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			1		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 2310
The training set contains 8443 sentences , and the test set contains 2000 sentences .
The training set contains 8443 sentences , and the test set contains 2000 sentences .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 2311
Text classification is defined as a task of determining for an input document the most suitable topic from the predefined topics .
Text classification is defined as a task of determining the most suitable topic from the predefined topics , for an input document .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			13:1			0		1.0
10:1			14:1			0		1.0
11:1			15:1			0		1.0
12:1			16:1			0		1.0
13:1			17:1			0		1.0
14:1			18:1			0		1.0
15:1			19:1			0		1.0
16:1			20:1			0		1.0
18:1			9:1			0		1.0
19:1			10:1			0		1.0
20:1			11:1			0		1.0
21:1			12:1			0		1.0
22:1			21:1			0		1.0

Alignment 2312
We implemented a text classification system similar to the system presented in ( Nguyen et al. , 2012 ) .
We implemented a text classification system similar to the system presented in ( Nguyen et al. , 2012 ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 2313
The difference is that we performed for document level , not for sentence level .
The difference is that we performed the task at the document level , instead of at the sentence level .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			3		1.0
17:1			12:1			0		1.0
18:1			13:1			0		1.0
19:1			14:1			0		1.0

Alignment 2314
Processing of the system is summarized as follows .
The processing of the system is summarized as follows .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0

Alignment 2315
An input document is preprocessed with word segmentation and stop-word removals .
An input document is preprocessed with word segmentation and stop-word removals .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 2316
Then , the document is represented in the form of a vector of weighted words appearing in the document .
Then , the document is represented in the form of a vector of weighted words appearing in the document .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 2317
The weight is calculated using standard tf-idf product .
The weight is calculated using standard tf-idf product .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 2318
An SVM-based classifier predicts the most probable topic for the vector , which also is the topic of the input document .
An SVM-based classifier predicts the most probable topic for the vector , which also is the topic for the input document .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 2319
In our experiment , for comparison of diﬀerent word segmentation criteria in topic classification , we only vary the word segmentation model used for this task , while fixing other configurations .
In our experiment , for comparison of diﬀerent word segmentation criteria in topic classification , we only vary the word segmentation model used for this task , while fixing other configurations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0

Alignment 2320
News articles of five topics : music , stock , entertainment , education , and fashion are used .
News articles of five topics : music , stock , entertainment , education , and fashion are used .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 2321
The sizes of the training and test data sets are summarized in Table 8 .
The sizes of the training and test data sets are summarized in Table 8 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 2322
A phrase-based SMT system for English-Vietnamese translation was implemented .
A phrase-based SMT system for English-Vietnamese translation was implemented .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 2323
In this system , we used SRILM ( Stolcke , 2002 ) to build the language model , GIZA++ ( Och and Ney , 2003 ) to train the word-aligned model , and Moses ( Holmqvist et al. , 2007 ) to train the phrase-based statistical translation model .
In this system , we used SRILM ( Stolcke , 2002 ) to build the language model , GIZA++ ( Och and Ney , 2003 ) to train the word-aligned model , and Moses ( Holmqvist et al. , 2007 ) to train the phrase-based statistical translation model .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0

Alignment 2324
Translation results are evaluated using BLUE score ( Papineni et al. , 2002 ) .
Translation results are evaluated using the BLUE score ( Papineni et al. , 2002 ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0

Alignment 2325
Both training and test data are word-segmented using the word segmentation models achieved .
Both training and test data are word-segmented using the word segmentation models achieved .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 2326
For the experiment , we used the VCL_EVC bilingual corpus , 18000 pairs of sentences for training , and 1000 pairs for testing .
For the experiment , we used the VCL_EVC bilingual corpus , 18000 pairs of sentences for training , and 1000 pairs for testing .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 2327
According to the result in Table 9 , the VAR_SPLIT criterion gives the highest WS performance .
According to the result in Table 9 , the VAR_SPLIT criterion gives the highest WS performance .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 2328
Except for STRUCT_NC , all the modifications to the original VTB corpus increase the performance of WS .
With the exception of STRUCT_NC , all of the modifications to the original VTB corpus increase the performance of WS .
Line2Start:Length	Line1Start:Length	Module		Score
3:1			15:1			0		1.0
4:1			2:1			0		1.0
5:1			3:1			0		1.0
6:1			4:1			0		1.0
8:1			5:1			0		1.0
9:1			6:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0

Alignment 2329
However , the word segmentation criterion with higher performance is not necessarily a better criterion , but a criterion should also be judged through applications of word segmentation .
However , the word segmentation criterion with higher performance is not necessarily a better criterion , but a criterion should also be judged through applications of word segmentation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 2330
In both SMT and TC experiments , the BASE model , which is based on the manually-modified inconsistency of special characters , achieved better results than the ORG model .
In both SMT and TC experiments , the BASE model , which is based on the manually-modified inconsistency of special characters , achieved better results than the ORG model .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0

Alignment 2331
In particular , in the TC experiment , the BASE model achieved 0.66 point higher than ORG , which is a significant improvement .
In particular , in the TC experiment , the BASE model achieved 0.66 point higher than ORG , which is a significant improvement .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 2332
The results support the conclusion that the quality of word-segmentation corpus is very important for building NLP applications .
The results support the conclusion that the quality of the word-segmentation corpus is very important for building NLP applications .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0

Alignment 2333
The SMT results show that three out of six augmented models , VAR_SPLIT , VAR_FREQ and BASE , gave higher performance than the ORG configuration .
The SMT results show that three out of six augmented models , VAR_SPLIT , VAR_FREQ and BASE , performed better than the ORG configuration .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0

Alignment 2334
Among them , the best model VAR_SPLIT achieved 36.91 BLEU score , which is 0.55 higher than ORG .
Among them , the best-performing model , VAR_SPLIT achieved 36.91 BLEU score , which is 0.55 higher than ORG .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0

Alignment 2335
In TC results , all six augmented models have higher results than ORG .
In TC results , all six augmented models achieved higher results than ORG .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 2336
In general , the augmented models are better than the ORG .
In general , the augmented models performed better than the ORG .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 2337
Additionally , because our automatic methods for inconsistency detection could not cover all types of inconsistency in word segmentation annotation , further improvement of corpus quality is demanded .
Additionally , because our automatic methods for inconsistency detection could not cover all of the types of inconsistencies in word segmentation annotation , further improvement of corpus quality is demanded .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			23:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			1		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0

Alignment 2338
Comparing the results of STRUCT_AFFIX and STRUCT_NC with BASE in WS , TC , and SMT , we can observe that combining aﬃxes with their head nouns resulted in slightly better results for WS , TC , and does not change the performance of SMT .
Comparing the results of STRUCT_AFFIX and STRUCT_NC with BASE in WS , TC , and SMT , we can observe that combining aﬃxes with their head nouns resulted in slightly better results for WS and TC , and did not change the performance of SMT .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			37:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0

Alignment 2339
However , the combination of clasifier nouns with their head nouns had negative eﬀects on WS and SMT .
However , the combination of classifier nouns with their head nouns had negative eﬀects on WS and SMT .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 2340
Another intention of our experiment is to compare two solutions for controversial cases of word segmentation , splitting and combining .
Another part of the scope of our experiment is to compare two solutions for controversial cases of word segmentation , splitting and combining .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
5:1			2:1			0		1.0
6:1			3:1			0		1.0
7:1			4:1			0		1.0
8:1			5:1			0		1.0
9:1			6:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			0		1.0
23:1			20:1			0		1.0

Alignment 2341
Splitting and combining variations are reflected by VAR_COMB and VAR_SPLIT , while STRUCT_AFFIX and STRUCT_NC represent the combination of affixes or classifier nouns with the words that they modify .
Splitting and combining variations are reflected by VAR_COMB and VAR_SPLIT , while STRUCT_AFFIX and STRUCT_NC represent the combination of affixes or classifier nouns with the words that they modify .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0

Alignment 2342
STRUCT_AFFIX and STRUCT_NC are contrasted with BASE where aﬃxes and classifier nouns remain untouched .
STRUCT_AFFIX and STRUCT_NC are contrasted with BASE where aﬃxes and classifier nouns remain untouched .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 2343
Comparing VAR_COMB and VAR_SPLIT in both TC experiment and SMT experiment , we see that the VAR_SPLIT results are better in both cases .
Comparing VAR_COMB and VAR_SPLIT in both the TC experiment and SMT experiment , we see that the VAR_SPLIT results are better in both cases .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0

Alignment 2344
Since the ratio of combined variations in the ORG corpus is 60.9% , it can be observed that splitting seems to be better than combining for WS , TC and SMT .
Since the ratio of combined variations in the ORG corpus is 60.9% , it can be observed that splitting seems to be better than combining for WS , TC and SMT .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0

Alignment 2345
In this paper , we have showed a quantitative analysis of the difficulties in word segmentation , through the detection of problematic cases in the Vietnamese treebank .
In this paper , we have provided a quantitative analysis of the difficulties in word segmentation , through the detection of problematic cases in the Vietnamese Treebank .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
27:1			27:1			0		1.0

Alignment 2346
Based on the analysis , we automatically created data representing the different word segmentation criteria , and evaluated the criteria indirectly through their applications .
Based on the analysis , we automatically created data that represent the different word segmentation criteria , and evaluated the criteria indirectly through their applications .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:2			9:1			3		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0

Alignment 2347
Our experimental results showed that manual modification done for annotation of spe cial characters , and most of other word segmentation criteria , significantly improved the performances of automatic word segmentation , text classification and statistical machine translation , comparing with the use of the original VTB corpus .
Our experimental results showed that manual modification , done for annotation of special characters , and most other word segmentation criteria , significantly improved the performances of automatic word segmentation , text classification and statistical machine translation , in comparison with the use of the original VTB corpus .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			38:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0
31:1			32:1			0		1.0
32:1			33:1			0		1.0
33:1			34:1			0		1.0
34:1			35:1			0		1.0
35:1			36:1			0		1.0
36:1			37:1			0		1.0
39:1			39:1			2		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0

Alignment 2348
Since the VTB corpus is the first eﬀort in building a treebank for Vietnamese , and is the only corpus publicly available for NLP research , this study contributes to further improvement of the corpus quality , which is essential for building efficient NLP systems .
Since the VTB corpus is the first eﬀort in building a treebank for Vietnamese , and is the only corpus that is publicly available for NLP research , this study contributes to further improvement of the corpus quality , which is essential for building efficient NLP systems .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:2			37:2			3		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
33:1			31:1			0		1.0
34:1			32:1			0		1.0
35:1			33:1			0		1.0
36:1			34:1			0		1.0
37:1			35:1			0		1.0
38:1			36:1			0		1.0
41:1			39:1			0		1.0
42:1			40:1			0		1.0
43:1			41:1			0		1.0
44:1			42:1			0		1.0
45:1			43:1			0		1.0
46:1			44:1			0		1.0
47:1			45:1			0		1.0

Alignment 2349
Generating short summary videos for rushes is a challenging task due to difficulty in redundancy elimination and determination of important objects and events being placed in the summary .
Generating short summary videos for rushes is a challenging task due to the difficulty in eliminating redundancy and determining the important objects and events to be placed in the summary .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			26:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			16:1			0		1.0
18:1			17:2			3		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
25:1			23:1			1		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0

Alignment 2350
Redundancy elimination is difficult since repetitive segments , which are takes of the same scene , usually have different lengths and motion patterns .
Redundancy elimination is difficult since repetitive segments , which are takes of the same scene , usually have different lengths and motion patterns .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 2351
This makes approaches using one keyframe for shot representation failed in doing clustering .
This makes approaches using one keyframe for a shot representation fail when trying to form a cluster .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			1		1.0
16:1			12:1			1		1.0
17:1			13:1			0		1.0

Alignment 2352
In addition , even repetitive segments can be determined precisely , the summary generated by concatenating together selected segments still has longer duration than the upper limit .
In addition , even repetitive segments can be precisely determined , but the summary generated by concatenating together the selected segments still takes longer than the upper limit .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			9:1			0		1.0
9:1			8:1			0		1.0
10:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			2		1.0
23:1			21:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0

Alignment 2353
It is questionable to select a sub-segment so that it conveys information of the scene as much as possible .
It is questionable to select a sub-segment so that it conveys information of the scene as much as possible .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 2354
In this paper , we introduce two approaches to these problems .
,We introduce two approaches to solve these problems .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			5:1			0		1.0
2:1			6:1			0		1.0
3:1			7:1			0		1.0
4:1			8:1			0		1.0
6:1			9:1			0		1.0
7:1			10:1			0		1.0
8:1			11:1			0		1.0

Alignment 2355
In the first approach , one keyframe is used for shot representation in doing clustering; and sub-segments are selected using motion information for generating the summary .
In the first approach , one keyframe is used for representing a shot when forming a cluster; and sub-segments are selected using the motion information for generating the summary .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
12:1			10:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0
26:1			23:1			0		1.0
27:1			24:1			0		1.0
28:1			25:1			0		1.0
29:1			26:1			0		1.0

Alignment 2356
Meanwhile , in the second approach , all frames of a shot are used for clustering; and a simple skimming method is used to select sub-segments .
Meanwhile , in the second approach , all the frames of a given shot are used for clustering; and a simple skimming method is used to select the sub-segments .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
28:1			25:1			0		1.0
29:1			26:1			0		1.0

Alignment 2357
Experimental results on the TRECVID 2008 dataset and comparison between the two approaches are reported .
The experimental results on the TRECVID 2008 dataset and a comparison between the two approaches are also reported .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0

Alignment 2358
With the availability of multimedia databases growing at an exponential rate , users are increasingly requiring assistance in accessing digital video contents .
With the availability of multimedia databases growing at an exponential rate , users are increasingly requiring assistance in accessing digital video contents .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 2359
Video summarization is a significant research that helps to meet these needs by developing a condensed version of a full length digital video with the most important contents \CITE .
Video summarization significantly helps to meet this need by developing a condensed version of a full length digital video using only the most important contents \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			3:2			3		1.0
3:1			7:1			0		1.0
4:1			8:1			0		1.0
5:1			9:1			0		1.0
7:1			11:1			1		1.0
8:1			12:1			0		1.0
9:1			13:1			0		1.0
10:1			14:1			0		1.0
11:1			15:1			0		1.0
12:1			16:1			0		1.0
13:1			17:1			0		1.0
14:1			18:1			0		1.0
15:1			19:1			0		1.0
16:1			20:1			0		1.0
17:1			21:1			0		1.0
18:1			22:1			0		1.0
21:1			24:1			0		1.0
22:1			25:1			0		1.0
23:1			26:1			0		1.0
24:1			27:1			0		1.0
25:1			28:1			0		1.0
26:1			29:1			0		1.0

Alignment 2360
Summary videos can help users to browse and navigate large video archives efficiently and effectively .
Summary videos can help users more efficiently and effectively browse and navigate through large video archives .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			12:1			0		1.0
7:1			13:1			0		1.0
8:1			14:1			0		1.0
9:1			6:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
13:1			9:1			0		1.0
14:1			10:1			0		1.0
15:1			11:1			0		1.0
16:1			15:1			0		1.0

Alignment 2361
Generating summary videos for BBC rushes \CITE is a challenging task due to difficulty in redundancy elimination and determination of important objects and events being placed in the summary .
Generating summary videos for BBC rushes \CITE is a challenging task due to the difficulty with redundancy elimination and determining the most important objects and events to be placed in the summary .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			27:1			0		1.0
14:1			13:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:2			3		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
27:1			24:1			1		1.0
28:1			25:1			0		1.0
29:1			26:1			0		1.0
31:1			28:1			0		1.0
32:1			29:1			0		1.0

Alignment 2362
Since the length of the summary is limited to 2\% duration of the original video , there is a trade-off between recall and usability ( e.g user friendly through smooth presentation , being easy to understand ) .
Since the length of the summary is limited to 2\% duration of the original video , there is a trade-off between the recall and usability ( e.g. user friendly through smooth presentation , / being easy to understand ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
34:1			32:1			0		1.0
35:1			33:1			0		1.0
36:1			34:1			0		1.0
37:1			35:1			0		1.0
38:1			36:1			0		1.0
39:1			37:1			0		1.0

Alignment 2363
High recall , i.e many objects and events ( called scenes ) are included in the summary , usually reduce the number of frames for each scene .
High recall , i.e. many objects and events ( called scenes ) included in the summary , usually reduces the number of frames for each scene .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			1		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0

Alignment 2364
For example , the maximum duration for the summary of a 30 minute length video is 36 seconds ( \MATH ) .
For example , the maximum duration for a summary of a 30 minute video is 36 seconds ( \MATH ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:2			7:2			3		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0

Alignment 2365
If the summary consists of 20 scenes , the average duration for each scene is 1.8 seconds .
If the summary consists of 20 scenes , the average duration for each scene is 1.8 seconds .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 2366
For the event such as " `Woman attacks man on bench on left and runs off with large bag .
For an event such as " `Woman attacks man on bench on left and runs off with large bag .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 2367
" ', with this length constraint , it is difficult to present it in a pleasant tempo and rhythm .
" ', with this length constraint , it would be difficult to present it in a pleasant tempo and rhythm .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:2			8:1			3		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0

Alignment 2368
On the contrary , smooth presentation of events consumes a lot number of frames , that decrease the recall .
On the other hand , a smooth presentation of these events would consume a large number of frames , which would decrease the recall .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:2			2:1			3		1.0
4:1			3:1			0		1.0
5:1			9:1			0		1.0
6:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
10:1			7:1			0		1.0
14:2			10:1			3		1.0
16:1			12:1			0		1.0
17:1			13:1			0		1.0
18:1			14:1			0		1.0
21:1			16:1			0		1.0
22:1			17:1			0		1.0
23:1			18:1			0		1.0
24:1			19:1			0		1.0

Alignment 2369
In general , generating summary videos consists of the following steps :
In general , generating summary videos consists of the following steps :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 2370
Video segmentation : This step decomposes the original video into segments , such shots or sub-shots .
Video segmentation : This step breaks down the original video into segments , such as shots or sub-shots .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0

Alignment 2371
Each segment should be aligned such that it is a part of a scene .
Each segment should be aligned so that it is a part of a scene .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 2372
Redundancy elimination : This step groups segments that belong to the same take into clusters .
Redundancy elimination : This step groups the segments that belong to the same take into clusters .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0

Alignment 2373
Only one representative segment is used for the final summary video .
Only one representative segment is used for the final summary video .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 2374
The others are discarded .
The others are discarded .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0

Alignment 2375
Junk elimination : This step removes color bars , clapboards , all black or all white frames that are unnecessary for the final summary video .
Junk elimination : This step removes the color bars , clapboards , and the all black or all white frames that are unnecessary in the final summary video .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			0		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0
26:1			23:1			0		1.0
27:1			24:1			0		1.0
28:1			25:1			0		1.0

Alignment 2376
Summary generation : This step selects frames from representative segments of clusters and concatenate to form the final summary video .
Summary generation : This step selects the frames from the representative segments of clusters and concatenates them to form the final summary video .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			1		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			0		1.0
23:1			20:1			0		1.0

Alignment 2377
While the steps of video segmentation and junk elimination are easy to handle , the steps of redundancy elimination and summary generation are difficult .
While the steps for video segmentation and junk elimination are easy to handle , the steps for redundancy elimination and summary generation are difficult .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 2378
For example , as for redundancy elimination , the question is how to represent a segment into a feature vector and how to compute the similarity between two segments having different length and motion pattern .
For example , as for redundancy elimination , the question is how to represent a segment in a feature vector and how to compute the similarity between two segments having different lengths and motion patterns .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			1		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			1		1.0
35:1			35:1			0		1.0

Alignment 2379
In the other case , assume that we have selected appropriate segments , the total length of these segments are usually larger than that of the final summary .
In the other case , assuming that we have selected the appropriate segments , the total length of these segments is usually larger than that of the final summary .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:2			5:2			3		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			25:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:2			19:2			3		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0

Alignment 2380
The question is how to determine the important part of the selected segment such that it conveys information of the scene as much as possible .
The question is how to determine the most important parts of the selected segments so that they convey as much of the information of the scene as possible .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			1		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			1		1.0
15:1			14:1			0		1.0
18:1			21:1			0		1.0
19:1			22:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			17:1			0		1.0
25:1			20:1			0		1.0
26:1			23:1			0		1.0
27:1			24:1			0		1.0
28:1			25:1			0		1.0

Alignment 2381
In this paper , we present two approaches for handling these difficult steps .
In this paper , we present two approaches for handling these difficult steps .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 2382
The first approach represents each segment by one key-frame and groups similar segments by doing clustering on these key-frames .
The first approach represents each segment by using one key-frame and groups similar segments by clustering them on these key-frames .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0

Alignment 2383
Then the portion of each segment that has high motion is used to include into the final summary .
Then the portion of each segment that has the highest motion is included in the final summary .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			8:1			2		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:3			3		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0

Alignment 2384
Meanwhile , the second approach uses another strategy for redundancy elimination .
Meanwhile , the second approach uses another strategy for redundancy elimination .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 2385
Specifically , for each segment , a set of frames are extracted by sampling at a certain time interval ( e.g 5 frames ) .
Specifically , for each segment , a set of frames are extracted by sampling at a certain time interval ( e.g. 5 frames ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 2386
The clustering process is performed on the frames of all segments .
The clustering process is performed on the frames of all the segments .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0

Alignment 2387
Then , the segments that share a large enough number of frames with respect to their size are merged into one cluster .
Then , segments that share a large enough number of frames with respect to their size are merged into one cluster .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0

Alignment 2388
In order to generate the final summary , with each representative segment , the middle part is selected with the skim rate of 2 frames .
In order to generate the final summary , with each representative segment , the middle part is selected with a skim rate of 2 frames .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 2389
This paper is organized as follows : section \REF introduces details of the first approach; , while section \REF presents details of the second approach .
This paper is organized as follows : section \REF introduces the details of the first approach; , while section \REF presents the details of the second approach .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0

Alignment 2390
Section \REF describes experimental results on the TRECVID 2008 dataset .
Section \REF describes our experimental results on the TRECVID 2008 dataset .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0

Alignment 2391
Finally , section \REF and section \REF conclude the paper .
Finally , section \REF and section \REF conclude the paper .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 2392
From the definition , all rushes are unedited; therefore it must consist of hard cut only .
By definition , all rushes are unedited; therefore they must consist of hard cuts only .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			1		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0

Alignment 2393
The shot boundary detection algorithm in \CITE is used to determine shot boundary and partition the input video into shots .
The shot boundary detection algorithm in \CITE is used to determine the shot boundary and to partition the input video into shots .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0

Alignment 2394
A local color histogram is extracted by dividing a video frame into \MATH blocks .
A local color histogram is extracted by dividing a video frame into \MATH blocks .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 2395
The \MATH distance is used to compute the distance between each blocks of frames \MATH and \MATH .
The \MATH distance is used to compute the distance between each block of frames \MATH and \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			1		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 2396
Next , these values are sorted into an ascending order .
Next , these values are sorted into ascending order .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0

Alignment 2397
The sum of the middle eight of these 16 values are used to define a cut between frames \MATH and \MATH if these values exceed a threshold \MATH .
The sum of the middle eight of these 16 values is used to define the cut between frames \MATH and \MATH if these values exceed the threshold \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:2			10:2			3		1.0
12:1			12:1			0		1.0
13:2			13:2			3		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 2398
However , this algorithm cannot distinguish between hard cut and the large objects motion .
However , this algorithm cannot distinguish between hard cuts and the motion of large objects .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			1		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			13:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			14:1			0		1.0

Alignment 2399
To overcome this problem , motion-based features are computed for each video frame using the Lucas-Kanade point-based tracking functions provided in the OpenCV toolkit\footnote{http : //opencvlibrary.sourceforge.net / } .
To overcome this problem , motion-based features are computed for each video frame using the Lucas-Kanade point-based tracking functions provided in the OpenCV toolkit\footnote{http : //opencvlibrary.sourceforge.net / } .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 2400
The magnitude is computed from the motion vector for each frame .
The magnitude is computed from the motion vector for each frame .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 2401
Therefore , if the algorithm detected a cut between frames \MATH and \MATH , whose magnitude is larger than a threshold \MATH , these cuts are rejected since they are motions from large objects .
Therefore , if the algorithm detected a cut between frames \MATH and \MATH , whose magnitude is larger than the threshold \MATH , these cuts are rejected since they are the motions of large objects .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
31:1			30:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0

Alignment 2402
Finally , the short shots with less than 25 frames ( 1 second ) are removed .
Finally , short shots of less than 25 frames ( 1 second ) are removed .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0

Alignment 2403
The sub-shot segmentation algorithm in \CITE is used to divide shots into smaller units .
The sub-shot segmentation algorithm in \CITE is used to divide shots into smaller units .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 2404
A first frame of the shot is chosen as the base frame \MATH and next frame \MATH for comparison .
The first frame of the shot is chosen as the base frame \MATH and the next frame \MATH for a comparison .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0

Alignment 2405
The \MATH distance used to compute the distance of frame sequence until the sum of the sorted value of lower eight is larger than a threshold \MATH .
The \MATH distance used to compute the distance of the frame sequence until the sum of the sorted value of the lower eight is larger than the threshold \MATH . //[distance / length?]
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			15:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0

Alignment 2406
The frames from \MATH to \MATH , then , form a sub-shot and frame \MATH is used as the next base frame .
The frames from \MATH to \MATH , then , form a sub-shot and frame \MATH is used as the next base frame .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 2407
Finally , the short sub-shots with less than 25 frames are removed .
Finally , the short sub-shots of less than 25 frames are removed .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 2408
We employ a keyframe extraction algorithm proposed in \CITE to extract the representative keyframes from each sub-shot .
We use the keyframe extraction algorithm proposed in \CITE to extract the representative keyframes from each sub-shot .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			2		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 2409
In this approach , cosine distance is used to measure the difference between neighboring frames in each sub-shot .
In this approach , the cosine distance is used to measure the difference between neighboring frames in each sub-shot .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0

Alignment 2410
Keyframes are selected at the midpoints between two consecutive high curvature points where the high curvature points are detected from the curve of the cumulative frame difference .
Keyframes are selected at the midpoints between two consecutive high curvature points where the high curvature points are detected from the curve of the cumulative frame difference .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0

Alignment 2411
The characteristics of color bars are vertically averaged , and the color histograms for each block in the same column should be similar .
The characteristics of color bars are vertically averaged , and the color histograms for each block in the same column should be similar .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 2412
We employ the algorithm proposed in \CITE by using \MATH distance to compute histogram differences between any two neighboring blocks in each column .
We used the algorithm proposed in \CITE by using the \MATH distance to compute the histogram differences between any two neighboring blocks in each column .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			2		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0

Alignment 2413
Next , we sort these values into an ascending order .
Next , we sort these values into ascending order .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0

Alignment 2414
If the value of the \MATH is smaller than threshold \MATH , then these sub-shot is defined as a color bar sub-shot .
If the value of the \MATH is smaller than the threshold \MATH , then these sub-shots are defined as a color bar sub-shot .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			1		1.0
16:2			15:2			3		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0

Alignment 2415
From the properties of single color image , a dominant color in its global histogram is large .
From the properties of a single color image , the dominant color in its global histogram is large .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			8:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0

Alignment 2416
If the value of the \MATH of global color histogram is larger than threshold \MATH , then these sub-shots are defined as a single color sub-shot .
If the value of the \MATH of the global color histogram is larger than the threshold \MATH , then these sub-shots are defined as a single color sub-shot .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0

Alignment 2417
In rushes videos , there are many types of clapper boards , appearance but the same type of clapper boards is often used in the same movie .
In rushes videos , there are many types of clapper boards , but the same type of clapper board is often used in the same movie .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			1		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0

Alignment 2418
The clapper boards have many types , such as scale , rotation , and illumination changes .
There are many types of clapper boards , such as scale , rotation , and illumination changes .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			3:1			3		1.0
2:1			4:1			0		1.0
3:1			5:1			0		1.0
5:1			1:1			0		1.0
6:1			2:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0

Alignment 2419
The NDK algorithm , proposed in \CITE , is invariant to image scaling , translation , rotation , illumination changes , and affine or 3D projection .
The NDK algorithm , proposed in \CITE , is invariant to image scaling , translation , rotation , illumination changes , and affine or 3D projection .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 2420
A set of 80 example keyframes of clapper boards are extracted from the development set and used as a set of queries .
A set of 80 example keyframes of clapper boards were extracted from the development set and is used as a set of queries .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			2		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0

Alignment 2421
Next , we extract the keypoints of the keyframes given from section \REF and match them with the query .
Next , we extract the keypoints of the keyframes given from section \REF and match them with the query .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 2422
If a result of the NDK algorithm returns a match between a keyframe with a query then we define the sub-shot is a clapper board sub-shot .
If the result of the NDK algorithm returns a match from a keyframe with a query then the sub-shot is defined as a clapper board sub-shot .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			19:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			17:2			3		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 2423
The unused keyframes containing of story units for generate video summary are removed .
The unused keyframes containing story units for the generated video summary are removed .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
8:1			8:1			1		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 2424
However , rushes videos containing of repetitive story , such as retake scenes , are unedited .
However , rushes videos containing a repetitive story , such as a retake of scenes , are unedited .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			5:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0

Alignment 2425
To create the efficiently of rushes videos , the repetitive contents must be eliminated .
To efficiently create rushes videos , the repetitive contents must be eliminated .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			3:1			0		1.0
2:1			1:1			0		1.0
3:1			5:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0

Alignment 2426
Generally , a group of continuous contents often share some properties .
Generally , a group of continuous contents often share some properties .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 2427
From this characteristic , clustering technique can be used to separate the data into groups of similar contents .
With this characteristic in mind , a clustering technique can be used to separate the data into groups of similar contents .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
5:1			3:1			0		1.0
7:1			4:1			0		1.0
8:1			5:1			0		1.0
9:1			6:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0

Alignment 2428
Each group , called cluster , consists of contents that are similar between themselves and dissimilar to contents of other groups .
Each group , called a cluster , consists of contents that are similar between themselves and dissimilar to the contents of other groups .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0

Alignment 2429
GreedyRSC , proposed in \CITE , is used to find clusters with high precision and the number of clusters is automatically determined .
GreedyRSC , proposed in \CITE , is used to find clusters at high precision and the number of clusters is automatically determined .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:2			11:2			3		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 2430
To do the clustering on keyframes , three different features , including mean , variance , and skewness , are extracted from local color histogram .
To do clustering on keyframes , three different features , including the mean , variance , and skew , are extracted from the local color histogram .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			2:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			1		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0

Alignment 2431
These values are used to represent the keyframes content and defined as follows :
These values are used to represent the keyframes content and are defined as follows :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0

Alignment 2432
Figure \REF shows an example of clustering result .
Figure \REF shows an example of a clustering result .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0

Alignment 2433
So far , we completely remove the unused contents from rushes video and reduce repetition of the story contents .
So far , we have completely removed the unused contents from rushes videos and reduced any repetition of the story contents .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			1		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			1		1.0
13:1			12:1			0		1.0
14:1			13:1			1		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0

Alignment 2434
The objective of rushes summarization at TRECVID 2008 is to generate short summaries ( the upper limit of the duration of summary is 2\% of the original video ) , less repetitive of content , and must have many objects and events as possible .
The objective of rushes summarization at TRECVID 2008 is to generate short summaries ( the upper limit of the duration of a summary is 2\% of the original video ) , less repetitive content , and must have as many objects and events as possible .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			42:1			0		1.0
39:1			38:1			0		1.0
40:1			39:1			0		1.0
41:1			40:1			0		1.0
42:1			41:1			0		1.0
44:1			43:1			0		1.0
45:1			44:1			0		1.0

Alignment 2435
To reach this objective , the important keyframes should be selected to generate summary video .
To reach this objective , only the most important keyframes should be selected to generate a summary video .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0

Alignment 2436
To generate summary , we first compute its maximum duration in seconds \MATH ,
To generate a summary , we first compute its maximum duration in seconds \MATH ,
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0

Alignment 2437
where \MATH is the maximum duration for the summary .
where \MATH is the maximum duration for the summary .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 2438
Second , we compute quota length for each cluster based on the cluster size \MATH .
Second , we compute the quota length for each cluster based on the cluster size \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0

Alignment 2439
Third , merge consecutive sub-shots in each cluster into shots and compute the priority of each shot based on priority of shot weighted duration and shot weighted average motion magnitude using the following equation : \MATH</p>
Third , merge the consecutive sub-shots in each cluster into shots and compute the priority of each shot based on the priority of the shot weighted duration and shot weighted average motion magnitude using the following equation : \MATH</p>
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			31:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0
26:1			23:1			0		1.0
27:1			24:1			0		1.0
28:1			25:1			0		1.0
29:1			26:1			0		1.0
30:1			27:1			0		1.0
31:1			28:1			0		1.0
32:1			29:1			0		1.0
33:1			30:1			0		1.0
35:1			32:1			0		1.0
36:1			33:1			0		1.0
37:1			34:1			0		1.0
38:1			35:1			0		1.0

Alignment 2440
Next , these \MATH values are sorted into descending order and the first shot is selected .
Next , these \MATH values are sorted into descending order and the first shot is selected .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 2441
Forth , sort sub-shots in the selected shot in descending order based on the average motion magnitude .
Fourth , sub-shots in the selected shot in descending order are sorted based on the average motion magnitude .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0

Alignment 2442
Select sub-shots from top to bottom until the quota length for that shot is reached .
The sub-shots are selected from top to bottom until the quota length for that shot is reached .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
4:1			2:1			0		1.0
5:1			3:1			0		1.0
6:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0

Alignment 2443
Fifth , for each selected sub-shot , extract 25 frames ( 1 second ) around the middle to generate the final summary .
Fifth , for each selected sub-shot , 25 frames ( 1 second ) around the middle are extracted to generate the final summary .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0

Alignment 2444
This system is adopted with some modifications from the system developed for the same task last year \CITE .
This system has some modifications from the system developed for the same task last year \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			3		1.0
3:1			5:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0

Alignment 2445
Specifically , the original video is decomposed into segments , which are shots with hard cut transition .
Specifically , the original video is broken down into segments , which are shots with a hard cut transition .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0

Alignment 2446
These segments are further decomposed into fragments so that each fragment represents a portion of a scene .
These segments are further broken down into fragments so that each fragment represents a portion of a scene .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0

Alignment 2447
In order to reduce the computation time , we only extract a subset of frames from the original video by sampling at a five frame interval ( i.e extract frames 0th , 5th , 10th , and so on ) .
In order to reduce the computation time , we only extract a subset of the frames from the original video by sampling it at a five frame interval ( i.e. extract frames 0 , 5th , 10th , and so on ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			16:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
33:1			31:1			0		1.0
34:1			32:1			0		1.0
35:1			33:1			0		1.0
36:1			34:1			0		1.0
37:1			35:1			0		1.0
38:1			36:1			0		1.0
39:1			37:1			0		1.0
40:1			38:1			0		1.0
41:1			39:1			0		1.0
42:1			40:1			0		1.0

Alignment 2448
For each frame , we use grid color moments with the same configuration as in \CITE for feature representation .
For each frame , we use grid color moments with the same configuration as in \CITE for feature representation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 2449
The segment boundary , which is located at hard cut transition , is determined by using a loose threshold on the Euclidean distance between two consecutive frames .
The segment boundary , which is located at the hard cut transition , is determined by using a loose threshold on the Euclidean distance between two consecutive frames .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0

Alignment 2450
Meanwhile , the fragment boundary is determined by using a strict threshold to detect dramatic motion .
Meanwhile , the fragment boundary is determined by using a strict threshold to detect any dramatic motion .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0

Alignment 2451
Instead of selecting one keyframe to represent one fragment as many other systems do , we use all frames of each fragment for redundancy elimination .
Instead of selecting one keyframe to represent one fragment as many other systems do , we use all the frames of each fragment for the redundancy elimination .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0

Alignment 2452
We use GreedyRSC \CITE to do clustering on the set of all sampled frames extracted from the original video .
We use GreedyRSC \CITE to do the clustering on the set of all the sampled frames extracted from the original video .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0

Alignment 2453
The number of clusters is determined automatically by this method .
The number of clusters is determined automatically using this method .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 2454
Frames that belong to the same cluster are assigned the same label .
Frames that belong to the same cluster are assigned the same label .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 2455
By this discretization process , we can cast one fragment as one string whose characters are labels of its frames .
By this discretization process , we can cast one fragment as one string whose characters are the labels of its frames .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0

Alignment 2456
We compute the similarity value between two fragments by counting the number of shared characters between two strings and being normalized to the size of each string .
We compute the similarity between two fragments by counting the number of shared characters between two strings and being normalized to the size of each string .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0

Alignment 2457
If this value is larger than a threshold , these two segments are merged into one cluster .
If this value is larger than the threshold , these two segments are merged into one cluster .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 2458
We found that this approach is more effective than the approach using one keyframe for one fragment since the more number of keyframes is used , the more information is available to make right decision .
We found that this approach is more effective than the approach using one keyframe for one fragment since the more keyframes that are used , the more information is available to make the right decision .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			22:1			0		1.0
22:2			23:2			3		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0
31:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0

Alignment 2459
We select junk frames such as color bar frames , single color ( black or white ) frames to form the reference junk frame set .
We select junk frames such as color bar frames , and single color ( black or white ) frames to form the reference junk frame set .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0

Alignment 2460
To check whether a fragment is a junk , we compare the frames of this fragment to the frames of the reference junk frame set .
To check whether a fragment is junk , we compare the frames of this fragment to the frames of the reference junk frame set .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0

Alignment 2461
The similarity between two frames is the Euclidean distance between two grid color moment feature vectors .
The similarity between two frames is the Euclidean distance between two grid color moment feature vectors .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 2462
We empirically select thresholds for each type of junk .
We empirically select the thresholds for each type of junk .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0

Alignment 2463
If the similarity between one frame in the input fragment and one frame in the reference junk frame set is lower than the predefined thresholds, the input fragment is considered as junk and all fragments of the cluster containing junk fragment are eliminated .
If the similarity between one frame in the input fragment and one frame in the reference junk frame set is lower than the predefined thresholds, the input fragment is considered junk and all the fragments of the cluster containing the junk fragment are eliminated .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			31:1			0		1.0
31:1			32:1			0		1.0
32:1			33:1			0		1.0
33:1			36:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
40:1			39:1			0		1.0
41:1			40:1			0		1.0
42:1			41:1			0		1.0
43:1			42:1			0		1.0
44:1			43:1			0		1.0

Alignment 2464
In our system, we only check fragments that are located at two ends of the original video for reducing computation time .
In our system, we only check the fragments that are located at the two ends of the original video for reducing the computation time .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
22:1			19:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0

Alignment 2465
However, by using the clustering result, junk fragments that are not checked against the reference junk frame set are also removed .
However, by using the clustering result, junk fragments that are not checked against the reference junk frame set are also removed .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 2466
For each cluster, we merge adjacent fragments into longer fragments and select the longest fragment as the representative fragment to be included in the final summary .
For each cluster, we merge adjacent fragments into longer fragments and select the longest fragment as the representative fragment to be included in the final summary .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 2467
Since the length of these fragments is still larger than the maximum length of the final summary, we employ a simple strategy to shrink these fragments as follows .
Since the length of these fragments is still larger than the maximum length of the final summary, we use the following simple strategy to shrink these fragments .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			2		1.0
19:2			26:2			3		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			28:1			0		1.0

Alignment 2468
First, we assign a quota, which is the maximum duration, for each fragment by dividing the maximum duration for the summary to the number of clusters .
First, we assign a quota, which is the maximum duration, for each fragment by dividing the maximum duration for the summary to the number of clusters .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 2469
Second, for each fragment, we extract the portion which is expanded from the central of the fragment .
Second, for each fragment, we extract the portion that is expanded from the central part of the fragment .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:2			8:2			3		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0

Alignment 2470
This portion covers a duration twice as much as the fragment quota by selecting frames with sampling rate of 2 frames .
This portion covers a duration twice the size of the fragment quota by selecting the frames with a sampling rate of two frames .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:2			5:4			3		1.0
8:1			18:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:2			19:1			3		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0

Alignment 2471
Specifically, we select frames \MATH, \MATH, ..., \MATH, \MATH, ..., \MATH, \MATH, where \MATH is the middle frame of the fragment, and \MATH is half of number of frames computed from the quota\MATH and frame rate ( 25fps ) \MATH :
Specifically, we select frames \MATH, \MATH, ..., \MATH, \MATH, ..., \MATH, \MATH, where \MATH is the middle frame of the fragment, and \MATH is half the number of frames computed from the quota\MATH and the frame rate ( 25fps ) \MATH :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:2			24:2			3		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
37:1			36:1			0		1.0
38:1			37:1			0		1.0
39:1			38:1			0		1.0
40:1			39:1			0		1.0
41:1			40:1			0		1.0

Alignment 2472
We have tested our approaches with 40 videos of TRECVID 2008 test set .
We have tested our approaches on 40 videos from the TRECVID 2008 test set .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			6:1			0		1.0
7:2			7:2			3		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0

Alignment 2473
Table \REF shows a comparison between these approaches for the measures used in evaluation of this task \CITE .
Table \REF presents a comparison between these approaches for the measures used in evaluation of this task \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			2		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 2474
The system NII-2 achieves higher recall ( IN ) than the system NII-1 since NII-1 only uses one keyframe for each sub-shot and has shorter duration ( DU ) for summary videos .
The NII-2system achieves a higher recall ( IN ) than the NII-1 system because NII-1 only uses one keyframe for each sub-shot and has a shorter duration ( DU ) for summary videos .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			12:1			0		1.0
12:1			1:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0

Alignment 2475
However, NII-1 has a better score in quality .
However, NII-1 has better quality .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			4:1			0		1.0
4:1			7:1			0		1.0
5:1			8:1			0		1.0

Alignment 2476
The summary videos generated by NII-1 have fewer duplications ( RE ), are presented in a smoother way ( TE ) and are easy to judge for inclusions ( TT ) .
The summary videos generated by NII-1 have less duplication ( RE ), are presented in a smoother way ( TE ), and are easy to judge for inclusions ( TT ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			3		1.0
8:1			8:1			1		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0

Alignment 2477
In terms of efficiency, NII-2 is much better .
In terms of efficiency, NII-2 is much better .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 2478
The clapper board detection process using NDK consumes around half of processing time of NII-1 but performance is low due to large variations of clapper boards in videos ( see Figure \REF ) .
The clapper board detection process using NDK consumes around half of the processing time of NII-1, but its performance is low due to the large variations in clapper boards in the videos ( see Figure \REF ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
16:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0
27:1			24:1			0		1.0
28:1			25:1			0		1.0
29:1			26:1			0		1.0
31:1			27:1			0		1.0
32:1			28:1			0		1.0
33:1			29:1			0		1.0
34:1			30:1			0		1.0
35:1			31:1			0		1.0
36:1			32:1			0		1.0
37:1			33:1			0		1.0

Alignment 2479
The comparable performance in junk elimination of both systems suggests that simple methods are more favorable .
The comparable performance in the junk elimination of both systems suggests that simpler methods are more favorable .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			2		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0

Alignment 2480
In addition, by using simple features and sampling frames in the original video, NII-2 significantly speeds up the processing time ( computed from the time taking the input video to the time picking the summary video ) to quasi real-time .
In addition, by using simple features and sampling frames in the original video, NII-2 significantly increases the processing time ( computed from the time the input video is taken to the time the summary video is picked ) to quasi real-time .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			26:1			0		1.0
25:1			27:1			0		1.0
26:1			28:1			0		1.0
28:1			25:1			2		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			33:1			0		1.0
33:1			34:1			0		1.0
34:1			35:1			0		1.0
37:1			36:1			0		1.0
38:1			37:1			0		1.0
39:1			38:1			0		1.0
40:1			39:1			0		1.0
41:1			40:1			0		1.0

Alignment 2481
Practical summarization systems usually have good balance between fraction of inclusions and user-friendliness .
Practical summarization systems usually have a good balance between the fraction of inclusions and user-friendliness .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0

Alignment 2482
In Table \REF, we show performance of such systems .
In Table \REF, we present the performance of such systems .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			2		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0

Alignment 2483
The 14 systems listed in this table have IN score larger than the median ( 0.45 ); and other scores such as RE and TE larger than half of maximum score ( 2.5 ) .
The 14 systems listed in this table have an IN score that is above the median ( 0.45 ); and other scores, such as RE and TE, are larger than half of the maximum score ( 2.5 ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
28:1			25:1			0		1.0
29:1			26:1			0		1.0
30:1			27:1			0		1.0
31:1			28:1			0		1.0
33:1			29:1			0		1.0
34:1			30:1			0		1.0
35:1			31:1			0		1.0
36:1			32:1			0		1.0
37:1			33:1			0		1.0
38:1			34:1			0		1.0

Alignment 2484
Compared to other systems listed in this list, our system NII-2 is one of the fastest systems .
Compared to the other systems listed in this table, our NII-2system is one of the fastest .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
9:1			8:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			17:1			0		1.0

Alignment 2485
Compared to the other systems participating in this task of TRECVID 2008, NII-1 has good performance in measures such as DU and TT ( see Figure \REF and Figure \REF; while NII-2 achieves good performance in measure IN ( see Figure \REF ) .
Compared to the other systems participating in this task of TRECVID 2008, NII-1 performed better in such measures as DU and TT ( see Figure \REF and Figure \REF; while NII-2 performs well in the IN measure ( see Figure \REF ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			3		1.0
14:1			14:1			2		1.0
15:1			16:1			0		1.0
16:1			18:1			0		1.0
17:1			17:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0
33:1			35:1			0		1.0
35:1			37:1			0		1.0
36:1			36:1			0		1.0
37:1			38:1			0		1.0
38:1			39:1			0		1.0
39:1			40:1			0		1.0
40:1			41:1			0		1.0
41:1			42:1			0		1.0
42:1			43:1			0		1.0

Alignment 2486
One of most difficult steps is redundancy elimination .
One of the most difficult steps is redundancy elimination .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0

Alignment 2487
Lack of discriminative representation of segments and robust clustering methods is the main reason \CITE .
The lack of discriminative representation of the segments and robust clustering methods is the main reason \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0

Alignment 2488
Two typical cases that usually happen in clustering result are fragmentation and outliers .
Two typical cases that usually happen in clustering results are fragmentation and outliers .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			1		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 2489
Fragmentation is the case that samples of one cluster are put into several different clusters .
Fragmentation is where samples of one cluster are put into several different clusters .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:2			3		1.0
3:1			5:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0

Alignment 2490
Outliers are irrelevant and noisy samples in one cluster due to poor determination of cluster boundary .
Outliers are irrelevant and noisy samples in one cluster due to the poor determination of the cluster boundary .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0

Alignment 2491
Therefore, it is necessary to develop robust methods for detection of repetitive segments .
Therefore, it is necessary to develop robust methods for detecting repetitive segments .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			1		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0

Alignment 2492
Using all frames of one segment instead of using one keyframe as proposed in NII-2 is one of the efforts toward this direction .
Using all the frames of one segment instead of using one keyframe as proposed in NII-2 is one of the current efforts being made towards this end .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
21:1			19:1			0		1.0
24:1			20:1			1		1.0
25:2			21:2			3		1.0
27:1			23:1			0		1.0

Alignment 2493
Although the result is not very high as expected, we still believe that this approach is promising .
Although the results are not as high as expected, we still believe that this approach is promising .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:2			2:2			3		1.0
4:1			4:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 2494
We have presented two different approaches for generating short summary for rushes video .
We have presented two different approaches for generating a short summary for rushes videos .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			1		1.0
14:1			13:1			0		1.0

Alignment 2495
In the first approach, NII-1, redundancy elimination is done by doing clustering on the set of keyframes extracted from sub-shots .
In the first approach, NII-1, clustering the set of keyframes extracted from the sub-shots helps to eliminate redundancy .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			11:1			0		1.0
6:1			13:1			0		1.0
7:1			14:1			0		1.0
8:1			15:1			0		1.0
9:1			16:1			0		1.0
10:1			17:1			0		1.0
11:1			18:1			0		1.0
13:1			19:1			0		1.0
17:1			5:1			0		1.0
18:1			20:1			0		1.0

Alignment 2496
With each representative segment of each cluster, the portion that has high degree of motion is selected to form the summary .
With each representative segment of each cluster, the portion with the highest degree of motion is selected to form the summary .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
11:1			11:1			2		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 2497
This approach achieves good performance in usability score but low performance in recall .
This approach has a good usability score but is not very good at recall .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
4:1			3:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0

Alignment 2498
In the second approach, NII-2, all frames of each sub-shot are used to compute the similarity among sub-shots in clustering process .
In the second approach, NII-2, all the frames of each sub-shot are used to compute the similarity among the sub-shots in the clustering process .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
22:1			19:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0

Alignment 2499
With each representative segment of each cluster, the middle part is selected to form the summary with skipping rate of 2 frames .
With each representative segment of each cluster, the middle part is selected to form the summary with a skipping rate of two frames .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			2		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0

Alignment 2500
This approach achieves good performance in recall and reasonable performance in usability score .
This approach is good for recall and has a reasonably good usability score .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
8:2			8:1			3		1.0
10:1			3:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 2501
Compared to other systems participating in TRECVID 2008 summarization task, NII-2 is among best systems that have good balance between recall and usability .
Compared to other systems participating in the TRECVID 2008 summarization task, NII-2 is among the best systems with a good balance between recall and usability .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
18:2			16:2			3		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0

Alignment 2502
Face Retrieval Improvement by Learning Visual Consistency
Face Retrieval Improvement by the Learning of Visual Consistency
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0

Alignment 2503
Searching persons is one of the essential tasks required by users for image and video search engines .
Searching for images of people is one of the essential tasks required by users for image and video search engines .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			11:1			0		1.0
4:2			1:2			3		1.0
6:1			3:1			0		1.0
7:1			4:1			0		1.0
8:1			5:1			0		1.0
9:1			6:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0

Alignment 2504
However , the current search engines have limited capabilities for this task since they usually rely on texts associated with image and video which are likely to return many irrelevant results .
However , the current search engines have limited capabilities for this task since they usually rely on texts associated with image and video , which are likely to return many irrelevant results .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0

Alignment 2505
In this paper , we propose a method to effectively retrieve relevant faces for one person by learning visual consistency from results retrieved from text correlation based search engines .
We propose a method to effectively retrieve relevant faces for one person by learning visual consistency from results retrieved from text correlation based search engines .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			5:1			0		1.0
2:1			6:1			0		1.0
3:1			7:1			0		1.0
4:1			8:1			0		1.0
5:1			9:1			0		1.0
6:1			10:1			0		1.0
7:1			11:1			0		1.0
8:1			12:1			0		1.0
9:1			13:1			0		1.0
10:1			14:1			0		1.0
11:1			15:1			0		1.0
12:1			16:1			0		1.0
13:1			17:1			0		1.0
14:1			18:1			0		1.0
15:1			19:1			0		1.0
16:1			20:1			0		1.0
17:1			21:1			0		1.0
18:1			22:1			0		1.0
19:1			23:1			0		1.0
20:1			24:1			0		1.0
21:1			25:1			0		1.0
22:1			26:1			0		1.0
23:1			27:1			0		1.0
24:1			28:1			0		1.0
25:1			29:1			0		1.0

Alignment 2506
This problem is challenging because ( i ) no any label is provided leading to be difficult to use supervised-based ranking methods .
This problem is challenging because ( i ) there is no label provided making it difficult to use supervised-based ranking methods .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			11:1			0		1.0
10:1			8:1			0		1.0
11:1			10:1			0		1.0
12:1			12:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0

Alignment 2507
( ii ) current face recognition techniques are still unmatured with wild-face databases even with supervised learning methods .
( ii ) current face recognition techniques are still immature with wild-face databases even with supervised learning methods .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 2508
In the proposed method , we treat the problem as a classification problem which input faces are classified as 'personX' ( the queried person ) or 'non-personX' and the faces are ranked based on their relevant score that is inferred from the classifier 's probability output .
In the proposed method , we treat this problem as a classification problem in which input faces are classified as 'person-X' ( the queried person ) or 'non-person-X' , and the faces are ranked based on their relevant score inferred from the classifier 's probability output .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:2			7:2			3		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
33:1			31:1			0		1.0
34:1			32:1			0		1.0
35:1			33:1			0		1.0
36:1			34:1			0		1.0
37:1			35:1			0		1.0
38:1			36:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0

Alignment 2509
In order to train this classifier , we use a bagging-based framework to combine results from multiple weak classifiers which are trained using different subsets .
To train this classifier , we use a bagging-based framework to combine results from multiple weak classifiers , which are trained using different subsets .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			3:1			0		1.0
2:1			4:1			0		1.0
3:1			5:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0

Alignment 2510
These training subsets are extracted and labeled automatically from the rank list produced from the classifier trained from the previous step .
These training subsets are extracted and labeled automatically from the rank list produced from the classifier trained from the previous step .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 2511
In addition , outliers detection methods are used to produce the rank list for initialization .
In addition , outlier detection methods are used to produce the rank list for initialization .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			1		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 2512
Experimental results on various face sets retrieved from the caption of news photos show that the retrieval performance is improved after each iteration leading the final performance outperforms the baseline algorithms .
Experimental results on various face sets retrieved from the captions of news photos show that the retrieval performance improved after each iteration with the final performance outperforming the baseline algorithms .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			1		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			1		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0

Alignment 2513
With the rapid growing of digital technology , large image and video databases are available easier than ever to users .
With the rapid growth of digital technology , large image and video databases are more available than ever to users .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:2			3:2			3		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 2514
Therefore , effective and efficient tools are strongly needed for indexing and retrieving based on visual contents .
Therefore , effective and efficient tools are needed for indexing and retrieving based on visual contents .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0

Alignment 2515
One of the typical examples for this application is to search a specific person by providing his or her name .
A typical example for this application is searching for a specific person by providing his or her name .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			3:1			0		1.0
2:1			4:1			1		1.0
3:1			5:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0

Alignment 2516
Usually , most of current search engines use text associated with images or videos as a significant clue to return the results .
Usually , most current search engines use the texts associated with images or videos as significant clues for returning results .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			20:1			0		1.0
8:1			8:1			1		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			1		1.0
18:1			19:1			1		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0

Alignment 2517
However , since it is not necessary faces and names appear simultaneously and are aligned ( as shown in Figure \REF ) , the main drawback of this approach is existence of many irrelevant results that makes the retrieval performance very low .
However , other un-queried faces and names appear simultaneously and are aligned ( as shown in Figure \REF ) , which significantly lowers retrieval performance .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
4:1			7:1			0		1.0
5:1			8:1			0		1.0
6:1			9:1			0		1.0
7:1			10:1			0		1.0
8:1			11:1			0		1.0
9:1			12:1			0		1.0
10:1			13:1			0		1.0
11:1			14:1			0		1.0
12:1			15:1			0		1.0
13:1			16:1			0		1.0
14:1			17:1			0		1.0
15:1			18:1			0		1.0
16:1			19:1			0		1.0
17:1			20:1			0		1.0
18:1			21:1			0		1.0
19:1			22:1			0		1.0
23:1			38:1			0		1.0
24:1			39:1			0		1.0
25:1			42:1			0		1.0

Alignment 2518
Therefore it is necessary to improve the retrieval performance by taking into account visual information from the retrieved faces .
Therefore , it is necessary to improve the retrieval performance by taking into account the visual information from the retrieved faces .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0

Alignment 2519
This problem is challenging due to the following reasons :
This problem is challenging due to the following reasons :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 2520
-Large variations in face appearance due to pose changes , illumination conditions , occlusions and facial expressions make face recognition difficult even with state of the art techniques \CITE .
-Large variations in face appearance due to pose changes , illumination conditions , occlusions , and facial expressions make face recognition difficult even with state of the art techniques \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0

Alignment 2521
-The fact the retrieved face set consists of faces of several persons while no any label is given makes supervised learning methods as well as unsupervised learning methods such as \MATH -means inapplicable .
-The fact the retrieved face set consists of faces of several people with no label makes supervised learning methods as well as unsupervised learning methods such as , \MATH -means , inapplicable .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:2			11:1			3		1.0
13:1			13:1			0		1.0
14:1			15:1			0		1.0
15:1			18:1			0		1.0
16:1			19:1			0		1.0
17:1			20:1			0		1.0
18:1			21:1			0		1.0
19:1			22:1			0		1.0
20:1			23:1			0		1.0
21:1			24:1			0		1.0
22:1			25:1			0		1.0
23:1			26:1			0		1.0
24:1			27:1			0		1.0
25:1			28:1			0		1.0
26:1			29:1			0		1.0
28:1			30:1			0		1.0
29:1			31:1			0		1.0
31:1			32:1			0		1.0
32:1			33:1			0		1.0

Alignment 2522
In this paper , we propose a method to solve the mentioned problem .
We propose a method to solve the above-mentioned problem .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			5:1			0		1.0
2:1			6:1			0		1.0
3:1			7:1			0		1.0
4:1			8:1			0		1.0
5:1			9:1			0		1.0
6:1			10:1			0		1.0
8:1			12:1			0		1.0
9:1			13:1			0		1.0

Alignment 2523
The main idea is to learn visual consistency assumed to exist among the results returned from current text-based search engines .
The main idea is to assume that there is visual consistency among the results returned from current text-based search engines .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
7:2			10:1			3		1.0
9:1			6:1			0		1.0
10:1			7:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 2524
The method consists of two stages .
This method consists of two stages .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0

Alignment 2525
In the first stage , we explore local density of faces to identify potential candidates for relevant faces .
In the first stage , we explore local density of faces to identify potential candidates for relevant faces .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 2526
This stage is stemmed from the observation that faces relevant to the queried person tend to form dense clusters while irrelevant faces are very sparse since they look different from each other .
This stage is based on the observation that facial images of the queried person tend to form dense clusters while irrelevant facial images are sparse since they look different from each other .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			2		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
23:1			22:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0

Alignment 2527
We use an outliers detection method for this purpose .
We use an outlier detection method for this purpose .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			1		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 2528
The output is a rank list in which faces having larger number of neighbors within a distance are predicted as relevant ones and therefore are put on the top .
The output is a rank list in which faces with larger number of neighbors within a certain distance are considered as relevant and are therefore put at the top of the list . //[What do you mean by �gneighbors�h ? Do you mean the un-queried faces ? ]
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			22:1			0		1.0
23:1			24:1			0		1.0
24:1			23:1			0		1.0
25:1			25:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
32:1			29:1			0		1.0

Alignment 2529
Since the above ranking method is based on the number of neighbors , it is sensitive to the chosen distance .
Since the above ranking method is based on the number of neighbors , it is sensitive to the specified distance .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 2530
It is necessary to use the second stage to improve the rank list .
A second stage is necessary to improve this rank list .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			6:1			0		1.0
2:1			7:1			0		1.0
3:1			1:1			0		1.0
4:1			2:1			0		1.0
5:1			3:1			0		1.0
6:1			9:1			0		1.0
8:1			11:1			0		1.0
9:1			12:1			0		1.0
10:1			13:1			0		1.0

Alignment 2531
We model this problem as a classification problem which input faces are classified as personX ( the queried person ) or non-personX ( the irrelevant person ) .
We model this problem as a classification problem in which input faces are classified as person-X ( the queried person ) or non-person-X ( the irrelevant person ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0

Alignment 2532
The faces are ranked based on their relevant score that is inferred from the classifier 's probability output .
The faces are ranked based on their relevancy score that is inferred from the classifier 's probability output .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			1		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 2533
Since annotation data is not available , the rank list from the previous step is used to assign labels for a subset of faces .
Since annotation data is not available , the rank list from the previous step is used to assign labels for a subset of faces .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 2534
This subset then is used to train a classifier using a supervised method such as support vector machines ( SVM ) .
This subset then is used to train a classifier using supervised methods such as support vector machines ( SVM ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			1		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0

Alignment 2535
The trained classifier is used to re-rank faces in the original input set again .
The trained classifier is used to re-rank faces in the original input set .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			14:1			0		1.0

Alignment 2536
This step is repeated a number of times to get the final rank list .
This step is repeated a number of times to get the final rank list .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 2537
Since automatically assigning labels from the rank list is not reliable , the trained classifiers are weak .
Since automatically assigning labels from the rank list is not reliable , the trained classifiers are weak .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 2538
In order to get the final strong classifier , we employ the idea of ensemble learning \CITE in which weak classifiers trained on different subsets are combined to improve stability and classification accuracy of single classifiers .
In order to get the final strong classifier , we use the idea of ensemble learning \CITE in which weak classifiers trained on different subsets are combined to improve the stability and classification accuracy of single classifiers .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			2		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
37:1			36:1			0		1.0

Alignment 2539
This stage is effective for improving the rank list due to the following reasons :
This stage is effective for improving the rank list for the following reasons :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0

Alignment 2540
-Supervised learning methods such as SVM have strong theoretical background in finding optimal decision boundary even with existence of noisy data .
-Supervised learning methods such , as SVMs , provide a strong theoretical background in finding optimal decision boundary even with existence of noisy data .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0

Alignment 2541
Furthermore , with recent studies \CITE SVM classifiers can provide probability outputs that are suitable for ranking .
Furthermore , recent studies suggest that \CITE SVM classifiers provide probability outputs that are suitable for ranking .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 2542
-Bagging framework helps to leverage noises in the unsupervised labeling process .
-Bagging framework helps to leverage noises in the unsupervised labeling process .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 2543
Our contribution is two-fold :
Our contribution is two-fold :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0

Alignment 2544
-We propose a general framework to boost the face retrieval performance from the results retrieved from text correlation based search engines by learning visual consistency .
-We propose a general framework to boost the face retrieval performance from results retrieved from text correlation-based search engines by the learning of visual consistency .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			12:1			0		1.0
21:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 2545
It integrates seamlessly current existing data mining methods such as outliers detection , supervised learning and unsupervised learning based on bagging for a practical problem .
It seamlessly integrates current data mining methods such as outlier detection , supervised learning , and unsupervised learning based on bagging for a practical problem . //[What or who is �glearning�h visual consistency ? Are the search engines learning ? ]
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			2:1			0		1.0
2:1			1:1			0		1.0
3:1			3:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			1		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 2546
Our framework requires few parameters and works stably .
Our framework requires few parameters and works stably .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 2547
-We demonstrate feasibility of using tolerance of supervised learning methods when working with noisy datasets combined with ensemble learning to improve the final performance .
-We demonstrate the feasibility of using tolerance of supervised learning methods when working with noisy datasets combined with ensemble learning to improve the final performance .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0

Alignment 2548
There are several approaches proposed for general object classification rather than for face retrieval .
There are several more proposed approaches for general object classification than for those for face retrieval .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			4:1			0		1.0
5:1			3:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0

Alignment 2549
For example , as described in \CITE , objects are retrieved by an image search engine and then are re-ranked by learning visual consistencies from the retrieved objects .
For example , as described in \CITE , objects are retrieved by an image search engine and then are re-ranked by the learning of visual consistencies from the retrieved objects .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
22:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0

Alignment 2550
Compared to the problem of face retrieval based recognition , the problem of object classification is easier since classification of different object types such as airplane and non-airplane only needs to handle inter-variations between different categories while discriminating personA and personB requires to handle both intra-variations and inter-variations of the same category .
Compared to the problem of face-based recognition , the problem of object classification is easier since classification of different object types such as airplane and non-airplane only needs to handle inter-variations between different categories , while discriminating between person-A and person-B requires handling of both intra-variations and inter-variations of the same category .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0
24:1			26:1			0		1.0
25:1			27:1			0		1.0
26:1			28:1			0		1.0
27:1			29:1			0		1.0
28:1			30:1			0		1.0
29:1			31:1			0		1.0
30:1			32:1			0		1.0
31:1			33:1			0		1.0
32:1			34:1			0		1.0
33:1			35:1			0		1.0
35:1			36:1			0		1.0
36:1			37:1			0		1.0
39:1			39:1			0		1.0
41:1			41:1			0		1.0
43:1			48:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
49:1			49:1			0		1.0
50:1			50:1			0		1.0
51:1			51:1			0		1.0
52:1			52:1			0		1.0

Alignment 2551
Furthermore , in order to work in unsupervised mode , these approaches need a method to collect negative samples ( e.g. non-airplane ) which are inapplicable in our problem .
Furthermore , in order to work in unsupervised mode , these approaches need a method to collect negative samples ( e.g. non-airplane ) , which are inapplicable to our problem .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0

Alignment 2552
Working closely to our problem , in \cite{Ozkan06CVPR} , a graph based approach was proposed \CITEin which a graph is formed by faces as nodes and weights of edges linked between nodes are the similarity of faces .
A graph-based approach was proposed by \CITE , in which a graph is formed by faces as nodes , and the weights of edges linked between nodes are the similarity of faces , is closely related to our problem .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			12:1			0		1.0
3:1			13:1			0		1.0
4:1			14:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			16:1			0		1.0
10:1			17:1			0		1.0
11:1			18:1			0		1.0
12:1			19:1			0		1.0
13:1			20:1			0		1.0
14:1			21:1			0		1.0
15:1			22:1			0		1.0
16:1			23:1			0		1.0
17:1			24:1			0		1.0
18:1			8:1			0		1.0
19:1			25:1			0		1.0
20:1			33:1			0		1.0
21:1			26:1			0		1.0
22:1			27:1			0		1.0
23:1			28:1			0		1.0
24:1			29:1			0		1.0
25:1			30:1			0		1.0
26:1			31:1			0		1.0
27:1			32:1			0		1.0
29:1			34:1			0		1.0
30:1			35:1			0		1.0
31:1			36:1			0		1.0
34:1			1:1			0		1.0
36:1			2:1			0		1.0
37:1			3:1			0		1.0
38:1			4:1			0		1.0
39:1			37:1			0		1.0

Alignment 2553
By assuming that the number of faces of the queried person are larger than that of other persons , and these faces tend to form the most similar subset among the set of retrieved faces , this problem is considered equal to the problem of finding the densest subgraph of a full graph whose solution is available .
Assuming that the number of faces of the queried person is larger than that of others and that these faces tend to form the most similar subset among the set of retrieved faces , this problem is considered equal to the problem of finding the densest subgraph of a full graph with an available solution . //[Do graphs have solutions ? They just provide information .]
Line2Start:Length	Line1Start:Length	Module		Score
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			55:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			49:1			0		1.0
15:1			15:2			3		1.0
16:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0
24:1			26:1			0		1.0
25:1			27:1			0		1.0
26:1			28:1			0		1.0
27:1			29:1			0		1.0
28:1			30:1			0		1.0
29:1			31:1			0		1.0
30:1			32:1			0		1.0
31:1			33:1			0		1.0
32:1			34:1			0		1.0
33:1			35:1			0		1.0
34:1			36:1			0		1.0
35:1			37:1			0		1.0
36:1			38:1			0		1.0
37:1			39:1			0		1.0
38:1			40:1			0		1.0
39:1			41:1			0		1.0
40:1			42:1			0		1.0
41:1			43:1			0		1.0
42:1			44:1			0		1.0
43:1			45:1			0		1.0
44:1			46:1			0		1.0
45:1			47:1			0		1.0
46:1			48:1			0		1.0
48:1			50:1			0		1.0
49:1			51:1			0		1.0
50:1			52:1			0		1.0
53:1			56:1			0		1.0
54:1			54:1			0		1.0
55:1			57:1			0		1.0

Alignment 2554
Although , experimental results showed effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person .
Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0

Alignment 2555
Furthermore , choosing an optimal threshold to convert the initial graph into a binary graph is difficult and rather ad hoc due to the curse of dimensionality .
Furthermore , choosing an optimal threshold to convert the initial graph into a binary graph is difficult and rather ad hoc due to dimensionality .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			26:1			0		1.0
24:1			27:1			0		1.0

Alignment 2556
In another work \CITE , a clustering-based approach was proposed to associate names and faces in news photos .
In another work \CITE , a clustering-based approach was proposed for associating names and faces in news photos .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:2			9:2			3		1.0
11:1			11:1			1		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 2557
To solve the problem of ambiguity between several names and one face , a modified \MATH -means clustering process was used in which faces are assigned to the closest cluster ( each cluster corresponding to one name ) after a number of iterations .
To solve the problem of ambiguity between several names and one face , a modified \MATH -means clustering process was used in which faces are assigned to the closest cluster ( each cluster corresponding to one name ) after a number of iterations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0

Alignment 2558
Although the result was impressive , it is not easy to apply for our problem since a large number of irrelevant faces ( more than 12% ) are eliminated manually before doing clustering .
Although the result was impressive , it is not easy to apply it to our problem since a large number of irrelevant faces ( more than 12% ) are eliminated manually before performing clustering .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0

Alignment 2559
This paper is organized as follows : Section \REF introduces our proposed framework .
This paper is organized as follows : Section \REF introduces our proposed framework .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 2560
Section \REF introduce briefly typical outliers detection methods .
Section \REF briefly introduces typical outlier detection methods .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			1		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 2561
Experiments and results are described in section \REF .
Experiments and results are described in section \REF .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 2562
Finally , section \REF concludes the paper .
Finally , section \REF concludes the paper .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 2563
Given a set of faces returned by any text-based correlation search engine , our method performs a ranking process summarized as follows :
Given a set of faces returned by any text-based correlation search engine , our method is used to perform a ranking process summarized as follows :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
18:1			15:1			1		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0

Alignment 2564
-Step 1 : Detect eye positions , and then perform face normalizations .
-Step 1 : Detect eye positions , and then perform face normalizations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 2565
-Step 2 : Compute an eigenface space and project the input faces into this subspace .
-Step 2 : Compute an eigenface space and project the input faces into this subspace .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 2566
-Step 3 : Estimate ranks of faces using an outliers detection method mentioned in \REF .
-Step 3 : Estimate ranks of faces using an outlier detection method mentioned in \REF .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			1		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 2567
-Step 4 : Train a ensemble classifier \MATH using this rank list by Bag-Rank-SVM .
-Step 4 : Train an ensemble classifier \MATH using this rank list by Bag-Rank-SVM .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 2568
-Step 5 : Use the classifier \MATH to estimate the probability of faces in the original set .
-Step 5 : Use the classifier \MATH to estimate the probability of faces in the original set .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 2569
Rank these faces using their probability score .
Rank these faces using their probability scores .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			1		1.0
7:1			7:1			0		1.0

Alignment 2570
-Step 6 : Repeat steps from 4 and 5 $T$ times and return ranked faces produced by the last classifier \MATH to users .
-Step 6 : Repeat steps 4 and 5 $T$ times and return ranked faces produced by the last classifier \MATH to users .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0

Alignment 2571
Steps from 1 and 2 are typical for any face processing system and described in details in \REF .
Steps 1 and 2 are typical for any face processing system and described in detail in \REF .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			1		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0

Alignment 2572
Step 3 used to find initial ranks for faces is described in \REF .
Step 3 used to find initial ranks for faces described in \REF .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0

Alignment 2573
We use a simple outliers detection method for this step .
We used a simple outlier detection method for this step .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			1		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			1		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 2574
The Bag-Rank-SVM algorithm is described as follows :
The Bag-Rank-SVM algorithm is described as follows :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 2575
-Step 1 : Select a set \MATH including \MATH top ranked faces and then randomly select a subset \MATH from \MATH .
-Step 1 : Select a set \MATH including \MATH top ranked faces and then randomly select a subset \MATH from \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 2576
Label faces in \MATH as positive samples .
Label faces in \MATH as positive samples .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 2577
-Step 2 : Select a set \MATH including \MATH bottom ranked faces and then randomly select a subset \MATH from \MATH .
-Step 2 : Select a set \MATH including \MATH bottom ranked faces and then randomly select a subset \MATH from \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 2578
Label faces in \MATH as negative samples .
Label faces in \MATH as negative samples .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 2579
-Step 3 : Use \MATH and \MATH to train a weak classifier \MATH using LibSVM \CITE with probability outputs .
-Step 3 : Use \MATH and \MATH to train a weak classifier \MATH using LibSVM \CITE with probability outputs .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 2580
-Step 4 : Repeat steps from Step 1 to Step 3 \MATH times .
-Step 4 : Repeat steps Step 1 to Step 3 \MATH times .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0

Alignment 2581
-Step 5 : Return \MATH .
-Step 5 : Return \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0

Alignment 2582
Since it is not guaranteed top \MATH and bottom \MATH of faces in the rank list are correctly correspondent to faces of the queried person \MATH and faces of non person \MATH as shown in Figure \REF , selecting randomly subsets to train weak classifiers and then combining these classifiers might help to reduce risk of using noisy training sets .
Since it is not guaranteed that the top \MATH and bottom \MATH of faces in the rank list correctly correspond to the faces of the queried person-\MATH and faces of non person-\MATH as shown in Figure \REF , randomly selecting subsets to train weak classifiers , and then combining these classifiers might help reduce the risk of using noisy training sets .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			22:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			1		1.0
20:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
25:1			23:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			39:1			0		1.0
39:1			38:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
46:1			45:1			0		1.0
47:1			46:1			0		1.0
48:1			47:1			0		1.0
49:1			48:1			0		1.0
50:1			49:1			0		1.0
51:1			50:1			0		1.0
52:1			51:1			0		1.0
53:1			53:1			0		1.0
55:1			54:1			0		1.0
56:1			55:1			0		1.0
57:1			56:1			0		1.0
58:1			57:1			0		1.0
59:1			58:1			0		1.0
60:1			59:1			0		1.0
61:1			60:1			0		1.0

Alignment 2583
In our framework , outliers detection methods are used to initialize the rank list that is then used to label a subset of samples for training SVM classifiers .
In our framework , outlier detection methods are used to initialize the rank list that is then used to label a subset of samples for training SVM classifiers .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			1		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 2584
We introduce here two common outliers detection methods including distance-based outliers detection( DBO ) \CITE and local outliers factor based method ( LOF ) \CITE .
We introduce two common outlier detection methods , distance-based outlier detection ( DBO ) \CITE and local outlier factor-based method ( LOF ) \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			1		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			1		1.0
11:1			21:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			1		1.0
19:1			20:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0

Alignment 2585
Adapting the definition \CITE , given a set of objects \MATH , an object \MATH is considered as an outliers if there are fewer than \MATH neighboring objects in \MATH lying within a distance \MATH .
Adapting the definition from Knorr \CITE , given a set of objects \MATH , an object \MATH is considered as an outlier if there are fewer than \MATH neighboring objects in \MATH lying within a distance \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
5:1			3:1			0		1.0
6:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			1		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
33:1			31:1			0		1.0
34:1			32:1			0		1.0
35:1			33:1			0		1.0
36:1			34:1			0		1.0
37:1			35:1			0		1.0

Alignment 2586
The outliers detection process is summarized as follows :
This outlier detection process is summarized as follows :
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			1		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 2587
-Step 1 : Compute the distance between every pair of data objects .
-Step 1 : Compute the distance between every pair of data objects .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 2588
-Step 2 : For each object , compute \MATH which is the number of neighboring objects lying within a distance \MATH .
-Step 2 : For each object , compute \MATH , which is the number of neighboring objects lying within a distance \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0

Alignment 2589
-Step 3 : Rank objects based on their scores \MATH .
-Step 3 : Rank objects based on their scores \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 2590
In our experiments , the distance between two objects is Euclidean distance between two faces and is computed in the eigen-subspace ( described in section \REF ) .
In our experiments , the distance between two objects is the Euclidean distance between two faces and is computed in the eigen-subspace ( described in section \REF ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			19:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0

Alignment 2591
Figure \REF shows two examples of good and bad performance using this method for ranking relevant faces .
Figure \REF shows two examples of good and bad performances using this method for ranking relevant faces .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			1		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 2592
According to the method described in \CITE , the local outliers factor of an object \MATH is computed by the following steps and then used to rank faces :
According to the method described in \CITE , the local outlier factor of an object \MATH is computed by the following steps and then used to rank faces :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			1		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 2593
-Step 1 : For each data object \MATH compute \MATH ( the distance to the \MATH nearest neighbor ) and \MATH ( all points in a \MATH sphere ) .
-Step 1 : For each data object \MATH compute the \MATH ( the distance to the \MATH nearest neighbor ) and \MATH ( all points in a \MATH sphere ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			14:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0

Alignment 2594
- Step 2 : Compute reachability distance for each data object \MATH with respect to data object \MATH as : \MATH , where \MATH is distance from data object \MATH to data object \MATH .
- Step 2 : Compute the reachability distance for each data object \MATH with respect to data object \MATH as : \MATH , where \MATH is the distance from data object \MATH to data object \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
33:1			31:1			0		1.0
34:1			32:1			0		1.0
35:1			33:1			0		1.0
36:1			34:1			0		1.0

Alignment 2595
-Step 3 : Compute local reachability density of data object \MATH as inverse of the average reachability distance based on the \MATH ( minimum number of data objects ) nearest neighbors of data object \MATH .
-Step 3 : Compute local reachability density of data object \MATH as inverse of the average reachability distance based on the \MATH ( minimum number of data objects ) of the nearest neighbors to data object \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			31:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
34:1			32:1			0		1.0
35:1			33:1			0		1.0
36:1			34:1			0		1.0
37:1			35:1			0		1.0

Alignment 2596
-Step 4 : Compute LOF of data object \MATH as average of the ratios of the local reachability density of data object \MATH and local reachability density of \MATH nearest neighbors .
-Step 4 : Compute LOF of data object \MATH as the average of the ratios of the local reachability density of data object \MATH and local reachability density of \MATH of nearest neighbors .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			15:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
33:1			31:1			0		1.0

Alignment 2597
We used the dataset described in \CITE for our experiments .
We used the dataset described in \CITE for our experiments .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 2598
This dataset consists of approximately half a million news pictures and captions from Yahoo News over a period of roughly two years .
This dataset consisted of approximately half a million news pictures and captions from Yahoo News over a period of roughly two years .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:2			2:2			3		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 2599
Using a robust face detector , 44 , 773 faces were detected and normalized to the size of 86\MATH86 pixels .
Using a robust face detector , 44 , 773 faces were detected and normalized to the size of 86\MATH86 pixels .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 2600
After eliminating faces whose facial features are poorly detected by a rectification process and faces whose associated names are not extracted properly from corresponding captions , 30 , 281 faces were kept .
After eliminating faces whose facial features were poorly detected by a rectification process and faces whose associated names were not extracted properly from the corresponding captions , 30 , 281 faces were kept .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			2		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			30:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0

Alignment 2601
Figure \REF shows an example of a news photo and its caption .
Figure \REF shows an example of a news photo and its caption .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 2602
We selected sixteen celebrities who are government leaders such as George W . Bush ( US ) , Vladimir Putin ( Russia ) , Ziang Jemin ( China ) , Tony Blair ( UK ) , Junichiro Koizumi ( Japan ) , Roh Moo-hyun ( Korea ) , Abdullah Gul ( Turkey ) , and other key persons such as John Paul II ( the Former Pope ) , Kofi Annan and Hans Blix ( UN ) . These persons are selected since their appearances are highly frequent in the dataset \CITE .
We selected sixteen government leaders including George W . Bush ( US ) , Vladimir Putin ( Russia ) , Ziang Jemin ( China ) , Tony Blair ( UK ) , Junichiro Koizumi ( Japan ) , Roh Moo-hyun ( Korea ) , Abdullah Gul ( Turkey ) , and other key individuals such as John Paul II ( the Former Pope ) and Kofi Annan and Hans Blix ( UN ) since their images appeared frequently in the dataset \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			6:1			0		1.0
4:1			7:1			0		1.0
6:1			10:1			0		1.0
7:1			11:1			0		1.0
8:1			12:1			0		1.0
9:1			13:1			0		1.0
10:1			14:1			0		1.0
11:1			15:1			0		1.0
12:1			16:1			0		1.0
13:1			17:1			0		1.0
14:1			18:1			0		1.0
15:1			19:1			0		1.0
16:1			20:1			0		1.0
17:1			21:1			0		1.0
18:1			22:1			0		1.0
19:1			23:1			0		1.0
20:1			24:1			0		1.0
21:1			25:1			0		1.0
22:1			26:1			0		1.0
23:1			27:1			0		1.0
24:1			28:1			0		1.0
25:1			29:1			0		1.0
26:1			30:1			0		1.0
27:1			31:1			0		1.0
28:1			32:1			0		1.0
29:1			33:1			0		1.0
30:1			34:1			0		1.0
31:1			35:1			0		1.0
32:1			36:1			0		1.0
33:1			37:1			0		1.0
34:1			38:1			0		1.0
35:1			39:1			0		1.0
36:1			40:1			0		1.0
37:1			41:1			0		1.0
38:1			42:1			0		1.0
39:1			43:1			0		1.0
40:1			44:1			0		1.0
41:1			45:1			0		1.0
42:1			46:1			0		1.0
43:1			47:1			0		1.0
44:1			48:1			0		1.0
45:1			49:1			0		1.0
46:1			50:1			0		1.0
47:1			51:1			0		1.0
48:1			52:1			0		1.0
49:1			53:1			0		1.0
50:1			54:1			0		1.0
51:1			55:1			0		1.0
52:1			56:1			0		1.0
53:1			57:1			2		1.0
54:1			58:1			0		1.0
55:1			59:1			0		1.0
56:1			60:1			0		1.0
57:1			61:1			0		1.0
58:1			62:1			0		1.0
59:1			63:1			0		1.0
60:1			64:1			0		1.0
61:1			65:1			0		1.0
62:1			66:1			0		1.0
63:1			67:1			0		1.0
64:1			71:1			0		1.0
65:1			69:1			0		1.0
66:1			70:1			0		1.0
68:1			72:1			0		1.0
69:1			73:1			0		1.0
70:1			74:1			0		1.0
71:1			75:1			0		1.0
72:1			76:1			0		1.0
73:1			82:1			0		1.0
74:1			83:1			0		1.0
76:1			84:1			1		1.0
77:2			87:2			3		1.0
79:1			89:1			0		1.0
80:1			90:1			0		1.0
81:1			91:1			0		1.0
82:1			92:1			0		1.0

Alignment 2603
For each person , variations of his name are collected . For example , George W . Bush , President Bush , U . S . President , etc are variations of U . S . President Bush .
For each person , variations of his name were collected . For example , George W . Bush , President Bush , U . S . President , etc are variations of U . S . President Bush .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:2			8:2			3		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0

Alignment 2604
We indexed image captions and then used this index to retrieve faces associated with the captions containing names of the queried person .
We indexed image captions and then used this index to retrieve faces associated with the captions containing names of the queried person .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 2605
The faces retrieved from different names of each person are merged into a set used for our ranking process .
The faces retrieved from different names of each person were merged into a set used for our ranking process .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			2		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 2606
Figure \REF shows faces retrieved when searching Mr . Kofi Annan .
Figure \REF shows faces retrieved when searching Mr . Kofi Annan .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 2607
Figure \REF shows the distribution of retrieved faces from this method and the corresponding number of relevant faces for these ten persons .
Figure \REF shows the distribution of retrieved faces from this method and the corresponding number of relevant faces for these ten individuals .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			2		1.0
22:1			22:1			0		1.0

Alignment 2608
In total , 3 , 907 faces are retrieved in which 2 , 094 faces are relevant .
In total , 3 , 907 faces were retrieved in which 2 , 094 faces were relevant .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			2		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			2		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 2609
On average , the precision is 52.49% .
On average , the precision was 52.49% . //[precision / accuracy ? ]
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			2		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 2610
We used an eye detector to detect eye positions of detected faces .
We used an eye detector to detect eye positions of detected faces .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 2611
These eye positions were used to align faces to a predefined canonical pose .
These eye positions were used to align faces to a predefined canonical pose .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 2612
To compensate for illumination effects , the subtraction of the bestfit brightness plane followed by histogram equalization was applied .
To compensate for illumination effects , the subtraction of the best-fit brightness plane followed by histogram equalization was applied .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 2613
This normalization process is shown in Figure \REF .
This normalization process is shown in Figure \REF .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 2614
We then used PCA \CITE to reduce the number of dimensions of the feature vector for face representation .
We then used principle component analysis \CITE to reduce the number of dimensions of the feature vector for face representation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
6:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0

Alignment 2615
Eigenfaces were computed from the original face set returned by the text based query method .
Eigenfaces were computed from the original face set returned by the text-based query method .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0

Alignment 2616
The number of eigenfaces was selected so that 97% of the total energy are retained \CITE .
A number of eigenfaces was selected so that 97% of the total energy was retained \CITE . //[What is that number ? ]
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			2		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 2617
We evaluated the retrieval performance with measures that are popularly used in information retrieval such as precision , recall and average precision .
We evaluated the retrieval performance with measures that are commonly used in information retrieval such as precision , recall , and average precision .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			3		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0

Alignment 2618
Given a queried person , assuming that \MATH is the total number of faces returned , \MATH is the number of relevant faces , \MATH is the number of relevant faces , we calculate recall and precision as follows :
Given a queried person , assuming that \MATH is the total number of faces returned , \MATH is the number of relevant faces , \MATH is the number of relevant faces , we calculated recall and precision as follows : //[Nrel and Nhit are exactly the same here . They should be different .]
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:4			18:3			3		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:3			9:4			3		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			1		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0

Alignment 2619
Precision and recall only evaluate the quality of an unordered set of retrieved faces .
Precision and recall only evaluate the quality of an unordered set of retrieved faces .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 2620
To evaluate ranked lists , the average precision is used .
To evaluate ranked lists , average precision is used .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0

Alignment 2621
The average precision is computed by taking average of the interpolated precision measured at the 11 recall levels of 0.0 , 0.1 , 0.2 , ... , 1.0 .
The average precision is computed by taking the average of the interpolated precision measured at the 11 recall levels of 0.0 , 0.1 , 0.2 , ... , 1.0 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0

Alignment 2622
The interpolated precision \MATH at a certain recall level \MATH is defined as the highest precision found for any recall level \MATH :
The interpolated precision \MATH at a certain recall level \MATH is defined as the highest precision found for any recall level \MATH :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 2623
In addition , to evaluate performance of multiple queries , we used mean average precision that is the mean of average precisions computed from queries .
In addition , to evaluate the performance of multiple queries , we used mean average precision , which is the mean of average precisions computed from queries .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			17:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
17:2			15:2			3		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0

Alignment 2624
We show in Figure \REF the retrieval performance of outliers detection methods and the baseline method using text correlation .
We show in Figure \REF the retrieval performance of the outlier detection methods and the baseline method using text correlation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			9:1			1		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0

Alignment 2625
In the baseline method , faces are sorted by the time that the associated news article is published .
In the baseline method , faces were sorted by the time the associated news article was published .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			2		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			2		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0

Alignment 2626
It indicates that DBO-based method outperforms the others .
It indicated that the DBO-based method outperformed the others .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:2			1:2			3		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			1		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0

Alignment 2627
The baseline method performs the worst .
The baseline method performed the worst .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			1		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0

Alignment 2628
LOF-based method tends to be less sensitive when the threshold is changed .
The LOF-based method tends to be less sensitive when the threshold is changed .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			0:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0

Alignment 2629
This suggests that the input face sets are quite dense .
This suggests that the input face sets were quite dense .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:2			7:2			3		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 2630
We studied effect of choosing number of times \MATH in the Bag-Rank-SVM algorithm .
We studied the effect of choosing the number of times \MATH appeared in the Bag-Rank-SVM algorithm .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0

Alignment 2631
We used DBO as the method for making the initial rank list from which 30 training subsets were generated and used for training SVM classifiers using linear kernel with probability output .
We used DBO as the method for making the initial rank list from which 30 training subsets were generated and used for training SVM classifiers using linear kernels with probability output .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			1		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0

Alignment 2632
To select one subset , we set \MATH and \MATH which means 20% of highest ranked faces are used for \MATH and 30% of lowest ranked faces are used for \MATH .
To select one subset , we set \MATH and \MATH which means 20% of the highest ranked faces were used for \MATH and 30% of the lowest ranked faces were used for \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:2			17:2			3		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:2			27:2			3		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
33:1			31:1			0		1.0

Alignment 2633
The subsets \MATH and \MATH are generated by randomly selecting with replacement 70% samples of \MATH amd \MATH .
The subsets \MATH and \MATH were generated by randomly selecting with replacement 70% samples of \MATH and \MATH .[�gWith replacement�h does not make sense here . I am not sure what you want to say .]
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:2			5:2			3		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
17:1			17:1			0		1.0
25:1			18:1			0		1.0

Alignment 2634
Figure \REF shows performance of single classifiers and ensemble classifiers .
Figure \REF shows the performance of single and ensemble classifiers .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 2635
It suggests that the performance does not change significantly after 5 iterations .
It suggests that the performance does not change significantly after five iterations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			2		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 2636
In addition , the performance of the ranking process is improved when using the ensemble classifier .
In addition , the performance of the ranking process improved when the ensemble classifier was used .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 2637
We set the number of iterations for the Bag-Rank-SVM algorithm being 5 and set the number of iterations of the outer loop $T=30$ to see how much the final performance changes .
We set the number of iterations for the Bag-Rank-SVM algorithm at five and set the number of iterations of the outer loop $T=30$ to see how much the final performance changes .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			11:1			2		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0

Alignment 2638
As shown in Figure \REF , the performance does not change so much after 5 iterations .
As shown in Figure \REF , the performance did not change much after five iterations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			2		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0

Alignment 2639
From these experiments , \MATH and \MATH are suitable values for the proposed method .
From these experiments , \MATH and \MATH are suitable values for the proposed method .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 2640
The performance of different methods shown in Figure \REF indicates that our proposed method outperforms the distance-based outliers detection method and has comparable performance with the supervised method using 5% annotation data .
The performance of different methods shown in Figure \REF indicates that our proposed method outperformed the distance-based outlier detection method and performed comparable to the supervised method using 5% annotation data .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			1		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			1		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			3		1.0
22:1			22:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0
31:1			32:1			0		1.0

Alignment 2641
As shown in Figure \REF , \REF , \REF , our proposed method produces better results in terms of average precision in which relevant faces are put on the top of the returned list .
As shown in Figures \REF , \REF , \REF , our proposed method produced better results in terms of average precision in which relevant faces were put at the top of the returned list .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			1		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			1		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			2		1.0
26:1			26:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0

Alignment 2642
We present a method to effectively rank faces retrieved by text-based correlation methods when searching a specific person .
We presented a method for effectively ranking faces retrieved using text-based correlation methods when searching for a specific person .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			1		1.0
2:1			2:1			0		1.0
3:2			3:2			3		1.0
5:1			5:1			0		1.0
6:1			6:1			1		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0

Alignment 2643
Using the rank list estimated from the previous steps , we automatically select a subset of positive and negative samples to train a classifier using SVM with probability outputs .
Using the rank list estimated from the previous steps , we automatically selected a subset of positive and negative samples to train a classifier using SVM with probability outputs . //[Since this is the conclusion , you might want to be more specific on what �gthe previous steps�h are . ]
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			1		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0

Alignment 2644
This classifier is used to rank input faces for the next step .
This classifier was used to rank input faces for the next step .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:2			2:2			3		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 2645
Since labels of training sets are still noisy , the classified trained by these datasets are weak .
Since the labels of training sets were still noisy , the classifiers trained from these datasets were weak .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			2		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			1		1.0
12:1			11:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			2		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0

Alignment 2646
By combining multiple weak classifiers in a bagging framework , the final strong classifier is constructed and produce good results .
By combining multiple weak classifiers in a bagging framework , we constructed the final strong classifier , which produced good results .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			15:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
18:1			17:1			1		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0

Alignment 2647
To get initial rank for the first step , we propose to use common outliers detection method .
To obtain the initial rank for the first step , we proposed using a common outlier detection method .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			2		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:2			3		1.0
12:1			12:1			1		1.0
14:1			13:1			0		1.0
15:1			14:1			1		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0

Alignment 2648
Experiments on a large number of persons with thousands of retrieved images show effectiveness of the proposed method .
Experiments on a large number of persons with thousands of retrieved images showed the effectiveness of the proposed method .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			1		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0

Alignment 2649
Face detection , tracking , and recognition for broadcast video
Face detection , tracking , and recognition for broadcast video
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 2650
Human face processing techniques for broadcast video including face detection , tracking and recognition have long been a topic that attracts much research interest due to its crucial value in various applications including video structuring , indexing , retrieval , summarization , etc.
Human face processing techniques for broadcast video , including face detection , tracking , and recognition , have long been a topic that has attracted a lot of research interest due to its crucial value in various applications , such as in video structuring , indexing , retrieval , and summarization .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			35:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			37:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			39:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			0		1.0
24:1			20:1			1		1.0
25:3			21:1			3		1.0
28:1			22:1			0		1.0
29:1			23:1			0		1.0
30:1			24:1			0		1.0
31:1			25:1			0		1.0
32:1			26:1			0		1.0
33:1			27:1			0		1.0
34:1			28:1			0		1.0
35:1			29:1			0		1.0
36:1			30:1			0		1.0
37:1			31:1			0		1.0
38:1			41:1			0		1.0
42:1			33:1			0		1.0
43:1			34:1			0		1.0
45:1			36:1			0		1.0
47:1			38:1			0		1.0
50:1			40:1			0		1.0

Alignment 2651
The main reason is human face provides rich information for people 's appearance such as a government leader in a news video , a pitcher in a sport video or a hero in a movie , and is the basis for interpreting facts .
The main reason for this is that the human face provides rich information for people 's appearances , such as for a government leader in a news video , a pitcher in a sports video or a hero in a movie , and is the basis for interpreting facts .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			40:1			0		1.0
5:1			3:1			0		1.0
7:1			38:1			0		1.0
8:1			4:1			0		1.0
9:1			5:1			0		1.0
10:1			6:1			0		1.0
11:1			7:1			0		1.0
12:1			8:1			0		1.0
13:1			9:1			0		1.0
14:1			10:1			0		1.0
15:1			11:1			0		1.0
16:1			12:1			1		1.0
17:1			35:1			0		1.0
18:1			13:1			0		1.0
19:1			14:1			0		1.0
21:1			15:1			0		1.0
22:1			16:1			0		1.0
23:1			17:1			0		1.0
24:1			18:1			0		1.0
25:1			19:1			0		1.0
26:1			20:1			0		1.0
27:1			21:1			0		1.0
28:1			22:1			0		1.0
29:1			23:1			0		1.0
30:1			24:1			0		1.0
31:1			25:1			0		1.0
32:1			26:1			0		1.0
33:1			27:1			1		1.0
34:1			28:1			0		1.0
35:1			29:1			0		1.0
36:1			30:1			0		1.0
37:1			31:1			0		1.0
38:1			32:1			0		1.0
39:1			33:1			0		1.0
40:1			34:1			0		1.0
42:1			36:1			0		1.0
43:1			37:1			0		1.0
45:1			39:1			0		1.0
47:1			41:1			0		1.0
48:1			42:1			0		1.0
49:1			43:1			0		1.0

Alignment 2652
This article describes state-of-the art techniques for face detection , tracking and recognition with application to broadcast video .
This article describes some state-of-the art techniques for face detection , tracking , and recognition with applications to broadcast video .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			1		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0

Alignment 2653
Face detection which is the task of localizing faces in an input image is fundamental for any face processing system .
Face detection , which is the task of localizing faces in an input image , is a fundamental part of any face processing system .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
15:1			13:1			0		1.0
17:1			14:1			0		1.0
20:1			16:1			0		1.0
21:1			17:1			0		1.0
22:1			18:1			0		1.0
23:1			19:1			0		1.0
24:1			20:1			0		1.0

Alignment 2654
The extracted faces can then be used for initializing of face tracking or automatic face recognition .
The extracted faces can then be used for initializing face tracking or automatic face recognition .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0

Alignment 2655
An ideal face detector should possess the following characteristics :
An ideal face detector should possess the following characteristics :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 2656
- Robustness : it should be capable of handling appearance variations of pose changes , size , illuminations , occlusions , complex background , facial expressions , low resolutions , etc.
- Robustness : it should be capable of handling appearance variations , such as pose changes , size , illuminations , occlusions , complex backgrounds , facial expressions , and low resolutions .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			29:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			1		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
30:1			27:1			0		1.0
31:1			28:1			0		1.0

Alignment 2657
- Fastness : it should be fast for real-time processing which is an important factor in processing large video archives .
- Quickness : it should be fast in order to perform real-time processing , which is an important factor in processing large video archives .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
14:1			10:1			0		1.0
15:1			11:1			0		1.0
16:1			12:1			0		1.0
17:1			13:1			0		1.0
18:1			14:1			0		1.0
19:1			15:1			0		1.0
20:1			16:1			0		1.0
21:1			17:1			0		1.0
22:1			18:1			0		1.0
23:1			19:1			0		1.0
24:1			20:1			0		1.0

Alignment 2658
- Simplicity : The training process should be simple .
- Simplicity : the training process should be simple .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 2659
For example , the training time is short , the number of parameters is small and training samples are collected without costly .
For example , the training time is short , the number of parameters is small , and training samples are collected cheaply .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
22:1			22:1			0		1.0

Alignment 2660
Many approaches have been proposed for building fast and robust face detectors \CITE .
Many approaches have been proposed for building faster and more robust face detectors \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			2		1.0
8:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0

Alignment 2661
Among them , those using advanced learning methods such as neural network , support vector machines and boosting are the best .
Among them , those using advanced learning methods , such as neural network , support vector machines and boosting , are the best .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0

Alignment 2662
Typically , detecting faces in an image includes the following steps :
Typically , detecting the faces in an image takes the following steps :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0

Alignment 2663
- Window scanning : in order to detect faces at multiple locations and sizes , a fixed window size ( e.g. 24x24 pixels ) is used to extract image patterns at every location and scale .
- Window scanning : in order to detect faces at multiple locations and sizes , a fixed window size ( e.g. 24 x 24 pixels ) is used to extract image patterns at every location and scale .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
33:1			31:1			0		1.0
34:1			32:1			0		1.0
35:1			33:1			0		1.0
36:1			34:1			0		1.0
37:1			35:1			0		1.0

Alignment 2664
The number of patterns extracted from one 320x240 frame image is large , approximately 160 ,000 in which only a small number of patterns containing face .
The number of patterns extracted from a 320 x 240 frame image is large , approximately 160 ,000 , in which only a small number of patterns contain a face .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0
26:1			23:1			0		1.0
27:1			24:1			1		1.0
29:1			25:1			0		1.0
30:1			26:1			0		1.0

Alignment 2665
- Feature extraction : given an image pattern , features are extracted .
- Feature extraction : given an image pattern , the features are extracted .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0

Alignment 2666
The most popular feature type is Haar wavelet since it is very fast to compute using the integral image \CITE .
The most popular feature type is the Haar wavelet because it is very fast to compute using the integral image \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0

Alignment 2667
Other feature types can be listed including pixel intensity \CITE , local binary patterns \CITE and edge orientation histogram \CITE .
Other feature types can be listed including the pixel intensity \CITE , local binary patterns \CITE , and edge orientation histogram \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0

Alignment 2668
- Classification : the extracted features is passed through a classifier which is trained beforehand to classify the input pattern associated with these features as a face or a non-face .
- Classification : the extracted features are passed through a classifier that has been previously trained to classify the input pattern associated with these features as a face or a non-face . //[trained / programmed ?]
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			2		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:2			12:1			3		1.0
14:1			14:1			3		1.0
15:1			13:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0

Alignment 2669
- Merging overlapping detections : since the classifier is insensitive to small changes in translation and scale , there might be multiple detections around each face .
- Merging overlapping detections : since the classifier is insensitive to small changes in translation and scale , there might be multiple detections around each face .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 2670
In order to return one final detection per face , it is necessary to combine overlapping detections into a single detection .
In order to return a single final detection per face , it is necessary to combine the overlapping detections into a single detection .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			2		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0

Alignment 2671
Since the number of processed patterns is large while the vast majority of them are non-face , a single classifier based systems such as neural network \CITE and support vector machines \CITE are usually slow .
Since the vast majority of processed patterns are non-face , the single classifier based systems , such as the neural network \CITE and the support vector machines \CITE , are usually slow .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			10:1			0		1.0
3:1			11:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			14:1			0		1.0
8:1			15:1			0		1.0
9:1			16:1			0		1.0
10:2			17:2			3		1.0
12:1			19:1			0		1.0
13:1			20:1			0		1.0
14:1			21:1			0		1.0
16:1			22:1			0		1.0
17:1			23:1			0		1.0
18:1			9:1			0		1.0
19:1			24:1			0		1.0
20:1			25:1			0		1.0
21:1			26:1			0		1.0
22:1			27:1			0		1.0
24:1			28:1			0		1.0
25:1			29:1			0		1.0
26:1			30:1			0		1.0
27:1			31:1			0		1.0
29:1			32:1			0		1.0
30:1			33:1			0		1.0
31:1			34:1			0		1.0
32:1			35:1			0		1.0

Alignment 2672
To overcome this problem , a combination of simple-to-complex classifiers has been proposed \CITE leading to the first real-time robust face detector in the world .
To overcome this problem , a combination of simple-to-complex classifiers has been proposed \CITE leading to the first real-time robust face detector in the world .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 2673
In this structure , fast and simple classifiers are used as filters at the earliest stages to quickly reject a large number of non-face patterns and slower yet more accurate classifiers are then used for classifying face-like patterns .
In this structure , fast and simple classifiers are used as filters in the earliest stages to quickly reject a large number of the non-face patterns and then slower but more accurate classifiers are used for classifying the face-like patterns .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			32:1			0		1.0
28:1			26:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
33:1			31:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
38:1			36:1			0		1.0
39:1			37:1			0		1.0
40:1			38:1			0		1.0

Alignment 2674
In this way , the complexity of classifiers can be adapted corresponding to the increasing difficulty in the input patterns .
In this way , the complexity of classifiers can be adapted to correspond to the increasing difficulty with the input patterns .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			11:1			1		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0

Alignment 2675
Training classifiers usually consists of several steps :
Training classifiers usually consist of the following steps :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			1		1.0
4:1			4:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0

Alignment 2676
- Training set preparation : Supervised learning methods require a large number of training samples to obtain accurate classifiers .
- Training set preparation : Supervised learning methods require a large number of training samples to obtain accurate classifiers .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 2677
The training samples are patterns that must be labeled as face ( positive sample ) or non-face ( negative sample ) in advance .
The training samples are patterns that must be labeled as face ( positive samples ) or non-face ( negative samples ) in advance .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			1		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			1		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 2678
Face patterns are manually collected in images containing faces and then are scaled to the same size and normalized to a canonical pose which eyes , mouth and nose are aligned .
Face patterns are manually collected from images containing faces and then are scaled to the same size and normalized to a canonical pose in which the eyes , mouth , and nose are aligned .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			5:1			0		1.0
24:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
30:1			27:1			0		1.0
31:1			28:1			0		1.0
32:1			29:1			0		1.0
33:1			30:1			0		1.0
34:1			31:1			0		1.0

Alignment 2679
Then these face patterns can be used to generate other artificial faces by randomly rotating the images ( about their center points ) up to 10 degree , scaling between 90% and 110% , translating up to half a pixel , and mirroring to enlarge the number of positive samples \CITE .
Then these face patterns can be used to generate other artificial faces by randomly rotating the images ( about their center points ) by up to 10 degrees , scaling them between 90 and 110% , translating them up to half a pixel , and mirroring them to enlarge the number of positive samples \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			1		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
31:1			29:1			0		1.0
33:1			31:1			0		1.0
34:1			32:1			0		1.0
35:1			33:1			0		1.0
36:1			34:1			0		1.0
38:1			35:1			0		1.0
39:1			36:1			0		1.0
40:1			37:1			0		1.0
41:1			38:1			0		1.0
42:1			39:1			0		1.0
43:1			40:1			0		1.0
44:1			41:1			0		1.0
45:1			42:1			0		1.0
47:1			43:1			0		1.0
48:1			44:1			0		1.0
49:1			45:1			0		1.0
50:1			46:1			0		1.0
51:1			47:1			0		1.0
52:1			48:1			0		1.0
53:1			49:1			0		1.0
54:1			50:1			0		1.0
55:1			51:1			0		1.0

Alignment 2680
Collecting non-face patterns are usually done automatically by scanning through images which contain no faces .
The collection of non-face patterns is usually done automatically by scanning through images which contain no faces .
Line2Start:Length	Line1Start:Length	Module		Score
3:1			1:1			0		1.0
4:1			2:1			0		1.0
5:1			3:1			2		1.0
6:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0

Alignment 2681
The accurate classifier described in \CITE requires about five thousand original face patterns and hundreds of million non-face patterns extracted from 9 ,500 non-face images .
The accurate classifier described in \CITE requires about five thousand original face patterns and hundreds of millions of non-face patterns extracted from 9 ,500 non-face images .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:2			16:1			3		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0

Alignment 2682
In \CITE a smaller number of training samples can be used to build a robust face detector by using edge orientation histogram feature .
In \CITE a smaller number of training samples can be used to build a robust face detector by using an edge orientation histogram .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			23:1			0		1.0

Alignment 2683
- Learning method selection : Basically , in the ideal case with proper settings , advanced learning methods such as neural network , support vector machines and AdaBoost produce similar performance .
- Learning method selection : Basically , in an ideal situation with the proper settings , the advanced learning methods , such as the neural network , support vector machines , and AdaBoost , can perform similarly .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			9:1			0		1.0
11:1			11:1			0		1.0
12:1			8:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			0		1.0
24:1			20:1			0		1.0
25:1			21:1			0		1.0
26:1			22:1			0		1.0
27:1			23:1			0		1.0
28:1			24:1			0		1.0
29:1			25:1			0		1.0
31:1			26:1			0		1.0
32:1			27:1			0		1.0
35:1			30:1			1		1.0
36:1			29:1			1		1.0
37:1			31:1			0		1.0

Alignment 2684
However , in practice , it is difficult to find these proper settings .
However , in practice , it is difficult to find these proper settings .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 2685
Using neural network requires the design of layers , nodes , etc.hich is complicated .
Using a neural network requires the design of layers , nodes , etc. , which is complicated .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0

Alignment 2686
Therefore , it is preferable to use support vector machines since the number of parameters is only two if using RBF kernel and many tools are available .
Therefore , it is preferable to use support vector machines because only two parameters are necessary if a RBF kernel is used and many tools are available .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			16:1			0		1.0
12:1			17:1			0		1.0
13:1			14:1			0		1.0
16:1			18:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			15:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0

Alignment 2687
Another learning method which has been used widely in many object detection systems is AdaBoost and its variants .
Another learning method that has been widely used in many object detection systems is AdaBoost and its variants .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:2			3:2			3		1.0
5:1			5:1			0		1.0
6:1			7:1			0		1.0
7:1			6:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 2688
The advantage of AdaBoost is it can be used for both selecting features and learning the classifier .
The advantage of AdaBoost is it can be used for both selecting features and learning the classifier .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 2689
Face tracking is the process of locating a moving face or several ones in time using a camera , as illustrated in Figure 1 .
Face tracking is the process of locating a moving face or several of them over a period of time using a camera , as illustrated in Fig. 1 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
18:1			14:1			0		1.0
19:1			15:1			0		1.0
20:1			16:1			0		1.0
21:1			17:1			0		1.0
22:1			18:1			0		1.0
23:1			19:1			0		1.0
24:1			20:1			0		1.0
25:1			21:1			0		1.0
27:1			23:1			0		1.0
28:1			24:1			0		1.0

Alignment 2690
Face is first initialized manually or by a face detector .
A given face is first initialized manually or by a face detector .
Line2Start:Length	Line1Start:Length	Module		Score
3:1			1:1			0		1.0
4:1			2:1			0		1.0
5:1			3:1			0		1.0
6:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0

Alignment 2691
Face tracker then analyses subsequent video frames and outputs the location of the initialized face within these frames by estimating the motion parameters of the moving face .
The face tracker then analyzes the subsequent video frames and outputs the location of the initialized face within these frames by estimating the motion parameters of the moving face .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			26:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			0		1.0
5:1			24:1			0		1.0
6:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
27:1			25:1			0		1.0
29:1			27:1			0		1.0

Alignment 2692
Different from face detection , the outcome of which is the position and scale of one single face in one single frame , face tracking enables the information acquisition of multiple consecutive faces within consecutive video frames .
This is different from face detection , the outcome of which is the position and scale of one single face in one single frame ; face tracking enables the information acquisition of multiple consecutive faces within consecutive video frames .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			9:1			0		1.0
3:1			1:1			0		1.0
4:1			2:1			0		1.0
5:1			3:1			0		1.0
6:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
33:1			31:1			0		1.0
34:1			32:1			0		1.0
35:1			33:1			0		1.0
36:1			34:1			0		1.0
37:1			35:1			0		1.0
38:1			36:1			0		1.0
39:1			37:1			0		1.0

Alignment 2693
More important , these faces have the same identity .
More important , these faces have the same identity .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 2694
Although frame-based face detection techniques have demonstrated success on real images , the current ability on detecting faces from video is still primitive .
Although frame-based face detection techniques have been successfully demonstrated on real images , the current ability for detecting faces from video is still primitive .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0

Alignment 2695
The detector responses can decrease due to different reasons including occlusions , lighting conditions and face pose .
The quality of the detector responses can decrease due to different reasons including occlusions , lighting conditions , and face poses .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
4:1			1:1			0		1.0
5:1			2:1			0		1.0
6:1			3:1			0		1.0
7:1			4:1			0		1.0
8:1			5:1			0		1.0
9:1			6:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
18:1			14:1			0		1.0
19:1			15:1			0		1.0
20:1			16:1			1		1.0
21:1			17:1			0		1.0

Alignment 2696
Without any additional information , these responses can easily be rejected even if they indicate the presence of a face .
Without any additional information , these responses can easily be rejected , even if they indicate the presence of a face .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0

Alignment 2697
It is therefore important to incorporate the temporal information in a video sequence to provide more complete video segments displaying the person of interest , which is always named as face tracking .
It is therefore important to incorporate the temporal information in a video sequence to provide more complete video segments displaying the person of interest , which is always named as / already called ? face tracking .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
34:1			30:1			0		1.0
35:1			31:1			0		1.0
36:1			32:1			0		1.0

Alignment 2698
One of the main applications of face tracking is person retrieval from broadcast video , for example : intelligent fast-forwards " , where the video jumps to the next scene containing a certain person / actor ; or retrieval of different TV interventions , e.g. interviews , shows , etc. , of a given person in a video or a large collection of TV broadcast videos .
One of the main applications for face tracking is in the person retrieval from broadcast video , for example : " Intelligent fast-forwards�E, where the video jumps to the next scene containing a certain person / actor ; or retrieval of different TV interventions , e.g. interviews , shows , etc. , of a given person in a video or a large collection of TV broadcast videos .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			15:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			55:1			0		1.0
10:1			27:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			20:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
37:1			36:1			0		1.0
38:1			37:1			0		1.0
39:1			38:1			0		1.0
40:1			39:1			0		1.0
41:1			40:1			0		1.0
42:1			41:1			0		1.0
43:1			42:1			0		1.0
44:1			43:1			0		1.0
45:1			44:1			0		1.0
46:1			45:1			0		1.0
47:1			46:1			0		1.0
48:1			47:1			0		1.0
49:1			48:1			0		1.0
50:1			49:1			0		1.0
51:1			50:1			0		1.0
52:1			51:1			0		1.0
53:1			52:1			0		1.0
54:1			53:1			0		1.0
55:1			54:1			0		1.0
57:1			56:1			0		1.0
58:1			57:1			0		1.0
59:1			58:1			0		1.0
60:1			59:1			0		1.0
61:1			60:1			0		1.0
62:1			61:1			0		1.0
63:1			62:1			0		1.0
64:1			63:1			0		1.0
65:1			64:1			0		1.0
66:1			65:1			0		1.0
67:1			66:1			0		1.0

Alignment 2699
In [5] , a person retrieval system for feature-length movie video is proposed using straightforward face tracking .
In [5] , the person retrieval system for a feature-length movie video is proposed using straightforward face tracking .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			3:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0

Alignment 2700
At run time a user outlines a face in a frame of the video , and the face tracks within the movie are then ranked according to the similarity to the outlined query face in the manner of Google .
At run time a user outlines a face in a video frame , and the face tracks within the movie are then ranked according to their similarity to the outlined query face in the same way as Google .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			13:1			0		1.0
11:1			10:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0
24:1			26:1			0		1.0
26:1			28:1			0		1.0
27:1			29:1			0		1.0
28:1			30:1			0		1.0
29:1			31:1			0		1.0
30:1			32:1			0		1.0
31:1			33:1			0		1.0
32:1			34:1			0		1.0
33:1			35:1			0		1.0
35:2			36:1			3		1.0
37:1			38:1			0		1.0
38:1			39:1			0		1.0

Alignment 2701
Since one face track corresponds to one identity , the workload of intra-shot face matching is greatly reduced , which is not available in frame-based face detection .
Since one face track corresponds to one identity , the workload of intra-shot face matching is greatly reduced , which is not available in frame-based face detection .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0

Alignment 2702
In addition , face tracking provides multiple examples of the same character 's appearance to help with inter-shot face matching .
In addition , face tracking provides multiple examples of the same character 's appearance to help with inter-shot face matching .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 2703
Face tracking also finds applications in the area of face-name association , the objective of which is to label television or movie footage with the identity of the person present in each frame of the video .
Face tracking is also used in the area of face-name association , the objective of which is to label television or movie footage with the identity of the person present in each frame of the video .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			16:1			0		1.0
3:1			2:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0

Alignment 2704
Everingham et al [8] proposed an automatic face-name association system .
Everingham et al. [8] proposed an automatic face-name association system .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 2705
This system uses a face tracker similar with [5] to extract a few hundred tracks of a particular character each in a single shot .
This system uses a face tracker similar to the one in [5] that can extract a few hundred tracks of each particular character in a single shot .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			9:1			0		1.0
11:1			8:1			0		1.0
14:1			10:1			0		1.0
15:1			11:1			0		1.0
16:1			12:1			0		1.0
17:1			13:1			0		1.0
18:1			14:1			0		1.0
19:1			15:1			0		1.0
20:1			19:1			0		1.0
21:1			17:1			0		1.0
22:1			18:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0
26:1			23:1			0		1.0
27:1			24:1			0		1.0

Alignment 2706
Based on the temporal information obtained from the face tracker , textual information for TV and movie footage including subtitles and transcripts is employed to assign the character 's name to each face track .
Based on the temporal information obtained from the face tracker , the textual information for TV and the movie footage including the subtitles and transcripts is employed to assign the character 's name to each face track .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			26:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
22:1			19:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0
26:1			23:1			0		1.0
27:1			24:1			0		1.0
28:1			25:1			0		1.0
30:1			27:1			0		1.0
31:1			28:1			0		1.0
32:1			29:1			0		1.0
33:1			30:1			0		1.0
34:1			31:1			0		1.0
35:1			32:1			0		1.0
36:1			33:1			0		1.0
37:1			34:1			0		1.0

Alignment 2707
For instance , shots containing a particular person can be retrieved by a keyword like " Bush " or " Julia Roberts " instead of an outlined query face as used in [5] .
For instance , shots containing a particular person can be retrieved by a keyword like " Bush " or " Julia Roberts " instead of the use of an outlined query face as used in [5] .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
26:1			30:2			3		1.0
28:1			25:1			0		1.0
29:1			26:1			0		1.0
30:1			27:1			0		1.0
31:1			28:1			0		1.0
32:1			29:1			0		1.0
35:1			32:1			0		1.0
36:1			33:1			0		1.0

Alignment 2708
Besides broadcast video , face tracker also has important applications in the video used in humanoid robotics , visual surveillance , human-computer interaction ( HCI ) , video conferencing , face-based biometric person authentication , etc.
Besides broadcast video , face tracker also has important applications in the videos used in humanoid robotics , visual surveillance , human-computer interaction ( HCI ) , video conferencing , and face-based biometric person authentication among others .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			1		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0

Alignment 2709
Choosing a face tracker can be a difficult task due to the variety of face trackers available .
Choosing a face tracker can be a difficult task because of the variety of face trackers currently available .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:2			9:2			3		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0

Alignment 2710
The application provider will have to decide which face tracker is best suited to his / her individual needs and , of course , the type of video that he / she wants to use as the target .
The application provider will have to decide which face tracker is best suited to his / her individual needs and , of course , the type of video that he / she wants to use as the target .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0

Alignment 2711
Generally speaking , the important issues that should be addressed include speed , robustness and accuracy .
Generally speaking , the important issues that should be addressed include speed , robustness , and accuracy .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0

Alignment 2712
Can the system run in real time ? Similar with many other processing tools for broadcast video , speed is not the most critical issue because offline processing is permitted in most cases of video structuring and indexing .
Can the system run in real time ? Similar to many other processing tools for broadcast video , speed is not the most critical issue because offline processing is permitted in most video structuring and indexing cases .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			34:1			0		1.0
33:1			35:1			0		1.0
34:1			36:1			0		1.0
35:1			37:1			0		1.0
36:1			32:1			0		1.0
37:1			38:1			0		1.0

Alignment 2713
However , a real-time face tracker will become necessary if the target archive is established from too large quantities of videos , e.g. 24-hour continuous video recording that needs daily structuring .
However , a real-time face tracker will become necessary if a target archive is established from too large a quantity of videos , e.g. 24-hour continuous video recording that needs daily structuring .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:2			10:2			3		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
19:1			18:1			1		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0

Alignment 2714
On the other hand , the speed of the tracker is critical in most cases of applications for non-broadcast video , e.g. HCI .
On the other hand , the speed of the tracker is critical in most of the application cases for non-broadcast video , e.g. HCI .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			15:1			0		1.0
17:1			14:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0

Alignment 2715
It should be noted that there is always a tradeoff between speed and performance-related issues including robustness and accuracy .
It should be noted that there is always a tradeoff between speed and performance-related issues including the robustness and accuracy .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0

Alignment 2716
Can the system cope with varying illumination , facial expression , scale , pose , camerawork , occlusion and large head motion ? A number of illumination factors , e.g. light sources , background colors , luminance levels , and media , impact greatly on the change in appearance of a moving face , for instance , when tracking a person who are moving from indoor to outdoor environment .
Can the system cope with varying illuminations , facial expressions , scales , poses , camerawork , occlusion , and large head motions ? A number of illumination factors , e.g. light sources , background colors , luminance levels , and media , impact greatly on the change in appearance of a moving face , for instance , when tracking a person who is moving from an indoor to an outdoor environment .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			1		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			1		1.0
10:1			10:1			0		1.0
11:1			11:1			1		1.0
12:1			12:1			0		1.0
13:1			13:1			1		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			32:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			1		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			41:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
37:1			36:1			0		1.0
38:1			37:1			0		1.0
39:1			38:1			0		1.0
40:1			39:1			0		1.0
41:1			40:1			0		1.0
42:1			56:1			0		1.0
43:1			42:1			0		1.0
44:1			43:1			0		1.0
45:1			44:1			0		1.0
46:1			45:1			0		1.0
47:1			46:1			0		1.0
48:1			47:1			0		1.0
49:1			48:1			0		1.0
50:1			49:1			0		1.0
51:1			50:1			0		1.0
52:1			51:1			0		1.0
53:1			52:1			0		1.0
54:1			53:1			0		1.0
55:1			54:1			0		1.0
56:1			55:1			0		1.0
58:1			57:1			0		1.0
59:1			58:1			0		1.0
60:1			59:1			0		1.0
61:1			60:1			0		1.0
62:1			61:1			0		1.0
63:3			62:3			3		1.0
67:1			65:1			0		1.0
68:1			66:1			0		1.0
70:1			67:1			0		1.0
71:1			68:1			0		1.0
72:1			69:1			0		1.0

Alignment 2717
Face tracking also tends to fail under large facial deformations of eyes , nose , mouth , etc. due to facial expression variation .
Face tracking also tends to fail under large facial deformations of the eyes , nose , mouth , etc. due to the facial expression variation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0

Alignment 2718
Different from non-broadcast video , e.g. video used for HCI , faces appearing in broadcast video varies from large close-up faces to small faces taken by a long-shot .
Different from non-broadcast video , e.g. video used for HCI , faces appearing in broadcast video vary from large close-up faces to small faces taken by a long-shot .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:2			16:2			3		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 2719
Small face scale always leads to low resolution and will reject most face trackers designed by computer vision researchers .
A smaller face scale always leads to a lower resolution and will reject most face trackers designed by computer vision researchers .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
8:1			6:1			2		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0

Alignment 2720
Pose variation , i.e. head rotations including pitch , roll and yaw , is another influencing factor , which can cause disappearance of part of the face .
Pose variations , i.e. head rotations including the pitch , roll , and yaw , is another influencing factor , which can cause disappearances of parts of faces .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			1		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			25:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			17:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:2			21:2			3		1.0
25:2			23:2			3		1.0
27:1			26:1			1		1.0
28:1			27:1			0		1.0

Alignment 2721
In some cases , the variation of scale and pose might be caused by camerawork change .
In some cases , the scale and pose variations might be caused by camerawork changes .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			1		1.0
15:1			16:1			0		1.0

Alignment 2722
Disappearance of part of the face is also apt to happen due to occlusion by other objects , and motion information may be distracted by alternate motion of them .
The partial disappearance of a face is also apt to happen due to occlusion by other objects , and motion information may be distracted by an alternate motion .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			2:1			3		1.0
3:1			1:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			29:1			0		1.0

Alignment 2723
Moreover , the task of face tracking becomes even more difficult when the head are moving fast relative to the frame rate so that the tracker fails to arrive in time " .
Moreover , the task of face tracking becomes even more difficult when the head is moving fast relative to the frame rate , so that the tracker fails to �arrive in time�E.
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			2		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
30:1			29:1			0		1.0

Alignment 2724
How accurate is the tracking ? The first factor that affects the accuracy might be the false face detections generated when initializing the tracker by a face detector .
How accurate is the tracking ? The first factor that affects the accuracy might be the false face detections generated when initializing the tracker by a face detector .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 2725
This problem is difficult to solve due to a fixed threshold .
This problem is difficult to solve because it has a fixed threshold .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:2			3		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0

Alignment 2726
Lowering the threshold of the face detector reduces false rejections but increases the number of false detections , and vice versa .
Lowering the threshold of the face detector reduces the number of false rejections , but increases the number of false detections , and vice versa .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			12:1			0		1.0
9:1			13:1			0		1.0
10:1			14:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
14:1			10:1			0		1.0
15:1			11:1			0		1.0
19:1			15:1			0		1.0
20:1			16:1			0		1.0
21:1			17:1			0		1.0
22:1			18:1			0		1.0
23:1			19:1			0		1.0
24:1			20:1			0		1.0
25:1			21:1			0		1.0

Alignment 2727
The drifting or the long sequence motion problem is another factor that might affect the accuracy .
The drifting or the long sequence motion problem is another factor that might affect the accuracy .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 2728
This problem always happens due to the imperfect motion estimation technique .
This problem always happens due to the imperfect motion estimation technique .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 2729
A tracker might accumulate motion errors and eventually lose track of the face , for instance , when tracking faces that change from a frontal view to a profile position .
A tracker might accumulate motion errors and eventually lose track of a face , for instance , when tracking faces that change from a frontal view to a profile position .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0

Alignment 2730
Face tracking can be considered as an algorithm that analyses the video frames and outputs the location of moving faces within the video frame .
Face tracking can be considered an algorithm that analyzes the video frames and outputs the location of moving faces within the video frame .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0

Alignment 2731
For each tracked face , three steps are involved that are initialization , tracking and a stopping procedure , as illustrated in Figure 2 .
For each tracked face , three steps are involved , which are the initialization , tracking , and stopping procedures , as illustrated in Fig. 2 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			18:1			0		1.0
10:3			9:2			3		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			1		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0

Alignment 2732
Most of the developed methods use a face detector as the initialization of their tracking process .
Most of the developed methods use a face detector for the initialization of their tracking processes .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			1		1.0
16:1			16:1			0		1.0

Alignment 2733
An always ignored but existing difficulty of this step lies in the control of false face detections described above .
An always ignored but existing difficulty with this step lies in the control of the false face detections described above .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0

Alignment 2734
Another problem is the difficulty in handling the appearance of new non-frontal faces .
Another problem is the difficulty in handling the appearance of new non-frontal faces .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 2735
Although there have been literatures in profile or intermediate pose face detector , this kind of work suffers from the false-detection problem far more than frontal face detector .
Although there have been literatures on profile or intermediate pose face detectors , this kind of work suffers from the false-detection problem far more than a frontal face detector .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			1		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0

Alignment 2736
To alleviate these two problems , Chaudhury et al [1] used two face probability maps instead of a fixed threshold to initialize face tracker , one for frontal views and one for profiles .
To alleviate these two problems , Chaudhury et al. [1] used two face probability maps instead of a fixed threshold to initialize the face tracker , one for frontal views and one for profiles .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0

Alignment 2737
All local maxima in these maps are chosen as the face candidates , the face probabilities of which are propagated throughout the temporal sequence .
All local maxima in these maps are chosen as the face candidates , the face probabilities of which are propagated throughout the temporal sequence .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 2738
Candidates whose probabilities either go to zero or remain low over time are determined as non-face and eliminated .
Candidates whose probabilities either go to zero or remain low over time are determined as non-face and eliminated .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 2739
The information from two face probability maps is combined to represent intermediate head pose .
The information from the two face probability maps is combined to represent an intermediate head pose .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0

Alignment 2740
Their experiments showed that the proposed probabilistic detector improved the accuracy over traditional face detector and is able to handle the head movement covering a range of �90 degrees out-of-plane rotation ( yaw ) .
Their experiments showed that the proposed probabilistic detector improved the accuracy more than a traditional face detector and is able to handle the head movement covering a range of �90 degrees out-of-plane rotation ( yaw ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:2			11:1			3		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
33:1			31:1			0		1.0
34:1			32:1			0		1.0
35:1			33:1			0		1.0
36:1			34:1			0		1.0

Alignment 2741
After initialization , one should choose what features to track before tracking the face .
After initialization , one should choose what features to track before tracking a face .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 2742
The exploitation of color is one of the common choices in order to be invariant to facial expression , scale and pose change [4 , 9] .
The exploitation of color is one of the more common choices in order to be invariant to facial expressions , scale , and pose changes [4 , 9] .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			1		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			24:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			1		1.0
25:1			23:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0

Alignment 2743
However , color-based face trackers often depend on a learning set dedicated to the type of processed videos and are not guaranteed to be easily expendable to unknown videos with varying illumination conditions or different races .
However , color-based face trackers often depend on a learning set dedicated to the type of processed videos and are not guaranteed to be easily expendable to unknown videos with varying illumination conditions or different races .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0

Alignment 2744
Also , color is susceptible to occlusion by other head-like objects .
Also , color is susceptible to occlusion by other head-like objects .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 2745
Another two choices are key-point [5 , 8] and facial features [3 , 6 , 10] , e.g. eyes , nose , mouth , etc. , both of which are more robust to varying illumination and occlusion .
Two other choices are the key-point [5 , 8] and facial features [3 , 6 , 10] , e.g. eyes , nose , mouth , etc. , both of which are more robust to varying illuminations and occlusions .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			1		1.0
36:1			35:1			0		1.0
37:1			36:1			1		1.0
38:1			37:1			0		1.0

Alignment 2746
Although the generality of key-point allows for tracking different kinds of objects , without any face-specific knowledge its discriminant power between target and clutter might be in peril under tough conditions , e.g. strong background noise .
Although the generality of key-points allows for tracking different kinds of objects , without any face-specific knowledge its discriminant power between the target and clutter might be in peril under tough conditions , e.g. strong background noise .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			1		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
37:1			36:1			0		1.0

Alignment 2747
Facial features enable to track higher-level information from a human face but are weak in low video quality .
Facial features enable the tracking of higher-level information from a human face , but are weak in lower video quality .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			2		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0

Alignment 2748
Most facial-feature-based face trackers [6 , 10] are only tested by using non-broadcast video , e.g. webcam video , and their application potentiality to broadcast video is questionable .
Most facial-feature-based face trackers [6 , 10] have been tested using only non-broadcast video , e.g. webcam video , and their application potentiality to broadcast video is questionable .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:2			7:1			3		1.0
9:1			9:1			0		1.0
10:1			11:1			0		1.0
11:1			8:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 2749
Note that these different cues described above may be combined .
Note that these different cues described above may be combined .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 2750
An appearance-based or featureless tracker matches an observation model of the entire facial appearance with the input image , instead of choosing a few features to track .
An appearance-based or featureless tracker matches an observation model of the entire facial appearance with the input image , instead of choosing only a few features to track .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0

Alignment 2751
One example of appearance-based face tracker is [1] that has been introduced above .
One example of an appearance-based face tracker is [1] , which was introduced above .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
10:2			8:3			3		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0

Alignment 2752
Another example is proposed by Li et al [9] , which uses a multi-view face detector to detect and track faces of different poses .
Another example was proposed by Li et al. [9] , which uses a multi-view face detector to detect and track faces from different poses .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			2		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:2			21:2			3		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 2753
Besides the face-based observation model , a head model is also included to represent the information of head rear .
Besides the face-based observation model , a head model is also included to represent the information of head rear .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 2754
It is based on the idea that head can be considered as the object of interest instead of face because face is not always present in the tracking process .
It is based on the idea that a head can be considered an object of interest instead of a face , because the face is not always present in the tracking process .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
19:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			12:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0
26:1			23:1			0		1.0
27:1			24:1			0		1.0
28:1			25:1			0		1.0
29:1			26:1			0		1.0
30:1			27:1			0		1.0
31:1			28:1			0		1.0
32:1			29:1			0		1.0

Alignment 2755
An extended particle filter is proposed to fuse these two interrelated information so as to handle the occlusion due to out-of-plane head rotation ( yaw ) that is more than �90 degrees .
An extended particle filter is proposed to fuse these two interrelated information together so as to handle the occlusion due to out-of-plane head rotation ( yaw ) that is more than �90 degrees .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0

Alignment 2756
During the tracking procedure , face tracking systems usually employ a motion model that describes how the image of the target might change for different possible motions of the face to track .
During the tracking procedure , face tracking systems usually use a motion model that describes how the image of the target might change for different possible motions of the face to track .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:2			9:2			3		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0

Alignment 2757
Examples of simple motion models are as follows .
Some examples of simple motion models are as follows .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0

Alignment 2758
Based on the assumption that face can be considered as a planar object , the corresponding motion model can be a 2D transformation , e.g. affine transformation or homography , of an image of the face , e.g. the initial frame [3 , 6] .
Based on the assumption that a face can be considered a planar object , the corresponding motion model can be a 2D transformation , e.g. affine transformation or homography , of an image of the face , e.g. the initial frame [3 , 6] .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			20:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0

Alignment 2759
Some researchers assume the face as a rigid 3D object , thus the motion model defines its aspect depending on its 3D position and orientation [10] .
Some researchers view a face as a rigid 3D object , thus the motion model defines its aspect depending on its 3D position and orientation [10] .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 2760
However , face is actually both 3D and deformable .
However , a face is actually both 3D and deformable .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0

Alignment 2761
Some system try to model face in this sense , and the image of deformable faces can be covered with a mesh , i.e. a sophisticated geometry and texture face model [2 , 7] .
Some systems try to model faces in this sense , and the image of deformed face can be covered with a mesh , i.e. a sophisticated geometry and texture face model [2 , 7] .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			1		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			15:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			1		1.0
15:1			5:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0

Alignment 2762
The motion of the face is defined by the position of the nodes of the mesh .
The motion of the face is defined by the position of the nodes of the mesh .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 2763
Generally if the quality of the video is high , more sophisticated motion model is used , more accurate result the face tracker generates .
Generally if the quality of the video is high , a more sophisticated motion model is used , and then the face tracker generates a more accurate result .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
25:1			17:1			0		1.0
26:1			18:1			0		1.0
27:1			19:1			0		1.0
28:1			24:1			0		1.0

Alignment 2764
For instance , a sophisticated geometry and texture model might suffer from false face detections and drifting less than a simple 2D transformation model .
For instance , a sophisticated geometry and texture model might suffer from false face detections and a level of drifting [less than / that is worse than ?] a simple 2D transformation model .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
19:1			16:1			0		1.0
21:1			18:1			0		1.0
28:1			19:1			0		1.0
29:1			20:1			0		1.0
30:1			21:1			0		1.0
31:1			22:1			0		1.0
32:1			23:1			0		1.0
33:1			24:1			0		1.0

Alignment 2765
But note that most 3D-based and mesh-based face trackers require relatively clear appearance , high resolution , and limited pose variation of the face , e.g. out-of-plane head rotations ( roll and yaw ) that are far less than �90 degrees .
However , it must be noted that most 3D-based and mesh-based face trackers require a relatively clear appearance , high resolution , and a limited pose variation of the face , e.g. out-of-plane head rotations ( roll and yaw ) that are far less than �90 degrees .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			24:1			0		1.0
4:2			1:1			3		1.0
6:1			2:1			0		1.0
7:1			3:1			0		1.0
8:1			4:1			0		1.0
9:1			5:1			0		1.0
10:1			6:1			0		1.0
11:1			7:1			0		1.0
12:1			8:1			0		1.0
13:1			9:1			0		1.0
15:1			10:1			0		1.0
16:1			11:1			0		1.0
17:1			12:1			0		1.0
18:1			13:1			0		1.0
19:1			14:1			0		1.0
20:1			15:1			0		1.0
21:1			16:1			0		1.0
22:1			17:1			0		1.0
24:1			18:1			0		1.0
25:1			19:1			0		1.0
26:1			20:1			0		1.0
27:1			21:1			0		1.0
28:1			22:1			0		1.0
29:1			23:1			0		1.0
31:1			25:1			0		1.0
32:1			26:1			0		1.0
33:1			27:1			0		1.0
34:1			28:1			0		1.0
35:1			29:1			0		1.0
36:1			30:1			0		1.0
37:1			31:1			0		1.0
38:1			32:1			0		1.0
39:1			33:1			0		1.0
40:1			34:1			0		1.0
41:1			35:1			0		1.0
42:1			36:1			0		1.0
43:1			37:1			0		1.0
44:1			38:1			0		1.0
45:1			39:1			0		1.0
46:1			40:1			0		1.0
47:1			41:1			0		1.0

Alignment 2766
Both of these requirements are always unavailable in the case of broadcast video .
Both of these requirements are always unavailable in the case of broadcast video .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 2767
Therefore , most 3D-based and mesh-based face trackers are only tested by using non-broadcast video , e.g. webcam video [2 , 7 , 10] .
Therefore , most 3D-based and mesh-based face trackers are only tested by using non-broadcast video , e.g. webcam video [2 , 7 , 10] .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 2768
Finally , the stopping procedure is rarely discussed .
Finally , the stopping procedure is rarely discussed .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 2769
This constitutes a major deficiency of face tracking algorithms that are generally not able to stop a face track in case of tracking error , i.e. drifting .
This constitutes a major deficiency for the face tracking algorithms that are generally not able to stop a face track in case of tracking errors , i.e. drifting .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			1		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0

Alignment 2770
Arnaud et al [3] proposed an approach that uses a general object tracker for face tracking and a stopping criterion based on the addition of an eye tracker to alleviate drifting .
Arnaud et al. [3] proposed an approach that uses a general object tracker for face tracking and a stopping criterion based on the addition of an eye tracker to alleviate drifting .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0

Alignment 2771
Two positions of tracked eyes are compared with tracked face position .
The two positions of the tracked eyes are compared with the tracked face position .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
5:1			3:1			0		1.0
6:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0

Alignment 2772
If none of the two eyes are in the face region , it will be determined as drifting and the tracking process will be stopped .
If neither of the eyes is in the face region , it will be determined as drifting and the tracking process will be stopped .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:2			1:2			3		1.0
3:1			3:1			0		1.0
4:1			5:1			0		1.0
5:1			22:2			3		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:2			6:1			3		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0

Alignment 2773
Besides , most mesh-based trackers and top-down trackers are considered to be able to avoid drifting .
In addition , most mesh-based and top-down trackers are assumed to be able to avoid drifting .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 2774
Face tracking has attracted much attention from researchers in communities including multimedia content analysis , computer vision , etc. because of its wide application .
Face tracking has attracted much attention from researchers in communities including multimedia content analysis , computer vision , etc. because of its wide applications .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			1		1.0
24:1			24:1			0		1.0

Alignment 2775
However , while most attempts have been made on face tracking for videos with high quality by computer vision researchers , only a limited number of face trackers are designed for broadcast video .
However , while most of the attempts have been on the face tracking for high-quality videos by computer vision researchers , only a limited number of face trackers are designed for broadcast video .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
6:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0

Alignment 2776
This is because the current ability of face tracking still depends on relatively clear appearance , high resolution , and limited pose variation of the face , which are unavailable in broadcast video .
This is because the current ability of face tracking still depends on a relatively clear appearance , high resolution , and limited pose variation of the face , which are unavailable in broadcast video .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0

Alignment 2777
On the other hand , currently proposed face trackers are still evaluated by using different types of videos and different criteria .
On the other hand , currently proposed face trackers are still evaluated by using different types of videos and different criteria .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 2778
A general evaluation criterion , in terms of speed , robustness and accuracy , is needed for performance comparison between face trackers of different purposes .
A general evaluation criterion , in terms of speed , robustness , and accuracy , is needed for a performance comparison between the face trackers with different purposes .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0
25:2			22:2			3		1.0
27:1			24:1			0		1.0
28:1			25:1			0		1.0

Alignment 2779
Unsupervised Face Annotation by Mining the Web
Unsupervised Face Annotation by Mining the Web
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0

Alignment 2780
Searching for images of people is an essential task for image and video search engines .
Searching for images of people is an essential task for image and video search engines .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 2781
However , current search engines have limited capabilities for this task since they rely on text associated with images and video , and such text is likely to return many irrelevant results .
However , current search engines have limited capabilities for this task since they rely on text associated with images and video , and such text is likely to return many irrelevant results .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0

Alignment 2782
We propose a method to retrieve relevant faces for one person by learning the visual consistency among results retrieved from text-correlation-based search engines .
We propose a method for retrieving relevant faces of one person by learning the visual consistency among results retrieved from text-correlation-based search engines .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			8:1			0		1.0
5:1			5:1			1		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 2783
The method consists of two steps .
The method consists of two steps .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0

Alignment 2784
In the first step , each candidate face obtained from a text-based search engine is ranked by a score that measures the distribution of visual similarities among the faces .
In the first step , each candidate face obtained from a text-based search engine is ranked with a score that measures the distribution of visual similarities among the faces .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0

Alignment 2785
Faces that are possibly very relevant or irrelevant are ranked at the top or bottom of the list .
Faces that are possibly very relevant or irrelevant are ranked at the top or bottom of the list , respectively .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
20:1			18:1			0		1.0

Alignment 2786
The second step improves this ranking by treating this problem as a classification problem in which input faces are classified as 'person-$X$' or 'non-person-$X$' ; and the faces are re-ranked according to their relevant score inferred from the classifier 's probability output .
The second step improves this ranking by treating this problem as a classification problem in which input faces are classified as 'person-$X$' or 'non-person-$X$' ; and the faces are re-ranked according to their relevant score inferred from the classifier 's probability output .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0

Alignment 2787
To train this classifier , we use a bagging-based framework to combine results from multiple weak classifiers trained using different subsets .
To train this classifier , we use a bagging-based framework to combine results from multiple weak classifiers trained using different subsets .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 2788
These training subsets are extracted and labeled automatically from the rank list produced from the classifier trained from the previous step .
These training subsets are extracted and labeled automatically from the rank list produced from the classifier trained from the previous step .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 2789
In this way , the accuracy of the ranked list increases after a number of iterations .
In this way , the accuracy of the ranked list increases after a number of iterations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 2790
Experimental results on various face sets retrieved from captions of news photos show that the retrieval performance improved after each iteration , with the final performance being higher than those of the existing algorithms .
Experimental results on various face sets retrieved from captions of news photos show that the retrieval performance improved after each iteration , with the final performance being higher than those of the existing algorithms .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0

Alignment 2791
With the rapid growth of digital technology , large image and video databases have become more available than ever to users .
With the rapid growth of digital technology , large image and video databases have become more available than ever to users .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 2792
This trend has shown the need for effective and efficient tools for indexing and retrieving based on visual content .
This trend has shown the need for effective and efficient tools for indexing and retrieving visual content .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0

Alignment 2793
A typical application is searching for a specific person by providing his or her name .
A typical application is searching for a specific person by providing his or her name .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 2794
Most current search engines use the text associated with images and video as significant clues for returning results .
Most current search engines use the text associated with images and video as significant clues for returning results .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 2795
However , other un-queried faces and names may appear with the queried ones ( as shown in Figure xx ) , and this significantly lowers retrieval performance .
However , other un-queried faces and names may appear with the queried ones ( Figure xx ) , and this significantly lowers the retrieval performance .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			17:1			0		1.0
15:1			18:1			0		1.0
16:1			19:1			0		1.0
17:1			20:1			0		1.0
18:1			21:1			0		1.0
19:1			22:1			0		1.0
20:1			23:1			0		1.0
21:1			24:1			0		1.0
23:1			25:1			0		1.0
24:1			26:1			0		1.0
25:1			27:1			0		1.0

Alignment 2796
One way to improve the retrieval performance is to take into account visual information present in the retrieved faces .
One way to improve the retrieval performance is to take into account visual information present in the retrieved faces .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 2797
This task is challenging for the following reasons :
This task is challenging for the following reasons :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 2798
-Large variations in facial appearance due to pose changes , illumination conditions , occlusions and facial expressions make face recognition difficult even with state-of-the-art techniques\CITE ( see an example in Figure xx ) .
-Large variations in facial appearance due to pose changes , illumination conditions , occlusions , and facial expressions make face recognition difficult even with state-of-the-art techniques\CITE ( see example in Figure xx ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0

Alignment 2799
-The fact that the retrieved face set consists of faces of several people with no labels makes supervised and unsupervised learning methods inapplicable .
-The fact that the retrieved face set consists of faces of several people with no labels makes supervised and unsupervised learning methods inapplicable .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 2800
We propose a method to solve the above problem .
We propose a method for solving the above problem .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:2			4:2			3		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 2801
The main idea is to assume that there is visual consistency among the results returned from text-based search engines ; and then learn this visual consistency through an interactive process .
The main idea is the assumption that there is visual consistency among the results returned from text-based search engines and this visual consistency is then learned through an interactive process .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			20:1			0		1.0
20:1			23:1			0		1.0
21:1			24:1			0		1.0
22:1			25:1			0		1.0
24:1			21:1			0		1.0
25:1			22:1			1		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0

Alignment 2802
This method consists of two stages .
This method consists of two stages .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0

Alignment 2803
In the first stage , we explore the local density of faces to identify potential candidates for relevant faces and irrelevant faces .
In the first stage , we explore the local density of faces to identify potential candidates for relevant faces and irrelevant faces .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 2804
This stage reflects the fact that the facial images of the queried person tend to form dense clusters , whereas irrelevant facial images are sparse since they look different from each other .
This stage reflects the fact that the facial images of the queried person tend to form dense clusters , whereas irrelevant facial images are sparse since they look different from each other .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0

Alignment 2805
For each face , we define a score to measure the density of its neighbor set .
For each face , we define a score to measure the density of its neighbor set .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 2806
This score is used to form a ranked list , in which faces having high density scores are considered relevant and are put at the top of the list .
This score is used to form a ranked list , in which faces with high-density scores are considered relevant and are put at the top .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			29:1			0		1.0

Alignment 2807
The above ranking method is weak since dense clusters have no guarantee of containing relevant faces .
The above ranking method is weak since dense clusters have no guarantee of containing relevant faces .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 2808
Therefore , a second stage is necessary to improve this ranked list .
Therefore , a second stage is necessary to improve this ranked list .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 2809
We model this problem as a classification problem in which input faces are classified as person-\MATH ( the queried person ) or non-person-\MATH ( the un-queried person ) .
We model this problem as a classification problem in which input faces are classified as person-\MATH ( the queried person ) or non-person-\MATH ( the un-queried person ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 2810
The faces are ranked according to a relevancy score that is inferred from the classifier 's probability output .
The faces are ranked according to a relevancy score that is inferred from the classifier 's probability output .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 2811
Since annotation data is not available , the rank list from the previous step is used to assign labels for a subset of faces .
Since annotation data is not available , the rank list from the previous step is used to assign labels for a subset of faces .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 2812
This subset is then used to train a classifier using supervised methods such as support vector machine ( SVM ) .
This subset is then used to train a classifier using supervised methods such as a support vector machine ( SVM ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0

Alignment 2813
The trained classifier is used to re-rank faces in the original input set .
The trained classifier is used to re-rank faces in the original input set .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 2814
This step is repeated a number of times to get the final ranked list .
This step is repeated a number of times to get the final ranked list .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 2815
Since automatically assigning labels from the ranked list is not reliable , the trained classifiers are weak .
Since automatically assigning labels from the ranked list is not reliable , the trained classifiers are weak .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 2816
To get the final strong classifier , we use the idea of ensemble learning \CITE in which weak classifiers trained on different subsets are combined to improve the stability and classification accuracy of single classifiers .
To obtain the final strong classifier , we use the [idea / concept?] of ensemble learning \CITE in which weak classifiers trained on different subsets are combined to improve the stability and classification accuracy of single classifiers .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:2			1:2			3		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
33:1			31:1			0		1.0
34:1			32:1			0		1.0
35:1			33:1			0		1.0
36:1			34:1			0		1.0
37:1			35:1			0		1.0

Alignment 2817
The learned classifier can be further used for recognizing new facial images of the queried person .
The learned classifier can be further used for recognizing new facial images of the queried person .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 2818
The second stage improves the ranked list and recognition performance for the following reasons :
The second stage improves the ranked list and recognition performance for the following reasons :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 2819
-Supervised learning methods , such as SVM , provide a strong theoretical background for finding the optimal decision boundary even with noisy data .
-Supervised learning methods , such as an SVM , provide a strong theoretical background for finding the optimal decision boundary even with noisy data .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0

Alignment 2820
Furthermore , recent studies \CITE suggest that SVM classifiers provide probability outputs that are suitable for ranking .
Furthermore , recent studies \CITE suggest that SVM classifiers provide probability outputs that are suitable for ranking .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 2821
-The bagging framework helps to leverage noises in the unsupervised labeling process .
-The bagging framework helps to leverage noises in the unsupervised labeling process .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 2822
Our contribution is two-fold :
Our contribution is two-fold :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0

Alignment 2823
-We propose a general framework to boost the face retrieval performance of text-based search engines by visual consistency learning .
-We propose a general framework to boost the face retrieval performance of text-based search engines by visual consistency learning .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 2824
The framework seamlessly integrates data mining techniques such as supervised learning , and unsupervised learning based on bagging .
The framework seamlessly integrates data mining techniques such as supervised learning and unsupervised learning based on bagging .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0

Alignment 2825
-Our framework requires only a few parameters and works stably .
-Our framework requires only a few parameters and works stably .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 2826
We demonstrate its feasibility of a practical web mining application .
We demonstrate its feasibility with a practical web mining application .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 2827
A comprehensive evaluation on a large face dataset of many people was carried out and it confirmed that our approach is promising .
A comprehensive evaluation on a large face dataset of many people was carried out and confirmed that our approach is promising .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0

Alignment 2828
There are several approaches for re-ranking and learning models from web images .
There are several approaches for re-ranking and learning models from web images .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 2829
Their underlying assumption is that text-based search engines return a large fraction of relevant images .
Their underlying assumption is that text-based search engines return a large fraction of relevant images .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 2830
The challenge is how to model what is common in the relevant images .
The challenge is how to model what is common in the relevant images .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 2831
One approach is to model this problem in a probabilistic framework in which the returned images are used to learn the parameters of the model .
One approach is to model this problem in a probabilistic framework in which the returned images are used to learn the parameters of the model .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 2832
For examples , as described in \CITE , [Reference numbers generally should not be grammatically part of the sentence .
For examples , as described by Fergus et al. \CITE , [Reference numbers generally should not be grammatically part of the sentence .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:2			4:2			3		1.0
9:1			6:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			0		1.0

Alignment 2833
It is better to use the authors�f names .]objects retrieved by an image search engine are re-ranked by extending the constellation model .
It is better to use the authors�f names .] objects retrieved using an image search engine are re-ranked by extending the constellation model .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
10:1			9:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0

Alignment 2834
Another proposal , described in \CITE , uses a non-parametric graphical model and an interactive framework to simultaneously learn object class models and collect object class datasets .
Another proposal , described in \CITE , uses a non-parametric graphical model and an interactive framework to simultaneously learn object class models and collect object class datasets .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0

Alignment 2835
The main contribution of these approaches are probabilistic models that can be learned with a small number of training images .
The main contribution of these approaches is probabilistic models that can be learned with a small number of training images .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			2		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 2836
However , these models are complicated , since they require several hundred parameters for learning , and they are susceptible to over-fitting .
However , these models are complicated since they require several hundred parameters for learning and are susceptible to over-fitting .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			16:1			0		1.0
15:1			18:1			0		1.0
16:1			19:1			0		1.0
17:1			20:1			0		1.0
18:1			21:1			0		1.0
19:1			22:1			0		1.0

Alignment 2837
Furthermore , to obtain robust models , a small amount of supervision is required to select seed images .
Furthermore , to obtain robust models , a small amount of supervision is required to select seed images .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 2838
Another study \CITE proposed a clustering-based method for associating names and faces in news photos .
Another study \CITE proposed a clustering-based method for associating names and faces in news photos .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 2839
To solve the problem of ambiguity between several names and one face , a modified \MATH-means clustering process was used in which faces are assigned to the closest cluster ( each cluster corresponding to one name ) after a number of iterations .
To solve the problem of ambiguity between several names and one face , a modified \MATH-means clustering process was used in which faces are assigned to the closest cluster ( each cluster corresponding to one name ) after a number of iterations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0

Alignment 2840
Although the result was impressive , it is not easy to apply it to our problem since it is based on a strong assumption that requires a perfect alignment in the case that the news photo only has one face and its caption only has one name .
Although the result was impressive , it is not easy to apply it to our problem since it is based on a strong assumption that requires a perfect alignment when a news photo only has one face and its caption only has one name .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
31:1			34:1			0		1.0
32:1			35:1			0		1.0
33:1			36:1			0		1.0
34:1			37:1			0		1.0
35:1			38:1			0		1.0
36:1			39:1			0		1.0
37:1			40:1			0		1.0
38:1			41:1			0		1.0
39:1			42:1			0		1.0
40:1			43:1			0		1.0
41:1			44:1			0		1.0
42:1			45:1			0		1.0
43:1			46:1			0		1.0
44:1			47:1			0		1.0

Alignment 2841
Furthermore , a large number of irrelevant faces ( more than 12\% ) have to be manually eliminated before clustering .
Furthermore , a large number of irrelevant faces ( more than 12\% ) have to be manually eliminated before clustering .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 2842
A graph-based approach was proposed by \CITE , in which a graph is formed by faces as nodes , and the weights of edges linked between nodes are the similarity of faces , is closely related to our problem .
A graph-based approach was proposed by Ozkan and Duygu \CITE , in which a graph is formed from faces as nodes , and the weights of edges linked between nodes are the similarity of faces , is closely related to our problem .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			19:1			0		1.0
9:1			6:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0
26:1			23:1			0		1.0
27:1			24:1			0		1.0
28:1			25:1			0		1.0
29:1			26:1			0		1.0
30:1			27:1			0		1.0
31:1			28:1			0		1.0
32:1			29:1			0		1.0
33:1			30:1			0		1.0
34:1			31:1			0		1.0
35:1			32:1			0		1.0
36:1			33:1			0		1.0
37:1			34:1			0		1.0
38:1			35:1			0		1.0
39:1			36:1			0		1.0
40:1			37:1			0		1.0
41:1			38:1			0		1.0
42:1			39:1			0		1.0

Alignment 2843
Assuming that the number of faces of the queried person is larger than that of others and that these faces tend to form the most similar subset among the set of retrieved faces , this problem is considered equal to the problem of finding the densest subgraph of a full graph ; and therefore can be solved by taking an available solution .[It might be unclear as to what " available solution " you are talking about .
Assuming that the number of faces of the queried person is larger than that of others and that these faces tend to form the most similar subset among the set of retrieved faces , this problem is considered equal to the problem of finding the densest subgraph of a full graph ; and can therefore , be solved by taking an available solution . //It might be unclear as to what " available solution " you are talking about . You might want to give more detail here .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0
49:1			49:1			0		1.0
50:1			50:1			0		1.0
51:1			51:1			0		1.0
52:1			52:1			0		1.0
53:1			54:1			0		1.0
54:1			53:1			0		1.0
56:1			55:1			0		1.0
57:1			56:1			0		1.0
58:1			57:1			0		1.0
59:1			58:1			0		1.0
60:1			59:1			0		1.0
61:1			60:1			0		1.0
62:1			61:1			0		1.0
63:1			77:1			0		1.0
65:1			63:1			0		1.0
66:1			64:1			0		1.0
67:1			65:1			0		1.0
68:1			66:1			0		1.0
69:1			67:1			0		1.0
70:1			68:1			0		1.0
71:1			69:1			0		1.0
72:1			70:1			0		1.0
73:1			71:1			0		1.0
74:1			72:1			0		1.0
75:1			73:1			0		1.0
76:1			74:1			0		1.0
77:1			75:1			0		1.0
78:1			76:1			0		1.0

Alignment 2844
You might want to give more detail here .] Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person and it is easy to extend for the ranking problem .
Although experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of the relevant faces of the queried person and it is easy to extend for the ranking problem .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			9:1			0		1.0
1:1			11:1			0		1.0
2:1			12:1			0		1.0
3:1			13:1			0		1.0
4:1			14:1			0		1.0
5:1			15:1			0		1.0
6:1			16:1			0		1.0
7:1			17:1			0		1.0
8:1			18:1			0		1.0
9:1			19:1			0		1.0
10:1			20:1			0		1.0
11:1			21:1			0		1.0
12:1			22:1			0		1.0
13:1			23:1			0		1.0
14:1			24:1			0		1.0
15:1			25:1			0		1.0
16:1			26:1			0		1.0
17:1			27:1			0		1.0
18:1			28:1			0		1.0
19:1			29:1			0		1.0
20:1			30:1			0		1.0
21:1			31:1			0		1.0
22:1			45:1			0		1.0
23:1			32:1			0		1.0
24:1			33:1			0		1.0
25:1			34:1			0		1.0
26:1			35:1			0		1.0
27:1			36:1			0		1.0
28:1			37:1			0		1.0
29:1			38:1			0		1.0
30:1			39:1			0		1.0
31:1			40:1			0		1.0
32:1			41:1			0		1.0
33:1			42:1			0		1.0
34:1			43:1			0		1.0
35:1			44:1			0		1.0
37:1			46:1			0		1.0
38:1			47:1			0		1.0
39:1			48:1			0		1.0

Alignment 2845
Furthermore , choosing an optimal threshold to convert the initial graph into a binary graph is difficult and rather ad hoc due to the curse of dimensionality .
Furthermore , choosing an optimal threshold to convert the initial graph into a binary one is difficult and rather ad hoc due to dimensionality .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			26:1			0		1.0
24:1			27:1			0		1.0

Alignment 2846
The good point of the methods \CITE is they are fully unsupervised .
An advantage of these methods \CITE is they are fully unsupervised .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			3:1			0		1.0
3:2			4:2			3		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0

Alignment 2847
However , the bad point is no model is learned to predict new images of the same category .
However , a disadvantage is that no model is learned for predicting new images of the same category .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
4:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			10:2			3		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 2848
Furthermore , they perform hard categorization on input images that is [It is not clear if " hard categorization " is inapplicable or if the " input images " are inapplicable .]in applicable for re-ranking .
Furthermore , they are used for performing hard categorization on input images that are inapplicable for re-ranking . //It is not clear if " hard categorization " is inapplicable or if the " input images " are inapplicable .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			29:1			0		1.0
5:1			33:1			0		1.0
6:1			3:1			1		1.0
7:1			4:1			0		1.0
8:1			5:1			0		1.0
9:1			6:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			2		1.0
14:1			30:1			0		1.0
16:1			34:1			0		1.0
17:1			35:1			0		1.0
19:1			12:1			0		1.0
20:1			13:1			0		1.0
21:1			14:1			0		1.0
22:1			15:1			0		1.0
23:1			16:1			0		1.0
24:1			17:1			0		1.0
25:1			18:1			0		1.0
26:1			19:1			0		1.0
27:1			20:1			0		1.0
28:1			21:1			0		1.0
29:1			22:1			0		1.0
30:1			23:1			0		1.0
31:1			24:1			0		1.0
32:1			25:1			0		1.0
33:1			26:1			0		1.0
34:1			27:1			0		1.0
35:1			28:1			0		1.0

Alignment 2849
The balance of recall and precision was not addressed .
The balance of recall and precision was not addressed .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 2850
Typically , these approaches tend to ignore the recall to obtain high precision .
Typically , these approaches tend to ignore the recall to obtain high precision .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 2851
This leads the number of collected images is reduced .
This leads to the reduction in the number of collected images .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:2			8:1			3		1.0
6:1			2:1			0		1.0
7:1			3:1			0		1.0
8:1			4:1			0		1.0
9:1			5:1			0		1.0
10:1			6:1			0		1.0
11:1			9:1			0		1.0

Alignment 2852
Our approach combines a number of advances over the existing approaches .
Our approach combines a number of advances over the existing approaches .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 2853
Specifically , we learn a model for each query from the returned images for purposes such as re-ranking and predicting new images .
Specifically , we learn a model for each query from the returned images for purposes such as re-ranking and predicting new images .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 2854
However , different from the methods in \cite{xx} , we used an unsupervised method to select training samples automaticallyCITE .
However , we used an unsupervised method to select training samples automatically , which is different from the methods proposed by Fergus et al. and Li et al. \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			9:1			0		1.0
3:1			10:1			0		1.0
4:1			11:1			0		1.0
5:1			12:1			0		1.0
6:1			13:1			0		1.0
7:1			14:1			0		1.0
8:1			15:1			0		1.0
9:1			16:1			0		1.0
10:1			17:1			0		1.0
12:1			8:1			0		1.0
15:1			2:1			0		1.0
16:1			3:1			0		1.0
17:1			4:1			0		1.0
18:1			5:1			0		1.0
29:1			19:1			0		1.0

Alignment 2855
This unsupervised method is different from the one in \CITE in its way of modeling the distribution of relevant images .
This unsupervised method is different from the one by Ozkan and Dugyu \CITE in the modeling of the distribution of relevant images .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			0		1.0
15:1			14:1			0		1.0
16:1			13:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0

Alignment 2856
We use density-based estimation rather than the densest graph .
We use density-based estimation rather than the densest graph .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 2857
Given a set of images returned by any text-based search engine for a queried person ( e.g. 'George Bush' ) , we perform a ranking process and learning of person |\MATH 's model as follows :
Given a set of images returned by any text-based search engine for a queried person ( e.g. 'George Bush' ) , we perform a ranking process and learning of person |\MATH 's model as follows :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0

Alignment 2858
-Step 1 : Detect faces and eye positions , and then perform face normalizations .
-Step 1 : Detect faces and eye positions , and then perform face normalizations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 2859
-Step 2 : Compute an eigenface space and project the input faces into this subspace .
-Step 2 : Compute an eigenface space and project the input faces into this subspace .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 2860
-Step 3 : Estimate the ranked list of these faces by Rank-By-Local-Density-Score .
-Step 3 : Estimate the ranked list of these faces by rank-by-local-density score .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
13:1			12:1			0		1.0

Alignment 2861
-Step 4 : Improve this ranked list by Rank-By-Bagging-ProbSVM . //I found not hits for " rank-by-bagging-probSVM " on the Internet . You might want to double check to see if this is a standard term . The same is true for " rank-by-local-density score " . If this is your own term , you might want to specify this at some point .
-Step 4 : Improve this ranked list using rank-by-bagging-probSVM . //I found not hits for " rank-by-bagging-probSVM " on the Internet. You might want to double check to see if this is a standard term . The same is true for " rank-by-local-density score " . If this is your own term , you might want to specify this at some point .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			16:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0
31:1			32:1			0		1.0
32:1			33:1			0		1.0
33:1			34:1			0		1.0
34:1			35:1			0		1.0
35:1			36:1			0		1.0
36:1			37:1			0		1.0
37:1			38:1			0		1.0
38:1			39:1			0		1.0
39:1			40:1			0		1.0
40:1			41:1			0		1.0
41:1			42:1			0		1.0
42:1			43:1			0		1.0
43:1			44:1			0		1.0
44:1			45:1			0		1.0
45:1			46:1			0		1.0
46:1			47:1			0		1.0
47:1			48:1			0		1.0
48:1			49:1			0		1.0
49:1			50:1			0		1.0
50:1			51:1			0		1.0
51:1			52:1			0		1.0
52:1			53:1			0		1.0
53:1			54:1			0		1.0
54:1			55:1			0		1.0
55:1			56:1			0		1.0
56:1			57:1			0		1.0
57:1			58:1			0		1.0
58:1			59:1			0		1.0
59:1			60:1			0		1.0
60:1			61:1			0		1.0
61:1			62:1			0		1.0
62:1			63:1			0		1.0

Alignment 2862
Steps 1 and 2 are typical for any face processing system , and they are described in section \REF .
Steps 1 and 2 are typical for any face processing system , and they are described in section \REF .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 2863
The algorithms used in Step 3 and Step 4 are described in section \REF and section \REF .
The algorithms used in Steps 3 and 4 are described in section \REF and section \REF , respectively .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			1		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
18:1			17:1			0		1.0

Alignment 2864
Figure \REF illustrates the proposed framework .
Figure \REF illustrates the proposed framework .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0

Alignment 2865
Among the faces retrieved by the text-based search engines for a query of person-\MATH , as shown in Figure \REF , relevant faces usually look similar and can form the largest cluster .
Among the faces retrieved by text-based search engines for a query of person-\MATH , as shown in Figure \REF , relevant faces usually look similar and forms the largest cluster .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			28:1			1		1.0
27:1			29:1			0		1.0
28:1			30:1			0		1.0
29:1			31:1			0		1.0
30:1			32:1			0		1.0

Alignment 2866
One approach to re-rank these faces is to do clustering based on visual similarity .
One approach of re-ranking these faces is to cluster based on visual similarity .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:2			1:2			3		1.0
3:1			3:1			1		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			9:1			1		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0

Alignment 2867
However , to get ideal clustering result is impossible , since these faces are high dimensional data and the clusters are in different shapes , sizes and densities .
However , to obtain ideal clustering results is impossible since these faces are high dimensional data and the clusters are in different shapes , sizes , and densities .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			2		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			1		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			9:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 2868
Instead , in \cite{xx} , a graph based approach was proposed CITEin which the nodes are faces and edge weights are the similarities between two faces .
Instead , a graph-based approach was proposed by Ozkan and Dugyu \CITE in which the nodes are faces and edge weights are the similarities between two faces .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			5:1			0		1.0
4:1			8:1			0		1.0
5:1			9:1			0		1.0
6:1			10:1			0		1.0
12:1			2:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0

Alignment 2869
With the observation that the nodes ( faces ) of the queried person are similar to each other and different from other nodes in the graph , the densest component of the full graph ? the set of highly connected nodes in the graph ? will correspond to the face of the queried person .
With the observation that the nodes ( faces ) of the queried person are similar to each other and different from other nodes in the graph , the densest component of the full graph ? the set of highly connected nodes in the graph ? will correspond to the face of the queried person .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0
49:1			49:1			0		1.0
50:1			50:1			0		1.0
51:1			51:1			0		1.0
52:1			52:1			0		1.0
53:1			53:1			0		1.0
54:1			54:1			0		1.0

Alignment 2870
The main drawback of this approach is it needs a threshold to convert the initial weighted graph to a binary graph .
The main drawback of this approach is it needs a threshold to convert the initial weighted graph to a binary graph .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 2871
Choosing this threshold in high dimensional spaces is difficult since different persons might have different optimal thresholds .
Choosing this threshold in high dimensional spaces is difficult since different persons might have different optimal thresholds .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 2872
We use the idea of density-based clustering described in \CITE to solve this problem .
We use the idea of density-based clustering described by Ester et al. and Breunig et al. \CITE to solve this problem . //idea / concept?
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:2			7:2			3		1.0
16:1			9:1			0		1.0
17:1			10:1			0		1.0
18:1			11:1			0		1.0
19:1			12:1			0		1.0
20:1			13:1			0		1.0
21:1			14:1			0		1.0

Alignment 2873
Specifically , we define local density score ( LDS ) of a point \MATH( i.e. a face ) as the average distance to its k-nearest neighbors :
Specifically , we define the local density score ( LDS ) of a point \MATH( i.e. a face ) as the average distance to its k-nearest neighbors .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0

Alignment 2874
where \MATH is the set of \MATH - neighbors of \MATH , and \MATH is the similarity between \MATH and \MATH .
where \MATH is the set of \MATH - neighbors of \MATH , and \MATH is the similarity between \MATH and \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 2875
Since faces are represented in high dimensional feature space , and face clusters might have different sizes , shapes and densities ; we do not use directly the Euclidean distance between two points in this feature space for \MATH .
Since faces are represented in high dimensional feature space , and face clusters might have different sizes , shapes , and densities , we do not directly use the Euclidean distance between two points in this feature space for \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			26:1			0		1.0
27:1			25:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
37:1			36:1			0		1.0
38:1			37:1			0		1.0
39:1			38:1			0		1.0
40:1			39:1			0		1.0

Alignment 2876
Instead , we use another similarity measure defined by the number of shared neighbors between two points .
Instead , we use another similarity measure defined by the number of shared neighbors between two points .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 2877
The efficiency of this similarity measure for density-based clustering methods was described . //There is no period here , so it is not clear if there should be a period or there should be more to this sentence that is not here . If the sentence does end here , you might want to go into more detail about who or what " described " this .]
The efficiency of this similarity measure for density-based clustering methods was described . //There is no period here , so it is not clear if there should be a period or there should be more to this sentence that is not here . If the sentence does end here , you might want to go into more detail about who or what " described " this .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0
49:1			49:1			0		1.0
50:1			50:1			0		1.0
51:1			51:1			0		1.0
52:1			52:1			0		1.0
53:1			53:1			0		1.0
54:1			54:1			0		1.0
55:1			55:1			0		1.0
56:1			56:1			0		1.0
57:1			57:1			0		1.0
58:1			58:1			0		1.0
59:1			59:1			0		1.0
60:1			60:1			0		1.0
61:1			61:1			0		1.0
62:1			62:1			0		1.0
63:1			63:1			0		1.0
64:1			64:1			0		1.0
65:1			65:1			0		1.0

Alignment 2878
A high value of \MATH indicates a strong association between \MATH and its neighbors .
A high value of \MATH indicates a strong association between \MATH and its neighbors .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 2879
Therefore , we can use this local density score to rank faces .
Therefore , we can use this local density score to rank faces .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 2880
Faces with higher scores are considered to be potential candidates that are relevant to person-\MATH , while faces with lower scores are considered as outliers and thus are potential candidates for non-person-\MATH .
Faces with higher scores are considered to be potential candidates that are relevant to person-\MATH , while faces with lower scores are considered as outliers and thus are potential candidates for non-person-\MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0

Alignment 2881
Algorithm 1 : Rank-By-Local-Density-Score Step 1 : For each face p , compute LDS( p , k ) , where k is the number of neighbors of p and is the input of the ranking process .
Algorithm 1 : Rank-By-Local-Density-Score Step 1 : For each face p , compute LDS( p , k ) , where k is the number of neighbors of p and is the input of the ranking process .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0

Alignment 2882
Step 2 : Rank these faces using LDS( p , k ) ( The higher the more relevant ) .
Step 2 : Rank these faces using LDS( p , k ) ( The higher the score the more relevant ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0

Alignment 2883
One limitation of the local density score based ranking is it could not handle the case that faces of another person have strong association in \MATH-neighbor set ( for example , many duplicates ) .
One limitation of the local density score based ranking is it cannot handle faces of another person strongly associated in the \MATH-neighbor set ( for example , many duplicates ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:2			3		1.0
12:1			13:1			0		1.0
13:1			17:1			0		1.0
14:1			18:1			0		1.0
15:1			19:1			0		1.0
16:1			20:1			0		1.0
17:1			22:1			1		1.0
18:1			23:1			1		1.0
19:1			24:1			0		1.0
20:1			14:1			0		1.0
21:1			25:1			0		1.0
22:1			26:1			0		1.0
23:1			27:1			0		1.0
24:1			28:1			0		1.0
25:1			29:1			0		1.0
26:1			30:1			0		1.0
27:1			31:1			0		1.0
28:1			32:1			0		1.0
29:1			33:1			0		1.0
30:1			34:1			0		1.0

Alignment 2884
Therefore , another step is proposed to handle this case .
Therefore , another step is proposed for handling this case .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:2			6:2			3		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 2885
As a result , we have a model that can be used for both re-ranking current faces and predicting new incoming faces .
As a result , we have a model that can be used for both re-ranking current faces and predicting new incoming faces .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 2886
The main idea is to use a probabilistic model to measure the relevancy of a face to person-\MATH , \MATH .
The main idea is to use a probabilistic model to measure the relevancy of a face to person-\MATH , \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 2887
Since the labels are not available for training , we use the input rank list found from the previous step to extract a subset of faces lying at the top and bottom of the ranked list to form the training set .
Since the labels are not available for training , we use the input rank list found from the previous step to extract a subset of faces lying at the top and bottom of the ranked list to form the training set .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0

Alignment 2888
After that , we use SVM with probabilistic output \CITE implemented in LibSVM \CITE to learn the person-\MATH model .
After that , we use an SVM with probabilistic output \CITE implemented in LibSVM \CITE to learn the person-\MATH model .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0

Alignment 2889
This model is applied to faces of the original set and the output probabilistic scores are used to re-rank these faces .
This model is applied to faces of the original set , and the output probabilistic scores are used to re-rank these faces .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0

Alignment 2890
Since it is not guaranteed that faces lying at two ends of the input rank list correctly correspond to the faces of person-\MATH and faces of non person-\MATH , we adopt the idea of bagging framework \CITE in which randomly selecting subsets to train weak classifiers , and then combining these classifiers help reduce the risk of using noisy training sets .
Since it is not guaranteed that faces lying at two ends of the input rank list correctly correspond to the faces of person-\MATH and faces of non person-\MATH , we adopt the [idea / concept?] of a bagging framework \CITE in which randomly selecting subsets to train weak classifiers , and then combining these classifiers help reduce the risk of using noisy training sets .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
35:1			33:1			0		1.0
37:1			34:1			0		1.0
38:1			35:1			0		1.0
39:1			36:1			0		1.0
40:1			37:1			0		1.0
41:1			38:1			0		1.0
42:1			39:1			0		1.0
43:1			40:1			0		1.0
44:1			41:1			0		1.0
45:1			42:1			0		1.0
46:1			43:1			0		1.0
47:1			44:1			0		1.0
48:1			45:1			0		1.0
49:1			46:1			0		1.0
50:1			47:1			0		1.0
51:1			48:1			0		1.0
52:1			49:1			0		1.0
53:1			50:1			0		1.0
54:1			51:1			0		1.0
55:1			52:1			0		1.0
56:1			53:1			0		1.0
57:1			54:1			0		1.0
58:1			55:1			0		1.0
59:1			56:1			0		1.0
60:1			57:1			0		1.0
61:1			58:1			0		1.0
62:1			59:1			0		1.0
63:1			60:1			0		1.0
64:1			61:1			0		1.0

Alignment 2891
The details of Rank-By-Bagging-ProbSVM-InnerLoop method , improving an input rank list by combining weak classifiers trained from subsets annotated by that rank list are described in Algorithm 2 .
The details of the Rank-By-Bagging-ProbSVM-InnerLoop method , improving an input rank list by combining weak classifiers trained from subsets annotated by that rank list , are described in Algorithm 2 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0

Alignment 2892
Step 1 : Train a weak classifier hi .
Step 1 : Train a weak classifier , hi .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0

Alignment 2893
Step 1 .1 : Select a set Spos including p% top ranked faces and then randomly select a subset S?pos from Spos .
Step 1 .1 : Select a set Spos including p% of top ranked faces and then randomly select a subset S?pos from Spos .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0

Alignment 2894
Label faces in S?pos as positive samples .
Label faces in S?pos as positive samples .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 2895
Step 1 .2 : Select a set Sneg including p% bottom ranked faces and then randomly select a subset S? neg from Sneg .
Step 1 .2 : Select a set Sneg including p% of bottom ranked faces and then randomly select a subset S? neg from Sneg .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0

Alignment 2896
Label faces in S? neg as negative samples .
Label faces in S? neg as negative samples .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 2897
Step 1 .3 : Use S?pos and S? neg to train a weak classifier hj using LibSVM [8] with probability outputs .
Step 1 .3 : Use S?pos and S? neg to train a weak classifier , hj , using LibSVM [8] with probability outputs .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
15:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0

Alignment 2898
Step 2 : Compute ensemble classifier Hi = Pij=1 hj .
Step 2 : Compute ensemble classifier Hi = Pij=1 hj .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 2899
Step 3 : Apply Hi to the original face set and form the rank list Ranki by using the output probabilistic scores .
Step 3 : Apply Hi to the original face set and form the rank list , Ranki , using the output probabilistic scores .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
16:1			15:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0

Alignment 2900
Step 4 : Repeat steps from Step 1 to Step 3 until Dist2RankList( Ranki?1 ,Ranki ) <= ? .
Step 4 : Repeat steps 1 to 3 until Dist2RankList( Ranki?1 ,Ranki ) <= ? .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			10:1			0		1.0
8:1			11:1			0		1.0
9:1			12:1			0		1.0
10:1			13:1			0		1.0
11:1			14:1			0		1.0
12:1			15:1			0		1.0
13:1			16:1			0		1.0
14:1			17:1			0		1.0
15:1			18:1			0		1.0

Alignment 2901
Step 5 : Return Hi = Pij=1 hj .
Step 5 : Return Hi = Pij=1 hj .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 2902
Step 1 : Rankcur = Rank-By-Bagging-ProbSVM-InnerLoop( Rankprev ) .
Step 1 : Rankcur = Rank-By-Bagging-ProbSVM-InnerLoop ( Rankprev ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0

Alignment 2903
Step 2 : dist = Dist2RankList( Rankprev ,Rankcur ) .
Step 2 : dist = Dist2RankList ( Rankprev ,Rankcur ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0

Alignment 2904
Step 3 : Rankfinal = Rankcur .
Step 3 : Rankfinal = Rankcur .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0

Alignment 2905
Step 4 : Rankprev = Rankcur .
Step 4 : Rankprev = Rankcur .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0

Alignment 2906
Step 5 : Repeat steps from Step 1 to Step 4 until dist <= ? .
Step 5 : Repeat steps 1 to 4 until dist <= ? .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			10:1			0		1.0
8:1			11:1			0		1.0
9:1			12:1			0		1.0
10:1			13:1			0		1.0
11:1			14:1			0		1.0
12:1			15:1			0		1.0

Alignment 2907
Step 5 : Return Rankfinal .
Step 6 : Return Rankfinal .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0

Alignment 2908
Given an input ranked list , Rank-By-Bagging-ProbSVM-InnerLoop is used to improve this rank list .
Given an input ranked list , Rank-By-Bagging-ProbSVM-InnerLoop is used to improve this list .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0

Alignment 2909
We repeat the process a number of times whereby the ranked list output from the previous step is used as the input ranked list of the next step .
We repeat the process a number of times whereby the ranked list output from the previous step is used as the input ranked list of the next step .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 2910
In this way , the iterations significantly improve the final ranked list .
In this way , the iterations significantly improve the final ranked list .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 2911
The details are described in Algorithm 3 .
The details are described in Algorithm 3 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 2912
To determine the number of iterations of Rank-By-Bagging-ProbSVM-InnerLoop and Rank-By-Bagging-ProbSVM-OuterLoop , we use the \MATH distance \CITE , which is a metric that counts the number of pairwise disagreements between two lists .
To determine the number of iterations of Rank-By-Bagging-ProbSVM-InnerLoop and Rank-By-Bagging-ProbSVM-OuterLoop , we use the \MATH distance \CITE , which is a metric that counts the number of pairwise disagreements between two lists .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0

Alignment 2913
The larger the distance , the more dissimilar the two lists are .
The larger the distance , the more dissimilar the two lists are .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 2914
The \MATH distance between two list \MATH and \MATH is defined as follows :
The \MATH distance between two lists , \MATH and \MATH , is defined as follows :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			1		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0

Alignment 2915
Since the maximum value of \MATH is \MATH where \MATH is the number of members of the list , the normalized Kendall tau distance can be written as follows :
Since the maximum value of \MATH is \MATH , where \MATH is the number of members of the list , the normalized Kendall tau distance can be written as follows :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			18:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0

Alignment 2916
Using this measure for checking when the loops stop means that if the ranked list does not change significantly after a number of iterations , it is reasonable to stop .
Using this measure for checking when the loops stop means that if the ranked list does not change significantly after a number of iterations , it is reasonable to stop .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0

Alignment 2917
We used the dataset described in \CITE for our experiments .
We used the dataset described by Berg et al. \CITE for our experiments .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:2			4:2			3		1.0
9:1			6:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			0		1.0

Alignment 2918
This dataset consists of approximately half a million news [pictures / photos?] and captions from Yahoo News collected over a period of roughly two years .
This dataset consists of approximately half a million news pictures and captions from Yahoo News collected over a period of roughly two years .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0

Alignment 2919
This dataset is better than datasets collected from image search engines such as Google that usually limit the total number of returned images to 1 ,000 .
This dataset is better than datasets collected from image search engines such as Google that usually limit the total number of returned images to 1 ,000 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 2920
Furthermore , it has annotations that are valuable for evaluation of methods .
Furthermore , it has annotations that are valuable for evaluation of methods .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 2921
Note that these annotations are used for evaluation purpose only .
Note that these annotations are used for evaluation purpose only .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 2922
Our method is fully unsupervised , so it assumes the annotations are not available at running time .
Our method is fully unsupervised , so it assumes the annotations are not available at running time .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 2923
Only frontal faces were considered since current frontal face detection systems \CITE can work in real time and have accuracies exceeding 95\% .
Only the front of faces were considered since current frontal face detection systems \CITE work in real time and have accuracies exceeding 95\% .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
4:1			2:1			0		1.0
5:1			3:1			0		1.0
6:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0

Alignment 2924
44 ,773 faces were detected and normalized to the size of 86\MATH86 pixels .
44 ,773 faces were detected and normalized to 86\MATH86 pixels .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			11:1			0		1.0
9:1			12:1			0		1.0
10:1			13:1			0		1.0

Alignment 2925
We selected fifteen government leaders , including George W. Bush ( US ) , Vladimir Putin ( Russia ) , Ziang Jemin ( China ) , Tony Blair ( UK ) , Junichiro Koizumi ( Japan ) , Roh Moo-hyun ( Korea ) , and Abdullah Gul ( Turkey ) , and other key individuals , such as John Paul II ( the Former Pope ) and Hans Blix ( UN ) , because their images frequently appear in the dataset \CITE .
We selected fifteen government leaders , including George W. Bush ( US ) , Vladimir Putin ( Russia ) , Ziang Jemin ( China ) , Tony Blair ( UK ) , Junichiro Koizumi ( Japan ) , Roh Moo-hyun ( Korea ) , Abdullah Gul ( Turkey ) , and other key individuals , such as John Paul II ( the Former Pope ) and Hans Blix ( UN ) , because their images frequently appear in the dataset \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			45:1			0		1.0
45:1			46:1			0		1.0
46:1			47:1			0		1.0
47:1			48:1			0		1.0
48:1			49:1			0		1.0
49:1			50:1			0		1.0
50:1			51:1			0		1.0
51:1			52:1			0		1.0
52:1			53:1			0		1.0
53:1			54:1			0		1.0
54:1			55:1			0		1.0
55:1			56:1			0		1.0
56:1			57:1			0		1.0
57:1			58:1			0		1.0
58:1			59:1			0		1.0
59:1			60:1			0		1.0
60:1			61:1			0		1.0
61:1			62:1			0		1.0
62:1			63:1			0		1.0
63:1			64:1			0		1.0
64:1			65:1			0		1.0
65:1			66:1			0		1.0
66:1			67:1			0		1.0
67:1			68:1			0		1.0
68:1			69:1			0		1.0
69:1			70:1			0		1.0
70:1			71:1			0		1.0
71:1			72:1			0		1.0
72:1			73:1			0		1.0
73:1			74:1			0		1.0
74:1			75:1			0		1.0
75:1			76:1			0		1.0
76:1			77:1			0		1.0
77:1			78:1			0		1.0
78:1			79:1			0		1.0
79:1			80:1			0		1.0
80:1			81:1			0		1.0
81:1			82:1			0		1.0

Alignment 2926
The variations in each person 's name were collected .
Variations in each person 's name were collected .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0

Alignment 2927
For example , George W. Bush , President Bush , U.S. President , etc. , all refer to the current U.S. president .
For example , George W. Bush , President Bush , U.S. President , etc. , all refer to the current U.S. president .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 2928
We performed simple string search in captions to check whether a caption contains one of these names .
We performed simple string search in captions to check whether a caption contained one of these names .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			1		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 2929
The faces extracted from the corresponding image associated with this caption were returned .
The faces extracted from the corresponding image associated with this caption were returned .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 2930
The faces retrieved from the different name queries were merged into one set and used as input for ranking .
The faces retrieved from the different name queries were merged into one set and used as input for ranking .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 2931
Figure \REF shows the distribution of retrieved faces from this method and the corresponding number of relevant faces for these fifteen individuals .
Figure \REF shows the distribution of retrieved faces from this method and the corresponding number of relevant faces for these fifteen individuals .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 2932
In total , 5 ,603 faces were retrieved in which 3 ,374 faces were relevant .
In total , 5 ,603 faces were retrieved in which 3 ,374 faces were relevant .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 2933
On average , the accuracy was 60 .22\% .
On average , the accuracy was 60 .22\% .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 2934
We used an eye detector to detect the positions of the eyes in the detected faces .
We used an eye detector to detect the positions of the eyes of the detected faces .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 2935
The eye detector , built with the same approach as in \CITE , had an accuracy of more than 95\% .
The eye detector , built with the same approach as that of Viola and jones \CITE , had an accuracy of more than 95\% .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
15:1			11:1			0		1.0
16:1			12:1			0		1.0
17:1			13:1			0		1.0
18:1			14:1			0		1.0
19:1			15:1			0		1.0
20:1			16:1			0		1.0
21:1			17:1			0		1.0
22:1			18:1			0		1.0
23:1			19:1			0		1.0
24:1			20:1			0		1.0

Alignment 2936
If the eye positions were not detected , predefined eye locations were assigned .
If the eye positions were not detected , predefined eye locations were assigned .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 2937
The eye positions were used to align faces to a predefined canonical pose .
The eye positions were used to align faces to a predefined canonical pose .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 2938
To compensate for illumination effects , the subtraction of the bestfit brightness plane followed by histogram equalization was applied .
To compensate for illumination effects , the subtraction of the best-fit brightness plane followed by histogram equalization was applied .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 2939
This normalization process is shown in Figure \REF .
This normalization process is shown in Figure \REF .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 2940
We then used principle component analysis \CITE to reduce the number of dimensions of the feature vector for face representation .
We then used principle component analysis \CITE to reduce the number of dimensions of the feature vector for face representation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 2941
Eigenfaces were computed from the original face set returned by the text-based query method .
Eigenfaces were computed from the original face set returned using the text-based query method .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 2942
The number of eigenfaces used to form the eigen space was selected so that 97\% of the total energy was retained \CITE .
The number of eigenfaces used to form the eigen space was selected so that 97\% of the total energy was retained \CITE . //It is not clear what you mean by " energy " in this context . This is the first time you mention this term . You might want to specify what kind of energy you are talking about .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 2943
The number of dimensions of these feature spaces ranged from 80 to 500 .
The number of dimensions of these feature spaces ranged from 80 to 500 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 2944
We evaluated the retrieval performance with measures that are commonly used in information retrieval , such as precision , recall , and average precision .
We evaluated the retrieval performance with measures that are commonly used in information retrieval , such as precision , recall , and average precision .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 2945
Given a queried person and letting \MATH be the total number of faces returned , \MATH the number of relevant faces , and \MATH the total number of relevant faces , recall and precision can be calculated as follows :
Given a queried person and letting \MATH be the total number of faces returned , \MATH the number of relevant faces , and \MATH the total number of relevant faces , recall and precision can be calculated as follows :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0

Alignment 2946
Precision and recall only evaluate the quality of an unordered set of retrieved faces .
Precision and recall are only used to evaluate the quality of an unordered set of retrieved faces .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			0		1.0
7:1			4:1			0		1.0
8:1			5:1			0		1.0
9:1			6:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0

Alignment 2947
To evaluate ranked lists in which both recall and precision are taken into account , the average precision is usually used .
To evaluate ranked lists in which both recall and precision are taken into account , average precision is usually used .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0

Alignment 2948
The average precision is computed by taking the average of the interpolated precision measured at the 11 recall levels of 0 .0 , 0 .1 , 0 .2 , . . . , 1 .0 .
The average precision is computed by taking the average of the interpolated precision measured at the 11 recall levels of 0 .0 , 0 .1 , 0 .2 , . . . , 1 .0 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0

Alignment 2949
The interpolated precision \MATH at a certain recall level \MATH is defined as the highest precision found for any recall level \MATH :
The interpolated precision \MATH at a certain recall level \MATH is defined as the highest precision found for any recall level \MATH :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 2950
In addition , to evaluate the performance of multiple queries , we used mean average precision , which is the mean of average precisions computed from queries
In addition , to evaluate the performance of multiple queries , we used mean average precision , which is the mean of average precisions computed from queries
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 2951
The parameters of our method include :
The parameters of our method include :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0

Alignment 2952
-\MATH : the fraction of faces lying at the top and bottom of the ranked list that are used to form a positive set \MATH and negative set \MATH for training weak classifiers in Rank-By-Bagging-ProbSVM-InnerLoop .
-\MATH : the fraction of faces at the top and bottom of the ranked list that are used to form a positive set \MATH and negative set \MATH for training weak classifiers in Rank-By-Bagging-ProbSVM-InnerLoop .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0
31:1			32:1			0		1.0
32:1			33:1			0		1.0
33:1			34:1			0		1.0
34:1			35:1			0		1.0

Alignment 2953
We empirically selected \MATH ( i .e 40\% samples of the rank list were used ) since larger \MATH will increase the number of incorrect labels and smaller \MATH will cause over-fitting .
We empirically selected \MATH ( i .e 40\% samples of the rank list were used ) since a larger \MATH will increase the number of incorrect labels , and a smaller \MATH will cause over-fitting .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
28:1			26:1			0		1.0
30:1			27:1			0		1.0
31:1			28:1			0		1.0
32:1			29:1			0		1.0
33:1			30:1			0		1.0
34:1			31:1			0		1.0
35:1			32:1			0		1.0

Alignment 2954
In addition , \MATH consists of \MATH samples that are selected randomly with replacement from \MATH .
In addition , \MATH consists of \MATH samples that are selected randomly with replacement from \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 2955
This sampling strategy is adopted from the bagging framework \CITE .
This sampling strategy is adopted from the bagging framework \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 2956
The same setting was used for \MATH .
The same setting was used for \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 2957
-\MATH : the maximum Kendall tau distance \MATH between two rank lists \MATH and \MATH .
-\MATH : the maximum Kendall tau distance \MATH between two rank lists \MATH and \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 2958
This value is used to determine when the inner loop and the outer loop are stopped .
This value is used to determine when the inner loop and the outer loop stop .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			15:1			1		1.0
15:1			16:1			0		1.0

Alignment 2959
We set \MATH for balance between accuracy and processing time .
We set \MATH for balancing between accuracy and processing time .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			1		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 2960
Note that smaller \MATH requires more number of iterations making the system 's speed slower .
Note that a smaller \MATH requires more iterations , making the system 's speed slower .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 2961
-\MATH : the kernel type is used for SVM .
-\MATH : the kernel type is used for the SVM .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0

Alignment 2962
The default is linear kernel that is defined as : \MATH .
The default is a linear kernel that is defined as : \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0

Alignment 2963
We have tested other kernel types such as RBF or polynomial , the performance did not change so much .
We have tested other kernel types , such as RBF or polynomial , but the performance did not change much .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0

Alignment 2964
Therefore , we used the linear kernel for simplicity .
Therefore , we used the linear kernel for simplicity .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 2965
We performed a comparison between our proposed method with other existing approaches .
We performed a comparison between our proposed method with other ones .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			12:1			0		1.0

Alignment 2966
Text Based Baseline ( TBL ) : Once faces corresponding with images whose captions contain the query name are returned , they are ranked by the time order .
Text Based Baseline ( TBL ) : Once faces corresponding with images whose captions contain the query name are returned , they are ranked in time order .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0

Alignment 2967
This is very naive method in which no prior knowledge between names and faces is used .
This is a rather naive method in which no prior knowledge between names and faces is used .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:2			2:1			3		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0

Alignment 2968
Distance-Based Outlier ( DBO ) : We adopted the idea of distance-based outliers detection for ranking \CITE .
Distance-Based Outlier ( DBO ) : We adopted the idea of distance-based outlier detection for ranking \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			1		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 2969
Given a threshold \MATH , for each point \MATH , we counted the number of points \MATH so that \MATH , where \MATH is the Euclidean distance between \MATH and \MATH in the feature space mentioned in section \REF .
Given a threshold \MATH , for each point \MATH , we counted the number of points \MATH so that \MATH , where \MATH is the Euclidean distance between \MATH and \MATH in the feature space mentioned in section \REF .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0

Alignment 2970
This number then was used as the score to rank faces .
This number was then used as the score to rank faces .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			3:1			0		1.0
3:1			2:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 2971
We selected a range of \MATH values for experiments : \MATH .}
We selected a range of \MATH values for experiments : \MATH .}
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 2972
Densest Sub-Graph based Method ( DSG ) : We re-implemented the densest sub-graph based method \CITE for ranking .
Densest Sub-Graph based Method ( DSG ) : We re-implemented the densest sub-graph based method \CITE for ranking .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 2973
Once the densest subgraph was found after an edge elimination process , we counted the number of surviving edge of each node ( i .e face ) and used this number as the score for ranking .
Once the densest subgraph was found after an edge elimination process , we counted the number of surviving edges of each node ( i .e face ) and used this number as the ranking score .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			1		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			35:1			0		1.0
34:1			33:1			0		1.0
35:1			36:1			0		1.0

Alignment 2974
To form the graph , the Euclidean distance \MATH was used to assign the weight for the edge linked between node $p$ and node \MATH .
To form the graph , the Euclidean distance \MATH was used to assign the weight for the edge linked between node $p$ and node \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 2975
DSG require a threshold \MATH to convert the weighted graph to the binary graph before searching for the densest subgraph .
DSG requires a threshold \MATH to convert the weighted graph to the binary graph before searching for the densest subgraph .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			1		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 2976
We selected a range of \MATH values that are the same as the values used in DBO : \MATH .
We selected a range of \MATH values that are the same as the values used in DBO : \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 2977
Local Density Score ( LDS ) : This is the first stage of our proposed method .
Local Density Score ( LDS ) : This is the first stage of our proposed method .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 2978
It requires the input value \MATH to compute the local density score .
It requires the input value \MATH to compute the local density score .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 2979
Since we do not know the number of returned faces from text based search engines , we used another input value \MATH defined as the fraction of neighbors and estimated \MATH by the formula : \MATH , where \MATH is the number of returned faces .
Since we do not know the number of returned faces from text-based search engines , we used another input value \MATH , defined as the fraction of neighbors , and estimated \MATH by the formula : \MATH , where \MATH is the number of returned faces .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			36:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
38:1			37:1			0		1.0
39:1			38:1			0		1.0
40:1			39:1			0		1.0
41:1			40:1			0		1.0
42:1			41:1			0		1.0
43:1			42:1			0		1.0
44:1			43:1			0		1.0
45:1			44:1			0		1.0
46:1			45:1			0		1.0

Alignment 2980
We used a range of $fraction$ values for experiments : \MATH .
We used a range of $fraction$ values for experiments : \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 2981
In the case of large number of returned faces , we set \MATH to the maximum value of 200 : \MATH .
For a large number of returned faces , we set \MATH to the maximum value of 200 : \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			4:1			0		1.0
3:1			5:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0

Alignment 2982
Unsupervised Ensemble Learning Using Local Density Score ( UEL-LDS ) : This is a combination of ranking by local density scores and then the ranked list is used for training classifier [Singular or plural?]to boost the rank list .
Unsupervised Ensemble Learning Using Local Density Score ( UEL-LDS ) : This is a combination of ranking by local density scores , and the ranked list is used for training a classifier to boost the rank list .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
31:1			30:1			0		1.0
33:1			34:1			0		1.0
34:1			35:1			0		1.0
35:1			36:1			0		1.0
36:1			37:1			0		1.0
37:1			38:1			0		1.0

Alignment 2983
Supervised Learning ( SVM-SUP ) : We randomly selected a portion \MATH of the data with annotations to train the classifier ; and then used this classifier to re-rank remaining faces .
Supervised Learning ( SVM-SUP ) : We randomly selected a portion \MATH of the data with annotations to train the classifier ; and then used this classifier to re-rank the remaining faces .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0

Alignment 2984
This process was repeated five times and the average performance was reported .
This process was repeated five times and the average performance was reported .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 2985
We used a range of portion \MATH values for experiments : \MATH .
We used a range of portion \MATH values for experiments : \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 2986
Figure \REF shows a performance comparison of these methods .
Figure \REF shows a performance comparison of these methods .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 2987
Our proposed methods ( LDS and UEL-LDS ) outperform other unsupervised methods such as TBL , DBO and DSG .
Our proposed methods ( LDS and UEL-LDS ) outperform other unsupervised methods such as TBL , DBO , and DSG .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0

Alignment 2988
Furthermore , the performance of methods DBO and DSG are sensitive to the distance threshold ; while the performance of our proposed method is less sensitive .
Furthermore , the DBO and DSG methods are sensitive to the distance threshold , while the performance of our proposed method is less sensitive .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			6:1			0		1.0
4:1			7:1			0		1.0
5:1			8:1			0		1.0
6:1			5:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0
24:1			26:1			0		1.0

Alignment 2989
It confirms that the similarity measure using shared nearest neighbors is relieable for estimation of the local density score .
It confirms that the similarity measure using shared nearest neighbors is reliable for estimation of the local density score .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 2990
The performance of UEL-LDS is slightly better than LDS since the training sets labeled automatically from the ranked list are noisy .
The performance of UEL-LDS is slightly better than LDS since the training sets labeled automatically from the ranked list are noisy .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 2991
However , UEL-LDS improves the performance significantly even when the performance of LDS is poor .
However , UEL-LDS improves significantly even when the performance of LDS is poor .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0

Alignment 2992
These performances are worse than that of SVM-SUP using a small number of labeled samples .
These performances are worse than that of SVM-SUP using a small number of labeled samples .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 2993
Figure \REF shows an examples of top 50 faces ranked by the methods TBL , DBO , DSG and LDS .
Figure \REF shows an examples of the top 50 faces ranked using the TBL , DBO , DSG , and LDS methods .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			11:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			12:1			0		1.0
22:1			20:1			0		1.0

Alignment 2994
The performance of DBO is poor since a low threshold is used .
The performance of DBO is poor since a low threshold is used .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 2995
This makes irrelevant faces that are near duplicates ( row 2 and row 3 in Figure \REF( b ) ) ranked higher than relevant faces .
This ranks irrelevant faces that are near duplicates ( rows 2 and 3 in Figure \REF( b ) ) higher than relevant faces .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			1		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0

Alignment 2996
This explains the same situation with DSG .
This explains the same situation with DSG .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 2997
In Figure \REF , we show the performance of five single classifiers and that of five ensemble classifiers .
In Figure \REF , we show the performance of five single classifiers and that of five ensemble classifiers .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 2998
The ensemble classifier \MATH is formed by combination of single classifiers from \MATH to \MATH .
The ensemble classifier \MATH is formed by combining single classifiers from \MATH to \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			1		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0

Alignment 2999
It clearly indicates that the ensemble classifier is more stable that single weak classifiers .
It clearly indicates that the ensemble classifier is more stable than single weak classifiers . //You use both plural and singular forms of " classifier " here , so it is a bit confusing if you are talking about a single classifier or more than one . I suggest you use the same form throughout if applicable .]
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 3000
We conducted another experiment to show the effectiveness of our approach in which learned models can be used to annotate new faces of other databases .
We conducted another experiment to show the effectiveness of our approach in which learned models are used to annotate new faces of other databases .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			16:1			2		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0

Alignment 3001
For each name in the list , we used it as the query to obtain top 500 images from Google Image Search Engine .
We used each name in the list as a query to obtain the top 500 images from the Google Image Search Engine ( GoogleSE ) .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			8:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			10:1			0		1.0
9:1			12:1			0		1.0
10:1			13:1			0		1.0
11:1			14:1			0		1.0
12:1			11:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
25:1			23:1			0		1.0

Alignment 3002
Next , these images were processed as the steps described in section \REF : extracting faces , detecting eyes and doing normalization .
Next , these images were processed using the steps described in section \REF : extracting faces , detecting eyes , and doing normalization .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0

Alignment 3003
We projected these faces to the PCA subspace trained for that name and used the learned model to re-rank faces .
We projected these faces to the PCA subspace trained for that name and used the learned model to re-rank faces .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 3004
There were 4 ,103 faces ( including false positives - non-faces were detected as faces ) detected from 7 ,500 returned images .
There were 4 ,103 faces ( including false positives - non-faces detected as faces ) detected from 7 ,500 returned images .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0

Alignment 3005
We manually labeled these faces and there were 2 ,342 relevant faces .
We manually labeled these faces and there were 2 ,342 relevant faces .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 3006
On average , the accuracy of the Google Search Engine ( GoogleSE ) is 57 .08\% .
On average , the accuracy of the GoogleSE is 57 .08\% .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			11:1			0		1.0
8:1			13:1			0		1.0
9:1			14:1			0		1.0
10:1			15:1			0		1.0
11:1			16:1			0		1.0

Alignment 3007
In Table \REF , we compare the performance of the methods .
In Table \REF , we compare the performance of the methods .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 3008
The performance of UEL-LDS was obtained by running the best system , which is shown as the peak of UEL-LDS curve in Figure \REF .
The performance of UEL-LDS was obtained by running the best system , which is shown as the peak of the UEL-LDS curve in Figure \REF .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0

Alignment 3009
The performances of SVM-SUP-05 and SVM-SUP-10 correspond to the supervised systems ( cf . section \REF ) that used \MATH of the data set respectively .
The performances of SVM-SUP-05 and SVM-SUP-10 correspond to the supervised systems ( cf . section \REF ) that used \MATH of the data set , respectively .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0

Alignment 3010
We evaluated the performance by calculating the precision at top 20 returned faces , which is popular for image search engines ; and recall and precision on all detected faces of the test set .
We evaluated the performance by calculating the precision of the top 20 returned faces , which is common for image search engines and recall and precision on all detected faces of the test set .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			30:1			0		1.0
9:1			31:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0

Alignment 3011
UEL-LDS achieved comparable performance to the supervised methods and outperformed the baseline GoogleSE .
UEL-LDS achieved comparable performance to the supervised methods and outperformed the baseline GoogleSE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 3012
The precision at top 20 of SVM-SUP-05 is poorer than that of UEL-LDS is due to small number of training samples .
The precision of the top 20 of SVM-SUP-05 is poorer than that of UEL-LDS due to the small number of training samples .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			18:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0

Alignment 3013
Figure \REF shows top 20 faces ranked by these two methods .
Figure \REF shows top 20 faces ranked using these two methods .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 3014
Our approach works fairly well for well known people , where the main assumption that text-based search engines return a large fraction of relevant images is satisfied .
Our approach works fairly well for well known people , where the main assumption that text-based search engines return a large fraction of relevant images is satisfied .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0

Alignment 3015
Figure \REF shows an example where this assumption is broken .
Figure \REF shows an example where this assumption is broken .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 3016
Consequently , as shown in Figure \REF , the model learned by this set obtained poor performance in recognizing new faces returned by GoogleSE .
Consequently , as shown in Figure \REF , the model learned by this set performed poorly in recognizing new faces returned by GoogleSE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			16:1			1		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0

Alignment 3017
Our approach solely relies on the above assumption , therefore it is not affected by the ranking of text-based search engines .
Our approach solely relies on the above assumption ; therefore , it is not affected by the ranking of text-based search engines .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			9:1			0		1.0
10:1			8:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0

Alignment 3018
The iteration of bagging SVM classifiers does not guarantee a significant improvement in performance .
The iteration of bagging SVM classifiers does not guarantee a significant improvement in performance .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 3019
Our future work is to study how to improve the quality of the training sets used in this iteration .
The aim of our future work is to study how to improve the quality of the training sets used in this iteration .
Line2Start:Length	Line1Start:Length	Module		Score
4:1			1:1			0		1.0
5:1			2:1			0		1.0
6:1			3:1			0		1.0
7:1			4:1			0		1.0
8:1			5:1			0		1.0
9:1			6:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			0		1.0

Alignment 3020
We presented a method for ranking faces retrieved using text-based correlation methods in searches for a specific person .
We presented a method for ranking faces retrieved using text-based correlation methods in searches for a specific person .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 3021
This method learns the visual consistency among the faces in a two-stage process .
This method learns the visual consistency among faces in a two-stage process .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0

Alignment 3022
In the first stage , a relative density score is used to form a ranked list in which faces ranked at the top or bottom of the list are likely relevant or irrelevant faces .
In the first stage , a relative density score is used to form a ranked list in which faces ranked at the top or bottom of the list are likely to be relevant or irrelevant faces , respectively .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
32:1			30:1			0		1.0
33:1			31:1			0		1.0
34:1			32:1			0		1.0
35:1			33:1			0		1.0
38:1			34:1			0		1.0

Alignment 3023
In the second stage , a bagging framework is used to combine weak classifiers trained on subsets labeled from the ranked list into a strong classifier .
In the second stage , a bagging framework is used to combine weak classifiers trained on subsets labeled from the ranked list into a strong classifier .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 3024
This strong classifier is then applied to the original set to re-rank faces on the basis of the output probabilistic scores .
This strong classifier is then applied to the original set to re-rank faces on the basis of the output probabilistic scores .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 3025
Experiments on various face sets showed the effectiveness of this method .
Experiments on various face sets showed the effectiveness of this method .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 3026
Our approach is beneficial in the case multiple faces residing in the returned image as shown in Figure \REF .
Our approach is beneficial when there are several faces in a returned image , as shown in Figure \REF .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
7:1			7:1			3		1.0
8:1			8:1			0		1.0
9:1			4:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 3027
A Text Segmentation Based Approach to Video Shot Boundary Detection
A Text Segmentation Based Approach to Video Shot Boundary Detection
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 3028
Video shot boundary detection is one of the fundamental tasks of video indexing and retrieval applications .
Video shot boundary detection is one of the fundamental tasks of video indexing and retrieval applications .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 3029
Although many methods have been proposed for this task , finding a general and robust shot boundary method that is able to handle various transition types caused by photo flashes , rapid camera movement and object movement is still challenging .
Although many methods have been proposed for this task , finding a general and robust shot boundary method that is able to handle the various transition types caused by photo flashes , rapid camera movement , and object movement is still challenging .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
36:1			34:1			0		1.0
37:1			35:1			0		1.0
38:1			36:1			0		1.0
39:1			37:1			0		1.0
40:1			38:1			0		1.0
41:1			39:1			0		1.0
42:1			40:1			0		1.0

Alignment 3030
In this paper , we present a novel approach for detecting video shot boundaries in which we cast the problem of shot boundary detection into the problem of text segmentation in natural language processing .
We present a novel approach for detecting video shot boundaries in which we cast the problem of shot boundary detection into the problem of text segmentation in natural language processing . //detecting / determining?
Line2Start:Length	Line1Start:Length	Module		Score
1:1			5:1			0		1.0
2:1			6:1			0		1.0
3:1			7:1			0		1.0
4:1			8:1			0		1.0
5:1			9:1			0		1.0
6:1			10:1			0		1.0
7:1			11:1			0		1.0
8:1			12:1			0		1.0
9:1			13:1			0		1.0
10:1			14:1			0		1.0
11:1			15:1			0		1.0
12:1			16:1			0		1.0
13:1			17:1			0		1.0
14:1			18:1			0		1.0
15:1			19:1			0		1.0
16:1			20:1			0		1.0
17:1			21:1			0		1.0
18:1			22:1			0		1.0
19:1			23:1			0		1.0
20:1			24:1			0		1.0
21:1			25:1			0		1.0
22:1			26:1			0		1.0
23:1			27:1			0		1.0
24:1			28:1			0		1.0
25:1			29:1			0		1.0
26:1			30:1			0		1.0
27:1			31:1			0		1.0
28:1			32:1			0		1.0
29:1			33:1			0		1.0
30:1			34:1			0		1.0

Alignment 3031
By the formulation that each frame is considered as a word and shot boundaries are treated as boundaries of text segments ( e .g topics ) .
This is possible by assuming that each frame is a word and then the shot boundaries are treated as text segment boundaries ( e.g. topics ) .
Line2Start:Length	Line1Start:Length	Module		Score
5:1			3:1			0		1.0
6:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
13:1			1:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			1		1.0
21:1			17:1			0		1.0
22:1			21:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 3032
Text segmentation based approaches that have been well studied in natural language processing can be adopted .
The text segmentation based approaches in natural language processing can be used .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			9:1			0		1.0
6:1			10:1			0		1.0
7:1			11:1			0		1.0
8:1			12:1			0		1.0
9:1			13:1			0		1.0
10:1			14:1			0		1.0
12:1			16:1			0		1.0

Alignment 3033
Experimental results on various long video sequences show the effectiveness of our approach .
The experimental results from various long video sequences have proven the effectiveness of our approach .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
9:1			7:1			2		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0

Alignment 3034
Recent advances in digital technology have made many video archives available .
Recent advances in digital technology have made many video archives readily available .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0

Alignment 3035
Therefore scalable , efficient and effective tools for indexing and retrieving video are needed .
Therefore scalable , efficient , and effective tools for indexing and retrieving video are needed .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0

Alignment 3036
With a large amount of information encoded in one video , typically the first step of any video processing tools is to segment the input video into elementary shots in which each shot is defined as continuous frames from a single camera at a time .
With a large amount of information encoded in one video , typically the first step of any video processing tools is to segment the input video into elementary shots in which each shot is defined as a continuous frame from a single camera at a given moment .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			43:1			0		1.0
37:1			36:1			0		1.0
38:1			37:1			1		1.0
39:1			38:1			0		1.0
40:1			39:1			0		1.0
41:1			40:1			0		1.0
42:1			41:1			0		1.0
43:1			42:1			0		1.0
46:1			44:1			3		1.0
47:1			45:1			0		1.0

Alignment 3037
By decomposing a video into shots and then extracting keyframes from these shots , a 30-minute video with 54 ,000 frames can be represented by around 500 keyframes ( 108 times smaller ) which are easily manageable for many video applications in indexing , browsing , summarization , retrieval and so on .
By breaking down a video into individual shots and then extracting the keyframes from these shots , a 30-minute video containing 54 ,000 frames can be represented by around 500 keyframes ( 108 times smaller ) that are easily manageable for many video applications [in / such as? / including?] indexing , browsing , summarization , and retrieval .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0
26:1			23:1			0		1.0
27:1			24:1			0		1.0
28:1			25:1			0		1.0
29:1			26:1			0		1.0
30:1			27:1			0		1.0
31:1			28:1			0		1.0
32:1			29:1			0		1.0
33:1			30:1			0		1.0
34:1			31:1			0		1.0
35:1			32:1			0		1.0
36:2			33:2			3		1.0
38:1			35:1			0		1.0
39:1			36:1			0		1.0
40:1			37:1			0		1.0
41:1			38:1			0		1.0
42:1			39:1			0		1.0
43:1			40:1			0		1.0
50:1			42:1			0		1.0
51:1			43:1			0		1.0
52:1			44:1			0		1.0
53:1			45:1			0		1.0
54:1			46:1			0		1.0
55:1			47:1			0		1.0
56:1			49:1			0		1.0
57:1			48:1			0		1.0
58:1			52:1			0		1.0

Alignment 3038
There are many types of transitions between shots .
There are many types of transitions between shots .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 3039
According to TRECVID 's categorization \CITE , shot boundaries can be classified into two main categories : cut and gradual .
According to TRECVID 's categorization \CITE , shot boundaries can be classified into two main categories : cut and gradual .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 3040
A cut is an abrupt shot change that occurs in a single frame while a gradual is a slow change that occurs in a number of consecutive frames .
A cut is an abrupt shot change that occurs in a single frame while a gradual is a slow change that occurs over a number of consecutive frames .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 3041
With the gradual type , fades and dissolves are common .
With the gradual type , fades and dissolves are common .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 3042
A fade is usually a change in brightness with one or several solid black frames in between , while a dissolve occurs when the images in the current shot get dimmer and the images of the next shot get brighter \CITE .
A fade is usually a change in brightness with one or several solid black frames in between the key frames , while a dissolve occurs when the images in the current shot get dimmer and the images of the next shot get brighter \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			35:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0
26:1			23:1			0		1.0
27:1			24:1			0		1.0
28:1			25:1			0		1.0
29:1			26:1			0		1.0
30:1			27:1			0		1.0
31:1			28:1			0		1.0
32:1			29:1			0		1.0
33:1			30:1			0		1.0
34:1			31:1			0		1.0
35:1			32:1			0		1.0
36:1			33:1			0		1.0
37:1			34:1			0		1.0
39:1			36:1			0		1.0
40:1			37:1			0		1.0
41:1			38:1			0		1.0
42:1			39:1			0		1.0
43:1			40:1			0		1.0
44:1			41:1			0		1.0

Alignment 3043
Figure \REF shows examples of shot boundary types .
Figure \REF shows examples of shot boundary types .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 3044
Many approaches have been proposed for shot boundary detection .
Many approaches have been proposed for shot boundary detection .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 3045
The simplest approach is to compute the differences between color distributions of consecutive frames and use a threshold to classify whether a hard cut occurs .
The simplest approach is to compute the differences between the color distributions of consecutive frames and use a threshold to classify whether a hard cut occurs .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0

Alignment 3046
In order to detect gradual transitions , edge change ratio or motion vectors can be used \CITE .
In order to detect gradual transitions , edge change ratios or motion vectors can be used \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			1		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 3047
Since these approaches use threshold-based models for detection , their advantage is fast speed .
Since these approaches use threshold-based models for detection , their advantage is they are fast .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			14:1			0		1.0

Alignment 3048
Nevertheless , they are sensitive to changes of illumination and motion .
Nevertheless , they are sensitive to changes in illumination and motion .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:2			6:2			3		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 3049
Furthermore , they are difficult to generalize for new datasets .
Furthermore , they are difficult to generalize for new datasets .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 3050
Recent works \CITE use machine learning methods for making decision and show impressive results on test videos of TRECVID \CITE which is a de-facto benchmark for evaluation of various techniques in shot boundary detection .
Recent works \CITE use machine learning methods for making decisions and have received impressive results on the test videos of TRECVID \CITE , which is a de-facto benchmark for evaluating the various techniques used in shot boundary detection .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:2			9:2			3		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0
26:1			23:1			0		1.0
27:1			24:1			0		1.0
28:1			25:1			0		1.0
29:1			26:2			3		1.0
31:1			28:1			0		1.0
32:1			29:1			0		1.0
34:1			30:1			0		1.0
35:1			31:1			0		1.0
36:1			32:1			0		1.0
37:1			33:1			0		1.0
38:1			34:1			0		1.0

Alignment 3051
In this study , we propose a new approach inspired from natural language processing text segmentation techniques in which the problem of shot boundary detection is treated similarly to the problem of text segmentation .
In this study , we propose a new approach that was inspired by the natural language processing text segmentation techniques in which the problem of shot boundary detection is treated similarly to the problem in text segmentation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
11:1			9:1			0		1.0
13:1			29:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0
26:1			23:1			0		1.0
27:1			24:1			0		1.0
28:1			25:1			0		1.0
29:1			26:1			0		1.0
30:1			27:1			0		1.0
31:1			28:1			0		1.0
33:2			30:2			3		1.0
35:1			32:1			0		1.0
36:1			33:1			0		1.0
37:1			34:1			0		1.0

Alignment 3052
Specifically , each frame is considered as a word and a set of consecutive frames , forming a shot , is considered as a text segment .
Specifically , each frame is considered a word and a set of consecutive frames , forming a shot , is considered a text segment .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0
24:1			26:1			0		1.0

Alignment 3053
Then , the text segmentation problem can be considered a sequential tagging problem in which each word is labeled by one of labels such as
Then , the text segmentation problem can be considered a sequential tagging problem in which each word is labeled by one of the following labels :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
24:1			22:1			0		1.0

Alignment 3054
PRESEG ( word beginning of a segment ) , INSEG ( word inside a segment ) and POSTSEG ( word outside a segment ) .
PRESEG ( word beginning of a segment ) , INSEG ( word inside a segment ) , and POSTSEG ( word outside a segment ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0

Alignment 3055
Given a sequence of labeled words , the boundary between text segments can be identified .
Given a sequence of labeled words , the boundary between text segments can be identified .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 3056
The remaining of the paper is organized as follows .
The remainder of this paper is organized as follows .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			3		1.0
2:1			2:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 3057
In section \REF , we present an overview of our framework .
In section \REF , we present an overview of our framework .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 3058
Section \REF introduces experiments on different long video sequences from TRECVID dataset .
Section \REF introduces our experiments on different long video sequences from the TRECVID dataset .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0

Alignment 3059
Section \REF concludes the paper .
Section \REF concludes the paper .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0

Alignment 3060
Given a video , the shot boundary detection process is carried out through two main stages .
The shot boundary detection process for a given video is carried out through two main stages .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			5:1			0		1.0
2:1			6:1			0		1.0
3:1			7:1			0		1.0
4:1			8:1			0		1.0
6:1			1:1			0		1.0
8:1			2:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 3061
In the first stage , frames are extracted and labeled by pre-defined labels .
In the first stage , frames are extracted and labeled with pre-defined labels .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 3062
In the second stage , shot boundaries are identified by grouping labeled frames into segments .
In the second stage , the shot boundaries are identified by grouping the labeled frames into segments .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0

Alignment 3063
We use the following six labels to label frames in video : NORM -FRM ( frame of a normal shot ) , PRE -CUT ( pre-frame of a CUT transition ) , POST -CUT ( post-frame of a CUT transition ) , PRE -GRAD ( pre-frame of a GRADUAL transition ) , IN -GRAD ( frame inside a GRADUAL transition ) , POST -GRAD ( post-frame of a GRADUAL transition ) .
We use the following six labels to label frames in a video : NORM -FRM ( frame of a normal shot ) , PRE -CUT ( pre-frame of a CUT transition ) , POST -CUT ( post-frame of a CUT transition ) , PRE -GRAD ( pre-frame of a GRADUAL transition ) , IN -GRAD ( frame inside a GRADUAL transition ) , and POST -GRAD ( post-frame of a GRADUAL transition ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			67:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
37:1			36:1			0		1.0
38:1			37:1			0		1.0
39:1			38:1			0		1.0
40:1			39:1			0		1.0
41:1			40:1			0		1.0
42:1			41:1			0		1.0
43:1			42:1			0		1.0
44:1			43:1			0		1.0
45:1			44:1			0		1.0
46:1			45:1			0		1.0
47:1			46:1			0		1.0
48:1			47:1			0		1.0
49:1			48:1			0		1.0
50:1			49:1			0		1.0
51:1			50:1			0		1.0
52:1			51:1			0		1.0
53:1			52:1			0		1.0
54:1			53:1			0		1.0
55:1			54:1			0		1.0
56:1			55:1			0		1.0
57:1			56:1			0		1.0
58:1			57:1			0		1.0
59:1			58:1			0		1.0
60:1			59:1			0		1.0
61:1			60:1			0		1.0
62:1			61:1			0		1.0
64:1			62:1			0		1.0
65:1			63:1			0		1.0
66:1			64:1			0		1.0
67:1			65:1			0		1.0
68:1			66:1			0		1.0
70:1			68:1			0		1.0
71:1			69:1			0		1.0
72:1			70:1			0		1.0
73:1			71:1			0		1.0

Alignment 3064
Given a sequence of labeled frames , shot boundaries and transition types are identified by looking up and processing frames marked by non NORM -FRM label .
Given a sequence of labeled frames , the shot boundaries and transition types are identified by looking up and processing the frames marked with a non NORM -FRM label .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
25:1			22:1			0		1.0
26:1			23:1			0		1.0
27:1			24:1			0		1.0
28:1			25:1			0		1.0
29:1			26:1			0		1.0

Alignment 3065
For example , if we encounter two consecutive frames marked by IN-CUT and POST-CUT respectively , we can declare that a shot boundary occurs at these frames and the transition type is CUT .
For example , if we encounter two consecutive frames respectively marked by IN-CUT and POST-CUT , we can declare that a shot boundary occurs at these frames and the transition type is a CUT .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			14:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0

Alignment 3066
In another case , if we encounter a number of frames marked by xxx-GRAD , we can declare a GRADUAL shot boundary occurs at these frames .
In another case , if we encounter a number of frames marked by xxx-GRAD , we can declare that a GRADUAL shot boundary occurs at these frames .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0

Alignment 3067
Figure \REF shows an example of labeled frames of a shot transition .
Figure \REF shows an example of the labeled frames of a shot transition .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0

Alignment 3068
To label a frame in video , firstly we extract features for that frame and then use a classifier , that has been trained by annotated frames in advance , to classify it into one of six categories mentioned above .
To label a frame in a video , we must firstly extract the features for that frame and then use a classifier , which has been trained in advance by the annotated frames , to classify it into one of the six categories mentioned above .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			17:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			8:1			0		1.0
10:1			7:1			0		1.0
11:1			9:1			0		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			0		1.0
23:2			20:2			3		1.0
25:1			22:1			0		1.0
26:1			23:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			24:1			0		1.0
31:1			25:1			0		1.0
32:1			26:1			0		1.0
33:1			29:1			0		1.0
34:1			30:1			0		1.0
35:1			31:1			0		1.0
36:1			32:1			0		1.0
37:1			33:1			0		1.0
38:1			34:1			0		1.0
39:1			35:1			0		1.0
41:1			36:1			0		1.0
42:1			37:1			0		1.0
43:1			38:1			0		1.0
44:1			39:1			0		1.0
45:1			40:1			0		1.0

Alignment 3069
The feature extraction process and classifier learning using support vector machine ( SVM ) are described in details below .
The feature extraction process and classifier learning using a support vector machine ( SVM ) are described in detail below .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			1		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0

Alignment 3070
We use two typical features that are color moments , edge direction histogram for representing visual information of each frame .
We use two typical features , which are the color moments and edge direction histogram , to represent the visual information of each frame .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			9:1			0		1.0
6:3			5:2			3		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
16:2			14:1			3		1.0
19:1			15:1			0		1.0
20:1			16:1			0		1.0
21:1			17:1			0		1.0
22:1			18:1			0		1.0
23:1			19:1			0		1.0
24:1			20:1			0		1.0

Alignment 3071
However , using this representation is not discriminative enough for frame categorization since frames of a shot transition usually have strong relation to their neighbor frames .
However , using this representation is not discriminative enough for frame categorization since the frames of a shot transition usually strongly relate to their neighboring frames .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			20:1			1		1.0
21:1			21:1			1		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			1		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 3072
For example , an abrupt change in illumination between two consecutive frames is a strong cue for a hard cut , or one solid black frames in between dark and then bright frames might help to identify a fade shot transition .
For example , an abrupt change in illumination between two consecutive frames is a strong cue for a hard cut , or one solid black frame in between dark and then bright frames might help to identify a fade shot transition .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			1		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0

Alignment 3073
Therefore , in this study , we do not directly use above features .
Therefore , in this study , we do not directly use the above features .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0

Alignment 3074
Instead , we use them indirectly to model the difference and motion between the current frame and its neighbor frames .
Instead , we use them indirectly to model the difference and motion between the current frame and its neighboring frames .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			1		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 3075
Specifically , for each frame , we compute \MATH distances between the current frame \MATH and neighbor frames ranging from \MATH .
In particular , for each frame , we compute \MATH distances between the current frame \MATH and neighboring frames ranging from \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			1		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0

Alignment 3076
These distances are used to form a feature vector for frame \MATH in training and testing process later .
These distances are used to form a feature vector for frame \MATH in the training and testing process later .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0

Alignment 3077
By this way , we can have a unified framework for shot boundary detection and consequently avoid to have special treatments for different shot boundary types as described in many works participated the TRECVID benchmark \CITE .
In this way , we can have a unified framework for the shot boundary detection and consequently avoid having to give special treatment to the different shot boundary types as described in many of the works that participated the TRECVID benchmark \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			32:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			2		1.0
21:1			19:1			0		1.0
22:1			20:1			1		1.0
25:1			22:1			0		1.0
26:1			23:1			0		1.0
27:1			24:1			0		1.0
28:1			25:1			0		1.0
29:1			26:1			0		1.0
30:1			27:1			0		1.0
31:1			28:1			0		1.0
32:1			29:1			0		1.0
35:1			30:1			0		1.0
37:1			31:1			0		1.0
39:1			33:1			0		1.0
40:1			34:1			0		1.0
41:1			35:1			0		1.0
42:1			36:1			0		1.0

Alignment 3078
Color moments have been successfully used in retrieval systems and proved to be efficient and effective in representing color distributions of images \CITE .
Color moments have been successfully used in retrieval systems and proved to be efficient and effective in representing the color distributions of images \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0

Alignment 3079
The first order ( mean ) , the second order ( variance ) and the third order ( skewness ) color moments are defined as :
The first order ( mean ) , the second order ( variance ) , and the third order ( skewness ) color moments are defined as :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0

Alignment 3080
where \MATH is the value of the \MATH -th color component of the image pixel \MATH , and \MATH is the number of pixels in the image .
where \MATH is the value of the \MATH -th color component of image pixel \MATH , and \MATH is the number of pixels in the image .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0

Alignment 3081
Edge orientation histogram has also been used widely in shot boundary detection \CITE .
Edge orientation histogram has also been widely used in shot boundary detection \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			7:1			0		1.0
7:1			6:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 3082
The basic steps to compute edge orientation histogram feature are as follows :
The basic steps for computing the edge orientation histogram features are as follows :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:2			2:2			3		1.0
4:1			4:1			1		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			1		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0

Alignment 3083
Extract edges from the input image by using Canny edge detector .
Extract edges from the input image by using Canny edge detector .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 3084
Compute a \MATH -bin histogram of edge and non-edge pixels .
Compute a \MATH -bin histogram of edge and non-edge pixels .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 3085
The first \MATH bins are used to represent edge directions quantized at \MATH interval and the remaining bin is used for counting non-edge pixels .
The first \MATH bins are used to represent the edge directions quantized at a \MATH interval and the remaining bin is used for counting the non-edge pixels .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
25:1			22:1			0		1.0
26:1			23:1			0		1.0
27:1			24:1			0		1.0

Alignment 3086
The histogram is normalized by the number of all pixels to compensate for different image sizes .
The histogram is normalized by the total number of all the pixels to compensate for different image sizes .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0

Alignment 3087
We use color moments and edge orientation histogram to compute distances between the current frame \MATH and it neighbor frames as follows :
We use color moments and an edge orientation histogram to compute the distances between the current frame \MATH and its neighboring frames as follows :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			1		1.0
20:1			18:1			1		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0

Alignment 3088
The input image is converted to LUV color space ( for GCM ) or grayscale ( for EOH ) and then divided into sub-images by a \MATH grid .
The input image is converted to a LUV color space ( for GCM ) or grayscale ( for EOH ) and then divided into sub-images by a \MATH grid .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0

Alignment 3089
The color moments and edge orientation histogram are extracted from these sub-images .
The color moments and edge orientation histogram are extracted from these sub-images .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 3090
For color moments , there are \MATH values .
For color moments , there are \MATH values .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 3091
For edge orientation histogram , there are \MATH values for each input frame image .
For the edge orientation histogram , there are \MATH values for each input frame image .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0

Alignment 3092
Compute \MATH values which are the Euclidean distance between current frame \MATH and its neighbor frames ranging from \MATH .
Compute \MATH values , which are the Euclidean distances between the current frame \MATH and its neighboring frames ranging from \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			1		1.0
9:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			1		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0

Alignment 3093
In other words , we compute \MATH where \MATH .
In other words , we compute \MATH , where \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0

Alignment 3094
These values \MATH are then used to form the feature vector for frame \MATH .
These values \MATH are then used to form the feature vector for frame \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 3095
The Support Vector Machines ( SVM ) is a statistical learning method based on the structure risk minimization principle \CITE .
Support Vector Machines ( SVM ) are a statistical learning method based on the structure risk minimization principle \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			1:1			0		1.0
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			2		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0

Alignment 3096
It has been very efficiently proved in many pattern recognition applications \CITE .
They have been very efficiently proved to be useful in many pattern recognition applications \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
1:2			1:2			3		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
9:1			6:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0

Alignment 3097
In the binary classification case , the objective of the SVM is to find a best separating hyperplane with a maximum margin .
In the case of binary classification , the objective of the SVM is to find the best separating hyperplane with a maximum margin .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			4:1			0		1.0
4:1			2:1			0		1.0
5:1			3:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:2			14:2			3		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0

Alignment 3098
The form of SVM classifiers is : \MATH
The form of the SVM classifiers is : \MATH
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0

Alignment 3099
where \MATH is the d-dimensional vector of an observation example , \MATH is a class label , \MATH is the vector of the \MATH training example , \MATH is the number of training examples , and \MATH is a kernel function , \MATH is learned through the learning process .
where \MATH is the d-dimensional vector of an observation example , \MATH is the class label , \MATH is the vector of the \MATH training example , \MATH is the number of training examples , and \MATH is a kernel function , \MATH is learned through the learning process .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			46:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0
49:1			49:1			0		1.0

Alignment 3100
SVM were originally designed for binary classification .
SVMs were originally designed for binary classification .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 3101
To handle the case of multi-class classification , there are two common approaches .
There are two common approaches for handling multi-class classification .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			9:1			0		1.0
2:1			10:1			0		1.0
3:1			11:1			0		1.0
4:1			12:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			13:1			0		1.0

Alignment 3102
The first one is the one-against-all method that combines \MATH binary classifiers where \MATH is the number of classes .
The first one is the one-against-all method that combines \MATH binary classifiers , where \MATH is the number of classes .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0

Alignment 3103
The \MATH SVM classifier is trained by positive samples being examples of the \MATH class and negative samples being examples of the other classes .
The \MATH SVM classifier is trained using positive samples as examples of the \MATH class and negative samples as the examples of the other classes .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0

Alignment 3104
The second one is the one-against-one method that combines \MATH binary classifiers in which each classifier is trained on examples of two classes .
The second one is the one-against-one method that combines \MATH binary classifiers in which each classifier is trained on examples from the two classes .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0

Alignment 3105
There are seven classes in our framework : NORM FRM ( frame of a normal shot ) , PRE CUT ( pre-frame of a CUT transition ) , POST CUT ( postframe
There are seven classes in our framework : NORM FRM ( frame of a normal shot ) , PRE CUT ( pre-frame of a CUT transition ) , POST CUT ( postframe
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0

Alignment 3106
of a CUT transition ) , PRE GRAD ( pre-frame of a GRADUAL transition ) , IN GRAD ( frame inside a GRADUALtransition ) , POST GRAD ( post-frame of a GRADUAL transition ) and NORM-FRM ( normal frame which does not belong to any shot transitions ) .
of a CUT transition ) , PRE GRAD ( pre-frame of a GRADUAL transition ) , IN GRAD ( frame inside a GRADUALtransition ) , POST GRAD ( post-frame of a GRADUAL transition ) , and NORM-FRM ( normal frame that does not belong to any shot transitions ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
37:1			36:1			0		1.0
38:1			37:1			0		1.0
39:1			38:1			0		1.0
40:4			39:4			3		1.0
44:1			43:1			0		1.0
45:1			44:1			0		1.0
46:1			45:1			0		1.0
47:1			46:1			0		1.0
48:1			47:1			0		1.0
49:1			48:1			0		1.0

Alignment 3107
To learn this classifier , we manually annotate frames in the training data .
To train this classifier , we manually annotated frames in the training data . //learn / learn about? / find? / educate? / develop? / train?
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			1		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
16:1			1:1			0		1.0

Alignment 3108
Using the trained classifier , we can label a sequence of frames with tags mentioned above .
Using the trained classifier , we can label a sequence of frames with the tags mentioned above .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0

Alignment 3109
A gradual transition usually has the pattern " ` . . . , PRE-GRAD , IN-GRAD , IN-GRAD , . . . , IN-GRAD , POS-GRAD , . . . " ' and a cut transition usually has the pattern " ` . . . , PRE-CUT , IN-CUT , . . . , IN-CUT , POST-CUT , . . . " ' .
A gradual transition usually has a " ` . . . , PRE-GRAD , IN-GRAD , IN-GRAD , . . . , IN-GRAD , POS-GRAD , . . . " ' pattern and a cut transition usually has a " ` . . . , PRE-CUT , IN-CUT , . . . , IN-CUT , POST-CUT , . . . " 'pattern .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			33:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0
31:1			6:1			0		1.0
32:1			32:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:2			37:2			3		1.0
39:1			40:1			0		1.0
40:1			41:1			0		1.0
41:1			42:1			0		1.0
42:1			43:1			0		1.0
43:1			44:1			0		1.0
44:1			45:1			0		1.0
45:1			46:1			0		1.0
46:1			47:1			0		1.0
47:1			48:1			0		1.0
48:1			49:1			0		1.0
49:1			50:1			0		1.0
50:1			51:1			0		1.0
51:1			52:1			0		1.0
52:1			53:1			0		1.0
53:1			54:1			0		1.0
54:1			55:1			0		1.0
55:1			56:1			0		1.0
56:1			57:1			0		1.0
57:1			58:1			0		1.0
58:1			59:1			0		1.0
59:1			60:1			0		1.0
60:1			61:1			0		1.0
62:1			63:1			0		1.0

Alignment 3110
The shot boundary detection process is started by checking these transition patterns in the tagged sequence .
The shot boundary detection process is started by checking for these transition patterns in the tagged sequence .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0

Alignment 3111
Once a pattern is encountered , PRE-xxx and POST-xxx tags are used to identify the shot boundary and the two ends of the shot transition .
Once a pattern is encountered , PRE-xxx and POST-xxx tags are used to identify the shot boundary and the two ends of the shot transition .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 3112
Since the classifier occasionally produce false predictions due to variations caused by photo flashes , rapid camera movement and object movement , only using the perfect match between the predefined patterns and sub-sequences usually skips many truth shot boundaries .
Since the classifier occasionally produces false predictions due to the variations caused by photo flashes , rapid camera movement , and object movement , only using the perfect match between the predefined patterns and sub-sequences usually skips many of the true shot boundaries .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			1		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			28:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			21:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
33:1			31:1			0		1.0
34:1			32:1			0		1.0
35:1			33:1			0		1.0
36:1			34:1			0		1.0
37:1			35:1			0		1.0
40:1			36:1			3		1.0
41:1			37:1			0		1.0
42:1			38:1			0		1.0
43:1			39:1			0		1.0

Alignment 3113
Instead , we use a more flexible matching algorithm in which a match is declared if a portion of the predefined pattern is found in the input sub-sequence .
Instead , we use a more flexible matching algorithm in which a match is declared if a portion of the predefined pattern is found in the input sub-sequence .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 3114
We used annotated data sets from TRECVID 2003 test sets for training and testing .
We used annotated data sets from the TRECVID 2003 test sets for the training and testing .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0

Alignment 3115
We divided 8 videos , each 30-minute length , into two sets : training set and testing set .
We divided eight videos , each 30-minute long , into two sets : a training set and a test set .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			2		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			3		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:2			16:1			3		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0

Alignment 3116
The number of frames , the number of shot boundaries and types of these sets are shown in Table \REF .
The number of frames , the number of shot boundaries , and the types of these sets are shown in Table \REF .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0

Alignment 3117
Note that , the number of shot boundaries is equal to the number of frames with PRE-CUT / GRAD label and the number of frames with PRE-CUT / GRAD label is equal to the number of frames with POST-CUT / GRAD label .
Note that , the number of shot boundaries is equal to the number of frames with a PRE-CUT / GRAD label and the number of frames with a PRE-CUT / GRAD label is equal to the number of frames within a POST-CUT / GRAD label .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
33:1			31:1			0		1.0
34:1			32:1			0		1.0
35:1			33:1			0		1.0
36:1			34:1			0		1.0
37:1			35:1			0		1.0
38:1			36:1			0		1.0
41:1			38:1			0		1.0
42:1			39:1			0		1.0
43:1			40:1			0		1.0
44:1			41:1			0		1.0
45:1			42:1			0		1.0

Alignment 3118
We used \MATH grid for dividing the input image into sub-images .
We used \MATH grid to divide the input image into sub-images .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:2			5:1			3		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 3119
As for edge orientation histogram , we used 12-bins for edge pixels and one bin for non-edge pixels .
As for the edge orientation histogram , we used 12-bins for the edge pixels and one bin for the non-edge pixels .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0

Alignment 3120
Furthermore , we used 20 neighbor frames before and after the current frame ( \MATH ) for computing the distances .
Furthermore , we used 20 neighboring frames before and after the current frame ( \MATH ) for computing the distances .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			1		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 3121
These parameters were selected from our empirical studies when participating TRECVID 's tasks .
These parameters were selected from our empirical studies when participating in TRECVID 's tasks .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0

Alignment 3122
The extracted features are normalized to zero mean and unit standard deviation and then stored for training and testing .
The extracted features are normalized to zero mean and a unit standard deviation and then stored for training and testing .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0

Alignment 3123
Specifically , the normalized vector \MATH
Specifically , the normalized vector \MATH
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0

Alignment 3124
where \MATH is the \MATH-th element of the feature vectors \MATH respectively , \MATH is the number of dimensions .
where \MATH is the \MATH-th element of the feature vectors \MATH , respectively , and \MATH is the number of dimensions .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			12:1			0		1.0
12:1			11:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0

Alignment 3125
In order to handle the problem of imbalanced training sets where the number of NORM-FRM frames is much larger than other frames , we randomly take \MATH of NORM-FRM frames and 100\% of the other frames to form the training set .
In order to handle the problem of imbalanced training sets where the number of NORM-FRM frames is much larger than other frames , we randomly take the \MATH of NORM-FRM frames and 100\% of the other frames to form the training set .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			38:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
37:1			36:1			0		1.0
38:1			37:1			0		1.0
40:1			39:1			0		1.0
41:1			40:1			0		1.0
42:1			41:1			0		1.0

Alignment 3126
We use LibSVM \CITE to train SVM classifiers with RBF kernel .
We use LibSVM \CITE to train the SVM classifiers with a RBF kernel .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0

Alignment 3127
The optimal \MATH parameters are found by conducting a grid search with 5-fold cross validation on a subset 10 ,000 samples stratified selected from the original dataset .
The optimal \MATH parameters are found by conducting a grid search with a 5-fold cross validation on a subset of 10 ,000 samples stratified selected from the original dataset .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0

Alignment 3128
As for multi-class classification , LibSVM used the one-against-one approach .
As for the multi-class classification , LibSVM used the one-against-one approach .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0

Alignment 3129
The results that were evaluated by a tool provided by TRECVID with standard measurement such as precision , recall and F1 score clearly show that our proposed method significantly outperforms the baseline method and the combination of GCM+EOH obtains the best result .
The results that were evaluated by a tool provided by TRECVID with a standard measurements , such as the precision , recall , and F1 score , clearly show that our proposed method significantly outperforms the baseline method and the combination of GCM+EOH obtains the best result .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			1		1.0
15:1			17:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			39:1			0		1.0
19:1			16:1			0		1.0
21:1			18:1			0		1.0
23:1			19:1			0		1.0
24:1			20:1			0		1.0
25:1			21:1			0		1.0
27:1			22:1			0		1.0
28:1			23:1			0		1.0
29:1			24:1			0		1.0
30:1			25:1			0		1.0
31:1			26:1			0		1.0
32:1			27:1			0		1.0
33:1			28:1			0		1.0
34:1			29:1			0		1.0
35:1			30:1			0		1.0
36:1			31:1			0		1.0
37:1			32:1			0		1.0
38:1			33:1			0		1.0
39:1			34:1			0		1.0
40:1			35:1			0		1.0
41:1			36:1			0		1.0
42:1			37:1			0		1.0
43:1			38:1			0		1.0
45:1			40:1			0		1.0
46:1			41:1			0		1.0
47:1			42:1			0		1.0

Alignment 3130
We evaluated the performance of our system with different choices for taking the number of NORM -FRM frames used in training process .
We evaluated the performance of our system with different choices for taking the number of NORM -FRM frames used in training process . //for / by?
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 3131
Specifically , we selected three sampling rates \MATH which are \MATH and \MATH .
Specifically , we selected three sampling rates \MATH , which were \MATH and \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			2		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0

Alignment 3132
As shown in Figure \REF , the best performance is obtained with the sampling rate of \MATH .
As shown in Figure \REF , the best performance was obtained at a sampling rate of \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			2		1.0
10:1			10:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 3133
In Table \REF we show the evaluation of using different features for forming the feature vector using distances between current frames and its neighbors .
In Table \REF , we list the evaluation results when using different features to form the feature vector using the distances between the current frames and their neighbors .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
14:1			12:1			1		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0
23:1			19:1			0		1.0
24:1			20:1			0		1.0
25:1			21:1			0		1.0
26:1			22:1			3		1.0
27:1			23:1			0		1.0
28:1			24:1			0		1.0

Alignment 3134
The first one is GCM , the second one is EOH and the last one GCM+EOH is combination of distances using GCM and distances using EOH .
The first one is GCM , the second one is EOH , and the last one GCM+EOH is a combination of the distances using GCM and the distances using EOH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
22:1			19:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0
27:1			23:1			0		1.0
28:1			24:1			0		1.0
29:1			25:1			0		1.0
30:1			26:1			0		1.0

Alignment 3135
The number of dimensions of feature vectors using GCM and EOH is 20 while that of feature vectors using GCM+EOH is 40 .
The number of dimensions of the feature vectors using GCM and EOH was 20 , while that of feature vectors using GCM+EOH was 40 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:2			11:2			3		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:2			20:2			3		1.0
24:1			22:1			0		1.0

Alignment 3136
We also compare the proposed method with the baseline method that computes differences in color histograms between two consecutive frames and then decides a shot transitition by using a predefined threshold .
We also compared the proposed method with the baseline method that computes the differences in the color histograms between two consecutive frames , and then decides the shot transition by using a predefined threshold .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			1		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0
27:1			24:1			0		1.0
29:1			26:1			0		1.0
30:1			27:1			0		1.0
31:1			28:1			0		1.0
32:1			29:1			0		1.0
33:1			30:1			0		1.0
34:1			31:1			0		1.0

Alignment 3137
In Figure \REF , we superimpose our result on the results reported in the shot boundary detection task of TRECVID 2003 .
In Figure \REF , we superimposed our result on the results reported in the shot boundary detection task of TRECVID 2003 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			1		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 3138
Our system achieves high precision and recall for the CUT transition and the result is comparable with the third-ranked system .
Our system achieves a high precision and recall for the CUT transition and this result is comparable to the third-ranked system .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:2			12:2			3		1.0
15:1			14:1			0		1.0
16:2			15:2			3		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0

Alignment 3139
Note that our system is general and has no special treatment for particular shot transition .
Note that our system is general and has no special treatment for particular shot transitions .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			1		1.0
15:1			15:1			0		1.0

Alignment 3140
Many previous shot boundary detectors usually divided the system into sub-systems in which special treatments were proposed to handle different types of shot transitions .
Many previous shot boundary detectors usually divide the system into sub-systems in which special treatments are proposed to handle different types of shot transitions .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:2			6:2			3		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			2		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 3141
Therefore , it is difficult to generalize for new test sets .
Therefore , it is generalization is difficult for new test sets .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			6:1			1		1.0
6:1			4:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 3142
Different from these approaches , in this paper , we have proposed a unified and general framework for shot boundary detection using a text segmentation based approach .
We have proposed a unified and general framework for shot boundary detection that uses a text segmentation based approach .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			10:1			0		1.0
2:1			11:1			0		1.0
3:1			12:1			0		1.0
4:1			13:1			0		1.0
5:1			14:1			0		1.0
6:1			15:1			0		1.0
7:1			16:1			0		1.0
8:1			17:1			0		1.0
9:1			18:1			0		1.0
10:1			19:1			0		1.0
11:1			20:1			0		1.0
13:1			21:1			1		1.0
14:1			22:1			0		1.0
15:1			23:1			0		1.0
16:1			24:1			0		1.0
17:1			25:1			0		1.0
18:1			26:1			0		1.0
19:1			27:1			0		1.0

Alignment 3143
Firstly , we label frames by one of six labels defined for different types of frames : NORM -FRM , PRE -CUT , POST -CUT , PRE -GRAD , IN -GRAD and POST -GRAD .
Firstly , we label the frames with one of the six labels defined for different types of frames : NORM -FRM , PRE -CUT , POST -CUT , PRE -GRAD , IN -GRAD , and POST -GRAD .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
34:1			31:1			0		1.0
35:1			32:1			0		1.0
36:1			33:1			0		1.0
37:1			34:1			0		1.0

Alignment 3144
Then we extract shot boundaries and types from these labeled frames .
Then we extract the shot boundaries and types from these labeled frames .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0

Alignment 3145
In order to label frames , we proposed a new feature type to model the difference and motion in color and edge between frames and used it in classification with SVM classifiers .
In order to label frames , we proposed a new feature type to model the difference and motion in color and the edges between the frames and used it in the classification with SVM classifiers .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
22:1			21:1			1		1.0
23:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
31:1			28:1			0		1.0
32:1			29:1			0		1.0
33:1			30:1			0		1.0
34:1			31:1			0		1.0
35:1			32:1			0		1.0

Alignment 3146
Experiments on various videos of TRECVID 2003 have shown that our approach is effective .
The experiments we conducted on various videos from TRECVID 2003 have shown that our approach is effective .
Line2Start:Length	Line1Start:Length	Module		Score
4:1			1:1			0		1.0
5:1			2:1			0		1.0
6:2			3:2			3		1.0
8:1			5:1			0		1.0
9:1			6:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0

Alignment 3147
Ent-Boost : Boosting Using Entropy Measure
Ent-Boost : Boosting Using Entropy Measures
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			1		1.0

Alignment 3148
for Robust Object Detection
for Robust Object Detection
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0

Alignment 3149
Recently , boosting is used widely in object detection applications because of its impressive performance in both speed and accuracy .
Recently , boosting has come to be used widely in object detection applications because of its impressive performance in both speed and accuracy .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:2			3:1			3		1.0
7:1			4:1			0		1.0
8:1			5:1			0		1.0
9:1			6:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			0		1.0
23:1			20:1			0		1.0

Alignment 3150
However , learning weak classifiers which is one of the most significant tasks in using boosting is left for users .
However , learning weak classifiers , which is one of the most significant tasks in using boosting , is left to users . //learning / training / identifying / finding?<--Here and throughout , I am not sure that " learning " is the best word choice . If you change it here , it should be changed throughout .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
18:1			16:1			0		1.0
19:2			17:2			3		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0

Alignment 3151
In Discrete AdaBoost , weak classifiers with binary output are too weak to boost when the training data is complex .
In Discrete AdaBoost , weak classifiers with binary output are too weak to boost when the training data is complex .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 3152
Meanwhile , determining the appropriate number of bins for weak classifiers learned by Real AdaBoost is a challenging task because small one might not well approximate the real distribution while large one might cause over-fitting , increase computation time and waste storage space .
Meanwhile , determining the appropriate number of bins for weak classifiers learned by Real AdaBoost is a challenging task because small ones might not accurately approximate the real distribution while large ones might cause over-fitting , increase computation time , and waste storage space .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			1		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			1		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
40:1			39:1			0		1.0
41:1			40:1			0		1.0
42:1			41:1			0		1.0
43:1			42:1			0		1.0
44:1			43:1			0		1.0

Alignment 3153
This paper describes a novel method for efficiently learning weak classifiers using entropy measures , called Ent-Boost .
We have developed Ent-Boost , a novel method for efficiently learning weak classifiers using entropy measures . //method / boosting scheme?
Line2Start:Length	Line1Start:Length	Module		Score
3:1			16:1			0		1.0
4:1			14:1			0		1.0
5:1			3:1			0		1.0
6:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			17:1			0		1.0

Alignment 3154
The class entropy information is used to estimate the optimal number of bins automatically through discretization process .
Class entropy information is used to automatically estimate the optimal number of bins through discretization .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			13:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			17:1			0		1.0

Alignment 3155
Then Kullback-Leibler divergence which is the relative entropy between probability distributions of positive and negative samples is employed to select the best weak classifier in the weak classifier set .
Then Kullback-Leibler divergence , which is the relative entropy between probability distributions of positive and negative samples , is used to select the best weak classifier in the weak classifier set .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			2		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0

Alignment 3156
Experiments have shown that strong classifiers learned by Ent-Boost can achieve good performance , and have compact storage space .
Experiments showed that strong classifiers learned by Ent-Boost can achieve good performance and be stored compactly . //[be stored compactly / achieve compact storage?]
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:2			3		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			14:1			0		1.0
16:1			19:1			0		1.0
22:1			16:1			0		1.0

Alignment 3157
Results on building a robust face detector are also reported .
The results of building a robust face detector using Ent-Boost showed the boosting scheme to be effective .
Line2Start:Length	Line1Start:Length	Module		Score
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
17:1			10:1			0		1.0

Alignment 3158
Building a robust and reliable classifier is always a fundamental problem of pattern recognition .
Building a robust and reliable classifier is always a fundamental problem of pattern recognition .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 3159
Several kinds of classifiers , such as Neural Network [1] and Support Vector Machines [2] , have been proposed and applied successfully in many object-detection systems .
Several kinds of classifiers , such as neural networks [1] and support vector machines [2] , have been proposed and applied successfully in many object-detection systems .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 3160
Boosting [3] and its variants [4] ,[5] ,[6] ,[7] ,[8] ,[9] ,[10] have recently gained a lot of attentions from researchers because of its excellent performance .
Boosting [3] and its variants [4] ? [10] have recently gained much attention from researchers because of their excellent performance .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
8:1			12:1			0		1.0
9:1			13:1			0		1.0
10:1			14:1			0		1.0
11:1			15:2			3		1.0
12:1			18:1			1		1.0
13:1			19:1			0		1.0
14:1			20:1			0		1.0
15:1			21:1			0		1.0
16:1			17:1			0		1.0
17:1			22:2			3		1.0
18:1			24:1			0		1.0
19:1			25:1			0		1.0
20:1			26:1			0		1.0

Alignment 3161
In regards to face detection , for example , the methods described in works [4] ,[5] ,[10] represent the state of the art in terms of both high accuracy and running speed .
In regard to face detection , for example , the methods described in [4] , [5] , and [10] are state-of-the-art in terms of both accuracy and running speed .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			1		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			14:1			0		1.0
17:1			29:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0
24:1			26:1			0		1.0
25:1			28:1			0		1.0
27:1			30:1			0		1.0
28:1			31:1			0		1.0
29:1			32:1			0		1.0

Alignment 3162
The main idea of boosting is to combine the performance of weak classifiers to form a strong classifier .
The main idea of boosting is to combine the performance of weak classifiers to form a strong classifier .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 3163
Typically , each weak classifier is any classifier whose performance is better than random guessing ( i.e. , error rate is less than 0 .5 ) .
Typically , a weak classifier is any classifier whose performance is better than random guessing ( i.e. , its error rate is less than 0 .5 ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0

Alignment 3164
Performances of weak classifiers are integrated into the final form of the strong classifier through a learning process in which more accurate weak classifiers have larger weights in final voting .
The performances of these weak classifiers are integrated into the final form of a strong classifier through a learning process in which more accurate weak classifiers have larger weights in final voting .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
4:1			2:1			0		1.0
5:1			3:1			0		1.0
6:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:2			11:2			3		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0

Alignment 3165
In practical problems , designing and learning weak classifiers are left for practitioners with two main challenges : computational evaluation and discriminant power .
In practical problems , designing and learning weak classifiers leave practitioners with two main challenges : computational evaluation and discriminant power .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			10:1			2		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0

Alignment 3166
Generally , for efficient computation , the dimension of the input space of weak classifiers is reduced to much lower than that of the strong classifier .
Generally , for efficient computation , the dimensions of the input space of weak classifiers are reduced be to much smaller than those of the strong classifier[s?] .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:2			7:2			3		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			2		1.0
16:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			2		1.0
21:1			20:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
27:1			26:1			0		1.0

Alignment 3167
In object-detection frameworks [4] ,[5] ,[11] ,[12] ,[13] weak classifiers are usually constructed from one or several features .
In object-detection frameworks [4] , [5] , [11] ? [13] , weak classifiers are usually constructed from one or several features .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0

Alignment 3168
For example , a weak classifier can be constructed from one Haar wavelet feature that is evaluated very rapidly through an integral image [4] .
For example , a weak classifier can be constructed from one Haar wavelet feature that is evaluated very rapidly through an integral image [4] .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 3169
Given a feature type , choosing the suitable way to form a weak classifier that balance efficiency and computation is still a open problem [14] .
Given a feature type , choosing the suitable way to form a weak classifier that balances efficiency and computation is still an open problem [14] .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			1		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 3170
There are two key trends for seeking the most discriminant weak classifier .
Two key trends exist for seeking the most discriminant weak classifier .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			3:1			0		1.0
2:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0

Alignment 3171
The first trend is dealing with the problem of how to design features for best representation of the target object .
The first trend is dealing with the problem of how to design features for best representing the target object .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:2			15:3			3		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0

Alignment 3172
Besides Haar wavelet features [4] , Gabor wavelets [5] , edge orientation histogram ( EOH ) [11] , orientation dominants [12] , scale invariant feature transform ( SIFT )-based-high-level features [13] and local binary pattern ( LBP ) [15] have also been used .
Besides Haar wavelet features [4] , Gabor wavelets [5] , edge orientation histograms ( EOH ) [11] , orientation dominants [12] , scale invariant feature transform ( SIFT )-based high-level features [13] , and local binary patterns ( LBP ) [15] have also been used .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			1		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
33:1			31:1			0		1.0
34:1			32:1			0		1.0
35:1			33:1			0		1.0
36:1			34:1			1		1.0
37:1			35:1			0		1.0
38:1			36:1			0		1.0
39:1			37:1			0		1.0
40:1			38:1			0		1.0
41:1			39:1			0		1.0
42:1			40:1			0		1.0
43:1			41:1			0		1.0
44:1			42:1			0		1.0
45:1			43:1			0		1.0

Alignment 3173
The second trend is studying how to optimally select the best weak classifier from a weak classifier set .
The second trend is studying how to optimally select the best weak classifier from a weak classifier set .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 3174
In Discrete AdaBoost [16] , weak classifiers are threshold-functions whose the output is restricted to binary .
In Discrete AdaBoost [16] , weak classifiers are threshold-functions whose output is restricted to binary data. //[data / values??I think you need a noun here?binary what?]
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0

Alignment 3175
This leads weak classifiers are too weak to boost when handling complex data sets .
This leads weak classifiers to be too weak to boost when handling complex data sets .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:3			4:2			3		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0

Alignment 3176
For example , in later layers of the cascaded face classifiers [4] , the error rate of weak classifiers is between 0 .4 and 0 .5 .
For example , in later layers of the cascaded face classifiers [4] , the error rate of weak classifiers is between 0 .4 and 0 .5 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 3177
Meanwhile , in Real AdaBoost [3] , a generalized version of Discrete AdaBoost , weak classifiers are piece-wise functions whose the output is a real value representing the confidence-rated prediction .
Meanwhile , in Real AdaBoost [3] , a generalized version of Discrete AdaBoost , weak classifiers are piece-wise functions whose output is a real value representing the confidence-rated prediction .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0

Alignment 3178
Normally , to construct such weak classifiers , one splits the input space \MATH into non-overlapping blocks ( or subspaces ) \MATH , \MATH , . . . , \MATH so that the predictions of the weak classifier are the same for all instances falling into the same block .
Normally , to construct such weak classifiers , one splits the input space \MATH into non-overlapping blocks ( or subspaces ) \MATH , \MATH , . . . , \MATH so that the predictions of the weak classifier are the same for all instances falling into the same block .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0
49:1			49:1			0		1.0

Alignment 3179
In the case of one-feature-based weak classifiers , this is equivalent to dividing the real line into intervals .
In the case of one-feature-based weak classifiers , this is equivalent to dividing the real line into intervals .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 3180
Typically , most current works [5] ,[17] ,[6] ,[8] ,[10] split the data into \MATH bins that are equal width which suffers from following limitations :
Typically , most current works [5] , [6] , [8] , [10] , [17] split the data into \MATH bins that are equal in width . This method suffers from the following limitations : //[works / systems?]
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
14:1			10:1			0		1.0
15:1			11:1			0		1.0
16:1			12:1			0		1.0
17:1			13:1			0		1.0
18:1			14:1			0		1.0
19:1			15:1			0		1.0
20:1			16:1			0		1.0
21:1			17:1			0		1.0
22:1			18:1			0		1.0
24:1			19:1			0		1.0
28:1			21:1			0		1.0
29:1			22:1			0		1.0
31:1			23:1			0		1.0
32:1			24:1			0		1.0
33:1			25:1			0		1.0

Alignment 3181
-Choosing the appropriate number of bins is undetermined .
-The way to choose the appropriate number of bins is undetermined .
Line2Start:Length	Line1Start:Length	Module		Score
4:1			1:1			0		1.0
5:1			2:1			0		1.0
6:1			3:1			0		1.0
7:1			4:1			0		1.0
8:1			5:1			0		1.0
9:1			6:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0

Alignment 3182
Normally , it has been done by trials and errors [6] ,[17] - a tedious task .
Normally , it has been done by trial and error [6] , [17] ? a tedious task .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:2			7:2			3		1.0
9:1			9:1			1		1.0
10:1			10:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0

Alignment 3183
In the training cascade of classifiers [6] ,[17] , when the complexity of the training data changes over time , using the same number of bins for training every layers is not optimal .
In the training cascade of classifiers [6] , [17] , when the complexity of the training data changes over time , using the same number of bins for training every layer is not optimal .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			19:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			1		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0

Alignment 3184
-Choosing a large number of bins might cause over-fitting because of outliers in the case of noisy data [18] .
-Choosing a large number of bins might cause over-fitting because of outliers in the case of noisy data [18] .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 3185
Furthermore it might increase computation and training time , waste storage space which is critical in applications with limited resources , for example , face detection on mobile phones .
Furthermore , it might lengthen computation and training time and waste storage space , which is critical in applications with limited resources , for example , face detection on mobile phones .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			8:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0

Alignment 3186
Meanwhile choosing a small number of bins might not well approximate the real densities of the data distribution and thus influence selection of the best weak classifier .
Choosing a small number of bins , however , might not accurately approximate the real densities of the data distribution and could influence the selection of the best weak classifier .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
22:1			20:1			0		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0
26:1			23:1			0		1.0
27:1			24:1			0		1.0
28:1			25:1			0		1.0
29:1			26:1			0		1.0
30:1			27:1			0		1.0

Alignment 3187
It is therefore necessary to have a deterministic method to choose this number of bins automatically and optimally .
A deterministic method is therefore needed to automatically and optimally choose the number of bins .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			7:1			0		1.0
2:1			8:1			0		1.0
3:1			1:1			0		1.0
4:1			2:1			0		1.0
5:1			3:2			3		1.0
6:1			9:1			0		1.0
7:1			15:1			0		1.0
8:1			16:1			0		1.0
9:1			17:1			0		1.0
10:1			10:1			0		1.0
11:2			11:2			3		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			18:1			0		1.0

Alignment 3188
This problem can be formulated as a discretization problem in which subspace boundaries are found by some criteria .
This problem can be formulated as a discretization problem in which subspace boundaries are found by some criteria . //[some criteria?This sounds a bit vague . Could you be more specific?]
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 3189
Among discretization methods , the entropy based method [19] has been proved most efficiently ; hence , we propose using it to solve the problem .
Among discretization methods , the entropy-based method [19] has been proved most efficient . Hence , we propose using it to solve the problem .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			1		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0

Alignment 3190
The entropy based discretization method is an algorithm that automatically selects appropriate thresholds to split feature values into optimal bins by using entropy measurement .
The entropy-based discretization method is an algorithm that automatically selects appropriate thresholds to split feature values into optimal bins by using entropy measurement .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0

Alignment 3191
It is a supervised discretization method which takes into account class information and data distribution , so it is generic and can be applied for any kinds of input data .
It is a supervised discretization method that takes into account class information and data distribution , so it is generic and can be applied to any kind of input data .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:2			6:2			3		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
25:1			25:1			0		1.0
26:2			26:2			3		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0

Alignment 3192
Furthermore , many studies have been shown that discretization process might help to improve performance in induction tasks [18] , it can also work with a weighted data distribution ; therefore , it is most appropriate for boosting-based methods .
Furthermore , many studies have shown that the discretization process might help to improve performance in induction tasks [18] and it can also work with a weighted data distribution . Therefore , it is most appropriate for boosting-based methods .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0

Alignment 3193
Besides learning weak classifiers , selecting the best weak classifier in the large weak classifier set in each round of boosting is also important .
Besides learning weak classifiers , selecting the best weak classifier in the large set of weak classifiers in each round of boosting is also important .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			15:1			0		1.0
14:1			19:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			1		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0

Alignment 3194
Adopting [5] , it is done by choosing the weak classifier that maximizes Kullback-Leibler ( KL ) divergence between two distributions of positive and negative samples .
Following the method used in [5] , it is done by choosing the weak classifier that maximizes Kullback-Leibler ( KL ) divergence between two distributions of positive and negative samples . // [used / proposed?]
Line2Start:Length	Line1Start:Length	Module		Score
5:1			1:1			0		1.0
6:1			2:1			0		1.0
7:1			3:1			0		1.0
8:1			4:1			0		1.0
9:1			5:1			0		1.0
10:1			6:1			0		1.0
11:1			7:1			0		1.0
12:1			8:1			0		1.0
13:1			9:1			0		1.0
14:1			10:1			0		1.0
15:1			11:1			0		1.0
16:1			12:1			0		1.0
17:1			13:1			0		1.0
18:1			14:1			0		1.0
19:1			15:1			0		1.0
20:1			16:1			0		1.0
21:1			17:1			0		1.0
22:1			18:1			0		1.0
23:1			19:1			0		1.0
24:1			20:1			0		1.0
25:1			21:1			0		1.0
26:1			22:1			0		1.0
27:1			23:1			0		1.0
28:1			24:1			0		1.0
29:1			25:1			0		1.0
30:1			26:1			0		1.0

Alignment 3195
The integration of entropy-based discretization process and optimal weak classifier selection into the current boosting framework forms a new variant of AdaBoost , called Ent-Boost .
The integration of the entropy-based discretization process and optimal weak classifier selection into the current boosting framework formed a new variant of AdaBoost , called Ent-Boost .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			1		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0

Alignment 3196
Experiments on building a robust face detector have shown effectiveness of this new boosting scheme .
Experiments on building a robust face detector have shown the effectiveness of this new boosting scheme .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0

Alignment 3197
Originally , Discrete AdaBoost proposed by Freund and Schapire [16] is a learning method of combining weak classifiers to a strong classier .
Originally , Discrete AdaBoost , proposed by Freund and Schapire [16] , was a learning method of combining weak classifiers to form a strong classier .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
12:1			10:1			2		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
22:1			19:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0

Alignment 3198
Given a training set \MATH where \MATH and \MATH , a weak classifier \MATH has the form \MATH .
Given a training set \MATH , where \MATH and \MATH , a weak classifier \MATH has the form \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			9:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0

Alignment 3199
Normally , a weak classifier is any classifier whose performance measured by error rate is less than 0 .5 .
Normally , a weak classifier is any classifier whose performance measured by error rate is less than 0 .5 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 3200
Therefore , in many applications [4] ,[5] ,[7] , it is simplified by associating to one feature \MATH .
Therefore , in many applications [4] , [5] , [7] , it is simplified by associating with one feature \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0

Alignment 3201
Through boosting processing , weak classifiers are combined into a strong classifier \MATH where \MATH are values that measure performance of the selected weak classifier .
Through boosting processing , weak classifiers are combined into a strong classifier \MATH where \MATH are values that measure the performance of the selected weak classifier .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0

Alignment 3202
In boosting process , a distribution \MATH or set of weights over the training samples are maintained and updated so that subsequent weak classifiers focus on the hard classified samples .
In the boosting process , a distribution \MATH or set of weights over the training samples are maintained and updated so that subsequent weak classifiers focus on the strong-classified samples . //[hard / strong?]
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0

Alignment 3203
Real AdaBoost [3] is a generalized version of Discrete AdaBoost in that weak classifiers are real-valued functions instead of binary ones and \MATH is found numerically in general instead of predescription .
Real AdaBoost [3] is a generalized version of Discrete AdaBoost in that weak classifiers are real-valued functions instead of binary ones and \MATH is found numerically instead of by predescription . //[This method also involves?NOTE : A method cannot propose something .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			28:1			0		1.0
27:1			29:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0

Alignment 3204
This method also proposes designing weak classifiers that partition the input space into subspaces so that its predictions are unique in each subspace .
Do you mean that the creators of this system proposed this?] designing weak classifiers that partition the input space into subspaces so that the predictions are unique in each subspace .
Line2Start:Length	Line1Start:Length	Module		Score
11:1			4:1			0		1.0
12:1			5:1			0		1.0
13:1			6:1			0		1.0
14:1			7:1			0		1.0
15:1			8:1			0		1.0
16:1			9:1			0		1.0
17:1			10:1			0		1.0
18:1			11:1			0		1.0
19:1			12:1			0		1.0
20:1			13:1			0		1.0
21:1			14:1			0		1.0
22:1			15:1			0		1.0
23:2			16:2			3		1.0
25:1			18:1			0		1.0
26:1			19:1			0		1.0
27:1			20:1			0		1.0
28:1			21:1			0		1.0
29:1			22:1			0		1.0
30:1			23:1			0		1.0

Alignment 3205
Such weak classifiers are used widely in current state of the art object detection systems [5] ,[17] ,[8] .
Such weak classifiers are used widely in current state-of-the-art object detection systems [5] , [8] , [17] .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			12:1			0		1.0
10:1			13:1			0		1.0
11:1			14:1			0		1.0
12:1			15:1			0		1.0
17:1			18:1			0		1.0

Alignment 3206
Suppose that \MATH , \MATH , . . . , \MATH is a partition of the domain \MATH on which such weak classifiers $h$ are defined .
Suppose that \MATH , \MATH , . . . , \MATH is a partition of the domain \MATH on which such weak classifiers $h$ are defined .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 3207
The prediction of \MATH depends only on which block \MATH a given instance falls into .
The prediction of \MATH depends only on which block \MATH a given instance falls into .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 3208
On the other hand , \MATH for all \MATH .
On the other hand , \MATH for all \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 3209
In the case of one-feature-based weak classifiers , the histograms of positive and negative samples are computed as follows \MATH where \MATH .
In the case of one-feature-based weak classifier , the histograms of positive and negative samples are computed as follows \MATH where \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			1		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 3210
It is proved in [3] that the most appropriate choice for the prediction of the weak classifier on block \MATH to maximize the margin is \MATH where \MATH is a smoothed value in order to handle cases that \MATH is very small or even zero .
It is proven in [3] that the most appropriate choice for the prediction of the weak classifier on block \MATH to maximize the margin is \MATH where \MATH is a smoothed value in order to handle cases in which \MATH is very small or even zero .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			2		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
39:1			38:1			0		1.0
40:1			39:1			0		1.0
41:1			40:1			0		1.0
42:1			41:1			0		1.0
43:1			42:1			0		1.0
44:1			43:1			0		1.0
45:1			44:1			0		1.0
46:1			45:1			0		1.0

Alignment 3211
A summary of the Real AdaBoost algorithm is given in Algorithm 1 .
A summary of the Real AdaBoost algorithm is given in Algorithm 1 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 3212
Real AdaBoost is easy to implement ; however , in practical applications , designing and learning weak classifiers depend on specific applications .
Real AdaBoost is easy to implement , but in practical applications , designing and learning weak classifiers depend on specific applications .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0

Alignment 3213
In such face detection systems as [5] ,[6] ,[17] ,[8] , weak classifiers are usually associated with one feature .
In such face detection systems as [those described in?] [5] , [6] , [8] , and [17] , weak classifiers are usually associated with one feature .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
9:1			6:1			0		1.0
17:1			10:1			0		1.0
18:1			11:1			0		1.0
19:1			12:1			0		1.0
20:1			13:1			0		1.0
21:1			14:1			0		1.0
22:1			15:1			0		1.0
23:1			16:1			0		1.0
24:1			17:1			0		1.0
25:1			18:1			0		1.0
26:1			19:1			0		1.0

Alignment 3214
With a very large number of available features , hundreds of thousands , there are a lot of choices to choose one weak classifier for each round of boosting .
With a very large number of available features ? hundreds of thousands ? [there are many candidates from which to / many choices must be made to?] select one weak classifier for each round of boosting .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
14:1			14:1			0		1.0
19:1			19:1			0		1.0
22:1			18:1			0		1.0
27:1			20:1			2		1.0
28:1			21:1			0		1.0
29:1			22:1			0		1.0
30:1			23:1			0		1.0
31:1			24:1			0		1.0
32:1			25:1			0		1.0
33:1			26:1			0		1.0
34:1			27:1			0		1.0
35:1			28:1			0		1.0
36:1			29:1			0		1.0

Alignment 3215
Generally , optimally selecting the suitable weak classifier will make the final strong classifier more robust and efficient .
Optimally selecting the suitable weak classifier makes the final strong classifier more robust and efficient .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			3:1			0		1.0
2:1			4:1			0		1.0
3:1			5:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			9:1			1		1.0
7:1			10:1			0		1.0
8:1			11:1			0		1.0
9:1			12:1			0		1.0
10:1			13:1			0		1.0
11:1			14:1			0		1.0
12:1			15:1			0		1.0
13:1			16:1			0		1.0
14:1			17:1			0		1.0
15:1			18:1			0		1.0

Alignment 3216
Furthermore , it can reduce the number of boosting rounds that directly shorten training time .
Furthermore , optimal selection can reduce the number of boosting rounds , thus directly shortening training time .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			1		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0

Alignment 3217
So far , most current studies have been focused on how to measure the discriminant power of weak classifiers in order to select the best weak classifier .
Most studies so far have been focused on how to measure the discriminant power of weak classifiers in order to select the best weak classifier .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			5:1			0		1.0
3:1			1:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0
24:1			26:1			0		1.0
25:1			27:1			0		1.0

Alignment 3218
Many measurements have been proposed ; for example , Bhattacharyya distance [6] , Kullback-Leibler divergence [5] and , recently , Jensen-Shannon divergence [8] and mutual information [9] ( cf . Table 1 .
Many measurements have been proposed , for example , Bhattacharyya distance [6] , Kullback-Leibler divergence [5] , and recently , Jensen-Shannon divergence [8] and mutual information [9] ( Table 1 ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			17:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			19:1			0		1.0
17:1			16:1			0		1.0
18:1			18:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			30:1			0		1.0
29:1			31:1			0		1.0
31:1			29:1			0		1.0

Alignment 3219
Meanwhile , few studies have been made for efficiently partitioning subspaces .
Meanwhile , few studies have been made on efficiently partitioning subspaces .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 3220
As shown in Figure 1 , using a fixed number of bins , strong classifiers trained by above measurements give comparable performance .
As shown in Figure 1 , using a fixed number of bins , strong classifiers trained by the above measures give similar performances . //[measurements / measures?]
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			1		1.0
20:1			19:1			0		1.0
21:1			20:1			3		1.0
22:1			21:1			1		1.0
23:1			22:1			0		1.0

Alignment 3221
However , it will be shown in section 5 , these performances are affected seriously if different subspace splitting methods are used .
However , as section 5 will show , these performances are affected dramatically if different subspace splitting methods are used .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			7:1			0		1.0
4:1			8:1			0		1.0
5:1			3:1			0		1.0
6:1			4:2			3		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0

Alignment 3222
The proposed boosting scheme Ent-Boost is an integration of adaptive entropy-based subspace splitting and the symmetric KL divergence-based weak classifier selection .
The proposed boosting scheme , Ent-Boost , is an integration of adaptive entropy-based subspace splitting and the symmetric KL divergence-based weak classifier selection .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0

Alignment 3223
In Ent-Boost , each weak classifier is constructed from one feature and trained on the weighted training samples similar to Real AdaBoost .
In Ent-Boost , each weak classifier is constructed from one feature and trained on weighted training samples similar to [those used in?] Real AdaBoost .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0

Alignment 3224
However , instead of using equal-width binning method like Real AdaBoost [6] ,[17] which is hard to know the suitable number of bins in advance , we use entropy-based discretization method [19] to split the input space into subspaces .
However , instead of using the equal-width binning method used in Real AdaBoost [6] , [17] which has a hard time predicting the suitable number of bins in advance , we use the entropy-based discretization method [19] to split the input space into subspaces .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			34:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			27:1			1		1.0
10:1			23:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			25:1			0		1.0
16:1			13:1			0		1.0
17:2			14:1			3		1.0
19:1			15:1			0		1.0
22:1			18:1			0		1.0
23:1			19:1			0		1.0
24:1			20:1			0		1.0
25:1			21:1			0		1.0
26:1			22:1			0		1.0
28:1			24:1			0		1.0
30:1			26:1			0		1.0
33:1			28:1			0		1.0
34:1			29:1			0		1.0
35:1			30:1			0		1.0
36:1			31:1			0		1.0
37:1			32:1			0		1.0
38:1			33:1			0		1.0
40:1			35:1			0		1.0
41:1			36:1			0		1.0
42:1			37:1			0		1.0
43:1			38:1			0		1.0
44:1			39:1			0		1.0

Alignment 3225
This subspace splitting process is totally automatically in which the stopping criteria of splitting process is determined through using Minimum Description Length Principles ( MDLP ) ( see the next section ) .
This subspace splitting process is totally automatic ; the stopping criteria of the splitting process are determined using minimum description length principles ( MDLP ) . This process will be described in greater detail in the next section .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			1		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			28:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
16:1			16:1			0		1.0
17:1			18:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			32:1			0		1.0
28:2			15:1			3		1.0
31:1			7:1			0		1.0
36:1			29:1			0		1.0
37:1			30:1			0		1.0

Alignment 3226
To select the best weak classifier from the input weak classifier set , we use symmetric KL divergence as in [5] which measures the distance between two distributions as follows : \MATH where \MATH and \MATH are probability distributions of a discrete random variable .
To select the best weak classifier from the input weak classifier set , we use symmetric KL divergence as in [5] , which measures the distance between two distributions as follows : \MATH where \MATH and \MATH are probability distributions of a discrete random variable .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
37:1			36:1			0		1.0
38:1			37:1			0		1.0
39:1			38:1			0		1.0
40:1			39:1			0		1.0
41:1			40:1			0		1.0
42:1			41:1			0		1.0
43:1			42:1			0		1.0
44:1			43:1			0		1.0
45:1			44:1			0		1.0

Alignment 3227
This formula can be rewritten in entropy terms : \MATH or \MATH where \MATH and \MATH are entropy , and \MATH is cross entropy of \MATH and \MATH .
This formula can be rewritten in entropy terms : \MATH or \MATH where \MATH and \MATH are entropy and \MATH is cross entropy of \MATH and \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0

Alignment 3228
The outline of Ent-Boost is shown in Algorithm 2 .
The outline of Ent-Boost is shown in Algorithm 2 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 3229
Note that the discretization process is performed in every round of boosting to adapt to new distributions of samples .
Note that the discretization process is performed in every round of boosting to adapt to new distributions of samples .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 3230
As a result , the number of intervals of selected weak classifier varies .
As a result , the number of intervals of the selected weak classifier varies . //[classifier varies / classifiers vary?]
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0

Alignment 3231
This is different from previous methods that fix the number of equal-width intervals in advance .
This is different from previous methods , which fix the number of equal-width intervals in advance .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0

Alignment 3232
This section gives a brief introduction on automatic subspace splitting using entropy-based discretization .
This section briefly describes automatic subspace splitting using entropy-based discretization .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			3:2			3		1.0
4:1			7:1			0		1.0
5:1			8:1			0		1.0
6:1			9:1			0		1.0
7:1			10:1			0		1.0
8:1			11:1			0		1.0
9:1			12:1			0		1.0
10:1			13:1			0		1.0

Alignment 3233
Basically , discretization is a quantizing process that converts continuous values into discrete values ; it typically consists of four steps [18] :
Discretization is a quantizing process that converts continuous values into discrete values . It typically consists of four steps [18] .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			3:1			0		1.0
2:1			4:1			0		1.0
3:1			5:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0

Alignment 3234
Step 1 : Sorting the continuous values of the feature to be discretized .
Step 1 : Sorting the continuous values of the feature to be discretized .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 3235
Step 2 : valuating candidate cut-points and selecting the best cut-point for splitting .
Step 2 : Evaluating candidate cut-points and selecting the best cut-point for splitting .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 3236
A cut-point is a threshold value that divides the range of continuous values into two intervals ; one interval is less than or equal to the threshold , and the other interval is greater than the threshold .
A cut-point is a threshold value that divides the range of continuous values into two intervals ; one interval is less than or equal to the threshold , and the other interval is greater than the threshold .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0

Alignment 3237
Step 3 : Splitting the data into two intervals using the selected cut-point in step 2 .
Step 3 : Splitting the data into two intervals using the cut-point selected in step 2 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			12:1			0		1.0
12:1			11:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 3238
Step 4 : Continuing discretization with each interval until a stopping criteria is satisfied .
Step 4 : Continuing discretization with each interval until a stopping criteria is satisfied .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 3239
The stopping criteria are usually selected according to a trade-off between lower arity ( the number of intervals or the number of bins ) and its effect on the accuracy of classification tasks .
The stopping criteria are usually selected by considering a trade-off between lower arity ( the number of intervals or the number of bins ) and its effect on the accuracy of classification tasks .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0

Alignment 3240
A higher arity can make the understanding of an attribute more difficult , while a very low arity may affect predictive accuracy negatively .
A higher arity can make the complicate the understanding of an attribute , while a very low arity may damage predictive accuracy .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:2			11:1			3		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			23:1			0		1.0

Alignment 3241
Given a set \MATH of sorted continuous values \MATH , candidate cut-points are usually selected as mid-points of every successive pair of \MATH .
Given a set \MATH of sorted continuous values \MATH , candidate cut-points are usually selected as mid-points of every successive pair of \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 3242
On the other hand , candidate cut-points are \MATH .
On the other hand , candidate cut-points are \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 3243
For each cut-point \MATH that splits set \MATH into two subsets \MATH , the class entropy of a subset \MATH is defined as \MATH where \MATH is the number of classes \MATH , and \MATH is the proportion of examples in \MATH that have class \MATH .
For each cut-point \MATH that splits set \MATH into two subsets \MATH , the class entropy of a subset \MATH is defined as \MATH where \MATH is the number of classes \MATH , and \MATH is the proportion of examples in \MATH that have class \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0

Alignment 3244
To evaluate the resulting class entropy after set \MATH is partitioned into two sets \MATH and \MATH , the class-information entropy of the partition induced by cut-point T is defined by taking the weighted average of their resulting class entropies \MATH he best cut-point selected in step 2 is the cut-point \MATH for which \MATH is minimal amongst all the candidate cut-points .
To evaluate the resulting class entropy after set \MATH is partitioned into two sets \MATH and \MATH , the class-information entropy of the partition induced by cut-point T is defined by taking the weighted average of their resulting class entropies \MATH he best cut-point selected in step 2 is the cut-point \MATH for which \MATH is minimal amongst all the candidate cut-points .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0
49:1			49:1			0		1.0
50:1			50:1			0		1.0
51:1			51:1			0		1.0
52:1			52:1			0		1.0
53:1			53:1			0		1.0
54:1			54:1			0		1.0
55:1			55:1			0		1.0
56:1			56:1			0		1.0
57:1			57:1			0		1.0
58:1			58:1			0		1.0
59:1			59:1			0		1.0
60:1			60:1			0		1.0
61:1			61:1			0		1.0
62:1			62:1			0		1.0

Alignment 3245
Given set S and a potential binary partition , \MATH , specified on S by the given cut-point \MATH , a stopping criteria is used to decide whether or not this partition should be accepted .
Given set S and a potential binary partition \MATH , specified on S by the given cut-point \MATH , a stopping criteria is used to decide whether or not this partition should be accepted .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0
31:1			32:1			0		1.0
32:1			33:1			0		1.0
33:1			34:1			0		1.0
34:1			35:1			0		1.0

Alignment 3246
If the answer is YES , the discretization will continue with each partition given by \MATH ; otherwise , the discretization process will stop .
If the answer is YES , the discretization will continue with each partition given by \MATH ; otherwise , the discretization process will stop .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 3247
Suppose \MATH is the probability of a \MATH answer , and \MATH is the probability of the \MATH answer .
Suppose \MATH is the probability of a \MATH answer , and \MATH is the probability of a \MATH answer .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 3248
Partition \MATH is only accepted if \MATH .
Partition \MATH is only accepted if \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 3249
However , in practice , there is no easy way to estimate these probabilities directly .
However , in practice , there is no easy way to estimate these probabilities directly .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 3250
Instead , Fayyad and Irani [19] proposed using MDLP to indirectly estimate them .
Instead , Fayyad and Irani [19] proposed using MDLP to indirectly estimate them .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 3251
Originally , the minimum description length of an object is defined as the minimum number of bits required to uniquely specify that object out of the universe of all objects .
The minimum description length of an object is defined as the minimum number of bits required to uniquely specify that object out of the universe of all objects .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			3:1			0		1.0
2:1			4:1			0		1.0
3:1			5:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0
24:1			26:1			0		1.0
25:1			27:1			0		1.0
26:1			28:1			0		1.0
27:1			29:1			0		1.0
28:1			30:1			0		1.0

Alignment 3252
To employ MDLP in choosing the stopping criteria , Fayyad and Irani formulated the above problem as a communication problem between a sender and a receiver .
To employ MDLP in choosing the stopping criteria , Fayyad and Irani formulated the above problem as a communication problem between a sender and a receiver .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 3253
It is assumed that the sender has the entire set of training examples , while the receiver has the examples without their class labels .
It is assumed that the sender has the entire set of training examples , while the receiver has the examples without their class labels .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 3254
The sender needs to convey to proper class labeling of the example set to the receiver .
The sender needs to convey needed information for the proper class labeling of the example set to the receiver .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
9:1			6:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0

Alignment 3255
It says that the partition induced by a cut-point is accepted if and only if the length of the message required to send before partition is more than the length of the message required to send after partition .
It says that the partition induced by a cut-point is accepted if and only if the length of the message required to be sent before the partition is more than the length of the message required to be sent after the partition .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:2			22:1			3		1.0
24:1			23:1			0		1.0
25:1			31:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
34:1			32:1			0		1.0
35:1			33:1			0		1.0
36:1			34:1			0		1.0
37:2			35:1			3		1.0
39:1			36:1			0		1.0
41:1			37:1			0		1.0
42:1			38:1			0		1.0

Alignment 3256
By inferring from coding hypothesis , the stopping criteria is defined as follows : MDLP Criteria :A partition induced by cut-point \MATH for a set \MATH of \MATH examples is accepted iff :\MATH
By inferring from coding hypothesis , the stopping criteria is defined as follows : MDLP Criteria :A partition induced by cut-point \MATH for a set \MATH of \MATH examples is accepted iff :\MATH
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0

Alignment 3257
where \MATH and \MATH \MATH is the number of classes in \MATH Extensive experiments [19] ,[18] recommended that this method should be the first choice for variable discretization because it gives small number of cut-points while maintaining consistency .
where \MATH and \MATH where\MATH is the number of classes in \MATH Extensive experiments [18] , [19] recommended that this method should be the first choice for variable discretization because it gives a small number of cut-points while maintaining consistency .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
33:1			31:1			0		1.0
34:1			32:1			0		1.0
35:1			33:1			0		1.0
36:1			34:1			0		1.0
37:1			35:1			0		1.0
38:1			36:1			0		1.0
39:1			37:1			0		1.0
40:1			38:1			0		1.0

Alignment 3258
For experiments , face and non-face patterns are of size 24x24 .
For our experiments , face and non-face patterns were of size 24x24 . //[what is the unit here?]
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			2		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0

Alignment 3259
A set of 10 ,000 face patterns were collected from the Internet .
A set of 10 ,000 face patterns were collected from the Internet .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 3260
Another set of 10 ,000 hard non-face patterns were false positives collected by running a cascade of 17 AdaBoost classifiers at different locations and scales on 8 ,440 images with various subjects , such as rocks , trees , buildings , scenery , and flowers , containing no faces .
Another set of 10 ,000 hard non-face patterns were false positives collected by running a cascade of 17 AdaBoost classifiers at different locations and scales on 8 ,440 images with various subjects , such as rocks , trees , buildings , scenery , and flowers , containing no faces .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0
49:1			49:1			0		1.0

Alignment 3261
The 10 ,000 patterns in each set are divided into a training set of 6 ,000 patterns and a test set of 4 ,000 examples .
The 10 ,000 patterns in each set were divided into a training set of 6 ,000 patterns and a test set of 4 ,000 examples .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:2			7:2			3		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 3262
Some examples of the collected 24x24 face and non-face patterns are shown in Figure 2 .
Some examples of the collected 24x24 face and non-face patterns are shown in Figure 2 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 3263
Haar wavelet feature that has been widely used in many face detection systems [4] ,[6] ,[14] is used in our experiments .
Haar wavelet features , which have been used in many face detection systems [4] , [6] , [14] , were used in our experiments .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			1		1.0
5:1			4:1			2		1.0
6:1			5:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
19:1			16:1			2		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0

Alignment 3264
It consists of four kinds of features modeled from adjacent basic rectangles with the same size and shape .
These consisted of four kinds of features modeled from adjacent basic rectangles with the same size and shape .
Line2Start:Length	Line1Start:Length	Module		Score
1:2			1:2			3		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 3265
The feature value is defined as the difference of sum of the pixels within rectangles ( cf . Figure 3 ) .
The feature value was defined as the difference of the sum of the pixels within rectangles ( Figure 3 ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:2			3:2			3		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0

Alignment 3266
In total , 134 ,736 features were used for training classifiers .
In total , 134 ,736 features were used for training classifiers .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 3267
Figure 4 shows a comparison of performances of strong classifiers trained by different boosting schemes that are AdaBoost [4] , Real AdaBoost [17] and Ent-Boost .
Figure 4 shows a comparison of the performances of strong classifiers trained by the different boosting schemes : AdaBoost [4] , Real AdaBoost [17] , and Ent-Boost .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0

Alignment 3268
Each strong classifier is a combination of 80 weak classifiers ( using more weak classifiers does not improve much the performance ) .
Each strong classifier is a combination of 80 weak classifiers ( using more weak classifiers does not much improve the performance ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			18:1			0		1.0
18:1			17:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 3269
As for Real AdaBoost , the subspace splitting is done by equal width binning in which the number of bins is arbitrarily selected to be 64 and 128 .
For Real AdaBoost , subspace splitting is done by equal-width binning in which the number of bins is arbitrarily selected to be 64 and 128 .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
10:1			13:1			0		1.0
11:1			14:1			0		1.0
12:1			15:1			0		1.0
13:1			16:1			0		1.0
14:1			17:1			0		1.0
15:1			18:1			0		1.0
16:1			19:1			0		1.0
17:1			20:1			0		1.0
18:1			21:1			0		1.0
19:1			22:1			0		1.0
20:1			23:1			0		1.0
21:1			24:1			0		1.0
22:1			25:1			0		1.0
23:1			26:1			0		1.0
24:1			27:1			0		1.0
25:1			28:1			0		1.0

Alignment 3270
The curves indicate that the performances of Real AdaBoost and Ent-Boost are better than that of AdaBoost .
The curves indicate that the performances of Real AdaBoost and Ent-Boost were better than that of AdaBoost .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:2			11:2			3		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 3271
In addition , the performance of Real AdaBoost classifiers varies when using different number of bins .
In addition , the performance of Real AdaBoost classifiers varied when using different numbers of bins .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			1		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:2			13:2			3		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 3272
Overall , Ent-Boost has the best result .
Overall , Ent-Boost produced the best result .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 3273
As for storage space , the Ent-Boost based classifier only employs 6 .79 bins on average which is much smaller than that of Real AdaBoost-based classifiers .
As for storage space , the Ent-Boost-based classifier only uses 6 .79 bins on average , which is much fewer than the number used by Real AdaBoost-based classifiers .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			2		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
20:3			20:2			3		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0

Alignment 3274
Using Ent-Boost , a robust face detector was built .
Using Ent-Boost , a robust face detector was built .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 3275
It was a cascade of Ent-Boost based classifiers that were trained similar to [4] .
It was a cascade of Ent-Boost-based classifiers that were trained [through a process similar to that used in] [4] .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
18:1			13:1			0		1.0
19:1			14:1			0		1.0

Alignment 3276
The result cascade has 25 layers employing 3 ,850 features .
The resulting cascade has 25 layers using 3 ,850 features .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			1		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			2		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 3277
Performances of AdaBoost-based face detector [4] and Ent-Boost based face detector on MIT+CMU test set [1] shown in Table 2 has confirmed the effectiveness of our proposed boosting scheme .
The performances of the AdaBoost-based face detector [4] and our Ent-Boost-based face detector on the MIT+CMU test set [1] confirmed the effectiveness of our proposed boosting scheme ( Table 2 ) .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			22:1			0		1.0
4:1			2:1			0		1.0
5:1			3:1			0		1.0
6:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			21:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0
24:1			26:1			0		1.0
25:1			27:1			0		1.0
26:1			28:1			0		1.0
28:1			18:1			0		1.0
29:1			19:1			0		1.0
31:1			29:1			0		1.0

Alignment 3278
Some detection results are given in Figure 5 .
Some detection results are given in Figure 5 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 3279
We have presented Ent-Boost , a variant of AdaBoost , which uses entropy measure for automatic subspace splitting and optimal weak classifier selection .
We have described Ent-Boost , a variant of AdaBoost , which uses entropy measures for automatic subspace splitting and optimal weak classifier selection .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:2			13:2			3		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 3280
The resulted strong classifier has good performance and compact storage .
The resultant strong classifier has good performance and achieves compact storage .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			1		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0

Alignment 3281
Furthermore , it overcomes the main limitation of Real AdaBoost which is hard to determine the suitable number of bins for subspace splitting .
Furthermore , this new boosting scheme overcomes the main limitation of Real AdaBoost , which is difficulty in determining the suitable number of bins for subspace splitting .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
6:1			3:1			0		1.0
7:1			4:1			0		1.0
8:1			5:1			0		1.0
9:1			6:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
14:1			10:1			0		1.0
15:1			11:1			0		1.0
17:2			13:2			3		1.0
19:1			15:1			0		1.0
20:1			16:1			0		1.0
21:1			17:1			0		1.0
22:1			18:1			0		1.0
23:1			19:1			0		1.0
24:1			20:1			0		1.0
25:1			21:1			0		1.0
26:1			22:1			0		1.0
27:1			23:1			0		1.0

Alignment 3282
By considering the class information and the distribution of the input data in splitting process , this method is generic and can be applied to other applications .
Because it considers the class information and the distribution of the input data in the splitting process , this method is generic and can be used for other applications .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			1		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			2		1.0
26:2			24:2			3		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0

Alignment 3283
Experiments have shown promising results , especially in building a robust face detector .
Experiments have shown promising results , especially in the building of a robust face detector .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0

Alignment 3284
ROBUST OBJECT DETECTION USING FAST FEATURE SELECTION FROM HUGE FEATURE SETS
ROBUST OBJECT DETECTION USING FAST FEATURE SELECTION FROM HUGE FEATURE SETS
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 3285
This paper describes an efficient feature selection method which quickly selects a small subset out of a given huge feature set for building robust object detection systems .
This paper describes an efficient feature selection method which that quickly selects a small subset out of a given huge feature set ; the proposed method for will be useful for building robust object detection systems .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
30:1			21:1			0		1.0
31:1			22:1			0		1.0
32:1			23:1			0		1.0
33:1			24:1			0		1.0
34:1			25:1			0		1.0
35:1			26:1			0		1.0
36:1			27:1			0		1.0

Alignment 3286
In this filter-based method , features are selected so that not only maximizing their relevance with the target class but also minimizing their mutual dependency .
In this filter-based method , features are selected so that not only to maximizeing their relevance with the target class but also to minimizeing their mutual dependency .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
13:1			12:1			1		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
23:1			21:1			1		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0

Alignment 3287
As a result , the selected feature set only contains highly informative and non-redundant features which when combined together , significantly improve classification performance .
As a result , the selected feature set only contains only highly informative and non-redundant features , which significantly improve classification performance when combined together , significantly improve classification performance .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			16:1			0		1.0
23:1			17:1			0		1.0
24:1			18:1			0		1.0
25:1			19:1			0		1.0
30:1			24:1			0		1.0

Alignment 3288
The relevance and mutual dependency of features are measured by using conditional mutual information ( CMI ) in which features and classes are treated as discrete random variables .
The relevance and mutual dependency of features are measured by using conditional mutual information ( CMI ), in which features and classes are treated as discrete random variables . //[ ,?<--A comma can be used here if the following describes CMI in general .]
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 3289
Experiments on different huge feature sets have shown that the proposed CMI-based feature selection can both reduce significantly the training time and achieve high accuracy .
Experiments on different huge feature sets have shown that the proposed CMI-based feature selection can both reduce significantly the training time significantly and achieve high accuracy .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0

Alignment 3290
One of the fundamental research issues in pattern recognition is feature selection which is the task of finding a small subset out of a given large set of features .
One of the fundamental research issues in pattern recognition is feature selection , which is the task of finding a small subset out of a given large set of features .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0

Alignment 3291
It is significant due to the following three reasons .
Improving the method of accomplishing this task is important due to the following three reasons .
Line2Start:Length	Line1Start:Length	Module		Score
7:1			1:1			0		1.0
8:1			2:1			2		1.0
9:1			3:1			0		1.0
10:1			4:1			0		1.0
11:1			5:1			0		1.0
12:1			6:1			0		1.0
13:1			7:1			0		1.0
14:1			8:1			0		1.0
15:1			9:1			0		1.0

Alignment 3292
First , there are many ways to represent a target object , leading to a huge feature set .
First , there are many ways can be used to represent a target object , and this variety leadsleading to a huge feature set .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
9:1			6:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0
19:1			13:1			0		1.0
20:1			14:1			0		1.0
21:1			15:1			0		1.0
22:1			16:1			0		1.0
23:1			17:1			0		1.0
24:1			18:1			0		1.0

Alignment 3293
For example , the number of Haar wavelet features used in [1] for face detection is hundreds of thousands .
For example , the number of Haar wavelet features used in [1] for face detection is hundreds of thousands .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 3294
However , only small and incomplete training sets are available .
However , only small and incomplete training sets are available .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 3295
As a result , these systems suffer from the curse of dimensionality and over-fitting .
As a result , these systems suffer from the curse of dimensionality and over-fitting .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 3296
Second , a huge feature set usually includes many irrelevant and redundant features that can degrade the generalization performance of classifiers , waste storage space and increase training time [2 , 3] .
Second , a huge feature set usually includes many irrelevant and redundant features that can degrade the generalization performance of classifiers , waste storage space , and increase training time [2 , 3] .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0

Alignment 3297
Third , selecting an optimal feature subset from a huge feature set can improve the performance and speed of classifiers .
Third , selecting an optimal feature subset from a huge feature set can improve the performance and speed of classifiers .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 3298
Furthermore , less complex model is easier to understand and verify .
Furthermore , less complex models is are easier to understand and verify .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			1		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0

Alignment 3299
In face detection , the success of systems such as those in [1 , 4] comes mainly from efficient feature selection methods .
In face detection , the success of systems such as those in [1 , 4] comes mainly from efficient feature selection methods .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 3300
Generally , feature selection methods can be categorized into two kinds : filter-based approach and wrapper-based approach [5] .
Generally , feature selection methods can be categorized into two kinds : the filter-based approach and the wrapper-based approach [5] .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0

Alignment 3301
The filter-based approach is independent of any induction algorithm while the wrapper-based approach is associated with a specific induction algorithm to evaluate the goodness of the selected feature subset .
The filter-based approach is independent of any induction algorithm , while but the wrapper-based approach is associated with a specific induction algorithm to evaluate the quality of the selected feature subset . //[goodness / quality / appropriateness?<--If " goodness " is the word you would usually use in your field for this , it is fine , but I would suggest a different word choice otherwise . " Goodness " seems vague , so in what sense do you mean " good " ?]
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
38:1			23:1			0		1.0

Alignment 3302
In the filter-based approach , features are normally selected based on their individual predictive power which is measured by Fisher scores , Pearson correlation [6] or mutual information [7] .
In the filter-based approach , features are normally selected based on their individual predictive power . This power is measured by Fisher scores , Pearson correlation [6] , or mutual information [7] .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
28:1			25:1			0		1.0
29:1			26:1			0		1.0
30:1			27:1			0		1.0
31:1			28:1			0		1.0
32:1			29:1			0		1.0

Alignment 3303
The major advantage of these methods is their speed and ability to scale to huge feature sets .
The major advantage of these measurement methods is their speed and ability to scale to huge feature sets .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0

Alignment 3304
However , the mutual relationships between features is often not taken into account , leading selected features might be highly redundant and less informative because two features with high individual predict power when combined together might not bring significant performance improvement compared with two features which one of them has low predictive power but is useful when combined with others .
However , because the mutual relationships between features is are often not taken into account , leading the selected features might be highly redundant and less informative because two features with high individual predictive power , when combined together , might not bring significant performance improvement . Combining compared with two features of which one of them has low predictive power but is useful when combined with others would thus be more effective for improving performance .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			24:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			54:1			2		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0
26:1			23:1			0		1.0
28:1			25:1			0		1.0
29:1			26:1			0		1.0
30:1			27:1			0		1.0
31:1			28:1			0		1.0
32:1			29:1			0		1.0
33:1			51:1			0		1.0
34:1			52:1			0		1.0
36:1			32:1			0		1.0
37:1			33:1			0		1.0
38:1			34:1			0		1.0
40:1			35:1			0		1.0
41:1			36:1			0		1.0
42:1			37:1			0		1.0
43:1			38:1			0		1.0
44:1			39:1			0		1.0
45:1			40:1			0		1.0
46:1			60:1			0		1.0
48:1			41:1			0		1.0
49:1			42:1			0		1.0
50:1			43:1			0		1.0
51:1			44:1			0		1.0
52:1			47:1			0		1.0
53:1			45:1			0		1.0
54:1			46:1			0		1.0
56:1			48:1			0		1.0
57:1			49:1			0		1.0
58:1			50:1			0		1.0
59:1			30:1			1		1.0
60:1			31:1			0		1.0
61:1			53:1			0		1.0
63:1			55:1			0		1.0
64:1			56:1			0		1.0
65:1			57:1			0		1.0
66:1			58:1			0		1.0
67:1			59:1			0		1.0

Alignment 3305
Since wrapper-based feature selection methods use machine learning algorithms as a black box in selection process , they can suffer from over-fitting in situations of small training sets .
Since wrapper-based feature selection methods use machine learning algorithms as a black box in the selection process , they can suffer from over-fitting in situations of when applied to small training sets . //[when used with / when applied to?]
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
29:1			25:1			0		1.0
30:1			26:1			0		1.0
31:1			27:1			0		1.0
32:1			28:1			0		1.0

Alignment 3306
Furthermore , in practical object detection systems as in [1 , 8] , the feature sets usually have hundreds of thousands features , using wrapper-based methods is obviously inefficient because of very high computation cost .
Furthermore , in practical object detection systems as in [1 , 8] , the feature sets usually have hundreds of thousands of features , so using wrapper-based methods is obviously inefficient because of the very high computation costs they incur .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
34:1			31:1			0		1.0
35:1			32:1			0		1.0
36:1			33:1			0		1.0
37:1			34:1			1		1.0
40:1			35:1			0		1.0

Alignment 3307
For example , in the state of the art face detection system [1] , choosing a 6 ,061- feature set out of a 180 ,000-feature set by AdaBoost has taken several weeks .
For example , in the state- of- the- art face detection system in [1] , choosing a 6 ,061- feature set out of a 180 ,000-feature set by using AdaBoost has takentook several weeks . //[by using / generated by?]
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
32:1			30:1			0		1.0
33:1			31:1			0		1.0
34:1			32:1			0		1.0

Alignment 3308
Consequently , conditional mutual information ( CMI ) based feature selection methods have been proposed [9 , 8 , 7 , 10] to take full advantage of above approaches for handling large scale feature sets .
Consequently , feature selection methods based on conditional mutual information ( CMI ) based feature selection methods have been proposed [9 , 8 , 7 , 10] to take full advantage of the above approaches for handling large scale feature sets .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			9:1			0		1.0
3:1			10:1			0		1.0
4:1			11:1			0		1.0
7:1			2:1			0		1.0
8:1			3:1			0		1.0
9:1			4:1			0		1.0
10:1			5:1			0		1.0
11:1			6:1			0		1.0
12:1			7:1			0		1.0
13:1			8:1			0		1.0
14:1			33:1			0		1.0
17:1			12:1			0		1.0
18:1			13:1			0		1.0
19:1			14:1			0		1.0
20:1			15:1			0		1.0
21:1			16:1			0		1.0
22:1			17:1			0		1.0
23:1			18:1			0		1.0
24:1			19:1			0		1.0
25:1			20:1			0		1.0
26:1			21:1			0		1.0
27:1			22:1			0		1.0
28:1			23:1			0		1.0
29:1			24:1			0		1.0
30:1			25:1			0		1.0
31:1			26:1			0		1.0
33:1			27:1			0		1.0
34:1			28:1			0		1.0
35:1			29:1			0		1.0
36:1			30:1			0		1.0
37:1			31:1			0		1.0
38:1			32:1			0		1.0
40:1			34:1			0		1.0
41:1			35:1			0		1.0

Alignment 3309
The main idea of CMI-based methods is to select features which maximize their relevance with the target class and simultaneously minimize mutual dependency between selected ones .
The main goal of these CMI-based methods is to select features which that maximize their relevance with the target class and to simultaneously minimize mutual dependency between selected ones . //[idea / goal?]
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
22:1			19:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0
26:1			23:1			0		1.0
27:1			24:1			0		1.0
28:1			25:1			0		1.0
29:1			26:1			0		1.0

Alignment 3310
It does not select a feature similar to already selected ones , even if it is individual powerful , as selecting it might not increase much information about the target class [7] .
It doesThese methods do not select a feature similar to ones already selected ones , even if itthe feature is individually powerful , as because selecting it might not do much to increase much information about the target class [7] .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
3:2			1:2			3		1.0
5:1			3:1			0		1.0
6:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
19:1			15:1			0		1.0
20:1			16:1			1		1.0
21:1			17:1			0		1.0
22:1			18:1			0		1.0
23:1			19:1			0		1.0
25:1			20:1			0		1.0
26:1			21:1			0		1.0
27:1			22:1			0		1.0
28:1			23:1			0		1.0
30:1			25:1			0		1.0
32:1			24:1			0		1.0
34:1			26:1			0		1.0
35:1			27:1			0		1.0
36:1			28:1			0		1.0
37:1			29:1			0		1.0
38:1			30:1			0		1.0
39:1			31:1			0		1.0
40:1			32:1			0		1.0

Alignment 3311
One of the important tasks in using CMI-based methods is mutual information estimation which involves to compute probability densities of continuous random variables .
One of the important tasks in using CMI-based methods is mutual information estimation , which involves to computecomputing the probability densities of continuous random variables .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0

Alignment 3312
In [9] , Kwak and Choi used Parzen windows based density estimation method in which many parameters such as kernel function and window width are complicated to determine .
In [9] , Kwak and Choi used a Parzen windows -based density estimation method in which many parameters such as kernel function and window width are complicated to determine .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0

Alignment 3313
For simplification , discretizing features is often used .
For simplification , discretizing features is often used on the features . //[discretizing features is often used on the features / the features are often discretized?]
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
11:1			8:1			0		1.0

Alignment 3314
So far , in object detection systems like [8 , 7] , features are treated as binary random variables by choosing appropriate thresholds .
So far , in object detection systems like [8 , 7] treat , features are treated as binary random variables by choosing appropriate thresholds .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0

Alignment 3315
However , binarizing features is not a suitable way to handle highly complex data for which it is hard to find the best threshold .
However , binarizing features is not a suitable way to handle highly complex data for which it is hard to finding the best threshold is difficult .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:2			20:2			3		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
26:1			24:1			0		1.0

Alignment 3316
It is better if multiple thresholds are used to discretize data .
Using multiple thresholds to discretize data is better than using a binary approach .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			4:1			0		1.0
2:1			5:1			0		1.0
3:1			8:1			0		1.0
4:1			9:1			0		1.0
5:1			10:1			0		1.0
6:1			1:1			0		1.0
7:1			2:1			0		1.0
13:1			11:1			0		1.0

Alignment 3317
Such a simple method is equal-width binning which divides the range of feature values into m equal sized bins , where m must be known in advance .
Such a simple method is equal-width binning , which divides the range of feature values into m equally sized bins , where m must be known in advance .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			1		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0

Alignment 3318
Our method is also a CMI-based feature selection method .
Our method is also a CMI-based feature selection method .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 3319
However , the main distinguished point is that it employs the entropy-based discretization method [11] to discretize features .
However , the method�fs main distinguishing point is that it employs the entropy-based discretization method [11] to discretize features . //[distinguishing / unique?]
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			1		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0

Alignment 3320
This discretization method is simpler than Parzen windows based density estimation method and more efficient than binary discretization .
This discretization method is simpler than the Parzen window-s based density estimation method and is more efficient than binary discretization .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0

Alignment 3321
Furthermore , contrary to equal-width binning , it can automatically evaluate the optimal number of bins based on data distribution .
Furthermore , contrary to equal-width binning , it can automatically evaluate the optimal number of bins based on data distribution . //[evaluate / determine?]
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 3322
Experiments show that the proposed method can well handle huge feature sets for face detection such as Haar wavelets [1] and Gabor wavelets [12] , significantly reduce the training time while maintaining high classification performance .
Experiments show that the proposed method can well capably handle huge feature sets of data such as Haar wavelets [1] and Gabor wavelets [12] for face detection , significantly reducinge the training time while maintaining high classification performance .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			12:1			0		1.0
25:1			13:1			0		1.0
26:1			14:1			0		1.0
27:1			24:1			0		1.0
28:1			25:1			0		1.0
30:1			27:1			0		1.0
31:1			28:1			0		1.0
32:1			29:1			0		1.0
33:1			30:1			0		1.0
34:1			31:1			0		1.0
35:1			32:1			0		1.0
36:1			33:1			0		1.0
37:1			34:1			0		1.0
38:1			35:1			0		1.0

Alignment 3323
FEATURE SELECTION " >
FEATURE SELECTION " >
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0

Alignment 3324
Huge feature sets usually contain four kinds of features : ( i ) irrelevant features , ( ii ) weakly relevant and redundant features , ( iii ) weakly relevant but non-redundant features and ( iv ) strongly relevant features in which ( iii ) and ( iv ) are the objective of feature selection methods [13] .
Huge feature sets usually contain four kinds of features : ( i ) irrelevant features , ( ii ) weakly relevant and redundant features , ( iii ) weakly relevant but non-redundant features , and ( iv ) strongly relevant features ; in which ( iii ) and ( iv ) are the objectives of feature selection methods [13] .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
37:1			36:1			0		1.0
38:1			37:1			0		1.0
39:1			38:1			0		1.0
40:1			39:1			0		1.0
42:1			40:1			0		1.0
43:1			41:1			0		1.0
44:1			42:1			0		1.0
45:1			43:1			0		1.0
46:1			44:1			0		1.0
47:1			45:1			0		1.0
48:1			46:1			0		1.0
49:1			47:1			0		1.0
50:1			48:1			0		1.0
51:1			49:1			0		1.0
52:1			50:1			0		1.0
53:1			51:1			1		1.0
54:1			52:1			0		1.0
55:1			53:1			0		1.0
56:1			54:1			0		1.0
57:1			55:1			0		1.0
58:1			56:1			0		1.0
59:1			57:1			0		1.0

Alignment 3325
To measure relevance of a feature , the entropy-based measure which quantifies the uncertainty of random variables is normally used .
To measure the relevance of a feature , an entropy-based measure , which quantifies the uncertainty of random variables , is normally used .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			7:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			0		1.0
23:1			20:1			0		1.0

Alignment 3326
The entropy of a discrete random variable X is defined as : \MATH and the conditional entropy of X after another variable Y is known is defined as \MATH
The entropy of a discrete random variable X is defined as : \MATH and the conditional entropy of X after another variable Y is known is defined as \MATH
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 3327
The mutual dependence between two random variables is measured by mutual information \MATH .
The mutual dependence between two random variables is measured by mutual information : \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0

Alignment 3328
The conditional mutual information is defined as : \MATH
The conditional mutual information is defined as : \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 3329
In the first step , the most relevant feature F1 which has the highest mutual information is selected .
In the first step , the most relevant feature F1 , which has the highest largest amount of mutual information , is selected .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
18:1			14:1			0		1.0
19:1			15:1			0		1.0
21:1			16:1			0		1.0
22:1			17:1			0		1.0
23:1			18:1			0		1.0

Alignment 3330
However , in the second step , the condition to select feature F2 is not its mutual information alone , but how much information of F2 can add with respect to the already existing F1 .
However , iIn the second step , however , the condition to select feature F2 is not its mutual information alone , but how much information of F2 can add with respect to the already existing F1 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			19:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
33:1			31:1			0		1.0
34:1			32:1			0		1.0
35:1			33:1			0		1.0
36:1			34:1			0		1.0
37:1			35:1			0		1.0

Alignment 3331
Therefore , F2 is selected so that maximizing :\MATH .
Therefore , F2 is selected so that maximizingas to maximize the information it can add :\MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
15:1			8:1			0		1.0
16:1			9:1			0		1.0

Alignment 3332
Following the same scheme , we iteratively add the feature that brings the highest increase of information content contained in current selected feature set .
Following the same scheme, we iteratively add the feature that brings the highest increase of the information content contained in the current selected feature set . //[the / an?<-- " An " is correct if there is more than one such measure .]
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0

Alignment 3333
The next feature Ft to be added at iteration t is defined by :\MATH .
The next feature Ft to be added at iteration t is defined by :\MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 3334
In order to simply estimate mutual information , the easiest way is features are discretized in binary values by specifying thresholds [8 , 7] .
To simply estimate mutual information , the easiest way is to discretize features are discretized in binary values by specifying thresholds [8 , 7] .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			3:1			0		1.0
2:1			4:1			0		1.0
3:1			5:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			2:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 3335
However , for complex data , it is not efficient ; therefore , we use entropy-based method proposed by Fayyad and Irani [11] for discretization .
However , for complex data , doing thisit is not efficient ; therefore , we use the entropy-based method proposed by Fayyad and Irani [11] for discretization .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0

Alignment 3336
This method is a supervised method , thus it is generic and can adapt very well to any kind of data distributions .
This method is a supervised method , thus so it is generic and can adapt very well to any kind of data distributions .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0

Alignment 3337
Basically , discretization is a quantizing process that converts continuous values into discrete values .
Discretization is essentially a quantizing process that converts continuous values into discrete values .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0

Alignment 3338
Suppose that we are given a set of instances S , a feature A and a cut-point T ( a cutpoint is a threshold value that divides the range of continuous values into two intervals ; one interval is less than or equal to the threshold , and the other interval is greater than the threshold ) .
Suppose that we are given a set of instances S , a feature A , and a cut-point T . ( A cut-point is a threshold value that divides the range of continuous values into two intervals ; one interval is less than or equal to the threshold , and the other interval is greater than the threshold . ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			46:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			57:1			0		1.0
20:1			18:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
33:1			31:1			0		1.0
34:1			32:1			0		1.0
35:1			33:1			0		1.0
36:1			34:1			0		1.0
37:1			35:1			0		1.0
38:1			36:1			0		1.0
39:1			37:1			0		1.0
40:1			38:1			0		1.0
41:1			39:1			0		1.0
42:1			40:1			0		1.0
43:1			41:1			0		1.0
44:1			42:1			0		1.0
45:1			43:1			0		1.0
46:1			44:1			0		1.0
47:1			45:1			0		1.0
49:1			47:1			0		1.0
50:1			48:1			0		1.0
51:1			49:1			0		1.0
52:1			50:1			0		1.0
53:1			51:1			0		1.0
54:1			52:1			0		1.0
55:1			53:1			0		1.0
56:1			54:1			0		1.0
57:1			55:1			0		1.0
59:1			56:1			0		1.0

Alignment 3339
The class-information entropy of the partition induced by T is defined as :
The class-information entropy of the partition induced by T is defined as :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 3340
Among candidate cut-points , the best candidate cut-point Tmin which minimizes the entropy function \MATH is selected to split \MATH into two partitions \MATH and \MATH .
Among candidate cut-points , the best candidate cut-point Tmin , which minimizes the entropy function \MATH , is selected to split \MATH into two partitions \MATH and \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0

Alignment 3341
This process can then be repeated recursively to \MATH and \MATH until some stopping condition is satisfied , thus creating multiple intervals on the feature \MATH .
This process can then be repeated recursively forto \MATH and \MATH until some stopping condition is satisfied , thus creating multiple intervals on the feature \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 3342
Using MDLP , the stopping criteria is proposed by Fayyad and Irani [11] as follows :
Using MDLP , the stopping criteria is was proposed by Fayyad and Irani [11] as follows :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0

Alignment 3343
MDLP Criteria : A partition induced by cut-point T for a set S of N examples is accepted if : \MATH Where \MATH ,where \MATH , \MATH , \MATH is the number of classes in \MATH , \MATH , \MATH .
MDLP Criteria : A partition induced by cut-point T for a set S of N examples is accepted if : \MATH wWhere \MATH ,where \MATH , \MATH , and \MATH is are the numbers of classes in \MATH , \MATH , and \MATH , respectively .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
32:1			30:1			0		1.0
33:1			31:1			1		1.0
34:1			32:1			0		1.0
35:1			33:1			0		1.0
36:1			34:1			0		1.0
37:1			35:1			0		1.0
38:1			36:1			0		1.0
39:1			37:1			0		1.0
40:1			38:1			0		1.0
42:1			39:1			0		1.0
45:1			40:1			0		1.0

Alignment 3344
Extensive experiments [11 , 14] have shown that this method is one of the best variable discretization one because it gives small number of cut-points while maintaining consistency .
Extensive experiments [11 , 14] have shown that this method is one of the best in variable discretization one because it gives a small number of cut-points while maintaining consistency .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0

Alignment 3345
The outline of the proposed feature selection method is shown in Algorithm 1 .
The outline of the proposed feature selection method is shown in Algorithm 1 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 3346
For experiments , a set face and non-face patterns of size 24x24 was used .
For experiments , a set of face and non-face patterns of size 24x24 was used .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0

Alignment 3347
A set of 10 ,000 face patterns were collected from the Internet .
A set of 10 ,000 face patterns were collected from the Internet .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 3348
Another set of 10 ,000 complex non-face patterns were false positives collected by running a face detector based on a cascade of 17 AdaBoost classifiers at different locations and scales on 8 ,440 images with various subjects , such as rocks , trees , buildings , scenery , and flowers , containing no faces .
Another set of 10 ,000 complex non-face patterns were false positives collected by running a face detector based on a cascade of 17 AdaBoost classifiers at different locations and scales on 8 ,440 images that contained no faces ; the images with included various subjects , such as rocks , trees , buildings , scenery , and flowers , containing no faces .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:2			51:1			3		1.0
36:1			52:1			0		1.0
37:1			53:1			0		1.0
41:1			34:1			0		1.0
43:1			35:1			0		1.0
44:1			36:1			0		1.0
45:1			37:1			0		1.0
46:1			38:1			0		1.0
47:1			39:1			0		1.0
48:1			40:1			0		1.0
49:1			41:1			0		1.0
50:1			42:1			0		1.0
51:1			43:1			0		1.0
52:1			44:1			0		1.0
53:1			45:1			0		1.0
54:1			46:1			0		1.0
55:1			47:1			0		1.0
56:1			48:1			0		1.0
57:1			49:1			0		1.0
58:1			50:1			0		1.0
62:1			54:1			0		1.0

Alignment 3349
The 10 ,000 patterns in each set were divided into a training set of 6 ,000 patterns and a test set of 4 ,000 patterns .
The 10 ,000 patterns in each set were divided into a training set of 6 ,000 patterns and a test set of 4 ,000 patterns .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 3350
Some examples of the collected 24x24 face and non-face patterns are shown in Figure 1 .
Some examples of the collected 24x24 face and non-face patterns are shown in Figure 1 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 3351
Two types of features that are Haar wavelet feature and Gabor wavelet feature were used in experiments .
Two types of features ?that are Haar wavelet features and Gabor wavelet features ? were used in our experiments .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			1		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			1		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0

Alignment 3352
Haar wavelet features have been widely used in many face detection systems [1 , 15] .
Haar wavelet features have been widely used in many face detection systems [1 , 15] .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 3353
It consists of four kinds of features modeled from adjacent basic rectangles with the same size and shape .
They consists of four kinds of features modeled from adjacent basic rectangles with the same size and shape . //I�fm not 100 percent clear on what " they " points to here . " These Haar wavelet features , " perhaps? But can features consist of other kinds of features? You may want to clarify here .]
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 3354
The feature value is defined as the difference of sum of the pixels within rectangles .
The feature value is defined as the difference of the sum of the pixels within the rectangles .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0

Alignment 3355
In total , 134 ,736 features were used for training classifiers .
In total , 134 ,736 features were used for training classifiers .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 3356
Gabor wavelet features have also often been used in face recognition systems [12] and are defined as : \MATH where \MATH and \MATH define the orientation and scale of the Gabor kernels respectively , \MATH , and the wave vector \MATH , is defined as : \MATH where \MATH , \MATH \MATH .
Gabor wavelet features have also often been used often in face recognition systems [12] and are defined as : \MATH , where \MATH and \MATH define the orientation and scale of the Gabor kernels respectively , \MATH , and the wave vector \MATH , is defined as : \MATH where \MATH , \MATH and \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			49:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
33:1			31:1			0		1.0
34:1			32:1			0		1.0
35:1			33:1			0		1.0
36:1			34:1			0		1.0
37:1			35:1			0		1.0
38:1			36:1			0		1.0
39:1			37:1			0		1.0
40:1			38:1			0		1.0
41:1			39:1			0		1.0
42:1			40:1			0		1.0
43:1			41:1			0		1.0
44:1			42:1			0		1.0
45:1			43:1			0		1.0
46:1			44:1			0		1.0
47:1			45:1			0		1.0
48:1			46:1			0		1.0
49:1			47:1			0		1.0
50:1			48:1			0		1.0
52:1			50:1			0		1.0
54:1			51:1			0		1.0
55:1			52:1			0		1.0

Alignment 3357
The Gabor representation of a face image is computed by convolving the face image with the Gabor filters .
The Gabor representation of a face image is computed by convolving the face image with the Gabor filters .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 3358
Let \MATH be the face image , its convolution with a Gabor filter �� ,_( z ) is defined as : \MATH where \MATH denotes the convolution operator .
Let \MATH be the face image ; , its convolution with a Gabor filter �� ,_( z ) is defined as : \MATH where \MATH denotes the convolution operator .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0

Alignment 3359
Similar to [12] , Gabor kernels at five scales \MATH and eight orientations \MATH were used .
Similar to [12] , Gabor kernels at five scales , \MATH , and eight orientations , \MATH , were used .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
16:1			13:1			0		1.0
18:1			14:1			0		1.0
19:1			15:1			0		1.0
20:1			16:1			0		1.0

Alignment 3360
At each pixel position , 40 Gabor features are computed by convolving the input image with the real part of Gabor filters .
At each pixel position , 40 Gabor features are computed by convolving the input image with the real part of Gabor filters .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 3361
As a result , \MATH there are \MATH Gabor features for one 24x24 training sample .
As a result , one \MATH training sample hasthere are \MATH Gabor features for one 24x24 training sample .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
9:1			6:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0

Alignment 3362
In order to show effectiveness of the proposed feature selection method ( CMI-Multi ) , we compared it with two other feature selection methods that are forward feature selection ( FFS ) [16] and CMI-basedmethod using binary features ( CMIBinary ) [8 , 7] on the data set and feature setsmentioned above .
To prove the effectiveness of the proposed feature selection method ( CMI-Multi ) , we compared it with two other feature selection methods ?that are forward feature selection ( FFS ) [16] and a CMI-based methods using binary features ( CMI-Binary ) [8 , 7] ? on the data set and feature sets mentioned described above .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			45:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0
31:1			32:1			0		1.0
32:1			33:1			0		1.0
36:1			35:1			0		1.0
37:1			36:1			0		1.0
38:1			37:1			0		1.0
39:1			38:1			0		1.0
41:1			40:1			0		1.0
42:1			41:1			0		1.0
43:1			42:1			0		1.0
44:1			43:1			0		1.0
46:1			44:1			0		1.0
48:1			46:1			0		1.0
49:1			47:1			0		1.0
50:1			48:1			0		1.0
51:1			49:1			0		1.0
55:1			51:1			0		1.0
56:1			52:1			0		1.0

Alignment 3363
All classifiers were trained using AdaBoost similar to [1] .
All classifiers were trained using AdaBoost similar to [1] .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 3364
We chose the forward feature selection proposed by Wu et. al. [16] because it has very impressive results when not only reducing significantly the training time of AdaBoost-based face detection system [1] ( about 100 times ) but also maintaining comparable performance .
We chose the forward feature selection proposed by Wu et. al. [16] because it has very impressive results , when not only reducing significantly the training time of the AdaBoost-based face detection systems [1] by ( about 100 times , ) but also maintaining comparable performance .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			1		1.0
33:1			31:1			0		1.0
35:1			32:1			0		1.0
36:1			33:1			0		1.0
37:1			34:1			0		1.0
38:1			35:1			0		1.0
40:1			36:1			0		1.0
41:1			37:1			0		1.0
42:1			38:1			0		1.0
43:1			39:1			0		1.0
44:1			40:1			0		1.0
45:1			41:1			0		1.0
46:1			42:1			0		1.0

Alignment 3365
Figure 2 shows performance of classifiers trained by Haar feature subsets selected by three feature selection methods .
Figure 2 shows performance of classifiers trained by Haar feature subsets selected by three feature selection methods .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 3366
It indicates that , the proposed method CMI-Multi outperforms the others while FFS and CMI-Binary have comparable performance .
The figureIt indicates that , the proposed method , CMI-Multi , outperforms the others while the performances of FFS and CMI-Binary have were comparable performanceto one another .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
9:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0
18:1			12:1			0		1.0
19:1			13:1			0		1.0
20:1			14:1			0		1.0
21:1			15:1			0		1.0
23:1			16:1			0		1.0
27:1			18:1			0		1.0

Alignment 3367
The similar result is also shown when tested on Gabor wavelet features .
The A similar result is was also shown when the three feature selection methods were tested on Gabor wavelet features .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
6:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
15:1			7:1			0		1.0
16:1			8:1			0		1.0
17:1			9:1			0		1.0
18:1			10:1			0		1.0
19:1			11:1			0		1.0
20:1			12:1			0		1.0

Alignment 3368
In this case , CMI-based feature selection methods obviously outperform FFS and CMI-Multi is confirmed to be more efficient than CMI-Binary .
In this case , CMI-based feature selection methods obviously clearly outperformed FFS , and CMI-Multi is was confirmed to be more efficient than CMI-Binary .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			9:1			1		1.0
11:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0

Alignment 3369
Because our proposed method uses same principle as FFS which only trains weak classifiers once , it is extremely fast compared with AdaBoost [1] .
Because our proposed method uses same principle as FFS , which only trains weak classifiers once , it is extremely fast compared with AdaBoost [1] .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0

Alignment 3370
We built two cascade of AdaBoost classifiers that use CMI-Multi and AdaBoost [1] as feature selection methods .
We built two cascades of AdaBoost classifiers that use CMI-Multi and AdaBoost [1] as feature selection methods .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			1		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 3371
Testing on the standard benchmark MIT+CMU test set , they have comparable performance .
Testing on the standard benchmark MIT+CMU test set , they hadve comparable performance .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 3372
However , CMI-Multi is trained faster than AdaBoost approximately 70 times .
However , CMI-Multi wasis trained faster than was AdaBoost by approximately 70 times .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0

Alignment 3373
We have presented a fast feature selection method using conditional mutual information to handle huge feature sets .
We have presented a fast feature selection method using conditional mutual information to handle huge feature sets .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 3374
The estimation of mutual information is simplified by using MDLP based discretization method .
The estimation of mutual information is simplified by using an MDLP- based discretization method .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0

Alignment 3375
Integrated into AdaBoost-based object detection systems , it can not only reduce the training time significantly but also achieve high classification performance .
Integrated into AdaBoost-based object detection systems , our proposed methodit can not only reduces the training time significantly , but also achieves high classification performance .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			1		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			1		1.0
22:1			19:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0

Alignment 3376
Experiments on two popular feature sets such as Haar wavelets and Gabor wavelets have demonstrated the effectiveness of the proposed method .
Experiments on two popular feature sets have demonstrated the effectiveness of the proposed method . //[Please note : I am not sure which of the following you mean .--> one composed of such as Haar wavelets and the other composed of Gabor wavelets / ? Haar wavelets and Gabor wavelets ?]
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			13:1			0		1.0
7:1			14:1			0		1.0
8:1			15:1			0		1.0
9:1			16:1			0		1.0
10:1			17:1			0		1.0
11:1			18:1			0		1.0
12:1			19:1			0		1.0
13:1			20:1			0		1.0
14:1			21:1			0		1.0
32:1			6:1			0		1.0
33:1			7:1			0		1.0
34:1			8:1			0		1.0
35:1			9:1			0		1.0
36:1			10:1			0		1.0
41:1			11:1			0		1.0
42:1			12:1			0		1.0

Alignment 3377
A Multi-Stage Approach to Fast Face Detection
A Multi-Stage Approach to Fast Face Detection
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0

Alignment 3378
A multi-stage approach --- which is fast , robust and easy to train --- for a face-detection system is proposed .
A multi-stage approach that is fast , robust , and easy to train is proposed for a face-detection system .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:2			4:2			3		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			18:1			0		1.0
14:1			19:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			20:1			0		1.0

Alignment 3379
Motivated by the work of Viola and Jones [1] , this approach uses a cascade of classifiers to yield a coarse-to-fine strategy to reduce significantly detection time while maintaining a high detection rate .
Motivated by the work of Viola and Jones [1] , this approach uses a cascade of classifiers to yield a coarse-to-fine strategy to significantly reduce detection time while maintaining a high detection rate .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			24:1			0		1.0
24:1			23:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0

Alignment 3380
However , it is distinguished from previous work by two features .
However , our [system / approach?] is distinguished from previous work by two features .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
6:1			3:1			0		1.0
7:1			4:1			0		1.0
8:1			5:1			0		1.0
9:1			6:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0

Alignment 3381
First , a new stage is added to detect face candidate regions more quickly by using a larger window size and larger moving step size .
First , a new stage has been added to detect face candidate regions more quickly by using a larger window size and larger moving step size .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:2			5:1			3		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0

Alignment 3382
Second , SVM classifiers are used instead of AdaBoost classifiers in the last stage , and Haar wavelet features selected by the previous stage are reused for the SVM classifier robustly and efficiently .
Second , support vector machine ( SVM ) classifiers are used instead of AdaBoost classifiers in the last stage , and Haar wavelet features selected by the previous stage are reused for the SVM classifier robustly and efficiently .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
6:1			2:1			0		1.0
8:1			3:1			0		1.0
9:1			4:1			0		1.0
10:1			5:1			0		1.0
11:1			6:1			0		1.0
12:1			7:1			0		1.0
13:1			8:1			0		1.0
14:1			9:1			0		1.0
15:1			10:1			0		1.0
16:1			11:1			0		1.0
17:1			12:1			0		1.0
18:1			13:1			0		1.0
19:1			14:1			0		1.0
20:1			15:1			0		1.0
21:1			16:1			0		1.0
22:1			17:1			0		1.0
23:1			18:1			0		1.0
24:1			19:1			0		1.0
25:1			20:1			0		1.0
26:1			21:1			0		1.0
27:1			22:1			0		1.0
28:1			23:1			0		1.0
29:1			24:1			0		1.0
30:1			25:1			0		1.0
31:1			26:1			0		1.0
32:1			27:1			0		1.0
33:1			28:1			0		1.0
34:1			29:1			0		1.0
35:1			30:1			0		1.0
36:1			31:1			0		1.0
37:1			32:1			0		1.0
38:1			33:1			0		1.0

Alignment 3383
By combining AdaBoost and SVM classifiers , the final system can achieve both fast and robust detection because most non-face patterns are rejected quickly in earlier layers , while only a small number of promising face patterns is classified robustly in later layers .
By combining AdaBoost and SVM classifiers , the final system can achieve both fast and robust detection because most non-face patterns are rejected quickly in earlier layers , while only a small number of promising face patterns are classified robustly in later layers .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			2		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0

Alignment 3384
The proposed multi-stage-based system is shown to run faster than the original AdaBoost-based system while maintaining comparable accuracy .
The proposed multi-stage-based system has been shown to run faster than the original AdaBoost-based system while maintaining comparable accuracy .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:2			4:1			3		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0

Alignment 3385
Face detection is one of the most active research areas in computer vision because of its many interesting applications in fields such as security , surveillance , multimedia retrieval , and human-computer interaction .
Face detection is one of the most active research areas in computer vision because of its many interesting applications in fields such as security , surveillance , multimedia retrieval , and human-computer interaction .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0

Alignment 3386
For example , face detection is combined with other modules to identify who a person in a video sequence is [2] .
For example , face detection is combined with other modules to identify a person in a video sequence [2] .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0

Alignment 3387
Face locations , the results of a face detection system , can be used for applications such as face recognition and video indexing [3] .
Face locations , the results of a face detection system , can be used for applications such as face recognition and video indexing [3] .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 3388
Although it has been studied for more than 30 years , developing a fast and robust face detection system that can handle the variations found in different faces in real applications , such as facial expressions , pose changes , illumination changes , complex backgrounds , and low resolutions , is still a challenging research target [4] .
Although this area has been studied for more than 30 years , developing a fast and robust face detection system that can handle the variations found in different faces in real applications , such as facial expressions , pose changes , illumination changes , complex backgrounds , and low resolutions , is still a challenging research target [4] .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
37:1			36:1			0		1.0
38:1			37:1			0		1.0
39:1			38:1			0		1.0
40:1			39:1			0		1.0
41:1			40:1			0		1.0
42:1			41:1			0		1.0
43:1			42:1			0		1.0
44:1			43:1			0		1.0
45:1			44:1			0		1.0
46:1			45:1			0		1.0
47:1			46:1			0		1.0
48:1			47:1			0		1.0
49:1			48:1			0		1.0
50:1			49:1			0		1.0
51:1			50:1			0		1.0
52:1			51:1			0		1.0
53:1			52:1			0		1.0
54:1			53:1			0		1.0
55:1			54:1			0		1.0
56:1			55:1			0		1.0
57:1			56:1			0		1.0
58:1			57:1			0		1.0

Alignment 3389
Recently , with advances in machine learning research , Neural Network [5] ,[6] , Support Vector Machines ( SVM ) [7] ,[8] ,[9] and AdaBoost [1] ,[10] ,[11] ,[12] ,[13] are typical choices for building robust face detectors .
Recently , with advances in machine learning research , neural networks [5] , [6] , support vector machines ( SVM ) [7] , [8] , [9] and AdaBoost [1] , [10] , [11] , [12] , [13] are typical choices for building robust face detectors .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
11:1			11:1			0		1.0
12:1			13:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
26:1			23:1			0		1.0
27:1			24:1			0		1.0
28:1			25:1			0		1.0
37:1			30:1			0		1.0
38:1			31:1			0		1.0
39:1			32:1			0		1.0
40:1			33:1			0		1.0
41:1			34:1			0		1.0
42:1			35:1			0		1.0
43:1			36:1			0		1.0
44:1			37:1			0		1.0
45:1			38:1			0		1.0

Alignment 3390
Current research is focusing on feature extractions and appropriate structures for combining classifiers .
Current research is focusing on feature extractions and appropriate structures for combining classifiers .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 3391
Generally , to classify an input pattern of intensities as a face or non-face , features must be extracted and normalized before passing to a classifier [14] .
Generally , to classify an input pattern of intensities as a face or non-face , features must be extracted and normalized before passing [the image / the pattern / the results?] to a classifier [14] .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
31:1			23:1			0		1.0
32:1			24:1			0		1.0
33:1			25:1			0		1.0
34:1			26:1			0		1.0
35:1			27:1			0		1.0

Alignment 3392
There are many kinds of features that have been used ranging from simple features such as intensity values [7] ,[5] and eigenspace [15] to complex features such as wavelets [16] ,[1] ,[12] , edge orientation histograms [17] ,[18] and Bayesian discriminating features ( BDF ) [19] .
Many kinds of features have been used , ranging from simple ones such as intensity values [7] , [5] and eigenspace [15] to complex ones such as wavelets [16] , [1] , [12] , edge orientation histograms [17] , [18] , and Bayesian discriminating features ( BDF ) [19] .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			3:1			0		1.0
2:1			4:1			0		1.0
3:1			5:1			0		1.0
4:1			7:1			0		1.0
5:1			8:1			0		1.0
6:1			9:1			0		1.0
7:1			32:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
37:1			36:1			0		1.0
41:1			38:1			0		1.0
42:1			39:1			0		1.0
43:1			40:1			0		1.0
44:1			41:1			0		1.0
45:1			42:1			0		1.0
46:1			43:1			0		1.0
47:1			44:1			0		1.0
48:1			45:1			0		1.0
49:1			46:1			0		1.0

Alignment 3393
Discriminative and informative features usually increase detection rate and reduce complexity of the training procedure [17] .
Discriminative and informative features usually increase detection rates and reduce the complexity of training procedures [17] .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:2			7:2			3		1.0
9:1			9:1			0		1.0
10:1			12:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			1		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 3394
In a typical face detector which is scale-free and location-free , the number of analyzed patterns is usually very large ( 160 ,000 patterns for a 320x240 pixel image ) because the face classifier has to scan over the input image at every location and every scale .
In a typical face detector that is scale- and location-free , the number of analyzed patterns is usually very large ( 160 ,000 patterns for a 320x240 pixel image ) because the face classifier has to scan over the input image at every location and every scale .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:2			5:2			3		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0

Alignment 3395
However , the huge majority of the analyzed patterns are non-face .
However , the vast majority of the analyzed patterns are non-face .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			2		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 3396
Statistics from [9] have shown that the ratio of non-face to face patterns is about 50 ,000 to 1 .
Statistics from [9] have shown that the ratio of non-face to face patterns is about 50 ,000 to 1 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 3397
Face detectors based on single classifiers such as SVM [7] ,[8] ,[9] and Neural Network [6] ,[5] are usually slow because they process non-face regions and face regions in the input image equally .
Face detectors based on single classifiers such as SVM [7] , [8] , [9] and neural networks [6] , [5] are usually slow because they equally process non-face and face regions in the input image .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
14:1			12:1			0		1.0
17:1			15:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0
25:1			32:1			0		1.0
26:1			22:1			0		1.0
27:1			23:1			0		1.0
28:1			25:1			0		1.0
29:1			26:1			0		1.0
30:1			27:1			0		1.0
31:1			28:1			0		1.0
32:1			29:1			0		1.0
33:1			30:1			0		1.0
34:1			31:1			0		1.0
35:1			33:1			0		1.0

Alignment 3398
To deal with the problem of processing a large number of patterns , a combination of simple-to-complex classifiers is proposed [8] ,[1] ,[9] ,[20] ,[21] ,[11] .
To deal with the problem of processing a large number of patterns , a combination of simple-to-complex classifiers has been proposed [8] , [1] , [9] , [20] , [21] , [11] .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:2			18:1			3		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
32:1			26:1			0		1.0

Alignment 3399
In particular , fast and simple classifiers are used as filters at the earliest stages to quickly reject a large number of non-face patterns and a slower yet more accurate classifier is then used for classifying face-like patterns .
In particular , fast and simple classifiers are [recommended to be?] used as filters at the earliest stages to quickly reject a large number of non-face patterns and a slower yet more accurate classifier is then recommended to be used for classifying face-like patterns .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0
26:1			23:1			0		1.0
27:1			24:1			0		1.0
28:1			25:1			0		1.0
29:1			26:1			0		1.0
30:1			27:1			0		1.0
31:1			28:1			0		1.0
32:1			29:1			0		1.0
33:1			30:1			0		1.0
34:1			31:1			0		1.0
35:1			32:1			0		1.0
39:1			33:1			0		1.0
40:1			34:1			0		1.0
41:1			35:1			0		1.0
42:1			36:1			0		1.0
43:1			37:1			0		1.0
44:1			38:1			0		1.0

Alignment 3400
By this way , the complexity of classifiers is adapted corresponding to the difficulty in the input patterns .
In this way , the complexity of classifiers can be adapted corresponding to the difficulty in the input patterns . / / [is / can be?]
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:2			8:1			3		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0

Alignment 3401
In [8] , non linear SVM classifiers using pixel-based features are arranged into a sequence with increasing number of support vectors , or in [9] , linear SVM classifiers trained at different resolutions are used for rejection and a reduced set of principle component analysis ( PCA )-based features are used with the non linear SVM at the classification stage in order to reduce computation time .
In [8] , nonlinear SVM classifiers using pixel-based features were arranged into a sequence by increasing the number of support vectors , while in [9] , linear SVM classifiers trained at different resolutions were used for rejection and a reduced set of principle component analysis ( PCA )-based features were used with the nonlinear SVM at the classification stage in order to reduce computation time .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			2		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
15:1			16:1			0		1.0
16:1			57:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:2			33:2			3		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0
49:2			49:2			3		1.0
51:1			51:1			0		1.0
52:1			52:1			0		1.0
54:1			55:1			0		1.0
55:1			56:1			0		1.0
57:1			58:1			0		1.0
58:1			59:1			0		1.0
59:1			60:1			0		1.0
60:1			61:1			0		1.0
61:1			62:1			0		1.0
62:1			63:1			0		1.0
63:1			64:1			0		1.0
64:1			65:1			0		1.0
65:1			66:1			0		1.0

Alignment 3402
In [1] , AdaBoost based classifiers are arranged in a degeneration decision tree or a cascade .
In [1] , AdaBoost-based classifiers were arranged in a degeneration decision tree or a cascade .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			2		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0

Alignment 3403
Using about 10 features of the first two layers , more than 90\% of non-face patterns are rejected .
Using about 10 features of the first two layers , more than 90\% of non-face patterns were rejected .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:2			16:2			3		1.0
18:1			18:1			0		1.0

Alignment 3404
Recently , boosting chain [20] and nested cascade [11] have also been proposed for improvements .
Recently , a boosting chain [20] and a nested cascade [11] have also been proposed for improvements .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0

Alignment 3405
It is believed that the cascade structure of classifiers is the key factor in enhancement of current real-time face detectors .
It is believed that the cascade structure of classifiers is the key factor in enhancement of current real-time face detectors . / / It is believed?This sounds vague?who believes this? " May researchers believe , " for example , would be clearer and sound more believable .]
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 3406
This work is motivated by Viola and Jones [1] who proposed a framework for fast and robust face detection .
This work is motivated by Viola and Jones [1] , who proposed a framework for fast and robust face detection .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0

Alignment 3407
Their success mainly comes from three contributions :
Their success comes mainly from three contributions :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			3:1			0		1.0
3:1			2:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 3408
-Firstly , the cascaded structure of simple-to-complex classifiers reduces computation time dramatically ( as mentioned above ) .
-The cascaded structure of simple-to-complex classifiers reduces computation time dramatically .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			3:1			0		1.0
2:1			4:1			0		1.0
3:1			5:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			17:1			0		1.0

Alignment 3409
-Secondly , AdaBoost is used to select discriminative and significant features from a pool of a very large number of features and then construct the classifier .
-AdaBoost is used to select discriminative and significant features from a pool of a very large number of features and then construct the classifier .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			3:1			0		1.0
2:1			4:1			0		1.0
3:1			5:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0
24:1			26:1			0		1.0

Alignment 3410
The output classifier built from these selected features is very fast and robust in classification .
The output classifier built from these selected features is very fast and robust in classification .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 3411
Compared to SVM-based classifiers or neural network-based classifiers , AdaBoost based classifiers are hundreds of times faster .
Compared to SVM-based classifiers or neural network-based classifiers , AdaBoost-based classifiers are hundreds of times faster .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0

Alignment 3412
-Thirdly , Haar-wavelet features used for all stages are informative [22] and evaluated extremely fast due to the introduction of the integral image .
-Haar wavelet features used for all stages are informative [22] and can be evaluated extremely quickly due to the introduction of the integral image .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			3		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0

Alignment 3413
However , this framework still has the following problems :
However , this framework still has the following problems :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 3414
-First , the cascaded classifiers that use AdaBoost and Haar wavelet features are only efficient in quickly rejecting simple non-face patterns .
-First , the cascaded classifiers that use AdaBoost and Haar wavelet features are only efficient in quickly rejecting simple non-face patterns .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 3415
To robustly classify complex patterns , it is necessary to use a larger number of features and layer classifiers .
To robustly classify complex patterns , it is necessary to use a larger number of features and layer classifiers .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 3416
This need is apparent when face and non-face patterns become hard to distinguish , weak classifiers are too weak to boost [22] .
This need is apparent because when face and non-face patterns become hard to distinguish , weak classifiers are too weak to boost [22] .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0

Alignment 3417
With the first several layers in our experiment ( cf. Figure 1 ) , using some 800 weak classifiers , more than \MATH of non-face patterns are rejected .
With the first several layers in our experiment ( cf . Figure 1 ) , using some 800 weak classifiers , more than \MATH of non-face patterns were rejected .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			2		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			2		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0

Alignment 3418
However , turning the later layers into robustly classifying a smaller number of remaining patterns , it requires a lot more , e.g. , 5 ,660 , weak classifiers , thus making the training task much more complicated .
However , enabling the later layers to robustly classify a smaller number of remaining patterns requires many more weak classifiers ( around 5 ,660 ) , thus making the training task much more complicated .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			1		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			17:1			0		1.0
17:1			20:1			0		1.0
18:1			27:1			0		1.0
19:1			28:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0
25:1			29:1			0		1.0
26:1			30:1			0		1.0
27:1			31:1			0		1.0
28:1			32:1			0		1.0
29:1			33:1			0		1.0
30:1			34:1			0		1.0
31:1			35:1			0		1.0
32:1			36:1			0		1.0
33:1			37:1			0		1.0
34:1			38:1			0		1.0

Alignment 3419
-Second , the training process is complicated .
-Second , the training process is complicated .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 3420
Firstly , it requires a long training time because the training time is proportional to the number of features in the input feature set ( which is normally hundreds of thousands ) and the number of training samples ( which is generally tens of thousands ) .
It requires a long time because the training time is proportional to the number of features in the input feature set ( which is normally hundreds of thousands ) and the number of training samples ( which is generally tens of thousands ) .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			3:1			0		1.0
2:1			4:1			0		1.0
3:1			5:1			0		1.0
4:1			7:1			0		1.0
5:1			8:1			0		1.0
6:1			9:1			0		1.0
7:1			10:1			0		1.0
8:1			11:1			0		1.0
9:1			12:1			0		1.0
10:1			13:1			0		1.0
11:1			14:1			0		1.0
12:1			15:1			0		1.0
13:1			16:1			0		1.0
14:1			17:1			0		1.0
15:1			18:1			0		1.0
16:1			19:1			0		1.0
17:1			20:1			0		1.0
18:1			21:1			0		1.0
19:1			22:1			0		1.0
20:1			23:1			0		1.0
21:1			24:1			0		1.0
22:1			25:1			0		1.0
23:1			26:1			0		1.0
24:1			27:1			0		1.0
25:1			28:1			0		1.0
26:1			29:1			0		1.0
27:1			30:1			0		1.0
28:1			31:1			0		1.0
29:1			32:1			0		1.0
30:1			33:1			0		1.0
31:1			34:1			0		1.0
32:1			35:1			0		1.0
33:1			36:1			0		1.0
34:1			37:1			0		1.0
35:1			38:1			0		1.0
36:1			39:1			0		1.0
37:1			40:1			0		1.0
38:1			41:1			0		1.0
39:1			42:1			0		1.0
40:1			43:1			0		1.0
41:1			44:1			0		1.0
42:1			45:1			0		1.0
43:1			46:1			0		1.0

Alignment 3421
In our experiment , with 20 ,000 training samples and 134 ,736 features , the average training time for choosing one feature associated with the weak classifier is about 30 minutes on a PC ( Pentium 4 , 2 .8 MHz , 512-MB RAM ) .
In our experiment , with 20 ,000 training samples and 134 ,736 features , the average training time for choosing one feature associated with the weak classifier was about 30 minutes on a PC ( Pentium 4 , 2 .8 MHz , 512-MB RAM ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:2			27:2			3		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0

Alignment 3422
Therefore , training a cascade of classifiers with around 6 ,060 features [1] might take in order of several weeks .
Therefore , training a cascade of classifiers with around 6 ,060 features [1] might take on the order of several weeks .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0

Alignment 3423
Secondly , AdaBoost-based classifiers are constructed by adding features after each round of boosting , so several training parameters must be tuned manually while training .
Another thing that complicates the training process is that AdaBoost-based classifiers are constructed by adding features after each round of boosting , so several training parameters must be tuned manually while training .
Line2Start:Length	Line1Start:Length	Module		Score
9:1			2:1			0		1.0
10:1			3:1			0		1.0
11:1			4:1			0		1.0
12:1			5:1			0		1.0
13:1			6:1			0		1.0
14:1			7:1			0		1.0
15:1			8:1			0		1.0
16:1			9:1			0		1.0
17:1			10:1			0		1.0
18:1			11:1			0		1.0
19:1			12:1			0		1.0
20:1			13:1			0		1.0
21:1			14:1			0		1.0
22:1			15:1			0		1.0
23:1			16:1			0		1.0
24:1			17:1			0		1.0
25:1			18:1			0		1.0
26:1			19:1			0		1.0
27:1			20:1			0		1.0
28:1			21:1			0		1.0
29:1			22:1			0		1.0
30:1			23:1			0		1.0
31:1			24:1			0		1.0
32:1			25:1			0		1.0

Alignment 3424
In practice , for stopping training a classifier , at least the following three parameters must be determined in advance : minimum detection rate , maximum false positive rate , and maximum number of boosting rounds ( or the number of weak classifiers of each layer ) .
In practice , for stopping training a classifier , at least the following three parameters must be determined in advance : minimum detection rate , maximum false positive rate , and maximum number of boosting rounds ( or the number of weak classifiers of each layer ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0

Alignment 3425
Because the complexity of the training sets varies through layers in the cascade , it is undetermined how to choose these parameters automatically and optimally .
Because the complexity of the training sets varies throughout the layers in the cascade , a way to choose these parameters automatically and optimally has not been determined .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			3		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:3			17:2			3		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
28:1			25:1			0		1.0

Alignment 3426
For example , in the first layers , it is quite easy to train a classifier with a minimum detection rate of \MATH and a maximum false-positive rate of \MATH .
For example , in the first layers , it is quite easy to train a classifier with a minimum detection rate of \MATH and a maximum false-positive rate of \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0

Alignment 3427
However , in later layers , choosing the detection rate of \MATH will give a false positive rate greater than \MATH [22] .
However , in later layers , choosing the detection rate of \MATH will give a false positive rate greater than \MATH [22] .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 3428
Adding more features directly increases computation time and might cause over-fitting .
Adding more features directly increases computation time and might cause over-fitting .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 3429
The authors therefore propose a multi-stage approach to build a face-detection system by adopting the advantages of Viola and Jones' approach and by introducing a method to address the above problems .
The authors therefore propose a multi-stage approach to build a face-detection system by adopting the advantages of Viola and Jones' approach and by introducing a method to address the above problems .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0

Alignment 3430
Specifically , for quick rejection of non-face patterns , we reuse two key ingredients of Viola and Jones' system , that is , the cascaded structure of simple-to-complex classifiers and AdaBoost trained with Haar-wavelet features .
Specifically , for quick rejection of non-face patterns , we have reused two key ingredients of Viola and Jones' system , that is , the cascaded structure of simple-to-complex classifiers and AdaBoost trained with Haar wavelet features .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			10:1			1		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
36:1			34:1			0		1.0
37:1			35:1			0		1.0

Alignment 3431
Furthermore , for robust classification and simple training , we propose using SVM classifiers for later layers .
Furthermore , for robust classification and simple training , we propose using SVM classifiers for later layers .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 3432
The contribution of this approach is three fold :
The contribution of this approach is threefold :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			3		1.0
7:1			8:1			0		1.0

Alignment 3433
-First , to detect the face candidate regions , a new stage ( using a larger window size and a larger moving step size ) is added .
-First , to detect the face candidate regions , a new stage ( using a larger window size and a larger moving step size ) has been added .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:2			25:1			3		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0

Alignment 3434
We use 36 x 36-pixel window-based classifiers with a moving step size of 12 pixels , to quickly estimate the candidate face regions .
We use 36 x 36-pixel window-based classifiers with a moving step size of 12 pixels to quickly estimate the candidate face regions .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0

Alignment 3435
The idea of using larger windows and moving the step size was adopted in [5] , but it severely degraded performance .
The idea of using larger windows and moving the step size was adopted in [5] , but it severely degraded performance .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 3436
To improve speed while maintaining high accuracy , our approach takes advantage of the combination of the Haar wavelet features and the AdaBoost learning for fast and robust evaluation
To improve speed while maintaining high accuracy , our approach takes advantage of the combination of the Haar wavelet features and the AdaBoost learning for fast and robust evaluation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 3437
Second , how to efficiently reuse the features selected by AdaBoost in the previous stage , for the SVM classifiers of the last stage , is investigated .
Second , we have investigated how to efficiently reuse the features selected by AdaBoost in the previous stage for the SVM classifiers of the last stage .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
4:1			26:1			0		1.0
5:1			2:1			0		1.0
6:1			3:1			0		1.0
7:1			4:1			0		1.0
8:1			5:1			0		1.0
9:1			6:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			27:1			0		1.0

Alignment 3438
Reusing these features brings to two advantages : ( i ) Haar wavelet features are very fast in evaluating and normalizing [1] .
Reusing these features brings two advantages : ( i ) Haar wavelet features are very fast in being evaluated and normalized [1] .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
18:1			18:1			1		1.0
19:1			19:1			0		1.0
20:1			20:1			1		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 3439
Furthermore , it is unnecessary to re-evaluate these features because they have been previously evaluated .
Furthermore , these features do not need to be re-evaluated because they have already been evaluated .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			7:1			0		1.0
3:1			8:1			0		1.0
4:3			3:2			3		1.0
7:1			5:1			0		1.0
9:1			6:1			1		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0

Alignment 3440
( ii ) By using SVM classifiers with powerful generalization , using too many features in the cascade is avoided , therefore importantly training time is saved and over-fitting is avoided .
( ii ) By using SVM classifiers with powerful generalization , using too many features in the cascade is avoided , with the important results of saving training time and avoiding over-fitting .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
27:1			23:1			0		1.0
28:1			24:1			0		1.0
29:1			27:1			0		1.0
31:1			28:1			0		1.0
32:1			31:1			0		1.0

Alignment 3441
Third , the training time of AdaBoost classifiers is shortened by using simple sampling techniques to reduce the number of features in the feature set .
Third , the training time of AdaBoost classifiers has been shortened by using simple sampling techniques to reduce the number of features in the feature set .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:2			8:1			3		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0

Alignment 3442
Experiments will show that for rejection , using a full feature set and a sampled feature set gives the comparable performance .
Experiments showed that for rejection , the performance gained by using a sampled feature set was comparable to that of a full feature set .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			2:1			1		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			18:1			0		1.0
7:1			20:1			0		1.0
10:1			7:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
16:1			19:1			0		1.0
20:1			8:1			0		1.0
21:1			9:1			0		1.0
22:1			10:1			0		1.0
23:1			11:1			0		1.0
24:1			21:1			0		1.0

Alignment 3443
Along with using several SVM classifiers instead of many AdaBoost classifiers in later layers , the total training time is reduced significantly .
Along with using several SVM classifiers instead of many AdaBoost classifiers in later layers , the total training time has been significantly reduced .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:2			19:1			3		1.0
21:1			21:1			0		1.0
22:1			20:1			0		1.0
23:1			22:1			0		1.0

Alignment 3444
There have been several studies working on how to handle the drawbacks of Viola and Jones' system .
Several studies have worked on addressing the drawbacks of Viola and Jones' system .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			4:1			0		1.0
2:1			1:1			0		1.0
3:1			5:1			1		1.0
4:1			6:1			0		1.0
5:1			9:1			2		1.0
6:1			10:1			0		1.0
7:1			11:1			0		1.0
8:1			12:1			0		1.0
9:1			13:1			0		1.0
10:1			14:1			0		1.0
11:1			15:1			0		1.0
12:1			16:1			0		1.0
13:1			17:1			0		1.0

Alignment 3445
Wu et al. [23] used direct feature selection to reduce training time while maintaining comparable performance .
Wu et al. [23] used direct feature selection to reduce training time while maintaining comparable performance .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 3446
Their idea is to separate the training process into two stages : feature selection and classifier construction .
Their idea is to separate the training process into two stages : feature selection and classifier construction .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 3447
In Viola and Jones' work , features are selected by the discriminative performance of their associated weak classifiers through the boosting process .
In Viola and Jones' work , features are selected by the discriminative performance of their associated weak classifiers through the boosting process .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 3448
It is therefore very time consuming because all weak classifiers must be trained every time one feature is selected .
This process is very time consuming because all weak classifiers must be trained every time one feature is selected .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 3449
With their new proposal , weak classifiers are trained only once and features are selected by the direct feature selection method that directly maximizes the learning objective of the output classifier .
With the new proposal of Wu et al. , weak classifiers are trained only once and features are selected by the direct feature selection method , which directly maximizes the learning objective of the output classifier .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			28:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
8:1			4:1			0		1.0
9:1			5:1			0		1.0
10:1			6:1			0		1.0
11:1			7:1			0		1.0
12:1			8:1			0		1.0
13:1			9:1			0		1.0
14:1			10:1			0		1.0
15:1			11:1			0		1.0
16:1			12:1			0		1.0
17:1			13:1			0		1.0
18:1			14:1			0		1.0
19:1			15:1			0		1.0
20:1			16:1			0		1.0
21:1			17:1			0		1.0
22:1			18:1			0		1.0
23:1			19:1			0		1.0
24:1			20:1			0		1.0
26:2			21:2			3		1.0
28:1			23:1			0		1.0
29:1			24:1			0		1.0
30:1			25:1			0		1.0
31:1			26:1			0		1.0
32:1			27:1			0		1.0
34:1			29:1			0		1.0
35:1			30:1			0		1.0
36:1			31:1			0		1.0

Alignment 3450
They claim that their method is 100 times faster than Viola and Jones' method .
They claim that their method is 100 times faster than Viola and Jones' method .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 3451
Another direction is to optimally build the cascade to improve the overall performance of the cascade .
Another direction is to optimally build the cascade to improve its overall performance .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:2			9:2			3		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			16:1			0		1.0

Alignment 3452
Sun et al. [24] and [25] propose a scheme to optimally tune parameters in layer classifiers .
Sun et al. [24] and [25] proposed a scheme to optimally tune parameters in layer classifiers .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			1		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 3453
However , their approach is somewhat complicated and is not easy to implement .
However , their approach is somewhat complicated and is not easy to implement .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 3454
Xiao et al. [20] and Huang et al. [11] propose the boosting chain structure in which subsequent layers utilize historical information of previous layers .
Xiao et al. [20] and Huang et al. [11] proposed a boosting chain structure in which subsequent layers utilize the historical information of the previous layers .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			1		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			10:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0

Alignment 3455
This significantly reduces the number of features used in each layer .
This significantly reduces the number of features used in each layer .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 3456
Discrete AdaBoost uses a binary weak classifier that is too weak to boost in the case of the hard distinguished dataset .
Discrete AdaBoost uses a binary weak classifier that is too weak to boost in the case of a hard distinguished dataset .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 3457
Studies based on RealBoost [26] , such as [12] ,[10] ,[27] ,[11] , introduced new kinds of weak classifiers that are stronger than binary weak classifiers .
Studies based on RealBoost [26] , such as [12] , [10] , [27] , and [11] , introduced new kinds of weak classifiers that are stronger than binary weak classifiers .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
16:1			12:1			0		1.0
17:1			13:1			0		1.0
18:1			14:1			0		1.0
19:1			15:1			0		1.0
20:1			16:1			0		1.0
21:1			17:1			0		1.0
22:1			18:1			0		1.0
23:1			19:1			0		1.0
24:1			20:1			0		1.0
25:1			21:1			0		1.0
26:1			22:1			0		1.0
27:1			23:1			0		1.0
28:1			24:1			0		1.0
29:1			25:1			0		1.0
30:1			26:1			0		1.0

Alignment 3458
New real-valued weak classifiers can effectively discriminate face and non-face distributions and , in consequence , the total number of features used also reduces dramatically .
These new real-valued weak classifiers can effectively discriminate face and non-face distributions , so the total number of features used is also reduced dramatically .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			12:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			1		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0

Alignment 3459
Face detection systems such as [27] ,[11] only use around 800 features .
Face detection systems such as [27] and [11] only use around 800 features .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0

Alignment 3460
However , the main problem with these systems is how to choose the most appropriate number of bins .
However , the main problem with these systems is how to choose the most appropriate number of bins .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 3461
Small number of bins might not well approximate the real distribution while large number of bins might cause over-fitting , increase computation time and waste storage space .
A small number of bins might not accurately approximate the real distribution , while a large number of bins might cause over-fitting , increase computation time , and waste storage space .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
13:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0
27:1			23:1			0		1.0
28:1			24:1			0		1.0
29:1			25:1			0		1.0
30:1			26:1			0		1.0
31:1			27:1			0		1.0

Alignment 3462
Actually , our system can benefit from this approach when building the rejection stage and thus also reduce the training time much more .
However , our system can benefit from this approach when building the rejection stage and can thus reduce the training time even further .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
22:1			16:1			3		1.0
23:1			23:1			0		1.0

Alignment 3463
The proposed face detection system consists of three stages that classify a 24x24 pixel window as either a face or a non-face .
The proposed face detection system consists of three stages that classify a 24x24-pixel window as either a face or a non-face .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0

Alignment 3464
To detect faces of different sizes and locations , the detector is applied at every location and scale in the input image with a scale factor of 1 .2 , which is similar to the other approaches [5] ,[6] ,[9] .
To detect faces of different sizes and locations , the detector is applied at every location and scale in the input image with a scale factor of 1 .2 , which is similar to other approaches [5] , [6] , [9] .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			35:1			0		1.0
35:1			36:1			0		1.0
36:1			37:1			0		1.0
41:1			40:1			0		1.0

Alignment 3465
An outline of this system is given in Figure 2 .
An outline of this system is given in Figure 2 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 3466
The first stage is a cascade of classifiers used to estimate face candidate regions by evaluating 36x36 input windows , with a moving step of 12 pixels .
The first stage is a cascade of classifiers used to estimate face candidate regions by evaluating 36x36 input windows , with a moving step of 12 pixels .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0

Alignment 3467
If a 36x36 window is detected as the existence of a face , 144 ( i.e. 12x12 ) likely face positions are collected and passed to the next stage .
If a 36x36-pixel window is detected as the existence of a face , 144 ( i.e. , 12x12 ) likely face positions are collected and passed to the next stage .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0

Alignment 3468
The second stage is a cascade of classifiers used to investigate 24x24 window face candidate locations returned from the previous stage .
The second stage is a cascade of classifiers used to investigate 24x24 window face candidate locations returned from the previous stage .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 3469
The main purpose of designing these two stages is trying to filter out a large number of non-face patterns as quick as possible before passing complex patterns to the final stage classifier .
The main purpose of designing these two stages is trying to filter out a large number of non-face patterns as quickly as possible before passing complex patterns to the final stage classifier .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			1		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0

Alignment 3470
This is done by taking advantages of Viola and Jones' approach [1] , in which Haar wavelet features and the cascaded AdaBoost classifiers are extremely fast in computation .
This is done by taking advantage of Viola and Jones' approach [1] , in which Haar wavelet features and the cascaded AdaBoost classifiers enable extremely fast computation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:2			5:2			3		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0

Alignment 3471
Although the cascade of \MATH AdaBoost classifiers rejects non-face patterns rapidly , it is still influenced by the large number of \MATH patterns that it must process .
Although the cascade of \MATH AdaBoost classifiers rejects non-face patterns rapidly , it is still influenced by the large number of \MATH patterns that it must process .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0

Alignment 3472
The reason why the fist stage , which is a cascade of \MATH classifiers , is added is to decrease the number of analyzed patterns .
For this reason , the first stage , which is a cascade of \MATH classifiers , is added is to decrease the number of analyzed patterns .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
4:1			3:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0

Alignment 3473
To this end , this stage is trained specially to make the classifiers invariant to small face translations .
To this end , this stage is trained specially to make the classifiers invariant to small face translations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 3474
These classifiers can detect faces that are off-center by up to six pixels in any direction .
These classifiers can detect faces that are off-center by up to six pixels in any direction .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 3475
An illustration of the difference between 24x24 and \MATH face training samples is depicted in Figure 3 .
An illustration of the difference between 24x24 and \MATH face training samples is depicted in Figure 3 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 3476
The \MATH window is chosen in accordance with the idea from [5] stated that the classifier can be trained to be invariant to translation by up to \MATH of original window size .
The \MATH window is chosen in accordance with the idea in [5] that the classifier can be trained to be invariant to translation by up to \MATH of the original window size .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:2			9:2			3		1.0
11:1			11:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0

Alignment 3477
With this flexible classifier , the moving step size can be increased up to 12 pixels that reduce dramatically number of analyzed patterns .
With this flexible classifier , the moving step size can be increased up to 12 pixels to dramatically reduce the number of analyzed patterns .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
17:1			18:1			0		1.0
18:1			17:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0

Alignment 3478
Efficiency of this stage will be discussed further in section 6 .3 .
The efficiency of this stage will be discussed further in section 6 .3 .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0

Alignment 3479
The last stage is a cascade of non-linear SVM classifiers that reuses features that have been selected by AdaBoost in the second stage classifier .
The last stage is a cascade of nonlinear SVM classifiers that reuses features that have been selected by AdaBoost in the second stage classifier .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 3480
These feature values are evaluated and scaled to be between 0 and 1 to form a feature vector .
These feature values are evaluated and scaled to be between 0 and 1 to form a feature vector .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 3481
In our experiments , only 100 features are used and hence it is faster than using any pixel-based SVM classifiers [8] ,[9] .
In our experiments , only 100 features were used , making classification faster than it would have been using pixel-based SVM classifiers [8] , [9] .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			8:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			11:1			0		1.0
16:2			7:1			3		1.0
18:1			15:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
25:1			22:1			0		1.0

Alignment 3482
The same feature set as proposed in [1] is used ( cf. Figure 4 ) .
The same feature set proposed in [1] was used ( cf . Figure 4 ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			2		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			2		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 3483
It consists of four kinds of features modeled from adjacent basic rectangles with the same size and shape .
It consists of four kinds of features modeled from adjacent basic rectangles of the same size and shape .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 3484
The feature value is defined as the difference of sum of the pixels within rectangles .
The feature value is defined as the difference of the sum of the pixels within rectangles .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0

Alignment 3485
Each feature is parameterized by four parameters : the position within the window \MATH , width \MATH and height \MATH ( cf. Figure 5 ) .
Each feature is parameterized by four parameters : the position within the window \MATH , the width \MATH , and the height \MATH ( cf . Figure 5 ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
19:1			17:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			2		1.0
26:1			22:1			0		1.0
27:1			23:1			0		1.0
28:1			24:1			0		1.0
29:1			25:1			0		1.0

Alignment 3486
By using integral image definition [1] , these rectangle feature values can be computed extremely quickly .
By using integral image definition [1] , the feature values of these rectangles can be computed extremely quickly .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
11:1			7:1			0		1.0
12:1			8:1			1		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0

Alignment 3487
The integral image at location \MATH is defined as \MATH , where \MATH is the integral image and \MATH is the original image .
The integral image at location \MATH is defined as \MATH , where \MATH is the integral image and \MATH is the original image .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 3488
In practice , \MATH can be computed simply by using the following recurrent function :\MATH , and sum of the pixels within a rectangle can be computed from four integral image values of its vertices , for example , \MATH .
In practice , \MATH can be computed simply by using the following recurrent function :\MATH , and sum of the pixels within a rectangle can be computed from four integral image values of its vertices , for example , \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0

Alignment 3489
Boosting is used to improve the classification performance of any given simple learning algorithm [28] .
Boosting is used to improve the classification performance of any given simple learning algorithm [28] .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 3490
Given \MATH weak classifiers \MATH learned through \MATH rounds of boosting , the strong classifier is formed by a linear combination : \MATH where \MATH are coefficients found in the boosting process .
Given \MATH weak classifiers \MATH learned through \MATH rounds of boosting , the strong classifier is formed by a linear combination : \MATH , where \MATH are coefficients found in the boosting process .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0

Alignment 3491
Each weak classifier \MATH is associated with a feature \MATH and a threshold \MATH such that the number of incorrect classified examples corresponding to this weak classifier is minimized : \MATH , where polarity \MATH indicates the direction of the inequality sign .
Each weak classifier \MATH is associated with a feature \MATH and a threshold \MATH such that the number of incorrectly classified examples corresponding to the weak classifier is minimized : \MATH , where polarity \MATH indicates the direction of the inequality sign .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			1		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			39:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0

Alignment 3492
In each round of boosting , the best weak classifier \MATH that has the lowest error \MATH will be chosen .
In each round of boosting , the best weak classifier \MATH that has the lowest error \MATH will be chosen .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 3493
The error of each weak classifier is measured with respect to the set of weights over each example of the training set \MATH , where \MATH and \MATH are the weight and the label of the training example \MATH , respectively .
The error of each weak classifier is measured with respect to the set of weights over each example of the training set \MATH , where \MATH and \MATH are the respective weight and label of the training example \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			41:1			0		1.0

Alignment 3494
After each round , these weights are updated such that the weak learner will focus much more on the hard examples in the next round .
After each round , these weights are updated such that the weak learner will focus much more on the hard examples in the next round .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 3495
The main idea of building a cascade of classifiers is to reduce the computation time by giving different treatments to different complexities of input windows ( cf .
The main idea of building a cascade of classifiers is to reduce the computation time by giving different treatments to different complexities of input windows ( cf .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0

Alignment 3496
Figure 7 ) .
Figure 7 ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0

Alignment 3497
Only input windows that have passed through all layers of the cascade are classified as faces .
Only input windows that have passed through all layers of the cascade are classified as faces .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 3498
Training cascaded classifiers that can achieve both good detection rate and less computation time is quite complex , because a higher detection rate requires more features , but more features are correspondent to more time for evaluation .
Training cascaded classifiers that can achieve both good detection rates and less computation time is quite complex ; a higher detection rate requires more features , but more features correspond to more time needed for evaluation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			1		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			31:1			1		1.0
30:1			32:1			0		1.0
31:1			33:1			0		1.0
32:1			34:1			0		1.0
34:1			35:1			0		1.0
35:1			36:1			0		1.0
36:1			37:1			0		1.0

Alignment 3499
To simplify this , the detection rate goal and the false positive rate goal for each layer are usually set beforehand .
To simplify this , the detection rate goal and the false positive rate goal for each layer are usually set beforehand .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 3500
Viola and Jones [1] stated that , if the layer classifier could achieve the predefined target goals after 200 features are used , the training process will stop and a new layer will be added .
Viola and Jones [1] stated that , if the layer classifier has achieved the predefined target goals after 200 features are used , the training process will stop and a new layer will be added .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			12:1			1		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0

Alignment 3501
1 . <section label= " SVM Classifier " >
1 . <section label= " SVM Classifier " >
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 3502
The support vector machine is a statistical learning method based on the structure-risk minimization principle .
The support vector machine is a statistical learning method based on the structure-risk minimization principle .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 3503
It has been very efficiently proved in many pattern recognition applications [29] ,[8] ,[9] .
It has been very efficiently proven in many pattern recognition applications [29] , [8] , [9] .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			2		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
16:1			14:1			0		1.0

Alignment 3504
In the binary classification case , the objective of the SVM is to find the best separating hyperplane with a maximum margin .
In the binary classification case , the objective of the SVM is to find the best separating hyperplane with a maximum margin .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 3505
The form of SVM classifiers is : \MATH where : \MATH is the d-dimensional vector of an observation example , \MATH is a class label , and \MATH is the vector of the \MATH training example .
The form of SVM classifiers is : \MATH where \MATH is the d-dimensional vector of an observation example , \MATH is a class label , and \MATH is the vector of the \MATH training example .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0
31:1			32:1			0		1.0
32:1			33:1			0		1.0
33:1			34:1			0		1.0
34:1			35:1			0		1.0
35:1			36:1			0		1.0

Alignment 3506
All the \MATH corresponding to non-zero \MATH are called support vectors .
All the \MATH corresponding to non-zero \MATH are called support vectors .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 3507
It is important to choose the appropriate kernel and parameter \MATH in order to to obtain the robust SVM classifier .
It is important to choose the appropriate kernel and parameter \MATH in order to obtain the robust SVM classifier .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0

Alignment 3508
Although many kernels have been introduced by researchers , the following four kernels are commonly used : \MATH where \MATH and \MATH are kernel parameters .
Although many kernels have been introduced by researchers , the following four kernels are commonly used : \MATH where \MATH , and \MATH are kernel parameters .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0

Alignment 3509
Compared to AdaBoost classifiers , SVM classifiers run much slower in running because of the large number of support vectors and heavy kernel computation .
Compared to AdaBoost classifiers , SVM classifiers run much more slowly because of the large number of support vectors and the heavy kernel computation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:2			9:1			3		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 3510
To control the trade-off between the number of support vectors and errors , Scholkopf et al. [30] proposed using a new parameter \MATH instead of the parameter \MATH .
To control the trade-off between the number of support vectors and errors , Scholkopf et al. [30] proposed using a new parameter \MATH instead of the parameter \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 3511
They proved that the parameter \MATH is an upper bound of the fraction of margin errors and a lower bound of the fraction of support vectors .
They proved that the parameter \MATH is an upper bound of the fraction of margin errors and a lower bound of the fraction of support vectors .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 3512
The implementations of \MATH and \MATH are provided by LibSVM [31] .
The implementations of \MATH and \MATH are provided by LibSVM [31] .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 3513
For training , we collected 7 ,500 , 24x24-size face patterns from the Internet .
For training , we collected 7 ,500 , 24x24-size face patterns from the Internet . / / size / pixel?
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 3514
Non-face patterns were generated at different locations and scales from 8 ,440 images with various subjects , such as rocks , trees , buildings , scenery , and flowers , containing no faces .
Non-face patterns were generated at different locations and scales from 8 ,440 images with various subjects , such as rocks , trees , buildings , scenery , and flowers , containing no faces .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0

Alignment 3515
Some examples of the collected 24x24 face patterns are shown in Figure 8 .
Some examples of the collected 24x24 face patterns are shown in Figure 8 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 3516
Face patterns for training the 36x36 classifiers are generated by selecting 36x36 windows containing the 24x24 face window of the input image .
Face patterns for training the 36x36 classifiers were generated by selecting 36x36 windows containing the 24x24 face window of the input image .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:2			7:2			3		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 3517
Figure 9 shows some examples of 36x36 face patterns that include various kinds of floating positions and backgrounds .
Figure 9 shows some examples of 36x36 face patterns that include various kinds of floating positions and backgrounds .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 3518
To train the cascade of 24x24 AdaBoost classifiers used in the rejection stage , the same 7 ,500 face patterns are used for all layers .
To train the cascade of 24x24 AdaBoost classifiers used in the rejection stage , the same 7 ,500 face patterns were used for all layers .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:2			20:2			3		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 3519
Non-face patterns of the training and the validating sets of the first layer in the cascade are selected randomly .
Non-face patterns of the training and the validating sets of the first layer in the cascade were selected randomly .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:2			16:2			3		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 3520
Non-face patterns of the subsequent layer classifiers are false positives collected by the partially trained cascade on the set of non-face images .
Non-face patterns of the subsequent layer classifiers are false positives collected by the partially trained cascade on the set of non-face images .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 3521
For each layer classifier , 7 ,500 non-face patterns are used for training and 7 ,500 other non-face patterns are used for validating .
For each layer classifier , 7 ,500 non-face patterns were used for training and 7 ,500 other non-face patterns were used for validating .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:2			9:2			3		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:2			19:2			3		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 3522
To compare the performance of classifiers , we have implemented a fully cascade of classifiers trained by AdaBoost , similar to that used by Viola and Jones [1] .
To compare the performance of classifiers , we implemented a full cascade of classifiers trained by AdaBoost , similar to that used by Viola and Jones [1] .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			2		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0

Alignment 3523
The training parameters of each layer were set as follows .
The training parameters of each layer were set as follows .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 3524
The minimum of the detection rate is \MATH , the maximum of the false positive rate is \MATH and the maximum of the number of features in each layer is 200 .
The minimum of the detection rate was \MATH , the maximum of the false positive rate was \MATH , and the maximum of the number of features in each layer was 200 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			15:2			3		1.0
7:1			17:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:2			6:1			3		1.0
17:1			7:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			2		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0

Alignment 3525
This setting resulted in a face detector that consists of 38 layers with 6 ,360 features .
This setting resulted in a face detector that consists of 38 layers with 6 ,360 features .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 3526
All experiments were run on a PC ( Pentium 4 , 2 .8 MHz , 512-MB RAM ) .
All experiments were run on a PC ( Pentium 4 , 2 .8 MHz , 512-MB RAM ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 3527
The training process was terminated when no more false positives were found in the non-face images of the data set .
The training process was terminated when no more false positives were found in the non-face images of the data set .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 3528
If \MATH is the number of Haar wavelet features and \MATH is the number of training patterns , the learning time of AdaBoost to train \MATH weak classifiers is roughly[1] .
If \MATH is the number of Haar wavelet features and \MATH is the number of training patterns , the learning time of AdaBoost to train \MATH weak classifiers is roughly [1] .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
31:1			30:1			0		1.0

Alignment 3529
Therefore , if the number of training patterns is fixed , the learning time can be shortened when either the number of features in the feature set or the number of weak classifiers in the final cascade is reduced .
Therefore , if the number of training patterns is fixed , the learning time can be shortened when either the number of features in the feature set or the number of weak classifiers in the final cascade is reduced .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0

Alignment 3530
In our approach , the cascaded classifiers are only used for efficient rejection , so we can reduce both these numbers in order to keep training time for the full system reasonable .
In our approach , the cascaded classifiers are only used for efficient rejection , so we can reduce both of these numbers in order to keep the training time for the full system reasonable .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
33:1			31:1			0		1.0
34:1			32:1			0		1.0

Alignment 3531
As mentioned in section 4 .1 , each feature is parameterized by a tuple of four parameters \MATH .
As mentioned in section 4 .1 , each feature is parameterized by a tuple of four parameters \MATH . / / If this ( and other places ) do not display with spaces after the commas , spaces must be insert . A comma should always be followed by a space . I recommend checking this carefully throughout .]
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 3532
A set of features is then formed by changing these parameters in correspondent steps \MATH .
A set of features is then formed by changing these parameters in corresponding steps \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			1		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 3533
In the other hand , a feature set is parameterized by \MATH .
A feature set , on the other hand , is parameterized by \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			6:1			0		1.0
2:1			7:1			0		1.0
5:1			1:1			0		1.0
6:1			2:1			0		1.0
7:1			3:1			0		1.0
8:1			4:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0

Alignment 3534
One of the simplest ways to sub-sample the feature set is to change parameters \MATH , for example , from a full feature set \MATH to a reduced feature set \MATH .
One of the simplest ways to sub-sample the feature set is to change parameters \MATH , for example , from a full feature set \MATH to a reduced feature set \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0

Alignment 3535
Because the full feature set is redundant , this sub-sampling is expected not to affect the rejection performance of AdaBoost classifiers significantly .
Because the full feature set is redundant , this sub-sampling is expected not to significantly affect the rejection performance of AdaBoost classifiers .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			21:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			22:1			0		1.0

Alignment 3536
We carried out experiments to compare the performance of classifiers trained on these two feature sets : the full feature set \MATH containing 134 ,736 features and the reduced feature set \MATH containing 14 ,807 features ( excluding features with the small size ) .
We carried out experiments to compare the performance of classifiers trained on these two feature sets : the full feature set \MATH , containing 134 ,736 features and the reduced feature set \MATH , containing 14 ,807 features ( excluding features of small size ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
34:1			32:1			0		1.0
35:1			33:1			0		1.0
36:1			34:1			0		1.0
37:1			35:1			0		1.0
38:1			36:1			0		1.0
39:1			37:1			0		1.0
40:1			38:1			0		1.0
41:2			40:2			3		1.0
43:1			42:1			0		1.0
44:1			43:1			0		1.0
45:1			44:1			0		1.0

Alignment 3537
Two classifiers are trained up to the maximum of 200 features .
Two classifiers were trained up to the maximum of 200 features .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:2			2:2			3		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 3538
The classifier 's threshold is changed to meet the detection rate of \MATH .
The classifier 's threshold was changed to meet the detection rate of \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			2		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 3539
The training set contains 7 ,500 face patterns and 7 ,500 non-face patterns .
The training set contains 7 ,500 face patterns and 7 ,500 non-face patterns .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 3540
Rejection performance is evaluated through the false positive rate on a validation test set which contains 500 ,000 non-face patterns .
Rejection performance was evaluated through the false positive rate on a validation test set that contains 500 ,000 non-face patterns .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			2		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:2			14:2			3		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 3541
All non-face patterns are selected randomly from the training set mentioned above .
All non-face patterns were selected randomly from the training set mentioned above .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:2			3:2			3		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 3542
The result shown in Figure 10 indicates that the performances of these two classifiers are no different , especially when the number of features is large enough , for example , more than 50 .
The results shown in Figure 10 indicate that the performances of these two classifiers were no different , especially when the number of features was large enough , for example , more than 50 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			1		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:2			6:2			3		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:2			14:2			3		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			2		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0

Alignment 3543
As a result , by using the reduced feature set , the training time can be shortened approximately to one ninth .
As a result , by using the reduced feature set , the training time can be shortened to approximately one-ninth .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			18:1			0		1.0
18:1			17:1			0		1.0
19:1			20:1			2		1.0
20:1			21:1			0		1.0

Alignment 3544
Our another experiment has shown that , for similar performance , the AdaBoost classifier trained on the reduced feature set that uses larger sampling step sizes requires more features than that trained on the full feature set .
Another experiment we conducted showed that , for similar performance , an AdaBoost classifier trained on the reduced feature set that uses larger sampling step sizes requires more features than one trained on the full feature set . / / [Do you need a reference here , or is this still talking about the experiments you report in this paper?]
Line2Start:Length	Line1Start:Length	Module		Score
1:1			2:1			0		1.0
4:1			3:2			3		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
53:1			11:1			0		1.0

Alignment 3545
Therefore , only the sampling parameter \MATH was used in training the 24x24 AdaBoost classifiers .
Therefore , only the sampling parameter \MATH was used in training the 24x24 AdaBoost classifiers .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 3546
In our system , the first stage is a cascade of classifiers that processes 36x36 patterns with a moving step size of 12 pixels .
In our system , the first stage is a cascade of classifiers that processes 36x36 patterns with a moving step size of 12 pixels .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 3547
By taking advantage of simplification in training classifiers only for rejection demonstrated in section 6 .2 , training this cascade only uses the feature set generated from a 36x36 window with sampling parameters \MATH .
By taking advantage of simplification in training classifiers only for rejection , as demonstrated in section 6 .2 , training this cascade only uses the feature set generated from a 36x36 window with sampling parameters \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
33:1			31:1			0		1.0
34:1			32:1			0		1.0
35:1			33:1			0		1.0
36:1			34:1			0		1.0

Alignment 3548
As a result , 12 ,223 features are produced .
As a result , 12 ,223 features are produced .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 3549
The training set contains 12 ,000 face patterns and 12 ,000 non-face patterns .
The training set contains 12 ,000 face patterns and 12 ,000 non-face patterns .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 3550
Since a 36x36 face sample contains a lot of background outside the 24x24 face region while the classifier is required to be fast and to keep all possible face regions , training parameters are set as follows : the minimum detection rate of \MATH and maximum of false positive rate of \MATH .
Since a 36x36 face sample contains a large proportion of background outside the 24x24 face region and the classifier is required to be fast and to keep all possible face regions , a minimum detection rate of \MATH and a maximum of false positive rate of \MATH were set as the training parameters .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:2			7:2			3		1.0
9:1			50:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			44:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:2			38:2			3		1.0
34:1			40:1			0		1.0
35:1			41:1			0		1.0
36:1			42:1			0		1.0
37:1			43:1			0		1.0
40:1			45:1			0		1.0
41:1			46:1			0		1.0
42:1			47:1			0		1.0
43:1			48:1			0		1.0
44:1			49:1			0		1.0
46:1			51:1			0		1.0
47:1			35:2			3		1.0
48:1			34:1			0		1.0
51:1			31:1			0		1.0
52:1			32:1			0		1.0
53:1			52:1			0		1.0

Alignment 3551
In our experiments , after reaching 50 features , the classifier 's performance does not significantly increase anymore , so the maximum number of features for each layer is set to 50 .
In our experiments , after reaching 50 features , the classifier 's performance did not significantly increase , so the maximum number of features for each layer is set to 50 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0
31:1			32:1			0		1.0

Alignment 3552
To keep a balance between computation speed and robustness , the maximum number of layers is set to three because using more layers would degrade the overall detection rate dramatically .
To keep a balance between computation speed and robustness , the maximum number of layers is set to three because using more layers would degrade the overall detection rate dramatically .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0

Alignment 3553
Figure 11( a ) shows several features of the first 36x36 layer classifier selected by AdaBoost .
Figure 11( a ) shows several features of the first 36x36 layer classifier selected by AdaBoost .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 3554
It is somehow similar to features of the first 24x24 layer classifier as shown in Figure 11( b ) .
They are somehow similar to the features of the first 24x24 layer classifier as shown in Figure 11( b ) . / / [somehow?This sounds vague . How are they similar?]
Line2Start:Length	Line1Start:Length	Module		Score
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
28:2			1:1			3		1.0

Alignment 3555
In addition , Figure 12 shows an example of face candidate regions estimated by using this cascade .
In addition , Figure 12 shows an example of face candidate regions estimated by using this cascade .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 3556
Two main issues surrounding the reuse of features selected by AdaBoost are : ( i ) which layer whose features will be reused for SVM is the best? and ( ii ) How many features should be used?
Two main issues surrounding the reuse of features selected by AdaBoost are : ( i ) which layer�fs features should be reused for SVM and ( ii ) how many features should be used .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
18:1			19:1			0		1.0
19:1			35:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			28:1			0		1.0
25:1			29:1			0		1.0
26:1			30:1			0		1.0
27:1			31:1			0		1.0
29:1			33:1			0		1.0
30:1			34:1			0		1.0
32:1			36:1			0		1.0

Alignment 3557
For comparison of the performance of SVM classifiers , 2 ,450 face patterns and 7 ,500 non-face patterns which are separated from the training set ( section 6 .1 ) were used .
For comparison of the performance of SVM classifiers , 2 ,450 face patterns and 7 ,500 non-face patterns that were separated from the training set ( section 6 .1 ) were used .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:2			18:2			3		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0

Alignment 3558
The SVM classifiers were trained with a RBF kernel whose parameter \MATH is \MATH .
The SVM classifiers were trained with a RBF kernel whose parameter \MATH is \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 3559
The parameter \MATH is set to \MATH .
The parameter \MATH was set to \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			2		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 3560
These parameters were found by using cross-validation test .
These parameters were found by using a cross-validation test .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0

Alignment 3561
Figure 13 compares the performance of classifiers trained on 200-feature sets selected by different layers in the cascade ( layers 14 , 17 , 20 , and 25 ) .
Figure 13 compares the performance of classifiers trained on 200-feature sets selected by different layers in the cascade ( layers 14 , 17 , 20 , and 25 ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0

Alignment 3562
These comparable performances suggest that the second stage ( using AdaBoost ) can be switched to the final stage ( using SVM ) at any time .
These comparable performances suggest that the second stage ( using AdaBoost ) can be switched to the final stage ( using SVM ) at any time .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 3563
As a result , total training time of the system can be easily controlled .
As a result , the total training time of the system can easily be controlled .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			12:1			0		1.0
13:1			11:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0

Alignment 3564
To determine how many features is robust enough , we used the 200-feature set selected in layer 17 to generate different subsets of features with different number of features .
To determine the number of features is that would be sufficiently robust , we used the 200-feature set selected in layer 17 to generate different subsets of features with different numbers of features .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:2			2:2			3		1.0
4:1			27:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
10:1			7:1			3		1.0
11:1			6:1			0		1.0
12:1			8:1			0		1.0
13:1			9:1			0		1.0
14:1			10:1			0		1.0
15:1			11:1			0		1.0
16:1			12:1			0		1.0
17:1			13:1			0		1.0
18:1			14:1			0		1.0
19:1			15:1			0		1.0
20:1			16:1			0		1.0
21:1			17:1			0		1.0
22:1			18:1			0		1.0
23:1			19:1			0		1.0
24:1			20:1			0		1.0
25:1			21:1			0		1.0
26:1			22:1			0		1.0
27:1			23:1			0		1.0
28:1			24:1			0		1.0
29:1			25:1			0		1.0
30:2			26:1			3		1.0
32:1			28:1			0		1.0
33:1			29:1			0		1.0

Alignment 3565
Features in each set were selected in the order that they were added in the training process .
Features in each set were selected in the order in which they were added in the training process .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0

Alignment 3566
For example , a 25-feature set consists of first 25 features selected by AdaBoost when training layer 17 .
For example , a 25-feature set consists of the first 25 features selected by AdaBoost when training layer 17 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0

Alignment 3567
The results shown in Figure 14 indicate that with more than 100 features , the performance of classifiers is comparable .
The results shown in Figure 14 indicate that with more than 100 features , the performance of the classifiers was comparable . / / [to what?]
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			2		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0

Alignment 3568
Basically , the speed of a SVM classifier is proportional to the number of features used , so the greater number of features used , the slower the classifier will be .
Basically , the speed of a SVM classifier is proportional to the number of features used , so the greater the number of features used , the slower the classifier will be .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			27:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0

Alignment 3569
Figure 15 shows the processing speed of SVM classifiers that uses different subsets of features .
Figure 15 shows the processing speed of SVM classifiers using different subsets of features .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			10:1			1		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0

Alignment 3570
The SVM classifier using 25 features run fastest while the SVM classifier using 200 features run slowest .
The SVM classifier using 25 features ran the fastest , while the SVM classifier using 200 features was the slowest .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			2		1.0
7:1			9:1			0		1.0
8:1			7:1			0		1.0
10:1			8:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0

Alignment 3571
The speeds of SVM classifiers using 100 , 125 and 175 features are not importantly different because their difference in terms of number of features and number of support vectors is inconsiderable .
The speeds of SVM classifiers using 100 , 125 , and 175 features were not importantly different because their difference in terms of number of features and number of support vectors were not large enough to have a significant impact .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:2			12:2			3		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			2		1.0
40:1			32:1			0		1.0

Alignment 3572
Therefore , 100 features might be the best trade-off between the speed and the performance .
Therefore , 100 features might be the best trade-off between speed and performance .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0

Alignment 3573
We carried out an experiment to show efficiency of a single SVM classifier over a cascade of AdaBoost classifiers .
We carried out an experiment to show the efficiency of a single SVM classifier over a cascade of AdaBoost classifiers .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0

Alignment 3574
In this experiment , 40 ,000 false positives were gathered by running a cascade of 17 AdaBoost classifiers ( CAB17 ) on the set of non-face images mentioned in section 6 .1 .
In this experiment , 40 ,000 false positives were gathered by running a cascade of 17 AdaBoost classifiers ( CAB17 ) on the set of non-face images mentioned in section 6 .1 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0

Alignment 3575
These false positives then were used as hard non-face patterns to train and test the performance of two classifiers : a single RBF SVM classifier and a cascade of other 18 AdaBoost classifiers .
These false positives then were used as hard non-face patterns to train and test the performance of two classifiers : a single RBF SVM classifier and a cascade of other 18 AdaBoost classifiers .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0

Alignment 3576
Of 40 ,000 non-face patterns , 7 ,500 non-face patterns were used along with 7 ,500 face patterns to train these two classifiers .
Of 40 ,000 non-face patterns , 7 ,500 non-face patterns were used along with 7 ,500 face patterns to train these two classifiers .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 3577
The remaining 34 ,000 non-face patterns and other 2 ,450 face patterns were used to compare the accuracy .
The remaining 34 ,000 non-face patterns and other 2 ,450 face patterns were used to compare the accuracy of the classifiers .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
21:1			18:1			0		1.0

Alignment 3578
The cascade of AdaBoost classifiers were trained with the parameters set as in section 6 .1 .
The cascade of AdaBoost classifiers were trained with the parameters set as in section 6 .1 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 3579
The RBF SVM classifier reused 100 features selected by the last layer of CAB17 as the feature vector and was trained by a RBF kernel whose parameter \MATH is \MATH .
The RBF SVM classifier reused 100 features selected by the last layer of CAB17 as the feature vector and was trained by an RBF kernel whose parameter \MATH is \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0

Alignment 3580
The parameter \MATH is set to \MATH .
The parameter \MATH was set to \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			2		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 3581
These parameters are found by using cross-validation test .
These parameters were found by using a cross-validation test .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			2		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0

Alignment 3582
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters .
The result shown in Figure 16 demonstrates that with hard classified patterns that later layers of the cascade will process , the single SVM classifier can achieve higher accuracy than the cascade of AdaBoost classifiers trained by roughly predefined training parameters . / / ?NOTE : I believe that I hyphenated this term in your previous document , but after seeing it used here , I would say that it does not need to be hyphenated. My apologies for any confusion . A better way to express this , however , might be " patterns that have been classified as difficult " or " patterns shown to be difficult to classify .]
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0

Alignment 3583
Furthermore , the training time of a single SVM ( which takes several hours ) is much smaller than that of a cascade of AdaBoost classifiers ( which might take everal weeks ) .
Furthermore , the training time of a single SVM ( which takes several hours ) is much shorter than that of a cascade of AdaBoost classifiers ( which might take several weeks ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0

Alignment 3584
The final system consists of three stages .
The final system consists of three stages .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 3585
In the first stage , the cascaded 36x36 classifiers consist of three layers , making a total number of features used of 120 .
In the first stage , the cascaded 36x36 classifiers consist of three layers , making for a total of 120 features .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			21:1			0		1.0
19:1			22:1			0		1.0
20:1			19:1			0		1.0
21:1			23:1			0		1.0

Alignment 3586
The second stage consists of 17 layers with 2 ,160 features .
The second stage consists of 17 layers with 2 ,160 features .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 3587
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and , thus , can save significant training time ( which is approximate 27 times in total ) .
Compared to the system with 6 ,061 features used in [1] , our system uses fewer features and can thus save significant training time ; the training time needed using the new system is approximately 27 times shorter / approximately 27 rounds of training are needed in the new system . / / <--I think that the first choice here is your intended meaning , but please check carefully .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			21:1			0		1.0
19:1			19:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0
27:1			31:2			3		1.0
33:1			28:1			0		1.0
34:1			29:1			1		1.0
35:1			30:1			0		1.0
50:1			35:1			0		1.0
64:1			18:1			0		1.0

Alignment 3588
The final stage is a cascade of three SVM classifiers that take 100 features of the last layer in the second stage as the feature vector .
The final stage is a cascade of three SVM classifiers that take 100 features of the last layer in the second stage as the feature vectors .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			1		1.0
26:1			26:1			0		1.0

Alignment 3589
Each SVM classifier was trained by using 7 ,500 face patterns and 7 ,500 non-face patterns .
Each SVM classifier was trained by using 7 ,500 face patterns and 7 ,500 non-face patterns .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 3590
The same 7 ,500 face patterns were used in training all these SVM classifiers .
The same 7 ,500 face patterns were used in training all these SVM classifiers .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 3591
By running the cascade of AdaBoost classifiers of the second stage on the set of non-face images , 40 ,000 false positives were collected and used as non-face patterns to train the SVM classifiers .
By running the cascade of AdaBoost classifiers of the second stage on the set of non-face images , 40 ,000 false positives were collected and used as non-face patterns to train the SVM classifiers .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0

Alignment 3592
7 ,500 non-face patterns used to train the first SVM classifier were selected randomly from the 40 ,000 non-face patterns .
The 7 ,500 non-face patterns used to train the first SVM classifier were selected randomly from the 40 ,000 non-face patterns .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			0:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0

Alignment 3593
Non-face patterns in the subsequent SVM classifiers were false positives collected by the partially cascaded SVM classifiers on these 40 ,000 non-face patterns .
Non-face patterns in the subsequent SVM classifiers were false positives collected by the partially cascaded SVM classifiers on these 40 ,000 non-face patterns .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 3594
To control the number of support vectors , the parameter \MATH was used instead of the parameter \MATH .
To control the number of support vectors , the parameter \MATH was used instead of the parameter \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 3595
All SVM classifiers were trained by using the RBF kernel with \MATH .
All SVM classifiers were trained by using the RBF kernel with \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 3596
All these parameters were found by using cross-validation test tool provided by LibSVM [31]} .
All these parameters were found by using a cross-validation test tool provided by LibSVM [31] . / / ?NOTE : I believe that I hyphenated this term in your previous document , but after seeing it used here , I would say that it does not need to be hyphenated
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
15:1			14:1			0		1.0

Alignment 3597
This training procedure resulted three SVM classifiers whose the numbers of support vectors are 4 ,725 , 5 ,043 , and 4 ,847 respectively .
This training procedure yielded three SVM classifiers whose numbers of support vectors are 4 ,725 , 5 ,043 , and 4 ,847 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			24:1			0		1.0

Alignment 3598
The average evaluating speed of a SVM classifier is approximate 610 WPS ( windows per second ) .
The average evaluating speed of a SVM classifier is approximately 610 WPS ( windows per second ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			1		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 3599
We tested our system on the MIT+CMU frontal-face standard test set [5] which consists of 124 images with 480 frontal faces ( excluding images containing hand-drawn , cartoon and small faces ) .
We tested our system on the MIT+CMU frontal-face standard test set [5] , which consists of 124 images with 480 frontal faces ( excluding images containing hand-drawn , cartoon , and small faces ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
33:1			31:1			0		1.0
34:1			32:1			0		1.0

Alignment 3600
The configuration and rejection performance of the classifiers are listed in Table 1 and 2 .
The configuration and rejection performance of the classifiers are listed in Tables 1 and 2 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			1		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 3601
The first row presents the number of features of each layer , and the second row shows the fraction of the remaining patterns after each layer processing .
The first row presents the number of features of each layer and the second row shows the fraction of the remaining patterns after each layer were processed . / / [fraction / percentage?<--Here and after , you use " percentage " in the graph , so you may want to keep the same term here .]
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
26:1			26:1			1		1.0
27:1			27:1			0		1.0
35:1			11:1			0		1.0

Alignment 3602
The last row indicates the fraction of time that each layer consumes .
The last row indicates the fraction of time that each layer consumed . / / [fraction / percentage?]
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			1		1.0
12:1			12:1			0		1.0

Alignment 3603
All these statistics are extracted from running the classifiers on the MIT+CMU test set .
All these statistics were extracted by running the classifiers on the MIT+CMU test set .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			2		1.0
4:1			4:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 3604
The fraction of the remaining patterns on these two tables indicates that most of the non-face patterns , i.e. , \MATH , are rejected by the first stage , the cascade of 36x36 AdaBoost classifiers .
The fraction of the remaining patterns on these two tables indicates that most of the non-face patterns , i.e. , \MATH , were rejected by the first stage , the cascade of 36x36 AdaBoost classifiers .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:2			22:2			3		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0

Alignment 3605
If the first 24x24 layer classifier is added to the cascade of 36x36 classifiers , this combination rejects 85 .91\% of analyzed patterns compared to \MATH of using only the first layer of the single cascade 24x24 classifiers .
When the first 24x24 layer classifier was added to the cascade of 36x36 classifiers , this combination rejected 85 .91\% of analyzed patterns compared to \MATH of using only the first layer of the single cascade of 24x24 classifiers .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			2		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			1		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
37:1			36:1			0		1.0
38:1			37:1			0		1.0
39:1			38:1			0		1.0

Alignment 3606
Furthermore , the rejection of this very large number of patterns is done extremely quickly , only using \MATH of processing time .
Furthermore , the rejection of this very large number of patterns was done extremely quickly , only using \MATH of the total processing time . / / [the total / the standard?]
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			2		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0

Alignment 3607
It also shows that most of the processing time used by the AdaBoost+SVM system , \MATH , is used for SVM classifiers .
It also shows that most of the processing time used by the AdaBoost+SVM system , \MATH , was used for SVM classifiers .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:2			17:2			3		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 3608
Detection rate and speed of classifiers with ten false positives are listed in Table 3 .
The detection rate and speed of the classifiers with ten false positives are listed in Table 3 .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0

Alignment 3609
It is clear that our multi-stage system runs faster than the single cascade of 24x24 AdaBoost classifiers while detection rates are comparable .
It is clear that our multi-stage system ran faster than the single cascade of 24x24 AdaBoost classifiers while achieving comparable detection rates .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			2		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
19:1			21:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			22:1			0		1.0

Alignment 3610
This performance is possible because of the three following reasons :
This performance was possible for three reasons .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			2		1.0
3:1			3:1			0		1.0
5:1			7:1			0		1.0
6:1			9:1			0		1.0

Alignment 3611
First , the cascade of 36x36 AdaBoost classifiers rejects a lot of non-face patterns extremely fast while slow SVM classifiers only process a very small number of the remaining patterns .
First , the cascade of 36x36 AdaBoost classifiers rejected many of non-face patterns extremely quickly , while slow SVM classifiers only processed a very small number of the remaining patterns .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			1		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			3		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			1		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0

Alignment 3612
Second , many images in the MIT+CMU test set contain large portion of background which was mentioned in [9] which said the ratio of non-face to face patterns is about 50 ,000 to 1 .
Second , many images in the MIT+CMU test set contain large portion of background , which [9] mentioned has a ratio of non-face to face patterns of about 50 ,000 to 1 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			18:1			0		1.0
17:1			16:1			0		1.0
18:2			28:1			3		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0
24:1			26:1			0		1.0
25:1			27:1			0		1.0
27:1			29:1			0		1.0
28:1			30:1			0		1.0
29:1			31:1			0		1.0
30:1			32:1			0		1.0
31:1			33:1			0		1.0
32:1			34:1			0		1.0

Alignment 3613
Experimental results showed that the AdaBoost+SVM system runs faster than that of the original AdaBoost on \MATH of total number of images in this test set .
Experimental results showed that the AdaBoost+SVM system ran faster than that of the original AdaBoost on \MATH of the total number of images in this test set .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			2		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:4			17:2			3		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0

Alignment 3614
Third , at a small number of false positives , some true face candidate regions rejected by 36x36 classifiers do not affect so much in final performance because it might also be rejected by 24x24 classifiers in later layers .
Third , at a small number of false positives , some true face candidate regions rejected by 36x36 classifiers did not severely affect the final performance because they might also be rejected by 24x24 classifiers in later layers .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:2			19:2			3		1.0
22:1			21:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0
31:1			32:1			0		1.0
32:1			33:1			0		1.0
33:1			34:1			0		1.0
34:1			35:1			0		1.0
35:1			36:1			0		1.0
36:1			37:1			0		1.0
37:1			38:1			0		1.0
38:1			39:1			0		1.0

Alignment 3615
Some detection results are given in Figure 17 .
Some detection results are given in Figure 17 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 3616
We have developed a method to build a fast and robust face detection system based on a multi-stage approach .
We have developed a method to build a fast and robust face detection system based on a multi-stage approach .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 3617
The cascaded structure of AdaBoost-based classifiers in two first stages allows to best adapt to various complexities of input patterns ,while non linear SVM classifiers at the final stage are robust enough to achieve good results .
The cascaded structure of AdaBoost-based classifiers in the two first stages allows the system to best adapt to various complexities of input patterns , while nonlinear SVM classifiers at the final stage are robust enough to achieve good results .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			26:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			0		1.0
26:1			23:1			0		1.0
27:1			24:1			0		1.0
28:1			25:1			0		1.0
30:1			27:1			0		1.0
31:1			28:1			0		1.0
32:1			29:1			0		1.0
33:1			30:1			0		1.0
34:1			31:1			0		1.0
35:1			32:1			0		1.0
36:1			33:1			0		1.0
37:1			34:1			0		1.0
38:1			35:1			0		1.0
39:1			36:1			0		1.0

Alignment 3618
Extensive experiments demonstrated that a significant computation time is devoted to potential face regions because almost all non-face patterns are rejected quickly by the two first stages , and only a very small number of face-like patterns is processed by the slow SVM classifiers .
Extensive experiments demonstrated that a significant computation time is devoted to potential face regions because almost all non-face patterns are rejected quickly by the two first stages , and only a very small number of face-like patterns are processed by the slow SVM classifiers . / / [are / need to be?]
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			2		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0

Alignment 3619
Discriminant Haar wavelet features selected from AdaBoost are used for all stage classifier to take advantages from their efficient representation and fast evaluation .
Discriminant Haar wavelet features selected from AdaBoost are used for all stage classifiers to take advantage of their efficient representation and fast evaluation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			1		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			1		1.0
16:2			16:2			3		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 3620
Unsupervised Face Re-Ranking By Mining the Web and Video Archives
Unsupervised Face Re-Ranking By Mining the Web and Video Archives
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 3621
to improve the retrieval performance of image search engines that use textual information for indexing , it is necessary to utilize visual information .
It is necessary to utilize visual information to improve the efficiency of retrieval in image-search engines that use textual information for indexing .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			17:1			0		1.0
2:1			18:1			0		1.0
3:1			19:1			0		1.0
4:1			20:1			0		1.0
5:1			21:1			0		1.0
6:1			22:1			0		1.0
7:1			0:1			0		1.0
8:1			1:1			0		1.0
9:1			2:1			0		1.0
10:2			4:2			3		1.0
12:1			3:1			0		1.0
15:1			8:1			0		1.0
16:1			9:1			0		1.0
17:1			10:1			0		1.0
18:1			11:1			0		1.0
19:1			12:1			0		1.0
20:1			13:1			0		1.0
21:1			14:1			0		1.0
22:1			23:1			0		1.0

Alignment 3622
One popular approach is to learn visual consistency among the images returned by these search engines .
One popular approach has been to learn visual consistency between images returned by these search engines .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:2			3:1			3		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:2			3		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 3623
Most of the state of the art methods for learning the visual consistency usually learn one specific classifier for each query for re-ranking the returned images .
Most state-of-the-art methods of learning visual consistency usually learn one specific classifier for each query to re-rank the returned images .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			7:1			0		1.0
3:1			1:1			0		1.0
4:1			9:1			0		1.0
5:1			11:1			0		1.0
6:1			12:1			0		1.0
7:1			13:1			0		1.0
8:1			14:1			0		1.0
9:1			15:1			0		1.0
10:1			16:1			0		1.0
11:1			17:1			0		1.0
12:1			18:1			0		1.0
13:1			19:1			0		1.0
14:1			20:1			0		1.0
16:1			22:1			1		1.0
17:1			23:1			0		1.0
18:1			24:1			0		1.0
19:1			25:1			0		1.0
20:1			26:1			0		1.0

Alignment 3624
The drawback of these methods is it requires computational cost and processing time that are unsuitable for handling a large number of queries .
The main drawback with these methods is that they require computational cost and processing time that are unsuitable for handling a large number of queries .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			1:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
9:1			7:1			1		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0

Alignment 3625
We propose a method in which one generic classifier is learned and then is used for all queries .
We propose a method in which one generic classifier is learned and is then used for all queries .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			13:1			0		1.0
13:1			12:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 3626
Different from query-specific based methods that learn classifiers for recognition concepts encoded in each query , the generic classifier of our method learns relevancy between images and the query for re-ranking purpose .
Different from query-specific based methods that learn classifiers for recognition concepts encoded in each query , the generic classifier in our method learns relevance between images and the query for re-ranking purposes .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			1		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			1		1.0
32:1			32:1			0		1.0

Alignment 3627
The key contribution of this paper is to introduce a query-dependent feature to represent this relevancy and an unsupervised method to collect training samples for learning the generic classifier .
The key contribution of this research is to introduce a query-dependent feature to represent this relevance and an unsupervised method of collecting training samples to learn the generic classifier .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			1		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:2			20:2			3		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:2			25:1			3		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0

Alignment 3628
The generic classifier is built automatically and independent with existing ranking algorithms of input search engines .
The generic classifier is built automatically and is independent of existing ranking algorithms for input search engines .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			12:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0

Alignment 3629
experimental results show that the proposed method achieves good performance in various datasets .
The experimental results demonstrated that the proposed method performed very well in various datasets .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			0:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			2		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0

Alignment 3630
Image search is essential for many search engines .
Image searches are essential for many search engines .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			1		1.0
2:2			2:2			3		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 3631
Most of existing image search engines usually use text information for judging relevancy , resulting low precision performance .
Most existing image-search engines usually use text information to determine relevance , resulting in poor precision .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			2:1			0		1.0
3:1			5:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:2			10:2			3		1.0
10:1			12:1			1		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
15:1			16:1			0		1.0
16:1			18:1			0		1.0

Alignment 3632
To improve the retrieval performance , it is necessary to use visual information of images for re-ranking .
To improve the accuracy of retrieval , it is necessary to use visual information from images to re-rank them .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			13:1			0		1.0
5:1			3:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
15:1			14:1			0		1.0
17:1			16:1			1		1.0
19:1			17:1			0		1.0

Alignment 3633
However , content-based image understanding is a challenging and unsolved problem .
However , understanding content-based images remains a challenging and unsolved problem .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			4:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			1		1.0
5:1			5:1			3		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 3634
In addition , using visual information requires huge computational cost compared with using text .
In addition , using visual information requires much greater computational cost than using text .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 3635
One popular approach \CITE combining both text and visual information is to use text information to quickly retrieve a set of candidates and then do post-processing (i . e . re-rank) on this set to improve the precision .
One popular approach \CITE combining both text and visual information has been to use text information to quickly retrieve a set of candidates and then do post-processing ( i . e . , re-ranking ) on this set to improve precision .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:2			10:1			3		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
35:1			31:1			0		1.0
36:1			32:1			0		1.0
37:1			33:1			0		1.0
38:1			34:1			0		1.0
39:1			35:1			0		1.0
40:1			37:1			0		1.0
41:1			38:1			0		1.0

Alignment 3636
There are two ways for post-processing : The first way \CITE is to build a ranker or a classifier specific to the given query using the returned images .
There are two ways of doing post-processing : The first \CITE has been to build a ranker or a classifier specific to the given query using the returned images .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			10:1			0		1.0
11:2			11:1			3		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0

Alignment 3637
Building such classifiers requires large computational cost and time .
Building such classifiers involves large computational cost and time .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			2		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 3638
As a result , this way is not scalable for applications processing very large number of queries .
As a result , this way is not scalable for applications that process very large numbers of queries .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			11:1			1		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			1		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0

Alignment 3639
The second way \CITE is to build a generic classifier once and then use it for all new queries .
The second way \CITE has been to build a generic classifier once and then use it for all new queries .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:2			4:1			3		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0

Alignment 3640
This way is more scalable and can be used for practical applications such as meta search engines .
This is more scalable and can be used for practical applications such as meta-search engines .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0

Alignment 3641
We follow the latter way for the problem of face retrieval in which the system enables users to search persons's appearance by their names .
We pursued the latter way to solve the problem with face retrieval in which the system enables users to search people's appearances by their names .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			2		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:2			4:2			3		1.0
7:1			6:1			0		1.0
8:2			7:2			3		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
21:1			20:1			1		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0

Alignment 3642
Our system re-ranks the faces returned by text-based search engines by a generic classifier that is trained in advance using visual information before returning to the user .
Our system re-ranks the faces returned by text-based search engines with a generic classifier that is trained in advance using visual information before returning them to the user .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0

Alignment 3643
Building such generic classifiers requires solving two problems : finding good query-relative representation of faces and collecting a large labeled dataset for training the classifier .
Building such generic classifiers requires two problems to be solved : finding a good query-relative representation of faces and collecting a large labeled dataset to train the classifier .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			0		1.0
23:1			20:1			0		1.0
24:2			21:2			3		1.0
26:1			23:1			0		1.0
27:1			24:1			0		1.0
28:1			25:1			0		1.0

Alignment 3644
By addressing these problems , Our contribution is two-fold :
Our contribution by addressing these problems is two-fold :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			5:1			0		1.0
1:1			6:1			0		1.0
3:1			1:1			0		1.0
4:1			2:1			0		1.0
5:1			3:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0

Alignment 3645
-We propose a general framework for re-ranking faces returned by existing text-based search engine .
-We propose a general framework for re-ranking faces returned by existing text-based search engines .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			1		1.0
14:1			14:1			0		1.0

Alignment 3646
In this framework , We learn a relevance classifier that classifies whether an input face is relevant to the associated query or not .
We learn a relevance classifier that classifies whether an input face is relevant to the associated query or not in this framework .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			4:1			0		1.0
1:1			5:1			0		1.0
2:1			6:1			0		1.0
3:1			7:1			0		1.0
4:1			8:1			0		1.0
5:1			9:1			0		1.0
6:1			10:1			0		1.0
7:1			11:1			0		1.0
8:1			12:1			0		1.0
9:1			13:1			0		1.0
10:1			14:1			0		1.0
11:1			15:1			0		1.0
12:1			16:1			0		1.0
13:1			17:1			0		1.0
14:1			18:1			0		1.0
15:1			19:1			0		1.0
16:1			20:1			0		1.0
17:1			21:1			0		1.0
18:1			22:1			0		1.0
20:1			1:1			0		1.0
21:1			2:1			0		1.0
22:1			23:1			0		1.0

Alignment 3647
The output scores returned by this classifier are used to re-rank the faces .
The output scores returned by this classifier are used to re-rank the faces .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 3648
The more relevant a face to the query , the higher score is .
The more relevant a face is to the query , the higher score is .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0

Alignment 3649
This approach is different from existing approaches such as \CITE that learn a classifier to recognize the identity of the returned faces .
This approach is different from existing ones \CITE that learn a classifier to recognize the identity of the returned faces .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0

Alignment 3650
For example , it recognizes a face as the appearance of 'personX' or not the appearance of 'personX' .
For example , it recognizes a face as the appearance of 'personX' or not the appearance of 'personX' .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 3651
Instead , the relevance classifier is learned to classify a face being relevant or irrelevant to the query .
Instead , the relevance classifier is learned to classify a face being relevant or irrelevant to the query .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 3652
this classifier is independent with the identity of faces , so it can be shared for multiple queries (cf . Figure \REF) .
As this classifier is independent of the identity of faces , it can be shared for multiple queries ( cf . Figure \REF ) .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			0:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:2			3:2			3		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
24:1			22:1			0		1.0

Alignment 3653
We propose a novel representation for each face that models relevance between that face and the query .
We propose a novel representation for each face that models the relevance between that face and the query .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0

Alignment 3654
Once this query-dependent feature for each face is extracted , one relevance classifier can be shared by faces of various queries .
Once this query-dependent feature for each face is extracted , one relevance classifier can be shared by the faces of various queries .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0

Alignment 3655
experimental results show that the relevance classifier that is independent with underlying ranking algorithm of existing search engines can significantly boost the performance .
The experimental results demonstrated that the relevance classifier that is independent of the underlying ranking algorithms of existing search engines could significantly boost performance .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			0:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			2		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:2			9:2			3		1.0
12:1			21:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			1		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			3		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0

Alignment 3656
-We propose a simple yet efficient mining technique for automatically collecting labeled data for training the generic classifier .
-We propose a simple yet efficient mining technique of automatically collecting labeled data to train the generic classifier .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:2			13:2			3		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 3657
Specifically , We detect and group faces of persons appearing in video programs in face tracks in which each face track contains of the faces of one person .
We specifically detected and grouped faces of people appearing in video programs in face tracks in which each face track contained the faces of one person .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			2:1			0		1.0
2:1			3:1			1		1.0
3:1			4:1			0		1.0
4:1			5:1			1		1.0
5:1			6:1			0		1.0
6:1			22:1			0		1.0
7:1			7:2			3		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			1		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0
24:1			26:1			0		1.0
25:1			27:1			0		1.0
26:1			28:1			0		1.0

Alignment 3658
To distinguish face tracks of different persons , we assume that if multiple faces are detected at different locations in one frame , they are of different persons (cf . Figure \REF) .
To distinguish the face tracks of different people , we assumed that if multiple faces were detected at different locations in one frame , they would be of different people ( cf .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			3		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:2			9:2			3		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			24:2			3		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:2			14:1			3		1.0
28:1			26:1			0		1.0
29:1			27:1			3		1.0
32:1			29:1			0		1.0

Alignment 3659
Using this assumption , we collect the face tracks whose faces are detected in the same frames to guarantee that each face track is associated to one unique person .
Using this assumption , we collected face tracks whose faces were detected in the same frames to guarantee that each face track was associated with one unique person .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			1		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			2		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			2		1.0
23:1			24:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0

Alignment 3660
To enlarge the number of such face tracks , We use video programs of multiple genres and channels .
We used video programs from multiple genres and channels to increase the number of such face tracks .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			9:1			0		1.0
1:1			10:1			1		1.0
2:1			11:1			0		1.0
3:1			12:1			0		1.0
5:1			14:1			0		1.0
6:1			15:1			0		1.0
7:1			16:1			0		1.0
8:1			17:1			0		1.0
10:1			1:1			3		1.0
11:1			2:1			0		1.0
12:1			3:1			0		1.0
13:1			4:1			0		1.0
14:1			5:1			0		1.0
15:1			6:1			0		1.0
16:1			7:1			0		1.0
17:1			18:1			0		1.0

Alignment 3661
From these faces , We can artificially generate face sets similar to the sets returned by search engines given person names .
We could artificially generate face sets from these faces similar to the sets returned by search engines given people's names .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			4:1			0		1.0
1:1			5:1			3		1.0
2:1			6:1			0		1.0
3:1			7:1			0		1.0
4:1			8:1			0		1.0
5:1			9:1			0		1.0
7:1			1:1			0		1.0
8:1			2:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0

Alignment 3662
Since we know the relevance of these faces to the artificial sets , the labels of each face can be easily generated and no human intervention is needed for this process .
Since we knew the relevance of these faces to the artificial sets , the labels for each face could be easily generated and no human intervention was needed in this process .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			2		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			28:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:2			18:2			3		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:2			26:2			3		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0

Alignment 3663
Note that the label of faces in our approach is not identity of that face . It is the relevance between the face and the associated query .
Note that the labels of faces in our approach did not identity those faces but the relevance between the faces and the associated query .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			18:1			0		1.0
3:1			2:2			3		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			3		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
15:1			24:1			0		1.0
16:1			19:1			0		1.0
17:1			20:1			0		1.0
18:1			21:1			0		1.0
19:1			22:1			1		1.0
20:1			23:1			0		1.0
22:1			25:1			0		1.0
23:1			26:1			0		1.0
24:1			27:1			0		1.0

Alignment 3664
Collecting training sets from such external sources as video archives is easy and efficient because : firstly , a large number of videos can be easy to obtain .
Collecting training sets from such external sources as video archives is easy and efficient because , first , a large number of videos can be easily obtained .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
16:1			16:1			1		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:2			3		1.0
26:1			27:1			1		1.0
27:1			28:1			0		1.0

Alignment 3665
For example , people can record broadcast videos of different channels in a certain period .
For example , people can record broadcast videos from different channels within a certain period .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:2			8:2			3		1.0
10:1			10:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 3666
Secondly , a huge number of faces can be obtained by applying the face detector in every frame .
Second , a huge number of faces can be obtained by applying a face detector to all frames .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			1		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
17:1			17:1			1		1.0
18:1			18:1			0		1.0

Alignment 3667
In addition , using temporal information , faces of one person appearing in consecutive frames can be automatically grouped with high accuracy .
In addition , the faces of one person appearing in consecutive frames can be automatically grouped with a high degree of accuracy using temporal information .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			7:1			0		1.0
5:1			8:1			0		1.0
6:1			9:1			0		1.0
7:1			10:1			0		1.0
8:1			11:1			0		1.0
9:1			12:1			0		1.0
10:1			13:1			0		1.0
11:1			14:1			0		1.0
12:1			15:1			0		1.0
13:1			16:1			0		1.0
14:1			17:1			0		1.0
15:1			18:1			0		1.0
16:1			19:1			0		1.0
18:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			3:1			0		1.0
23:1			4:1			0		1.0
24:1			5:1			0		1.0
25:1			22:1			0		1.0

Alignment 3668
given a query described by text , for example , 'airplane' or 'George Bush' , finding relevant images with high precision is essential for image search engines .
It is essential for image-search engines to find relevant images with a high degree of precision given queries described by text , e.g. , 'airplane' or 'George Bush' .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			21:1			0		1.0
2:1			22:1			0		1.0
3:1			23:1			0		1.0
5:1			26:1			0		1.0
6:2			15:1			3		1.0
8:1			16:1			0		1.0
9:1			17:1			0		1.0
10:1			18:1			0		1.0
11:1			1:1			0		1.0
12:1			19:1			0		1.0
15:1			20:1			0		1.0
16:1			0:1			0		1.0
17:1			2:1			1		1.0
18:1			3:1			0		1.0
19:1			4:1			0		1.0
20:1			5:1			0		1.0
21:1			6:1			0		1.0
23:1			9:1			0		1.0
24:1			10:1			0		1.0
25:1			11:1			0		1.0
26:1			12:1			0		1.0
27:1			13:1			0		1.0
28:1			27:1			0		1.0

Alignment 3669
Existing image search engines usually use textual information associated with the images such as filename , image caption , and surrounding text for ranking that leads to poor precision .
Existing image-search engines usually use textual information associated with images such as filenames , image captions , and surrounding text for ranking that leads to poor precision .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			1		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			1		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0
24:1			26:1			0		1.0
25:1			27:1			0		1.0
26:1			28:1			0		1.0
27:1			29:1			0		1.0

Alignment 3670
To improve the precision , visual information is used to re-rank the returned images .
To improve precision , visual information is used to re-rank the returned images .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0

Alignment 3671
The idea is to rely on the visual consistency among these images to learn visual classifiers that measure the relevancy between an image and the input query .
The idea is to rely on the visual consistency between these images to learn visual classifiers that measure the relevance between an image and the input query .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			20:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			1		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0

Alignment 3672
There are different approaches described in \CITE for re-ranking images containing general objects and faces returned from text-based search engines .
There have been different approaches \CITE to re-ranking images containing general objects and faces returned from text-based search engines .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:2			1:1			3		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			6:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0

Alignment 3673
Work such as \CITE extend topics models using probabilistic Late Semantic Analysis , Latent Dirichlet Allocation , or Hierarchical Dirichlet Process to learn generative model based classifiers .
Work \CITE has extended to topics on models using probabilistic Late Semantic Analysis , Latent Dirichlet Allocation , or the Hierarchical Dirichlet Process to learn generative model-based classifiers .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			3:1			0		1.0
3:2			4:1			3		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0

Alignment 3674
These models can handle noisy image data in some degree .
These models can handle noisy image data to some degree .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:2			6:2			3		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 3675
However , they have many parameters needed to be tuned such as number of topics and feature configurations .
However , they have many parameters that need to be tuned such as the number of topics and feature configurations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			1		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0

Alignment 3676
In addition , how to select the best topic associated with the input query for identifying target label is still challenging \CITE .
In addition , how the best topic is selected associated with the input query to identify the target label is still a difficult issue \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			18:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			4:1			0		1.0
15:2			15:1			3		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
20:1			19:1			0		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0

Alignment 3677
In \CITE , Textual information is used to build a text ranker to re-rank the returned images \CITE .
Textual information has been used to build a text ranker to re-rank the returned images \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			3:1			0		1.0
1:1			4:1			0		1.0
2:2			5:1			3		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0

Alignment 3678
The top images in this ranked list are used as positive samples to train visual classifiers using SVM (Support vector machines) .
The top images in this ranked list were used as positive samples to train visual classifiers using SVM ( Support vector machines ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:2			7:2			3		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
20:1			19:1			0		1.0
23:1			21:1			0		1.0

Alignment 3679
This method makes the training data cleaner that leads to performance improvement .
This method made the training data cleaner and led to improved performance .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			2		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:2			8:2			3		1.0
11:1			10:1			0		1.0
12:1			12:1			0		1.0

Alignment 3680
In \CITE , A multiple instance learning framework is used to learn category models from images associated with keywords \CITE .
A multiple-instance learning framework has been used to learn category models from images associated with keywords \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			3:1			0		1.0
2:1			6:1			0		1.0
3:1			7:1			0		1.0
4:2			8:1			3		1.0
6:1			9:1			0		1.0
7:1			10:1			0		1.0
8:1			11:1			0		1.0
9:1			12:1			0		1.0
10:1			13:1			0		1.0
11:1			14:1			0		1.0
12:1			15:1			0		1.0
13:1			16:1			0		1.0
14:1			17:1			0		1.0
15:1			18:1			0		1.0
16:1			19:1			0		1.0
17:1			20:1			0		1.0

Alignment 3681
The returned images are treated as positive bag .
The returned images were treated as a positive bag .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			2		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0

Alignment 3682
Negative bags are collected from image sets corresponding to unrelated keywords .
Negative bags were collected from image sets corresponding to unrelated keywords .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:2			2:2			3		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 3683
The learned model is used to re-rank the images .
The learned model was used to re-rank the images .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:2			3:2			3		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 3684
The work mentioned above are for re-ranking images containing general objects .
These researchers re-ranked images containing general objects .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			6:1			1		1.0
3:1			7:1			0		1.0
4:1			8:1			0		1.0
5:1			9:1			0		1.0
6:1			10:1			0		1.0
7:1			11:1			0		1.0

Alignment 3685
For re-ranking faces , work described in \CITE use Gaussian mixture models to build face recognizers and apply these recognizers back to the input faces for re-ranking \CITE .
Gaussian mixture models have been used for re-ranking faces to build face recognizers and apply these recognizers back to the input faces for re-ranking \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			9:1			0		1.0
1:1			10:1			0		1.0
2:1			11:1			0		1.0
4:2			8:1			3		1.0
6:1			25:1			0		1.0
7:1			1:1			0		1.0
8:1			2:1			0		1.0
9:1			12:1			0		1.0
10:1			13:1			0		1.0
11:1			14:1			0		1.0
12:1			15:1			0		1.0
13:1			16:1			0		1.0
14:1			17:1			0		1.0
15:1			18:1			0		1.0
16:1			19:1			0		1.0
17:1			20:1			0		1.0
18:1			21:1			0		1.0
19:1			22:1			0		1.0
20:1			23:1			0		1.0
21:1			24:1			0		1.0
23:1			26:1			0		1.0
24:1			27:1			0		1.0
25:1			28:1			0		1.0

Alignment 3686
In \CITE , Discriminative approach based models such as SVM and linear discriminant analysis are used instead of Gaussian mixture models \CITE .
Discriminative-approach-based models such as SVM and linear discriminant analysis have been used instead of Gaussian mixture models \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			6:1			0		1.0
2:1			7:1			0		1.0
3:1			8:1			0		1.0
4:1			9:1			0		1.0
5:1			10:1			0		1.0
6:1			11:1			0		1.0
7:1			12:1			0		1.0
8:1			13:1			0		1.0
9:2			14:1			3		1.0
11:1			15:1			0		1.0
12:1			16:1			0		1.0
13:1			17:1			0		1.0
14:1			18:1			0		1.0
15:1			19:1			0		1.0
16:1			20:1			0		1.0
17:1			21:1			0		1.0
18:1			22:1			0		1.0

Alignment 3687
In \CITE , A densest graph based method is used for finding the face group relevant to the query \CITE .
A densest-graph-based method has been used for finding the face group relevant to the query \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			3:1			0		1.0
2:1			7:1			0		1.0
3:2			8:1			3		1.0
5:1			9:1			0		1.0
6:1			10:1			0		1.0
7:1			11:1			0		1.0
8:1			12:1			0		1.0
9:1			13:1			0		1.0
10:1			14:1			0		1.0
11:1			15:1			0		1.0
12:1			16:1			0		1.0
13:1			17:1			0		1.0
14:1			18:1			0		1.0
15:1			19:1			0		1.0
16:1			20:1			0		1.0

Alignment 3688
As for these approaches , One specific classifier is built for each query .
One specific classifier is built for each query in these approaches .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			5:1			0		1.0
1:1			6:1			0		1.0
2:1			7:1			0		1.0
3:1			8:1			0		1.0
4:1			9:1			0		1.0
5:1			10:1			0		1.0
6:1			11:1			0		1.0
7:1			12:1			0		1.0
9:1			2:1			0		1.0
10:1			3:1			0		1.0
11:1			13:1			0		1.0

Alignment 3689
Therefore , to handle a large number of queries , many classifiers must be built which are not suitable in practice .
Therefore , many classifiers must be built , which are not suitable in practice , to handle a large number of queries .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			9:1			0		1.0
2:1			10:1			0		1.0
3:1			11:1			0		1.0
4:1			12:1			0		1.0
5:1			13:1			0		1.0
6:1			14:1			0		1.0
8:1			15:1			0		1.0
9:1			16:1			0		1.0
10:1			17:1			0		1.0
11:1			18:1			0		1.0
12:1			19:1			0		1.0
13:1			20:1			0		1.0
14:1			1:1			0		1.0
15:1			2:1			0		1.0
16:1			3:1			0		1.0
17:1			4:1			0		1.0
18:1			5:1			0		1.0
19:1			6:1			0		1.0
20:1			7:1			0		1.0
21:1			8:1			0		1.0
22:1			21:1			0		1.0

Alignment 3690
In \CITE{Krapac10CVPR} , Only one generic classifier is built in advance \CITE and then used for all queries .
Only one generic classifier has been built in advance \CITE and then used for all queries .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			3:1			0		1.0
1:1			4:1			0		1.0
2:1			5:1			0		1.0
3:1			6:1			0		1.0
4:2			7:1			3		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0

Alignment 3691
This generic classifier is a relevance classifier that learns relevancy between an image and the query .
This generic classifier was a relevance classifier that learned relevance between an image and the query .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:2			3:2			3		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			1		1.0
9:1			9:1			1		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 3692
As for specific classifiers , Each image is classified as 'class-A' or 'non-class-A' , where 'class-A' is the category associated with the query , for example , 'airplane' .
Each image for specific classifiers is classified as 'class-A' or 'non-class-A' , where 'class-A' is the category associated with the query , e.g. , 'airplane' .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			5:1			0		1.0
1:1			6:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
23:1			26:1			0		1.0
24:1			27:1			0		1.0
25:1			28:1			0		1.0

Alignment 3693
In other words , each specific classifier is associated with one class label implied by the query .
In other words , each specific classifier is associated with one class label implied by the query .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 3694
In generic classifier , Each image is classified as relevant or irrelevant to the query .
Each image in a generic classifier is classified as relevant or irrelevant to the query .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			4:1			0		1.0
1:1			5:1			0		1.0
4:1			1:1			0		1.0
5:1			2:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 3695
Therefore , it is independent to class labels and can be used for any query .
Therefore , it is independent of class labels and can be used for any query .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 3696
This method works well for objects such as car , flag , but fails to handle faces .
This method works well for objects such as cars and flags , but fails to handle faces .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			1		1.0
10:1			10:1			1		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 3697
Our method is inspired by the generic classifier based approach .
Our method was inspired by the generic-classifier-based approach .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			2		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0

Alignment 3698
We extend it by two means : first , query-dependent features specific for faces are proposed , and second , the training data for learning the generic classifier is collected automatically by mining video archives .
We extended it in two ways : first , query-dependent features specific to faces are proposed , and second , the training data for learning the generic classifier are collected automatically by mining video archives .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			1		1.0
2:1			2:1			0		1.0
3:2			3:2			3		1.0
5:1			5:1			2		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			2		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0

Alignment 3699
Given a set of faces returned by any search engine for a queried person ( e .g . 'George Bush' ) , our task is to re-rank these faces to improve the precision .
Given a set of faces returned by any search engine for a queried person ( e.g. , 'George Bush' ) , our task is to re-rank these faces to improve precision .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0
30:1			32:1			0		1.0
31:1			33:1			0		1.0

Alignment 3700
To this end , we extract query-dependent feature for each face and then use the generic classifier trained in advance to predict scores representing the relevance between that face and the query .
To this end , we extract query-dependent features for each face and then use the generic classifier trained in advance to predict scores representing the relevance between that face and the query .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			1		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0

Alignment 3701
These scores are sorted and used for re-ranking .
These scores are sorted and used for re-ranking .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 3702
The ranked list is then return to users as shown in Figure \REF( b ) .
The ranked list is then returned to users as shown in Figure \REF( b ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:2			5:2			3		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 3703
This approach is different from existing approaches such as \CITE as shown in Figure \REF( a ) in which one specific classifier is built for each query .
This approach is different from the existing approaches \CITE shown in Figure \REF( a ) in which one specific classifier is built for each query .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			9:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0
24:1			26:1			0		1.0
25:1			27:1			0		1.0

Alignment 3704
To build the specific classifier for re-ranking faces returned by the query of 'personX' , each face is represented by the query-independent feature such as pixel intensity around facial features such as eyes , nose , and mouth \CITE .
To build a specific classifier for re-ranking faces returned by the query of 'personX' , each face is represented by a query-independent feature such as pixel intensity around facial features such as the eyes , nose , and mouth \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			2:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
37:1			36:1			0		1.0
38:1			37:1			0		1.0
39:1			38:1			0		1.0
40:1			39:1			0		1.0

Alignment 3705
The label for each face is 'personX' or 'non-personX' meaning that it is relevant or irrelevant to 'personX' .
The label for each face is 'personX' or 'non-personX' meaning that it is relevant or irrelevant to 'personX' .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 3706
Meanwhile , to build the generic classifier which is independent with any \textit{'personX'} , each face is represented by the query-dependent feature .
Further , each face is represented by the query-dependent feature to build a generic classifier that is independent of any 'personX' .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			13:1			0		1.0
2:1			14:1			0		1.0
3:1			15:1			0		1.0
4:1			16:1			0		1.0
5:1			17:1			0		1.0
6:1			18:1			0		1.0
7:1			19:1			0		1.0
8:1			20:1			0		1.0
9:1			21:1			0		1.0
10:1			2:1			0		1.0
11:1			3:1			0		1.0
13:1			5:1			0		1.0
14:1			6:1			0		1.0
15:2			7:2			3		1.0
17:2			9:2			3		1.0
19:1			11:1			0		1.0
21:1			22:1			0		1.0

Alignment 3707
The label for each face is relevant or irrelevant to the query .
The label for each face is relevant or irrelevant to the query .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 3708
The query-dependent feature is used to encode this relevancy .
The query-dependent feature is used to encode this relevance .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			1		1.0
9:1			9:1			0		1.0

Alignment 3709
In \CITE , the Query-dependent features using textual information are proposed \CITE .
Query-dependent features using textual information has been proposed \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			4:1			0		1.0
1:1			5:1			0		1.0
2:1			6:1			0		1.0
3:1			7:1			0		1.0
4:1			8:1			0		1.0
6:1			9:1			2		1.0
7:1			10:1			0		1.0
8:1			11:1			0		1.0
9:1			12:1			0		1.0

Alignment 3710
Each feature is treated as binary indicating the presence or absence of the query terms in textual data associated with the input image , for example , filename , image title , and nearby text .
Each feature was treated as binary indicating the presence or absence of query terms in the textual data associated with the input image , e.g. , filenames , image titles , and nearby text .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:2			2:2			3		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			12:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			1		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			1		1.0
30:1			31:1			0		1.0
31:1			32:1			0		1.0
32:1			33:1			0		1.0
33:1			34:1			0		1.0
34:1			35:1			0		1.0

Alignment 3711
Extending this query-dependent feature for using visual information is not trivial since we can not compute the presence and absence of the query term such as 'George Bush' in each face .
Extending this query-dependent feature to use visual information is not trivial since we cannot compute the presence or absence of query terms such as 'George Bush' in each face .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:2			4:2			3		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:2			3		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			1		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0
24:1			26:1			0		1.0
25:1			27:1			0		1.0
26:1			28:1			0		1.0
27:1			29:1			0		1.0
28:1			30:1			0		1.0
29:1			31:1			0		1.0

Alignment 3712
In \CITE , Each image \CITE is represented as a set of visual words .
Each image in \CITE is represented as a set of visual words .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			3:1			0		1.0
1:1			4:1			0		1.0
3:1			5:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0

Alignment 3713
The top- \MATH visual words that are strongly associated with the set of the returned images for the query are selected .
The top- \MATH visual words that are strongly associated with the set of returned images for the query are selected .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0

Alignment 3714
The binary features for each image are computed by evaluating the presence and absence of these visual words in that image .
The binary features for each image are computed by evaluating the presence and absence of these visual words in that image .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 3715
Since this method is suitable for general objects rather than faces , we proposed another method described below for extracting query-dependent features to train the generic classifier .
Since this method is suitable for general objects rather than faces , we propose another method of extracting query-dependent features to train the generic classifier that is described below .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			1		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0
24:1			26:1			0		1.0
27:1			16:1			0		1.0
28:1			17:1			0		1.0
29:1			27:1			0		1.0

Alignment 3716
To be able to model the relevance between a face and the given query , We assume that there is visual consistency among faces returned by search engines for that query .
We assumed that there would be visual consistency between faces returned by search engines for a query to be able to model the relevance between a face and that given query .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			15:1			0		1.0
1:1			16:1			1		1.0
2:1			17:1			0		1.0
3:1			18:1			0		1.0
4:2			19:1			3		1.0
6:1			20:1			0		1.0
7:1			21:1			0		1.0
8:1			7:1			0		1.0
9:1			23:1			0		1.0
10:1			24:1			0		1.0
11:1			25:1			0		1.0
12:1			26:1			0		1.0
13:1			27:1			0		1.0
14:1			28:1			0		1.0
15:1			8:1			0		1.0
16:1			13:1			0		1.0
17:1			3:1			0		1.0
18:1			1:1			0		1.0
19:1			2:1			0		1.0
21:1			4:1			0		1.0
22:1			5:1			0		1.0
23:1			6:1			0		1.0
26:1			9:1			0		1.0
27:1			10:1			0		1.0
28:1			29:1			0		1.0
29:1			12:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0

Alignment 3717
In the other word , we assume faces that are relevant to the query form the largest cluster .
In the other words , we assumed faces that were relevant to the query would form the largest cluster .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			1		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			1		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			2		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0

Alignment 3718
Note that finding such cluster is still difficult since the number of clusters is not known in advance and the accuracy of clustering algorithms always depends on the discriminative power of feature representation .
Note that finding such clusters is still difficult since the number of clusters is not known in advance and the accuracy of clustering algorithms always depends on the discriminative power of feature representation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			1		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0

Alignment 3719
This assumption is widely accepted in most of the work of this field \CITE .
This assumption is widely accepted in most of the work in this field \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:2			9:2			3		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 3720
We consider the problem of finding relevant and irrelevant faces in the input set as the problem of outlier detection \CITE that is popular in data mining community .
We consider the problem of finding relevant and irrelevant faces in the input set to be the problem of outlier detection \CITE that is popular in the data-mining community .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0

Alignment 3721
We first describe several distance based outlier detection methods that use the distance to the \MATH -nearest neighbors to determine observations as outliers or non-outliers .
We first describe several distance-based methods of outlier detection that use the distance to the \MATH -nearest neighbors to determine observations as outliers or non-outliers .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			8:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 3722
Then the adaptation is proposed to form the query-dependent feature .
Then , adaptation is proposed to form a query-dependent feature .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 3723
Given a threshold \MATH , for each point \MATH , we examine number of points \MATH so that \MATH , where \MATH is the distance ( e .g . Euclidean distance ) between \MATH and \MATH in the feature space .
Given threshold \MATH , for each point \MATH , we examine the number of points \MATH so that \MATH , where \MATH is the distance ( e.g. , Euclidean distance ) between \MATH and \MATH in the feature space .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			37:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0
31:1			32:1			0		1.0
32:1			33:1			0		1.0
33:1			34:1			0		1.0
34:1			35:1			0		1.0
35:1			36:1			0		1.0
37:1			38:1			0		1.0
38:1			39:1			0		1.0
39:1			40:1			0		1.0

Alignment 3724
This number of points \MATH is called the neighborhood score of \MATH and is defined as follows : \MATH where \MATH is the total number of points of the input dataset .
This number of points \MATH is called the neighborhood score of \MATH and is defined as : \MATH where \MATH is the total number of points in the input dataset .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:2			26:2			3		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0

Alignment 3725
A low value of \MATH indicates \MATH is a candidate of outliers , while a high value of \MATH indicates \MATH is a member of one strong association cluster .
A low value for \MATH indicates \MATH is a candidate of outliers , while a high value for \MATH indicates \MATH is a member of one strong association cluster .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:2			2:2			3		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:2			16:2			3		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0

Alignment 3726
In practice , it is difficult to know \MATH because it depends on underlying distribution of the input dataset .
In practice , it is difficult to know \MATH because this depends on the underlying distribution of the input dataset .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:2			9:2			3		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0

Alignment 3727
For each point \MATH , find its \MATH -nearest neighbors \MATH , the distance score of \MATH is the sum of the distances between \MATH and its \MATH -nearest neighbors \MATH and is defined as follows : \MATH
For each point \MATH , find its \MATH -nearest neighbors \MATH ; the distance score of \MATH is the sum of the distances between \MATH and its \MATH -nearest neighbors \MATH and is defined as : \MATH
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			36:1			0		1.0
36:1			37:1			0		1.0

Alignment 3728
Points with larger values for \MATH have more sparse neighborhoods and are likely outliers than points belonging to dense clusters which usually have lower values of \MATH .
Points with larger values for \MATH have sparser neighborhoods and are more likely outliers than points belonging to dense clusters , which usually have lower values for \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			8:1			2		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			7:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:2			24:2			3		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0

Alignment 3729
Similar to nearest neighbor score , it is difficult to determine the appropriate \MATH value for each dataset .
Similar to the nearest neighbor score , it is difficult to determine the appropriate \MATH value for each dataset .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0

Alignment 3730
We consider the generic classifier as an outlier classifier that classifies an input sample as outlier or non-outlier .
We consider the generic classifier as an outlier classifier that classifies an input sample as an outlier or a non-outlier .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0

Alignment 3731
In our framework , Each face is an sample , and non-outliers / outliers mean faces relevant / irrelevant to the query ( i .e . target person ) .
Each face in our framework is a sample , and non-outliers / outliers mean faces are relevant / irrelevant to the query ( i.e. , target person ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			4:1			0		1.0
1:1			5:1			0		1.0
3:1			1:1			0		1.0
4:1			2:1			0		1.0
5:2			6:2			3		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
24:1			3:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0

Alignment 3732
As described above , \MATH and \MATH of outliers and non-outliers might have distributions shown in Figure \REF , these scores can be used as feature values to discriminate non-outliers and outliers .
As described above , the \MATH and \MATH of outliers and non-outliers might have the distributions in Figure \REF ; these scores can be used as feature values to discriminate non-outliers from outliers .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0

Alignment 3733
From this observation , the feature vector is formed by varying parameters such as \MATH and \MATH in formula of \MATH and \MATH as follows : \MATH .
From this observation , the feature vector is formed by varying parameters such as \MATH and \MATH in the formula of \MATH and \MATH as follows : \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0

Alignment 3734
In order to train the relevance classifier using supervised learning methods such as SVM , it requires a sufficient number of training samples .
It requires a sufficient number of training samples to train the relevance classifier using supervised learning methods such as SVM .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			16:1			0		1.0
2:1			17:1			0		1.0
3:1			18:1			0		1.0
4:1			19:1			0		1.0
5:1			20:1			0		1.0
6:1			21:1			0		1.0
7:1			22:1			0		1.0
8:1			2:1			0		1.0
9:1			3:1			0		1.0
10:1			4:1			0		1.0
11:1			5:1			0		1.0
12:1			6:1			0		1.0
13:1			7:1			0		1.0
14:1			8:1			0		1.0
15:1			9:1			0		1.0
16:1			10:1			0		1.0
17:1			11:1			0		1.0
18:1			12:1			0		1.0
19:1			13:1			0		1.0
20:1			23:1			0		1.0

Alignment 3735
To collect training samples , The simplest way \CITE is we pick many names , and pass them to search engines .
The simplest way \CITE of collecting training samples is to pick many names , and pass them to search engines .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			5:1			0		1.0
1:1			6:1			0		1.0
2:1			7:1			0		1.0
3:1			8:1			0		1.0
5:1			1:1			1		1.0
6:1			2:1			0		1.0
7:1			3:1			0		1.0
8:1			9:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0

Alignment 3736
After collecting the returned faces , we manually label each face whether it is relevant to the input query or not .
After collecting the returned faces , we manually label each face as to whether it is relevant to the input query or not .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0

Alignment 3737
It is a tedious task and requires human labor cost .
This is a tedious task and involves a human-labor cost .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			2		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 3738
We propose another approach to automatically collect training samples for training the relevant classifier .
We propose another approach to automatically collecting training samples to train the relevant classifier .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			1		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:2			9:2			3		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 3739
This approach consists of two steps :
This approach consists of two steps .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0

Alignment 3740
First , by mining video archives , we automatically collect a set of faces of \MATH different persons \MATH , where \MATH is the set of faces of person \MATH , and \MATH is the number of persons; and
First , by mining video archives , we automatically collect a set of faces of \MATH different people \MATH , where \MATH is the set of faces of person \MATH , and \MATH is the number of people .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			3		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0

Alignment 3741
Second , we generate a set of subsets \MATH , where \MATH is the set of faces that is picked from \MATH , and \MATH is the number of subsets .
Second , we generate a set of subsets \MATH , where \MATH is the set of faces that is picked from \MATH , and \MATH is the number of subsets .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0

Alignment 3742
The restriction is the assumption of visual consistency is satisfied .
The restriction is that the assumption of visual consistency is satisfied .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0

Alignment 3743
In other words , as shown in Figure \REF , \MATH might have several face clusters and the largest cluster is equivalent to the faces relevant to the query if returning by a search engine .
In other words , as seen in Figure \REF , \MATH might have several face clusters and the largest cluster is equivalent to the faces relevant to the query if they are returned by a search engine .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
32:1			30:1			1		1.0
33:1			31:1			0		1.0
34:1			32:1			0		1.0
35:1			33:1			0		1.0
36:1			34:1			0		1.0
37:1			35:1			0		1.0

Alignment 3744
As a result , this method can stimulate face sets returned by search engines using many names mentioned above .
As a result , this method can be used to stimulate face sets returned by search engines using many names as mentioned above .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
21:1			17:1			0		1.0
22:1			18:1			0		1.0
23:1			19:1			0		1.0

Alignment 3745
To obtain \MATH , we use a simple technique for faces extracted from video archives .
To obtain \MATH , we use a simple technique for faces extracted from video archives .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 3746
Specifically , We use the following heuristics to pick a set of different persons appearing in video archives :
We specifically use the following heuristics to pick a set of different people appearing in video archives :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			3		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0

Alignment 3747
-If there are more than one face appearing in different locations in one frame , they likely belong to different persons .
-If there is more than one face appearing in different locations in one frame , they are likely to belong to different people .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			2:1			0		1.0
17:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			3		1.0
23:1			21:1			0		1.0

Alignment 3748
Figure \REF shows an example of this case .
Figure \REF shows an example where this has occurred .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			6:1			0		1.0
9:1			8:1			0		1.0

Alignment 3749
-If two persons appear in video programs broadcast by different broadcast stations ( e .g . , CNN , MSNBC , and CCTV ) , they are likely different .
-If two people appear in video programs broadcast by different broadcast stations ( e.g. , CNN , MSNBC , and CCTV ) , they are likely to be different .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			3		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0
24:1			26:1			0		1.0
25:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0

Alignment 3750
If we have large video archives , using these heuristics we can collect a sufficient number of training samples for learning the relevance classifier .
If we have large video archives , we can collect a sufficient number of training samples to learn the relevance classifier by using these heuristics .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			10:1			0		1.0
8:1			11:1			0		1.0
9:1			12:1			0		1.0
10:1			13:1			0		1.0
11:1			14:1			0		1.0
12:1			15:1			0		1.0
13:1			16:1			0		1.0
14:1			17:1			0		1.0
15:1			18:1			0		1.0
16:2			20:1			3		1.0
18:1			21:1			0		1.0
19:1			22:1			0		1.0
20:1			23:1			0		1.0
22:1			7:1			0		1.0
23:1			8:1			0		1.0
24:1			9:1			0		1.0
25:1			24:1			0		1.0

Alignment 3751
We form a face set Generating \MATH by picking a subset of faces of Generating \MATH and adding randomly faces from other sets Generating \MATH .
We form face set Generating \MATH by picking a subset of faces of Generating \MATH and randomly adding faces from other sets Generating \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			18:1			0		1.0
17:1			17:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0

Alignment 3752
To keep the assumption of visual consistency satisfied , the number of faces selected in each set Generating \MATH must be smaller than the number of faces in set Generating \MATH .
To keep satisfying the assumption of visual consistency , the number of faces selected in each set Generating \MATH must be smaller than the number of faces in set Generating \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0

Alignment 3753
We then label faces in set Generating \MATH as relevant to the query associated with Generating \MATH , and the other faces of Generating \MATH as irrelevant to the query .
We then label faces in set Generating \MATH as relevant to the query associated with Generating \MATH , and the other faces of Generating \MATH as irrelevant to the query .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0

Alignment 3754
Once the training samples are collected , we use SVM with linear kernel to learn the relevance classifier .
Once the training samples are collected , we use SVM with a linear kernel to learn the relevance classifier .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0

Alignment 3755
TRECVID dataset : We collected all video programs of TRECVID 2006 dataset \CITE .
TRECVID dataset : We collected all video programs from the TRECVID 2006 dataset \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0

Alignment 3756
There are 527 video programs broadcast on 7 channels in 3 languages including English , Chinese and Arabic .
There were 527 video programs broadcast on seven channels in three languages including English , Chinese , and Arabic .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			2		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			2		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			2		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0

Alignment 3757
We extracted faces from these video programs and grouped faces belonging to one person in each shot in one face track using a similar method described in \CITE .
We extracted faces from these video programs and grouped faces belonging to one person in each shot in one face track using a similar method to that described in \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0

Alignment 3758
For each channel , We scanned all face tracks extracted from the videos broadcast by this channel , and picked face tracks extracted from keyframes that several faces were detected at different locations .
We scanned all face tracks for each channel extracted from the videos broadcast by this channel , and picked face tracks extracted from key frames where several faces were detected at different locations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			4:1			0		1.0
1:1			5:1			0		1.0
2:1			6:1			0		1.0
3:1			7:1			0		1.0
4:1			8:1			0		1.0
6:1			1:1			0		1.0
7:1			2:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0

Alignment 3759
To guarantee selected face tracks representing different persons , for one channel , only face tracks of one shot was picked .
To guarantee selected face tracks representing different people , only the face tracks from one shot were picked for one channel .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			3		1.0
8:1			8:1			0		1.0
9:1			13:1			0		1.0
11:1			14:1			0		1.0
12:1			15:1			0		1.0
14:1			17:1			0		1.0
15:1			18:1			0		1.0
16:2			19:1			3		1.0
18:1			9:1			0		1.0
19:1			10:1			0		1.0
20:1			11:1			0		1.0
21:1			21:1			0		1.0

Alignment 3760
As a result , there are 5 ,126 faces of 19 face tracks picked from the 7 channels corresponding to 19 different persons .
As a result , there were 5 ,126 faces of 19 face tracks selected from the seven channels corresponding to 19 different people .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			2		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			3		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			2		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			3		1.0
23:1			23:1			0		1.0

Alignment 3761
Note that , the system does not know the identity of these faces .
Note that the system did not know the identity of these faces .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0

Alignment 3762
It only knows any two face tracks represent different persons .
It only knew any two face tracks represented different people .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			2		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			1		1.0
8:1			8:1			0		1.0
9:1			9:1			3		1.0
10:1			10:1			0		1.0

Alignment 3763
The number of faces of these face tracks is shown in Figure \REF .
The number of faces in these face tracks is shown in Figure \REF .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 3764
Using these face tracks , We generated 133 labeled sets described in Section \REF and used them for training the relevance classifier .
We generated the 133 labeled sets described in Section \REF using these face tracks and used them to train the relevance classifier .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			5:1			0		1.0
1:1			6:1			0		1.0
3:1			7:1			0		1.0
4:1			8:1			0		1.0
5:1			9:1			0		1.0
6:1			10:1			0		1.0
7:1			11:1			0		1.0
8:1			12:1			0		1.0
9:1			13:1			0		1.0
11:1			1:1			0		1.0
12:1			2:1			0		1.0
13:1			3:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:2			17:2			3		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 3765
Yahoo News Images : This dataset consists of approximately half a million news photos and captions from Yahoo News collected over a period of roughly two years \CITE .
Yahoo News Images : This dataset consists of approximately half a million news photos and captions from Yahoo News collected over a period of roughly two years \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 3766
Using person names as queries , we applied simple string search to the captions this dataset to return a list of faces for each queried name .
Using people�fs names as queries , we applied a simple string search to the captions in this dataset to return a list of faces for each queried name .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0

Alignment 3767
We used 23 names of celebrities such as George W .
We used 23 names of celebrities such as George W .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 3768
Bush , Vladimir Putin , Ziang Jemin , Tony Blair , and Abdullah Gul .
Bush , Vladimir Putin , Ziang Jemin , Tony Blair , and Abdullah Gul .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 3769
These names are widely used in experiments such as \CITE .
These names have widely been used in experiments \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			3		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0

Alignment 3770
In total , 9 ,136 faces were retrieved in which 3 ,909 faces were relevant .
A total of 9 ,136 faces were retrieved in which 3 ,909 faces were relevant .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 3771
On average , The accuracy was \MATH .
The accuracy was \MATH on average .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			3:1			0		1.0
1:1			4:1			0		1.0
2:1			5:1			0		1.0
3:1			6:1			0		1.0
5:1			1:1			0		1.0
6:1			7:1			0		1.0

Alignment 3772
Google Images : We used the same set of person names used in Yahoo News Images dataset and put to Google Image Search Engine .
Google Images : We used the same set of people�fs names used in the Yahoo News Images dataset and input them into the Google Image Search Engine .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0
26:1			23:1			0		1.0
27:1			24:1			0		1.0

Alignment 3773
For each query , We crawled a maximum of 500 images from URLs returned by Google .
We crawled a maximum of 500 images from URLs returned by Google for each query .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			4:1			0		1.0
1:1			5:1			0		1.0
2:1			6:1			0		1.0
3:1			7:1			0		1.0
4:1			8:1			0		1.0
5:1			9:1			0		1.0
6:1			10:1			0		1.0
7:1			11:1			0		1.0
8:1			12:1			0		1.0
9:1			13:1			0		1.0
10:1			14:1			0		1.0
11:1			15:1			0		1.0
13:1			1:1			0		1.0
14:1			2:1			0		1.0
15:1			16:1			0		1.0

Alignment 3774
In total , 9 ,516 faces were extracted in which 5 ,816 faces were relevant .
A total of 9 ,516 faces were extracted in which 5 ,816 faces were relevant .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 3775
On average , The accuracy was \MATH .
The accuracy was \MATH on average .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			3:1			0		1.0
1:1			4:1			0		1.0
2:1			5:1			0		1.0
3:1			6:1			0		1.0
5:1			1:1			0		1.0
6:1			7:1			0		1.0

Alignment 3776
The TRECVID dataset was used for training the generic classifier .
The TRECVID dataset was used for training the generic classifier .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 3777
The datasets , Yahoo News Images and Google Images as shown in Figure \REF , were used for testing .
The datasets for Yahoo News Images and Google Images , as shown in Figure \REF , were used for testing .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			2:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0

Alignment 3778
We used the Viola-Jones face detector \CITE to detect frontal faces in images and video frames .
We used the Viola-Jones face detector \CITE to detect frontal faces in images and video frames .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 3779
To group faces belonging to one person in one video shot , We simply used a similar technique described in \CITE .
We simply used a similar technique to that described in \CITE to group faces belonging to one person in one video shot .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			12:1			0		1.0
1:1			13:1			0		1.0
2:1			14:1			0		1.0
3:1			15:1			0		1.0
4:1			16:1			0		1.0
5:1			17:1			0		1.0
8:1			18:1			0		1.0
9:1			19:1			0		1.0
10:1			20:1			0		1.0
12:1			1:1			0		1.0
13:1			2:1			0		1.0
14:1			3:1			0		1.0
15:1			4:1			0		1.0
16:1			5:1			0		1.0
17:1			6:1			0		1.0
18:1			7:1			0		1.0
19:1			8:1			0		1.0
20:1			9:1			0		1.0
21:1			10:1			0		1.0
22:1			21:1			0		1.0

Alignment 3780
Using the prior knowledge that faces of the same person in consecutive frames do not change much in locations and appearance , the technique used tracked points to robustly associate these faces into face tracks with the precision of \MATH .
Using prior knowledge that faces of the same person in consecutive frames do not change much in locations and appearance , the technique used tracked points to robustly associate these faces in face tracks with a precision of \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0
32:1			33:1			0		1.0
33:1			34:1			0		1.0
34:1			35:1			0		1.0
36:1			37:1			0		1.0
37:1			38:1			0		1.0
38:1			39:1			0		1.0
39:1			40:1			0		1.0

Alignment 3781
Once faces were extracted , we used the code provided by the authors \CITE to extract features .
Once faces were extracted , we used the code provided by the authors \CITE to extract features .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 3782
Each face is then represented as a point in a very high dimensional feature space .
Each face was then represented as a point in a very high dimensional feature space .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			2		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 3783
Specifically , for each face , 9 facial feature points were detected , and 4 more facial feature points were inferred from these 9 points .
Nine facial-feature points were specifically detected for each face , and four more facial feature points were inferred from these nine points .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			9:1			0		1.0
3:1			10:1			0		1.0
5:1			11:1			0		1.0
6:1			2:1			0		1.0
7:1			3:1			0		1.0
8:1			4:1			0		1.0
9:1			5:1			0		1.0
10:1			13:1			0		1.0
11:1			14:1			2		1.0
12:1			15:1			0		1.0
13:1			16:1			0		1.0
14:1			17:1			0		1.0
15:1			18:1			0		1.0
16:1			19:1			0		1.0
17:1			20:1			0		1.0
18:1			21:1			0		1.0
19:1			22:1			0		1.0
20:2			23:2			3		1.0
22:1			25:1			0		1.0

Alignment 3784
In total , There were 13 feature points from which features are extracted .
There were a total of 13 feature points from which features were extracted .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			3:1			0		1.0
1:2			11:1			3		1.0
3:1			1:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			4:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 3785
The features are intensity values lying within the circle with radius of 15 pixels .
The features were intensity values lying within a circle with a radius of 15 pixels .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			2		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:2			7:2			3		1.0
9:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0

Alignment 3786
The output feature has 13x149 = 1 ,937 dimensions .
The output feature had 13x149 = 1 ,937 dimensions .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			2		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 3787
Figure \REF shows illustration of this feature .
Figure \REF illustrates this feature .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			3		1.0
3:1			5:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0

Alignment 3788
We evaluated the retrieval performance with measures that are commonly used in information retrieval , such as precision , recall , and average precision .
We evaluated the efficiency of retrieval with measures that are commonly used in information retrieval , such as precision , recall , and average precision .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
5:1			3:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0

Alignment 3789
Given a queried person and letting \MATH be the total number of faces returned , \MATH the number of relevant faces , and \MATH the total number of relevant faces , recall and precision can be calculated as follows : \MATH .
Given a queried person and letting \MATH be the total number of faces returned , \MATH the number of relevant faces , and \MATH the total number of relevant faces , recall and precision can be calculated as : \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			39:1			0		1.0
39:1			40:1			0		1.0
40:1			41:1			0		1.0

Alignment 3790
Precision and recall only evaluate the quality of an unordered set of retrieved faces .
Precision and recall were only used to evaluate the quality of an unordered set of retrieved faces .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			0		1.0
7:1			4:1			0		1.0
8:1			5:1			0		1.0
9:1			6:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0

Alignment 3791
To evaluate ranked lists in which both recall and precision are taken into account , the average precision is usually used .
Average precision is usually used to evaluate ranked lists in which both recall and precision are taken into account .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			17:1			0		1.0
2:1			18:1			0		1.0
3:1			19:1			0		1.0
4:1			20:1			0		1.0
6:1			1:1			0		1.0
7:1			2:1			0		1.0
8:1			3:1			0		1.0
9:1			4:1			0		1.0
10:1			5:1			0		1.0
11:1			6:1			0		1.0
12:1			7:1			0		1.0
13:1			8:1			0		1.0
14:1			9:1			0		1.0
15:1			10:1			0		1.0
16:1			11:1			0		1.0
17:1			12:1			0		1.0
18:1			13:1			0		1.0
19:1			21:1			0		1.0

Alignment 3792
The average precision is computed by taking the average of the interpolated precision measured at the 11 recall levels of 0 .0 , 0 .1 , 0 .2 , . . . , 1 .0 .
The average precision is computed by taking the average of the interpolated precision measured at 11 recall levels of 0 .0 , 0 .1 , 0 .2 , . . . , 1 .0 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0
31:1			32:1			0		1.0
32:1			33:1			0		1.0
33:1			34:1			0		1.0
34:1			35:1			0		1.0

Alignment 3793
The interpolated precision \MATH at a certain recall level \MATH is defined as the highest precision found for any recall level \MATH :
The interpolated precision , \MATH , at a certain recall level , \MATH , is defined as the highest precision found for any recall level \MATH :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			0		1.0
6:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
12:1			9:1			0		1.0
14:1			10:1			0		1.0
15:1			11:1			0		1.0
16:1			12:1			0		1.0
17:1			13:1			0		1.0
18:1			14:1			0		1.0
19:1			15:1			0		1.0
20:1			16:1			0		1.0
21:1			17:1			0		1.0
22:1			18:1			0		1.0
23:1			19:1			0		1.0
24:1			20:1			0		1.0
25:1			21:1			0		1.0
26:1			22:1			0		1.0

Alignment 3794
In addition , to evaluate the performance of multiple queries , we used mean average precision , which is the mean of average precisions computed from queries .
In addition , we used the mean average precision to evaluate the performance of multiple queries , which is the mean of average precisions computed from queries .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			11:1			0		1.0
4:1			12:1			0		1.0
5:1			19:1			0		1.0
6:1			13:1			0		1.0
7:1			14:1			0		1.0
8:1			15:1			0		1.0
9:1			3:1			0		1.0
10:1			4:1			0		1.0
11:1			5:1			0		1.0
12:1			6:1			0		1.0
13:1			7:1			0		1.0
14:1			8:1			0		1.0
15:1			9:1			0		1.0
16:1			10:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0

Alignment 3795
In this experiment , We compare the MAP performance of the following systems testing on YahooNews Images :
We compared the performance of the Maximum A-Posteriori ( MAP ) algorithm in seven systems in this experiment by testing it on YahooNews Images :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			4:1			0		1.0
1:1			5:1			1		1.0
2:1			6:1			0		1.0
3:1			8:1			0		1.0
4:1			9:1			0		1.0
5:1			10:1			0		1.0
9:1			7:1			0		1.0
14:1			12:1			0		1.0
16:1			1:1			0		1.0
17:1			2:1			0		1.0
19:1			13:1			0		1.0
21:1			14:1			0		1.0
22:1			15:1			0		1.0
23:1			16:1			0		1.0
24:1			17:1			0		1.0

Alignment 3796
-DistScore-TrainGoogleImages : The training set is the set of annotated faces returned by Google Images Search for 23 person names .
-DistScore-TrainGoogleImages : The training set was the set of annotated faces returned by Google Images Search for 23 people�fs names .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:2			5:2			3		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 3797
The feature vector is computed using \MATH .
The feature vector was computed using \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			2		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 3798
-NNScore-TrainGoogleImages : The training set is the same as DistScore-TrainGoogleImages .
-NNScore-TrainGoogleImages : The training set was the same as DistScore-TrainGoogleImages .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:2			5:2			3		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 3799
The feature vector is computed using \MATH .
The feature vector was computed using \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			2		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 3800
DistScore-TrainTRECVID : The feature vector is computed using .
DistScore-TrainTRECVID : The feature vector was computed using .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			2		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 3801
The training set is the set of annotated faces artificially generated by our method described in Section \REF .
The training set was the set of annotated faces artificially generated with our method described in Section \REF .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:2			3:2			3		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 3802
-NNScore-TrainTRECVID : The training set is the same as DistScore-TrainTRECVID .
-NNScore-TrainTRECVID : The training set was the same as DistScore-TrainTRECVID .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:2			5:2			3		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 3803
The feature vector is computed using \MATH .
The feature vector was computed using \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			2		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 3804
-Krapac[11]-TrainGoogleImages : The training set is the same as DistScore-TrainGoogleImages .
-Krapac[11]-TrainGoogleImages : The training set was the same as DistScore-TrainGoogleImages .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:2			5:2			3		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 3805
We re-implemented the method proposed by Krapac et al . \CITE for extracting query-dependent feature .
We re-implemented the method proposed by Krapac et al. \CITE of extracting the query-dependent feature .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			10:1			0		1.0
11:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 3806
Since this method was proposed to handle images , not for faces , we modified it for handling faces .
Since this method was proposed to handle images , not faces , we modified it to handle faces .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:2			16:2			3		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0

Alignment 3807
Specifically , Each face is represented as a bag of visual words .
Each face was specifically represented as a bag of visual words .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			2:1			0		1.0
1:1			3:1			0		1.0
2:1			4:1			2		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0

Alignment 3808
We used 13 facial feature points detected in each face and their descriptors using pixel intensity as visual words .
We used 13 facial-feature points detected in each face and their descriptors using pixel intensity as visual words .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0

Alignment 3809
The codebook is formed by clustering all visual words extracted from all faces of the training set into 200 clusters .
The codebook was formed by clustering all visual words extracted from all faces of the training set into 200 clusters .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			2		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 3810
top-$k$ visual words strongly related to the returned faces of each query and the binary feature vector are computed as described in \CITE .
The top-$k$ visual words strongly related to the returned faces of each query and the binary feature vector were computed as described in \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			0:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			2		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0

Alignment 3811
-Mensink[15]-GaussianModels : This method proposed by Mensink et al . \CITE models the returned faces by using two Gaussians , one for the faces relevant to the target person and one for the remaining faces .
-Mensink[15]-GaussianModels : This method proposed by Mensink et al. \CITE modeled the returned faces by using two Gaussians , the first for the faces relevant to the target person and the second for the remaining faces .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			1		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			32:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
32:1			31:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0

Alignment 3812
-Mensink[15]-Friends : This method proposed by Mensink et al . \CITE uses linear discriminant analysis to train a specific classifier for each query .
-Mensink[15]-Friends : This method proposed by Mensink et al. \CITE used linear discriminant analysis to train a specific classifier for each query .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			1		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0

Alignment 3813
This method uses detected person names in captions associated with faces for query expansion to model faces of the target person 's friends .
This method used detected people�fs names in captions associated with faces for query expansion to model faces of the target person 's friends .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			1		1.0
3:1			3:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 3814
The Methods such as Mensink[15]-GaussianModels and Mensink[15]-Friends are the state of the art methods that learn a specific classifier for each query .
Methods such as Mensink[15]-GaussianModels and Mensink[15]-Friends are state-of-the-art that learn a specific classifier for each query .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			1:1			0		1.0
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
8:1			14:1			0		1.0
9:1			15:1			0		1.0
10:1			16:1			0		1.0
11:1			17:1			0		1.0
12:1			18:1			0		1.0
13:1			19:1			0		1.0
14:1			20:1			0		1.0
15:1			21:1			0		1.0
16:1			22:1			0		1.0

Alignment 3815
The method Krapac[11]-TrainGoogleImages is similar to our method in which one generic classifier is trained in advance and then is used for new queries .
Krapac[11]-TrainGoogleImages is similar to our method in which one generic classifier is trained in advance and then used for new queries .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			2:1			0		1.0
1:1			3:1			0		1.0
2:1			4:1			0		1.0
3:1			5:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			20:1			0		1.0
18:1			21:1			0		1.0
19:1			22:1			0		1.0
20:1			23:1			0		1.0
21:1			24:1			0		1.0

Alignment 3816
Figure \REF shows the performance comparison of these systems when testing on YahooNews Images dataset .
Figure \REF compares the performance of these systems when they were tested on the YahooNews Images dataset .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
11:1			10:1			1		1.0
12:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0

Alignment 3817
As for systems such as DistScore-TrainGoogleImages , NNScore-TrainGoogleImages , DistScore-TrainTRECVID , and NNScore-TrainTRECVID , the curves show the correlation between the performance and the number of features .
The curves plot the correlation between performance and the number of features for systems such as DistScore-TrainGoogleImages , NNScore-TrainGoogleImages , DistScore-TrainTRECVID , and NNScore-TrainTRECVID .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			15:1			0		1.0
3:1			17:1			0		1.0
4:1			18:1			0		1.0
5:1			19:1			0		1.0
6:1			21:1			0		1.0
7:1			22:1			0		1.0
8:1			23:1			0		1.0
9:1			24:1			0		1.0
10:1			25:1			0		1.0
11:1			26:1			0		1.0
12:1			1:1			0		1.0
13:1			2:1			0		1.0
14:1			3:1			0		1.0
15:1			4:1			0		1.0
16:1			5:1			0		1.0
17:1			6:1			0		1.0
18:1			7:1			0		1.0
19:1			8:1			0		1.0
20:1			9:1			0		1.0
21:1			10:1			0		1.0
22:1			11:1			0		1.0
23:1			12:1			0		1.0
24:1			27:1			0		1.0

Alignment 3818
-DistScore is significantly better than that of NNScore .
-DistScore performed significantly better than NNScore .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0

Alignment 3819
-The performance of DistScore and NNScore are not affected by selecting the number of features .
-The performance of DistScore and NNScore was not affected by selecting the number of features .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			2		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 3820
Therefore , we can use small number of features for reducing the computational cost .
Therefore , we could use small numbers of features to reduce the computational cost .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:2			3:2			3		1.0
5:1			5:1			0		1.0
6:2			6:2			3		1.0
8:1			8:1			0		1.0
9:2			9:2			3		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 3821
-The performance of the system using the training data generated artificially by our method is comparable with that of the system using the training data returned by search engines .
-The performance of the system using training data generated artificially with our method was comparable to that of the system using training data returned by search engines .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			16:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			2		1.0
14:1			15:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0
24:1			26:1			0		1.0
25:1			27:1			0		1.0
26:1			28:1			0		1.0
27:1			29:1			0		1.0

Alignment 3822
-Our proposed method DistScore-TrainTRECVID has comparable performance to the state of the art method in specific classifier-based approach Mensink[15]-Friends .
-The method of DistScore-TrainTRECVID we propose performed comparably to the state-of-the-art method in the specific classifier-based approach of Mensink[15]-Friends .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			2:1			0		1.0
2:1			10:1			0		1.0
3:1			3:1			0		1.0
4:2			1:1			3		1.0
6:1			4:1			3		1.0
7:1			5:1			1		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			11:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 3823
It outperforms the method using only visual information Mensink[15]-GaussianModels .
It outperformed the method where only visual information was used , i.e. , Mensink[15]-GaussianModels .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			1		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
13:1			8:1			0		1.0
14:1			9:1			0		1.0

Alignment 3824
-Our proposed method DistScore-TrainTRECVID outperforms the method proposed by Krapac et al . customized for handling faces .
-Our proposed method DistScore-TrainTRECVID outperformed the method proposed by Krapac et al. , which was customized to handle faces .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			1		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
15:1			13:1			0		1.0
16:2			14:2			3		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0

Alignment 3825
As shown in Figure \REF , DistScore-TrainTRECVID outperforms original ranking of Google Images Search Engine if using from 20 to 50 features .
As seen in Figure \REF , DistScore-TrainTRECVID outperformed the original ranking of the Google Images Search Engine if from 20 to 50 features were used .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			1		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
25:1			22:1			0		1.0

Alignment 3826
The result of DistScore-TrainTRECVID on YahooNews Images set and Google Images set indicates that the relevance classifier of our proposed method is able to generalize well on different queries and independent with underlying ranking algorithms of search engines .
The results for DistScore-TrainTRECVID on the YahooNews Images set and Google Images set indicate that the relevance classifier with our proposed method was able to generalize well on different queries and was independent of underlying ranking algorithms used in search engines .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			1		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			14:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:2			12:2			3		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			31:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			2		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
32:1			30:1			0		1.0
33:1			2:1			0		1.0
34:1			32:1			0		1.0
35:1			33:1			0		1.0
36:1			34:1			0		1.0
39:1			36:1			0		1.0
40:1			37:1			0		1.0
41:1			38:1			0		1.0

Alignment 3827
Figure \REF shows an example of re-ranking result of top-30 faces for the query John Paul that is one of the most difficult cases of the YahooNews Images set .
Figure \REF shows an example of re-ranking results for the top-30 faces for the query John Paul , which is one of the most difficult cases in the YahooNews Images set .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			1		1.0
8:1			11:1			0		1.0
9:1			12:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
13:1			25:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
18:4			16:4			3		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0

Alignment 3828
The result clearly shows that our proposed method outperforms the other state of the art methods .
The results clearly demonstrate that our proposed method outperformed the other state-of-the-art methods .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			1		1.0
2:1			2:1			0		1.0
3:2			3:2			3		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			1		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			15:1			0		1.0
13:1			16:1			0		1.0

Alignment 3829
Our query-dependent feature is based on nearest neighbors of the images in the returned image set that usually have complexity of \MATH , where \MATH is the total number of images in the set .
Our query-dependent feature was based on the nearest neighbors of images in the returned image set that usually have a complexity of \MATH , where \MATH is the total number of images in the set .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			2		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			9:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0

Alignment 3830
However , recent studies on indexing techniques such as \MATH -d tree , locality sensitive hashing ( LSH ) , and SASH \CITE can speed up the nearest neighbor search significantly .
However , recent studies on indexing techniques such as \MATH -d tree , locality sensitive hashing ( LSH ) , and a Self Adaptive Set of Histograms ( SASH ) \CITE could significantly speed up the nearest neighbor search .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
28:1			21:1			0		1.0
30:1			22:1			0		1.0
31:1			23:1			3		1.0
32:1			30:1			0		1.0
33:1			24:1			0		1.0
34:1			25:1			0		1.0
35:1			26:1			0		1.0
36:1			27:1			0		1.0
37:1			28:1			0		1.0
38:1			29:1			0		1.0
39:1			31:1			0		1.0

Alignment 3831
For example , as described in \CITE , the complexity of fast lookup of $k$ approximate nearest neighbors is \MATH \CITE .
For example , the complexity of the fast lookup of $k$ approximate nearest neighbors is \MATH \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			8:1			0		1.0
4:1			9:1			0		1.0
5:1			10:1			0		1.0
7:1			11:1			0		1.0
8:1			12:1			0		1.0
9:1			13:1			0		1.0
10:1			14:1			0		1.0
11:1			15:1			0		1.0
12:1			16:1			0		1.0
13:1			17:1			0		1.0
14:1			18:1			0		1.0
15:1			19:1			0		1.0
16:1			20:1			0		1.0
17:1			21:1			0		1.0

Alignment 3832
Studying other techniques to speedup the query-feature extraction process is our next step in future work .
Studying other techniques to speed up the process of query-feature extraction is our next step in future work .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
6:1			5:1			0		1.0
7:1			8:1			0		1.0
9:1			6:1			0		1.0
10:1			7:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0

Alignment 3833
b</subsection>
376
Line2Start:Length	Line1Start:Length	Module		Score

Alignment 3834
We have presented a novel method for re-ranking face images returned by existing search engines .
We have presented a novel method of re-ranking face images returned by existing search engines .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:2			5:2			3		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 3835
Instead of training a specific classifier for each new query , we train only one generic classifier and use it for ranking new queries .
Instead of training a specific classifier for each new query , we only trained one generic classifier and used it for ranking new queries .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			1		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 3836
This helps to make the ranking application more scalable .
This helped make the ranking application more scalable .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			1		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0

Alignment 3837
To train the generic classifier , We propose a simple unsupervised method to obtain a large number of labeled faces from video archives .
We propose a simple unsupervised method to train the generic classifier to obtain a large number of labeled faces from video archives .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			6:1			0		1.0
1:1			7:1			0		1.0
2:1			8:1			0		1.0
3:1			9:1			0		1.0
4:1			10:1			0		1.0
5:1			11:1			0		1.0
6:1			12:1			0		1.0
7:1			1:1			0		1.0
8:1			2:1			0		1.0
9:1			3:1			0		1.0
10:1			4:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0

Alignment 3838
It uses temporal information to group faces belonging to one person in one shot into one track .
It uses temporal information to group faces belonging to one person in one shot into one track .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 3839
Several heuristics are employed to guarantee that a subset of face tracks has the correct labels used in the training process .
Several heuristics are employed to guarantee that a subset of face tracks has the correct labels used in the training process .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 3840
Experiments shown that although our method is unsupervised and independent with underlying algorithms of existing search engines but successfully learns visual consistency among returned faces to boosts retrieval performance .
Experiments revealed that although our method is unsupervised and independent of underlying algorithms in existing search engines , it successfully learned visual consistency between returned faces to boost efficiency of retrieval .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:2			1:2			3		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			13:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			1		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			3		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			1		1.0
30:1			27:1			0		1.0
31:1			29:1			0		1.0

Alignment 3841
Enhancing mathematical search with names of formulas
Enhancing mathematical searches with names of formulas
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			1		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0

Alignment 3842
We present a method to enhance the performance of a mathematical search system in this paper .
We present a method to enhance the performance of a mathematical search system .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			16:1			0		1.0

Alignment 3843
Targeting to mathematical formulas that appear in natural language documents , we collect the names of formulas from the surrounding text , and incorpo-rate the correspondence to the search system 's database .
By targeting mathematical formulas that appear in natural language documents , we collect the names of formulas from the surrounding text and incorporate the correspondence into the search system 's database .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			22:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0
31:1			32:1			0		1.0

Alignment 3844
E ectiveness of the proposed approach is shown through experiments using Wikipedia mathematical articles and Wolfram Functions Site data sets .
The effectiveness of the approach is demonstrated through experiments using Wikipedia mathematical articles and Wolfram Functions Site data sets .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			2		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0

Alignment 3845
In the current digital environment , the mathematical content being published on the Web is increasing day by day . While more and more mathematical contents being available on the Web , retrieving mathematical contents becomes an important issue for many users .
The mathematical content being published on the Web is increasing day by day , and retrieving mathematical content has become an important issue for many users .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			7:1			0		1.0
2:1			8:1			0		1.0
3:1			9:1			0		1.0
4:1			10:1			0		1.0
5:1			11:1			0		1.0
6:1			12:1			0		1.0
7:1			13:1			0		1.0
8:1			14:1			0		1.0
9:1			15:1			0		1.0
10:1			16:1			0		1.0
11:1			17:1			0		1.0
12:1			18:1			0		1.0
13:1			5:1			0		1.0
14:1			22:1			0		1.0
15:1			32:1			0		1.0
16:1			33:1			0		1.0
17:2			34:1			3		1.0
19:1			35:1			1		1.0
20:1			36:1			0		1.0
21:1			37:1			0		1.0
22:1			38:1			0		1.0
23:1			39:1			0		1.0
24:1			40:1			0		1.0
25:1			41:1			0		1.0
26:1			42:1			0		1.0

Alignment 3846
Teach-ers , students , researchers do need to gain access to mathematical resources for teaching , studying , or obtaining updated information for research and development .
Teachers , students , and researchers need better access to mathematical resources for teaching , studying , and obtaining information for research and development .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			24:1			0		1.0
5:1			4:1			0		1.0
6:1			6:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
18:1			19:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
23:1			25:1			0		1.0
24:1			26:1			0		1.0

Alignment 3847
Therefore , users need specialized search systems to nd the formula that is relevant to their requirements .
Moreover , users need specialized search systems to find formulas that are relevant to their needs .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			10:1			1		1.0
10:1			11:1			0		1.0
11:1			12:1			2		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			3		1.0
16:1			17:1			0		1.0

Alignment 3848
Internet search engines are able to detect some particular keywords in mathematical formula but they mostly fail to recognize mathematical symbols and constructs such as integral sym-bols , square root symbols , fractions , or matrices .
Internet search engines can detect particular keywords in mathematical formulas but they mostly fail at recognizing mathematical symbols and constructs such as integral and square root symbols , fractions , and matrices .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:3			3		1.0
4:1			6:1			0		1.0
5:1			8:1			0		1.0
6:1			9:1			0		1.0
7:1			10:1			0		1.0
8:1			11:1			0		1.0
9:1			12:1			1		1.0
10:1			13:1			0		1.0
11:1			14:1			0		1.0
12:1			15:1			0		1.0
13:1			16:1			0		1.0
15:1			18:1			1		1.0
16:1			19:1			0		1.0
17:1			20:1			0		1.0
18:1			21:1			0		1.0
19:1			22:1			0		1.0
20:1			23:1			0		1.0
21:1			24:1			0		1.0
22:1			25:1			0		1.0
24:1			28:1			0		1.0
25:1			29:1			0		1.0
26:1			30:1			0		1.0
27:1			31:1			0		1.0
28:1			32:1			0		1.0
29:1			33:1			0		1.0
31:1			35:1			0		1.0
32:1			36:1			0		1.0

Alignment 3849
There exist some mathematical-dedicated search engines available on the Internet .
There are some mathematically oriented search engines on the Internet .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			2		1.0
2:1			2:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 3850
Although such engines provide more accurate and relevant results , they usually do not provide enough information for the user .
Although such engines provide more accurate and relevant results , they usually do not provide enough information for the user .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 3851
Furthermore , these systems do not take into account the semantics of mathematical formulas revealed by surrounding natural language text , like the name of the formula and its variables' descrip-tion .
Furthermore , these systems do not take into account the semantics of mathematical formulas as revealed by the surrounding natural language text , e.g. , the formula�fs name or the description of its variables .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			22:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
27:1			23:1			0		1.0
29:1			25:1			0		1.0
31:1			24:1			0		1.0
32:1			28:1			0		1.0
33:1			29:1			1		1.0
34:1			31:1			0		1.0

Alignment 3852
The Digital Library of Mathematical functions ( DLMF ) project is a mathematical database available on the Web [8] .
The Digital Library of Mathematical Functions ( DLMF ) project is a mathematical database available on the Web [8] .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 3853
This site provides a major resource of mathematical reference data for special formulas and their applications .
This site provides a major resource of mathematical reference data for special formulas and their applications .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 3854
But full mathematical search is still not available .
But even this site does not provide a full mathematical search .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			5:1			2		1.0
4:1			4:1			3		1.0
5:1			6:1			0		1.0
8:1			1:1			0		1.0
9:1			2:1			0		1.0
10:1			3:1			0		1.0
11:1			8:1			0		1.0

Alignment 3855
Other systems that support mathematical search are MathFind [4] , MathWebSearch [3] .
Other systems that support mathematical searches are MathFind [4] , MathWebSearch [3] .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			1		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 3856
These systems , however , provide neither similarity structures nor semantic meanings of the formulas .
These systems , however , provide neither similarity structures nor semantic meanings of their formulas .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 3857
The Wolfram Functions Site [7] contains large mathe-matical formulas and also provides a semantics search for mathematical formulas .
The Wolfram Functions Site [7] contains a large number of mathematical formulas and also provides a semantic search for them .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
10:1			16:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			1		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
20:1			18:1			0		1.0

Alignment 3858
This site and some recent works done by Adeel et al. [2] and Yokoi and Aizawa [1] propose similarity search methods based on MathML but these works do not make use of the semantics of the formulas' surrounding text , which is considered to be important information sources .
This site and some recent work done by Adeel et al. [2] and Yokoi and Aizawa [1] employ similarity search methods based on MathML but they do not make use of the semantics of the formulas' surrounding text . //[ ? ? propose is unclear in the sense of a website .]
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			1		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			30:2			3		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
31:1			32:1			0		1.0
32:1			33:1			0		1.0
33:1			34:1			0		1.0
34:1			35:1			0		1.0
35:1			36:1			0		1.0
36:1			37:1			0		1.0
37:1			38:1			0		1.0
38:1			48:1			0		1.0
42:1			17:1			0		1.0
43:1			41:1			0		1.0
47:3			40:1			3		1.0

Alignment 3859
The work presented in this paper focuses on retrieving mathematical formulas on the Web using mathematical expressions and the surrounding natural language text .
The work presented in this paper focuses on retrieving mathematical formulas on the Web by using mathematical expressions and the surrounding natural language text .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0

Alignment 3860
We describe here in detail our work toward creating a mathematical database that contains for-mulas , their names , their variables' descriptions and other related information .
We describe our work toward creating a mathematical database that contains formulas , their names , variable descriptions , and other related information .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			5:1			0		1.0
3:1			6:1			0		1.0
4:1			7:1			0		1.0
5:1			8:1			0		1.0
6:1			9:1			0		1.0
7:1			10:1			0		1.0
8:1			11:1			0		1.0
9:1			12:1			0		1.0
10:1			13:1			0		1.0
12:1			15:1			0		1.0
13:1			16:1			0		1.0
14:1			17:1			0		1.0
15:1			18:1			0		1.0
16:1			20:1			1		1.0
17:1			21:1			0		1.0
19:1			22:1			0		1.0
20:1			23:1			0		1.0
21:1			24:1			0		1.0
22:1			25:1			0		1.0
23:1			26:1			0		1.0

Alignment 3861
We also implement a mathematical search system that use this information as its base knowledge .
We implemented a mathematical search system that uses this information as its base knowledge .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			2:1			1		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			1		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0

Alignment 3862
This information is very helpful when performing mathematical search by reducing the need for formula input and solving the notational variation problem where mathematically equivalent formulas follow di erent notations .
This information is very helpful when performing mathematical search by reducing the need for formula input and solving the notational variation problem where mathematically equivalent formulas follow different notations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0

Alignment 3863
Relations between formulas and their name could also be used to correct errors in mathematical OCR systems , such as Infty [5] .
The relationship between formulas and their names can also be used to correct errors in mathematical OCR systems , such as Infty [5] .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			1		1.0
7:2			6:2			3		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0

Alignment 3864
It also provides opportunities to make mathematical better understandable and usable for di erent groups of people with disabilities .
It also provides opportunities to make mathematics better understandable and usable for people with disabilities .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			1		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			16:1			0		1.0
13:1			17:1			0		1.0
14:1			18:1			0		1.0
15:1			19:1			0		1.0

Alignment 3865
The remainder of this paper is organized as follow : In section 2 , we present an overview of the proposed framework .
The remainder of this paper is organized as follows : we present an overview of our framework in section 2 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			1		1.0
9:1			9:1			0		1.0
10:1			14:1			0		1.0
11:1			15:1			0		1.0
12:1			16:1			0		1.0
13:1			17:1			0		1.0
14:1			18:1			0		1.0
16:1			21:1			0		1.0
18:1			11:1			0		1.0
19:1			12:1			0		1.0
20:1			22:1			0		1.0

Alignment 3866
We then describe the results of our experiments in section 3 .
We then describe the results of our experiments in section 3 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 3867
Section 4 concludes the paper and gives avenues for future works .
Section 4 concludes the paper and gives avenues of future study .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:2			8:2			3		1.0
10:1			10:1			2		1.0
11:1			11:1			0		1.0

Alignment 3868
Mathematical formulas on the Web has many di erent formats , some of them are LaTeX , and the Mathematical Markup Language ( MathML ) [6] .
Mathematical formulas on the Web have many different formats , e.g. , LaTeX and Mathematical Markup Language ( MathML ) [6] .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			2		1.0
6:1			6:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
11:1			16:1			0		1.0
12:1			15:1			0		1.0
13:1			17:1			0		1.0
14:1			19:1			0		1.0
15:1			20:1			0		1.0
16:1			21:1			0		1.0
17:1			22:1			0		1.0
18:1			23:1			0		1.0
19:1			24:1			0		1.0
20:1			25:1			0		1.0
21:1			26:1			0		1.0

Alignment 3869
This makes the search more dif-cult .
This diversity makes searches more difficult .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			1:1			0		1.0
3:1			3:1			1		1.0
4:1			4:1			0		1.0
6:1			6:1			0		1.0

Alignment 3870
In this paper , we use the presentation MathML format for mathematical formulas .
In this paper , we shall use the MathML format for mathematical formulas .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 3871
Formulas with other formats can be easily converted to MathML format using existing freely available tools .
Formulas with other formats can be easily converted to MathML format by using freely available tools .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 3872
For our works , we use LaTeXML Converter which is freely available at \URL .
For our work , we used LaTeXML Converter , which is freely available at \URL .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			1		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			1		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0

Alignment 3873
We automatically collected our mathematical formulas from Wikipedia and the Wolfram Functions Site .
We automatically collected our mathematical formulas from Wikipedia and the Wolfram Functions Site .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 3874
Figure 1 shows a page on mathematical section on Wikipedia and the information we retrieved on this site besides the mathematical formulas .
Figure 1 shows a page from a mathematical section on Wikipedia and the information we retrieved on this site , besides the mathematical formulas .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0

Alignment 3875
At this point , we use some heuristics to provide an adequate solution for matching mathematical formulas with their names .
We used heuristics to ensure adequate matching of mathematical formulas with their names .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			5:2			3		1.0
2:1			7:1			0		1.0
3:1			8:1			0		1.0
5:1			11:1			0		1.0
6:1			14:1			0		1.0
8:1			15:1			0		1.0
9:1			16:1			0		1.0
10:1			17:1			0		1.0
11:1			18:1			0		1.0
12:1			19:1			0		1.0
13:1			20:1			0		1.0

Alignment 3876
These heuristics are based on the type settings and distances between the name strings and formulas in the same page .
These heuristics are based on the type settings and distances between the name strings and formulas on the same page .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 3877
After collecting the mathematical formulas from these resources , we extract keywords for indexing .
After collecting mathematical formulas from these resources , we extracted keywords for indexing .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			1		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0

Alignment 3878
The keywords include formulas' names , operators , variables' names , and so on .
The keywords included formulas' names , operators , variables' names , and so on .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			1		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 3879
Our system allows two ways of searching : text content search and formula content search .
Our system allows two ways of searching : text content and formula content .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			15:1			0		1.0

Alignment 3880
In the rst case , users can use the extracted keywords for search , for example : " sin " , " Pythagorean " or " trigonometric functions " .
In a text content search , users search with extracted keywords , e.g. , " sin " , " Pythagorean " or " trigonometric functions " .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
4:1			12:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			13:1			0		1.0
13:1			20:1			0		1.0
14:1			17:1			0		1.0
15:1			18:1			0		1.0
16:1			19:1			0		1.0
18:1			21:1			0		1.0
19:1			22:1			0		1.0
20:1			23:1			0		1.0
21:1			24:1			0		1.0
22:1			25:1			0		1.0
23:1			26:1			0		1.0
24:1			27:1			0		1.0
25:1			28:1			0		1.0
26:1			29:1			0		1.0

Alignment 3881
In the second case , users can input the mathematical formulas directly , for example : \MATH .
In a formula content search , users directly input the formulas , for example : \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			11:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			10:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0

Alignment 3882
The system then looks for relevant formula names .
The system then looks for relevant formula names .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 3883
If found , it will return other information related with that formula .
If found , it will return other information related to that formula .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 3884
Else , it just looks for mathematical formulas which are similar to the input ( including formulas with similar structure ) .
If nothing matching is found , it looks for mathematical formulas which are similar to the input ( including formulas with a similar structure ) .
Line2Start:Length	Line1Start:Length	Module		Score
5:1			1:1			0		1.0
6:1			2:1			0		1.0
7:1			4:1			0		1.0
8:1			5:1			0		1.0
9:1			6:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0
22:1			18:1			0		1.0
23:1			19:1			0		1.0
24:1			20:1			0		1.0
25:1			21:1			0		1.0

Alignment 3885
Evaluate a mathematical search system is not an easy task because we do not have any standard for this task .
Evaluating a mathematical search system is not an easy task because we do not have any standard for this task .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			1		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 3886
The similarity between mathematical formulas is very subjective .
The similarity between mathematical formulas is very subjective .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 3887
In our work , we manually consider formulas with the same semantic meaning are relevant .
We consider that formulas with the same semantic meaning are relevant . //[The original is unclear the rewrite seems to be what you mean .]
Line2Start:Length	Line1Start:Length	Module		Score
1:1			6:1			0		1.0
3:1			7:1			0		1.0
4:1			8:1			0		1.0
5:1			9:1			0		1.0
6:1			10:1			0		1.0
7:1			11:1			0		1.0
8:1			12:1			0		1.0
9:1			13:1			0		1.0
10:1			14:1			0		1.0
11:1			15:1			0		1.0

Alignment 3888
For example , while searching for sin( a ) , we also consider the results containing arcsin or cosin .
For example , while searching for sin( a ) , we also consider results containing arcsin or cosin .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0

Alignment 3889
Our experiments were conducted on a collection of about 16 ,000 mathematical docu-ments on Wikipedia and about 155 ,000 mathematical formulas on the Wolfram Functions Site .
Our experiments were conducted on a collection of about 16 ,000 mathematical docu-ments on Wikipedia and about 155 ,000 mathematical formulas on the Wolfram Functions Site .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 3890
In order to show the e ect of linking the formula with its name , we also set up an experimental search system without using the formula 's names .
To show the effect of linking the formula with its name , we also set up an experimental search system without using the formula 's names .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			3:1			0		1.0
2:1			4:1			0		1.0
4:1			7:1			0		1.0
5:1			8:1			0		1.0
6:1			9:1			0		1.0
7:1			10:1			0		1.0
8:1			11:1			0		1.0
9:1			12:1			0		1.0
10:1			13:1			0		1.0
11:1			14:1			0		1.0
12:1			15:1			0		1.0
13:1			16:1			0		1.0
14:1			17:1			0		1.0
15:1			18:1			0		1.0
16:1			19:1			0		1.0
17:1			20:1			0		1.0
18:1			21:1			0		1.0
19:1			22:1			0		1.0
20:1			23:1			0		1.0
21:1			24:1			0		1.0
22:1			25:1			0		1.0
23:1			26:1			0		1.0
24:1			27:1			0		1.0
25:1			28:1			0		1.0
26:1			29:1			0		1.0

Alignment 3891
Table 1 shows top 5 of the searching results for the query \MATH .
Table 1 shows the top 5 search results for the query " sin( a + b ) " .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			6:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			7:1			1		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
18:1			13:1			0		1.0

Alignment 3892
As can be seen from the table , when the system associates the formulas with their names , it can provide more useful information to the user .
As can be seen , when the system associates the formulas with their names , it can provide more useful information to the user .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			7:1			0		1.0
5:1			8:1			0		1.0
6:1			9:1			0		1.0
7:1			10:1			0		1.0
8:1			11:1			0		1.0
9:1			12:1			0		1.0
10:1			13:1			0		1.0
11:1			14:1			0		1.0
12:1			15:1			0		1.0
13:1			16:1			0		1.0
14:1			17:1			0		1.0
15:1			18:1			0		1.0
16:1			19:1			0		1.0
17:1			20:1			0		1.0
18:1			21:1			0		1.0
19:1			22:1			0		1.0
20:1			23:1			0		1.0
21:1			24:1			0		1.0
22:1			25:1			0		1.0
23:1			26:1			0		1.0
24:1			27:1			0		1.0

Alignment 3893
The system also allows the user to input the formula 's name directly .
The system also allows the user to input the formula 's name directly .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 3894
Table 2 shows top 10 results with the query " Pythagorean " .
Table 2 shows the top 10 results for the query " Pythagorean " .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0

Alignment 3895
Note that at this time , when the user submits a query that does not match any function 's name in our database , the system can not return anything .
Note that at this time , when the user submits a query that does not match any function 's name in our database , the system can not return anything .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0

Alignment 3896
In this paper , we presented a new framework for mathematical search where links between formulas and their names are automatically detected from the target documents and then utilized in the search .
We presented a new framework for mathematical searches where links between formulas and their names are automatically detected in the target documents and then utilized in the search .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			5:1			0		1.0
2:1			6:1			0		1.0
3:1			7:1			0		1.0
4:1			8:1			0		1.0
5:1			9:1			0		1.0
6:1			10:1			0		1.0
7:1			11:1			1		1.0
8:1			12:1			0		1.0
9:1			13:1			0		1.0
10:1			14:1			0		1.0
11:1			15:1			0		1.0
12:1			16:1			0		1.0
13:1			17:1			0		1.0
14:1			18:1			0		1.0
15:1			19:1			0		1.0
16:1			20:1			0		1.0
17:1			21:1			0		1.0
19:1			23:1			0		1.0
20:1			24:1			0		1.0
21:1			25:1			0		1.0
22:1			26:1			0		1.0
23:1			27:1			0		1.0
24:1			28:1			0		1.0
25:1			29:1			0		1.0
26:1			30:1			0		1.0
27:1			31:1			0		1.0
28:1			32:1			0		1.0

Alignment 3897
Due to unavailability of the standard corpora to evaluate mathemat-ical search systems , our evaluation at this moment still remained subjective and limited .
Due to unavailability of a standard corpora to evaluate mathematical search systems , our evaluation at this moment remains subjective and limited .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			19:1			1		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0

Alignment 3898
We believe that our approach , by incorporating information other than the mathematical formulas themselves , showed promising results .
We believe that our approach of incorporating information other than the mathematical formulas themselves showed promising results .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0

Alignment 3899
The experimental results have shown how helpful this information provides to the users of mathematical search .
The experimental results showed how helpful this information is to mathematical search users .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:2			3		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			3		1.0
9:1			10:1			0		1.0
10:1			14:1			0		1.0
11:1			15:1			0		1.0
12:1			12:1			0		1.0
13:1			16:1			0		1.0

Alignment 3900
However , this is only a rst step , some important issues are left for future study .
However , this is only a first step ; many important issues are left for future study .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			7:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 3901
Using formula 's name is one way of taking into account the semantic meaning of the formula , we are considering other information such as formula 's description and variable 's description .
Using a formula 's name is only one way of taking into account the semantic meaning of the formula ; we are considering other information such as the formula 's description and its variable 's description .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
28:1			25:1			0		1.0
29:1			26:1			0		1.0
30:1			27:1			0		1.0
31:1			28:1			0		1.0
33:1			29:1			0		1.0
34:1			30:1			0		1.0
35:1			31:1			0		1.0
36:1			32:1			0		1.0

Alignment 3902
Currently , our system uses only the links between formulas and their names in the same article .
Currently , our system uses only the links between formulas and their names in the same article .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 3903
Therefore , linking formulas across articles should be taken into account .
Therefore , linking formulas across articles should also be taken into account .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0

Alignment 3904
Automatic approach to understanding mathematical expressions using MathML Parallel Markup corpora
Automatic approach to understanding mathematical expressions using MathML Parallel Markup corpora
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 3905
This paper explores the use of MathML Pallel Markup Corpora for mathematical expression understanding , the task of which is formulated as a translation from Presentation to Content MathML Markups in our approach .
This paper explores the use of MathML Pallel Markup Corpora for automatic understanding of mathematical expressions , the task of which is formulated as a translation from Presentation to Content MathML Markups . // <the use of capitals implies that these are software applications like PowerPoint or Word . I assume this is the right idea .> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			13:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			1		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			33:1			0		1.0

Alignment 3906
In contrast to existing researches that mainly relied on manually encoded transformation rules , we adopt a Statistical-Machine-Translation-based method to automatically extract translation rules from parallel markup corpora .
In contrast to previous research that mainly relied on manually encoded transformation rules , we use a statistical-machine-translation-based method to automatically extract translation rules from parallel markup corpora .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			4:1			1		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
16:1			16:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 3907
Our study shows that the structural features embedded in the MathML tree can be effectively exploited in the sub-tree alignment and the translation rules extracted from the alignment give boost to the translation system .
Our study shows that the structural features embedded in the MathML tree can be effectively exploited in the sub-tree alignment and the translation rules extracted from the alignment give a boost to the translation system .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0

Alignment 3908
Experimental results on the Wolfram Function Site show that our approach achieves an improvement against the prior rule-based system .
Experimental results on the Wolfram Function Site show that our approach is an improvement over prior rule-based systems . // <Note : It seems that where were two prior systems that were compared . If not , you can go back to using a prior system .> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
18:1			19:1			0		1.0
32:1			14:1			3		1.0
45:1			18:1			0		1.0

Alignment 3909
One of the most significant current discussions in the digitization of mathematical and scientific content and its applications is the semantic enrichment of mathematical documents , that is adding or associating semantic tags - usually concepts - to mathematical expressions .
One of the most significant discussions regarding the digitization of mathematical and scientific content and its applications is about semantic enrichment of mathematical documents , that is , adding or associating semantic tags - usually concepts - with mathematical expressions .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			6:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0

Alignment 3910
By encoding the underlying mathematical meaning of an expression explicitly , it is possible to interchange information more precisely between systems that semantically process mathematical objects .
By encoding the underlying mathematical meaning of an expression explicitly , it is possible to interchange information more precisely between systems that semantically process mathematical objects .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 3911
The direct application of this is enabling semantic searches for mathematical expressions by understanding the intent of the searcher and the contextual meaning of mathematical terms improve search accuracy .
The direct application of this idea enables semantic searches for mathematical expressions whereby the system 's �eunderstanding ' of the intent of the searcher and the contextual meaning of mathematical terms improves search accuracy .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			6:1			1		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
13:1			20:1			0		1.0
18:1			23:1			0		1.0
19:1			14:1			0		1.0
20:1			15:1			0		1.0
21:1			16:1			0		1.0
22:1			17:1			0		1.0
23:1			18:1			0		1.0
24:1			19:1			0		1.0
26:1			21:1			0		1.0
27:1			22:1			0		1.0
29:1			24:1			0		1.0
30:1			25:1			0		1.0
31:1			26:1			1		1.0
32:1			27:1			0		1.0
33:1			28:1			0		1.0
34:1			29:1			0		1.0

Alignment 3912
It also benefits computer algebra systems , automatic reasoning system and multi-lingual translation systems .
It also benefits computer algebra systems , automatic reasoning systems and multi-lingual translation systems .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			1		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 3913
However , as is the case with natural language , the semantic enrichment of mathematical expressions is a non-trivial task .
However , as is the case with natural language , semantic enrichment of mathematical expressions is a non-trivial task .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0

Alignment 3914
- First , mathematical notation , though more rigorous than natural language , is nonetheless at times ambiguous , context-dependent , and varies from community to community .
- First , mathematical notation , though more rigorous than natural language , is nonetheless at times ambiguous , context-dependent , and varies from community to community .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0

Alignment 3915
- Second , the underlying mathematical meaning of an expression need to follow a semantic markup in a semantically rigorous way .
- Second , the underlying mathematical meaning of an expression needs to follow a semantic markup in a semantically rigorous way .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:2			10:2			3		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 3916
Because of this , failing to follow the constraint , the computer might not be able to process that expression .
Because of this , in failing to follow the constraint , the computer might not be able to process that expression .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0

Alignment 3917
- The third problem is that new notations tend to be introduced and used as and when needed so a mechanism is required for referring to mathematical concepts outside of the base collection , allowing them to be represented .
- The third problem is that new notations tend to be introduced and used when needed so a mechanism is required for referring to mathematical concepts outside of the base collection .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0
24:1			26:1			0		1.0
25:1			27:1			0		1.0
26:1			28:1			0		1.0
27:1			29:1			0		1.0
28:1			30:1			0		1.0
29:1			31:1			0		1.0
30:1			32:1			0		1.0
31:1			39:1			0		1.0

Alignment 3918
The aim of this paper is to introduce a method for automatic mathematics semantic enrichment that capable of analyze and disambiguate mathematical terms .
The aim of this paper is to describe a method of automatic semantic enrichment for mathematics that is capable of analyzing and disambiguating mathematical terms .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			11:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			10:1			0		1.0
15:1			12:1			0		1.0
16:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			1		1.0
21:1			19:1			0		1.0
22:1			20:1			1		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0

Alignment 3919
In our research , MathML \CITE Presentation Markup is used to display mathematical expressions and MathML Content Markup is used to convey mathematical meaning .
In our research , MathML \CITE Presentation Markup is used to display mathematical expressions and MathML Content Markup is used to convey mathematical meaning .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 3920
The semantic enrichment task then becomes generating Content MathML outputs from Presentation MathML expressions .
The semantic enrichment task then becomes one of generating Content MathML outputs from Presentation MathML expressions .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0

Alignment 3921
There are three reasons why we choose MathML markup in our research .
There are three reasons why we chose MathML markup in our research .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			2		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 3922
- First , since its first release in 1997 , MathML has grown to become a general format that enables mathematics to be served , received , and processed in a wide variety of applications .
- First , since its first release in 1997 , MathML has grown to become a general format that enables mathematics to be served , received , and processed in a wide variety of applications .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0

Alignment 3923
- Second , MathML can be used to encode both mathematical notation and mathematical content .
- Second , MathML can be used to encode both mathematical notations and mathematical content .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			1		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 3924
- Last , large collections of formulas are available in MathML and we can easily assess these collections .
- Last , large collections of formulas are available in MathML , and we can easily assess these collections .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0

Alignment 3925
- In the scope of this paper , we only make use the information within a mathematical expression for disambiguation when translating it to content markup .
- In the scope of this paper , we only make use the information within a mathematical expression for disambiguation when translating it into content markup .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 3926
The prior solution to this problem is SnuggleTeX \CITE , which was proposed by David McKain .
The prior solution to this problem is SnuggleTeX \CITE , which was proposed by David McKain .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 3927
The system used rule-based methods for disambiguation and translation .
The system uses rule-based methods for disambiguation and translation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			1		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 3928
This solution has two main limitations :
This solution has two main limitations :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0

Alignment 3929
- Since it is a hand written rule-based system , SnuggleTeX requires mathematical knowledge and human effort to develop
- Since it is a hand-written rule-based system , SnuggleTeX requires mathematical knowledge and human effort to develop .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0

Alignment 3930
- Due to the diversity of mathematical expressions , SnuggleTeX is still to be considered experimental and has difficulty processing complicated mathematical symbols and expressions .
- Due to the diversity of mathematical expressions , SnuggleTeX is still considered experimental and has difficulty processing complicated mathematical symbols and expressions .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0

Alignment 3931
In this paper , we propose an approach that automatically learn the semantics inference from a presentation from parallel markup data .
In this paper , we propose an approach that automatically learns semantic inferences in a presentation from parallel markup data . // <The original has too many from to be logically clear . The rewrite is a guess . > .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			1		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
27:1			14:1			0		1.0

Alignment 3932
The idea of this approach is based on statistical machine translation .
This approach is based on statistical machine translation .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			4:1			0		1.0
2:1			5:1			0		1.0
3:1			6:1			0		1.0
4:1			7:1			0		1.0
5:1			8:1			0		1.0
6:1			9:1			0		1.0
7:1			10:1			0		1.0
8:1			11:1			0		1.0

Alignment 3933
The underlying mathematical meaning of an expression is inferred according to the probability distribution $ p( c | p ) $ that a semantic expression $ c $ is the translation of a presentation expression $ p $ .
The underlying mathematical meaning of an expression is inferred from the probability distribution $ p( c | p ) $ that a semantic expression $ c $ is the translation of a presentation expression $ p $ .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0
31:1			32:1			0		1.0
32:1			33:1			0		1.0
33:1			34:1			0		1.0
34:1			35:1			0		1.0
35:1			36:1			0		1.0
36:1			37:1			0		1.0
37:1			38:1			0		1.0

Alignment 3934
The probability distribution will be automatically learned from data that have both Presentation and Content MathML markup , that is the parallel markup MathML data .
The probability distribution is automatically learned from both Presentation and Content MathML markup data , that is , parallel markup MathML data .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:2			3		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			11:1			0		1.0
8:1			12:1			0		1.0
9:1			13:1			0		1.0
10:1			14:1			0		1.0
11:1			15:1			0		1.0
12:1			16:1			0		1.0
13:1			8:1			0		1.0
14:1			17:1			0		1.0
15:1			18:1			0		1.0
16:1			19:1			0		1.0
18:1			21:1			0		1.0
19:1			22:1			0		1.0
20:1			23:1			0		1.0
21:1			24:1			0		1.0
22:1			25:1			0		1.0

Alignment 3935
The data used in this study was collected from the Wolfram Function Site \CITE .
The data used in this study was collected from the Wolfram Function Site \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 3936
We also prepare another parallel markup MathML data by annotating mathematical expressions on 20 papers from The Archives of the Association for Computational Linguistics \CITE ( ACL-ARC ) .
We also prepared other parallel markup MathML data by annotating mathematical expressions in 20 papers from The Archives of the Association for Computational Linguistics \CITE ( ACL-ARC ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			1		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 3937
We have two main contributions in this paper
There are two main contributions in this paper :
Line2Start:Length	Line1Start:Length	Module		Score
1:2			1:2			3		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 3938
- First , successfully apply the machine translation techniques to the problem of mathematic semantic enrichment .
- First , we successfully applied machine translation techniques to solving the problem of mathematic semantic enrichment .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			1		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0

Alignment 3939
Experimental results show that our system significantly outperforms the current rule-based system and it can handle a lot of practical cases in the mathematics semantic enrichment problem .
Experimental results show that our system significantly outperforms the current rule-based system and it can handle a lot of practical cases in the semantic enrichment problem .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0

Alignment 3940
Since both quantity and quality of mathematical expressions are continuing to grow and expand through time , we believe that our system will cover most of real life mathematical expressions .
The quantity and quality of mathematical expressions are continuing to grow , and we believe that our system will be able to cover most mathematical expressions .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			16:1			0		1.0
12:1			12:1			0		1.0
13:1			17:1			0		1.0
14:1			18:1			0		1.0
15:1			19:1			0		1.0
16:1			20:1			0		1.0
17:1			21:1			0		1.0
18:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			28:1			0		1.0
25:1			29:1			0		1.0
26:1			30:1			0		1.0

Alignment 3941
- Second , mathematics knowledge such as symbol 's meanings or structural relations is automatically learned while training , therefor it is not required mathematics experts nor human effort and it is also easier to update the system given more data .
- Second , mathematics knowledge such as a symbol 's meanings or structural relations is automatically learned while training ; therefore , the system requires no human effort or expertise , and it is easier to update with more data .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
20:1			19:1			1		1.0
21:1			18:1			0		1.0
22:1			36:1			0		1.0
23:1			37:1			0		1.0
25:2			22:1			3		1.0
27:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
33:1			31:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
38:1			39:1			0		1.0
39:1			40:1			0		1.0
40:1			41:1			0		1.0

Alignment 3942
Since new notations keep growing , it is important to update the system as quick as possible .
Since new notations keep cropping up , it is important to update the system as quickly as possible .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			1		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0

Alignment 3943
In our experiments , we performed a 10-folds cross validation on mathematical expressions from 6 categories of the Wolfram Functions Site to evaluate the effectiveness of our proposed learning method .
We performed a ten-fold cross validation on mathematical expressions from six categories of the Wolfram Functions Site to evaluate the effectiveness of our learning method .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			5:1			0		1.0
2:1			6:1			0		1.0
4:1			8:1			0		1.0
5:1			9:1			0		1.0
6:1			10:1			0		1.0
7:1			11:1			0		1.0
8:1			12:1			0		1.0
9:1			13:1			0		1.0
10:1			14:1			2		1.0
11:1			15:1			0		1.0
12:1			16:1			0		1.0
13:1			17:1			0		1.0
14:1			18:1			0		1.0
15:1			19:1			0		1.0
16:1			20:1			0		1.0
17:1			21:1			0		1.0
18:1			22:1			0		1.0
19:1			23:1			0		1.0
20:1			24:1			0		1.0
21:1			25:1			0		1.0
22:1			26:1			0		1.0
23:1			28:1			0		1.0
24:1			29:1			0		1.0
25:1			30:1			0		1.0

Alignment 3944
We set up another experiment to confirm the correlation between system performance and training set size and saw that increasing the size of training data actually boost the system performance .
We performed another experiment to assess the correlation between the system 's performance and training set size and found that increasing the size of the training data boosted the system 's performance .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			27:1			0		1.0
10:1			28:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:2			17:2			3		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
29:1			10:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0

Alignment 3945
We also performed extensive side-by-side comparison with prior work \CITE over a data set from ACL-ARC scientific papers .
We also performed an extensive comparison with prior work \CITE using a data set collected from ACL-ARC scientific papers .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0

Alignment 3946
Our experimental results show that the proposed approach works well on the mathematics semantic enrichment problem and it excels the previous work by providing significantly less error rate .
Our experimental results show that our approach works well in dealing with the mathematics semantic enrichment problem and it outperforms the previous work by making significantly fewer errors .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			3		1.0
27:1			26:1			1		1.0
28:1			28:1			0		1.0

Alignment 3947
The remainder of this paper is organized as follows : In Section 2 , we give a brief overview of the background and related work for semantic enrichment of mathematical expressions , while in Section 3 we present our proposed method .
The remainder of this paper is organized as follows : In Section 2 , we give a brief overview of the background and related work on semantic enrichment of mathematical expressions .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			41:1			0		1.0

Alignment 3948
We then describe the experimental setup and results in Section 4 .
We present our method in Section 3 and describe the experimental setup and results in Section 4 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
8:1			2:1			0		1.0
9:1			3:1			0		1.0
10:1			4:1			0		1.0
11:1			5:1			0		1.0
12:1			6:1			0		1.0
13:1			7:1			0		1.0
14:1			8:1			0		1.0
15:1			9:1			0		1.0
16:1			10:1			0		1.0
17:1			11:1			0		1.0

Alignment 3949
Section 5 concludes the paper and gives avenues for future work .
Section 5 concludes the paper and gives avenues for future work .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 3950
Since mathematical formulas contain both mathematical symbols and structures , a special markup is required for their representation .
Since mathematical formulas contain both mathematical symbols and structures , a special markup is required for their representation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 3951
Until recently , images have been used to represent mathematical formulas on the web .
Until recently , images have been used to represent mathematical formulas on the web .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 3952
This type of display does not need any markup language to decode the formulas , but it is hard to process them .
This type of display does not need any markup language to decode the formulas , but it is hard to process them .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 3953
A way of dealing with mathematical formulas in this format is to convert them to another text-based format , as seen in InftyReader \CITE .
A way of dealing with mathematical formulas in this format is to convert them into another text-based format , for example , InftyReader \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 3954
For scientific documents , \TeX{} has been used to encode mathematical formulas .
\TeX{} has been used to encode mathematical formulas in scientific documents .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			4:1			0		1.0
1:1			5:1			0		1.0
2:1			6:1			0		1.0
3:1			7:1			0		1.0
4:1			8:1			0		1.0
5:1			9:1			0		1.0
6:1			10:1			0		1.0
7:1			11:1			0		1.0
9:1			1:1			0		1.0
10:1			2:1			0		1.0
11:1			12:1			0		1.0

Alignment 3955
The formula is printed in a way a person would write by hand , or typeset the equation .
A formula is printed in a way a person would write by hand , or typeset the equation .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 3956
In some web pages , such as the Wikipedia site , a formula is displayed in both image and \TeX{} formats .
In some web pages , such as on the Wikipedia site , formulas are displayed in both image and \TeX{} formats .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			12:1			1		1.0
13:1			13:1			2		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 3957
The best known open markup format for representing mathematical formulas for the web is MathML \CITE , which was recommended by the W3C math working group .
The best known open markup format for representing mathematical formulas for the web is MathML \CITE , which was recommended by the W3C math working group .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 3958
It provides a standard way of representing mathematical expressions .
It provides a standard way of representing mathematical expressions .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 3959
It is an XML application for describing mathematical notations and encoding mathematical content within a text format .
It is an XML application for describing mathematical notations and encoding mathematical content within a text format .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 3960
MathML has two types of encoding , content-based encoding which is called Content MathML , dealing with the meaning of formulas , and presentation-based encoding which is called Presentation MathML , dealing with the display of formulas .
MathML has two types of encoding , content-based encoding , called Content MathML , dealing with the meaning of formulas , and presentation-based encoding , called Presentation MathML , dealing with the display of formulas .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			30:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
25:1			27:1			0		1.0
26:1			28:1			0		1.0
27:1			29:1			0		1.0
29:1			31:1			0		1.0
30:1			32:1			0		1.0
31:1			33:1			0		1.0
32:1			34:1			0		1.0
33:1			35:1			0		1.0
34:1			36:1			0		1.0
35:1			37:1			0		1.0

Alignment 3961
The illustration tree display of Presentation and Content Markup of the expression $ C_{-\frac{17}{2}}= \tilde {\infty} $ are depicted in Figure \REF and Figure \REF respectively .
The illustration trees of the Presentation and Content Markup of the expression $ C_{-\frac{17}{2}}= \tilde {\infty} $ are depicted in Figure \REF and Figure \REF .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			1		1.0
3:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			26:1			0		1.0

Alignment 3962
Besides MathML , there are other markups such as eqn \CITE , OpenOffice .
Besides MathML , there are other markups such as eqn \CITE , OpenOffice .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 3963
org Math \CITE , ASCIIMathML \CITE and OpenMath \CITE , but these markup can be converted to MathML using freely available tools .
org Math \CITE , ASCIIMathML \CITE , and OpenMath \CITE , but these markups can be converted into MathML by using freely available tools .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			1		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:2			15:2			3		1.0
18:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0

Alignment 3964
There are not many studies on semantic enrichment problem .
There are not many studies on the semantic enrichment problem .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0

Alignment 3965
In this section , we list some works that related to exploit the meaning of mathematical expressions .
In this section , we list some of the work on exploiting the meanings of mathematical expressions .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
10:2			10:2			3		1.0
12:1			12:1			0		1.0
13:1			13:1			1		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 3966
For understanding mathematical expressions , Grigole et al. \CITE proposed an approach based on the surrounding text of mathematical expressions .
Grigole et al. \CITE proposed an approach to understanding mathematical expressions based on the text surrounding the mathematical expressions .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			5:1			0		1.0
1:1			6:1			0		1.0
2:1			7:1			0		1.0
3:1			8:1			0		1.0
4:1			9:1			0		1.0
5:1			10:1			0		1.0
6:1			11:1			0		1.0
8:1			1:1			0		1.0
9:1			2:1			0		1.0
10:1			3:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			16:1			0		1.0
15:1			15:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0

Alignment 3967
The main idea of this approach is to use the surrounding text for disambiguation which is based on word sense disambiguation and lexical similarity .
The main idea of this approach is to use the surrounding text for disambiguation based on word sense disambiguation and lexical similarity .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0

Alignment 3968
First , a local context C ( 5 nouns preceding a target mathematical expression ) is found in each sentence .
First , a local context C ( five nouns preceding a target mathematical expression ) is found in each sentence .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			2		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 3969
For each noun , the system identifies a Term Cluster ( derived from the OpenMath Content Dictionary ) with the highest semantic similarity according to a similarity metric .
For each noun , the system identifies a Term Cluster ( derived from the OpenMath Content Dictionary ) with the highest semantic similarity according to a similarity metric .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 3970
The similarity scores obtained were weighted , summed up , and normalized by the length of the considered context .
The similarity scores obtained are weighted , summed up , and normalized by the length of the considered context .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			2		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 3971
The assigned interpretation is the Term Cluster with the highest similarity score .
The Term Cluster with the highest similarity score is assigned as the interpretation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			5:1			0		1.0
2:1			6:1			0		1.0
3:1			7:1			0		1.0
4:1			8:1			0		1.0
5:1			9:1			0		1.0
6:1			10:1			0		1.0
7:1			11:1			0		1.0
8:1			3:1			0		1.0
9:1			1:1			0		1.0
11:1			4:1			0		1.0
12:1			2:1			0		1.0
13:1			12:1			0		1.0

Alignment 3972
The approach was evaluated on 451 manually annotated mathematical expressions and the best result was 68.26 $ F_{0.5} $ score .
The approach was evaluated on 451 manually annotated mathematical expressions , and the best result was an F_{0.5} $ score of 68.26 $ .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
21:1			15:1			0		1.0
22:1			16:1			0		1.0
23:1			20:1			0		1.0

Alignment 3973
To deal with the meanings of mathematical formulas , Nghiem et al. \CITE proposed an approach for extracting the names or descriptions of the formulas using natural language text surrounding them .
To deal with the meanings of mathematical formulas , Nghiem et al. \CITE proposed an approach for extracting names or descriptions of formulas by using the natural language text surrounding them .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			18:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0

Alignment 3974
The most accurate extraction result using data from Wikipedia was $ 68.33 $ percent .
The most accurate extraction result using data from Wikipedia was $ 68.33 $ percent .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 3975
There are two other projects that deal with the semantic meaning of mathematical expressions .
There are two other projects that deal with the semantic meaning of mathematical expressions .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 3976
The first is the SnuggleTeX project \CITE , which provides a free and open-source Java library for converting fragments of LaTeX to XML including Content MathML .
The first is the SnuggleTeX project \CITE , which provides a free and open-source Java library for converting fragments of LaTeX into XML including Content MathML .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 3977
The other project is Lamapun \CITE .
The other project is Lamapun \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0

Alignment 3978
This project investigates semantic enrichment , structural semantics and ambiguity resolution in mathematical corpora .
This project investigates semantic enrichment , structural semantics , and ambiguity resolution in mathematical corpora .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0

Alignment 3979
Unfortunately , there are no evaluation report on these systems .
Unfortunately , there are no evaluations of these systems .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			1		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0

Alignment 3980
To translate mathematical expressions from the Presentation MathML to Content MathML format , a list of rules for translation is required .
To translate mathematical expressions from the Presentation MathML into Content MathML format , a list of translation rules is required .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			18:1			0		1.0
17:1			16:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0

Alignment 3981
Building these translation rules by hand is a large undertaking .
Building these translation rules by hand is a large undertaking .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 3982
Our task is inherently domain specific therefore we propose an approach which is based on statistical machine learning methods that automatically extract these rules from a dataset .
Our task is inherently domain-specific ; therefore , we devised an approach based on statistical machine learning for automatically extracting rules from a dataset .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
6:1			6:1			0		1.0
8:1			7:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			1		1.0
20:1			23:1			0		1.0
21:1			24:1			0		1.0
22:1			25:1			0		1.0
23:1			26:1			0		1.0
24:1			27:1			0		1.0

Alignment 3983
Nowadays , statistical machine translation ( SMT ) is by far the most widely-studied machine translation method .
Statistical machine translation ( SMT ) is by far the most widely studied machine translation method .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			3:1			0		1.0
2:1			4:1			0		1.0
3:1			5:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0

Alignment 3984
SMT uses a very large data set of good translations , that is , a corpus of texts which have already been translated into other language , and then uses those texts to automatically infer a statistical model of translation .
SMT uses a very large data set of good translations , that is , a corpus of texts which have already been translated into another language , and it uses those texts to automatically infer a statistical model of translation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:2			24:2			3		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0

Alignment 3985
The statistical model is then applied to new texts to make a translation .
The statistical model is then applied to new texts to make a translation of them .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
15:1			13:1			0		1.0

Alignment 3986
Tree-based or syntax-based SMT can be used for tree-to-tree translation but it has two drawbacks when apply to the problem of translating from Presentation to Content MathML expression .
Tree-based or syntax-based SMT can be used for tree-to-tree translation but it has two drawbacks when it is applied to the problem of translating Presentation into Content MathML .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
17:2			16:1			3		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			23:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			28:1			0		1.0

Alignment 3987
- The first drawback is tree-based SMT focus on generating the surface texts rather than the tree structures .
- The first drawback is that tree-based SMT focuses on generating surface texts rather than tree structures .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			1		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0

Alignment 3988
While mathematical expressions have strict structures , it fails to fulfill this requirement .
Mathematical expressions have strict structures , and it fails to fulfill this requirement .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 3989
- The second drawback is there are many long mathematical expressions in real-world data and translating long and complex sentences has been a critical problem in machine translation .
- The second drawback is there are many long mathematical expressions in real-world data and translating long and complex sentences has been a critical problem in machine translation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 3990
To overcome these limitations , we introduced two separated sets of rule : fragment rules and translation rules .
To overcome these limitations , we made two separate rule sets : fragment rules and translation rules .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			3		1.0
7:1			7:1			0		1.0
8:1			8:1			1		1.0
9:1			11:1			0		1.0
10:1			9:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0

Alignment 3991
The detail is described in the next section .
The details are described in the next section .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:2			1:2			3		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 3992
The framework of the system is shown in Figure \REF .
The framework of the system is shown in Figure \REF .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 3993
The system has three main modules .
The system has three main modules .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0

Alignment 3994
- Preprocessing : processes MathML expressions to remove error expressions or format tags with no semantic meaning .
- Preprocessing : This module processes MathML expressions by removing error expressions or format tags with no semantic meaning .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
5:1			3:1			0		1.0
6:1			4:1			0		1.0
7:1			5:1			0		1.0
9:1			7:1			1		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0

Alignment 3995
- Extracting Rules : given a dataset contains MathML parallel markup expressions , extract the rules for translation .
- Rule Extraction : This module is given a dataset containing MathML parallel markup expressions , and it extracts translation rules from it . // <The original is ungrammatical and unclear . The rewrite is a guess .> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			2:1			1		1.0
3:1			3:1			0		1.0
7:1			4:1			0		1.0
8:1			5:1			0		1.0
9:1			6:1			0		1.0
10:1			7:1			1		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
19:1			17:1			0		1.0
20:1			15:1			0		1.0
23:1			18:1			0		1.0

Alignment 3996
- Generating Content MathML : given a mathematical expressions in Presentation MathML markup , and a set of rules , generate Content MathML expressions to enrich the Presentation MathML expressions .
- Content MathML Generation : This module is given mathematical expressions in Presentation MathML markup and a set of rules , and it generates Content MathML expressions to enrich the Presentation MathML expressions .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			1:1			1		1.0
4:1			4:1			0		1.0
8:1			5:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
23:1			20:1			1		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0
26:1			23:1			0		1.0
27:1			24:1			0		1.0
28:1			25:1			0		1.0
29:1			26:1			0		1.0
30:1			27:1			0		1.0
31:1			28:1			0		1.0
32:1			29:1			0		1.0
33:1			30:1			0		1.0

Alignment 3997
The presentation elements of Presentation MathML are divided into two classes : token elements and layout schemata .
The presentation elements of Presentation MathML are divided into two classes : token elements and layout schemata .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 3998
Token elements represent identifier 's names , function 's names , numbers , etc.
Token elements represent the identifier 's names , function 's names , numbers , etc. // <the identifier 's names means there is one identifier with possibly many names . If this is what you want to say , it is okay . If not , maybe you mean simply " identifier names " . ><Likewise , maybe you mean " function names " .>
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0

Alignment 3999
Layout schemata build expressions out of parts .
Layout schemata build expressions out of parts .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 4000
By investigating the data from the Wolfram Function Site , we noticed that there are elements that have no specific meaning , they are used for displaying purpose only and most of them are layout schemata .
After investigating data on the Wolfram Function Site , we noticed that there are elements that have no specific meaning ; they are used for display purposes only and most of them are layout schemata .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			3:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			1		1.0
26:1			27:1			1		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0
31:1			32:1			0		1.0
32:1			33:1			0		1.0
33:1			34:1			0		1.0
34:1			35:1			0		1.0
35:1			36:1			0		1.0

Alignment 4001
For example , the $ <mtext> </mtext> $ or $ <mspace / > $ tags are used to insert some space between expressions .
For example , the $ <mtext> </mtext> $ or $ <mspace / > $ tags are used to insert some space between expressions .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 4002
Another example are the pairs of parentheses , it is used to indicate that the expressions in the parentheses go together , while its structure already encoded that information .
Another example is pairs of parentheses ; these are used to indicate that the expressions in the parentheses go together , despite that their structure already encodes that information . // <The original is unclear . The rewrite is a guess . > .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			9:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
8:1			2:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
22:1			27:1			0		1.0
23:2			23:2			3		1.0
25:1			25:1			0		1.0
26:1			26:1			1		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0

Alignment 4003
As a result , in this preprocessing step , these elements are removed .
This preprocessing step removes these elements .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			6:1			0		1.0
2:1			7:1			0		1.0
4:1			9:1			0		1.0
5:1			10:1			0		1.0
6:1			13:1			0		1.0

Alignment 4004
In this step , we also removed mathematical expressions with error markups such as expressions that have no Content markup .
We also remove mathematical expressions with error markups such as expressions that have no Content markup .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			5:1			0		1.0
2:1			6:1			1		1.0
3:1			7:1			0		1.0
4:1			8:1			0		1.0
5:1			9:1			0		1.0
6:1			10:1			0		1.0
7:1			11:1			0		1.0
8:1			12:1			0		1.0
9:1			13:1			0		1.0
10:1			14:1			0		1.0
11:1			15:1			0		1.0
12:1			16:1			0		1.0
13:1			17:1			0		1.0
14:1			18:1			0		1.0
15:1			19:1			0		1.0
16:1			20:1			0		1.0

Alignment 4005
For simplification , expressions with more than 200 content nodes also be removed .
For simplification , expressions with more than 200 content nodes are also removed .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:2			10:2			3		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 4006
In the training phase , we use GIZA++ \CITE for alignment between Presentation MathML terms and Content MathML terms .
In the training phase , we use GIZA++ \CITE for aligning Presentation MathML terms and Content MathML terms .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			1		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0

Alignment 4007
Based on the aligned data , we use some heuristics to extract rules which we called " fragment rules " .
Based on the aligned data , we use heuristics to extract rules that we call " fragment rules " .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:2			12:2			3		1.0
13:1			14:1			0		1.0
14:1			15:1			1		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0

Alignment 4008
Fragment rules are rules that define the translation from Presentation MathML sub-trees to Content MathML sub-trees .
Fragment rules are rules that define the translation from the Presentation MathML sub-trees to the Content MathML sub-trees .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0

Alignment 4009
These rules are applied to break the large Presentation MathML tree into smaller sub-trees while maintaining the structure of output Content MathML trees .
These rules are used to break up a large Presentation MathML tree into smaller sub-trees while maintaining the structure of the output Content MathML trees .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			2		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			6:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0

Alignment 4010
These rules are extracted based on the fact that translate small tree is easier than translate large one .
These rules are extracted based on the fact that translating a small tree is easier than translating a large one .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			1		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			1		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0

Alignment 4011
Each rule in fragment rule set is associated with its probability , that is the frequent that rule happened in the training data .
Each rule in the fragment rule set is associated with a probability , that is , the frequency at which a rule occurs in the training data .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			14:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
16:1			20:1			0		1.0
21:1			17:1			0		1.0
22:1			18:1			2		1.0
23:1			19:1			0		1.0
25:1			21:1			0		1.0
26:1			22:1			0		1.0
27:1			23:1			0		1.0

Alignment 4012
If the sub-trees can not be broken any longer , we extract another rules , which we called " translation rules " , at that point .
Once the sub-trees cannot be broken down further , we start to extract other rules , which we call " translation rules " .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:2			3		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
7:1			7:2			3		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
12:1			11:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			1		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			26:1			0		1.0

Alignment 4013
We then enhances the translation rule set with the translation terms extracted by GIZA++ .
We enhance the translation rule set with translation terms extracted by GIZA++ .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			2:1			1		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0

Alignment 4014
The pseudo code of the algorithm for extracting fragment rules is described in Algorithm \REF .
The pseudo code for extracting fragment rules is described in Algorithm \REF .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			6:1			0		1.0
4:1			7:1			0		1.0
5:1			8:1			0		1.0
6:1			9:1			0		1.0
7:1			10:1			0		1.0
8:1			11:1			0		1.0
9:1			12:1			0		1.0
10:1			13:1			0		1.0
11:1			14:1			0		1.0
12:1			15:1			0		1.0

Alignment 4015
In the previous steps , we got two sets of rules , fragment rule set and translation rule set .
In the previous steps , we get two sets of rules , a fragment rule set and a translation rule set .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			2		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0

Alignment 4016
We then use these rules for translation .
We then use these rules for translation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 4017
Given a mathematical expressions in Presentation MathML markup , the system will generate Content MathML markup of that expression .
Given mathematical expressions in Presentation MathML markup , the system will generate Content MathML markup for each expression .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0

Alignment 4018
- First , the expression is preprocess to remove non semantic elements .
- First , the expression is preprocessed to remove non-semantic elements .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			1		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0

Alignment 4019
- Second , the fragment rule is applied to the expression until it could not be divided any further .
- Second , the fragment rule is applied to the expression until it cannot be divided any further .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:2			3		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0

Alignment 4020
- Third , the small sub-expressions in Presentation MathML markup will be translated into sub-expressions in Content MathML markup using translation rule set .
- Third , the small sub-expressions in Presentation MathML markup are translated into sub-expressions in Content MathML markup by using the translation rule set .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:2			3		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
19:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0

Alignment 4021
If no translation rule is found for a sub-expression , that expression is marked as untranslated .
If no translation rule is found for a sub-expression , that expression is marked as untranslated .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 4022
- Last , sub-expressions in Content MathML markup is grouped to form the complete Content MathML expression .
- Last , sub-expressions in Content MathML markup are grouped to form the complete Content MathML expression .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			2		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 4023
Before the last step , we add a heuristic translation to translate numbers .
Before the last step , we add a heuristic translation to translate numbers .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 4024
The reason for this is that there is infinite number and we could never present every number in the rule .
The reason for this is that there is an infinite number of rules . // <The rewrite is a guess .> .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
12:1			19:1			1		1.0
13:1			20:1			0		1.0

Alignment 4025
The translation algorithm is described in Algorithm \REF .
The translation algorithm is described in Algorithm \REF .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 4026
The experiments were carried out using the datasets from the Wolfram Function site .
The experiments were carried out using datasets from the Wolfram Function site .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0

Alignment 4027
This site was created as a resource for educational , mathematical , and scientific communities .
This site was created as a resource for educational , mathematical , and scientific communities .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 4028
It contains the world 's most encyclopedic collection of information about mathematical functions .
It contains the world 's most encyclopedic collection of information about mathematical functions .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 4029
All formulas on this site are available in both Presentation MathML and Content MathML format .
All formulas on this site are available in both Presentation MathML and Content MathML format .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 4030
These datasets we used contain 205 , 653 mathematical expressions belong to 6 categories .
The datasets we used contain 205 , 653 mathematical expressions belonging to six categories .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:2			10:2			3		1.0
12:1			12:1			2		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 4031
All of these expressions have both MathML Presentation and Content Markup .
All of these expressions have both MathML Presentation and Content Markups .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			1		1.0
11:1			11:1			0		1.0

Alignment 4032
Training and testing were performed using 10-fold cross-validation ; for each category , the original corpus is partitioned into 10 subsets .
Training and testing were performed using ten-fold cross-validation ; for each category , the original corpus was partitioned into ten subsets .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			2		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			2		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 4033
Of the 10 subsets , a single subset is retained as the validation data for testing the model , and the remaining subsets are used as training data .
Of the ten subsets , a single subset was retained as the validation data for testing the model , and the remaining subsets were used as training data .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			20:1			0		1.0
2:1			1:2			3		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			2		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:2			23:2			3		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 4034
The cross-validation process is then repeated 10 times , with each of the 10 subsets used exactly once as the validation data .
The cross-validation process was repeated ten times , with each of the ten subsets used exactly once as the validation data .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			2		1.0
4:1			5:1			0		1.0
5:1			6:1			2		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			2		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0

Alignment 4035
The 10 results from the folds then are averaged to produce a single estimation .
The ten results from the folds then were averaged to produce a single estimation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			2		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			2		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 4036
To prove the effectiveness of our models to real data , we conducted another experiment on the mathematical expressions in scientific papers .
To prove the effectiveness of our models with real data , we conducted another experiment on the mathematical expressions in scientific papers .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 4037
Currently we have 20 papers from ACL archive , all of the math expressions in these papers are annotated manually with both Presentation Markup and Content Markup .
Currently , we have 20 papers from the ACL archive , and we manually annotated all of the math expressions in these papers with both Presentation Markup and Content Markup . // The original is somewhat vague . The rewrite is a guess . Use it if it is correct . > .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
13:1			19:1			0		1.0
14:1			18:1			0		1.0
15:1			9:1			0		1.0
16:1			10:1			0		1.0
17:1			11:1			0		1.0
18:1			12:1			0		1.0
19:1			13:1			0		1.0
20:1			14:1			0		1.0
21:1			15:1			0		1.0
22:1			16:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0
26:1			23:1			0		1.0
27:1			24:1			0		1.0
28:1			25:1			0		1.0
29:1			26:1			0		1.0
30:1			27:1			0		1.0

Alignment 4038
We called this data ACL-ARC .
We called this data ACL-ARC .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0

Alignment 4039
In the first experiment , the data is not compatible with SnuggleTeX since SnuggleTeX use ASCII MathML while the Wolfram Functions site does not .
In the first experiment , the data was not compatible with SnuggleTeX since SnuggleTeX uses ASCII MathML but the Wolfram Functions site does not .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:2			7:2			3		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			1		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 4040
In the second experiment with ACL-ARC data , we compared our model side by side with SnuggleTeX .
In the second experiment with ACL-ARC data , we compared our model with SnuggleTeX .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			15:1			0		1.0
13:1			16:1			0		1.0
14:1			17:1			0		1.0

Alignment 4041
Table \REF contains the various data statistics .
Table \REF lists the various data statistics .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 4042
Given a Presentation MathML expression $ e $ , we assume that tree $ A $ is the correct Content MathML tree of expression $ e $ and tree $ B $ is the output using the automatic translation .
Given a Presentation MathML expression $ e $ , we assume that tree $ A $ is the correct Content MathML tree of expression $ e $ and tree $ B $ is the output of the automatic translation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0

Alignment 4043
The basic idea to evaluate the correctness of tree $ B $ is directly comparing it with tree $ A $ .
The basic idea to evaluate the correctness of tree $ B $ is directly comparing it with tree $ A $ .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 4044
In the experiments , we extend the conventional definition of " Translation Error Rate " and use a metric which is the combined version of
In the experiments , we extended the conventional definition of " Translation Error Rate " and used a metric which is a combined version of
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			1		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			1		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:2			20:2			3		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 4045
- Tree Edit Distance \CITE : the tree edit distance is the minimal cost to transform A into B using edit operations .
- the Tree Edit Distance \CITE : the tree edit distance is the minimal cost to transform A into B using edit operations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0

Alignment 4046
There are three types of edit operations : substituting a node , inserting a node , and deleting a node .
There are three types of edit operation : substituting a node , inserting a node , and deleting a node .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			1		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 4047
- Translation Error Rate \CITE : translation error rate is an error metric for machine translation that measures the number of edits required to change a system output into one of the references .
- the Translation Error Rate \CITE : the translation error rate is an error metric for machine translation that measures the number of edits required to change a system output into one of the references .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			31:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
34:1			32:1			0		1.0
35:1			33:1			0		1.0

Alignment 4048
We call the new metric Tree Edit Distance Rate ( TEDR ) .
We called the new metric the Tree Edit Distance Rate ( TEDR ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			1		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0

Alignment 4049
TEDR is defined as the rate between ( 1 ) the minimal cost to transform a tree A into another tree B using edit operations and ( 2 ) the maximum number of nodes of A and B .
TEDR is defined as the rate between ( 1 ) the minimal cost to transform a tree A into another tree B using edit operations and ( 2 ) the maximum number of nodes of A and B . // <The " rate between " is unclear to me . Do you mean , " the ratio of " >
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0

Alignment 4050
It can be computed using Eq . \REF .
It can be computed using Eq . \REF .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 4051
For example , the output tree using translation system for the expression $ C_{-\frac{17}{2}}= \tilde {\infty} $ is depict in Figure \REF .
For example , the output tree using the translation system for the expression $ C_{-\frac{17}{2}}= \tilde {\infty} $ is depicted in Figure \REF .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			1		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0

Alignment 4052
Compare to the reference tree in Figure \REF , we need to substituting X node , inserting Y node , and deleting Z node , so that $ TED( A , B ) = x $ . While the maximum number of node of two trees is y .
Compared with the reference tree in Figure \REF , we need to substitute X nodes , insert Y nodes , and delete Z nodes , so that $ TED( A , B ) = x $ , while the maximum number of nodes of the two trees is y .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			1		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			1		1.0
13:1			13:1			0		1.0
14:1			14:1			1		1.0
15:1			15:1			0		1.0
16:1			16:1			1		1.0
17:1			17:1			0		1.0
18:1			18:1			1		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			1		1.0
22:1			22:1			0		1.0
23:1			23:1			1		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			1		1.0
43:1			43:1			0		1.0
45:1			44:1			0		1.0
46:1			45:1			0		1.0
47:1			46:1			0		1.0
48:1			47:1			0		1.0
49:1			48:1			0		1.0

Alignment 4053
Therefore , $ TEDR( A \rightarrow B ) = \frac{x}{y} = z $ .
Therefore , $ TEDR( A \rightarrow B ) = \frac{x}{y} = z $ .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 4054
For the data in Wolfram Function site , it appeared that SnuggleTeX is not applicable to this data since SnuggleTeX use ASCII MathML while the Wolfram Functions site does not .
It appeared that SnuggleTeX was not applicable to the data from the Wolfram Function site since it uses ASCII MathML but the site does not .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			9:1			0		1.0
2:1			10:1			0		1.0
3:1			11:1			0		1.0
4:1			12:1			2		1.0
5:1			13:1			0		1.0
6:1			14:1			0		1.0
7:1			15:1			0		1.0
8:1			1:1			0		1.0
9:1			2:1			0		1.0
11:1			24:1			0		1.0
12:1			4:1			0		1.0
13:1			5:1			0		1.0
14:1			6:1			0		1.0
15:1			18:1			0		1.0
16:1			8:1			0		1.0
17:1			20:1			1		1.0
18:1			21:1			0		1.0
19:1			22:1			0		1.0
22:1			27:1			0		1.0
23:1			28:1			0		1.0
24:1			29:1			0		1.0
25:1			30:1			0		1.0

Alignment 4055
Therefore we could not do the side-by-side comparison on this data .
Therefore , we could not do a comparison on this data .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 4056
Our experimental results show that our approach can archive reasonable results , that is 20 percent TEDR with large training data .
Our experimental results show that our approach gives reasonable results , that is , a 20 percent TEDR with large training data .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0

Alignment 4057
For small data which has less than 3000 training samples , the results vary from 50 to 75 percent TEDR .
For small data ( less than 3000 training samples ) , the results vary from 50 to 75 percent TEDR .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 4058
For ACL-ARC data , the experimental results from our side-by-side comparison show that our system significantly outperforms SnuggleTeX in terms of Tree Edit Distance Rate .
For ACL-ARC data , the experimental results show that our system significantly outperforms SnuggleTeX in terms of the Tree Edit Distance Rate .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			11:1			0		1.0
8:1			12:1			0		1.0
9:1			13:1			0		1.0
10:1			14:1			0		1.0
11:1			15:1			0		1.0
12:1			16:1			0		1.0
13:1			17:1			0		1.0
14:1			18:1			0		1.0
15:1			19:1			0		1.0
16:1			20:1			0		1.0
18:1			21:1			0		1.0
19:1			22:1			0		1.0
20:1			23:1			0		1.0
21:1			24:1			0		1.0
22:1			25:1			0		1.0

Alignment 4059
Our system archived 24 percent TEDR less than the output using SnuggleTeX .
Our system had a 24 percent lower TEDR in comparison with SnuggleTeX .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			6:1			3		1.0
7:1			5:1			0		1.0
9:2			7:1			3		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 4060
To find out the correlation between TEDR score and training set size , we set up an experiment using mathematical expressions in Elementary Functions category .
To investigate the correlation between the TEDR score and training set size , we set up an experiment using mathematical expressions in the Elementary Functions category .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0

Alignment 4061
We started with one fifth of the data , and then increase data one fifth each run .
We started with one fifth of the data and increased the data by one fifth in each run .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			9:1			0		1.0
11:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0

Alignment 4062
Our experimental results conform with the theoretical analysis that the more training data we have , the better the results are .
Our experimental results conformed with the theoretical analysis that the more training data we have , the better the results are .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			1		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 4063
Table \REF and Table \REF show the TEDR of our proposed method on the Wolfram Functions Site data and in comparison with SnuggleTeX on ACL ARC data , respectively .
Table \REF and Table \REF show the TEDR of our method on the Wolfram Functions Site data and in comparison with SnuggleTeX on ACL ARC data , respectively .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0

Alignment 4064
Table \REF and Figure \REF shows the correlation between TEDR score and training set size .
Table \REF and Figure \REF shows the correlation between TEDR score and training set size .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 4065
In this paper , we discussed the problem of the semantic enrichment of mathematical expressions .
We discussed the problem of semantic enrichment of mathematical expressions .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			5:1			0		1.0
2:1			6:1			0		1.0
3:1			7:1			0		1.0
4:1			8:1			0		1.0
5:1			10:1			0		1.0
6:1			11:1			0		1.0
7:1			12:1			0		1.0
8:1			13:1			0		1.0
9:1			14:1			0		1.0
10:1			15:1			0		1.0

Alignment 4066
Our experimental results show that our approach based on the statistical machine translation method for translating a Presentation MathML expression to a Content MathML expression has the significant improvement over a prior system .
Our experimental results show that our approach based on the statistical machine translation method for translating a Presentation MathML expressions to Content MathML expressions is a significant improvement over prior systems .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			1		1.0
20:1			20:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			1		1.0
24:1			25:2			3		1.0
25:1			21:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			31:1			0		1.0
30:1			32:1			1		1.0
31:1			33:1			0		1.0

Alignment 4067
As we mentioned before , mathematical notations are context-dependent .
As we mentioned before , mathematical notations are context-dependent .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 4068
That means we need to consider not only surrounding expressions but also the document that contains the notations in order to generate the correct semantic output .
That means we need to consider not only surrounding expressions but also the document that contains the notations in order to generate the correct semantic output .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 4069
In the scope of this paper , we only consider the first context information .
In the scope of this paper , we only considered the first sort of context information .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			1		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0

Alignment 4070
Since this is a first attempt to translate Presentation to Content MathML using a machine learning method , there is room for further improvement .
Since this is a first attempt to translate from Presentation to Content MathML using a machine learning method , there is room for further improvement .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0

Alignment 4071
Possible improvements are
Possible improvements are
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0

Alignment 4072
- Increasing the training data so the system can cover more mathematical notations
- Increasing the training data so the system can cover more mathematical notations
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 4073
- Expanding the work by incorporating the surrounding information of mathematical expressions , for example definitions or other mathematical expressions .
- Expanding the work by incorporating the surrounding information of mathematical expressions , for example , definitions or other mathematical expressions .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0

Alignment 4074
By combining the automatic extraction of fragment rules and translation rules , our approach has shown promising results .
Our approach combining automatic extraction of fragment rules and translation rules has shown promising results .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			13:1			0		1.0
2:1			1:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			14:1			0		1.0
12:1			15:1			0		1.0
13:1			16:1			0		1.0
14:1			17:1			0		1.0
15:1			18:1			0		1.0

Alignment 4075
The experimental results confirm that this approach is helpful to the understanding of mathematical expressions .
The experimental results confirm that it would be helpful for automatic understanding of mathematical expressions .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:2			7:1			3		1.0
8:2			8:2			3		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 4076
However , this is only a first step ; many important issues remain for future studies .
However , this is only a first step ; many important issues remain for future studies .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 4077
Currently , our system deals only with a sub-part of mathematical notations .
Currently , our system deals with a limited range of mathematical notations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 4078
In future work , we should also consider expanding it to cover all mathematical notations .
In the future , we should consider expanding it to cover all mathematical notations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			1:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0

Alignment 4079
Improving protein coreference resolution by simple semantic classification
Improving protein coreference resolution by simple semantic classification
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 4080
Recent research shows a major part of difficult cases in event extraction for the biomedical domain are related to coreference .
Current research has shown that major difficulties in event extraction cases for the biomedical domain are related to coreference .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:2			2:1			3		1.0
5:1			4:1			0		1.0
6:1			6:2			3		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			8:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0

Alignment 4081
Therefore , coreference resolution is believed to be useful for the improvement of event extraction .
Therefore , coreference resolution is believed to be useful for improving event extraction .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:3			3		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0

Alignment 4082
To address the problem of coreference resolution in molecular biology literature , the Protein Coreference ( COREF ) task was arranged in the BioNLP-ST 2011 as a supporting task .
To address coreference resolution in molecular biology literature , the Protein Coreference ( COREF ) task was arranged in the BioNLP-ST 2011 , as a supporting task .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			5:1			0		1.0
3:1			6:1			0		1.0
4:1			7:1			0		1.0
5:1			8:1			0		1.0
6:1			9:1			0		1.0
7:1			10:1			0		1.0
8:1			11:1			0		1.0
9:1			12:1			0		1.0
10:1			13:1			0		1.0
11:1			14:1			0		1.0
12:1			15:1			0		1.0
13:1			16:1			0		1.0
14:1			17:1			0		1.0
15:1			18:1			0		1.0
16:1			19:1			0		1.0
17:1			20:1			0		1.0
18:1			21:1			0		1.0
19:1			22:1			0		1.0
20:1			23:1			0		1.0
21:1			24:1			0		1.0
23:1			25:1			0		1.0
24:1			26:1			0		1.0
25:1			27:1			0		1.0
26:1			28:1			0		1.0
27:1			29:1			0		1.0

Alignment 4083
However , the shared task results showed that transferring coreference resolution methods developed for other domains to the biological domain was not straight forward , which is supposed to be caused by the domain differences in coreference phenomena .
However , the shared task results indicated that transferring coreference resolution methods developed for other domains to the biological domain was not straightforward , due to the domain differences in the coreference phenomena .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:2			6:2			3		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			2		1.0
23:1			24:1			0		1.0
24:2			30:2			3		1.0
26:1			32:1			0		1.0
27:1			33:1			0		1.0
28:1			34:1			0		1.0
29:1			35:1			0		1.0
31:1			36:1			0		1.0
32:1			37:1			0		1.0
33:1			38:1			0		1.0

Alignment 4084
We studied the contribution of domain-specific information , i .e information indicating the protein type , in a rule-based protein coreference resolution system .
We studied the contribution of domain-specific information , including information that indicates the protein type , in a rule-based protein coreference resolution system .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			10:1			0		1.0
11:1			11:1			1		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 4085
In particular , the domain-specific information is encoded into semantic classification modules whose output is used in different components of the coreference resolution .
In particular , the domain-specific information is encoded into semantic classification modules for which the output is used in different components of the coreference resolution .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:3			12:1			3		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0

Alignment 4086
We compared our system with the top four systems in the BioNLP-ST 2011 , and surprisingly we found that the minimal configuration has outperformed the best system in the BioNLP-ST 2011 .
We compared our system with the top four systems in the BioNLP-ST 2011 ; surprisingly , we found that the minimal configuration had outperformed the best system in the BioNLP-ST 2011 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
14:1			15:1			0		1.0
15:1			13:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			2		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0

Alignment 4087
Analysis of the experimental results showed that semantic classification using protein information has contributed to an increase in performance ( 2.3 % on the test data , and 4 .0% on the development data , in F-score ) .
Analysis of the experimental results revealed that semantic classification , using protein information , had contributed to an increase in performance by 2.3 % on the test data , and 4 .0% on the development data , in F-score .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:2			5:2			3		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			26:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			34:1			0		1.0
14:2			12:2			3		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
33:1			31:1			0		1.0
34:1			32:1			0		1.0
35:1			33:1			0		1.0
37:1			35:1			0		1.0
38:1			36:1			0		1.0
39:1			38:1			0		1.0

Alignment 4088
The use of domain-specific information in semantic classification is important for coreference resolution .
The use of domain-specific information in semantic classification is important for coreference resolution .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 4089
Since such information is difficult to be transferred across different domains , we need to continue seeking for methods to exploit and use it in coreference resolution .
Since it is difficult to transfer domain-specific information across different domains , we need to continue to seek methods to exploit and use it in coreference resolution .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			23:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:2			3		1.0
7:1			2:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			19:1			0		1.0
18:1			18:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0

Alignment 4090
While named entity recognition ( NER ) and relation or event extraction are regarded as standard tasks of biomedical information extraction ( IE ) , coreference resolution [ 2 , 16 , 30 ] is more and more recognized as an important component of IE for a higher performance .
While named entity recognition ( NER ) and relation / event extraction are regarded as standard tasks for biomedical information extraction ( IE ) , coreference resolution [ 2 , 16 , 30 ] is being recognized more and more as an important component of IE to achieve a higher performance .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			45:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
36:1			38:1			0		1.0
37:1			35:1			0		1.0
38:1			36:1			0		1.0
39:1			37:1			0		1.0
40:1			39:1			0		1.0
41:1			40:1			0		1.0
42:1			41:1			0		1.0
43:1			42:1			0		1.0
44:1			43:1			0		1.0
45:1			44:1			0		1.0
48:1			46:1			0		1.0
49:1			47:1			0		1.0
50:1			48:1			0		1.0
51:1			49:1			0		1.0

Alignment 4091
Without coreference resolution , the performance of IE is often substantially limited due to an abundance of coreference relations in natural language text , i.e. , information pieces written in text with involvement of a coreference relation are hard to be captured [ 9 , 14 ] .
Without coreference resolution , oftentimes , the IE performance issubstantially limited , due to the abundance of coreference relations in natural language text ; information pieces written in text with the involvement of a coreference relation are hard to be captured [ 9 , 14 ] .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			23:1			0		1.0
6:1			4:1			0		1.0
7:1			7:1			0		1.0
8:1			5:1			0		1.0
10:1			11:1			0		1.0
11:1			25:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
24:1			26:1			0		1.0
25:1			27:1			0		1.0
26:1			28:1			0		1.0
27:1			29:1			0		1.0
28:1			30:1			0		1.0
29:1			31:1			0		1.0
31:1			32:1			0		1.0
32:1			33:1			0		1.0
33:1			34:1			0		1.0
34:1			35:1			0		1.0
35:1			36:1			0		1.0
36:1			37:1			0		1.0
37:1			38:1			0		1.0
38:1			39:1			0		1.0
39:1			40:1			0		1.0
40:1			41:1			0		1.0
41:1			42:1			0		1.0
42:1			43:1			0		1.0
43:1			44:1			0		1.0
44:1			45:1			0		1.0
45:1			46:1			0		1.0
46:1			47:1			0		1.0

Alignment 4092
There have been several attempts for coreference resolution , particularly for newswire texts [ 7 , 8 , 22 , 23 , 28 , 30 ] .
There have been several attempts for coreference resolution ; in particular , they have been for newswire texts [ 7 , 8 , 22 , 23 , 28 , 30 ] .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:2			9:1			3		1.0
11:1			8:1			0		1.0
15:1			10:1			0		1.0
16:1			11:1			0		1.0
17:1			12:1			0		1.0
18:1			13:1			0		1.0
19:1			14:1			0		1.0
20:1			15:1			0		1.0
21:1			16:1			0		1.0
22:1			17:1			0		1.0
23:1			18:1			0		1.0
24:1			19:1			0		1.0
25:1			20:1			0		1.0
26:1			21:1			0		1.0
27:1			22:1			0		1.0
28:1			23:1			0		1.0
29:1			24:1			0		1.0
30:1			25:1			0		1.0
31:1			26:1			0		1.0

Alignment 4093
It is also one of the lessons from BioNLP Shared Task ( BioNLP-ST , hereafter ) 2009 that coreference relations in biomedical text substantially hinder the progress of fine-grained IE [ 10 ] .
Coreference resolution is also one of the lessons from the BioNLP Shared Task ( BioNLP-ST , hereafter ) 2009 , in which it was communicated that coreference relations in biomedical text substantially hinder the progress of fine-grained IE [ 10 ] .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			25:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
25:1			17:1			0		1.0
26:1			18:1			0		1.0
27:1			19:1			0		1.0
28:1			20:1			0		1.0
29:1			21:1			0		1.0
30:1			22:1			0		1.0
31:1			23:1			0		1.0
32:1			24:1			0		1.0
34:1			26:1			0		1.0
35:1			27:1			0		1.0
36:1			28:1			0		1.0
37:1			29:1			0		1.0
38:1			30:1			0		1.0
39:1			31:1			0		1.0
40:1			32:1			0		1.0
41:1			33:1			0		1.0

Alignment 4094
To address the problem of coreference resolution in molecular biology literature , the Protein Coreference ( COREF ) task was arranged in BioNLP-ST 2011 as a supporting task .
To address the problem of coreference resolution in molecular biology literature , the Protein Coreference ( COREF ) task was arranged in BioNLP-ST 2011 as a supporting task .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 4095
This task definition focuses on a specific type of entities , i.e. Protein .
This task definition focuses on protein , as a specific type of entity .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			10:1			0		1.0
8:1			5:1			0		1.0
9:1			6:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			1		1.0
13:1			13:1			0		1.0

Alignment 4096
Figure 1 shows an example text segmented into four sentences , S2 - S5 , where coreferential expressions are shown in brackets .
Figure 1 shows an example text segmented into four sentences , S2 - S5 , where coreferential expressions are shown in brackets .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 4097
In the figure , protein names are highlighted in bold face , P4 - P10 , and targeted anaphoric expressions of the shared task , e.g. pronouns and definite noun phrases , are T29 , and T32 , of which the antecedents are indicated by arrows if found in the text .
In the figure , protein names P4 - P10 are highlighted in boldface ; the targeted anaphoric expressions of the shared task ( pronouns and definite noun phrases ) are T29 , and T32 , for which the antecedents are indicated by arrows , if found in the text .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			12:1			0		1.0
7:1			13:1			0		1.0
8:1			14:1			0		1.0
9:1			6:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			2		1.0
14:1			49:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
23:1			26:1			0		1.0
24:1			27:1			0		1.0
25:1			28:1			0		1.0
26:1			29:1			0		1.0
27:1			30:1			0		1.0
29:1			32:1			0		1.0
30:1			33:1			0		1.0
31:1			34:1			0		1.0
32:1			35:1			0		1.0
33:1			36:1			0		1.0
34:1			37:1			0		1.0
35:2			38:2			3		1.0
37:1			40:1			0		1.0
38:1			41:1			0		1.0
39:1			42:1			0		1.0
40:1			43:1			0		1.0
41:1			44:1			0		1.0
42:1			45:1			0		1.0
43:1			11:1			0		1.0
44:1			46:1			0		1.0
45:1			47:1			0		1.0
46:1			48:1			0		1.0
48:1			50:1			0		1.0
49:1			51:1			0		1.0

Alignment 4098
In the example , the definite-noun-phrase expression , this transcription factor ( T32 ) , is considered coreferential with the protein mention p65 ( P10 ) .
In the example , the definite-noun-phrase expression , this transcription factor ( T32 ) , is considered coreferential with the protein mention p65 ( P10 ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 4099
Without knowing this coreference relation , it becomes hard to capture the information written in the phrase , nuclear exclusion of this transcription factor , which is localization of p65 ( out of nucleus ) according to the framework of BioNLP-ST .
Without knowing this coreference relation , it becomes difficult to capture the information written in the phrase , nuclear exclusion of this transcription factor , which is a localization of p65 ( out of nucleus ) , according to the framework of BioNLP-ST .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:2			3		1.0
9:1			36:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
37:1			35:1			0		1.0
39:1			37:1			0		1.0
40:1			38:1			0		1.0
41:1			39:1			0		1.0
42:1			40:1			0		1.0
43:1			41:1			0		1.0

Alignment 4100
The terminologies used in this paper are similar to those in [ 25 ] .
The terminologies used in this paper are similar to those in [ 25 ] .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 4101
A new term is introduced in the BioNLP-ST is antecedent protein , which indicates the protein mention contained in the antecedent expression , e.g. p65 in T28 .
A new term introduced in the BioNLP-ST is antecedent protein , which indicates the protein mention contained in the antecedent expression , e.g. , p65 in T28 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0

Alignment 4102
There are other coreferential expressions which are ignored in the context of this COREF task such as this complex and the NF-kappa B transcription factor complex ( Figure 1 ) , since we only focus on the antecedent expressions that contain and point to protein mentions .
There are other coreferential expressions , which are ignored in the context of this COREF task , such as : this complex and the NF-kappa B transcription factor complex ( Figure 1 ) , since our focus is on the antecedent expressions that contain and point to protein mentions .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			30:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0
26:1			23:1			0		1.0
27:1			24:1			0		1.0
28:1			25:1			0		1.0
29:1			26:1			0		1.0
30:1			27:1			0		1.0
31:1			28:1			0		1.0
32:1			29:1			0		1.0
34:1			31:1			0		1.0
36:1			34:1			0		1.0
38:1			35:1			0		1.0
39:1			36:1			0		1.0
40:1			37:1			0		1.0
41:1			38:1			0		1.0
42:1			39:1			0		1.0
43:1			40:1			0		1.0
44:1			41:1			0		1.0
45:1			42:1			0		1.0
46:1			43:1			0		1.0
47:1			44:1			0		1.0
48:1			45:1			0		1.0
49:1			46:1			0		1.0

Alignment 4103
The best system in the COREF shared task according to the primary evaluation found 22 .2% of anaphoric protein references at the precision of 73 .3% ( 34 .1% Fscore ) .
The best system in the COREF shared task , according to the primary evaluation , found 22 .2% of the anaphoric protein references at the precision of 73 .3% ( 34 .1% F-score ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0
26:1			23:1			0		1.0
27:1			24:1			0		1.0
28:1			25:1			0		1.0
29:1			26:1			0		1.0
30:1			27:1			0		1.0
31:1			28:1			0		1.0
33:1			30:1			0		1.0
34:1			31:1			0		1.0

Alignment 4104
This is an encouraging result , since the authors make use of an external coreference resolution tool originally built for the news domain , without much domain adaptation on the main coreference resolution algorithm .
The results are promising , since the authors make use of an external coreference resolution tool originally built for the news domain , without much domain adaptation on the main coreference resolution algorithm .
Line2Start:Length	Line1Start:Length	Module		Score
3:1			3:1			3		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0
31:1			32:1			0		1.0
32:1			33:1			0		1.0
33:1			34:1			0		1.0

Alignment 4105
Modifications are mostly made to the markable detection component and post processing for the output coreference links [ 11 ] .
Modifications are mostly made to the markable detection component and post-processing for the output coreference links [ 11 ] .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0

Alignment 4106
However , the external coreference tool achieves much lower results on biological texts than that on news texts , from 66 .38% down to 49 .65% in MUC-score [ 11 , 27 ] , which is supposed to be caused by domain differences .
However , the external coreference tool " s performance drops for biological texts than for news texts , from 66 .38% to 49 .65% in MUC-score [ 11 , 27 ] , which is supposed to be caused by domain differences .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:2			9:1			3		1.0
9:1			22:1			3		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0
24:1			26:1			0		1.0
25:1			27:1			0		1.0
26:1			28:1			0		1.0
27:1			29:1			0		1.0
28:1			30:1			0		1.0
29:1			31:1			0		1.0
30:1			32:1			0		1.0
31:1			33:1			0		1.0
32:1			34:1			0		1.0
33:1			35:1			0		1.0
34:1			36:1			0		1.0
35:1			37:1			0		1.0
36:1			38:1			0		1.0
37:1			39:1			0		1.0
38:1			40:1			0		1.0
39:1			41:1			0		1.0
40:1			42:1			0		1.0
41:1			43:1			0		1.0

Alignment 4107
A detailed analysis on the _nal submissions of the COREF task participants was reported in the organizer 's papers [ 15 , 31 ] , which is summarized in table 2 .
A detailed analysis on the _nal submission of the COREF task participants was reported in the organizer 's papers [ 15 , 31 ] , and is summarized in table 2 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			1		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0

Alignment 4108
In this analysis , the submitted predictions on the test data set of the COREF shared task are analyzed according to four types of anaphoric expressions : DNP for definite noun phrases , RELAT for relative pronouns , PRON for other pronouns including personal , possessive , and demonstrative pronouns , and OTHER for catch-all type .
In this analysis , the submitted predictions on the test data set of the COREF shared task are analyzed according to four types of anaphoric expressions : DNP for definite noun phrases , RELAT for relative pronouns , PRON for other pronouns including personal , possessive , and demonstrative pronouns , and OTHER for catch-all type .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0
49:1			49:1			0		1.0
50:1			50:1			0		1.0
51:1			51:1			0		1.0
52:1			52:1			0		1.0
53:1			53:1			0		1.0
54:1			54:1			0		1.0
55:1			55:1			0		1.0
56:1			56:1			0		1.0

Alignment 4109
Below are examples of the coreference types .
Examples of the coreference types are outlined below :
Line2Start:Length	Line1Start:Length	Module		Score
1:1			3:1			0		1.0
2:1			4:1			0		1.0
3:1			5:1			0		1.0
4:1			6:1			0		1.0
5:1			1:1			0		1.0

Alignment 4110
- " . . . ,the phosphorylation status of [ TRAF2 ] had significant effects on the ability of [ the protein ] to bind to CD40 , " ( DNP )
- " [ . . . ] the phosphorylation status of [ TRAF2 ] had significant effects on the ability of [ the protein ] to bind to CD40 , " ( DNP )
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			19:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			22:1			0		1.0
7:1			20:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
23:1			21:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
33:1			31:1			0		1.0

Alignment 4111
- " Subnuclear fractionation reveals that there are [ two ATF1 isoforms ] [ which ] appear to differ with respect to DNA binding activity , " ( RELAT )
- " Subnuclear fractionation reveals that there are [ two ATF1 isoforms , which ] appear to differ with respect to DNA binding activity , " ( RELAT )
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0

Alignment 4112
- " This ability of [ CIITA ] to facilitate promoter occupation is undissociable from [ its ] transactivation potential , " ( PRON )
- " This ability of [ CIITA ] to facilitate promoter occupation is undissociable from [ its ] transactivation potential , " ( PRON )
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 4113
The analysis results in also showed that the best resolution results for definite noun phrases ( the DNP type ) , and several pronouns of the PRON type are 27 .5% F-score and 10 .1 F-score respectively , which are far less than that for relative pronoun ( the RELAT type ) 66 .2 % F-score .
An analysis of the results indicated that the best resolution results for definite noun phrases ( the DNP type ) , and several pronouns of the PRON type was 27 .5% F-score and 10 .1 F-score , respectively ; the scores were much lower than the F-score for relative pronouns ( the RELAT type ) , which yielded a 66 .2 % F-score .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			24:1			0		1.0
3:1			25:1			0		1.0
4:1			2:1			0		1.0
5:2			5:2			3		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
25:1			48:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			2		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			37:1			0		1.0
37:1			36:1			0		1.0
41:2			39:2			3		1.0
43:2			41:2			3		1.0
46:1			55:1			0		1.0
47:1			44:1			0		1.0
48:1			45:1			0		1.0
49:1			46:1			1		1.0
50:1			47:1			0		1.0
52:1			49:1			0		1.0
53:1			50:1			0		1.0
54:1			51:1			0		1.0
56:1			38:1			0		1.0
59:1			52:1			0		1.0
60:1			53:1			0		1.0
61:1			54:1			0		1.0
63:1			56:1			0		1.0

Alignment 4114
Thus , it can be inferred that definite noun phrases and pronouns are more difficult to be resolved than relative pronouns .
Thus , it can be inferred that it is more difficult to resolve definite noun phrases and pronouns than relative pronouns .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			12:1			2		1.0
9:1			13:1			0		1.0
10:1			14:1			0		1.0
11:1			15:1			0		1.0
12:1			16:2			3		1.0
13:1			7:1			0		1.0
14:1			8:1			0		1.0
15:1			9:1			0		1.0
16:1			10:1			0		1.0
17:1			11:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 4115
The top four official results of the COREF shared task are shown again in the top four rows of Table 2 .
The top four official results of the COREF shared task are presented in the top four rows of Table 2 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			2		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0

Alignment 4116
In this paper , we compare the contributions of different features in coreference resolution , two simple types of domain-portable information : discourse preference and number-agreement , and domain-specific information which can be considered as more difficult to be transferred across different domains .
In this paper , we compare the contributions of different features in coreference resolution ; two simple types of domain-portable information : discourse preference and number-agreement , is compared , as well as domain-specific information , which is considered to be more difficult to be transferred across different domains .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			31:2			3		1.0
29:1			14:1			0		1.0
30:1			34:1			0		1.0
33:1			28:1			0		1.0
34:1			29:1			0		1.0
36:1			30:1			0		1.0
38:1			33:1			0		1.0
39:1			37:1			0		1.0
40:1			38:1			0		1.0
41:1			35:1			0		1.0
42:1			36:1			0		1.0
45:1			39:1			0		1.0
46:1			40:1			0		1.0
47:1			41:1			0		1.0
48:1			42:1			0		1.0
49:1			43:1			0		1.0

Alignment 4117
We implemented a protein coreference system that makes use of syntactic information from parser output , and protein-indicated information encoded in rule-based semantic classification .
We implemented a protein coreference system that makes use of syntactic information from the parser output , and protein-indicated information encoded in rule-based semantic classification .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0

Alignment 4118
Experimental results showed that domain specific semantic information is important for coreference resolution , and that simple semantic classification using semantic features helped our system to outperform the best reported result in the shared task .
Experimental results showed that domain-specific semantic information is important for coreference resolution , and that simple semantic classification using semantic features helped our system to outperform the best-reported system results in the shared task .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
29:1			30:1			1		1.0
30:1			31:1			0		1.0
31:1			32:1			0		1.0
32:1			33:1			0		1.0
33:1			34:1			0		1.0
34:1			35:1			0		1.0

Alignment 4119
As we needed to get an insight into the problem , we took a rule-based approach , analyzing the training data of BioNLP-ST 2011 Coref task .
In order to acquire insight into the problem , we took a rule-based approach , analyzing the training data of BioNLP-ST 2011 Coref task .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			3:1			0		1.0
3:1			4:1			2		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0
24:1			26:1			0		1.0

Alignment 4120
The performance of the system evaluated on the official test data set of the COREF task shows a significant improvement over the official winning system of the task .
The performance of the system evaluated on the official test dataset of the COREF task shows a significant improvement over the official winning system of the task .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0

Alignment 4121
This section presents the overview and the performance evaluation of our system .
This section presents the overview and the performance evaluation of our system .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 4122
Figure 2 shows the overall design of the system , which includes five main components : preprocessing , markable detection , anaphor selection , antecedent candidate selection , and antecedent prediction .
Figure 2 shows the overall design of the system , which includes five main components : preprocessing , markable detection , anaphor selection , antecedent candidate selection , and antecedent prediction .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0

Alignment 4123
Processing of each component is briefly described as below .
Processing of each component is briefly described below .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0

Alignment 4124
More details of implementation can be found in the method section .
More details of implementation can be found in the method section .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 4125
Step 0 - Preprocessing : The input text is preprocessed using NLP tools for sentence segmentation , and syntactic parsing .
Step 0 - Preprocessing : The input text is preprocessed using NLP tools for sentence segmentation , and syntactic parsing .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 4126
We used Genia Sentence Splitter and Enju Parser [ 15 ] for the purposes , respectively .
We used the Genia Sentence Splitter and Enju Parser [ 15 ] for sentence segmentation and syntactic parsing , respectively .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			12:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
18:1			14:1			0		1.0
19:1			15:1			0		1.0
20:1			16:1			0		1.0

Alignment 4127
( Enju parser comes with a default tokenizer and part-of-speech tagger for biological text . ) Row 1 in the example Table 1 shows three sentences outputted from Genia Sentence Splitter , and noun phrases outputted from Enju Parser for the sentence S3 .
( Enju parser comes with a default tokenizer and part-of-speech tagger for biological text . ) Row 1 in the example of Table 1 shows three sentences as the output from the Genia Sentence Splitter , and noun phrases as the output from the Enju Parser for the sentence , S3 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
28:1			40:1			0		1.0
29:1			26:1			1		1.0
30:1			27:1			0		1.0
32:1			28:1			0		1.0
33:1			29:1			0		1.0
34:1			30:1			0		1.0
35:1			31:1			0		1.0
36:1			32:1			0		1.0
37:1			33:1			0		1.0
38:1			34:1			0		1.0
41:1			35:1			1		1.0
42:1			36:1			0		1.0
44:1			37:1			0		1.0
45:1			38:1			0		1.0
46:1			39:1			0		1.0
48:1			41:1			0		1.0
50:1			42:1			0		1.0
51:1			43:1			0		1.0

Alignment 4128
Due to the limit of space , only a part of the phrases are shown in the table .
Due to the limited space , only a part of the phrases are shown in the table .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			1		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0

Alignment 4129
The full parse tree of this sentence is separately shown in Figure 3 .
The full parse tree for this sentence is separately shown in Figure 3 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 4130
Step 1 - Markable detection : collects text chunks that are candidate coreferential expressions , which are also called markables following the jargon of MUC-7 .
Step 1 - Markable detection : Text chunks that are candidate coreferential expressions , which are also called markables following the jargon of MUC-7 , are collected .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
27:1			25:1			0		1.0

Alignment 4131
For the set of markables , noun phrases , which do not include subordinate clause , are collected as analyzed by a syntactic parser , Enju in our case .
For the set of markables , noun phrases , which do not include a subordinate clause , are collected as they are analyzed by a syntactic parser ( in our case , Enju ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
22:1			19:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0
26:1			23:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			24:1			0		1.0
32:1			25:1			0		1.0
34:1			29:1			0		1.0

Alignment 4132
Pronouns are also collected as markables .
Pronouns are also collected as markables .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0

Alignment 4133
Then , for chunks that share the same head word , which is normally the main noun of a noun phrase , only the longest is taken .
Then , for chunks that share the same head word , which is normally the main noun of a noun phrase , only the longest chunk is taken .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0

Alignment 4134
Since the Enju parser output such head-word information for every noun phrase , we make use of this information for our processing without any modification .
Since the Enju parser outputs head-word information for every noun phrase , we make use of this information for our processing , without any modification .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			1		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 4135
The third row of Table 1 shows the result of markable detection for the sample text .
The third row of Table 1 shows the result of markable detection for the sample text .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 4136
In the sentence S3 , three noun phrases recognized by the NX and NP tags of Enju output , role , role for c-Myc in apoptosis , and this role for c-Myc in apoptosis ( Step 0 results ) share the same head word role , thus only the longest one this role for c-Myc in apoptosis is selected .
In the sentence S3 , three noun phrases recognized by the NX and NP tags of the Enju output , role , role for c-Myc in apoptosis , and this role for c-Myc in apoptosis ( Step 0 results ) share the same head-word role ; thus , only the longest noun phrase , this role for c-Myc in apoptosis , is selected .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			48:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
37:1			36:1			0		1.0
38:1			37:1			0		1.0
39:1			38:1			0		1.0
40:1			39:1			0		1.0
41:1			40:1			0		1.0
42:1			41:1			0		1.0
44:1			44:1			0		1.0
46:1			46:1			0		1.0
47:1			45:1			0		1.0
48:1			47:1			0		1.0
50:1			49:1			0		1.0
54:1			51:1			0		1.0
55:1			52:1			0		1.0
56:1			53:1			0		1.0
57:1			54:1			0		1.0
58:1			55:1			0		1.0
59:1			56:1			0		1.0
61:1			57:1			0		1.0
62:1			58:1			0		1.0
63:1			59:1			0		1.0

Alignment 4137
However , between studies and studies using . . .
However , between studies and studies using . . .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 4138
apoptosis , the former chunk is selected , since the latter contains a subordinate clause .
apoptosis , the former chunk is selected , since the latter contains a subordinate clause .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 4139
Step 2 - Anaphor selection : determines candidate anaphoric expressions , which are basically pronouns and definite noun phrases ( a minority of anaphors are indefinite noun phrases or entity names , which act as appositions . )
Step 2 - Anaphor selection : Candidate anaphoric expressions , which are basically pronouns and definite noun phrases , are determined . A minority of anaphors are indefinite noun phrases or entity names , which act as appositions .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			31:1			0		1.0
19:1			24:1			0		1.0
21:1			36:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
34:1			32:1			0		1.0
35:1			33:1			0		1.0
36:1			34:1			0		1.0
37:1			35:1			0		1.0

Alignment 4140
The system first considers all pronouns and definite noun phrases in the markable set as anaphors .
The system first considers all pronouns and definite noun phrases in the markable set as anaphors .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 4141
Then , several filters are applied to remove anaphors that are not relevant to the task definition .
Then , several filters are applied to remove anaphors that are not relevant to the task definition .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 4142
We implemented two types of filters : syntactic and semantic filters .
We implemented two types of filters : syntactic and semantic .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			11:1			0		1.0

Alignment 4143
Syntactic filters are used to filter out pleonastic its , or pronouns such as he , she , which are not expected to refer to proteins .
Syntactic filters are used to filter out pleonastic its , or pronouns , like : he , she , which are not expected to refer to proteins .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			17:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0

Alignment 4144
Moreover , because the focus of our task is protein references , semantic filters can be used to filter out non-protein anaphors at this stage .
Moreover , because our task focuses on protein references , semantic filters can be used to filter out non-protein anaphors at this stage .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			6:1			0		1.0
4:1			7:1			0		1.0
5:1			8:1			3		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0

Alignment 4145
In practice , for definite noun phrase type of anaphors , this is done using a list of possible head words of protein references , and for pronouns , their context words are used .
In practice , for definite noun phrase type of anaphors , this is accomplished , by using a list of possible head-words of protein references ; for pronouns , their context words are used .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			3		1.0
14:1			24:1			0		1.0
15:2			33:1			3		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
34:1			34:1			0		1.0

Alignment 4146
More details of the methods can be found in the following section .
More details of these methods can be found in the following section .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:2			3:2			3		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 4147
Step 3 - Antecedent candidate selection : For each anaphor , this component collects the antecedent candidates from the preceding expressions .
Step 3 - Antecedent candidate selection : For each anaphor , this component collects the antecedent candidates from the preceding expressions .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 4148
One of the candidates will become the response antecedent as a result of the antecedent prediction step .
One of the candidates will become the response antecedent , as a result of the antecedent prediction step .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0

Alignment 4149
In theory , all expressions in the set of markables can become antecedent candidates , however too much candidates makes it difficult to achieve correct antecedent prediction .
In theory , all expressions in the set of markables can become antecedent candidates ; however , too many candidates makes it difficult to achieve correct antecedent prediction .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
15:1			15:1			0		1.0
16:1			14:1			0		1.0
17:2			16:2			3		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0

Alignment 4150
Moreover , we also filter out candidates that violate syntactic or semantic constraints raised by the anaphor .
Moreover , we also filter out candidates that violate syntactic or semantic constraints raised by the anaphor .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 4151
In our system , this is done by using a window size in sentences , together with several syntactic filters .
In our system , this is done by using a particular window size in sentences , together with several syntactic filters .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0

Alignment 4152
One of the syntactic filters is based on syntactic relations among phrases outputted from the parser .
One of the syntactic filters is based on syntactic relations among phrases outputted from the parser .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 4153
The idea behind this is that some types of syntactic relations imply the impossibility of coreference relations between its argument noun phrases and the inclusive expressions of these noun phrases .
The idea behind this filter is that some types of syntactic relations imply the impossibility of coreference relations between its argument noun phrases and the inclusive expressions of these noun phrases .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0

Alignment 4154
For example , the two expressions dominant negative form and its in our example in Table 1 , can not be coreferential with each other , since they are connected via the preposition of .
For example , the two expressions : dominant negative form and its in our example in Table 1 , cannot be coreferential with each other , since they are connected via the preposition of .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:2			18:2			3		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0

Alignment 4155
Another syntactic filter removes pronouns which are not in the same pronoun family as the anaphor .
Another syntactic filter removes pronouns that are not in the same pronoun family as the anaphor .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:2			5:2			3		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 4156
This results in the disappearance of this in candidate antecedents of its .
This results in the disappearance of this in candidate antecedents of its .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 4157
Pronouns in the same family as its are its , it , and itself .
Pronouns in the same family as its are its , it , and itself .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 4158
Step 4 - Antecedent predicion : selects the best candidate in the antecedent candidate set , and forms a response coreference link .
Step 4 - Antecedent prediction : The best candidate in the antecedent candidate set is selected , and a response coreference link is formed .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			5:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
15:1			6:2			3		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
24:1			22:1			0		1.0

Alignment 4159
Antecedent candidates are compared with one another using a comparison procedure .
Antecedent candidates are compared with one another using a comparison procedure .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 4160
This procedure implements a decision rule list containing four rules , encoding the following selection preference conditions :
This procedure implements a decision rule list containing four rules , encoding the following selection preference conditions :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 4161
-Rule 1 ( Number agreement - NUM-AGREE ) : The candidate which is not number conflict with anaphor is selected .
-Rule 1 ( Number agreement - NUM-AGREE ) : The candidate , which does not conflict in number with the anaphor , is selected .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			3		1.0
14:1			13:1			0		1.0
15:1			15:1			0		1.0
17:1			14:1			0		1.0
18:1			16:1			0		1.0
20:1			17:1			0		1.0
22:1			18:1			0		1.0
23:1			19:1			0		1.0
24:1			20:1			0		1.0

Alignment 4162
-Rule 2 ( Semantic constraint - SEM-CONS ) : If anaphor is a protein reference , then protein candidate is selected .
-Rule 2 ( Semantic constraint - SEM-CONS ) : If the anaphor is a protein reference , then a protein candidate is selected .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0

Alignment 4163
-Rule 3 ( Discourse preference - DISC-PREF ) : According to the anaphor type , the farther candidate is selected .
-Rule 3 ( Discourse preference - DISC-PREF ) : According to the anaphor type , the farther candidate is selected .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 4164
-Default rule ( Default discourse preference - DEFAULT ) : The closer candidate is selected .
-Default rule ( Default discourse preference - DEFAULT ) : The closer candidate is selected .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 4165
The rules are implemented using different features of expressions such as syntactic types of expression , head noun , semantic types , etc. , in a similar way to [ 22 ] .
The rules are implemented using different features of expressions , such as syntactic types of expressions , head noun , semantic types , etc. , in a similar way to [ 22 ] .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			23:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			1		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
25:4			25:4			3		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0

Alignment 4166
Each rule in the decision list compares two candidates , and returns the preferrable candidate in concern with the anaphor .
Each rule in the decision list compares two candidates , and returns the preferable candidate in concern with the anaphor .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 4167
If equility happens , the next rule in the list is applied .
If equility happens , the next rule in the list is applied .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 4168
The default and also last rule in the decision rule list is special in the sense that depending on the anaphor , it prefers the closer or the farther candidate .
The default and also last rule in the decision rule list is special in the sense that depending on the anaphor , it prefers the closer or the farther candidate .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0

Alignment 4169
Thanks to this rule , the decision list never results in the equility result .
Because of this particular rule , the decision list never results in the equility result .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0

Alignment 4170
By this way , candidates can be sorted , and the best candidate is selected as antecedent .
In this way , candidates can be sorted , and the best candidate is selected as the antecedent .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0

Alignment 4171
Figure 4 illustrates how the decision list works when comparing two candidates and .
Figure 4 illustrates how the decision list works when comparing two candidates : and .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0

Alignment 4172
More details about the implementation of the main components of our system shown in Figure 2 are presented below .
More details concerning the implementation of the main components of our system shown in Figure 2 are presented below .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			3		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 4173
In this step , we want to filter out those pronouns and definite noun phrases that are not target of this task , comprised of two types : non-anaphoric expressions , and anaphoric expressions which do not point to proteins .
In this step , we want to filter out those pronouns and definite noun phrases that are not a target of this task . The expressions are comprised of two types : non-anaphoric expressions , and anaphoric expressions , which do not point to proteins .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			40:1			0		1.0
25:1			33:1			0		1.0
26:1			35:2			3		1.0
27:1			23:1			0		1.0
28:1			24:1			0		1.0
29:1			25:1			0		1.0
30:1			26:1			0		1.0
31:1			27:1			0		1.0
32:1			28:1			0		1.0
33:1			29:1			0		1.0
34:1			30:1			0		1.0
35:1			31:1			0		1.0
36:1			32:1			0		1.0
38:1			22:1			0		1.0
39:1			34:1			0		1.0
42:1			37:1			0		1.0
43:1			38:1			0		1.0
44:1			39:1			0		1.0

Alignment 4174
The term anaphoric is used with the common sense in NLP community .
The term anaphoric is used with the common sense in the NLP community .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0

Alignment 4175
Anaphoric expression means an expression that has a noun phrase as antecedent .
Anaphoric expression refers to an expression that has a noun phrase as an antecedent .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0

Alignment 4176
This means expressions with a sentence or phrase antecedents , or nominal but successive antecedents , are not our target and should be filtered out .
Thus , expressions with a sentence or phrase antecedents , or nominal but successive antecedents , are not our target and should be filtered out .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 4177
Non-anaphoric expressions includes first and second person pronouns such as I , we , you , . . . , and pleonastic it .
Non-anaphoric expressions include first and second-person pronouns such as I , we , you , and pleonastic it .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			1		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			20:1			0		1.0
16:1			21:1			0		1.0
17:1			22:1			0		1.0
18:1			23:1			0		1.0

Alignment 4178
First and second person pronouns are easily to be recognized by the part-of-speech tags , thus we use part-of-speech information for the filtering .
First and second-person pronouns are easily recognized by the part-of-speech tags ; thus , we use part-of-speech information for the filtering .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			9:1			0		1.0
7:1			10:1			0		1.0
8:1			11:1			0		1.0
9:1			12:1			0		1.0
10:1			13:1			0		1.0
12:1			15:1			0		1.0
13:1			14:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0

Alignment 4179
For pleonastic it , we make use of the following four patterns , which are similar to [ 13 ]
For pleonastic it , we make use of the following four patterns , which are similar to [ 13 ] :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 4180
It be [ Adj|Adv| verb ]* that
It be [ Adj|Adv| verb ]* that
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0

Alignment 4181
It be Adj [ for NP ] to VP
It be Adj [ for NP ] to VP
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 4182
It [ seems|appears|means|follows ] [ that ]*
It [ seems|appears|means|follows ] [ that ]*
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0

Alignment 4183
NP [ makes|finds|take ] it [ Adj ]* [ for NP ]* [ to VP|Ving ]
NP [ makes|finds|take ] it [ Adj ]* [ for NP ]* [ to VP|Ving ]
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 4184
To recognize and filter anaphoric expressions which do not point to proteins , the system is based on the protein semantic classification results determined by the method presented below .
To recognize and filter anaphoric expressions that do not point to proteins , the system is based on the protein semantic classification results determined by the method presented below .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0

Alignment 4185
For each anaphoric markable , the system collects a list of antecedent candidates , and select the most probable candidate to be the antecedent of the anaphor .
For each anaphoric markable , the system collects a list of antecedent candidates , and select the most probable candidate to be the antecedent of the anaphor .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0

Alignment 4186
Basically all expressions detected in the initial expression set are antecedent candidate , except for anaphoric pronouns .
Basically , all of the expressions detected in the initial expression set are an antecedent candidate , with the exception of anaphoric pronouns .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			1:1			0		1.0
5:1			2:1			0		1.0
6:1			3:1			0		1.0
7:1			4:1			0		1.0
8:1			5:1			0		1.0
9:1			6:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
14:1			10:1			0		1.0
15:1			11:1			0		1.0
16:1			12:1			0		1.0
17:4			13:2			3		1.0
21:1			15:1			0		1.0
22:1			16:1			0		1.0
23:1			17:1			0		1.0

Alignment 4187
However , if the list contains too many candidates , then it may be more difficult for the later antecedent-selection algorithm .
However , if the list contains too many candidates , then it may be more difficult for the later antecedent-selection algorithm .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 4188
Therefore , candidates that are not probable to be antecedent of the anaphor should be filtered out .
Therefore , candidates that are not probable to be an antecedent of the anaphor should be filtered out .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0

Alignment 4189
There are several filters that can be used :
There are several filters that can be used :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 4190
Window size sets a border to include or exclude antecedent candidates .
Window size Borders are set to include or exclude antecedent candidates .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 4191
This is a common method for antecedent candidate filtering having been used in the previous work [ 3 , 5 , 26 ] .
This is a common method for antecedent candidate filtering , as seen in the previous work [ 3 , 5 , 26 ] .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 4192
Since our task focuses on anaphoric coreference , antecedent expressions normally appear not too far ( in sentence distance ) from the anaphors , using window sizes is a proper technique .
Since our task focuses on anaphoric coreference , antecedent expressions normally appear not too far ( in sentence distance ) from the anaphors . Thus , using window sizes is a proper technique .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
33:1			31:1			0		1.0

Alignment 4193
Syntactic dependency relations The fact that arguments of some dependency relations such as poss-arg12 and prep-arg12 do not corefer with each other enables us to use them to correctly eliminate the number of antecedent candidates .
Syntactic dependency relations Since arguments of some dependency relations ( such as poss-arg12 and prep-arg12 ) do not corefer with each other , they can be used to correctly eliminate the number of antecedent candidates .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
25:2			25:2			3		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0

Alignment 4194
For instance , two such truncated forms definitely cannot be antecedent of the protein in this context two such truncated forms of the protein
For instance , two such truncated forms definitely cannot be an antecedent of the protein in this context : two such truncated forms of the protein .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0

Alignment 4195
After filtering non-relevant antecedent candidates for an anaphor in the above step , depending on the anaphor type , the remained candidates are ranked by fixed rules , or by using a pairwise comparison procedure :
After filtering non-relevant antecedent candidates for an anaphor in the step above , depending on the anaphor type , the remaining candidates are ranked by fixed rules , or by using a pairwise comparison procedure :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			11:1			0		1.0
11:1			10:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			1		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0

Alignment 4196
The relative pronoun can be said to be the easiest type of coreference resolution , because its antecedent expression is very close to the anaphor , and in many cases , it is right before the anaphor .
The relative pronoun can be said to be the easiest type of coreference resolution , because its antecedent expression is very close to the anaphor , and in many cases , it is right before the anaphor .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0

Alignment 4197
For this type of anaphors , any syntactic parser can be used to find the relations between relative pronouns and their arguments .
For these types of anaphors , any syntactic parser can be used to find the relation between relative pronouns and their arguments .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:2			1:2			3		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			1		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 4198
This is exactly what our system does .
Our system accomplishes this task .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			5:1			0		1.0
2:1			1:1			3		1.0
5:1			7:1			0		1.0

Alignment 4199
It simply produces coreference links between the relative pronouns and their arguments .
It simply produces coreference links between the relative pronouns and their arguments .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 4200
However , a disadvantage of this method is when the parser makes mistake on finding the correct arguments , coreference also fails , as in the example " . . .of transcription factor NF-kappa B also encodes a p70 I kappa B protein , I kappa B gamma , which is identical to the C-terminal 607 amino acids of . . . "
However , a disadvantage to using this method is that when the parser makes a mistake on finding the correct arguments , the coreference also fails . This is exemplified in the following : " . . .of transcription factor NF-kappa B also encodes a p70 I kappa B protein , I kappa B gamma , which is identical to the C-terminal 607 amino acids of . . . "
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			52:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			37:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0
22:1			53:1			0		1.0
23:1			19:1			0		1.0
24:1			20:1			0		1.0
25:1			21:1			0		1.0
26:1			61:1			0		1.0
28:1			50:1			0		1.0
30:1			24:1			0		1.0
31:1			25:1			0		1.0
34:1			27:1			0		1.0
35:1			28:1			0		1.0
36:1			29:1			0		1.0
37:1			30:1			0		1.0
38:1			31:1			0		1.0
39:1			32:1			0		1.0
40:1			33:1			0		1.0
41:1			34:1			0		1.0
42:1			35:1			0		1.0
43:1			36:1			0		1.0
45:1			38:1			0		1.0
46:1			39:1			0		1.0
47:1			40:1			0		1.0
48:1			41:1			0		1.0
49:1			42:1			0		1.0
50:1			43:1			0		1.0
51:1			44:1			0		1.0
52:1			45:1			0		1.0
53:1			46:1			0		1.0
54:1			47:1			0		1.0
55:1			48:1			0		1.0
56:1			49:1			0		1.0
58:1			51:1			0		1.0
61:1			54:1			0		1.0
62:1			55:1			0		1.0
63:1			56:1			0		1.0
64:1			57:1			0		1.0
65:1			58:1			0		1.0
66:1			59:1			0		1.0
67:1			60:1			0		1.0
69:1			62:1			0		1.0

Alignment 4201
This procedure compares two candidate expressions at a time with respect to preferences raised by the anaphor .
This procedure compares two candidate expressions at a time with respect to preferences raised by the anaphor .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 4202
The best antecedent expression is selected to form a response coreference link .
The best antecedent expression is selected to form a response coreference link .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 4203
In particular , a list of rules is used to compare two candidates of an anaphor in a deterministic manner .
In particular , a list of rules is used to compare two candidates of an anaphor in a deterministic manner .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 4204
For each rule , both of the candidates are checked against the condition hold by that rule .
For each rule , both of the candidates are checked against the condition hold by that rule .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 4205
If one candidate satisfies and the other does not , the procedure ends with the result that the former will be preferable to the latter .
If one candidate satisfies and the other does not , the procedure ends with the result that the former will be preferable over the latter .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 4206
If both satisfy or both do not satisfy , the procedure proceeds to the next rule in the same manner .
If both satisfy or both do not satisfy , the procedure proceeds to the next rule in the same manner .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 4207
The rules are applied in a succession order one after another until the inequality occurs , or end of the rule list is reached .
The rules are applied in a successive order , one after another , until the inequality occurs , or until the end-of-the-rule list is reached .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			1		1.0
7:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
20:1			19:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0

Alignment 4208
The default rule of the procedure prefers the closer antecedent candidate .
The default rule of the procedure , is in the preference of the closer antecedent candidate .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
12:1			7:1			0		1.0
13:1			8:1			0		1.0
14:1			9:1			0		1.0
15:1			10:1			0		1.0
16:1			11:1			0		1.0

Alignment 4209
By definition , two coreferential expressions refer to the same thing , which implies a semantic-constraint on coreference relationship .
By definition , two coreferential expressions are identical , which implies a semantic-constraint on coreference relationship .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:2			8:2			3		1.0
8:1			11:1			0		1.0
9:1			12:1			0		1.0
10:1			13:1			0		1.0
11:1			14:1			0		1.0
12:1			15:1			0		1.0
13:1			16:1			0		1.0
14:1			17:1			0		1.0
15:1			18:1			0		1.0
16:1			19:1			0		1.0

Alignment 4210
In other words , semantic types of coreferents must be compatible .
In other words , semantic types of coreferents must be compatible .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 4211
In practice , this compatibility is checked based on a given taxonomy of semantic classes in the following manner : two semantic classes are considered compatible or agreed with each other , when they have synonym relation , e.g. , or hypernym-hyponym relation .
In practice , this compatibility is checked based on a given taxonomy of semantic classes in the following manner : two semantic classes are considered compatible or agreed with each other , when they have a synonym relation , or hypernym-hyponym relation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
36:1			35:1			0		1.0
37:1			36:1			0		1.0
38:1			37:1			0		1.0
39:1			40:1			0		1.0
40:1			41:1			0		1.0
41:1			42:1			0		1.0
42:1			43:1			0		1.0

Alignment 4212
In this work , we only focus on the Protein type , ignoring other possible semantic types , so we do not take the structure of taxonomy into account .
In this work , we only focus on the Protein type , ignoring other possible semantic types , so the structure of the taxonomy is not taken into account .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			23:1			0		1.0
20:1			24:1			0		1.0
21:1			25:1			0		1.0
23:1			26:1			0		1.0
25:1			21:1			0		1.0
26:1			22:1			2		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0

Alignment 4213
Thus , the likelihood that two expressions are semantically compatible is definitely beneficial for antecedent prediction , besides syntactic information .
Therefore , the likelihood that two expressions are semantically compatible , is definitely beneficial for antecedent prediction , besides syntactic information .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0

Alignment 4214
Focusing on specific entity types , i.e. Protein type , helps us to find a proper method for determining the likelihood , and how to encode the likelihood in coreference resolution .
Focusing on specific entity types , i.e. , Protein type , enables us to find a proper method for determining the likelihood , and method for encoding the likelihood in coreference resolution .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			21:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
23:1			22:1			0		1.0
26:1			25:1			1		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0

Alignment 4215
Since gold protein annotations are given , we can use them in combination with syntactic information to judge whether an expression is protein-referential expession or not .
Since gold protein annotations are given , we can use them in combination with syntactic information to judge whether an expression is a protein-referential expression or not .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
23:1			22:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0

Alignment 4216
In details , if an expression is a noun phrase with a single head word , and it contains a protein mention that completely overlaps with the head word , then the expression is classied as Protein .
If an expression is a noun phrase with a single head word , and it contains a protein mention that completely overlaps with the head word , then the expression is classified as Protein .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			4:1			0		1.0
2:1			5:1			0		1.0
3:1			6:1			0		1.0
4:1			7:1			0		1.0
5:1			8:1			0		1.0
6:1			9:1			0		1.0
7:1			10:1			0		1.0
8:1			11:1			0		1.0
9:1			12:1			0		1.0
10:1			13:1			0		1.0
11:1			14:1			0		1.0
12:1			15:1			0		1.0
13:1			16:1			0		1.0
14:1			17:1			0		1.0
15:1			18:1			0		1.0
16:1			19:1			0		1.0
17:1			20:1			0		1.0
18:1			21:1			0		1.0
19:1			22:1			0		1.0
20:1			23:1			0		1.0
21:1			24:1			0		1.0
22:1			25:1			0		1.0
23:1			26:1			0		1.0
24:1			27:1			0		1.0
25:1			28:1			0		1.0
26:1			29:1			0		1.0
27:1			30:1			0		1.0
28:1			31:1			0		1.0
29:1			32:1			0		1.0
30:1			33:1			0		1.0
32:1			35:1			0		1.0
33:1			36:1			0		1.0
34:1			37:1			0		1.0

Alignment 4217
Another case is when the head noun is either protein or gene , and has a protein mention as its premodifier , such as the Tax protein .
In another case , when the head noun is either protein or gene , and has a protein mention as its premodifier , such as the Tax protein .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			21:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0

Alignment 4218
For a coordinated noun phrase , if one of its constituents is classified as Protein , then that noun phrase is also classified as Protein .
For a coordinated noun phrase , if one of its constituents is classified as a Protein , then that noun phrase is also classified as a Protein .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0

Alignment 4219
Pronouns , in particular , possessive pronouns occupy the majority of anaphoric pronouns in biological texts ( Table 5 ) .
Pronouns , in particular , possessive pronouns , occupy the majority of anaphoric pronouns in biological texts ( Table 5 ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0

Alignment 4220
However , they do not contain in themselves much useful information for the resolution , thus we need to exploit more information from its context [ 17 ] .
However , they do not contain very much useful information for the resolution ; thus , we need to exploit more information from its context [ 17 ] .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
14:1			15:1			0		1.0
15:1			14:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 4221
The analysis of BioNLP-ST 2011 also showed that we need different strategy to resolve such pronouns [ 18 ] .
The analysis of BioNLP-ST 2011 also showed that we need a different strategy to resolve such pronouns [ 18 ] .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0

Alignment 4222
Fortunately , the key to this problem lies in the context of pronouns .
Fortunately , the key to this problem lies in the context of pronouns .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 4223
We implemented a simple function to classify the semantic type of a possessive pronoun based on its context word .
We implemented a simple function to classify the semantic type of a possessive pronoun , based on its context word .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0

Alignment 4224
In particular , we check the noun phrase whose determiner is its or their ; if the noun phrase contains a protein key word then the inclusive pronoun is classified into the Protein semantic type .
In particular , we check the noun phrase in which the determiner is its or their ; if the noun phrase contains a protein key word , then the inclusive pronoun is classified into the Protein semantic type .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
10:1			31:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
27:1			24:1			0		1.0
28:1			25:1			0		1.0
29:1			26:1			0		1.0
30:1			27:1			0		1.0
31:1			28:1			0		1.0
32:1			29:1			0		1.0
33:1			30:1			0		1.0
35:1			32:1			0		1.0
36:1			33:1			0		1.0
37:1			34:1			0		1.0
38:1			35:1			0		1.0

Alignment 4225
protein key words can be a verb , a noun or an adjective that coocurred with protein mentions and can be used as a clue to distinguish the protein type from other semantic types .
Protein key words can be a verb , a noun or an adjective that co-occurred with protein mentions , and can be used as a clue to distinguish the protein type from other semantic types .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0

Alignment 4226
For example , the word binding in the following noun phrases its heterodimeric binding partner , or its binding site is a good clue to infer that it must be a protein reference .
For example , the word binding in the following noun phrases : its heterodimeric binding partner , or its binding site , is a clue to infer that it must be a protein reference .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0

Alignment 4227
For our preliminary experiment , we collect these key words manually by checking the noun phrases containing its and their in training data .
For our preliminary experiment , we collect these keywords manually by checking the noun phrases containing its and their in the training data .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 4228
Our final protein key word set includes 12 words : binding , expression , interaction , regulation , phosphatase activity , localization , gene , sequence , region , phosphorylation , transactivation , and transcription .
Our final protein keyword set includes 12 words : binding , expression , interaction , regulation , phosphatase activity , localization , gene , sequence , region , phosphorylation , transactivation , and transcription .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0
31:1			32:1			0		1.0
32:1			33:1			0		1.0
33:1			34:1			0		1.0
34:1			35:1			0		1.0

Alignment 4229
In future , the protein key words can be collected automatically using the term corpus , or other resources of proteins .
In future , the protein key words can be collected automatically using the term corpus , or other resources of proteins .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 4230
Coreferential definite noun phrases in text are used in broader meaning of coreference .
Coreferential definite noun phrases in text are used to include a broader definition of coreference .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:2			7:2			3		1.0
11:1			9:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0

Alignment 4231
In other words , their antecedents do not necessarily exist in the textual context ; in particular in biomedical scientific papers , many definite noun phrases do not have antecedents since the referred concepts can be anything understood by experts in the domain .
In other words , their antecedents do not necessarily exist in the textual context ; in particular , in biomedical scientific papers , many definite noun phrases do not have antecedents , since the referenced concepts can include any concept that is understood by subject matter experts in the domain .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			21:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
32:1			30:1			0		1.0
33:1			31:1			0		1.0
35:1			33:1			0		1.0
36:1			34:1			0		1.0
42:1			37:1			0		1.0
43:1			38:1			0		1.0
46:1			39:1			0		1.0
47:1			40:1			0		1.0
48:1			41:1			0		1.0
49:1			42:1			0		1.0
50:1			43:1			0		1.0

Alignment 4232
Distinguishing such non-anaphoric definite noun phrases from anaphoric ones is an uneasy task .
Distinguishing such non-anaphoric definite noun phrases from anaphoric ones is a difficult task .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:2			9:2			3		1.0
11:1			11:1			3		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 4233
Knowing their semantic type helps to filter out irrelevant candidate antecedents , increasing chance to pick up the right antecedent or the precision of antecedent prediction .
Knowing their semantic type helps to filter out irrelevant candidate antecedents , thereby increasing the chance of picking up the right antecedent , and increasing the precision of antecedent prediction .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			21:1			0		1.0
15:2			13:2			3		1.0
17:1			15:1			1		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
26:1			22:1			0		1.0
27:1			23:1			0		1.0
28:1			24:1			0		1.0
29:1			25:1			0		1.0
30:1			26:1			0		1.0

Alignment 4234
In our implementation , decision to keep an anaphoric expression for further processing steps for an anaphoric definite noun phrase is based on a protein head word list .
In our implementation , the decision to keep an anaphoric expression for further processing steps for an anaphoric definite noun phrase is based on a protein head word list .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0

Alignment 4235
We tested two different head word lists : one is built automatically from the gold anaphoric nominals in gold data , the other word list contains top seven common head words : protein , gene , factor , molecule , element , family , inhibitor , and receptor .
We tested two different head word lists : one is built automatically from the gold anaphoric nominals in gold data ; the other word list contains the top seven common head words : protein , gene , factor , molecule , element , family , inhibitor , and receptor .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
37:1			36:1			0		1.0
38:1			37:1			0		1.0
39:1			38:1			0		1.0
40:1			39:1			0		1.0
41:1			40:1			0		1.0
42:1			41:1			0		1.0
43:1			42:1			0		1.0
44:1			43:1			0		1.0
45:1			44:1			0		1.0
46:1			45:1			0		1.0
47:1			46:1			0		1.0
48:1			47:1			0		1.0
49:1			48:1			0		1.0

Alignment 4236
Semantic type information can be used in coreference resolution in several ways .
Semantic type information can be used in coreference resolution in several ways .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 4237
First , in anaphor selection , semantic information can be used to filter out non-protein anaphoric expressions .
First , in anaphor selection , semantic information can be used to filter out non-protein anaphoric expressions .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 4238
Second , in antecedent candidate filtering , semantic agreement between the antecedent candidates and the anaphoric expression is checked .
Second , in antecedent candidate filtering , semantic agreement between the antecedent candidates and the anaphoric expression is checked .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 4239
Those candidates which are not agree with the anaphor in semantics are filtered out .
Those candidates that are not in agreement with the anaphor in semantics are filtered out .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:2			2:2			3		1.0
4:1			4:1			0		1.0
5:2			5:1			3		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0

Alignment 4240
For example , if anaphor is classified as protein referent , then non-protein antecedent candidates are removed from the candidate set of the anaphor .
For example , if an anaphor is classified as a protein referent , then the non-protein antecedent candidates are removed from the candidate set of the anaphor .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0
26:1			23:1			0		1.0
27:1			24:1			0		1.0

Alignment 4241
Finally , in antecedent prediction : semantic agreement again can be used as a constraint when comparing two antecedent candidates to select the more probable candidate .
Finally , in antecedent prediction : semantic agreement can again be used as a constraint when comparing two antecedent candidates to select the more probable candidate .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			9:1			0		1.0
9:1			8:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 4242
Our minimal system configuration includes all the processing and filters from step 0 to step 3 as explained in the above section ( RB-MIN ) .
Our minimal system configuration includes all of the processing and filters from step 0 to step 3 , as explained in the section above ( RB-MIN ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			21:1			0		1.0
23:1			20:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0

Alignment 4243
For antecedent candidate selection , the window size used in step 4 is set to 2 , which means antecedent candidates are collected in the two nearest sentences from the anaphor , and the sentence embedding the anaphor .
For antecedent candidate selection , the window size used in step 4 is set to 2 , which means that antecedent candidates are collected in the two nearest sentences from the anaphor , and the sentence embedding the anaphor .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
37:1			36:1			0		1.0
38:1			37:1			0		1.0
39:1			38:1			0		1.0

Alignment 4244
As the statistics measured on the training set of the corpus shows that 97 .0% percent of protein coreference links have antecedents appearing in within 2 sentences .
The statistics measured on the training set of the corpus shows that 97 .0% percent of protein coreference links have antecedents appearing in within 2 sentences .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0

Alignment 4245
With this window size , the average number of candidates per anaphor is 6 .1 .
With this window size , the average number of candidates per anaphor is 6 .1 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 4246
Also , experiments with wider window sizes did not help .
Also , experiments with wider window sizes did not help .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 4247
The word list used to filter out anaphoric definite noun phrases in step 2 contains the following words : protein , gene , factor , molecule , element ,family , inhibitor , and receptor .
The word list used to filter out anaphoric definite noun phrases in step 2 contains the following words : protein , gene , factor , molecule , element , family , inhibitor , and receptor .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			31:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0

Alignment 4248
These words are selected from the top appearring head words extracted from the training data .
These words are selected from the top appearing head words extracted from the training data .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			1		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 4249
Besides , premodifiers of definite noun phrases are also limited to numbers and popular premodifiers of proteins such as nuclear , transcription .
Premodifiers of definite noun phrases are also limited to numbers and popular premodifiers of proteins , such as nuclear , and transcription .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			3:1			0		1.0
2:1			4:1			0		1.0
3:1			5:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			1:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 4250
Using this head word list and premodifiers , the system covers 83 .5 percent of the coreference links .
Using this head word list and premodifiers , the system covers 83 .5 percent of the coreference links .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 4251
To keep the minimal configuration simple , step 4 - antecedent selection of the baseline only uses the default comparison rule , which assures the closest antecedent candidate is selected .
To keep the minimal configuration simple , step 4 - antecedent selection of the baseline only uses the default comparison rule , which assures that the closest antecedent candidate is selected .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0

Alignment 4252
Table 2 compares our system with the top four official results of the COREF shared task in BioNLP-ST 2011 [ 18 ] : UU [ 11 ] , UZ [ 29 ] , CU , and UT [ 4 ] .
Table 2 compares our system with the top four official results of the COREF shared task in BioNLP-ST 2011 [ 18 ] : UU [ 11 ] , UZ [ 29 ] , CU , and UT [ 4 ] .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0

Alignment 4253
The scoring scheme used throughout this paper is the protein coreference evaluation , the primary evaluation method of the COREF shared task [ 18 ] .
The scoring scheme used throughout this paper is the protein coreference evaluation , the primary evaluation method of the COREF shared task [ 18 ] .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 4254
This primary evaluation method , which was particularly designed for the shared task , is based on protein coreference links automatically generated from manually annotated coreference links .
This primary evaluation method , which was particularly designed for the shared task , is based on protein coreference links that have been automatically generated from manually annotated coreference links .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0
26:1			23:1			0		1.0
27:1			24:1			0		1.0
28:1			25:1			0		1.0
29:1			26:1			0		1.0
30:1			27:1			0		1.0

Alignment 4255
The last column ALL shows the overall results , while its preceding three columns PRON , DNP , and RELAT shows the protein resolution results by three major subtypes of anaphors : pronouns , definite noun phrase and relative pronouns , respectively .
The last column ALL shows the overall results , while its preceding three columns PRON , DNP , and RELAT shows the protein resolution results by three major subtypes of anaphors : pronouns , definite noun phrase and relative pronouns , respectively .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0

Alignment 4256
Note that RB-MIN with minimal configuration already outperforms the best result by the UU team , with up to 7 .1% higher in Fscore .
Note that the results from RB-MIN with minimal configuration , already surpasses the best results obtained by the UU team , with up to 7 .1% higher performance in F-score .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			12:1			0		1.0
5:1			2:1			0		1.0
6:1			3:1			0		1.0
7:1			4:1			0		1.0
8:1			5:1			0		1.0
9:1			15:1			0		1.0
10:1			6:1			0		1.0
11:1			7:1			2		1.0
12:1			8:1			0		1.0
13:1			9:1			0		1.0
14:1			10:1			1		1.0
16:1			11:1			0		1.0
18:1			13:1			0		1.0
19:1			14:1			0		1.0
21:1			16:1			0		1.0
22:1			17:1			0		1.0
23:1			18:1			0		1.0
24:1			19:1			0		1.0
25:1			20:1			0		1.0
26:1			21:1			0		1.0
28:1			22:1			0		1.0
30:1			24:1			0		1.0

Alignment 4257
Since RB-MIN uses similar preprocessing tools as UU [ 11 ] , but less information in antecedent prediction , this gap in performance is supposed to be caused by the different markable detection methods .
Since RB-MIN uses similar preprocessing tools as UU [ 11 ] , but less information in antecedent prediction , this gap in performance is likely caused by the different markable detection methods .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
25:1			27:1			0		1.0
26:1			28:1			0		1.0
27:1			29:1			0		1.0
28:1			30:1			0		1.0
29:1			31:1			0		1.0
30:1			32:1			0		1.0
31:1			33:1			0		1.0
32:1			34:1			0		1.0

Alignment 4258
UU pointed in their paper that markable detection is one of the challenges of this task [ 11 ] .
UU pointed in their paper that markable detection is one of the challenges of this task [ 11 ] .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 4259
In their system , UU used a machine learning approach , and tested two distinguished models for markable detection : one solved both anaphors and antecedents together , the other treated anaphors and antecedents separately .
In their system , UU used a machine learning approach , and tested two distinguished models for markable detection : one solved both anaphors and antecedents together , the other treated anaphors and antecedents separately .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0

Alignment 4260
Meanwhile , our method is basically based on the boundary of noun phrases and pronouns , as is outputted from the parser .
Meanwhile , our method is basically based on the boundary of noun phrases and pronouns , as is outputted from the parser .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 4261
The patterns used to extract the proper noun phrases and pronouns , are manually designed concerning the markable boundaries annotated in the training data .
The patterns used to extract the proper noun phrases and pronouns , are manually designed concerning the markable boundaries annotated in the training data .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 4262
Breaking down the system performance by types of anaphors gives us an insight into what have been solved by our methods , and what needs more improvement effort .
Breaking down the system performance by the different types of anaphors provides us with insight into what has been accomplished / solved by our methods , and also provides us with improvement opportunities .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:2			9:2			3		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:2			15:2			3		1.0
21:1			17:1			0		1.0
22:1			18:1			0		1.0
23:1			19:1			0		1.0
24:1			20:1			0		1.0
25:1			21:1			0		1.0
26:1			22:1			0		1.0
31:1			26:1			0		1.0
33:1			28:1			0		1.0

Alignment 4263
Concerning the RELAT type of coreference , we can see that RB-MIN and RB-FULL both achieve comparable results with the best team in BioNLP-ST 2011 .
Concerning the RELAT type of coreference , we can see that RB-MIN and RB-FULL both achieve comparable results with the best team in BioNLP-ST 2011 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 4264
However , it should be noted that our antecedent prediction for the RELAT type is based completely on the output of Enju parser for the RELAT type , so in order to improve this type of coreference , we have to find ways to overcome the parse errors on noun phrase boundary detection and relative clause attachment ( See section Discussions ) .
However , it should be noted that our antecedent prediction for the RELAT type is based solely on the output of the Enju parser for the RELAT type , so in order to improve this type of coreference , we have to find ways to overcome the parse errors on noun phrase boundary detection and relative clause attachment ( See Discussions section ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			45:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
37:1			36:1			0		1.0
38:1			37:1			0		1.0
39:1			38:1			0		1.0
40:1			39:1			0		1.0
41:1			40:1			0		1.0
42:1			41:1			0		1.0
43:1			42:1			0		1.0
44:1			43:1			0		1.0
45:1			44:1			0		1.0
47:1			46:1			0		1.0
48:1			47:1			0		1.0
49:1			48:1			0		1.0
50:1			49:1			0		1.0
51:1			50:1			0		1.0
52:1			51:1			0		1.0
53:1			52:1			0		1.0
54:1			53:1			0		1.0
55:1			54:1			0		1.0
56:1			55:1			0		1.0
57:1			56:1			0		1.0
58:1			57:1			0		1.0
59:1			58:1			0		1.0
60:1			60:1			0		1.0
61:1			59:1			0		1.0
62:1			61:1			0		1.0
63:1			62:1			0		1.0

Alignment 4265
The increase in system performance on the PRON and DNP types by RB-FULL demonstrate the effectiveness of discourse and semantic information in the performance of protein coreference resolution .
The increase in system performance on the PRON and DNP types by RB-FULL demonstrate the effectiveness of discourse and semantic information in the performance of protein coreference resolution .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 4266
Comparing RB-MIN , RB-FULL and RB-MIN+1 , 3 , we found that rule 3 , which stands for discourse preference , works well for the PRON type ( 2 ) .
Comparing RB-MIN , RB-FULL and RB-MIN+1 , 3 , we found that rule 3 , which stands for discourse preference , works well for the PRON type ( 2 ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0

Alignment 4267
On the other hand , the major contribution to the improvement of DNP resolution is from rule 2 .
On the other hand , the major contribution to the improvement of DNP resolution is from rule 2 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 4268
This rule successfully utilizes the domain-specific information , which shows that coreference resolution requires domain-specific information .
This rule successfully utilizes the domain-specific information , which shows that coreference resolution requires domain-specific information .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 4269
To further explore the elements contributed to this significant improvement , we analyzed our system in more details .
To further explore the elements contributed to this significant improvement , we analyzed our system in more detail .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			1		1.0
18:1			18:1			0		1.0

Alignment 4270
The analysis results are given in section Discussions .
The analyses of the results are provided in the section entitled Discussions .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:3			1:1			3		1.0
4:1			2:1			0		1.0
5:1			3:1			0		1.0
7:1			5:1			0		1.0
9:1			6:1			0		1.0
11:1			7:1			0		1.0
12:1			8:1			0		1.0

Alignment 4271
" >
" >
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0

Alignment 4272
Table 3 compares various configurations of the rule-based system .
Table 3 compares various configurations of the rule-based system .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 4273
The first , RB-MIN , is the minimal system .
The first , RB-MIN , is the minimal system .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 4274
The following three show contribution of the three rules , NUM-AGREE , SEM-CONS , and DISC-PREF .
The following three show the contribution of the three rules , NUM-AGREE , SEM-CONS , and DISC-PREF .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0

Alignment 4275
RB-FULL is the full system .
RB-FULL is the full system .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0

Alignment 4276
To emphasize the contribution of the semantic rules , it also shows RB-FULL-sem system .
To emphasize the contribution of the semantic rules , it also shows RB-FULL-sem system .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 4277
The combination of rule 1 , 2 and 3 resulted in 62 .4% fscore ( RB-MIN+1 , 2 , 3 ) ( Table 3 ) In this configuration , rule 2 contribute to the increasement of 4 points Fscore on the development set , and 2 .3 points Fscore on the test set , when comparing RB-MIN+1 , 3 and RB-MIN+1 , 2 , 3 .
The combination of rule 1 , 2 and 3 resulted in a 62 .4% F-score ( RB-MIN+1 , 2 , 3 ) ( Table 3 ) In this configuration , rule 2 contributes to a 4-point F-score increase in the development set , and 2 .3-point F-score increase on the test set , when comparing RB-MIN+1 , 3 and RB-MIN+1 , 2 , 3 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:2			31:2			3		1.0
38:3			39:3			3		1.0
41:1			42:1			0		1.0
42:1			43:1			0		1.0
43:1			44:1			0		1.0
44:1			45:1			0		1.0
48:1			49:1			0		1.0
49:1			50:1			0		1.0
50:1			51:1			0		1.0
51:1			52:1			0		1.0
52:1			53:1			0		1.0
53:1			54:1			0		1.0
54:1			55:1			0		1.0
55:1			56:1			0		1.0
56:1			57:1			0		1.0
57:1			58:1			0		1.0
58:1			59:1			0		1.0
59:1			60:1			0		1.0
60:1			61:1			0		1.0
61:1			62:1			0		1.0
62:1			63:1			0		1.0
63:1			64:1			0		1.0
64:1			65:1			0		1.0

Alignment 4278
However , the result of RB-MIN is more than still 7 points higher than the state-of-the-art performance .
However , the result of RB-MIN is still more than 7 points higher than in state-of-the-art performance .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			9:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 4279
This gain is due to the fact that the rule ensures the semantic type of antecedents is the same as their anaphors , enabling the correct detection of antecedents .
This gain is due to the fact that the rule ensures that the semantic type of antecedents is the same as for their anaphors , thus enabling the correct detection of antecedents .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
26:1			23:1			0		1.0
27:1			24:1			0		1.0
28:1			25:1			0		1.0
29:1			26:1			0		1.0
30:1			27:1			0		1.0
31:1			28:1			0		1.0
32:1			29:1			0		1.0

Alignment 4280
In other words , if anaphor is classified as a protein reference , then antecedent must also be a protein reference .
In other words , if an anaphor is classified as a protein reference , then the antecedent must also be a protein reference .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0

Alignment 4281
The following examples illustrate the way rule 2 works .
The following examples illustrate the way rule 2 works .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 4282
( Coreference examples in this paper are represented as below : gold anaphoric and antecedent expressions are bracketed , antecedents before anaphors ; gold protein mentions are underlined ; and incorrect response antecedents are in italics . )
( Coreference examples in this paper are represented in the following manner : gold anaphoric and antecedent expressions are bracketed , antecedents before anaphors ; gold protein mentions are underlined ; and incorrect response antecedents are in italics . )
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			34:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
33:1			31:1			0		1.0
34:1			32:1			0		1.0
35:1			33:1			0		1.0
37:1			35:1			0		1.0
38:1			36:1			0		1.0
39:1			37:1			0		1.0

Alignment 4283
- " Therefore , [ IRF-1 ] may be an important contributor to IL-12 signaling , and we speculate that the defective IL-12 responses seen in IRF-1- / - mice might be attributable , in part , to the absence of [ this transcription factor ] . " ( PMID-10358173 )
- " Therefore , [ IRF-1 ] may be an important contributor to IL-12 signaling , and we speculate that the defective IL-12 responses seen in IRF-1- / - mice might be attributable , in part , to the absence of [ this transcription factor ] . " ( PMID-10358173 )
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0
49:1			49:1			0		1.0
50:1			50:1			0		1.0

Alignment 4284
In this example , without rule 2 , the faulty response antecedent of this transcription factor is part because it is the closet antecedent candidate agreeing with the anaphor on the singular number .
In this example , without rule 2 , the faulty response antecedent of this transcription factor is part because it is the closet antecedent candidate agreeing with the anaphor on the singular number .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0

Alignment 4285
Meanwhile since this transcription factor is recognized as a protein reference , its closest protein antecedent IRF-1 was successfully detected by RB-FULL .
Meanwhile , since this transcription factor is recognized as a protein reference , its closest protein antecedent IRF-1 was successfully detected by RB-FULL .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0

Alignment 4286
Another interesting example is
Another example is :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			2:1			0		1.0
2:1			3:1			0		1.0

Alignment 4287
- " This role for [ c-Myc ] in apoptosis is now confirmed in studies using a dominant negative form of [ its ] heterodimeric binding partner , Max , which . . . " ( PMID-7964516 )
- " This role for [ c-Myc ] in apoptosis is now confirmed in studies using a dominant negative form of [ its ] heterodimeric binding partner , Max , which . . . " ( PMID-7964516 )
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0

Alignment 4288
Concerning the anaphoric pronoun its in this example , there are several antecedent candidates : this role , c-Myc , apoptosis , studies , a dominant negative form of its heterodimeric binding partner .
Concerning the anaphoric pronoun its in this example , there are several antecedent candidates : this role , c-Myc , apoptosis , studies , a dominant negative form of its heterodimeric binding partner .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0

Alignment 4289
Although studies and a dominant negative form of its heterodimeric binding partner have been crossed out because of disagreement in numbers , and violation of abandoned syntactic constraints correspondingly , the system would return the incorrect antecedent apoptosis instead of c-Myc .
Although studies and a dominant negative form of its heterodimeric binding partner have been crossed out because of disagreement in numbers , and violation of abandoned syntactic constraints , correspondingly , the system would return the incorrect antecedent apoptosis instead of c-Myc .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			29:1			0		1.0
29:1			28:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
37:1			36:1			0		1.0
38:1			37:1			0		1.0
39:1			38:1			0		1.0
40:1			39:1			0		1.0
41:1			40:1			0		1.0
42:1			41:1			0		1.0

Alignment 4290
Fortunately , the containing noun phrase of the anaphor its has the modifier word binding , which is a clue for classifying its as a protein reference ( See Semantic type classification for pronominal anaphors ) .
Fortunately , the containing noun phrase of the anaphor its has the modifier word binding , which is a clue for classifying its as a protein reference ( See Semantic type classification for pronominal anaphors ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0

Alignment 4291
Rule 2 utilizes semantic classification result to make correct selection .
Rule 2 utilizes semantic classification result to make the correct selection .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0

Alignment 4292
In our system , domain-specific semantic information is ultilized at two places : anaphor selection and antecedent prediction .
In our system , domain-specific semantic information is utilized in two places : anaphor selection and antecedent prediction .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:2			9:2			3		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 4293
The effect of semantic information in antecedent prediction has been analyzed in above section .
The effect of semantic information in antecedent prediction has been analyzed in the sections above .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:2			13:1			3		1.0
14:1			12:1			0		1.0
15:1			14:1			0		1.0

Alignment 4294
In this subsection , we are going to explore the contribution of semantic information in the anaphor selection step .
In this subsection , we are going to explore the contribution of semantic information in the anaphor selection step .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 4295
To classify anaphors into protein or non-protein reference , our system employs a head-word based classfier for definite noun phrases , DEFNP-ANA-SEM , and a context-based classifier for pronouns , PRO-ANA-SEM ( Section Methods ) .
To classify anaphors into protein or non-protein reference , our system employs a head-word based classifier for definite noun phrases , DEFNP-ANA-SEM , and a context-based classifier for pronouns , PRO-ANA-SEM ( Section Methods ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			26:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0

Alignment 4296
Without limiting the number of anaphors by using semantic information-based filtering , the precision significantly drops , causing a big decrease in Fscore ( Table 4 , RB-FULL w / o DEFNP-ANA-SEM ) . .
Without limiting the number of anaphors by using semantic information-based filtering , the precision significantly drops , causing a big decrease in the F-score ( Table 4 , RB-FULL without DEFNP-ANA-SEM ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
30:1			31:1			0		1.0
31:1			32:1			0		1.0
32:1			33:1			0		1.0

Alignment 4297
This is because the semantic filter is the only way to filter out definite noun phrase anaphors .
This decrease is due to the fact that the semantic filter is the only way to filter out definite noun phrase anaphors .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			3		1.0
4:1			10:1			0		1.0
5:1			7:1			0		1.0
8:1			3:1			0		1.0
9:1			4:1			0		1.0
10:1			5:1			0		1.0
11:1			6:1			0		1.0
13:1			8:1			0		1.0
14:1			9:1			0		1.0
16:1			11:1			0		1.0
17:1			12:1			0		1.0
18:1			13:1			0		1.0
19:1			14:1			0		1.0
20:1			15:1			0		1.0
21:1			16:1			0		1.0
22:1			17:1			0		1.0

Alignment 4298
Without the filter , all definite expressions , which include a huge amount of non-anaphoric expressions , are considered as anaphors .
Without the filter , all definite expressions , which include a huge amount of non-anaphoric expressions , are considered as anaphors .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 4299
Besides the anaphoric use , definite noun phrases are also used to refer to entities or concepts in the common domain knowledge shared between readers and writers .
Besides the anaphoric use , definite noun phrases are also used to refer to entities or concepts in the common domain knowledge shared between readers and writers .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0

Alignment 4300
Statistics in [ 21 ] show that only around 30% of definite noun phrases are anaphoric , and the other uses according to their classification include associative , unfamiliar / larger situation , idiom and doubt .
Statistics in [ 21 ] show that only around 30% of definite noun phrases are anaphoric , and the other uses according to their classification include associative , unfamiliar / larger situation , idiom and doubt .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0

Alignment 4301
Distinguishing such non-anaphoric definite noun phrases from anaphoric ones is extremely difficult .
Distinguishing such non-anaphoric definite noun phrases from anaphoric ones is extremely difficult .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 4302
In our system , contextual information of possessive pronouns is utilized through the protein key words ( Section Methods ) , and this contributed to 1 .8% gain in f-score ( Table 4 , RB-FULL w / o PRO-ANA-SEM ) .
In our system , contextual information of possessive pronouns is utilized through the protein key words ( Section Methods ) , and this contributed to a 1 .8% gain in F-score ( Table 4 , RB-FULL without PRO-ANA-SEM ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
37:1			38:1			0		1.0
38:1			39:1			0		1.0
39:1			40:1			0		1.0

Alignment 4303
This is an encouraging sign to seek for a systematic method to exploit and include such contextual information in coreference resolution .
This gain is a good indication for seeking a systematic method to develop and include such contextual information in coreference resolution .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:2			1:2			3		1.0
6:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:2			12:2			3		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 4304
Below are the examples showing the effectiveness of semantic information from the context of pronouns .
Examples showing the effectiveness of semantic information from the context of pronouns is provided below :
Line2Start:Length	Line1Start:Length	Module		Score
1:1			4:1			0		1.0
2:1			5:1			0		1.0
3:1			6:1			0		1.0
4:1			7:1			0		1.0
5:1			8:1			0		1.0
6:1			9:1			0		1.0
7:1			10:1			0		1.0
8:1			11:1			0		1.0
9:1			12:1			0		1.0
10:1			13:1			0		1.0
11:1			14:1			0		1.0

Alignment 4305
- " This role for [ c-Myc ] in apoptosis is now confirmed in studies using a dominant negative form of [ its ] heterodimeric binding partner , Max , which . . . " ( MID-7964516 )
- " This role for [ c-Myc ] in apoptosis is now confirmed in studies using a dominant negative form of [ its ] heterodimeric binding partner , Max , which . . . " ( MID-7964516 )
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0

Alignment 4306
- " This ability of [ CIITA ] to facilitate promoter occupation is undissociable from [ its ] transactivation potential . " ( PMID-10221658 )
- " This ability of [ CIITA ] to facilitate promoter occupation is undissociable from [ its ] transactivation potential . " ( PMID-10221658 )
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 4307
- " In transient transfectin experiments , [ BCL6 ] can repress transcription from promoters linked to [ its ] DNA target sequence and this activity is . . . " ( PMID-8692924 )
- " In transient transfectin experiments , [ BCL6 ] can repress transcription from promoters linked to [ its ] DNA target sequence and this activity is . . . " ( PMID-8692924 )
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0

Alignment 4308
- " [ Human immunodeficiency virus type 1 ( HIV-1 ) Tat ] , an early regulatory protein that is critical for viral gene expression and replication , transactivates the HIV-1 long terminal repeat ( LTR ) via [ its ] binding to the transactivation response element ( TAR ) and , . . . " ( PMID-9261367 )
- " [ Human immunodeficiency virus type 1 ( HIV-1 ) Tat ] , an early regulatory protein that is critical for viral gene expression and replication , transactivates the HIV-1 long terminal repeat ( LTR ) via [ its ] binding to the transactivation response element ( TAR ) and , . . . " ( PMID-9261367 )
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0
49:1			49:1			0		1.0
50:1			50:1			0		1.0
51:1			51:1			0		1.0
52:1			52:1			0		1.0
53:1			53:1			0		1.0
54:1			54:1			0		1.0
55:1			55:1			0		1.0
56:1			56:1			0		1.0
57:1			57:1			0		1.0
58:1			58:1			0		1.0

Alignment 4309
In all the above examples , the appearance of words such as binding , transactivation , DNA target sequence in the noun phrases of which the anaphor plays a role as a determiner , is contextual indicator for the protein type .
In all the examples above , the appearance of words such as binding , transactivation , DNA target sequence in the noun phrases for which the anaphor plays a role as a determiner , is a contextual indicator for the protein type .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			4:1			0		1.0
4:1			3:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			37:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
36:1			35:1			0		1.0
37:1			36:1			0		1.0
39:1			38:1			0		1.0
40:1			39:1			0		1.0
41:1			40:1			0		1.0
42:1			41:1			0		1.0

Alignment 4310
Since the anaphors are predicted as protein reference from their context , the system correctly detects their protein antecedents .
Since the anaphors are predicted as protein reference from their context , the system correctly detects their protein antecedents .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 4311
Other challenges specific to the protein coreference task Number agreement is a constraint in English writing .
Other challenges specific to the protein coreference task Number agreement is a constraint in English writing .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 4312
However , we found in the data several coreferential expressions violating this constraint .
However , in the data , we found several coreferential expressions that violate this constraint .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			4:1			0		1.0
3:1			5:1			0		1.0
4:1			6:1			0		1.0
6:1			2:1			0		1.0
7:1			3:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:2			10:1			3		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0

Alignment 4313
For instance , the anaphor and antecedent in the following :
The anaphor and antecedent in the following is an instance of this violation :
Line2Start:Length	Line1Start:Length	Module		Score
1:1			4:1			0		1.0
2:1			5:1			0		1.0
3:1			6:1			0		1.0
4:1			7:1			0		1.0
5:1			8:1			0		1.0
6:1			9:1			0		1.0
9:1			1:1			0		1.0
13:1			10:1			0		1.0

Alignment 4314
- " . . .for OTF-2 in DRA gene transcription .
- " . . .for OTF-2 in DRA gene transcription .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 4315
In contrast , [ OTF-1-enriched protein fractions ] did not affect DRA gene transcription although [ it ] functionally enhanced the transcription of another . . . " ( PMID-1560002 )
In contrast , [ OTF-1-enriched protein fractions ] did not affect DRA gene transcription although [ it ] functionally enhanced the transcription of another . . . " ( PMID-1560002 )
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0

Alignment 4316
Coreference annotation and evaluation Current protein coreference evaluation scheme generates protein links ( links between anaphors and antecedent proteins ) from surface links ( links between anaphors and antecedent expressions ) , without concerning the relative position of antecedent proteins in the antecedent expression .
Coreference annotation and evaluation Current protein coreference evaluation schemes generate protein links ( links between anaphors and antecedent proteins ) from surface links ( links between anaphors and antecedent expressions ) , without concerning the relative position of antecedent proteins in the antecedent expression .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			1		1.0
9:1			9:1			1		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0

Alignment 4317
Therefore , when the proteins appear in premodifiers or postmodifers of noun phrases as [ cDNAs encoding EBF or a covalent homodimer of E47 ] in this example
Therefore , when the proteins appear in premodifiers or postmodifers of noun phrases as [ cDNAs encoding EBF or a covalent homodimer of E47 ] in this example :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0

Alignment 4318
- " With the aim of identifying genetic targets for these transcription factors , we stably transfected [ cDNAs encoding EBF or a covalent homodimer of E47 ] , individually or together , into immature hematopoietic Ba / F3 cells , which lack [ both factors ] . " ( PMID-9252117 )
- " With the aim of identifying genetic targets for these transcription factors , we stably transfected [ cDNAs encoding EBF or a covalent homodimer of E47 ] , individually or together , into immature hematopoietic Ba / F3 cells , which lack [ both factors ] . " ( PMID-9252117 )
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0
49:1			49:1			0		1.0
50:1			50:1			0		1.0
51:1			51:1			0		1.0

Alignment 4319
Such proteins might not be the right antecedent proteins .
Such proteins might not be the correct antecedent proteins .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			2		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 4320
In furture , corpus annotation and evaluation scheme should be revised for the ease of automation of coreference resolution .
In future , revision of corpus annotation and evaluation schemes would benefit the ease of automation of coreference resolution .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			2:1			0		1.0
3:2			10:1			3		1.0
5:1			3:1			0		1.0
6:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			1		1.0
10:1			8:1			3		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 4321
Parse error Coreference expression boundary is determined mostly based on noun phrase boundary output from parser .
Parse error Coreference expression boundary is determined mostly based on noun phrase boundary output from the parser .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0

Alignment 4322
Therefore , parse error on noun phrase boundary strongly affects the performance of coreference resolution .
Therefore , parse error on noun phrase boundary strongly affects the performance of coreference resolution .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 4323
Examining the data , we found that many antecedent expressions of plural anaphors are coordinated noun phrases , which are unfortunately difficult cases to many parsers including Enju .
Examining the data , we found that many antecedent expressions of plural anaphors are coordinated noun phrases , which are unfortunately difficult cases to many parsers including Enju .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 4324
Incorporation of recent works for coordination resolution like [ 20 ] should be useful to improve the performance .
Incorporation of recent works for coordination resolution like [ 20 ] should be useful for improving the performance .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:2			14:2			3		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 4325
The following example shows a coordination-structured antecedent AML1 / CBF beta , C / EBP , Ets , c-Myb , HOX , and MZF-1 that was failed to be detected by the parser .
The following example shows a coordination-structured antecedent AML1 / CBF beta , C / EBP , Ets , c-Myb , HOX , and MZF-1 that failed to be detected by the parser .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0
31:1			32:1			0		1.0
32:1			33:1			0		1.0

Alignment 4326
The spurious response expression is transcription factors from several families .
The spurious response expression is transcription factors from several families .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 4327
- " granulocytic and monocytic lineages , transcription factors from several families are active , including [ AML1 / CBF beta , C / EBP , Ets , c-Myb , HOX , and MZF-1 ] .
- " granulocytic and monocytic lineages , transcription factors from several families are active , including [ AML1 / CBF beta , C / EBP , Ets , c-Myb , HOX , and MZF-1 ] .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0

Alignment 4328
Few of [ these factors ] are expressed exclusively in myeloid cells ; . . . " ( PMID-9291089 )
Few of [ these factors ] are expressed exclusively in myeloid cells ; . . . " ( PMID-9291089 )
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 4329
Our work has confirmed again that domain knowledge is indispensable for coreference resolution .
Our current work has reconfirmed that domain knowledge is indispensable for coreference resolution .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 4330
Since the biologicaldomain has richer knowledge resources than any other domain , it would be interesting to continue studying how to exploit and employ domain-specific semantic information in coreference resolution for this domain .
Since the biological domain has richer knowledge resources than any other domain , it would be interesting to continue studying how to exploit and employ domain-specific semantic information in coreference resolution for this domain .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0

Alignment 4331
Another conclusion concerns with markable detection .
Another conclusion concerns markable detection .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0

Alignment 4332
This subproblem is often thought as an easy task in coreference resolution systems , however , indeed it is an important subtask which strongly affects the performance of coreference system .
This sub-problem is often regarded as an easy task in coreference resolution systems ; however , in actuality , it is an important subtask , which strongly affects the performance of coreference system .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
18:1			13:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
25:1			22:1			0		1.0
26:1			23:1			0		1.0
27:1			24:1			0		1.0
28:1			25:1			0		1.0
29:1			26:1			0		1.0
30:1			27:1			0		1.0
31:1			28:1			0		1.0
32:1			29:1			0		1.0
33:1			30:1			0		1.0

Alignment 4333
Sticking to the gold data in the designing markable detection method as we did in this paper is one of the strategies .
Sticking to the gold data in designing the markable detection method , as done in this paper , is one employed strategy .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			7:1			0		1.0
7:1			6:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			13:1			2		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
21:1			21:1			1		1.0
22:1			22:1			0		1.0

Alignment 4334
However , from another perspective , the perspective of coreference data creation , we should revise the markable annotations , for the sake of automatic and robust markable detection .
However , from the perspective of coreference data creation , revision of the markable annotations would aid in automatic and robust markable detection .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			6:1			0		1.0
4:1			7:1			0		1.0
5:1			8:1			0		1.0
6:1			9:1			0		1.0
7:1			10:1			0		1.0
8:1			11:1			0		1.0
9:1			12:1			0		1.0
10:3			15:2			3		1.0
13:1			17:1			0		1.0
14:1			18:1			0		1.0
15:1			14:1			3		1.0
18:1			24:1			0		1.0
19:1			25:1			0		1.0
20:1			26:1			0		1.0
21:1			27:1			0		1.0
22:1			28:1			0		1.0
23:1			29:1			0		1.0

Alignment 4335
As for the future , more effort should be spent on automating the semantic classification for coreference expressions using context .
For future opportunities , more effort should be spent on automating the semantic classification for coreference expressions , using context .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 4336
Furthermore , it would be interesting to test the results in this study in a machine learning framework .
Furthermore , it would be interesting to test the results in this study in a machine-learning framework .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0

Alignment 4337
The success of corpus-based methods has made syntactically annotated corpora important resources for natural language processing .
Syntactically annotated corpora have become important resources for natural language processing , due in part to the success of corpus-based methods .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			8:1			0		1.0
2:1			9:1			0		1.0
3:2			5:1			3		1.0
5:1			10:1			0		1.0
6:1			11:1			0		1.0
7:1			12:1			0		1.0
8:1			13:1			0		1.0
9:1			14:1			0		1.0
10:1			15:1			0		1.0
17:1			1:1			0		1.0
18:1			2:1			0		1.0
19:1			3:1			0		1.0
20:1			4:1			0		1.0
21:1			16:1			0		1.0

Alignment 4338
Since words are often considered as the primitive units of language structures , the annotation of word segmentation forms the basis of these corpora .
Since words are often considered as primitive units of language structures , the annotation of word segmentation forms the basis of these corpora .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0

Alignment 4339
This is also a concern of Vietnamese Treebank ( VTB ) , the first and the only publicly available syntactically annotated corpus so far for the Vietnamese language .
This is also a concern for the Vietnamese Treebank ( VTB ) , which is the first and only publicly available syntactically annotated corpus thus far for the Vietnamese language .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			24:1			0		1.0
6:1			15:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:2			22:2			3		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0

Alignment 4340
Although word segmentation is straight-forward for space-delimited languages like English , this is not true for languages like Vietnamese of which no standard criterion for word segmentation exists .
Although word segmentation is straight-forward for space-delimited languages like English , this is not the case for languages like Vietnamese for which a standard criterion for word segmentation does not exist .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:2			14:1			3		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:2			19:2			3		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
30:1			27:1			1		1.0
31:1			28:1			0		1.0

Alignment 4341
This work explores the challenges of Vietnamese word segmentation through the detection and correction of inconsistency for VTB .
This work explores the challenges of Vietnamese word segmentation through the detection and correction of inconsistency for VTB .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 4342
Then , by combining and splitting the inconsistent annotations detected , we could observe the influence of different word segmentation criteria on automatic word segmentation , and the applications of word segmentation , including text classification and English-Vietnamese statistical machine translation .
Then , by combining and splitting the inconsistent annotations that were detected , we are able to observe the influence of different word segmentation criteria on automatic word segmentation , and the applications of word segmentation , including text classification and English-Vietnamese statistical machine translation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:3			12:1			3		1.0
17:1			13:1			0		1.0
18:1			14:1			0		1.0
19:1			15:1			0		1.0
20:1			16:1			0		1.0
21:1			17:1			0		1.0
22:1			18:1			0		1.0
23:1			19:1			0		1.0
24:1			20:1			0		1.0
25:1			21:1			0		1.0
26:1			22:1			0		1.0
27:1			23:1			0		1.0
28:1			24:1			0		1.0
29:1			25:1			0		1.0
30:1			26:1			0		1.0
31:1			27:1			0		1.0
32:1			28:1			0		1.0
33:1			29:1			0		1.0
34:1			30:1			0		1.0
35:1			31:1			0		1.0
36:1			32:1			0		1.0
37:1			33:1			0		1.0
38:1			34:1			0		1.0
39:1			35:1			0		1.0
40:1			36:1			0		1.0
41:1			37:1			0		1.0
42:1			38:1			0		1.0
43:1			39:1			0		1.0
44:1			40:1			0		1.0
45:1			41:1			0		1.0

Alignment 4343
The analysis and experimental results showed that our methods improved the quality of VTB , which positively affected the performance of its applications .
The analysis and experimental results showed that our methods improved the quality of VTB , which positively affected the performance of its applications .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 4344
Treebanks , corpora annotated with syntatic structures , have become more and more impor-tant for language processing .
Treebanks , which are corpora annotated with syntactic structures , have become more and more important for language processing .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
4:1			2:1			0		1.0
5:1			3:1			0		1.0
6:1			4:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0

Alignment 4345
To strengthen the automatic processing of the Vietnamese language , the Vietnamese treebank ( VTB ) has been built as a part of the national project `` Vietnamese language and speech processing ( VLSP ) '' ( Nguyen et al ., 2009b ) .
In order to strengthen the automatic processing of the Vietnamese language , the Vietnamese Treebank ( VTB ) has been built as a part of the national project , `` Vietnamese language and speech processing ( VLSP ) '' ( Nguyen et al ., 2009b ) .
Line2Start:Length	Line1Start:Length	Module		Score
3:1			1:1			0		1.0
4:1			2:1			0		1.0
5:1			3:1			0		1.0
6:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
29:1			26:1			0		1.0
30:1			27:1			0		1.0
31:1			28:1			0		1.0
32:1			29:1			0		1.0
33:1			30:1			0		1.0
34:1			31:1			0		1.0
35:1			32:1			0		1.0
36:1			33:1			0		1.0
37:1			34:1			0		1.0
38:1			35:1			0		1.0
39:1			36:1			0		1.0
40:1			37:1			0		1.0
41:1			38:1			0		1.0
42:1			39:1			0		1.0
43:1			40:1			0		1.0
44:1			41:1			0		1.0
45:1			42:1			0		1.0
46:1			43:1			0		1.0

Alignment 4346
However , in our preliminary experiment with VTB , when we trained the Berkeley parser ( Petrov et al ., 2006 ) and evaluated it using the corpus , the parser achieved only 65 .8% in F-score .
However , in our preliminary experiment with VTB , when we trained the Berkeley parser ( Petrov et al ., 2006 ) and evaluated it by using the corpus , the parser achieved only 65 .8% in F-score .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
37:1			36:1			0		1.0
38:1			37:1			0		1.0

Alignment 4347
This performance is far lower than the state-of-the-art performance reported for Berkeley Parser on English Penn Treebank , 90 .3% in F-score ( Petrov et al ., 2006 ) .
This score is far lower than the state-of-the-art performance reported for the Berkeley Parser on the English Penn Treebank , which reported 90 .3% in F-score ( Petrov et al ., 2006 ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
22:1			18:1			0		1.0
23:1			19:1			0		1.0
24:1			20:1			0		1.0
25:1			21:1			0		1.0
26:1			22:1			0		1.0
27:1			23:1			0		1.0
28:1			24:1			0		1.0
29:1			25:1			0		1.0
30:1			26:1			0		1.0
31:1			27:1			0		1.0
32:1			28:1			0		1.0
33:1			29:1			0		1.0

Alignment 4348
There are two possible reasons for this .
There are two possible reasons to explain this outcome .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:2			4:2			3		1.0
7:1			6:1			0		1.0
9:1			7:1			0		1.0

Alignment 4349
First , the quality of VTB is not good enough to build a good a parser , including the quality of the annotation scheme , the annotation guidelines , and the annotation process .
One reason for this outcome is the quality of VTB , including the quality of the annotation scheme , the annotation guidelines , and the annotation process .
Line2Start:Length	Line1Start:Length	Module		Score
5:1			6:1			0		1.0
6:1			2:1			0		1.0
7:1			3:1			0		1.0
8:1			4:1			0		1.0
9:1			5:1			0		1.0
10:1			16:1			0		1.0
11:1			17:1			0		1.0
12:1			18:1			0		1.0
13:1			19:1			0		1.0
14:1			20:1			0		1.0
15:1			21:1			0		1.0
16:1			22:1			0		1.0
17:1			23:1			0		1.0
18:1			24:1			0		1.0
19:1			25:1			0		1.0
20:1			26:1			0		1.0
21:1			27:1			0		1.0
22:1			28:1			0		1.0
23:1			29:1			0		1.0
24:1			30:1			0		1.0
25:1			31:1			0		1.0
26:1			32:1			0		1.0
27:1			33:1			0		1.0

Alignment 4350
Second , parsing Vietnamese is a diffcult problem by its own , and we need to seek new solutions to the problem .
The second reason is the difficulty of parsing Vietnamese ; we need to seek new solutions to address this problem .
Line2Start:Length	Line1Start:Length	Module		Score
3:1			4:1			0		1.0
4:1			20:1			0		1.0
5:2			7:1			3		1.0
7:1			2:1			0		1.0
8:1			3:1			0		1.0
10:1			13:1			0		1.0
11:1			14:1			0		1.0
12:1			15:1			0		1.0
13:1			16:1			0		1.0
14:1			17:1			0		1.0
15:1			18:1			0		1.0
16:1			19:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0

Alignment 4351
VTB is annotated with three layers : word segmentation , POS tagging , and bracketing .
VTB is annotated with three layers : word segmentation , POS tagging , and bracketing .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 4352
This paper focuses on the word segmentation issues since the most basic unit of a treebank is word ( Di Sciullo and Edwin , 1987 ) , and defining `` What are words ? '' is the first problem that a treebank has to solve ( Xia , 2000b ,a ; Sornlertlamvanich et al ., 1997 , 1999 ) .
This paper focuses on the word segmentation , since the most basic unit of a treebank are words ( Di Sciullo and Edwin , 1987 ) , and defining `` words '' is the first step ( Xia , 2000b ,a ; Sornlertlamvanich et al ., 1997 , 1999 ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			56:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			31:1			0		1.0
17:1			32:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
31:1			34:1			0		1.0
32:1			35:1			0		1.0
33:1			36:1			0		1.0
34:1			37:1			0		1.0
36:1			45:1			0		1.0
37:1			46:1			0		1.0
38:1			47:1			0		1.0
39:1			48:1			0		1.0
40:1			49:1			0		1.0
41:1			50:1			0		1.0
42:1			51:1			0		1.0
43:1			52:1			0		1.0
44:1			53:1			0		1.0
45:1			54:1			0		1.0
46:1			55:1			0		1.0
48:1			57:1			0		1.0
49:1			58:1			0		1.0
50:1			59:1			0		1.0

Alignment 4353
For languages like English , answering this question is almost trivial because the blank spaces denote word delimiters .
For languages like English , defining `` words '' is almost trivial , because the blank spaces denote word delimiters .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0

Alignment 4354
However , for an isolating language like Vietnamese , where blank spaces play a role of syllable delimiters , `` What are words ? '' is not a trivial question .
However , for an isolating language like Vietnamese , for which blank spaces play a role of syllable delimiters , `` What are words ? '' is not a trivial question .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:2			9:1			3		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0

Alignment 4355
For example , the sentence `` H❅c sinh h❅c sinh h❅c ( students learn biology )1 '' is composed of three words `` h❅c sinh ( student ) '' , `` h❅c ( learn ) , '' and `` sinh h❅c ( biology ) ; '' Word segmentation is expected to break down the sentence at the boundaries of these words , not to split `` h❅c sinh ( student ) '' and `` sinh h❅c ( biology ) '' .
For example , the sentence `` H❅c sinh h❅c sinh h❅c ( students learn biology )1 '' is composed of three words , `` h❅c sinh ( student ) '' , `` h❅c ( learn ) , '' and `` sinh h❅c ( biology ) '' . Word segmentation is expected to break down the sentence at the boundaries of these words , instead of splitting `` h❅c sinh ( student ) '' and `` sinh h❅c ( biology ) '' .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			61:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
37:1			36:1			0		1.0
38:1			37:1			0		1.0
39:1			38:1			0		1.0
40:1			39:1			0		1.0
41:1			40:1			0		1.0
42:1			41:1			0		1.0
43:1			42:1			0		1.0
44:1			43:1			0		1.0
45:1			45:1			0		1.0
46:1			80:1			0		1.0
47:1			46:1			0		1.0
48:1			47:1			0		1.0
49:1			48:1			0		1.0
50:1			49:1			0		1.0
51:1			50:1			0		1.0
52:1			51:1			0		1.0
53:1			52:1			0		1.0
54:1			53:1			0		1.0
55:1			54:1			0		1.0
56:1			55:1			0		1.0
57:1			56:1			0		1.0
58:1			57:1			0		1.0
59:1			58:1			0		1.0
60:1			59:1			0		1.0
61:1			60:1			0		1.0
63:1			62:1			3		1.0
64:2			63:2			3		1.0
66:1			65:1			0		1.0
67:1			66:1			0		1.0
68:1			67:1			0		1.0
69:1			68:1			0		1.0
70:1			69:1			0		1.0
71:1			70:1			0		1.0
72:1			71:1			0		1.0
73:1			72:1			0		1.0
74:1			73:1			0		1.0
75:1			74:1			0		1.0
76:1			75:1			0		1.0
77:1			76:1			0		1.0
78:1			77:1			0		1.0
79:1			78:1			0		1.0
80:1			79:1			0		1.0

Alignment 4356
Note that the terminology `` word segmentation '' also refers to the task of extracting words statistically without concerning a gold-standard for segmentation , as in ( Ha , 2003 ; Le et al ., 2010 ) .
Note that the terminology `` word segmentation '' also refers to the task of extracting words statistically without concerning a gold-standard for segmentation , as in ( Ha , 2003 ; Le et al ., 2010 ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0

Alignment 4357
In such context , the extracted words are more appropriate for building a dictionary than for corpus-based language processing , which are out of the focus of this paper .
In such a context , the extracted words are more appropriate for building a dictionary , rather than for corpus-based language processing , which are outside of the scope of this paper .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			19:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0
25:2			22:2			3		1.0
27:1			24:1			0		1.0
29:1			26:1			0		1.0
30:1			27:1			0		1.0
31:1			28:1			0		1.0
32:1			29:1			0		1.0

Alignment 4358
Establishing a gold standard for Vietnamese word segmentation faces some diffcuties coming from the characteristics of the language .
Because of the discussed characteristics of the language , there are challenges in establishing a gold standard for Vietnamese word segmentation .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			13:1			0		1.0
4:1			14:1			0		1.0
5:1			15:1			0		1.0
6:1			16:1			0		1.0
7:1			17:1			0		1.0
14:1			1:1			0		1.0
15:1			2:1			0		1.0
16:1			3:1			0		1.0
17:1			4:1			0		1.0
18:1			5:1			0		1.0
19:1			6:1			0		1.0
20:1			7:1			0		1.0
21:1			18:1			0		1.0

Alignment 4359
The diffculties of Vietnamese word segmentation have been recognized by many researchers ( Ha , 2003 ; Nguyen et al ., 2004 , 2006 ; Le et al ., 2010 ) .
The difficulties in Vietnamese word segmentation have been recognized by many researchers ( Ha , 2003 ; Nguyen et al ., 2004 , 2006 ; Le et al ., 2010 ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0

Alignment 4360
Although most people agree that the Vietnamese language has two types of words : single and compound , there is little consensus on how to segment a sentence into words .
Although most people agree that the Vietnamese language has two types of words : single and compound , there is little consensus as to the methodology for segmenting a sentence into words .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
23:1			24:1			0		1.0
27:1			25:1			1		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0

Alignment 4361
The disagreement is not only because of the different functions of blank spaces as mentioned above , but also because Vietnamese is not an inflectional language like English or Japanese , where morphological forms can be useful clues for word segmentation .
The disagreement occurs not only because of the different functions of blank spaces ( as mentioned above ) , but also because Vietnamese is not an inflectional language , as is the case for English or Japanese , for which morphological forms can provide useful clues for word segmentation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			3		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			30:1			0		1.0
29:4			26:1			3		1.0
33:1			38:1			0		1.0
34:1			27:1			0		1.0
35:1			28:1			0		1.0
36:1			29:1			0		1.0
38:2			31:1			3		1.0
40:1			32:1			0		1.0
41:1			33:1			0		1.0
42:1			34:1			0		1.0
44:1			36:1			0		1.0
45:1			37:1			0		1.0
47:1			39:1			0		1.0
48:1			40:1			0		1.0
49:1			41:1			0		1.0

Alignment 4362
While the similar problems also happen with Chinese word segmentation ( Xia , 2000b ) , Vietnamese word segmentation may be more diffcult because the modern Vietnamese writing system is based on Latin characters , which represents the pronunciation but not the meaning of words .
While similar problems also occur with Chinese word segmentation ( Xia , 2000b ) , Vietnamese word segmentation may be more difficult , because the modern Vietnamese writing system is based on Latin characters , which represent the pronunciation , but not the meaning of words .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			2		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
22:1			34:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
35:1			35:1			0		1.0
36:2			36:2			3		1.0
38:1			38:1			0		1.0
40:1			39:1			0		1.0
41:1			40:1			0		1.0
42:1			41:1			0		1.0
43:1			42:1			0		1.0
44:1			43:1			0		1.0
45:1			44:1			0		1.0
46:1			45:1			0		1.0

Alignment 4363
All these characteristics make it diffcult to perform word segmentation for Vietnamese both manually and automatically , and have resulted in different criteria for word segmenation .
All of these characteristics make it diffcult to perform word segmentation for Vietnamese , both manually and automatically , and have thus resulted in different criteria for word segmentation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
22:1			19:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0
26:1			23:1			0		1.0
27:1			24:1			0		1.0
29:1			26:1			0		1.0

Alignment 4364
However , so far there have been few studies on the challenges in word segmentation , and the comparison of different word segmentation criteria .
However , so far , there have been few studies on the challenges in word segmentation , and the comparison of different word segmentation criteria .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0

Alignment 4365
In this paper , a brief introduction of the Vietnamese treebank VTB and its annotation scheme are given in Section 2 .
In this paper , a brief introduction of the Vietnamese Treebank VTB and its annotation scheme are provided in Section 2 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 4366
Then , we described our methods for the detection and correction of the problematic annotations in the VTB corpus ( Section 4 .2 ) .
Then , we described our methods for the detection and correction of the problematic annotations in the VTB corpus ( Section 4 .2 ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 4367
We classified the problematic annotations into several patterns of inconsistency , part of which were manually fixed to improve the quality of the corpus .
We classified the problematic annotations into several patterns of inconsistency , part of which were manually fixed to improve the quality of the corpus .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 4368
The rest , which can be considered as the most diffcult and controversial cases of word segmentation , were used to create different versions of the VTB corpus representing different word segmentation criteria .
The rest , which can be considered as the most difficult and controversial instances of word segmentation , were used to create different versions of the VTB corpus , representing different word segmentation criteria .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:2			13:2			3		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0

Alignment 4369
Finally , we evaluated these criteria in automatic word segmentation , and its application in text classification and English-Vietnamese statistical machine translation in Section 4 .
Finally , we evaluated these criteria in automatic word segmentation , and its application in text classification and English-Vietnamese statistical machine translation , in Section 4 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0

Alignment 4370
This study is not only beneficial for the development of computational processing technologies for Vietnamese , a language spoken by over 90 million people , but also for the similar languages such as Thai , Laos , and so on .
This study is not only beneficial for the development of computational processing technologies for Vietnamese , a language spoken by over 90 million people , but also for similar languages such as Thai , Laos , and so on .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0
31:1			32:1			0		1.0
32:1			33:1			0		1.0
33:1			34:1			0		1.0
34:1			35:1			0		1.0
35:1			36:1			0		1.0
36:1			37:1			0		1.0
37:1			38:1			0		1.0
38:1			39:1			0		1.0
39:1			40:1			0		1.0

Alignment 4371
This study also promotes the computational linguistic studies on how to transfer methods developed for a popular language like English to a language that has not yet intensively studied .
This study also promotes the computational linguistic studies on how to transfer methods developed for a popular language , like English , to a language that has not yet been intensively studied .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
30:1			27:1			0		1.0
31:1			28:1			0		1.0
32:1			29:1			0		1.0

Alignment 4372
Word segmentation in VTB aims to found a standard for word segmentation in a context of multi-level language processing .
Word segmentation in VTB aims at establishing a standard for word segmentation in a context of multi-level language processing .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:2			4:2			3		1.0
6:1			6:1			2		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 4373
VTB specifies 12 types of units that should be identified as words ( Table 1 ) ( Nguyen et al ., a ) , which can be divided into three groups : single , compound , and special `` words '' .
VTB specifies 12 types of units that should be identified as words ( Table 1 ) ( Nguyen et al ., a ) , which can be divided up into three groups : single , compound , and special `` words '' .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
37:1			36:1			0		1.0
38:1			37:1			0		1.0
39:1			38:1			0		1.0
40:1			39:1			0		1.0
41:1			40:1			0		1.0
42:1			41:1			0		1.0

Alignment 4374
Single words contain only one token .
Single words contain only one token .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0

Alignment 4375
The terminology tokens refers to text spans separated with each other by blank spaces .
The terminology tokens refers to text spans that are separated from each other by blank spaces .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
9:1			7:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0

Alignment 4376
Compound words have two or more tokens , and are divided into four types : compound words composed by semantic coordination ( semantic-coordinated compound ) , compound words composed by semantic subordination ( semantic-subordinated compound ) , compound words with affx , and reduplicated words .
Compound words have two or more tokens , and are divided into four types : compound words composed by semantic coordination ( semantic-coordinated compound ) , compound words composed by semantic subordination ( semantic-subordinated compound ) , compound words with an affx , and reduplicated words .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
41:1			40:1			0		1.0
42:1			41:1			0		1.0
43:1			42:1			0		1.0
44:1			43:1			0		1.0
45:1			44:1			0		1.0
46:1			45:1			0		1.0

Alignment 4377
Special `` words '' can be idioms , locutions , proper names , date times , numbers , symbols , sentence marks , foreign words , or abbreviations .
Special `` words '' include idioms , locutions , proper names , date times , numbers , symbols , sentence marks , foreign words , or abbreviations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0

Alignment 4378
The segmentation of these types of words forms a basis for the POS tagging , with 18 different POS tags shown in Table 2 ( Nguyen et al ., c ) .
The segmentation of these types of words forms a basis for the POS tagging , with 18 different POS tags , as shown in Table 2 ( Nguyen et al ., c ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
33:1			31:1			0		1.0

Alignment 4379
Each unit in Table 1 goes with several example words of which English translations are given in parentheses .
Each unit in Table 1 goes with several example words ; English translations are provided in parentheses .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0

Alignment 4380
Besides , we added a translation for each token when possible , so that the readers unfamiliar with Vietnamese can have an intuitive idea of how the compound words are formed .
Furthermore , we added a translation for each token , where possible , so that readers who are unfamiliar with Vietnamese can have an intuitive idea as to how the compound words are formed .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:2			9:2			3		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			15:1			0		1.0
17:1			29:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:3			24:2			3		1.0
29:1			26:1			0		1.0
30:1			27:1			0		1.0
31:1			28:1			0		1.0
33:1			30:1			0		1.0
34:1			31:1			0		1.0

Alignment 4381
The subscript of a token translation is the index of that token in the compound word .
The subscript of a token translation is the index of that token in the compound word .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 4382
However , for some tokens , we could not find any appropriate English translation , so we give it an empty translation marked with an asterisk .
However , for some tokens , we could not find any appropriate English translation , so we gave it an empty translation , marked with an asterisk .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			2		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0

Alignment 4383
Note that a Vietnamese word or a token in context can have other meanings in addition to the given translations .
Note that a Vietnamese word or a token in context can have other meanings , in addition to the given translations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0

Alignment 4384
A special type of words in Vietnamese is classifer noun , denoted by the part-of-speech Nc in Table 2 .
A classifier noun , denoted by the part-of-speech Nc in Table 2 , is a special type of word in Vietnamese .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			9:1			0		1.0
3:1			10:1			0		1.0
4:1			11:1			0		1.0
5:1			12:1			0		1.0
6:1			13:1			0		1.0
7:1			14:1			0		1.0
8:1			15:1			0		1.0
9:1			16:1			0		1.0
10:1			17:1			0		1.0
11:1			18:1			0		1.0
13:1			7:1			0		1.0
15:1			1:1			0		1.0
16:1			2:1			0		1.0
17:1			3:1			0		1.0
18:1			4:1			1		1.0
19:1			5:1			0		1.0
20:1			6:1			0		1.0
21:1			19:1			0		1.0

Alignment 4385
Classifier nouns are specific to several Southeast Asian languages like Vietnamese and Thai .
Classifier nouns are specific to several Southeast Asian languages , like Vietnamese and Thai .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0

Alignment 4386
One of the functions of classifier nouns is to express the definiteness .
One of the functions of classifier nouns is to express the definiteness .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 4387
For example , the common noun `` bàn '' means tables in general , while `` cái bàn '' means a specific table similar to the table in English .
For example , the common noun `` bàn '' generally means tables , while `` cái bàn '' means a specific table , similar to the table in English .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			11:2			3		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0

Alignment 4388
In this section , we analyzed the VTB corpus to know whether the diffculties in Vietnamese word segmentation affected the quality of VTB annotations .
In this section , we analyzed the VTB corpus to determine whether the difficulties in Vietnamese word segmentation affected the quality of VTB annotations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 4389
The analysis results revealed several types of inconsistent annotations , which are also
The analysis revealed several types of inconsistent annotations , which are also
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0

Alignment 4390
Vietnamese word segmentation .
Vietnamese word segmentation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0

Alignment 4391
Our analysis is based on two types of inconsistency : variation and structural inconsistency , whose definitions and details are given below .
Our analysis is based on two types of inconsistencies : variation and structural inconsistency , which are defined below .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			1		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			3		1.0
16:1			19:1			0		1.0
17:1			16:1			3		1.0
18:1			21:1			0		1.0
19:1			22:1			0		1.0

Alignment 4392
Variation inconsistency : is a sequence of tokens which have more than one way of seg-mentation in the corpus .
Variation inconsistency : is a sequence of tokens , which has more than one way of segmentation in the corpus .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			2		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0

Alignment 4393
For example , `` con gái/girl '' can remain as one word , or be segmented into two words `` con '' and `` gái '' .
For example , `` con gái/girl '' can remain as one word , or be segmented into two words , `` con '' and `` gái '' .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0

Alignment 4394
A variation can be an annotation inconsistency , or an ambiguity inVietnamese .
A variation can be an annotation inconsistency , or an ambiguity in Vietnamese .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
13:1			12:1			0		1.0

Alignment 4395
While ambiguity cases reflect the diffculty of the language , annotation inconsistencies are usually caused by the confusion in the decision of annotators , which should be eliminated in annotation .
While ambiguity cases reflect the difficulty of the language , annotation inconsistencies are usually caused by the confusion in the decision of annotators , which should be eliminated in annotation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0

Alignment 4396
We use the term variation instance to refer a single occurence of a variation .
We use the term variation instance to refer to a single occurrence of a variation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0

Alignment 4397
Structural inconsistency : happens when different sequences have similar structures , thus should be splitted in the same way , but are segmented in different ways in the corpus .
Structural inconsistency : happens when different sequences have similar structures , and thus should be split in the same way , but are segmented in different ways in the corpus .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			1		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0

Alignment 4398
For example , `` con gái/girl '' and `` con trai/boy '' have similar structures , a combination of a classifier noun and a common noun Nc + N , so when `` con gái/girl '' is splitted and `` con trai/boy '' is not , it is considered as a structural inconsistency of Nc .
For example , `` con gái/girl '' and `` con trai/boy '' have similar structures : a combination of a classifier noun and a common noun , Nc + N , so when `` con gái/girl '' is split , and `` con trai/boy '' is not , it is considered as a structural inconsistency of Nc .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			15:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
37:1			36:1			0		1.0
38:1			37:1			1		1.0
39:1			45:1			0		1.0
40:1			38:1			0		1.0
41:1			39:1			0		1.0
42:1			40:1			0		1.0
43:1			41:1			0		1.0
44:1			42:1			0		1.0
45:1			43:1			0		1.0
46:1			44:1			0		1.0
48:1			46:1			0		1.0
49:1			47:1			0		1.0
50:1			48:1			0		1.0
51:1			49:1			0		1.0
52:1			50:1			0		1.0
53:1			51:1			0		1.0
54:1			52:1			0		1.0
55:1			53:1			0		1.0
56:1			54:1			0		1.0
57:1			55:1			0		1.0

Alignment 4399
It is likely that structural inconsistency in word segmentation level makes the higher levels of processing , POS tagging and bracketing , become more complicated .
It is likely that structural inconsistency at the word segmentation level complicates the higher levels of processing , including POS tagging and bracketing .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			11:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:2			23:2			3		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			25:1			0		1.0

Alignment 4400
The detection method for variation inconsistency is based on N-gram sequences and the phrase structures in VTB treebank , following the definition of variation inconsistency above .
The detection method for variation inconsistency is based on N-gram sequences and the phrase structures in the VTB , following the definition for variation inconsistency , above .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0

Alignment 4401
In details , we counted N-gram sequences of different lengths in VTB that have two or more ways of word segmentation , satisfying one of the following two conditions :
In detail , we counted N-gram sequences of different lengths in VTB that have two or more ways of word segmentation , satisfying one of the following two conditions :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			1		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0

Alignment 4402
N tokens are all in the same phrase , and all have the same depth in phrase .
N tokens are all in the same phrase , and all have the same depth in phrase .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 4403
For example , the 3-gram " nhà tình nghĩa ( house of gratitude ) " in this structure " ( NP ( Nc-H căn ) ( N nhà ) ( A tình nghĩa ) ) , " OR
For example , the 3-gram " nhà tình nghĩa ( house of gratitude ) " in this structure " ( NP ( Nc-H căn ) ( N nhà ) ( A tình nghĩa ) ) , " OR
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0

Alignment 4404
nhà tình nghĩa " in this structure " ( NP ( Nc-H căn ) ( N nhà ) ( ADJP ( A tình nghĩa ) ) ) , " where the ADJP contains only one word .
nhà tình nghĩa " in this structure " ( NP ( Nc-H căn ) ( N nhà ) ( ADJP ( A tình nghĩa ) ) ) , " where the ADJP contains only one word .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0

Alignment 4405
Table 3 shows the overall statistics of the variation inconsistency detected by the above method .
Table 3 shows the overall statistics of the variation inconsistency detected by the method described above .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			14:1			0		1.0
15:1			13:1			0		1.0
16:1			15:1			0		1.0

Alignment 4406
Most of the diffcult cases of word segmentation lie in two-token variations , occupying the majority of variations ( 92 .9% ) .
Most of the diffcult cases of word segmentation occur in two-token variations , occupying the majority of variations ( 92 .9% ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 4407
This ratio of 2-gram variations is much higher than the evarage ratio of two-token words in Vietnamese reported in ( Nguyen et al., 2009a ) , which is 80% percent .
This ratio of 2-gram variations is much higher than the average ratio of two-token words in Vietnamese , as reported in ( Nguyen et al., 2009a ) , which is 80% .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			30:1			0		1.0

Alignment 4408
Variations have lengths of three and four tokens occupy 6 .1% and 1 .0% , respectively .
Variations that have lengths of three and four tokens occupy 6 .1% and 1 .0% , respectively .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0

Alignment 4409
We estimated the precision of our method by randomly selected 130 2-gram variation instances extracted from the above method , and manually checked whether they are true inconsistency .
We estimated the precision of our method by randomly selecting 130 2-gram variation instances , extracted from the method described above , and manually checked whether the inconsistencies are true .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			1		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			18:1			0		1.0
20:1			17:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
28:1			25:1			0		1.0
29:1			26:1			0		1.0
30:1			28:1			0		1.0

Alignment 4410
We found that 129 cases occupying 99 .2% of all extracted 2-grams are true inconsistency .
We found that 129 cases occupying 99 .2% of all extracted 2-grams are true inconsistencies .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			1		1.0
15:1			15:1			0		1.0

Alignment 4411
Only one instance is an ambiguous sequence giá c , which is one word when it means price , and two words giá / price c / all in đàu có giá c / all have ( their own ) price .
Only one instance of inconsistency was an ambiguous sequence giá c , which is one word when it means price , and two words giá / price c / all in đàu có giá c / all have ( their own ) price .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
5:1			3:1			2		1.0
6:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
33:1			31:1			0		1.0
34:1			32:1			0		1.0
35:1			33:1			0		1.0
36:1			34:1			0		1.0
37:1			35:1			0		1.0
38:1			36:1			0		1.0
39:1			37:1			0		1.0
40:1			38:1			0		1.0
41:1			39:1			0		1.0
42:1			40:1			0		1.0
43:1			41:1			0		1.0

Alignment 4412
The precision of our method is high enough so that so we can use the extracted variations to study the insights of word segmentation problem .
The precision for our method is high , so we can use the extracted variations to provide insights on the word segmentation problem .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
17:1			20:1			0		1.0
19:1			19:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0

Alignment 4413
We further analyzed the 2-gram variations to know what types of 2-grams were most confusing to annotators .
We further analyzed the 2-gram variations to understand what types of 2-grams were most confusing for annotators .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 4414
The analysis results showed that compound nouns , compound verbs , and compound adjectives are the top diffcult cases of word segmentation .
The analysis revealed that compound nouns , compound verbs , and compound adjectives are the most difficult cases of word segmentation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			3:1			3		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0

Alignment 4415
We classified the 2-gram variations according to their POS sequences in case the tokens in the 2-gram are splitted .
We classified the 2-gram variations according to their POS sequences in case the tokens in the 2-gram are split .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			1		1.0
19:1			19:1			0		1.0

Alignment 4416
There are totally 54 patterns of POS sequence , of which top 10 confusing patterns , a long with their counts of 2-gram variations , and examples are shown in Table 4 .
There are a total of 54 patterns of POS sequences . The top 10 confusing patterns , their counts of 2-gram variations , and examples are depicted in Table 4 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			16:1			0		1.0
4:1			9:1			0		1.0
5:1			3:1			0		1.0
6:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			1		1.0
10:1			32:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0
24:1			26:1			0		1.0
25:1			27:1			0		1.0
26:1			28:1			2		1.0
27:1			29:1			0		1.0
28:1			30:1			0		1.0
29:1			31:1			0		1.0

Alignment 4417
Table 5 and Table 6 show the POS patterns which a specific POS tag appearing at the beginning or ending of the sequence .
Table 5 and Table 6 show the POS patterns that are a specific POS tag , appearing at the beginning or ending of the sequence .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0

Alignment 4418
Investigating the inconsistent 2-grams extracted , we found that most of them are compound words according to the VTB guidelines ( Section 2 ) .
Investigating the inconsistent 2-grams extracted , we found that most of them are compound words , according to the VTB guidelines ( Section 2 ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0

Alignment 4419
One of the reasons why the compound words are sometimes splitted , is because the tokens in those compound words have their own meanings , which seem to contribute to the whole meaning of the compounds .
One of the reasons why the compound words are sometimes split , is because the tokens in those compound words have their own meanings , which seem to contribute to the overall meaning of the compounds .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			1		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			3		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0

Alignment 4420
This can be seen through the examples given in Table 4 , where the meanings of tokens are given with a subscript .
This can be seen through the examples provided in Table 4 , where the meanings of tokens are given with a subscript .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:2			6:2			3		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 4421
This problem seems to have caused a lot of trouble for the annotators of VTB .
This scenario has proven to be problematic for the annotators of VTB .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			5:2			3		1.0
4:1			3:1			0		1.0
7:1			10:1			0		1.0
8:1			11:1			0		1.0
9:1			12:1			0		1.0
10:1			13:1			0		1.0
11:1			14:1			0		1.0
12:1			15:1			0		1.0

Alignment 4422
Furthermore , observing the POS patterns in Table 5 and Table 6 , we can see the potential of structural inconsistency , in particular for closed-set POS tags .
Furthermore , by observing the POS patterns in Table 5 and Table 6 , we can see the potential for structural inconsistency , particularly for closed-set POS tags .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			24:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:2			22:2			3		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 4423
Among them , classifier nouns ( Nc ) and affxes ( S ) are two typical cases of structural inconsistency , which will be used in several settings of our experiments .
Among them , classifier nouns ( Nc ) and affixes ( S ) are two typical cases of structural inconsistency , which will be used in several settings for our experiments .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0

Alignment 4424
The same affx or classifier noun can modify different nouns , so when they are sometimes splitted , and sometimes combined in the variations , we can conclude that classifier nouns and affxes involve in structural inconsistency .
The same affx or classifier noun can modify different nouns , so when they are sometimes split and combined in the variations , we can conclude that classifier nouns and affixes involve in-structural inconsistencies .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			1		1.0
17:1			18:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0
24:1			26:1			0		1.0
25:1			27:1			0		1.0
26:1			28:1			0		1.0
27:1			29:1			0		1.0
28:1			30:1			0		1.0
29:1			31:1			0		1.0
31:1			33:1			0		1.0
33:1			36:1			1		1.0
34:1			37:1			0		1.0

Alignment 4425
In the following section , we presents our detection method for structural inconsistency for classifier nouns and affxes .
In the following section , we present our detection method for structural inconsistency for classifier nouns and affixes .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			1		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
18:1			18:1			0		1.0

Alignment 4426
The detection method for structural inconsistency of classifier nouns and affxes is simple .
The detection method for structural inconsistency of classifier nouns and affixes is simple .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 4427
First , we collected all affxes and classifier nouns in the VTB corpus . Then , extracted 2-grams containing these affxes or classifier nouns , which also are the structural inconsistencies .
We collected all affixes and classifier nouns in the VTB corpus , and then extracted 2-grams containing these affixes or classifier nouns , which are also structural inconsistencies .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			3:1			0		1.0
2:1			4:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			1:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0
24:1			27:1			0		1.0
25:1			26:1			0		1.0
26:1			29:1			0		1.0
27:1			30:1			0		1.0
28:1			31:1			0		1.0

Alignment 4428
For example , since " con " is tagged as a classifier noun in VTB , we extracted all 2-grams of " con " including both " con gái / girl " and " con trai / boy " .
For example , since " con " is tagged as a classifier noun in VTB , we extracted all 2-grams of " con " including both " con gái / girl " and " con trai / boy " .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0

Alignment 4429
Note that even though the sequence " con trai " is always splitted into two words throughout the corpus , it can still be an inconsistency if we consider similar structures such as " con gái " .
Even though the sequence , " con trai " is always split into two words throughout the corpus , it can still be an inconsistency , if we consider similar structures such as " con gái " .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			3:1			0		1.0
2:1			4:1			0		1.0
3:1			5:1			0		1.0
4:1			19:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			1		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0

Alignment 4430
In other words , by this method , we extract sequences that may be consistent at the surface level , but are not consistent if we consider the higher analysis levels , POS tagging .
In other words , by this method , we extract sequences that may be consistent at the surface level , but are not consistent , if we consider the higher analysis levels , POS tagging .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			31:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0

Alignment 4431
According to the VTB POS-tagging annotation guidelines ( Nguyen et al., c ) , classifier nouns should be separated from the words they modify .
According to the VTB POS-tagging annotation guidelines ( Nguyen et al., c ) , classifier nouns should be separated from the words that they modify .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0

Alignment 4432
However , in practice it is confusing when the classifier noun can be stand alone as a single word .
However , in practice , it is confusing when the classifier noun can be standalone as a single word .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 4433
For example a classifier noun , e.g. , " con " in " con trai ( boy ) " , or " con gái ( girl ) " , can also be a simple word which means " I ( first person pronoun used by a child when talking to his / her parents ) " , or part of a complex noun " con cái ( children ) " .
For example a classifier noun , e.g. , " con " in " con trai ( boy ) " , or " con gái ( girl ) " , can also be a simple word , which means " I ( first person pronoun used by a child when talking to his / her parents ) " , or part of a complex noun " con cái ( children ) " .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			56:1			0		1.0
36:1			35:1			0		1.0
37:1			36:1			0		1.0
38:1			37:1			0		1.0
39:1			38:1			0		1.0
40:1			39:1			0		1.0
41:1			40:1			0		1.0
42:1			41:1			0		1.0
43:1			42:1			0		1.0
44:1			43:1			0		1.0
45:1			44:1			0		1.0
46:1			45:1			0		1.0
47:1			46:1			0		1.0
48:1			47:1			0		1.0
49:1			48:1			0		1.0
50:1			49:1			0		1.0
51:1			50:1			0		1.0
52:1			51:1			0		1.0
53:1			52:1			0		1.0
54:1			53:1			0		1.0
55:1			54:1			0		1.0
56:1			55:1			0		1.0
58:1			57:1			0		1.0
59:1			58:1			0		1.0
60:1			59:1			0		1.0
61:1			60:1			0		1.0
62:1			61:1			0		1.0
63:1			62:1			0		1.0
64:1			63:1			0		1.0
65:1			64:1			0		1.0
66:1			65:1			0		1.0
67:1			66:1			0		1.0
68:1			67:1			0		1.0
69:1			68:1			0		1.0
70:1			69:1			0		1.0
71:1			70:1			0		1.0

Alignment 4434
Therefore , in our experiments , we want to evaluate the " splitting " and " combining " of these diffcult cases , to see whether the solution is fruitful for applications of the corpus .
Therefore , in our experiments , we want to evaluate the " splitting " and " combining " of these cases , in order to see whether the solution is successful for applications of the corpus .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:2			29:2			3		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0

Alignment 4435
Examing the variations extracted by the variation inconsistency detection , we found that there are cases when a special character like percentage % in " 30% " , is splitted or combined with " 30 " .
By examining the variations extracted by the variation inconsistency detection , we found that there are cases when a special character like a percentage ( % ) in " 30% " , is split or combined with " 30 " .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
23:1			21:1			0		1.0
25:1			22:1			0		1.0
27:1			23:1			0		1.0
28:1			24:1			0		1.0
29:1			25:1			0		1.0
30:1			26:1			0		1.0
31:1			27:1			0		1.0
32:1			28:1			0		1.0
33:1			29:1			1		1.0
34:1			30:1			0		1.0
35:1			31:1			0		1.0
36:1			32:1			0		1.0
37:1			33:1			0		1.0
38:1			34:1			0		1.0
39:1			35:1			0		1.0
40:1			36:1			0		1.0

Alignment 4436
Such inconsistent annotations are manually fixed based on their textual context .
Such inconsistent annotations are manually fixed based on their textual context .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 4437
Checking structural inconsistency of these special characters including percentage% , hyphen - , and so on , we found quite a significant amount of inconsistent annotations .
By checking structural inconsistencies of these special characters , including percentages ( % ) , hyphens ( - ) , and other symbols , we found quite a significant number of inconsistent annotations .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			1		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			16:1			0		1.0
9:1			7:1			0		1.0
14:1			9:1			0		1.0
15:1			10:1			1		1.0
17:1			11:1			0		1.0
19:1			12:1			0		1.0
20:1			13:1			0		1.0
24:1			17:1			0		1.0
25:1			18:1			0		1.0
26:1			19:1			0		1.0
27:4			20:4			3		1.0
31:1			24:1			0		1.0
32:1			25:1			0		1.0
33:1			26:1			0		1.0

Alignment 4438
For example , the character % in " 30% " is splitted but is combined with the number in " 50 % " , which is considered as a structural inconsistency .
For example , the character , % , in " 30% " is split , but is combined with a number in " 50 % " , which is considered to be a structural inconsistency .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			23:1			0		1.0
6:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			1		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			28:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0
27:5			26:2			3		1.0
33:1			29:1			0		1.0
34:1			30:1			0		1.0
35:1			31:1			0		1.0

Alignment 4439
Note that although it can be argued that whether " N% " can be splitted into two words or combined in one word is dependent on the blank space in between N and " % " .
Note that it can be argued that splitting " N% " into two words or combined in one word is dependent on the blank space in-between N and " % " .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			14:1			1		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			15:1			0		1.0
12:1			16:1			0		1.0
13:1			17:1			0		1.0
14:1			18:1			0		1.0
15:1			19:1			0		1.0
16:1			20:1			0		1.0
17:1			21:1			0		1.0
18:1			22:1			0		1.0
19:1			23:1			0		1.0
20:1			24:1			0		1.0
21:1			25:1			0		1.0
22:1			26:1			0		1.0
23:1			27:1			0		1.0
24:1			28:1			0		1.0
26:1			31:1			0		1.0
27:1			32:1			0		1.0
28:1			33:1			0		1.0
29:1			34:1			0		1.0
30:1			35:1			0		1.0
31:1			36:1			0		1.0

Alignment 4440
It does matter higher-levels of annotation such as POS tagging because we may need one or two different POS tags for different ways of annotation .
Higher-levels of annotation such as POS tagging is significant , because we may need one or two different POS tags for the different methods of annotation .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			4:1			0		1.0
2:1			5:1			0		1.0
3:1			6:1			0		1.0
4:1			7:1			0		1.0
5:1			8:1			0		1.0
6:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			3		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0

Alignment 4441
Therefore , we think it is better to carefully preprocess text and segment these special characters in a consistent way .
Therefore , we think that it is better to carefully preprocess text and segment these special characters in a consistent way .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0

Alignment 4442
To improve the quality of VTB corpus , we extracted the probably problematic sequences using patterns of the special characters , and manually fixed this type of inconsistency .
To improve the quality of the VTB corpus , we extracted the problematic sequences using patterns of the special characters , and manually fixed this type of inconsistency .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			17:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 4443
Automatically modification is diffcult since we must check the semantics of the special characters in their contexts .
Automatically modification is diffcult , since we must check the semantics of the special characters in their contexts .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0

Alignment 4444
For example , hyphens in date expressions like " 5-4-1975 " , which means the date " April the fifth , 1975 , " are combined with the numbers .
For example , hyphens in date expressions like " 5-4-1975 " , which refers to the date , " the fifth of April , 1975 , " are combined with the numbers .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:3			13:2			3		1.0
16:1			15:1			0		1.0
17:1			22:1			0		1.0
18:1			16:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
22:1			17:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0
26:1			23:1			0		1.0
27:1			24:1			0		1.0
28:1			25:1			0		1.0
29:1			26:1			0		1.0
30:1			27:1			0		1.0
31:1			28:1			0		1.0
32:1			29:1			0		1.0

Alignment 4445
However , when the hypen has a meaning of " ( from ) to " or " around .
However , when the hyphen indicates " ( from ) to " or " around .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
6:1			9:1			0		1.0
7:1			10:1			0		1.0
8:1			11:1			0		1.0
9:1			12:1			0		1.0
10:1			13:1			0		1.0
11:1			14:1			0		1.0
12:1			15:1			0		1.0
13:1			16:1			0		1.0
14:1			17:1			0		1.0
15:1			18:1			0		1.0

Alignment 4446
. .
. .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0

Alignment 4447
or " , as in " 2-3 gi░ sáng " meaning " around 2 or 3 o’clock in the morning " , we decided to separate it from the surrounding numbers .
or " , as in " 2-3 gi░ sáng " , meaning " around 2 or 3 o’clock in the morning " , we decided to separate it from the surrounding numbers .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			21:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0

Alignment 4448
As a result , we have fixed 685 inconsistent annotations of 21 special characters in VTB .
As a result , we have fixed 685 inconsistent annotations of 21 special characters in VTB .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 4449
The variation inconsistency and structural inconsistency found in Section 3 above can also be seen as representatives of different word segmentation criteria for Vietnamese .
The variation inconsistency and structural inconsistency found in Section 3 can also be seen as representatives of different word segmentation criteria for Vietnamese .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0

Alignment 4450
We organized the inconsistency detected in seven configurations of the original VTB corpus .
We organized the inconsistency detected in seven configurations of the original VTB corpus .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 4451
Then , by using these data sets , we could observe the influence of the different word segmentation criteria on three tasks : automatic word segmenation , text classification , and English-Vietnamese statistical machine translation .
Then , by using these data sets , we could observe the influence of the different word segmentation criteria on three tasks : automatic word segmentation , text classification , and English-Vietnamese statistical machine translation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0

Alignment 4452
Seven data sets corresponding to different segmentation criteria are organized as follows .
Seven data sets corresponding to different segmentation criteria are organized as follows .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 4453
ORG : The original VTB corpus .
ORG : The original VTB corpus .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0

Alignment 4454
BASE : The original VTB corpus + Manual modification of special characters done in Section 3 .3 .
BASE : The original VTB corpus + Manual modification of special characters done in Section 3 .3 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 4455
VAR_SPLIT : BASE + split all variations detected in Section 3 .1 .
VAR_SPLIT : BASE + split all variations detected in Section 3 .1 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 4456
VAR_COMB : BASE + combine all variations detected in Section 3 .1 .
VAR_COMB : BASE + combine all variations detected in Section 3 .1 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 4457
VAR_FREQ : BASE + select the segmentation with higher frequency among all variations detected in Section 3 .1 .
VAR_FREQ : BASE + select the segmentation with higher frequency among all variations detected in Section 3 .1 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 4458
STRUCT_NC : BASE + combine all classifier nouns detected in Section 3 .2 with the words they modify .
STRUCT_NC : BASE + combine all classifier nouns detected in Section 3 .2 with the words they modify .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 4459
STRUCT_AFFIX : BASE + combine all suffxes detected in Section 3 .2 with the words they modify .
STRUCT_AFFIX : BASE + combine all suffxes detected in Section 3 .2 with the words they modify .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 4460
These data sets are used in our experiments as illustrated in Figure 1 .
These data sets are used in our experiments , as illustrated in Figure 1 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0

Alignment 4461
The names of the data sets are also used to label our experimental configurations .
The names of the data sets are also used to label our experimental configurations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 4462
In this section , we briefly describe the task settings and the methods used for word segmentation ( WS ) , text classification ( TC ) , and English-Vietnamese statistical machine translation ( SMT ) .
In this section , we briefly describe the task settings and the methods used for word segmentation ( WS ) , text classification ( TC ) , and English-Vietnamese statistical machine translation ( SMT ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0

Alignment 4463
We used YamCha ( Kudo and Matsumoto , 2003 ) , a multi-purpose chunking tool , to train our word segmentation models .
We used YamCha ( Kudo and Matsumoto , 2003 ) , a multi-purpose chunking tool , to train our word segmentation models .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 4464
The core of YamCha is the Support Vector Machine ( SVM ) machine learning method , which has been proved to be effective in NLP tasks .
The core of YamCha is the Support Vector Machine ( SVM ) machine learning method , which has been proven to be effective for NLP tasks .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			2		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 4465
For the Vietnamese word segmentation problem , each token is labeled with standard B , I , or O labels , corresponding to beginning , inside , and outside positions , respectively .
For the Vietnamese word segmentation problem , each token is labeled with standard B , I , or O labels , corresponding to the beginning , inside , and outside positions , respectively .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0

Alignment 4466
Label of each token is determined based on the lexical features of two preceding words and two following words of that token .
The label of each token is determined based on the lexical features of two preceding words , and the two following words of that token .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
17:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0

Alignment 4467
Since Vietnamese language is not inflectional , we cannot utilize inflection features for word segmentation .
Since the Vietnamese language is not inflectional , we cannot utilize inflection features for word segmentation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0

Alignment 4468
Each of the seven data sets is splitted into two subsets for training and testing our WS models .
Each of the seven data sets is split into two subsets for training and testing our WS models .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			1		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 4469
The training set contains 8443 sentences , and the test set contains 2000 sentences .
The training set contains 8443 sentences , and the test set contains 2000 sentences .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 4470
Text classification is defined as a task of determining for an input document the most suitable topic from the predefined topics .
Text classification is defined as a task of determining the most suitable topic from the predefined topics , for an input document .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			13:1			0		1.0
10:1			14:1			0		1.0
11:1			15:1			0		1.0
12:1			16:1			0		1.0
13:1			17:1			0		1.0
14:1			18:1			0		1.0
15:1			19:1			0		1.0
16:1			20:1			0		1.0
18:1			9:1			0		1.0
19:1			10:1			0		1.0
20:1			11:1			0		1.0
21:1			12:1			0		1.0
22:1			21:1			0		1.0

Alignment 4471
We implemented a text classification system similar to the system presented in ( Nguyen et al., 2012 ) .
We implemented a text classification system similar to the system presented in ( Nguyen et al., 2012 ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 4472
The difference is that we performed for document level , not for sentence level .
The difference is that we performed the task at the document level , instead of at the sentence level .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			3		1.0
17:1			12:1			0		1.0
18:1			13:1			0		1.0
19:1			14:1			0		1.0

Alignment 4473
Processing of the system is summarized as follows .
The processing of the system is summarized as follows .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0

Alignment 4474
An input document is preprocessed with word segmentation and stop-word removals .
An input document is preprocessed with word segmentation and stop-word removals .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 4475
Then , the document is represented in the form of a vector of weighted words appearing in the document .
Then , the document is represented in the form of a vector of weighted words appearing in the document .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 4476
The weight is calculated using standard tf-idf product .
The weight is calculated using standard tf-idf product .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 4477
An SVM-based classifier predicts the most probable topic for the vector , which also is the topic of the input document .
An SVM-based classifier predicts the most probable topic for the vector , which also is the topic for the input document .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 4478
In our experiment for comparison of different word segmentation criteria in topic classification , we only vary the word segmentation model used for this task , while fixing other configurations .
In our experiment , for comparison of different word segmentation criteria in topic classification , we only vary the word segmentation model used for this task , while fixing other configurations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0

Alignment 4479
News articles of five topics : music , stock , entertainment , education , and fashion are used .
News articles of five topics : music , stock , entertainment , education , and fashion are used .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 4480
The sizes of the training and test data sets are summarized in Table 8 .
The sizes of the training and test data sets are summarized in Table 8 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 4481
A phrase-based SMT system for English-Vietnamese translation was implemented .
A phrase-based SMT system for English-Vietnamese translation was implemented .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 4482
In this system , we used SRILM ( Stolcke , 2002 ) to build the language model , GIZA++ ( Och and Ney , 2003 ) to train the word-aligned model , and Moses ( Holmqvist et al., 2007 ) to train the phrase-based statistical translation model .
In this system , we used SRILM ( Stolcke , 2002 ) to build the language model , GIZA++ ( Och and Ney , 2003 ) to train the word-aligned model , and Moses ( Holmqvist et al., 2007 ) to train the phrase-based statistical translation model .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0

Alignment 4483
Translation results are evaluated using BLUE score ( Papineni et al., 2002 ) .
Translation results are evaluated using the BLUE score ( Papineni et al., 2002 ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0

Alignment 4484
Both training and test data are word-segmented using the word segmentation models achieved .
Both training and test data are word-segmented using the word segmentation models achieved .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 4485
For the experiment , we used the VCL_EVC bilingual corpus , 18000 pairs of sentences for training , and 1000 pairs for testing .
For the experiment , we used the VCL_EVC bilingual corpus , 18000 pairs of sentences for training , and 1000 pairs for testing .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 4486
Evaluation of word segmentation models trained on different versions of the VTB are given in Table 9 .
Evaluation of word segmentation models trained on different versions of the VTB are given in Table 9 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 4487
And the experimental results with text classification and English-Vietnamese statistical machine translation are shown in Table 10 and Table 11 , respectively .
The experimental results with text classification and English-Vietnamese statistical machine translation are shown in Table 10 and Table 11 , respectively .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0

Alignment 4488
There are two important conclusions can be drawn from these tables : ( 1 ) Quality of the treebank strongly affects the applications since our BASE model and most of other enhanced models improved the performance of TC and SMT systems ; ( 2 ) " Splitting " seems to be a good solution for word segmentation of controversial cases , including the split of variations , affxes , and classifier nouns .
There are two important conclusions that can be drawn from these tables : ( 1 ) The quality of the treebank strongly affects the applications , since our BASE model and most of the other enhanced models improved the performance of TC and SMT systems ; ( 2 ) " Splitting " seems to be a good solution for word segmentation for controversial cases , including the split of variations , affxes , and classifier nouns .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			68:1			0		1.0
26:1			23:1			0		1.0
27:1			24:1			0		1.0
28:1			25:1			0		1.0
29:1			26:1			0		1.0
30:1			27:1			0		1.0
31:1			28:1			0		1.0
32:1			29:1			0		1.0
33:1			62:1			0		1.0
34:1			30:1			0		1.0
35:1			31:1			0		1.0
36:1			32:1			0		1.0
37:1			33:1			0		1.0
38:1			34:1			0		1.0
39:1			35:1			0		1.0
40:1			36:1			0		1.0
41:1			37:1			0		1.0
42:1			38:1			0		1.0
43:1			39:1			0		1.0
44:1			40:1			0		1.0
45:1			41:1			0		1.0
46:1			42:1			0		1.0
47:1			43:1			0		1.0
48:1			44:1			0		1.0
49:1			45:1			0		1.0
50:1			46:1			0		1.0
51:1			47:1			0		1.0
52:1			48:1			0		1.0
53:1			49:1			0		1.0
54:1			50:1			0		1.0
55:1			51:1			0		1.0
56:1			52:1			0		1.0
57:1			53:1			0		1.0
58:1			54:1			0		1.0
59:1			55:1			0		1.0
60:1			56:1			0		1.0
62:1			58:1			0		1.0
63:1			59:1			0		1.0
64:1			60:1			0		1.0
65:1			61:1			0		1.0
67:1			63:1			0		1.0
68:1			64:1			0		1.0
69:1			65:1			0		1.0
70:1			66:1			0		1.0
71:1			67:1			0		1.0
73:1			69:1			0		1.0
74:1			70:1			0		1.0
75:1			71:1			0		1.0
76:1			72:1			0		1.0

Alignment 4489
According to the result in Table 9 , the VAR_SPLIT criterion gives the highest WS performance .
According to the result in Table 9 , the VAR_SPLIT criterion gives the highest WS performance .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 4490
Except for STRUCT_NC , all the modifications to the original VTB corpus increase the performance of WS .
With the exception of STRUCT_NC , all of the modifications to the original VTB corpus increase the performance of WS .
Line2Start:Length	Line1Start:Length	Module		Score
3:1			15:1			0		1.0
4:1			2:1			0		1.0
5:1			3:1			0		1.0
6:1			4:1			0		1.0
8:1			5:1			0		1.0
9:1			6:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0

Alignment 4491
However , the word segmentation criterion with higher performance is not necessarily a better criterion , but a criterion should also be judged through applications of word segmentation .
However , the word segmentation criterion with higher performance is not necessarily a better criterion , but a criterion should also be judged through applications of word segmentation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 4492
In both SMT and TC experiments , the BASE model which is based on the manually-modified inconsistency of special characters , achieved better results than the ORG model .
In both SMT and TC experiments , the BASE model , which is based on the manually-modified inconsistency of special characters , achieved better results than the ORG model .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0

Alignment 4493
In particular , in the TC experiment , the BASE model achieved 0 .66 point higher than ORG , which is a significant improvement .
In particular , in the TC experiment , the BASE model achieved 0 .66 point higher than ORG , which is a significant improvement .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 4494
The results support the conclusion that the quality of word-segmentation corpus is very important for building NLP applications .
The results support the conclusion that the quality of the word-segmentation corpus is very important for building NLP applications .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0

Alignment 4495
The SMT results show that three out of six augmented models , VAR_SPLIT , VAR_FREQ and BASE , gave higher performance than the ORG configuration .
The SMT results show that three out of six augmented models , VAR_SPLIT , VAR_FREQ and BASE , performed better than the ORG configuration .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0

Alignment 4496
Among them , the best model VAR_SPLIT achieved 36 .91 BLEU score , which is 0 .55 higher than ORG .
Among them , the best-performing model , VAR_SPLIT achieved 36 .91 BLEU score , which is 0 .55 higher than ORG .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0

Alignment 4497
In TC results , all six augmented models have higher results than ORG .
In TC results , all six augmented models achieved higher results than ORG .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 4498
In general , the augmented models are better than the ORG .
In general , the augmented models performed better than the ORG .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 4499
Additionally , because our automatic methods for inconsistency detection could not cover all types of inconsistency in word segmentation annotation , further improvement of corpus quality is demanded .
Additionally , because our automatic methods for inconsistency detection could not cover all of the types of inconsistencies in word segmentation annotation , further improvement of corpus quality is demanded .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			23:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			1		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0

Alignment 4500
Comparing the results of STRUCT_AFFIX and STRUCT_NC with BASE in WS , TC , and SMT , we can observe that combining affxes with their head nouns resulted in slightly better results for WS , TC , and does not change the performance of SMT .
Comparing the results of STRUCT_AFFIX and STRUCT_NC with BASE in WS , TC , and SMT , we can observe that combining affxes with their head nouns resulted in slightly better results for WS and TC , and did not change the performance of SMT .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			37:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0

Alignment 4501
However , the combination of clasifier nouns with their head nouns had negative effects on WS and SMT .
However , the combination of classifier nouns with their head nouns had negative effects on WS and SMT .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 4502
Another intention of our experiment is to compare two solutions for controversial cases of word segmentation , splitting and combining .
Another part of the scope of our experiment is to compare two solutions for controversial cases of word segmentation , splitting and combining .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
5:1			2:1			0		1.0
6:1			3:1			0		1.0
7:1			4:1			0		1.0
8:1			5:1			0		1.0
9:1			6:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			0		1.0
23:1			20:1			0		1.0

Alignment 4503
Splitting and combining variations are reflected by VAR_COMB and VAR_SPLIT , while STRUCT_AFFIX and STRUCT_NC represent the combination of affxes or classifier nouns with the words they modify .
Splitting and combining variations are reflected by VAR_COMB and VAR_SPLIT , while STRUCT_AFFIX and STRUCT_NC represent the combination of affixes or classifier nouns with the words that they modify .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0

Alignment 4504
STRUCT_AFFIX and STRUCT_NC are contrasted with BASE where affxes and classifier nouns remain untouched .
STRUCT_AFFIX and STRUCT_NC are contrasted with BASE where affxes and classifier nouns remain untouched .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 4505
Comparing VAR_COMB and VAR_SPLIT in both TC experiment and SMT experiment , we see that the VAR_SPLIT results are better in both cases .
Comparing VAR_COMB and VAR_SPLIT in both the TC experiment and SMT experiment , we see that the VAR_SPLIT results are better in both cases .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0

Alignment 4506
Since the ratio of combined variations in the ORG corpus is 60 .9% , it can be observed that splitting seems to be better than combining for WS , TC and SMT .
Since the ratio of combined variations in the ORG corpus is 60 .9% , it can be observed that splitting seems to be better than combining for WS , TC and SMT .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0

Alignment 4507
In this paper , we have shown a quantitative analysis of the diffculties in word segmentation , through the detection of problematic cases in the Vietnamese treebank .
In this paper , we have provided a quantitative analysis of the difficulties in word segmentation , through the detection of problematic cases in the Vietnamese Treebank .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
27:1			27:1			0		1.0

Alignment 4508
Based on the analysis , we automatically created data representing the different word segmentation criteria , and evaluated the criteria indirectly through their applications .
Based on the analysis , we automatically created data that represent the different word segmentation criteria , and evaluated the criteria indirectly through their applications .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:2			9:1			3		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0

Alignment 4509
Our experimental results showed that manual modification done for annotation of spe-cial characters and most of other word segmentation criteria significantly improved the performances of automatic word segmentation , text classification and statistical machine translation , comparing with the use of the original VTB corpus .
Our experimental results showed that manual modification , done for annotation of special characters , and most other word segmentation criteria , significantly improved the performances of automatic word segmentation , text classification and statistical machine translation , in comparison with the use of the original VTB corpus .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			28:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
13:1			12:1			0		1.0
14:1			35:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
33:1			31:1			0		1.0
34:1			32:1			0		1.0
35:1			33:1			0		1.0
36:1			34:1			0		1.0
39:1			36:1			2		1.0
40:1			37:1			0		1.0
41:1			38:1			0		1.0
42:1			39:1			0		1.0
43:1			40:1			0		1.0
44:1			41:1			0		1.0
45:1			42:1			0		1.0
46:1			43:1			0		1.0
47:1			44:1			0		1.0
48:1			45:1			0		1.0

Alignment 4510
Since the VTB corpus is the first effort in building a treebank for Vietnamese , and is the only corpus publicly available for NLP research , this study contributes to further improvement of the corpus quality , which is essential for building effcient NLP systems .
Since the VTB corpus is the first effort in building a treebank for Vietnamese , and is the only corpus that is publicly available for NLP research , this study contributes to further improvement of the corpus quality , which is essential for building efficient NLP systems .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:2			37:2			3		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
33:1			31:1			0		1.0
34:1			32:1			0		1.0
35:1			33:1			0		1.0
36:1			34:1			0		1.0
37:1			35:1			0		1.0
38:1			36:1			0		1.0
41:1			39:1			0		1.0
42:1			40:1			0		1.0
43:1			41:1			0		1.0
45:1			43:1			0		1.0
46:1			44:1			0		1.0
47:1			45:1			0		1.0

Alignment 4511
Face retrieval on large-scale news video datasets
Face retrieval in large-scale news video datasets
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0

Alignment 4512
Face retrieval in news video has been identified as a challenging task due to huge variations in visual appearance of human face .
Face retrieval in news video has been identified as a challenging task due to huge variations in the visual appearance of the human face .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0

Alignment 4513
Although there are several approaches proposed to cope with this problem , their extremely high computational cost limits their scalability on largescale video datasets that may contain millions faces of hundreds characters .
Although several approaches have been proposed to deal with this problem , their extremely high computational cost limits their scalability to large-scale video datasets that may contain millions of faces of hundreds of characters .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			3:1			0		1.0
2:1			4:1			0		1.0
3:2			2:1			3		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:2			7:2			3		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
33:1			31:1			0		1.0
34:1			32:1			0		1.0

Alignment 4514
In this paper , we introduce approaches for face retrieval which are scalable on such datasets while maintaining competitive performances with the state-of-the-art approaches .
In this paper , we introduce approaches to face retrieval that are scalable to such datasets while maintaining competitive performances with state-of-the-art approaches .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:2			6:2			3		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:2			10:2			3		1.0
12:1			12:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0

Alignment 4515
To utilize the variability of face appearances in video , we use a set of face images called face-track to represent for the appearance of a character in a video shot .
To utilize the variability of face appearances in video , we use a set of face images called face track to represent the appearance of a character in a video shot .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0

Alignment 4516
Our first proposal is an approach for extracting face-tracks .
Our first proposal is an approach to extracting face tracks .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			7:1			0		1.0
10:1			9:1			0		1.0

Alignment 4517
We use a point tracker for exploring the connections between detected faces belonging to the same character , then grouping them into one face-track .
We use a point tracker to explore the connections between detected faces belonging to the same character and , then group them into one face track .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:2			6:2			3		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			1		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
26:1			24:1			0		1.0

Alignment 4518
We present techniques to make the approach robust to common problems caused by sudden illumination changes , partial occlusions , and scattered appearances of characters in news videos .
We present techniques to make the approach robust to common problems caused by sudden illumination changes , partial occlusions , and scattered appearances of characters in news videos .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 4519
In the second proposal , we introduce an efficient approach to match face-tracks for retrieval .
In the second proposal , we introduce an efficient approach to matching face tracks for retrieval .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			1		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0

Alignment 4520
Instead of using all faces in face-tracks to compute their similarity , our approach select representative faces for each face-track .
Instead of using all the faces in the face tracks to compute their similarity , our approach selects representative faces for each face track .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			1		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0
24:1			20:1			0		1.0

Alignment 4521
The representative faces are sampled from the original face-track .
The representative faces are sampled from the original face track .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
10:1			9:1			0		1.0

Alignment 4522
As a result , we significantly reduce the computational cost for face-track matching while taking into account variability of faces in face-tracks for high matching accuracy .
As a result , we significantly reduce the computational cost of face-track matching while taking into account the variability of faces in face tracks to achieve high matching accuracy .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:2			9:2			3		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
26:1			23:1			0		1.0
27:1			24:1			0		1.0
28:1			25:1			0		1.0
29:1			26:1			0		1.0

Alignment 4523
Experiments are conducted on two face-track datasets extracted from real-world news videos , .
Experiments are conducted on two face-track datasets extracted from real-world news videos , of such .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
15:1			13:1			0		1.0

Alignment 4524
Their scales have not been considered in literature ever .
scales that have never been considered in the literature .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			3		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			9:1			0		1.0

Alignment 4525
One dataset contains 1,497 face-tracks of 41 characters extracted from 370 hours of TRECVID videos .
One dataset contains 1,497 face tracks of 41 characters extracted from 370 hours of TRECVID videos .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0

Alignment 4526
The other dataset provides 5,567 face-tracks of 111 characters observed from television news program ( NHK News 7 ) channel in 11 years .
The other dataset provides 5,567 face tracks of 111 characters observed from a television news program ( NHK News 7 ) over 11 years .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0

Alignment 4527
We make both datasets public for research community .
We make both datasets public for the research community .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0

Alignment 4528
The experimental results demonstrate that our proposed approaches achieved a remarkable balance between accuracy and efficiency.
The experimental results show that our proposed approaches achieved a remarkable balance between accuracy and efficiency.
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:2			3:2			3		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 4529
News videos play an important role in our sources of information nowadays because of their rich and important contents .
News videos play an important role as a source of information nowadays because of their rich and relevant contents .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:2			5:2			3		1.0
7:2			8:1			3		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:2			16:2			3		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 4530
With the advances of modern technology , a huge amount of news videos can be obtained easily .
With the advances in modern technology , a huge amount of news videos can be obtained easily .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:2			3:2			3		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 4531
Accordingly , it creates an urgent demand for retrieving useful information in such news video datasets .
Accordingly , this creates an urgent demand to retrieve useful information from such news video datasets .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:2			6:2			3		1.0
8:1			8:1			1		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 4532
Since most of the news is related to human , human face retrieval , which is defined as the task of extracting and returning faces relevant to a given query , obviously becomes an important task .
Because most news are related to people , human face retrieval , which is defined as the task of extracting and returning faces relevant to a given query , obviously becomes an important task .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			4:1			0		1.0
3:1			5:1			2		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			3		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0
24:1			26:1			0		1.0
25:1			27:1			0		1.0
26:1			28:1			0		1.0
27:1			29:1			0		1.0
28:1			30:1			0		1.0
29:1			31:1			0		1.0
30:1			32:1			0		1.0
31:1			33:1			0		1.0
32:1			34:1			0		1.0
33:1			35:1			0		1.0
34:1			36:1			0		1.0

Alignment 4533
A robust face retrieval system on large-scale news video datasets is indeed of much benefit to a wide range of applications .
A robust face retrieval system for large-scale news video datasets is indeed of much benefit in a wide range of applications .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 4534
For example , by applying face retrieval to a news video dataset , we are returned a list of relevant shots or scenes containing appearance of a selected well-known character .
For example , by applying face retrieval to a news video dataset , we are returned a list of relevant shots or scenes containing the appearance of a selected well-known character .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0

Alignment 4535
With the list , important events related to the character can be detected or summarized.
With such a list , important events related to the character can be found or summarized.
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:3			1:2			3		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			2		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0

Alignment 4536
However , developing an accurate face retrieval system is not a trivial task because of the fact that imaged appearance of a face changes dramatically under large variations in poses , facial expressions , and complex capturing conditions .
However , developing an accurate face retrieval system is not a trivial task because of the fact that the imaged appearance of a face changes dramatically under large variations in poses , facial expressions , and complex capturing conditions .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
37:1			36:1			0		1.0
38:1			37:1			0		1.0
39:1			38:1			0		1.0

Alignment 4537
On the other hand , efficiency is also an issue of such a face retrieval system beside its accuracy since scales of available datasets are getting larger rapidly , for instance , exceeding thousands hours of videos with millions faces of hundreds character .
Besides accuracy , efficiency is also an issue in such a face retrieval system because the scales of available datasets are rapidly getting larger , for instance , exceeding thousands of hours of videos with millions of faces of hundreds of characters .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			18:1			0		1.0
2:1			4:1			0		1.0
3:1			5:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
15:1			1:1			0		1.0
16:1			20:1			0		1.0
17:1			21:1			0		1.0
18:1			22:1			0		1.0
19:1			23:1			0		1.0
20:1			24:1			0		1.0
21:1			27:1			0		1.0
22:1			25:1			0		1.0
23:1			26:1			0		1.0
24:1			28:1			0		1.0
25:1			29:1			0		1.0
26:1			30:1			0		1.0
27:1			31:1			0		1.0
28:1			32:1			0		1.0
29:1			33:1			0		1.0
30:1			10:1			0		1.0
31:1			34:1			0		1.0
32:1			35:1			0		1.0
33:1			36:1			0		1.0
34:1			37:1			0		1.0
35:1			38:1			0		1.0
37:1			39:1			0		1.0
38:1			40:1			0		1.0
39:1			41:1			0		1.0
41:1			42:1			1		1.0
42:1			43:1			0		1.0

Alignment 4538
Thus , accurate and efficient approaches for face retrieval are always required.
Thus , accurate and efficient approaches to face retrieval are always required.
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:2			5:2			3		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 4539
Generally , there are two principle steps in a face retrieval system .
Generally , a face retrieval system consists of two principal steps .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			8:1			0		1.0
3:1			9:1			0		1.0
4:1			10:1			0		1.0
5:1			11:1			0		1.0
6:1			3:1			3		1.0
8:1			4:1			0		1.0
10:1			6:1			0		1.0
11:1			12:1			0		1.0

Alignment 4540
The first step is extracting appearance of faces in video .
The first step is extracting the appearance of faces in videos .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			1		1.0
11:1			10:1			0		1.0

Alignment 4541
And , the second step is matching the extracted ones with a given query to return a rank list .
, The second step is matching the extracted appearances with a given query so as to return a rank list .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			1:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0

Alignment 4542
While conventional approaches consider single face images as the basic units for extracting and matching \CITE , recently proposed approaches sifted towards sets of face images called face-tracks .
Whereas conventional approaches consider single face images as the basic units in extracting and matching \CITE , recently proposed approaches shifted toward the use of sets of face images called face tracks .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
21:2			21:1			3		1.0
25:1			22:1			0		1.0
26:1			23:1			0		1.0
27:1			24:1			0		1.0
28:1			25:1			0		1.0
29:1			26:1			0		1.0
32:1			28:1			0		1.0

Alignment 4543
A face-track contains multiple face images belonging to the same individual character within a video shot .
A face track contains multiple face images belonging to the same individual character within a video shot .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0

Alignment 4544
Face images in a face-track may present the corresponding character under different viewpoints and facial expressions ( as shown in Figure 1 ) .
The face images in a face track may present the corresponding character from different viewpoints and with different facial expressions ( as shown in Figure 1 ) .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
18:1			14:1			0		1.0
19:1			15:1			0		1.0
20:1			16:1			0		1.0
21:1			17:1			0		1.0
22:1			18:1			0		1.0
23:1			19:1			0		1.0
24:1			20:1			0		1.0
25:1			21:1			0		1.0
26:1			22:1			0		1.0
27:1			23:1			0		1.0

Alignment 4545
By exploiting the plenteous information from multiple exemplar faces in face-tracks , face-track based approaches are expected to achieve more robust and stable performance.
By exploiting the plenteous information from the multiple exemplar faces in the face tracks , face track-based approaches are expected to achieve a more robust and stable performance.
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
14:1			11:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0
23:1			19:1			0		1.0
24:1			20:1			0		1.0
25:1			21:1			0		1.0
26:1			22:1			0		1.0
27:1			23:1			0		1.0

Alignment 4546
Once all face-tracks in video shots are extracted , they are matched with the query to return a ranked list as the output of the face retrieval system .
Once all the face tracks in the video shots are extracted , they are matched with the query to return a ranked list as the output of the face retrieval system .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			24:1			0		1.0
3:1			25:1			0		1.0
5:1			3:1			0		1.0
7:1			4:1			0		1.0
8:1			5:1			0		1.0
9:1			6:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0
26:1			23:1			0		1.0
29:1			26:1			0		1.0
30:1			27:1			0		1.0
31:1			28:1			0		1.0

Alignment 4547
Since each face-track is a set of face images , matching face-tracks essentially can be thought of as a problem of matching image sets .
Because each face track is a set of face images , matching face tracks can essentially be thought of as a problem of matching image sets .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
14:1			13:1			0		1.0
15:1			12:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0

Alignment 4548
There are several approaches introduced to deal with this problem \CITE .
Several approaches have been introduced to deal with this problem \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			3:1			0		1.0
2:2			1:1			3		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 4549
They differ in the ways in which the sets are modeled and the similarity between sets is computed .
They differ in the ways in which the sets are modeled and the similarity between sets is computed .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 4550
In these works , image set has been modeled in different way , such as distributions \CITE , subspaces \CITE , convex geometric region in feature space \CITE , or more general manifolds \CITE .
Using these approaches , the image set has been modeled in different ways , including as distributions \CITE , subspaces \CITE , a convex geometric region in a feature space \CITE , or more general manifolds \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			1		1.0
13:1			12:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
28:1			25:1			0		1.0
29:1			26:1			0		1.0
30:1			27:1			0		1.0
31:1			28:1			0		1.0
32:1			29:1			0		1.0
33:1			30:1			0		1.0
34:1			31:1			0		1.0
35:1			32:1			0		1.0
36:1			33:1			0		1.0
37:1			34:1			0		1.0

Alignment 4551
Although these approaches shown promising results on benchmark datasets , they require high computational costs to characterize the representation of face-tracks , such as computing the convex geometric region in \CITE , the probability in \CITE , and the eigenvectors in \CITE .
Although these approaches have shown promising results in benchmark datasets , they require high computational costs to characterize the representation of face tracks , such as computing the convex geometric region in \CITE , the probability in \CITE , and the eigenvectors in \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			40:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
33:1			31:1			0		1.0
34:1			32:1			0		1.0
35:1			33:1			0		1.0
36:1			34:1			0		1.0
37:1			35:1			0		1.0
38:1			36:1			0		1.0
39:1			37:1			0		1.0
40:1			38:1			0		1.0
41:1			39:1			0		1.0
43:1			41:1			0		1.0
44:1			42:1			0		1.0

Alignment 4552
Their complexity in modeling facetracks and estimating similarity between face-tracks limits their practicability on large-scale datasets.
Their complexity in modeling face tracks and estimating the similarity between face tracks limits their practicability in large-scale datasets.
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0

Alignment 4553
Working toward solving the above problems , our contributions in this paper is three-fold.
This paper provides a threefold contribution toward solving the above problems , .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			11:1			0		1.0
2:1			12:1			3		1.0
6:1			1:1			0		1.0
7:1			2:1			0		1.0
8:1			3:1			0		1.0
9:1			4:1			0		1.0
10:1			5:1			0		1.0
11:1			6:1			0		1.0

Alignment 4554
Robust face-track extraction on news video .
Robust face-track extraction from news video .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0

Alignment 4555
To enhance the performance of face-track matching , face-tracks should be first extracted accurately .
To enhance the performance of face-track matching , face tracks should first be extracted accurately .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
10:1			9:1			0		1.0
11:1			11:1			0		1.0
12:1			10:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0

Alignment 4556
, We introduce an approach for this purpose .
For this purpose , we introduce an approach .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			6:1			0		1.0
2:1			7:1			0		1.0
3:1			0:1			0		1.0
5:1			2:1			0		1.0
6:1			3:1			0		1.0
7:1			4:1			0		1.0
8:1			8:1			0		1.0

Alignment 4557
Our approach is motivated by a study of Everingham et al .
motivated by a study of Everingham et al .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			3:1			0		1.0
1:1			4:1			0		1.0
2:1			5:1			0		1.0
3:1			6:1			0		1.0
4:1			7:1			0		1.0
5:1			8:1			0		1.0
6:1			9:1			0		1.0
7:1			10:1			0		1.0
8:1			11:1			0		1.0

Alignment 4558
The basic idea is to employ a point tracker ( Kanade-Lucas-Tomasi tracker \CITE ) to establish the connections between faces belonging to the same character in consecutive frames of a shot .
The basic idea is to use a point tracker ( Kanade-Lucas-Tomasi tracker \CITE ) to establish the connections between faces belonging to the same character in consecutive frames of a shot .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:2			5:2			3		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0

Alignment 4559
, In constrast to the approach in \CITE , which is failed to deal with specific problems of news video caused by sudden illumination change and partial occlusion , our approach is incorporated techniques to overcome the problems .
Our approach incorporates techniques to overcome specific problems with news video caused by sudden illumination change and partial occlusion , in contrast to the approach in \CITE , which failed to deal with , these problems .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			30:1			0		1.0
2:1			31:2			3		1.0
3:1			33:1			0		1.0
4:1			34:1			0		1.0
5:1			35:1			0		1.0
6:1			15:1			0		1.0
7:1			16:1			0		1.0
8:1			14:1			0		1.0
9:1			18:1			0		1.0
10:1			19:1			0		1.0
11:1			20:1			0		1.0
12:1			21:1			0		1.0
13:1			22:1			0		1.0
14:1			23:1			0		1.0
15:1			24:1			0		1.0
16:1			25:1			0		1.0
17:1			26:1			0		1.0
18:1			27:1			0		1.0
19:1			28:1			0		1.0
20:1			6:1			0		1.0
22:1			3:1			0		1.0
23:1			4:1			0		1.0
24:1			5:1			0		1.0
26:1			7:1			0		1.0
27:1			8:1			0		1.0
28:1			9:1			0		1.0
29:1			11:1			0		1.0
30:1			12:1			0		1.0
31:1			13:1			0		1.0
33:1			0:1			0		1.0
34:2			36:2			3		1.0
36:1			38:1			0		1.0

Alignment 4560
Evaluations on a collection of real-world news videos showed that our proposed face-track extraction approach achieved approximately 95% accuracy , a significant improvement compare the approach in \CITE .
Evaluations of a collection of real-world news videos showed that our proposed face-track extraction approach achieved approximately 95% accuracy , a significant improvement compared to the approach in \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			1		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0

Alignment 4561
Efficient face-track matching .
Efficient face-track matching .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0

Alignment 4562
We introduce an approach which significantly reduces the computational cost for face-track matching while maintaining a competitive performance compare to those of the state-of-the-art approaches .
We introduce an approach that significantly reduces the computational cost for face-track matching while maintaining a competitive performance with state-of-the-art approaches .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:2			3:2			3		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
19:1			23:1			0		1.0
20:1			24:1			0		1.0
21:1			25:1			0		1.0

Alignment 4563
Based on the observation that face-tracks obtained by tracking provide highly similar faces in consecutive frames , we argue that it is redundant to use all faces in a face-track for learning the variation of faces .
Based on the observation that face tracks obtained by tracking provide highly similar faces in consecutive frames , we argue that it is redundant to use all the faces in a face track for learning the variation of faces .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			32:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
33:1			30:1			0		1.0
34:1			31:1			0		1.0
36:1			33:1			0		1.0
37:1			34:1			0		1.0
38:1			35:1			0		1.0
39:1			36:1			0		1.0

Alignment 4564
Thus , a set of faces is sampled from the original face-track for matching .
Thus , a set of faces is sampled from the original face track for matching .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0

Alignment 4565
The size of the set is much smaller than the size of original face-track .
The size of the set is much smaller than that of the original face track .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			11:1			0		1.0
11:1			9:1			0		1.0
12:1			12:1			0		1.0
15:1			14:1			0		1.0

Alignment 4566
Then , the mean face of sampled faces in the set is computed .
The , mean face of the sampled faces in the set is then computed .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			2:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0

Alignment 4567
The similarity between two face-tracks is the distance between their mean faces.
The similarity between two face tracks is the distance between their mean faces.
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0

Alignment 4568
Large-scale face-track datasets from real-world news videos .
Large-scale face-track datasets from real-world news videos .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 4569
We investigated the problem of face-retrieval on news video datasets whose scales have not been considered in literature ever .
We investigated the problem of face retrieval in news video datasets whose scales have never been considered in the literature .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			3		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			19:1			0		1.0

Alignment 4570
Our first dataset is from 370 hours TRECVID news videos which contains 405,887 detected faces belonging to 41 individuals .
Our first dataset is from 370 hours of TRECVID news videos and contains 405,887 detected faces belonging to 41 individuals .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0

Alignment 4571
The second dataset is observed from NHK News7 channel in 11 years .
The second dataset includes 1.2 million faces of 111 individuals observed in the NHK News 7 program over 11 years .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
10:1			4:1			0		1.0
11:1			9:1			0		1.0
13:1			6:1			0		1.0
18:1			10:1			0		1.0
19:1			11:1			0		1.0
20:1			12:1			0		1.0

Alignment 4572
In this dataset , 1.2 millions faces of 111 individuals are provided .
, .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			3:1			0		1.0
1:1			12:1			0		1.0

Alignment 4573
The total number of available face-track is 5,567 .
The total number of available face tracks is 5,567 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0

Alignment 4574
Number of occurrence of each individual character varies from 4 to 550 .
The number of occurrences of each individual character varies from 4 to 550 .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			1		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0

Alignment 4575
Both datasets are published for the research community.
Both datasets are published for the research community.
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 4576
The remaining of this paper is organized as follows .
The remainder of this paper is organized as follows .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			3		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 4577
In Section 2 , we introduce related works in details .
In Section 2 , we introduce related works in detail .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			1		1.0
10:1			10:1			0		1.0

Alignment 4578
Section 3 and Section 4 describe our face-track extraction and matching , approaches respectively .
Sections 3 and 4 describe our approaches to face-track extraction and matching , respectively .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			1		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			12:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 4579
Section 5 presents our experimental settings , .
Section 5 presents our experimental settings , and Section 6 provides our .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
12:1			7:1			0		1.0

Alignment 4580
Conclusion is given in the final Section 6.
conclusions.
Line2Start:Length	Line1Start:Length	Module		Score

Alignment 4581
Face-track extraction .
Face-track extraction .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0

Alignment 4582
Face-track extraction is a key step in a video-based face retrieval system .
Face-track extraction is a key step in a video-based face retrieval system .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 4583
Existing studies on automatic face-track extraction follow a standard paradigm that consists of two basic steps , detecting faces in frames and grouping faces of the same character into face-tracks .
The existing studies on automatic face-track extraction follow a standard paradigm that consists of two basic steps , detecting faces in frames and grouping faces of the same character into face tracks .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
32:1			30:1			0		1.0

Alignment 4584
In the first step , Viola-Jones detector is usually employed to detect near frontal faces in frames of videos .
In the first step , the Viola-Jones detector is usually used to detect near frontal faces in frames of videos .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			2		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0

Alignment 4585
Then , in the second step , detected faces of the same character will be grouped by using either clustering approaches \CITE or tracking approaches \CITE .
, In the second step , the detected faces of the same character are grouped by using either clustering \CITE or tracking approaches \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			1:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:2			3		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0
24:1			26:1			0		1.0

Alignment 4586
In \CITE , Ramanan et al .
In \CITE , Ramanan et al .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0

Alignment 4587
builds a color histogram for the hair , face , and torso associated with each detected face in a frame .
built a color histogram for the hair , face , and torso associated with each detected face in a frame .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			2		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 4588
A concatenated vector of the normalized color histograms represents the face .
A concatenated vector of the normalized color histogram represented the face .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			1		1.0
8:2			8:2			3		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 4589
They then cluster all vectors to obtain groups of similar faces , using agglomerative clustering .
They then clustered all vectors to obtain groups of similar faces , using agglomerative clustering .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			1		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 4590
Limitations of this approach includes the expensive computational cost for constructing and clustering high dimensional representation feature vectors; and , its dependence on determining a reasonable threshold for the clustering algorithm to ensure no group contains faces of multiple characters and groups are not over-fragmented.
The limitations of this approach include its high computational cost for constructing and clustering high-dimensional representation feature vectors and , its dependence on determining a reasonable threshold for the clustering algorithm to ensure that no group contains faces of multiple characters and that groups are not over-fragmented.
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			1		1.0
6:1			20:1			0		1.0
7:1			13:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
37:1			36:1			0		1.0
38:1			37:1			0		1.0
39:1			38:1			0		1.0
40:1			39:1			0		1.0
41:1			40:1			0		1.0
43:1			41:1			0		1.0
44:1			42:1			0		1.0
45:1			43:1			0		1.0
46:1			44:1			0		1.0

Alignment 4591
On the other hand , Everingham etl al .
On the other hand , Everingham et al .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 4592
in \CITE and Sivic et al .
\CITE and Sivic et al .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			1:1			0		1.0
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0

Alignment 4593
In \CITE , an affine covariance tracker of \CITE is used .
In \CITE , an affine covariance tracker of \CITE is used .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 4594
This tracker can develop tracks on deforming objects , where the between frame region deformation can be modelled by an affine geometric transformation plus perturbations .
This tracker can develop tracks on deforming objects , where the between-frame region deformation can be modeled by an affine geometric transformation plus perturbations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			1		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0

Alignment 4595
The outcome is that a face can be tracked ( by the collection of regions on it ) through significant pose variations and expression changes , allowing association of possibly distant face detections .
The outcome is that a face can be tracked ( by the collection of regions on it ) through significant pose variations and expression changes , allowing the association of possibly distant face detections .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0

Alignment 4596
The disadvantage of this tracker is the computational cost for locating and tracking affine covariance regions .
The disadvantage of this tracker is its high computational cost for locating and tracking affine covariance regions .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0

Alignment 4597
Another way of using tracker is introduced by Everingham et al .
Another way of using a tracker was introduced by Everingham et al .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			2		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0

Alignment 4598
in \CITE , .
in \CITE , in which .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
5:1			3:1			0		1.0

Alignment 4599
The authors employ Kanade-Lucas-Tomasi ( KLT ) tracker to create a set of point tracks starting at some frame in a shot and continuing until some later frame .
they used a Kanade-Lucas-Tomasi ( KLT ) tracker to create a set of point tracks starting at some frame in a shot and continuing until some later frame .
Line2Start:Length	Line1Start:Length	Module		Score
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 4600
Grouping faces in different frames of one character is based on enumerating track points shared between faces .
Grouping faces in different frames for one character is based on enumerating the track points shared between faces .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0

Alignment 4601
Although using tracking is an efficient solution , it may return poor tracking results since trackers are very sensitive to illumination changes and partial occlusions .
Although using tracking is an efficient solution , it may return poor tracking results because trackers are very sensitive to illumination changes and partial occlusions .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 4602
Face-track matching .
Face-track matching .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0

Alignment 4603
There are two major categories of approaches target to employ multiple-exemplar of faces in face-tracks ( i.e. , sets of face images ) for robust face matching and recognition .
There are two major categories of approaches to using multiple exemplars of faces in face tracks ( i.e. , sets of face images ) for robust face matching and recognition .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			2		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			20:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0

Alignment 4604
Approaches in the first category \CITE make use of both face images and temporal order of their appearances .
The approaches in the first category \CITE make use of both face images and the temporal order of their appearances .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0

Alignment 4605
Face dynamics within the video sequence are modeled and exploited to improve recognition accuracy .
The face dynamics within the video sequence are modeled and exploited to improve recognition accuracy .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0

Alignment 4606
For instance , Li et al .
For instance , Li et al .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0

Alignment 4607
Edwards et al .
Edwards et al .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0

Alignment 4608
They than use the trained statistical face model to incorporate identity evidence over a sequence .
They then used the trained statistical face model to incorporate identity evidence over a sequence .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:2			2:2			3		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 4609
In \CITE , Liu and Chen use an adaptive Hidden Markov Model ( HMM ) for this face recognition problem .
In \CITE , Liu and Chen used an adaptive hidden Markov model ( HMM ) for this face recognition problem .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			1		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			10:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 4610
In the training face , they create a HMM model for each character to learn the statistics and temporal dynamics using the eigen-face image sequence .
In the training face , they created a HMM for each character to learn the statistics and temporal dynamics using the eigen-face image sequence .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			1		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0

Alignment 4611
The implicit constraint of these approaches is that dynamics of faces should be temporally consecutive .
The implicit constraint of these approaches is that the dynamics of faces should be temporally consecutive .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0

Alignment 4612
In general , this constraint is not always satisfied.
In general , this constraint is not always satisfied.
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 4613
Without relying on temporal coherence between consecutive images , approaches in the second category uses multiple face images only .
Without relying on temporal coherence between consecutive images , the approaches in the second category use multiple face images only and .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			1		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
21:1			19:1			0		1.0

Alignment 4614
They treat the problem as a set matching problem .
treat the problem as a set-matching problem .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			1:1			0		1.0
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0

Alignment 4615
These approaches are differentiated based on the ways in which the sets are modeled and the similarity between sets is computed .
These approaches are differentiated based on the ways in which the sets are modeled and the similarity between sets is computed .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 4616
Shakhnarovich et al .
Shakhnarovich et al .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0

Alignment 4617
However , to make the computation tractable , they made a assumption that faces are normally distributed , which may not be true \CITE .
However , to make the computation tractable , they made the assumption that faces are normally distributed , which may not be true \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 4618
Cevikalp and Triggs \CITE claimed a face sequence was a set of points and discovered a convex geometric region expanded by these points .
Cevikalp and Triggs \CITE claimed that a face sequence is a set of points and discovered a convex geometric region expanded by these points .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			2		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0

Alignment 4619
The min-min approach \CITE considered a face sequence as a cluster of points and measured the distance between these clusters .
The min-min approach \CITE considered a face sequence as a cluster of points and measured the distance between these clusters .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 4620
Subspace methods \CITE viewed a face sequence as points spread over a subspace .
Subspace methods \CITE viewed a face sequence as points spread over a subspace .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 4621
Although these methods can be highly accurate , a lot of computation is needed to represent the distribution of the face sequence , such as computing the convex hulls in \CITE , the probability models in \CITE , and the eigenvectors in \CITE .
Although these methods can be highly accurate , a lot of computation is needed to represent the distribution of the face sequence , such as computing the convex hulls in \CITE , the probability models in \CITE , and the eigenvectors in \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0

Alignment 4622
For this reason , they are not scalable for large-scale video datasets .
For this reason , they are not scalable to large-scale video datasets .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 4623
Face Datasets .
Face datasets .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			2:1			0		1.0

Alignment 4624
To evaluate performance of face matching approaches , most of recent works on face retrieval in video uses two benchmark datasets Mobo ( Motion of Body ) \CITE and Honda / UCSD \CITE .
In evaluating the performance of face-matching approaches , most of the recent works on face retrieval in video use two benchmark datasets: Mobo ( Motion of Body ) \CITE and Honda / UCSD \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
3:1			2:1			0		1.0
4:1			3:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			1		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0

Alignment 4625
Scales of these datasets are limited , they are varying from hundreds to thousands face images of tens individual characters .
The scales of these datasets are limited , varying from hundreds to thousands of face images of tens of individual characters .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0

Alignment 4626
Particularly , Honda / UCSD consists of 75 videos involving 20 individual .
Particularly , Honda / UCSD consists of 75 videos involving 20 individuals .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			1		1.0
12:1			12:1			0		1.0

Alignment 4627
Each video contains approximately 300-500 frames .
Each video contains approximately 300-500 frames .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0

Alignment 4628
Meanwhile , Mobo provides 96 image sets of 24 individuals .
Meanwhile , Mobo provides 96 image sets of 24 individuals .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 4629
Hence , there are only 4 image sets for each individual .
Hence , there are only 4 image sets for each individual .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 4630
One of the largest available face dataset recently is the Youtube Faces dataset \CITE , .
One of the largest face datasets recently available is the YouTube Faces dataset \CITE , which .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			1		1.0
6:1			7:1			0		1.0
7:1			4:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
16:1			15:1			0		1.0

Alignment 4631
It provides 3,425 videos of 1,595 individual characters .
provides 3,425 videos of 1,595 individual characters .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			1:1			0		1.0
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0

Alignment 4632
However , one character has only around 2.15 videos .
However , each character has only around 2.15 videos .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 4633
Such a small number of samples for each character is not sufficient for stably evaluating a face matching or recognition approach , which is an important part of a face retrieval system .
Such a small number of samples for each character is not sufficient to stably evaluate a face-matching or recognition approach , which is an important part of a face retrieval system .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:2			11:2			3		1.0
13:1			13:1			0		1.0
14:1			14:1			1		1.0
15:1			15:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0
31:1			32:1			0		1.0

Alignment 4634
In addition , there is no face dataset related to real-world news videos , which is our targeted domain .
In addition , there is no face dataset related to real-world news videos , which is our targeted domain .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 4635
Because of all above mentioned reasons , we prepare new datasets for evaluating the approaches.
In view of all the above-mentioned considerations , we prepare new datasets for evaluating the approaches.
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
6:1			5:1			3		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0

Alignment 4636
Figure 2 illustrates the overview of our framework .
Figure 2 illustrates the overview of our framework .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 4637
In the offline stage , face-tracks in all shots of videos are extracted using our face-track extraction approach ( described in Section 4 ) .
In the off-line stage , the face tracks in all video shots are extracted using our face-track extraction approach ( described in Section 4 ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			9:2			3		1.0
11:1			8:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0

Alignment 4638
One extracted face-track contains multiple face images of one individual character , varied under different viewpoints , illumination conditions , and expressions within a shot .
Each extracted face track contains multiple face images of one individual character , varied under different viewpoints , illumination conditions , and expressions within a shot .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0

Alignment 4639
A single face image in a face-track is represented by a feature vector .
Each single face image in a face track is represented by a feature vector .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0

Alignment 4640
The process consisting of face-track extraction and face image representation is performed once for the entire video dataset .
The process consisting of face-track extraction and face image representation is performed once for the entire video dataset .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 4641
Our contribution here is to make the face-track extraction approach robust to sudden illumination changes , scattered appearance of characters , and occlusions.
Our contribution here is making the face-track extraction approach robust to sudden illumination changes , scattered appearances of characters , and occlusions.
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			5:1			1		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			1		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0

Alignment 4642
Given a face-track as an input retrieval query , the online stage of our system starts by using our proposed face-track matching algorithm ( described in Section 5 ) to estimate the similarity between a query face-track and each face-track in the retrieved set containing all face-tracks extracted from the dataset in the offline stage .
Given a face track as an input retrieval query , the online stage of our system starts by using our proposed face-track matching algorithm ( described in Section 5 ) to estimate the similarity between a query face track and each face track in the retrieved set containing all face tracks extracted from the dataset in the offline stage .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
39:1			37:1			0		1.0
40:1			38:1			0		1.0
43:1			40:1			0		1.0
44:1			41:1			0		1.0
45:1			42:1			0		1.0
46:1			43:1			0		1.0
47:1			44:1			0		1.0
48:1			45:1			0		1.0
51:1			47:1			0		1.0
52:1			48:1			0		1.0
53:1			49:1			0		1.0
54:1			50:1			0		1.0
55:1			51:1			0		1.0
56:1			52:1			0		1.0
57:1			53:1			0		1.0
58:1			54:1			0		1.0
59:1			55:1			0		1.0

Alignment 4643
A ranked list of the evaluated face-tracks is returned as retrieval results of the online stage .
A ranked list of the evaluated face tracks is returned as the retrieval result of the online stage .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			1		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0

Alignment 4644
Since the retrieved set is huge , our approach targets an extremely efficient face-track matching strategy while maintaining competitive performance with state-ofthe-art approaches.
Because the retrieved set is huge , our approach targets an extremely efficient face-track matching strategy while maintaining a competitive performance with state-of-the-art approaches.
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
23:1			22:1			0		1.0

Alignment 4645
Given a video shot with occurrences of multiple characters , face-track extraction is the process of extracting sets of face images .
Given a video shot with occurrences of multiple characters , face-track extraction is the process of extracting sets of face images .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 4646
A set is supposed to contain face images of only one character who appears in the shot .
A set is supposed to contain the face images of only one character who appears in the shot .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0

Alignment 4647
Such sets of face images are called face-tracks ( sometimes called face sequences ) .
Such sets of face images are called face tracks ( sometimes called face sequences ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0

Alignment 4648
A common strategy of existing approaches for face-track extraction consists of detecting faces in frames and grouping detected faces of the same character .
A common strategy in the existing approaches to face-track extraction consists in detecting faces in frames and grouping detected faces of the same character .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:2			2:2			3		1.0
4:1			20:1			0		1.0
5:1			4:1			0		1.0
6:2			5:2			3		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:2			9:2			3		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0

Alignment 4649
While detecting faces is done by using a standard face detector ( e.g. , Viola-Jones face detector ) \CITE , grouping detected faces requires comprehensive techniques to identify faces of the same character.
Whereas detecting faces is done by using a standard face detector ( e.g. , Viola-Jones face detector ) \CITE , grouping detected faces requires comprehensive techniques to identify faces of the same character.
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0

Alignment 4650
In this section , we first briefly introduce an approach for face-track extraction proposed by Everingham et al .
In this section , we first briefly introduce an approach to face-track extraction proposed by Everingham et al .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 4651
Its problems as it is applied to news video and our proposed solutions to overcome the problems is then presented.
We then present the problems with this approach as applied to news video and our proposed solutions.
Line2Start:Length	Line1Start:Length	Module		Score
1:1			18:1			0		1.0
3:1			15:1			0		1.0
4:1			16:1			0		1.0
8:1			2:1			0		1.0
9:1			5:1			0		1.0
10:1			6:1			0		1.0
11:1			7:1			0		1.0
12:1			8:1			0		1.0
13:1			9:1			0		1.0
14:1			10:1			0		1.0
15:1			11:1			0		1.0

Alignment 4652
To group detected faces into face-tracks , connections between faces belonging to the same character in different frames should be established .
To group detected faces into face tracks , connections should be established between faces belonging to the same character in different frames .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			18:1			0		1.0
10:1			19:1			0		1.0
11:1			20:1			0		1.0
12:1			8:1			0		1.0
13:1			9:1			0		1.0
14:1			10:1			0		1.0
15:1			11:1			0		1.0
16:1			12:1			0		1.0
17:1			13:1			0		1.0
18:1			14:1			0		1.0
19:1			15:1			0		1.0
20:1			16:1			0		1.0
21:1			17:1			0		1.0
22:1			21:1			0		1.0

Alignment 4653
Motion analysis can be used to investigate such connections .
Motion analysis can be used to investigate such connections .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 4654
If two faces in different frames are defined that they are translated faces of each other according to a motion , they are likely faces of the same character .
If two faces in different frames are defined that they are translated faces of each other according to a motion , they are likely faces of the same character .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0

Alignment 4655
Everingham et al .
Everingham et al .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0

Alignment 4656
in \CITE propose to use KLT tracker for this purpose .
in \CITE proposed the use of a KLT tracker for this purpose .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:2			3		1.0
4:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0

Alignment 4657
Their algorithm starts by detecting interest points in the first frame of the shot and propagating them to the next frames based on local appearance matching .
Their algorithm starts by detecting interest points in the first frame of the shot and propagating them to the next frames based on local appearance matching .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 4658
Points which can not be propagated from one frame to the next are eliminated and replaced with new points .
Points that cannot be propagated from one frame to the next are eliminated and replaced with new points .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			2:2			3		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0

Alignment 4659
Given two faces in different frames , if the number of point tracks passing through both faces is larger than half of the total number of point tracks which are not in common to both faces , they are grouped into one face-track.
Given two faces in different frames , if the number of point tracks passing through both faces is larger than half of the total number of point tracks that are not common to both faces , the faces are grouped into one face track.
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:2			28:2			3		1.0
30:1			30:1			0		1.0
31:1			32:1			0		1.0
32:1			33:1			0		1.0
33:1			34:1			0		1.0
34:1			35:1			0		1.0
35:1			36:1			0		1.0
37:2			37:2			3		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0

Alignment 4660
Although the approach by Everingham et al .
Although the approach by Everingham et al .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 4661
has demonstrated its efficiency and robustness on drama videos \CITE , directly applying the approach to news videos results poor performances due to following issues.
has shown its efficiency and robustness with drama videos \CITE , directly applying the approach to news videos results in poor performance due to the following issues.
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:2			1:2			3		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			1		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0

Alignment 4662
Tracking errors due to sudden illumination change .
Tracking errors due to sudden illumination change .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 4663
Since the KLT tracker uses intensity variance for computing the image motion to find the correspondence between points in different frames , it is unreliable when there is a sudden and significant change in illumination .
Because the KLT tracker uses intensity variance for computing the image motion to find the correspondence between points in different frames , it is unreliable when there is a sudden and significant change in illumination .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0

Alignment 4664
As shown in Figure 3 ( top ) , points are distracted when flash occurs .
As shown in Figure 3 ( top ) , points are distracted when a flash occurs .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0

Alignment 4665
As a result , the points are badly tracked .
As a result , the points are badly tracked .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 4666
The flash breaks all connections between faces in frames before and after its occurrence.
The flash breaks all connections between faces in the frames before and after its occurrence.
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0

Alignment 4667
Unadaptive track point generation .
Unadaptive track point generation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0

Alignment 4668
In \CITE , track point generation is totally independent with face appearances .
In \CITE , the track point generation is totally independent from face appearances .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0

Alignment 4669
New points are generated at the first frame of the shot or at a frame in which some existing points can not be propagated .
New points are generated at the first frame of the shot or at a frame in which some existing points cannot be propagated .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:2			3		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0

Alignment 4670
As a result , a face , which does not appear in the aforementioned frames , may not contain any point .
As a result , a face that , does not appear in the aforementioned frames , may not contain any point .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 4671
Its connections with other faces in the shot cannot be established for grouping.
Its connections with other faces in the shot cannot be established for grouping.
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 4672
Tracking errors due to occlusion .
Tracking errors due to occlusion .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0

Alignment 4673
To successfully connect actual faces of the same character in different frames , track points generated for the first face should be tracked and retained inside the latter faces for a sufficient number of shared points between faces .
To successfully connect actual faces of the same character in different frames , the track points generated for the first face should be tracked and retained inside the latter faces for a sufficient number of shared points between faces .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			26:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
37:1			36:1			0		1.0
38:1			37:1			0		1.0
39:1			38:1			0		1.0

Alignment 4674
However , when occlusion occurs , points are distracted by occluded regions .
However , when occlusion occurs , the points are distracted by occluded regions .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0

Alignment 4675
Thus , the number of shared points drops , .
Thus , the number of shared points drops , .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 4676
It results in face connection failure .
resulting in face connection failure .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			1:1			1		1.0
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0

Alignment 4677
As shown in Figure 3 ( bottom ) , when the woman moves the paper , which partially occludes her face in several frames , some points in her facial region are drifted with the paper .
As shown in Figure 3 ( bottom ) , when the woman moves the paper , which partially occludes her face in several frames , some points in her facial region are drifted with the paper .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0

Alignment 4678
These points are not lost so they are not replaced by new points .
These points are not lost so they are not replaced by new points .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 4679
But , they become meaningless to determine the connection between faces.
However , they become meaningless in determining the connection between faces.
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:2			5:2			3		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 4680
Based on above observed limitations of the approach in \CITE on news videos , we integrate techniques to bypass these liminations in our proposed approach for face-track extraction on news videos.
Based on the observed limitations of the approach in \CITE when applied to news videos , we integrate techniques to bypass these restrictions in our proposed approach to face-track extraction in news videos.
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
12:2			10:2			3		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0

Alignment 4681
Firstly , \CITE , our approach does not compare all possible pairs of faces in a shot for face grouping as in \CITE .
First , unlike in \CITE , our approach does not compare all possible pairs of faces in a shot for face grouping\CITE; .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			1		1.0
1:1			1:1			0		1.0
3:1			21:1			0		1.0
4:1			2:1			0		1.0
5:1			3:1			0		1.0
6:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
22:1			23:1			0		1.0

Alignment 4682
Such pair-wise comparison rapidly becomes intractable as the number of faces in a shot increases .
such pairwise comparison rapidly becomes intractable as the number of faces in a shot increases .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 4683
Instead of that , we group faces into face-track following temporal order of their appearances .
Instead , we group faces into face tracks according to the temporal order of their appearances .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			3:1			0		1.0
2:1			4:1			0		1.0
3:1			5:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0

Alignment 4684
A detected face in the current frame is considered to group into existing face-tracks formed by previously detected faces only .
A detected face in the current frame is considered for grouping into existing face tracks formed by previously detected faces only .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			10:1			1		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0

Alignment 4685
By doing this , we avoid greedy pairwise comparison.
By doing this , we avoid greedy pairwise comparison.
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 4686
Secondly , as our first observation , a sudden illumination change in any frame make the KLT tracker failed to track points properly .
Second , as described in our first observation , a sudden illumination change in any frame causes the KLT tracker to fail to track points properly .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			1		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
5:1			3:1			0		1.0
6:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			2		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
21:1			18:1			1		1.0
22:1			19:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0
26:1			23:1			0		1.0

Alignment 4687
Because such illumination changes are very common and they mostly appear together with important character in a news , a solution to this problem is vital .
Because such illumination changes are very common and mostly occur simultaneously with important characters in a news video , finding a solution to this problem is vital .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			9:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			1		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
18:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0

Alignment 4688
We learn that the occurences of such illumination changes are usually very short ( less than 3 frames ) .
We learn that the occurrences of such illumination changes are usually very short ( less than 3 frames ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 4689
And , faces appeared in those frames are less informative for recognition since most of the facial identity characteristics are loss due to overlighting .
and that the , faces that appear in those frames are less informative for recognition because most of the facial identity characteristics are lost due to over-lighting .
Line2Start:Length	Line1Start:Length	Module		Score
3:1			1:1			0		1.0
4:1			2:1			0		1.0
6:1			3:1			1		1.0
7:1			4:1			0		1.0
8:1			5:1			0		1.0
9:1			6:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0
15:2			12:2			3		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			0		1.0
23:1			20:1			3		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0
27:1			24:1			0		1.0

Alignment 4690
, They can not enrich information of its corresponding face-track , but may add noise .
Thus , the faces cannot enrich the information on its corresponding face track , but may only add noise .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			0:1			0		1.0
4:1			2:2			3		1.0
5:1			4:1			0		1.0
7:1			5:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
17:1			13:1			0		1.0
18:1			14:1			0		1.0
19:1			15:1			0		1.0

Alignment 4691
Therefore , our solution is to detect and skip all frames contain sudden illumination changes , .
Therefore , our solution is to detect and skip all frames containing sudden illumination changes , which .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			1		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
17:1			16:1			0		1.0

Alignment 4692
We call such frames as flashframes.
we call flash frames.
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0

Alignment 4693
To indetify flash-frames , we measures the brightness of frames in the video shot .
To identify flash frames , we measure the brightness of the frames in the video shot .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
3:1			9:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			1		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0

Alignment 4694
If the brightness of a frame significantly increases compared with those of its neighbors , the frame is declared as a flash-frame and is skipped for processing .
If the brightness of a frame is significantly increased compared with its neighbors , the frame is declared a flash frame and skipped in processing .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			23:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			1		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			20:1			0		1.0
21:1			22:1			0		1.0
22:1			24:1			0		1.0
24:1			26:1			0		1.0
25:1			27:1			0		1.0

Alignment 4695
Particularly , given a frame \SYM with t indicates its frame index , we compute the average luminosity L of the frame \SYM and its consicutive frames \SYM , where i = \SYM; t +W+ 1 , and W is the potential length of a sudden illumination change .
Particularly , given a frame \SYM with t indicating its frame index , we compute the average luminosity L of the frame \SYM and its consecutive frames \SYM , where i = \SYM; t +W+ 1 , and W is the potential length of a sudden illumination change .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			1		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0
39:1			39:1			0		1.0
40:1			40:1			0		1.0
41:1			41:1			0		1.0
42:1			42:1			0		1.0
43:1			43:1			0		1.0
44:1			44:1			0		1.0
45:1			45:1			0		1.0
46:1			46:1			0		1.0
47:1			47:1			0		1.0
48:1			48:1			0		1.0

Alignment 4696
Then , we compare the average luminosity L of each frame \SYM in the set S = \SYM with s = t; t +W to those of \SYM and \SYM .
Then , we compare the average luminosity L of each frame \SYM in the set S = \SYM with s = t; t +W to those of \SYM and \SYM .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0

Alignment 4697
If L( \SYM ) > L( \SYM ) and L( \SYM ) > L( \SYM ) , \SYM is defined as flash-frames regarding a predefined brightness sensitive threshold \SYM .
If L( \SYM ) > L( \SYM ) and L( \SYM ) > L( \SYM ) , \SYM is defined as flash frames according to a predefined brightness sensitive threshold \SYM .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0

Alignment 4698
In our experiments , we found that \SYM = 1:25 and W = {1; 2; 3} are optimal for detecting all flash-frames with a low false alarm rate.
In our experiments , we found that \SYM = 1:25 and W = {1; 2; 3} are optimal for detecting all flash frames with a low false alarm rate.
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0

Alignment 4699
Given a video shot , our approach starts by finding the first frame in which faces are detected .
Given a video shot , our approach starts by finding the first frame in which faces are detected .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 4700
All point tracking and face grouping processes are initialized from this frame , not at the first frame of the shot as in \CITE .
All point-tracking and face-grouping processes are initialized from this frame , not at the first frame of the shot as in \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			3:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0

Alignment 4701
This helps us to save computational cost as well as to avoid tracking errors caused by transition effects between shots .
This helps us to save on computational cost and avoid tracking errors caused by transition effects between shots .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0

Alignment 4702
Initial track points will be generated for all detected faces in the frame .
Initial track points will be generated for all detected faces in the frame .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 4703
Each face now becomes the first face of a corresponding newly formed face-track.
Each face now becomes the first face of a corresponding newly formed face track.
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 4704
After the initialization , we sequentially process each frame afterwards , knowing all flash-frames will be skipped .
After the initialization , we sequentially process each frame , knowing all flash frames will be skipped .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 4705
At a given frame , points from the previous frame are tracked by the KLT tracker to update their locations .
In a given frame , the points from the previous frame are tracked by the KLT tracker to update their locations .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0

Alignment 4706
If there are faces detected , each face is checked against all existing facetracks formed in the previous frames to find out which facetrack it belongs to .
If there are faces detected , each face is checked against all the existing face tracks formed in the previous frames to find out to which face track the face belongs .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
13:1			12:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			26:1			0		1.0
25:1			22:1			0		1.0
30:1			25:1			0		1.0
31:1			27:1			0		1.0

Alignment 4707
Checking between a face and a facetrack is based on enumerating points shared by both the face and the last appeared face of the face-track .
The checking between a face and a face track is based on enumerating the points shared by both the face and the last face that appeared on the face track .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			21:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			23:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			0		1.0
25:1			20:1			0		1.0
30:1			25:1			0		1.0

Alignment 4708
If the enumerated number is larger than half of the total number of points which are not in common to both faces , the faces is grouped into the face-track .
If the enumerated number is larger than half of the total number of points that are not common to both faces , the face is grouped into the face track .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:2			14:2			3		1.0
16:1			16:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			1		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
30:1			30:1			0		1.0

Alignment 4709
Our grouping criterion here is similar to \CITE .
Our grouping criterion here is similar to that in \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0

Alignment 4710
A face which can not be grouped into any face-track is treated as an initial face of a new face-track .
A face that cannot be grouped into any face track is treated as the initial face of a new face track .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:2			2:1			3		1.0
3:1			3:2			3		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			1:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
21:1			20:1			0		1.0

Alignment 4711
We then generate new track points inside such faces for tracking an grouping its corresponding faces in latter frames .
We then generate new track points within such faces for tracking and grouping its corresponding faces in latter frames .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			2		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 4712
In our approach , track points are generated in conjunction with face appearances .
In our approach , track points are generated in conjunction with face appearances .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 4713
We can ensure that there are always track points for all faces appear in the shot .
We can ensure that there are track points for all faces that appear in the shot .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 4714
Consequently , our approach overcomes the second observed limitation of \CITE.
Consequently , our approach overcomes the second observed limitation in \CITE.
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			10:1			0		1.0

Alignment 4715
In other case , when a face in the current frame is grouped to an existing face-track , we prepare points for further tracking .
In other cases , when a face in the current frame is grouped into an existing face track , we prepare points for further tracking .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			1		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0

Alignment 4716
We remove all points which are inside the last appeared face of the face-track but not inside the current face , and vice versa .
We remove all points that are inside the last face that appeared on the face track but are not inside the current face , and vice versa .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:2			4:2			3		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			10:1			0		1.0
11:1			9:1			0		1.0
13:1			12:1			0		1.0
14:1			19:1			0		1.0
16:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0
26:1			23:1			0		1.0
27:1			24:1			0		1.0

Alignment 4717
Since such points are likely tracked incorrectly , eliminating them prevent us from transferring tracking errors to latter frames .
Because such points are likely tracked incorrectly , eliminating them prevents us from transferring tracking errors to latter frames .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			1		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 4718
Points which are shared by both faces are kept .
Points that are shared by both faces are kept .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:2			1:2			3		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 4719
Besides , we generate additional points to replace the removed ones and to provide updated points .
Besides , we generate additional points to replace the removed ones and to provide updated points .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 4720
By doing that , our tracking results through a long sequence of frames become more accurate and reliable .
By doing so , our tracking results over a long sequence of frames become more accurate and reliable .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:2			1:2			3		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 4721
As a result , we can partly bypass the third observed limitation of \CITE .
As a result , we can partly bypass the third observed limitation of \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 4722
When a face is partly and slowly occluded , our approach can discard incorrectly tracked points as well as reproduce points for the face after being occluded .
When a face is partly and slowly occluded , our approach can discard incorrectly tracked points and reproduce points for the face after it has been occluded .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
25:1			25:1			3		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0

Alignment 4723
Thus , the connection between faces before and after the occlusion are retained.
Thus , the connection between faces before and after the occlusion is retained.
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			2		1.0
12:1			12:1			0		1.0

Alignment 4724
Our approach continuously process the next frame until reaching the end of the shot .
Our approach continuously processes the next frame until the end of the shot is reached .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			1		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
15:1			14:1			0		1.0

Alignment 4725
The pseudo-code is presented in the Algorithm 1 as follows.
The pseudo-code is presented in Algorithm 1 as follows.
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0

Alignment 4726
There are several approaches have been proposed for matching face-tracks ( as presented in Section 2 ) .
Several approaches to matching face tracks have been proposed ( as presented in Section 2 ) .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			3:1			0		1.0
3:1			8:1			0		1.0
6:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0

Alignment 4727
, Although these existing approaches achive high accuracy on benchmark datasets , their expensive computational costs limits their practical applications on large-scale datasets .
However , although these approaches have shown high accuracy in benchmark datasets , their high computational costs limit their practical applications in large-scale datasets .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			0:1			0		1.0
3:1			2:1			0		1.0
4:1			4:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			3		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			1		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0

Alignment 4728
This motivate us to target an matching approach which is balanced between accuracy and computational cost .
This motivates us to target a matching approach that provides a good balance between accuracy and computational cost .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			1		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			6:1			0		1.0
7:2			7:2			3		1.0
9:1			9:1			3		1.0
11:2			10:1			3		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0

Alignment 4729
The approach should be extremely efficient while archiving competitive performance compare to state-of-the-art approaches�f.
The approach should be extremely efficient while achieving a competitive performance with state-of-the-art approaches.
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
12:1			12:1			0		1.0

Alignment 4730
In order to maintain a competitive accuracy , we still employ plenteous information from multiple faces of a facetrack to enrich its representation .
To maintain competitive accuracy , we still use the plenteous information from the multiple faces of a face track to enrich the representation .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			3:1			0		1.0
2:1			5:1			0		1.0
3:1			6:1			0		1.0
4:1			7:1			0		1.0
5:1			8:1			0		1.0
6:1			9:1			0		1.0
7:1			10:1			2		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 4731
However , instead of using all faces in a face-track , we propose to subsample the faces .
However , instead of using all the faces in a face track , we propose taking a subsample of faces .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			15:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
17:1			14:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0

Alignment 4732
By doing that , the require computational cost can be reduced while a sufficient amount of information is kept for improving accuracy .
In doing so , the required computational cost can be reduced while keeping the amount of information sufficient to improve accuracy .
Line2Start:Length	Line1Start:Length	Module		Score
1:2			1:2			3		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			1		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			18:1			2		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			13:1			0		1.0
18:2			19:2			3		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0

Alignment 4733
We called our approach as k-Faces.
We call our approach k-Faces.
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			1		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			5:1			0		1.0

Alignment 4734
Given a specific value of k , which indicates the expected size of the sub-sampled set of a face-track , the approach starts by dividing each face-track into k parts following its temporal order .
Given a specific value of k , which indicates the expected size of the subsampled set of a face track , the approach starts by dividing each face track into k parts according to the temporal order of appearances .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
35:1			32:1			0		1.0
36:1			33:1			0		1.0
39:1			34:1			0		1.0

Alignment 4735
For each part , one face is selected to represent for all faces within the part .
For each part , one face is selected to represent all faces within the part .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0

Alignment 4736
The mean face of k selected faces is then computed .
The mean face of k selected faces is then computed .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 4737
The similarity between two face-tracks is now the distance between their mean faces.
The similarity between two face tracks is now the distance between their mean faces.
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0

Alignment 4738
Let denote mA = {\SYM; \SYM; : :; \SYM} and mB = {\SYM ; \SYM; : :; \SYM} are two mean faces of two face-track A and B , respectively , with N imposes the number of dimension of the feature space .
Let mA = {\SYM; \SYM; : :; \SYM} and mB = {\SYM ; \SYM; : :; \SYM} denote the mean faces of face tracks A and B , respectively , with N representing the number of dimensions of the feature space .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			1:1			0		1.0
18:1			39:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0
31:1			32:1			0		1.0
32:1			18:1			2		1.0
33:1			34:1			0		1.0
34:1			35:1			0		1.0
35:1			36:1			0		1.0
36:2			37:2			3		1.0
39:1			40:1			0		1.0
40:1			41:1			0		1.0
41:1			42:1			0		1.0

Alignment 4739
We employ following standard distance types to compute the distance between mA and mB.
We use following standard distance types to compute the distance between mA and mB.
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			2		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 4740
An illustration of our k-Faces , is shown in Figure 4 .
Figure 4 illustrates our k-Faces , with the following .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			9:1			0		1.0
1:1			10:1			0		1.0
2:1			1:1			1		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
8:1			6:1			2		1.0
9:1			11:1			0		1.0

Alignment 4741
Its pseudo-code is presented as follows .
pseudo-code: .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			6:1			0		1.0

Alignment 4742
Clearly , the higher value of k is selected , the more faces in each face-track are selected to compute the representative face of the face track .
Clearly , the higher the value of k selected , the more faces in each face track selected to compute the representative face and the .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			24:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			25:1			0		1.0
16:1			26:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
25:1			27:1			0		1.0

Alignment 4743
And , better approximations , may result in higher accuracies .
, better the approximations , which may result in higher accuracies .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			1:1			0		1.0
1:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0

Alignment 4744
However , the computational cost can overly increases .
However , the computational cost can overly increases .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 4745
By using k as a predefined parameter , k-Faces provides flexibility for users in balancing their expected accuracy and the cost which they can afford ( or time they can wait for the result ).
By using k as a predefined parameter , k-Faces provides users with flexibility in balancing the accuracy they expect and the cost they can afford ( or the time they can spend waiting for the result ).
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			12:1			0		1.0
12:1			10:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			32:1			0		1.0
16:1			17:1			0		1.0
17:1			28:1			0		1.0
18:1			30:2			3		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
28:1			27:1			0		1.0
30:1			29:1			0		1.0
33:1			11:1			0		1.0
35:1			33:1			0		1.0
36:1			34:1			0		1.0

Alignment 4746
Besides that , since k-Faces averages multiple faces for a representative face of a face-track , the effects of noisy or outliers faces on estimating the similarity of face-tracks will be substantially reduced.
Besides , because k-Faces averages multiple faces for the representative face of a face track , the effects of noisy or outlier faces on estimating the similarity of face tracks will be substantially reduced.
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			2:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			25:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			1		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0

Alignment 4747
In this section , we present our experiments to evaluate the proposed approaches .
In this section , we present our experiments to evaluate the proposed approaches .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 4748
The experiments are divided into two parts .
The experiments are divided into two parts; .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			7:1			0		1.0

Alignment 4749
In the first part , we evaluate the performance of the proposed approach for face-track extraction , .
the first , evaluates the performance of the proposed approach in face-track extraction , and the second in .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			1:1			0		1.0
1:1			2:1			0		1.0
2:1			4:1			0		1.0
3:1			6:1			1		1.0
4:1			7:1			0		1.0
5:1			8:1			0		1.0
6:1			9:1			0		1.0
7:1			10:1			0		1.0
8:1			11:1			0		1.0
9:1			12:1			0		1.0
11:1			14:1			0		1.0
12:1			15:1			0		1.0
13:1			16:1			0		1.0
18:1			17:1			0		1.0

Alignment 4750
Evaluation of the proposed approach for face-track matching is given in the second part.
face-track matching.
Line2Start:Length	Line1Start:Length	Module		Score
0:1			6:1			0		1.0

Alignment 4751
We tested our proposed approach for face-track extraction on 8 video sequences from different video broadcasting stations , including NHK News 7 , ABC News , and CNN News.
We tested our proposed approach to face-track extraction on 8 video sequences from different video broadcasting stations , including NHK News 7 , ABC News , and CNN News.
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0

Alignment 4752
All shot boundaries are provided in advance .
All shot boundaries are provided in advance .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 4753
A face detector based on Viola-Jones approach \CITE was used for detecting near frontal faces in every frame of these video sequences .
A face detector based on the Viola-Jones approach \CITE is used to detect near frontal faces in every frame of the video sequences .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			2		1.0
10:1			9:1			0		1.0
11:2			10:2			3		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0

Alignment 4754
A conservative threshold is used to reduce the number of false positives ( i.e. , a non-face classified as a face ).
A conservative threshold is used to reduce the number of false positives ( i.e. , a non-face classified as a face ).
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 4755
Ground-truth information on face-tracks in videos is manually prepared .
Ground-truth information on the face tracks in videos is manually prepared .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
6:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0

Alignment 4756
A face-track of one character appearing in a video shot is annotated by indexes of the frames which the first face and the last face of that character occur .
Each face track of a character appearing in a video shot is annotated by indexes of the frames in which the first face and the last face of that character occur .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			24:1			0		1.0
3:1			2:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0

Alignment 4757
An approach is called exactly extracting a face-track if it provides precise starting and ending frame indexes of the face-track , compared to ground-truth annotation .
An approach is considered as exactly extracting a face track if it provides precise starting and ending frame indexes of the face track , compared to ground-truth annotation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0
26:1			23:1			0		1.0
27:1			24:1			0		1.0
28:1			25:1			0		1.0

Alignment 4758
Note that if a character moves out of the frame then moves in again , annotators will divide the appearance of that character into two independent face-tracks in our ground-truth .
Note that if a character moves out of the frame and then moves back into it again , annotators will divide the appearance of that character into two independent face tracks in ground-truth annotation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
14:1			23:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0
27:1			24:1			0		1.0
28:1			25:1			0		1.0
31:1			12:1			0		1.0
32:1			29:1			0		1.0
34:1			30:1			0		1.0

Alignment 4759
The number of frames , faces , and face tracks are shown in Table 1 .
Table 1 shows the number of frames , faces , and face tracks .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			13:1			0		1.0
1:1			14:1			0		1.0
2:1			10:2			3		1.0
4:1			1:1			0		1.0
5:1			2:1			0		1.0
6:1			3:1			0		1.0
7:1			4:1			0		1.0
8:1			5:1			0		1.0
9:1			6:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			15:1			0		1.0

Alignment 4760
In this experiment , we directly compare our approach with one proposed by Everingham et al .
In this experiment , we directly compare our approach with that proposed by Everingham et al .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 4761
in \CITE.
in \CITE.
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0

Alignment 4762
As shown in Table 2 , by detecting flash-frames , our approach successfully overcomes the problem of face-track fragmentation due to illumination changes .
As shown in Table 2 , by detecting flash frames , our approach successfully overcomes the problem of face-track fragmentation due to illumination changes .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0

Alignment 4763
Meanwhile , the approach by Everingham et al .
Meanwhile , the approach by Everingham et al .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 4764
is almost failed to do that .
almost completely fails to do that .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			1:1			0		1.0
2:1			2:1			1		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0

Alignment 4765
In addition , the results also shows that our approach is superior to the approach by Everingham et al .
In addition , the results also show that our approach is superior to that of Everingham et al .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:2			6:2			3		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0

Alignment 4766
in handling problem caused by partial occlusion and appearance of character in the middle of a shot .
in handling problems caused by partial occlusion and the appearance of a character in the middle of a shot .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			1		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			15:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0

Alignment 4767
All face-tracks which we could not extract exactly are those fully occluded at some frames during their occurences .
The only face tracks that we could not extract exactly are those fully occluded in some frames during their occurrences .
Line2Start:Length	Line1Start:Length	Module		Score
5:1			3:1			0		1.0
6:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
20:1			18:1			0		1.0

Alignment 4768
In those cases , all points in face regions are drifted to background region .
In those cases , all points in the face regions are drifted to the background region .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0

Alignment 4769
Thus , there is no clue to re-group face of that person after such full occlusions .
After such full occlusions , there is no clue to regrouping the face of that person .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			13:1			0		1.0
2:1			14:1			0		1.0
3:1			15:1			0		1.0
4:1			1:1			0		1.0
5:1			2:1			0		1.0
6:1			3:1			0		1.0
7:1			4:1			0		1.0
8:1			5:1			0		1.0
9:1			6:1			0		1.0
12:1			8:1			0		1.0
13:1			9:1			0		1.0
14:1			10:1			0		1.0
15:1			11:1			0		1.0
16:1			16:1			0		1.0

Alignment 4770
To handle this problem , using only tracker is not enough .
, Using only a tracker is not enough to handle this problem .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			4:1			0		1.0
2:1			6:1			0		1.0
4:1			7:1			0		1.0
5:1			8:1			0		1.0
6:1			9:1			0		1.0
7:1			10:1			0		1.0
9:1			1:1			0		1.0
10:1			2:1			0		1.0
11:1			3:1			0		1.0
12:1			11:1			0		1.0

Alignment 4771
One can apply visual information based clustering to group the fragmented face-track , as in \CITE , .
One can apply visual information-based clustering to group the fragmented face track , as in \CITE , but this .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
19:1			17:1			0		1.0

Alignment 4772
Obviously , extra cost is required .
obviously , requires extra cost .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			4:2			3		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			6:1			0		1.0

Alignment 4773
However , we observe that fully occlusion is rarely happened in news video since characters reported in the news are recorded with care , especially with important and well-known character .
Nevertheless , we observe that full occlusion rarely happens in news video because the characters featured in the news are recorded with care , especially the important and well-known ones .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			2		1.0
6:1			6:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			1		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
13:1			17:1			0		1.0
14:1			14:1			0		1.0
16:1			16:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
30:1			30:1			0		1.0

Alignment 4774
This is a special property of news videos .
This is a special characteristic of news videos .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 4775
The last column of the table shows the overall extraction performance of both approaches .
The last column of the table shows the overall extraction performance of both approaches .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 4776
These facts clearly indicate that our approach is robust and outperforms the approach of Everingham et al .
These facts clearly indicate that our approach is robust and outperforms that of Everingham et al .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0

Alignment 4777
in \CITE.
in \CITE.
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0

Alignment 4778
In terms of speed , our approach is approximately 2 times slower than the approach of Everingham .
In terms of speed , our approach is approximately 2 times slower than that of Everingham et al .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
18:1			17:1			0		1.0

Alignment 4779
However , our complexity is somehow linear to total number of face , because we consequently enlarge face-tracks following temporal order by checking new faces with only one last appeared face of each face-track .
However , our complexity is somehow linear to the total number of faces , because we consequently enlarge face tracks according to the temporal order by checking new faces with only the last face that appeared on each face track .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			11:1			0		1.0
23:1			19:1			0		1.0
24:1			20:1			0		1.0
25:1			21:1			0		1.0
26:1			22:1			0		1.0
27:1			23:1			0		1.0
28:1			24:1			0		1.0
29:1			25:1			0		1.0
30:1			26:1			0		1.0
31:2			27:2			3		1.0
33:1			30:1			0		1.0
35:1			29:1			0		1.0
36:2			31:2			3		1.0
40:1			34:1			0		1.0

Alignment 4780
Meanwhile , Everingham et al .
Meanwhile , Everingham et al .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0

Alignment 4781
compare all pairs of faces in the shot .
compared all pairs of faces in the shot .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			1		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 4782
Their complexity is polynomial to the total number of faces .
Their complexity is polynomial to the total number of faces .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 4783
If this number is getting larger , the gap in speed between our approach and the approach by Everingham et al .
If the number of faces increases , the gap in speed between our approach and that by Everingham et al .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			15:1			0		1.0
2:2			2:2			3		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0

Alignment 4784
will be narrowed rapidly.
will narrow rapidly.
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			2:1			1		1.0
2:1			3:1			0		1.0

Alignment 4785
Because all presented problems here , such as those due to flash , occlusion , and in-the-middle face appearance , are practically observed , overcoming them is vital for practical application .
Because all the problems presented here , such as those due to flash , occlusion , and in-the-middle face appearance , are practically observed , overcoming them is vital for the practical application of our approach .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			3:1			0		1.0
4:1			2:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
36:1			31:1			0		1.0

Alignment 4786
In this experiment , we show that our proposed techniques and solutions for the problems are robust and efficient enough for extracting face-tracks in real-world news videos by successfully extracting 94% of all face-tracks .
In this experiment , we show that our proposed techniques and solutions to the problems are robust and efficient enough for extracting face tracks in real-world news videos by successfully extracting 94% of all face tracks .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:2			11:2			3		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0
36:1			34:1			0		1.0

Alignment 4787
From our observations , one can use other complex techniques to handle the problems .
Based on our observations , other complex techniques can be applied to handle the problems .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:2			4:2			3		1.0
10:1			6:1			2		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0

Alignment 4788
However , a trade-o_ between completely obtaining 6% remaining face-tracks and an overly expensive computational cost should be considered with care.
However , the trade-off between obtaining the 6% remaining face tracks and incurring an overly high computational cost should be considered with care.
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
4:1			4:1			0		1.0
5:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
11:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			3		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0

Alignment 4789
Due to the limitations of existing public datasets , we prepare new datasets for experiments .
Due to the limitations of existing public datasets , we prepared new datasets for the experiments .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			1		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0

Alignment 4790
Face-tracks in videos of the datasets are extracted by using our proposed approach for face-track extraction ( see section 4.2 ) .
Face tracks are extracted from videos of the datasets by using our proposed approach to face-track extraction ( see section 4.2 ) .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			6:1			0		1.0
3:1			7:1			0		1.0
5:1			2:1			0		1.0
6:1			3:1			0		1.0
7:1			4:1			0		1.0
8:1			5:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0

Alignment 4791
Identity of the character associated with each extracted face-track is given by annotators .
The identity of the character associated with each extracted face track is given by annotators .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0

Alignment 4792
Since our approach extract face-tracks in each video shot , shot boundaries for videos are required .
Because our approach extracts face tracks in each video shot , the shot boundaries of videos are required .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			1		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0

Alignment 4793
A simple shot boundary detector based on color histogram of frames is used .
A simple shot boundary detector based on a color histogram of frames is used .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0

Alignment 4794
The whole process , including detecting shot boundaries and face-track extraction , is fully automatic.
The whole process , including shot boundary detection and face-track extraction , is fully automated.
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			1		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 4795
TRECVID Dataset .
TRECVID dataset .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			2:1			0		1.0

Alignment 4796
We used the TRECVID news videos from 2004 to 2006 .
We used TRECVID news videos from 2004 to 2006 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0

Alignment 4797
This dataset contains 370 hours of videos in different languages , such as English , Chinese , and Arabic .
This dataset contains 370 hours of videos in different languages , such as English , Chinese , and Arabic .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 4798
The total number of frames that we processed was approximately 35 millions frames .
The total number of frames that we processed was approximately 35 million .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			1		1.0
12:1			13:1			0		1.0

Alignment 4799
Among those , 20 millions faces were grouped into 157,524 face tracks .
Among those , 20 million faces were grouped into 157,524 face tracks .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			1		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 4800
We filtered out short face tracks that had less than ten faces , .
We filtered out short face tracks that had less than 10 faces , which .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			2		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
14:1			13:1			0		1.0

Alignment 4801
This resulted in 35,836 face tracks .
resulted in 35,836 face tracks .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			1:1			0		1.0
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0

Alignment 4802
Finally , we annotated 1,497 face tracks containing 405,887 faces of 41 well known individual characters .
Finally , we annotated 1,497 face tracks containing 405,887 faces of 41 well-known individual characters .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0

Alignment 4803
NHKNews7 Dataset .
NHKNews7 dataset .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			2:1			0		1.0

Alignment 4804
This dataset is observed from NHKNews7 channel in 11 years .
This dataset consists of observations from the NHK News 7 program over 11 years .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:2			2:1			3		1.0
4:1			3:1			1		1.0
5:1			4:1			0		1.0
12:1			8:1			0		1.0
13:1			9:1			0		1.0
14:1			10:1			0		1.0

Alignment 4805
After the annotation process , 1,259,320 faces of 111 individuals are provided .
After the annotation process , 1,259,320 faces of 111 individuals are provided .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 4806
The total number of face-tracks is 5,567 .
The total number of face tracks is 5,567 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0

Alignment 4807
Each character has from 4 to 550 face-tracks .
Each character has from 4 to 550 face tracks .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
9:1			8:1			0		1.0

Alignment 4808
In this dataset , we discard facetracks with fewer than 100 faces and more than 500 faces .
In this dataset , we discard face tracks with fewer than 100 faces and more than 500 faces .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0

Alignment 4809
Compared to the TRECVID dataset , NHKNews7 dataset is much more challenging.
Compared to the TRECVID dataset , the NHKNews7 dataset is much more challenging.
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0

Alignment 4810
In the Table 4 , we compare our datasets with some public benchmark datasets .
Table 4 shows a , comparison between our datasets and some public benchmark datasets .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			2:1			0		1.0
1:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:2			3		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 4811
, It is obvious that our datasets are extremely higher than datasets , such as MoBo and Honda / UCSD , on all statistical terms , including the number of videos , characters , and average length of face-track .
Based on the results , it is obvious that our datasets are superior over the other datasets , such as MoBo and Honda / UCSD , on all statistical terms , including number of videos , number of characters , and average face-track length .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			21:1			0		1.0
2:1			27:1			0		1.0
4:1			0:1			0		1.0
6:1			2:1			0		1.0
7:1			3:1			0		1.0
8:1			4:1			0		1.0
9:1			5:1			0		1.0
10:1			6:1			0		1.0
11:1			7:1			0		1.0
16:1			11:1			0		1.0
17:1			12:1			0		1.0
18:1			13:1			0		1.0
19:1			14:1			0		1.0
20:1			15:1			0		1.0
21:1			16:1			0		1.0
22:1			17:1			0		1.0
23:1			18:1			0		1.0
24:1			19:1			0		1.0
25:1			20:1			0		1.0
27:1			22:1			0		1.0
28:1			23:1			0		1.0
29:1			24:1			0		1.0
30:1			25:1			0		1.0
31:1			26:1			0		1.0
32:1			28:1			0		1.0
33:1			29:1			0		1.0
34:1			30:1			0		1.0
35:1			31:1			0		1.0
37:1			37:1			0		1.0
38:1			32:1			0		1.0
39:1			33:1			0		1.0
40:1			34:1			0		1.0
41:1			35:1			0		1.0
42:1			38:1			0		1.0
43:1			36:1			0		1.0
44:1			39:1			0		1.0

Alignment 4812
Compared to Youtube Faces dataset , although ours have less number of character ( or subjects ) , we provide much more face-tracks ( or video shots ) per character , .
Compared to the YouTube Faces dataset , , we provide much more face tracks ( or video shots ) per character , although our datasets have smaller numbers of characters ( or subjects ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			17:1			0		1.0
8:1			18:1			0		1.0
9:1			19:1			0		1.0
10:1			20:1			0		1.0
11:1			21:1			0		1.0
14:1			23:1			0		1.0
15:1			24:1			0		1.0
16:1			25:1			0		1.0
17:1			26:1			0		1.0
18:1			27:1			0		1.0
19:1			28:1			0		1.0
20:1			29:1			0		1.0
21:1			30:1			0		1.0
22:1			6:1			0		1.0
23:1			7:1			1		1.0
25:1			8:1			0		1.0
27:2			10:2			3		1.0
29:1			12:1			1		1.0
30:1			13:1			0		1.0
31:1			14:1			0		1.0
32:1			15:1			0		1.0
33:1			16:1			0		1.0
34:1			31:1			0		1.0

Alignment 4813
Thus , ours are more relevant for evaluating retrieval system.
Thus , our datasets are more relevant in evaluating a face retrieval system.
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			1		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
8:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0

Alignment 4814
Statistical information of our datasets is given in the Figure 5 .
Figure 5 presents statistical information on our datasets .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			9:1			0		1.0
1:1			10:1			0		1.0
4:1			1:1			0		1.0
6:1			3:1			0		1.0
7:1			4:1			0		1.0
8:1			11:1			0		1.0

Alignment 4815
The datasets can be downloaded at http: / / satohlab .
The datasets can be downloaded from http: / / satohlab .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 4816
ex.nii.ac.jp / users / ndthanh / NIIFacetrackDatasets .
ex.nii.ac.jp / users / ndthanh / NIIFacetrackDatasets .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 4817
However , due to copyright issues , face images in face-tracks can not be published .
However , due to copyright issues , the face images in the face tracks cannot be published .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
14:1			11:2			3		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0

Alignment 4818
Instead , we provide a feature vector , used in \CITE , for each face image .
Instead , we provide a feature vector , used in \CITE , for each face image .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 4819
A feature vector of a face is extracted by computing descriptors of the local appearance of the face around each of the located facial features .
The feature vector of a face is extracted by computing the descriptors of the local appearance of the face around each of the located facial features .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			21:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0

Alignment 4820
Before extracting descriptors , the face is geometrically normalized to reduce the effect of pose variation .
Before extracting the descriptors , the face is geometrically normalized to reduce the effect of pose variation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0

Alignment 4821
They estimate an affine transformation , which transform the located facial feature points to a canonical set of feature positions .
An affine transformation is estimated , which transforms the located facial feature points to a canonical set of feature positions .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			3:1			0		1.0
2:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			1		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 4822
Then , appearance descriptors are computed around each facial feature .
Then , the appearance descriptors around each facial feature are computed .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			4:1			0		1.0
10:1			5:1			0		1.0
11:1			10:1			0		1.0

Alignment 4823
The final feature representation of the face is formed by concatenating all descriptors of its facial features.
The final feature representation of the face is formed by concatenating all the descriptors of its facial features.
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0

Alignment 4824
We compare k-Faces with several approaches , including approaches based on pair-wise distances , MSM \CITE and CMSM \CITE.
We compared k-Faces with several approaches , including those based on pair-wise distances , MSM \CITE and CMSM \CITE.
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			1		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 4825
Given two face-tracks having multiple face images represented as feature vectors , pair-wise based approaches compute distances between each possible pair of feature vectors in two face-tracks .
Given two face tracks having multiple face images represented as feature vectors , pair-wise-based approaches compute the distances between each possible pair of feature vectors in two face tracks .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
29:1			27:1			0		1.0

Alignment 4826
They then use the maximum distance , the minimum distance , or the mean distance of the computed pair-wise distances as the similarity measurement between two face-tracks .
The maximum distance , the minimum distance , or the mean distance of the computed pair-wise distances is the used as the similarity measurement between two face tracks .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			4:1			0		1.0
2:1			5:1			0		1.0
3:1			6:1			0		1.0
4:1			7:1			0		1.0
5:1			8:1			0		1.0
6:1			9:1			0		1.0
7:1			10:1			0		1.0
8:1			11:1			0		1.0
9:1			12:1			0		1.0
10:1			13:1			0		1.0
11:1			14:1			0		1.0
12:1			15:1			0		1.0
13:1			16:1			0		1.0
14:1			17:1			0		1.0
15:1			18:1			0		1.0
16:1			19:1			0		1.0
18:1			3:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
28:1			27:1			0		1.0

Alignment 4827
We denote the approaches as pair:max , pair:min , and pair:mean , respectively ( see Figure 6 for illustration ) .
We refer to the approaches as pair:max , pair:min , and pair:mean , respectively ( see Figure 6 for the illustration ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			2		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0

Alignment 4828
The pair:min ( sometimes called min-min ) is a state-of-the-art approach widely used in other studies \CITE.
The pair:min ( sometimes called min-min ) is a state-of-the-art approach widely used in other studies \CITE.
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 4829
Regarding to \CITE , if the pair-wise based approaches are representative for non-parametric sampled based approaches , MSM and CMSM are representative for approaches based on parametric model .
Regarding \CITE , if the pair-wise-based approaches are representative of nonparametric sample-based approaches , MSM and CMSM are representative of approaches based on a parametric model .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
12:1			15:1			0		1.0
13:1			16:1			0		1.0
14:1			17:1			0		1.0
15:1			18:1			0		1.0
16:1			19:1			0		1.0
17:1			20:1			0		1.0
18:2			21:2			3		1.0
20:1			23:1			0		1.0
21:1			24:1			0		1.0
22:1			25:1			0		1.0
24:1			26:1			0		1.0
25:1			27:1			0		1.0
26:1			28:1			0		1.0

Alignment 4830
MSM , introduced by Yamaguchi et al .
MSM , introduced by Yamaguchi et al .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 4831
The similarity between the sets is computed using the angle between subspaces .
The similarity between the sets is computed using the angle between subspaces .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 4832
CMSM is an extension of MSM , in which subspaces of the sets are projected on a constraint subspace .
CMSM is an extension of MSM , in which subspaces of the sets are projected onto a constraint subspace .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 4833
By doing that , the subspaces are expected to be better separatable .
In doing so , the subspaces are expected to be more separable .
Line2Start:Length	Line1Start:Length	Module		Score
1:2			1:2			3		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:2			9:2			3		1.0
12:1			12:1			0		1.0

Alignment 4834
All of these approaches had been shown their robustness on benchmark datasets , such as MoBo , HondaUCSD , and Youtube Faces .
All of these approaches have shown their robustness in benchmark datasets , such as MoBo , HondaUCSD , and YouTube Faces .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:2			3		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0

Alignment 4835
Therefore , it is appealing to compare our k-Faces with them for a comprehensive evaluation.
Therefore , it is appealing to compare our k-Faces with them for a comprehensive evaluation.
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 4836
Besides evaluating k-Faces with different values of k as well as different types of distance ( e.g. , Euclidean , L1 , cosine ) , we try another criterion to select k representative faces in a face-track .
Besides evaluating k-Faces with different values of k and different types of distance ( e.g. , Euclidean , L1 , and cosine ) , we try another criterion for selecting k representative faces in a face track .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:2			29:2			3		1.0
30:1			31:1			0		1.0
31:1			32:1			0		1.0
32:1			33:1			0		1.0
33:1			34:1			0		1.0
34:1			35:1			0		1.0
37:1			37:1			0		1.0

Alignment 4837
In the original way , we proposed to select these faces by partitioning the face-track following temporal order and selecting the middle face of each partition .
In the original way , we proposed selecting these faces by partitioning the face track according to the temporal order and choosing the middle face of each partition .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			19:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
16:1			7:1			0		1.0
17:1			20:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			8:1			2		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0

Alignment 4838
However , an yet another criterion can be applied to select these representative faces is based on clustering .
However , another criterion that is based on clustering can be applied in selecting these representative faces .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			4:1			0		1.0
3:1			5:1			0		1.0
5:1			14:1			0		1.0
6:1			15:1			0		1.0
7:1			16:1			0		1.0
8:1			17:1			0		1.0
9:1			6:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
12:2			9:2			3		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			18:1			0		1.0

Alignment 4839
In this new way , all faces in a face-track will be clustered in to k groups by a clustering algorithm .
In this new way , all the faces in a face track will be clustered to k groups by using a clustering algorithm .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0

Alignment 4840
The centroid of each group is selected .
The centroid of each group is selected .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 4841
Then , the mean of k centroids is used as the representative face for the face-track .
Then , the mean of k centroids is used as the representative face for the face track .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
17:1			16:1			0		1.0

Alignment 4842
In this experiment , we use the standard K-Means for clustering .
In this experiment , we use the standard K-Means for clustering .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 4843
We denote the former k-Faces as k-Faces.Temporal and the latter k-Faces as k-Faces.KMeans.
We refer to the former k-Faces as k-Faces.Temporal and to the latter k-Faces as k-Faces.KMeans.
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			2		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0

Alignment 4844
We evaluate performance of a face-track matching approach by computing the average precision on the rank list returned by the approach .
We evaluate the performance of a face-track matching approach by computing the average precision of the rank list that it returned .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			19:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			21:1			0		1.0

Alignment 4845
In particular , for each dataset , each face-track is alternatively picked out as a query facetrack , while the remaining face-tracks are used as the retrieved database .
In particular , in each dataset , a face track is alternatively picked out as a query face track , while the remaining face tracks are used as the retrieved database .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:2			3:2			3		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			14:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
16:1			15:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
25:1			22:1			0		1.0
26:1			23:1			0		1.0
27:1			24:1			0		1.0
28:1			25:1			0		1.0
29:1			26:1			0		1.0
30:1			27:1			0		1.0
31:1			28:1			0		1.0

Alignment 4846
, Average precision of the returned ranked list is computed , given a query .
Given a query , the average precision of the returned ranked list is computed , .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			12:1			0		1.0
2:1			13:1			0		1.0
3:1			0:1			0		1.0
6:1			2:1			0		1.0
7:1			3:1			0		1.0
8:1			4:1			0		1.0
9:1			5:1			0		1.0
10:1			6:1			0		1.0
11:1			7:1			0		1.0
12:1			8:1			0		1.0
13:1			9:1			0		1.0
14:1			10:1			0		1.0
15:1			14:1			0		1.0

Alignment 4847
Finally , the mean of all average precision ( MAP ) from all query is reported as the overall evaluation metric for the approach on the database.
Finally , the mean of all average precision ( MAP ) values for all queries is reported as the overall evaluation metric for the approach with the given database.
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			21:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			1		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
26:1			25:1			0		1.0
28:1			26:1			0		1.0

Alignment 4848
Let denote r as a rank in the returned face-track list , Pre( r ) as is the precision at the rank r of the list , Nl as the length of the list , Nhit as the total number of face-tracks matched with the query face-track q , and I sMatched( k ) as a binary function returning 1 if the face-track at rank r is matched with q ( based on ground-truth annotations ) , zero otherwise .
Let r denote a rank in the returned face-track list , Pre( r ) the precision at rank r of the list , Nl the length of the list , Nhit the total number of face tracks matched with the query face track q , and I sMatched( k ) a binary function returning 1 if the face track at rank r is matched with q ( based on ground-truth annotations ) and , zero otherwise .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			2:1			0		1.0
2:1			1:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			17:1			0		1.0
15:1			18:1			0		1.0
16:1			19:1			0		1.0
17:1			21:1			0		1.0
18:1			22:1			0		1.0
19:1			23:1			0		1.0
20:1			24:1			0		1.0
21:1			25:1			0		1.0
22:1			26:1			0		1.0
23:1			27:1			0		1.0
24:1			29:1			0		1.0
25:1			30:1			0		1.0
26:1			31:1			0		1.0
27:1			32:1			0		1.0
28:1			33:1			0		1.0
29:1			34:1			0		1.0
30:1			35:1			0		1.0
31:1			37:1			0		1.0
32:1			38:1			0		1.0
33:1			39:1			0		1.0
34:1			40:1			0		1.0
37:1			42:1			0		1.0
38:1			43:1			0		1.0
39:1			44:1			0		1.0
40:1			45:1			0		1.0
43:1			47:1			0		1.0
44:1			48:1			0		1.0
45:1			49:1			0		1.0
46:1			50:1			0		1.0
47:1			51:1			0		1.0
48:1			52:1			0		1.0
49:1			53:1			0		1.0
50:1			55:1			0		1.0
51:1			56:1			0		1.0
52:1			57:1			0		1.0
53:1			58:1			0		1.0
54:1			59:1			0		1.0
55:1			60:1			0		1.0
56:1			61:1			0		1.0
59:1			63:1			0		1.0
60:1			64:1			0		1.0
61:1			65:1			0		1.0
62:1			66:1			0		1.0
63:1			67:1			0		1.0
64:1			68:1			0		1.0
65:1			69:1			0		1.0
66:1			70:1			0		1.0
67:1			71:1			0		1.0
68:1			72:1			0		1.0
69:1			73:1			0		1.0
70:1			74:1			0		1.0
71:1			75:1			0		1.0
73:1			76:1			0		1.0
74:1			77:1			0		1.0
75:1			78:1			0		1.0
76:1			79:1			0		1.0

Alignment 4849
Then , the MAP of the evaluated approach can be computed as following: \MATH
Then , the MAP of the evaluated approach can be computed as follows: \MATH
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
13:1			13:1			0		1.0

Alignment 4850
MAP is a standard metric to evaluate retrieval and matching systems .
The MAP is a standard metric for evaluating retrieval and matching systems .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			0:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:2			5:2			3		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0

Alignment 4851
Besides MAP , we record processing times of the approaches on each dataset for efficiency comparison.
Besides the MAP , we record the processing times of the approaches in each dataset to compare their efficiency.
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:2			10:2			3		1.0
14:1			12:1			0		1.0

Alignment 4852
Figure 7 presents Mean Average Precision ( MAP ) of all evaluated approaches on our two datasets , Trecvid and NHKNews7 .
Figure 7 presents the mean average precision ( MAP ) of all the evaluated approaches in our two datasets , Trecvid and NHKNews7 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
13:1			11:1			0		1.0
14:2			12:2			3		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0

Alignment 4853
Generally , all MAPs vary from 64.61% to 76.54% on Trecvid dataset .
Generally , all the MAPs vary from 64.61% to 76.54% in the Trecvid dataset .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0

Alignment 4854
Meanwhile , , the best MAP is 60.99% , and the worst MAP is 42.75% on NHKNews7 dataset .
Meanwhile , in the NHKNews7 dataset , the best MAP is 60.99% , and the worst is 42.75% .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			10:1			0		1.0
4:1			16:1			0		1.0
5:1			17:1			0		1.0
6:1			2:1			0		1.0
7:1			3:1			0		1.0
8:1			4:1			0		1.0
9:1			5:1			0		1.0
10:1			6:1			0		1.0
11:1			7:1			0		1.0
12:1			8:1			0		1.0
13:1			9:1			0		1.0
15:1			11:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			18:1			0		1.0

Alignment 4855
The gap of MAPs between two datasets can be explained by following reasons .
The difference in the MAPs between the two datasets can be explained by following reasons .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:3			1:1			3		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0

Alignment 4856
Firstly , the number of characters in NHKNews7 is more larger than those in Trecvid , 111 characters in NHKNews7 compared to 41 characters in Trecvid .
First , the number of characters in NHKNews7 is larger than that in Trecvid , 111 characters in NHKNews7 compared to 41 characters in Trecvid .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			1		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0

Alignment 4857
This clearly increases the probability of mismatching face-tracks .
This clearly increases the probability of mismatching face tracks .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
9:1			8:1			0		1.0

Alignment 4858
Secondly , videos in NHKNews7 are recorded during a long time ( i.e. , 11 years ) .
Second , the videos in NHKNews7 were recorded over a long time ( i.e. , 11 years ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			1		1.0
1:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			2		1.0
7:1			6:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0

Alignment 4859
Thus , besides facial variations caused by enviromental conditions at the time of recording ( e.g. , illumination , pose , viewpoint ) in each face-track , face-tracks of a character themself also contain biological variation of the character during time .
Thus , besides facial variations in each face track caused by the environmental conditions at the time of recording ( e.g. , illumination , pose , viewpoint ) , the face tracks of the character themselves also reflect the biological variations of the character over time; .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			23:1			0		1.0
6:1			24:1			0		1.0
9:1			5:1			0		1.0
10:1			6:1			0		1.0
11:1			37:1			0		1.0
13:1			8:1			0		1.0
14:1			9:1			0		1.0
15:1			10:1			0		1.0
16:1			11:1			0		1.0
17:1			12:1			0		1.0
18:1			13:1			0		1.0
19:1			14:1			0		1.0
20:1			15:1			0		1.0
21:1			16:1			0		1.0
22:1			17:1			0		1.0
23:1			18:1			0		1.0
24:1			19:1			0		1.0
25:1			20:1			0		1.0
26:1			21:1			0		1.0
27:1			22:1			0		1.0
28:1			26:1			0		1.0
32:1			28:1			0		1.0
34:1			30:1			0		1.0
36:1			32:1			0		1.0
39:1			34:1			0		1.0
40:1			35:1			1		1.0
41:1			36:1			0		1.0
43:1			38:1			0		1.0
46:1			41:1			0		1.0

Alignment 4860
For instance , a character may look older after several years ( see Figure 8 , for example ) .
for instance , a character may look older after several years ( see Figure 8 , for example ) .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 4861
Due to those reasons , matching faces in NHKNews7 becomes more challenging , .
For these reasons , matching faces in NHKNews7 becomes more challenging , which .
Line2Start:Length	Line1Start:Length	Module		Score
1:2			2:2			3		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 4862
It results in drops of MAP( s ) of all evaluated approaches.
resulted in decreased MAP( s ) for all the evaluated approaches.
Line2Start:Length	Line1Start:Length	Module		Score
0:1			1:1			1		1.0
1:1			2:1			0		1.0
3:1			5:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
7:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0

Alignment 4863
A clear and consistent observation from both datasets is that pair:min ( i.e. , min-min ) always achieves the best MAPs , which are 76.54% and 60.99% on two dataset , respectively .
A clear and consistent observation from both datasets is that pair:min ( i.e. , min-min ) always achieves the best MAPs , which are 76.54% and 60.99% in the two datasets , respectively .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			1		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0

Alignment 4864
Among several distance types , L1 is the optimal one to be used with pair:min .
Among the distance types , L1 is the optimal for use with pair:min .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:2			10:3			3		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0

Alignment 4865
A reasonable replacement can be Euclidean distance .
A reasonable replacement is the Euclidean distance .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:2			3		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 4866
However , there is a minor accuracy gap between pair:min using L1 and pair:min using Euclidean .
However , there is a minor accuracy gap between pair:min using L1 and pair:min using the Euclidean distance .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
16:1			15:1			0		1.0
18:1			16:1			0		1.0

Alignment 4867
And , computing Euclidean distance between two feature vectors is more expensive than computing their L1 distance .
In addition , computing the Euclidean distance between two feature vectors is more expensive than computing their L1 distance .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
5:1			3:1			0		1.0
6:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0

Alignment 4868
The results also show that pair:min is better than pair:mean .
The results also show that pair:min is better than pair:mean .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 4869
This is because pair:mean uses the mean of all pair-wise distances between two face-tracks as their similarity score .
This is because pair:mean uses the mean of all pair-wise distances between two face tracks as the similarity score .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
15:1			14:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0

Alignment 4870
By computing the mean , pair:mean reduces the effect of noisy pairs .
By computing the mean , pair:mean reduces the effect of noisy pairs .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 4871
At the same time , it eliminates the influence of pairs containing identical faces , which can help to instantly determine they are belong to the same character .
At the same time , it eliminates the influence of pairs containing identical faces , which can help to instantly determine that the faces belong to the same character .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
22:1			25:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0

Alignment 4872
Thus , discriminative power of the computed similarity score is reduced , compared to one computed by pair:min .
Thus , the discriminative power of the computed similarity score is reduced , compared to that computed by pair:min .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0

Alignment 4873
It causes the gap of MAPs between pair:min and pair:min .
This causes the difference in MAPs between pair:min and pair:min .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:2			3:1			3		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 4874
More generally , this explains why such a gap between pair:min and pair:mean on NHKNews7 is larger than on Trecvid .
More generally , this explains why such a gap between pair:min and pair:mean is larger in NHKNews7 than in Trecvid .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
16:1			14:1			0		1.0
17:1			17:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 4875
Since the average length of face-tracks on NHKNews7 is longer ( i.e. , each face-track contains more sample faces of a character ) , there is more chance that two face-tracks of the same character contain identical faces.
Because the average length of face tracks on NHKNews7 is longer ( i.e. , each face track contains more sample faces of a character ) , there is a greater chance that two face tracks of the same character contain identical faces.
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:3			25:2			3		1.0
30:1			27:1			0		1.0
31:1			28:1			0		1.0
32:1			29:1			0		1.0
35:1			31:1			0		1.0
36:1			32:1			0		1.0
37:1			33:1			0		1.0
38:1			34:1			0		1.0
39:1			35:1			0		1.0
40:1			36:1			0		1.0
41:1			37:1			0		1.0

Alignment 4876
About our k-Faces , its MAP increases when k increases .
Regarding our k-Faces , its MAP increases when k increases .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 4877
Between k-Faces.Temporal and k-Faces.KMeans , the impact of k on MAP of k-Faces.KMeans is less significant .
Between k-Faces.Temporal and k-Faces.KMeans , the impact of k on the MAP of k-Faces.KMeans is less significant .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0

Alignment 4878
Since k-Faces.KMeans always use all faces in a facetrack for clustering and selecting centroids for representative faces , the final mean face is less sensitive to k .
Because k-Faces.KMeans always uses all the faces in a face track for clustering and selecting centroids for representative faces , the final mean face is less sensitive to k .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			1		1.0
4:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			21:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0

Alignment 4879
On the contrary , k plays an important role in k-Faces.Temporal .
In contrast , k plays an important role in k-Faces.Temporal .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:2			3		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0

Alignment 4880
The higher k is set , the more representative faces of each facetrack are selected .
The higher the k set , the more representative faces of each face track selected .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 4881
Thus , the final mean face of each facetrack becomes more reliable and accurate .
Thus , the final mean face of each face track becomes more reliable and accurate .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0

Alignment 4882
The advantages of k-Faces.KMeans is that it can achieve high accuracy even when k is very small .
The advantages of k-Faces.KMeans is that it can achieve high accuracy even when k is very small .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 4883
Meanwhile , its disadvantage is the expensive computational cost to perform clustering faces on a high dimensional feature space ( i.e. , 1937 dimensions ) .
However , its disadvantage is the high computational cost of clustering faces on a high-dimensional feature space ( i.e. , 1,937 dimensions ) .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			15:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0

Alignment 4884
When k is large enough , there is no substantial difference in MAP between k-Faces.KMeans and k-Faces.Temporal.
When k is large enough , there is no substantial difference in MAP between k-Faces.KMeans and k-Faces.Temporal.
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 4885
On both datasets , when k increases from 2 to 20 , MAPs of k-Faces approaches grow rapidly .
In both datasets , when k increases from 2 to 20 , the MAPs of k-Faces approaches grow rapidly .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0

Alignment 4886
However , theirs MAPs become stable from 20 afterwards .
However , the MAPs become stable from k = 20 upward .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
9:1			7:1			0		1.0
11:1			9:1			0		1.0

Alignment 4887
Since keep increasing k does not help to obtain imporant accuracy improvement but expensive computational cost , we select k = 20 to investigate the trade-off between accuracy and computational costs of k-Faces approaches compared to others .
Because further increasing k does not help improve accuracy but increases the computational cost , we select k = 20 for investigating the trade-off between the accuracy and computational cost of k-Faces approaches in comparison to others .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			10:1			0		1.0
9:1			12:1			0		1.0
11:1			24:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0
21:2			23:1			3		1.0
23:1			25:1			0		1.0
24:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:2			30:2			3		1.0
31:1			32:1			0		1.0
32:1			33:1			0		1.0
33:3			34:2			3		1.0
36:1			36:1			0		1.0
37:1			37:1			0		1.0

Alignment 4888
We report MAP and processing time of each approach in the Table 5 .
Table 5 shows the MAP and processing time of each approach .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			11:1			0		1.0
1:1			12:1			0		1.0
3:1			10:1			0		1.0
4:1			2:1			0		1.0
5:1			3:1			0		1.0
6:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			13:1			0		1.0

Alignment 4889
Processing time is separated into two parts , corresponding to preprocessing time and matching time .
Processing time is divided into two parts , preprocessing and matching .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			2		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			10:1			0		1.0
9:1			12:1			0		1.0
10:1			13:1			0		1.0
11:1			15:1			0		1.0

Alignment 4890
Preprocessing time presents time required for preprocessing face-tracks before matching .
The preprocessing time refers to the time required to preprocess face tracks before matching .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			6:1			0		1.0
2:1			1:1			0		1.0
6:1			3:1			0		1.0
7:1			4:1			0		1.0
10:1			2:1			2		1.0
12:1			8:1			0		1.0
13:1			9:1			0		1.0
14:1			10:1			0		1.0

Alignment 4891
With k-Faces approaches , preprocessing facetracks includes selecting representative faces and computing their mean face .
In k-Faces approaches , the preprocessing of face tracks includes selecting representative faces and computing their mean face .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
9:1			6:1			0		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0

Alignment 4892
In MSM and CMSM , it indicates time for computing subspaces for face-tracks .
In MSM and CMSM , preprocessing includes computing subspaces for face tracks .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
12:1			13:1			0		1.0

Alignment 4893
Matching time is averaged for one query run .
The matching time is averaged over one query run .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0

Alignment 4894
Time unit is second.
The time unit used is seconds.
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
4:1			2:1			0		1.0

Alignment 4895
According to Table 5 , k-Faces.KMeans and k- Faces.Temporal achieve almost equal accuracy and consume the same amount of time for one query on both datasets .
As shown in Table 5 , k-Faces.KMeans and k- Faces.Temporal achieve almost equal accuracy and consume the same amount of time for one query in both datasets .
Line2Start:Length	Line1Start:Length	Module		Score
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:2			23:2			3		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0

Alignment 4896
However , k-Faces.Temporal is hundreds times ( 240 times on Trecvid and 360 times on NHKNews7 ) faster than k-Faces.Temporal in the preprocessing phase .
However , k-Faces.Temporal is hundreds of times ( 240 times in Trecvid and 360 times in NHKNews7 ) faster than k-Faces.Temporal in the preprocessing phase .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0

Alignment 4897
This suggest that , selecting presentative faces based on tempo .
This suggests that in terms of both accuracy and efficiency , selecting representative faces based on temporal sampling is better than that based on clustering .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:3			1:2			3		1.0
10:1			3:1			0		1.0
11:1			4:1			0		1.0
13:1			6:1			0		1.0
14:1			7:1			0		1.0
15:1			8:1			0		1.0
25:1			10:1			0		1.0

Alignment 4898
ral sampling is better than one based on clustering , in both terms of accuracy and efficiency.
,
Line2Start:Length	Line1Start:Length	Module		Score
0:1			9:1			0		1.0

Alignment 4899
Compared to state-of-the-art approaches , our k- Faces.Temporal is thousands times faster than the best approach , which is pair:min , and hundred times faster than MSM and CMSM on both datasets .
Compared to state-of-the-art approaches , our k- Faces.Temporal is thousands of times faster than the best approach , which is pair:min , and hundreds of times faster than MSM and CMSM in both datasets .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:2			22:1			3		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:2			29:2			3		1.0
33:1			31:1			0		1.0
34:1			32:1			0		1.0

Alignment 4900
In terms of accuracy , k-Faces take second place , with 73.65% on Trevid dataset , after pair:min .
In terms of accuracy , k-Faces takes second place , with 73.65% in the Trevid dataset , after pair:min .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			1		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0

Alignment 4901
The gap with pair:min is 2.89% difference in MAP .
The difference in MAP between our approach and pair:min is 2.89% .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			6:1			0		1.0
2:1			7:1			0		1.0
3:1			8:1			0		1.0
8:1			3:1			0		1.0
9:1			4:1			0		1.0
10:1			5:1			0		1.0
11:1			9:1			0		1.0

Alignment 4902
Meanwhile , it is significantly better than MSM and CMSM , which respectively achieve 69.20% and 64.62% .
Meanwhile , k- Faces.Temporal is significantly better than MSM and CMSM , which respectively achieved 69.20% and 64.62% accuracy .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			1		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
19:1			17:1			0		1.0

Alignment 4903
On NHKNews7 dataset , our k-Faces.Temporal is still better than CMSM , but is worse than pair:min and MSM .
In the NHKNews7 dataset , k-Faces.Temporal is better than CMSM , but worse than pair:min and MSM .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0

Alignment 4904
One may concern that why MSM perform poorly on Trecvid dataset , but it is superior to our k-Faces.Temporal on NHKNews7 .
One may question why MSM performed poorly in the Trecvid dataset , but was superior to k-Faces.Temporal in NHKNews7 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			1		1.0
6:1			7:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			14:1			2		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			18:1			0		1.0
18:1			20:1			0		1.0
19:1			21:1			0		1.0

Alignment 4905
This is due to the fact that face-tracks on NHKNews7 dataset is larger than those on Trecvid dataset .
The reason for this is the fact that the face tracks in the NHKNews7 dataset are larger than those in the Trecvid dataset .
Line2Start:Length	Line1Start:Length	Module		Score
1:5			1:4			3		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
13:1			9:1			0		1.0
14:1			10:1			0		1.0
15:1			11:1			2		1.0
16:1			12:1			0		1.0
17:1			13:1			0		1.0
18:1			14:1			0		1.0
21:1			16:1			0		1.0
22:1			17:1			0		1.0
23:1			18:1			0		1.0

Alignment 4906
Therefore , more sample faces in each face-track can be used to obtain a reliable subspace .
Therefore , more sample faces in each face track can be used to obtain a reliable subspace .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0

Alignment 4907
As expected , the results in this experiment demonstrate that our proposed approach is extremely efficient while archiving comparable performance with state-of-the-art approaches�f.
As expected , the results of this experiment show that our proposed approach is extremely efficient while achieving comparable performance with state-of-the-art approaches .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:2			8:2			3		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 4908
In this paper , we investigate face retrieval on large-scale news video datasets .
In this paper , we investigate face retrieval in large-scale news video datasets .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 4909
Our contributions is 3-fold .
Our contribution is threefold .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			1		1.0
2:1			2:1			0		1.0
4:1			4:1			0		1.0

Alignment 4910
Firstly , we presented practical problems when a tracker is used to extract face-tracks in news videos .
First , we present the practical problems encountered when a tracker is used to extract face tracks in news videos .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			1		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			1		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0

Alignment 4911
Based on that , we introduce techniques and solutions to bypass the problems for robust face-track extraction .
Based on these , we introduce techniques and solutions to overcome these problems to achieve robust face-track extraction .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
12:2			12:2			3		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0

Alignment 4912
Secondly , we present an approach for face-track matching which significantly reduces the computational cost and achive competitive performance compared to state-of-the-art approaches .
Second , we present an approach for face-track matching that significantly reduces the computational cost while achieving competitive performance compared with state-of-the-art approaches .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			1		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:2			19:2			3		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 4913
Thirdly , we prepare , evaluate state-of-the-art face retreival approaches , and publish real-world face-track datasets whose scale have not been considered in literature ever.
Third , we prepare datasets , evaluate state-of-the-art face retrieval approaches , and publish real-world face-track datasets of such scales that have never been considered in the literature.
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			1		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			3		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0

Alignment 4914
Recommend-Me : recommending query regions for image search
Recommend-Me : recommending query regions for image search
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 4915
This paper presents a novel recommendation system , named Recommend-Me , to faciliate users in searching and exploring images of an unknown image database .
This paper presents a novel recommendation system , named Recommend-Me , to facilitate users in searching and exploring images in unknown image databases .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			1		1.0
23:1			24:1			0		1.0

Alignment 4916
Given an initial query image , Recommend-Me automatically introduces its recommendations to users .
Given an initial query image , Recommend-Me automatically shows its recommendations to users .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 4917
The recommendations indicate which and how frequent items in the initial query image occur in the database .
The recommendations indicate which and how frequent items in the initial query image occur in the database .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 4918
So that , users can make their own decisions before any actual search .
In this way , users can make their own decisions before any actual search .
Line2Start:Length	Line1Start:Length	Module		Score
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0

Alignment 4919
If there is a recommendation matched their search intention , relevant search results are ensured .
If there is a recommendation matching their search intention , relevant search results are ensured .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			1		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 4920
Otherwise , users should refine their initial query image for a better query sample .
Otherwise , users should refine their initial query image for a better query sample .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 4921
Or , they can start exploring the database by using the recommended items as hints .
Or , they can start exploring the database by using the recommended items as hints .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 4922
Recommend-Me helps users to avoid unnecessary trials and poor searching experiences .
Recommend-Me helps users to avoid unnecessary trials and poor searching experiences .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 4923
We introduce an efficient approach for Recommend-Me to deal with quantifying occurences of multiple candidate items over images of the database .
We describe an efficient approach for Recommend-Me to deal with quantifying occurrences of multiple candidate items in the images of the database .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0

Alignment 4924
Instead of scanning the database for each candidate item repspectively , the approach enumerate occurences of multiple candidate items simultaneously by investigating pairs of highly similar regions , knowing one pair is formed by a region in the intial image and a region in an image of the database .
Instead of scanning the database for each candidate item , the approach enumerate occurrences of multiple candidate items simultaneously by investigating pairs of highly similar regions , knowing one pair is formed by a region in the initial image and a region in an image of the database .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0
31:1			32:1			0		1.0
32:1			33:1			0		1.0
33:1			34:1			0		1.0
34:1			35:1			0		1.0
35:1			36:1			0		1.0
36:1			37:1			0		1.0
38:1			39:1			0		1.0
39:1			40:1			0		1.0
40:1			41:1			0		1.0
41:1			42:1			0		1.0
42:1			43:1			0		1.0
43:1			44:1			0		1.0
44:1			45:1			0		1.0
45:1			46:1			0		1.0
46:1			47:1			0		1.0
47:1			48:1			0		1.0
48:1			49:1			0		1.0

Alignment 4925
We formulate the problem of finding such pairs as an opmization problem , which can be solved by a branch-and-bound algorithm .
We formulate the problem of finding such pairs as an optimization problem , which can be solved by a branch-and-bound algorithm .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 4926
Experiments conducted on a real-life and publicly available dataset demonstrate the efficiency , the robustness and a promissing application of our system .
Experiments conducted on a real-life and publicly available dataset demonstrate the efficiency , robustness , and promising application of our system .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			14:1			0		1.0
15:1			15:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0

Alignment 4927
With the advances of modern technology , a large amount of digital images nowadays can be created and stored easily .
Thanks to the advances of modern technology , a large amount of digital images can be easily created and stored nowadays .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			19:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			13:1			0		1.0
21:1			20:1			0		1.0

Alignment 4928
As a result , the exponential growth of image repositories creates the urgent needs for searching images . Because of its importance and wide applications , image search has attracted more interest in recent years .
The resulting exponential growth of image repositories , however , has created an urgent need for effective ways of searching images .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			5:1			0		1.0
3:1			6:1			0		1.0
4:1			7:1			0		1.0
5:1			8:1			0		1.0
6:1			9:1			0		1.0
7:1			3:1			0		1.0
9:1			25:1			0		1.0
10:1			28:1			0		1.0
11:1			10:1			1		1.0
12:2			11:2			3		1.0
14:2			13:2			3		1.0
18:1			19:1			0		1.0
19:1			15:1			0		1.0
20:1			16:1			0		1.0
21:1			17:1			0		1.0

Alignment 4929
In a typical scenario of image search , users supply a query item which is usually represented by a region cropped from an image .
Moreover , image search has gained interest in recent years because of its importance and wide range of applications . In a typical scenario , users supply a query item , which is usually a region cropped from an image .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			7:1			0		1.0
2:1			5:1			0		1.0
3:1			6:1			0		1.0
11:1			4:1			0		1.0
19:1			24:1			0		1.0
20:1			0:1			0		1.0
21:1			1:1			0		1.0
22:1			2:1			0		1.0
23:1			3:1			0		1.0
25:1			8:1			0		1.0
26:1			9:1			0		1.0
27:1			10:1			0		1.0
28:1			11:1			0		1.0
29:1			12:1			0		1.0
31:1			13:1			0		1.0
32:1			14:1			0		1.0
33:1			15:1			0		1.0
34:1			18:1			0		1.0
35:1			19:1			0		1.0
36:1			20:1			0		1.0
37:1			21:1			0		1.0
38:1			22:1			0		1.0
39:1			23:1			0		1.0

Alignment 4930
The search system then returns a list of relevant images retrieved from a database .
The search system then returns a list of relevant images retrieved from a database .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 4931
The images are expected to contain the query item .
The images are expected to contain the query item .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 4932
Several extensive works have been conducted with great interest on improving search performance \CITE .
Extensive studies have been conducted with an eye to improving the performance of this sort of search \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			2:1			2		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
9:1			10:1			0		1.0
11:1			12:1			0		1.0
16:1			11:1			0		1.0
17:1			13:1			0		1.0
18:1			14:1			0		1.0

Alignment 4933
However , regardless of the powerfulness of state-of-the-art search techniques , there are still cases in which users are disappointed with search results .
However , regardless of the powerfulness of state-of-the-art search techniques , there are still cases in which users are disappointed with their search results .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0

Alignment 4934
The reason is because relevant items are not in the database .
The reason is that relevant items are not in the database .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:2			2:2			3		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 4935
Under such circumstances , whatever the search technique is , results are obviously irrelevant and unexpected .
Under such circumstances , whatever the search technique is , results are obviously irrelevant and unexpected .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 4936
A normal user without prior knowledge about the retrieved database has no choice but search by trial-and-error .
A normal user without prior knowledge about a database has no choice but to search it by trial-and-error .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
14:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0

Alignment 4937
We tackle this problem to facilitate users in searching and exploring images of such unknown database .
We decided to tackle this problem to help users in searching and exploring images in unknown databases .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
3:1			1:1			0		1.0
4:1			2:1			0		1.0
5:1			3:1			0		1.0
6:1			4:1			0		1.0
7:1			5:1			2		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			1		1.0
17:1			16:1			0		1.0

Alignment 4938
Our proposal is a novel recommendation system , named Recommend-Me .
Our proposal is a novel recommendation system , named Recommend-Me .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 4939
The expected scheme can be described as follows ( see Figure \REF for an example ) .
The envisioned scheme can be described as follows ( see Figure \REF for an example ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			3		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 4940
Given an unknown database and an initial query image , our Recommend-Me automatically presents its recommendations to user .
Given an unknown database and an initial query image , Recommend-Me automatically presents its recommendations to the user .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 4941
One recommendation is one item , bounded by a rectangular region , in the initial query image .
One recommendation is one item , bounded by a rectangular region , in the initial query image .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 4942
Each recommended item is assigned a number to clarify how many images of the database it occurs .
Each recommended item is assigned a number to show in how many images of the database it occurs .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0

Alignment 4943
Items with higher assigned numbers will be more recommended .
Items with larger assigned numbers will be more recommended .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			3		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 4944
By providing such recommendations , Recommend-Me supports users to :
By providing such recommendations , Recommend-Me helps users to :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 4945
- avoid unexpected search experience with poor queries that are subjectively ( and sometimes randomly ) selected ,
- avoid unexpected search experience with poor queries that are subjectively ( and sometimes randomly ) selected ,
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 4946
- rapidly refine the initial query image before any actual search , if the recommendations show that current search intention can not return relevant results ,
- rapidly refine the initial query image before any actual search , if the recommendations show that current search intention can not return relevant results ,
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 4947
- explore the database using the recommendations as hints .
- explore the database using the recommendations as hints .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 4948
Recommend-Me is a pure visual recommendation system .
Recommend-Me is a pure visual recommendation system .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 4949
No extra information or knowledge is required for input but an initial query image and a retrieved database .
No extra information or knowledge is required for an input besides an initial query image and a database . //<" and the name of the database " ? ? Or " and the location and name of the database " ? ?>
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			8:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 4950
To automatically generate recommendations , we need to address several critical issues .
To automatically generate recommendations , we need to address several issues .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0

Alignment 4951
First , there is a huge pool of candidate items in the initial query image .
First , there tends to be a huge pool of candidate items in the initial query image .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			3		1.0
6:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0

Alignment 4952
Basically , any rectangular region in the image can be considered as a candidate item .
Basically , any rectangular region in the image can be considered as a candidate item .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 4953
Examining all of them requires enormous computational cost .
Examining all of them would incur an enormous computational cost .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0

Alignment 4954
Second , even if a candidate item is known , enumerating its occurrences in the database is not trivial because it is subject to many variations such as viewpoint and scale changes , rotation or occlusion .
Second , even if a candidate item is known , enumerating its occurrences in the database is a not trivial task because it is subject to many variations in viewpoint , scale , rotation , occlusion , etc.
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
29:1			28:1			0		1.0
31:1			30:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
35:1			35:1			0		1.0

Alignment 4955
Furthermore , scanning over all regions in images of the database will inevitably be prohibitive , if not infeasible for practical purposes .
Furthermore , the cost of scanning all regions of the images of the database will inevitably be prohibitive for practical purposes .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			9:1			0		1.0
5:1			2:1			0		1.0
6:1			4:1			0		1.0
7:3			5:2			3		1.0
10:1			7:1			0		1.0
11:1			8:1			0		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0

Alignment 4956
In this paper , we employ state-of-the-art techniques such as SIFT and Bag-of-Words ( BoW ) model to handle matching regions under variations .
In this paper , we employ state-of-the-art techniques such as SIFT and the Bag-of-Words ( BoW ) model to handle the task of matching regions with the above variations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
23:1			19:1			0		1.0
24:1			20:1			0		1.0
28:1			22:1			0		1.0
29:1			23:1			0		1.0

Alignment 4957
Our main focus is an efficient approach for quantifying occurences of candidate items over the database to generate recommendations .
Our main focus is to devise an efficient approach for quantifying occurrences of candidate items in the database in order to generate recommendations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
6:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
20:1			16:1			0		1.0
21:1			17:1			0		1.0
22:1			18:1			0		1.0
23:1			19:1			0		1.0

Alignment 4958
The efficiency advantages of our approach come from various methodologies .
The advantage in efficiency comes from our use of various methodologies .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
3:1			1:1			0		1.0
4:1			6:1			1		1.0
5:1			7:1			0		1.0
6:1			4:1			0		1.0
8:1			3:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0

Alignment 4959
Based on an observation that users are mostly interested in object-like items , we use a selective search approach proposed by Van de Sande et al. \CITE to sample regions bounding object-like items in all images as a preprocessing step .
Based on the observation that users are mostly interested in object-like items , we decided to use a selective search approach proposed by Van de Sande et al. \CITE to sample regions bounding object-like items in all images as a preprocessing step .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
33:1			31:1			0		1.0
34:1			32:1			0		1.0
35:1			33:1			0		1.0
36:1			34:1			0		1.0
37:1			35:1			0		1.0
38:1			36:1			0		1.0
39:1			37:1			0		1.0
40:1			38:1			0		1.0
41:1			39:1			0		1.0
42:1			40:1			0		1.0

Alignment 4960
By applying the approach instead of other naive sampling approach such as sliding windows , the number of items ( i.e. regions ) that need to be processed in each image dramatically reduces .
By applying this approach instead of a naive sampling approach such as sliding windows , we were able to dramatically reduce the number of items ( i.e. regions ) that need to be processed in each image .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:2			2:2			3		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
18:1			25:1			0		1.0
19:1			31:1			0		1.0
20:1			32:1			1		1.0
21:1			15:1			0		1.0
22:1			16:1			0		1.0
23:1			17:1			0		1.0
24:1			18:1			0		1.0
25:1			19:1			0		1.0
26:1			20:1			0		1.0
27:1			21:1			0		1.0
28:1			22:1			0		1.0
29:1			23:1			0		1.0
30:1			24:1			0		1.0
32:1			26:1			0		1.0
33:1			27:1			0		1.0
34:1			28:1			0		1.0
35:1			29:1			0		1.0
36:1			30:1			0		1.0
37:1			33:1			0		1.0

Alignment 4961
Given two sets of regions , one contains regions of candidate items in the initial query image and the other contains regions of items in images of the database .
Given two sets of regions , one containing regions of candidate items in the initial query image and the other containing regions of items in images of the database , our task is to find occurrences of all candidate items in the database .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			1		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			1		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
43:1			29:1			0		1.0

Alignment 4962
Finding occurences of all candidate items in the database can be equally treated as finding pairs of matched regions , knowing a pair is formed by a region in one of the sets with a region in the other .
This task can be equivalently treated as finding pairs of matched regions , knowing that a pair is formed by a region in one of the sets with a region in the other .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			9:1			0		1.0
3:1			10:1			0		1.0
5:1			12:1			0		1.0
6:1			13:1			0		1.0
7:1			14:1			0		1.0
8:1			15:1			0		1.0
9:1			16:1			0		1.0
10:1			17:1			0		1.0
11:1			18:1			0		1.0
12:1			19:1			0		1.0
13:1			20:1			0		1.0
15:1			21:1			0		1.0
16:1			22:1			0		1.0
17:1			23:1			0		1.0
18:1			24:1			0		1.0
19:1			25:1			0		1.0
20:1			26:1			0		1.0
21:1			27:1			0		1.0
22:1			28:1			0		1.0
23:1			29:1			0		1.0
24:1			30:1			0		1.0
25:1			31:1			0		1.0
26:1			32:1			0		1.0
27:1			33:1			0		1.0
28:1			34:1			0		1.0
29:1			35:1			0		1.0
30:1			36:1			0		1.0
31:1			37:1			0		1.0
32:1			38:1			0		1.0
33:1			39:1			0		1.0

Alignment 4963
So , if top region pairs with sufficient high similarity scores are found , we can enumerate occurences of the items .
So , if the top region pairs are found with sufficiently high similarity scores , we can enumerate the occurrences of the items .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			11:1			0		1.0
8:1			12:1			0		1.0
9:1			6:1			0		1.0
10:1			7:1			1		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0

Alignment 4964
Based on these insights , we make an yet another efficiency boost by formulating the problem as an optimization problem which can be solved by applying a branh-and-bound algorithm .
Based on this insight , we can boost efficiency yet again by formulating the problem as an optimization problem that can be solved by applying a branch-and-bound algorithm .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			3:1			1		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			21:1			0		1.0
7:1			11:1			0		1.0
8:1			10:1			0		1.0
9:1			8:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0

Alignment 4965
In order to do that , we introduce a novel representation based on hierarchical structure to describe a set of region pairs and a corresponding function bounding the similarity scores of pairs over such a set .
In order to do that , we introduce a novel representation based on a hierarchical structure describing a set of region pairs and a corresponding function bounding the similarity scores of pairs over such a set .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			34:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:2			3		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
35:1			35:1			0		1.0
36:1			36:1			0		1.0

Alignment 4966
Related Works .
Related Work .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			1		1.0
2:1			2:1			0		1.0

Alignment 4967
With respect to discovering common items , Recommend-Me is related to recent studies on mining common items in image databases such as \CITE .
On the topic of discovering common items , Recommend-Me is related to recent studies on mining common items in image databases such as \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			3		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0

Alignment 4968
However , in contrast to these studies , Recommend-Me targets items which are shared by both an image database and user interest limited in an input initial image .
However , in contrast to these studies , Recommend-Me targets items which are shared by both an image database and the user 's particular interest inthe input initial image .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
21:1			20:1			0		1.0
24:1			21:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0

Alignment 4969
Meanwhile , \CITE only aim at finding common items within the database .
Meanwhile , \CITE only aims at finding common items within the database .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			1		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 4970
One can employ these techniques to our problem by firstly figuring out common items among images of the database , then looking them up in the initial query image again for recommendations .
One can employ these techniques to solve our problem by first identifying common items among the images of the database , then looking them up in the initial query image again to make recommendations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			1		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
33:1			31:1			0		1.0
34:1			32:1			0		1.0

Alignment 4971
However , by doing that , extra costs for mining unnecessary items , which appear in the database but the initial query image , arise accordingly .
However , doing that incurs the extra cost of mining unnecessary items that appear in the database , but not in the initial query image .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
5:1			19:1			0		1.0
6:1			6:1			0		1.0
7:2			7:2			3		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			5:1			0		1.0
18:1			18:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			26:1			0		1.0

Alignment 4972
One of the most related works to Recommend-Me for query suggestion is proposed by Zha et al in \CITE .
One of the most related studies to ours is that of Zha et al in \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			2		1.0
6:1			6:1			0		1.0
8:1			11:1			0		1.0
11:1			14:1			0		1.0
12:1			15:1			0		1.0
13:1			16:1			0		1.0
14:1			17:1			0		1.0
15:1			18:1			0		1.0
16:1			19:1			0		1.0

Alignment 4973
They introduced a system called Visual Query Suggestion ( VQS ) which simultanously provides both keyword and image suggestions for users .
They introduced a system , called Visual Query Suggestion ( VQS ) , that simultaneously provides both keyword and image suggestions to users .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
14:1			12:1			1		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0

Alignment 4974
There are clear differences between our Recommend-Me and VQS .
There are clear differences between Recommend-Me and VQS .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0

Alignment 4975
VQS requires an initial text query for suggestion formulation and its suggestions are both keywords and images .
VQS requires an initial text query for formulating the suggestion , and its suggestions are both keywords and images .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
9:1			7:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0

Alignment 4976
On the other hand , Recommend-Me takes an image as input and its outputs are regions in the image .
On the other hand , Recommend-Me takes an image as input , and its outputs are regions in the image .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0

Alignment 4977
Recommend-Me is a query suggestion system based on pure visual information .
Recommend-Me is a query suggestion system based on pure visual information .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 4978
Above all , although both Recommend-Me and VQS aim at facilitating users in searching images , the targeted problems are different .
Above all , although both Recommend-Me and VQS aim at helping users search for images , their targeted problems are different .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			2		1.0
11:1			11:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 4979
VQS proposes to help users to overcome query ambiguity formulation by precisely expressing search intents , assuming relevant items are always available .
VQS proposes to help users to overcome their tendency to formulate ambiguous queries by precisely expressing search intents , assuming the relevant items are always available .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
21:1			17:1			0		1.0
22:1			18:1			0		1.0
23:1			19:1			0		1.0
24:1			20:1			0		1.0
25:1			21:1			0		1.0
26:1			22:1			0		1.0

Alignment 4980
Meanwhile , Recommend-Me supports users to select queries based on the existence of their relevant items in the retrieved database .
Meanwhile , Recommend-Me helps users to select queries based on the existence of relevant items in the retrieved database .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0

Alignment 4981
To the best of our knowledge , Recommend-Me is the first attempt towards its targeted suggestion scheme .
To the best of our knowledge , Recommend-Me is the first attempt at this sort of targeted suggestion scheme .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0

Alignment 4982
From technical point of view , our solution is motivated by recent works for object localization and subimage retrieval based on branch-and-bound optimization \CITE .
From a technical point of view , our solution is motivated by recent work on object localization and subimage retrieval based on branch-and-bound optimization \CITE .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:2			3		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0

Alignment 4983
However , ours is differentiated in the way we represent sets of region pairs , instead of sets of regions only .
However , ours is differentiated from the other studies in that we represent sets of region pairs , instead of only sets of regions .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			6:1			0		1.0
9:1			5:1			0		1.0
11:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0
15:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			20:1			0		1.0
21:1			17:1			0		1.0
22:1			18:1			0		1.0
23:1			19:1			0		1.0
24:1			21:1			0		1.0

Alignment 4984
ESS and ESR \CITE use coordinate intervals for their presentation .
ESS and ESR \CITE use coordinate intervals for their presentation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 4985
Meanwhile , we utilize hierarchical structures in order to do that , since our regions are discrete .
In contrast , we utilize hierarchical structures in order to do that , since our regions are discrete .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0

Alignment 4986
Although coordinate intervals as in ESS ( or ESR ) can be extended to represent set of region pairs , such criterion may suffer the branch-and-bound algorithm from curse-of-dimensionality problem since the number of dimension required is at least doubled .
Although coordinate intervals as in ESS ( or ESR ) can be extended to represent sets of region pairs , such a criterion in the context of the branch-and-bound algorithm may suffer from the curse-of-dimensionality problem since the number of dimensions required at least doubles .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			1		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
22:1			21:1			0		1.0
24:1			31:1			0		1.0
27:1			24:1			0		1.0
28:1			25:1			0		1.0
29:1			26:1			0		1.0
30:1			22:1			0		1.0
31:1			23:1			0		1.0
32:1			27:1			0		1.0
34:1			28:1			0		1.0
35:1			29:1			0		1.0
36:1			30:1			0		1.0
38:1			32:1			0		1.0
39:1			33:1			0		1.0
40:1			34:1			1		1.0
41:1			35:1			0		1.0
42:1			37:1			0		1.0
43:1			38:1			0		1.0
44:1			39:1			1		1.0
45:1			40:1			0		1.0

Alignment 4987
Finally , ours and ESS , ESR do not share common approach to construct bounding quality function and to compute bounding values over the sets .
Finally , ESS , ESR and Recommend-Me differ in that they have different approaches to constructing a bounding quality function and to computing bounding values over the sets .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			4:1			0		1.0
3:1			5:1			0		1.0
4:1			6:1			0		1.0
5:1			3:1			0		1.0
13:1			11:1			1		1.0
14:1			12:1			0		1.0
15:1			13:1			1		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			1		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0
26:1			23:1			0		1.0
27:1			24:1			0		1.0
28:1			25:1			0		1.0

Alignment 4988
The rest of this paper is organized as follows .
The rest of this paper is organized as follows .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 4989
Section 2 presents an overview of the system .
Section 2 presents an overview of the system .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 4990
Details of our proposed approaches for finding region pairs with highest similarity scores are given in Section 3 .
The details of how we find region pairs with the highest similarity scores are given in Section 3 .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
5:1			5:2			3		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 4991
Section 4 presents our experiments and evaluations .
Section 4 presents our experiments and evaluations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 4992
Section 5 concludes our paper .
Section 5 concludes the paper .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:2			2:2			3		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0

Alignment 4993
The framework of Recommend-Me consists of 4 main steps towards formulating final recommendations for users .
The framework of Recommend-Me consists of four main steps .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			2		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			15:1			0		1.0

Alignment 4994
Figure \REF summarizes the pipeline .
Figure \REF summarizes the pipeline .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0

Alignment 4995
Step 1 : Candidate item selection in images .
Step 1 : Select candidate items in images .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 4996
Using all possible rectangular regions in images as candidate items is overly expensive for further processing .
Using all possible rectangular regions in images as candidate items is overly expensive in the subsequent processing .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
15:1			14:1			3		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0

Alignment 4997
More importantly , human users are often get attracted by object-like items .
More importantly , users are often attracted by object-like items .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0

Alignment 4998
Thus , we employ an approach proposed by Van de Sande et al. \CITE for item selection .
Thus , we employ an approach proposed by Van de Sande et al. \CITE for item selection .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 4999
The approach starts by oversegmenting an image into disjoint regions .
The approach starts by over-segmenting an image into disjoint regions .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0

Alignment 5000
Then , it performs a greedy algorithm which iteratively merges the two most similar regions together until the whole image becomes a single region .
Then , it performs a greedy search < ? ?> algorithm that iteratively merges the two most similar regions together until the whole image becomes a single region .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
10:1			6:1			0		1.0
12:1			8:1			0		1.0
13:1			9:1			0		1.0
14:1			10:1			0		1.0
15:1			11:1			0		1.0
16:1			12:1			0		1.0
17:1			13:1			0		1.0
18:1			14:1			0		1.0
19:1			15:1			0		1.0
20:1			16:1			0		1.0
21:1			17:1			0		1.0
22:1			18:1			0		1.0
23:1			19:1			0		1.0
24:1			20:1			0		1.0
25:1			21:1			0		1.0
26:1			22:1			0		1.0
27:1			23:1			0		1.0
28:1			24:1			0		1.0

Alignment 5001
All region throughout the hierarchy is considered as candidate items .
All regions throughout the hierarchy are considered to be candidate items .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			1		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			2		1.0
6:3			6:2			3		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0

Alignment 5002
Each item is represented by its rectangular bounding region .
Each item is represented by its rectangular bounding region .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 5003
Step 2 : Finding top region pairs with highest similarity scores .
Step 2 : Find top region pairs with the highest similarity scores .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			1		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0

Alignment 5004
There is a pool of region pairs if we compare each region in the initial query image with each region in images of the database .
There will be a pool of region pairs if we compare each region in the initial query image with each region in images of the database .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:2			1:1			3		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0

Alignment 5005
However , only region pairs with sufficient high similarity scores are meaningful for identifying occurrences of candidate items .
However , only region pairs with sufficiently high similarity scores are meaningful for identifying occurrences of candidate items .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			1		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 5006
In this step , we perform our proposed approach , explained in Section 3 , to find top \MATH ( an expected number of returned region pairs ) of such pairs in the pool .
In this step , we use the approach explained in Section 3 to find the top \MATH ( the expected number of returned region pairs ) of such pairs in the pool .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			32:1			0		1.0
7:1			8:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			15:1			0		1.0
13:1			16:1			0		1.0
15:1			17:1			0		1.0
16:1			18:1			0		1.0
17:1			19:1			0		1.0
19:1			21:1			0		1.0
20:1			22:1			0		1.0
21:1			23:1			0		1.0
22:1			24:1			0		1.0
23:1			25:1			0		1.0
24:1			26:1			0		1.0
25:1			27:1			0		1.0
26:1			28:1			0		1.0
27:1			29:1			0		1.0
28:1			30:1			0		1.0
29:1			31:1			0		1.0
31:1			33:1			0		1.0
32:1			34:1			0		1.0

Alignment 5007
Step 3 : Grouping overlapping regions .
Step 3 : Group overlapping regions .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			1		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0

Alignment 5008
Given \MATH region pairs returned in Step 2 and assuming each region pair in \MATH pairs is formed by a candidate item and its corresponding match , we now can enumerate the number of occurences of the items .
Given \MATH region pairs returned in Step 2 and assuming each region pair in the \MATH pairs is formed by a candidate item and its corresponding match , we can enumerate the number of occurrences of the items .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			36:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
35:1			35:1			0		1.0
37:1			37:1			0		1.0
38:1			38:1			0		1.0

Alignment 5009
However , there are several regions highly overlap each other due to merging in Step 1 .
However , there are likely several regions that overlap each other due to the merging done in Step 1 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
14:1			12:1			0		1.0
16:1			13:1			0		1.0
17:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0

Alignment 5010
They are perceived as the same item by human being .
These regions would be perceived as the same item by users .
Line2Start:Length	Line1Start:Length	Module		Score
2:2			1:1			3		1.0
4:1			2:1			0		1.0
5:1			3:1			0		1.0
6:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
11:1			10:1			0		1.0

Alignment 5011
Thus , we propose to use maximal clique analysis technique to group such regions for consistent recommendations .
Thus , we propose to use maximal clique analysis to group such regions so that the recommendations will be consistent .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
16:1			16:1			0		1.0
19:1			15:1			0		1.0
20:1			17:1			0		1.0

Alignment 5012
One clique is one group of regions .
One clique is one group of regions .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 5013
Step 4 : Formulating recommendations .
Step 4 : Formulate recommendations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			1		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0

Alignment 5014
Finally , for each group of regions , we count the number of images containing at least one match of one member region of the group .
Finally , for each group of regions , we count the number of images containing at least one match of one member region of the group .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0

Alignment 5015
The number indicates how frequent the item , represented by the group , occurs in the database .
The number indicates how frequent the item , represented by the group , occurs in the database .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 5016
Using those numbers , we rank all groups and then introduce them to users as our recommendations .
Using those numbers , we rank all groups and show them as recommendations to users .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			11:1			0		1.0
11:1			14:1			0		1.0
12:1			16:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			17:1			0		1.0

Alignment 5017
Representative of each group is a rectangular region located by averaging coordinates of all member regions of the group .
A representative of each group is a rectangular region located by averaging the coordinates of all member regions of the group .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0

Alignment 5018
In this section , we introduce our proposed approach for efficiently finding top \MATH similar region pairs in the pool of all possible region pairs .
In this section , we describe our approach for efficiently finding the top \MATH similar region pairs in the pool of all possible region pairs .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			6:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0

Alignment 5019
Given two sets of regions \MATH and \MATH , the set of all possible region pairs then can be represented as \MATH .
Given two sets of regions \MATH and \MATH , the set of all possible region pairs can then be represented as \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			17:1			0		1.0
17:1			16:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 5020
With a similarity function \MATH , we have to solve the following optimization problem in order to find the region pair \MATH with the highest similarity score .
By using the similarity function \MATH , we have to solve the following optimization problem in order to find the region pair \MATH with the highest similarity score .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			23:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0

Alignment 5021
Because \MATH elements , it is expensive to perform this maximization exhaustively .
Because \MATH elements , it is expensive to perform this maximization exhaustively .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 5022
We propose to use a branch-and-bound algorithm \CITE for the problem .
We hence propose to use a branch-and-bound algorithm \CITE to solve the problem .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0

Alignment 5023
Once \MATH is found , we can obtain the other top region pairs by continuing the search processs with the remaining search spaces , in which found top pairs eliminated .
Once \MATH is found , we can obtain the other top region pairs by continuing the search process with the remaining search space , in which the found top pairs have been eliminated .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			1		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
32:1			29:1			0		1.0
33:1			30:1			0		1.0

Alignment 5024
A general branch-and-bound algorithm works by hierarchically dividing the parameter space into disjoint parts , known as branching step .
A general branch-and-bound algorithm works by hierarchically dividing the parameter space into disjoint parts ; this is called the branching step .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
17:2			15:2			3		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0

Alignment 5025
In the bounding step , each part is assigned an upper bound value that the quality function could take on any of the members of the part .
In the bounding step , each part is assigned an upper bound for which the quality function could take on any of the members of the part . //<The rewrite is grammatical but I don 't know what " the quality function could take on any of the members of the part " . Inparticular what are these members and can they be computed in a function ?>
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
13:1			12:2			3		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0

Alignment 5026
Parts of the parameter space with higher upper bound values are examined first .
Those parts of the parameter space with higher upper bound values are examined first .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0

Alignment 5027
So , many portions of the parameter space can be eliminated if their upper bound values imply that they cannot contain the maximum .
Thus , many portions of the parameter space can be eliminated if their upper bound values imply that they cannot contain the maximum .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 5028
Adapting to our problem , the parameter space is the set of all region pairs \MATH , and the quality function is the similarity function \MATH .
In our problem , the parameter space is the set of all region pairs \MATH , and the quality function is the similarity function \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0

Alignment 5029
Assuming we can organize regions in \MATH and \MATH into two hierarchical structures \MATH and \MATH respectively , so that :
Assuming we can organize regions in \MATH and \MATH into two hierarchical structures \MATH and \MATH respectively , so that :
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 5030
- all regions are leaf nodes of the structures and non-leaf nodes are {\it virtual} nodes ,
- all regions are leaf nodes of the structures and non-leaf nodes are {\it virtual} nodes ,
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 5031
- if each node is repsented by a histgoram \MATH with \MATH bins , the value at each bin of a child node is constrainted to be equal or smaller the value at the same bin of its parent node .
- if each node is represented by a histogram \MATH with \MATH bins , the value in each bin of a child node is constrained to be equal or smaller than the value in the same bin of its parent node .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:2			16:2			3		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
31:1			30:1			0		1.0
32:2			31:2			3		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0
37:1			36:1			0		1.0
38:1			37:1			0		1.0
39:1			38:1			0		1.0
40:1			39:1			0		1.0
41:1			40:1			0		1.0

Alignment 5032
Given such structures , we show in the following how a branch-and-bound algorithm applied to our problem .
Given such structures , we show in what follows how the branch-and-bound algorithm can be used to solve our problem .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
8:1			8:1			1		1.0
9:1			9:1			0		1.0
10:1			7:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
15:1			13:1			2		1.0
16:1			14:1			0		1.0
18:1			15:1			0		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0

Alignment 5033
Let \MATH and \MATH denote two nodes on \MATH and \MATH .
Let \MATH and \MATH denote two nodes on \MATH and \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 5034
And , \MATH denotes the set containing all leaf nodes explored from \MATH .
And let \MATH denote the set containing all leaf nodes explored from \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			1		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 5035
If \MATH is a leaf node , \MATH .
If \MATH is a leaf node , \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 5036
Otherwise , given \MATH with \MATH are direct child nodes of \MATH , \MATH can be recursively defined as follows : \MATH
Otherwise , given \MATH with \MATH being direct child nodes of \MATH , \MATH can be recursively defined as follows : \MATH
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			3		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0

Alignment 5037
In a similar way , we have : \MATH
In a similar way , we have : \MATH
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0

Alignment 5038
Given \MATH indicates the set of node pairs formed by paring nodes in \MATH with nodes in \MATH , we have : \MATH
Letting \MATH indicate the set of node pairs formed by pairing nodes in \MATH with nodes in \MATH , we get : \MATH . //<the rewrite is a guess .>
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			1		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			2		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 5039
So , if \MATH and \MATH are roots of \MATH and \MATH respectively , \MATH will exactly be the entire search space \MATH .
Thus , if \MATH and \MATH are roots of \MATH and \MATH respectively , \MATH will be exactly the entire search space \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			17:1			0		1.0
17:1			16:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0

Alignment 5040
Branching Step .
Branching Step .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0

Alignment 5041
Dividing the search space ( i.e. set of region pairs ) covered by \MATH is straightforward by utilizing the hierarchical structures \MATH , \MATH at certain nodes \MATH , \MATH .
Dividing up the search space ( i.e. set of region pairs ) covered by \MATH can be done straightforwardly by utilizing the hierarchical structures \MATH , \MATH at certain nodes \MATH , \MATH . //<The rewrite is better if it is correct .>
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:2			14:1			3		1.0
18:1			15:1			1		1.0
19:1			16:1			0		1.0
20:1			17:1			0		1.0
21:1			18:1			0		1.0
22:1			19:1			0		1.0
23:1			20:1			0		1.0
24:1			21:1			0		1.0
25:1			22:1			0		1.0
26:1			23:1			0		1.0
27:1			24:1			0		1.0
28:1			25:1			0		1.0
29:1			26:1			0		1.0
30:1			27:1			0		1.0
31:1			28:1			0		1.0
32:1			29:1			0		1.0
33:1			30:1			0		1.0

Alignment 5042
Regarding to \REF , \REF and \REF , \MATH can be divided into disjoint parts as follows : \MATH
Regarding \REF , \REF and \REF , \MATH can be divided into disjoint parts as follows : \MATH
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0

Alignment 5043
Or , \MATH
Or , \MATH
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0

Alignment 5044
Selecting which way to divide can be based on sizes of \MATH and \MATH .
The way to divide can be based on the sizes of \MATH and \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0

Alignment 5045
We select the larger one to be divided first .
We divide the larger one first .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			5:3			3		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			8:1			0		1.0
6:1			9:1			0		1.0

Alignment 5046
An illustration of a branching step is given in Figure \REF .
The branching step is illustrated in Figure \REF .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			4:1			0		1.0
2:1			5:1			0		1.0
3:1			6:1			0		1.0
5:1			8:1			0		1.0
6:1			9:1			0		1.0
7:1			10:1			0		1.0
8:1			11:1			0		1.0

Alignment 5047
Bounding Step .
Bounding Step .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0

Alignment 5048
An essential requirement for branch-and-bound is the quality bounding function \MATH used to evaluate how necessary a part of the search space should be examined .
An essential requirement for the branch-and-bound algorithm is the quality bounding function \MATH used to determine whether a part of the search space should be examined . //<Or " determine the extent that " ? ?>
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0

Alignment 5049
Particularly , \MATH bounds the upper values of \MATH over a set of node pairs ( i.e. region pairs ) .
In particular , \MATH bounds the upper values of \MATH over a set of node pairs ( i.e. region pairs ) .
Line2Start:Length	Line1Start:Length	Module		Score
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0

Alignment 5050
Assuming we are now evaluating the upper bound of \MATH over all region pairs in \MATH .
Let us assume that we are evaluating the upper bound of \MATH over all region pairs in \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
4:1			1:1			0		1.0
5:1			2:1			0		1.0
6:1			4:1			0		1.0
7:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0

Alignment 5051
Among several types of distance for estimating the similarity of two regions , we stick to Normalized Histogram Intersection ( NHI ) distance since it is well-balanced between computational efficiency and robustness~\cite{ESR} .
Among the several distance formulas for estimating the similarity of two regions , we will use the Normalized Histogram Intersection ( NHI ) distance since it is well-balanced between computational efficiency and robustness~\cite{ESR} .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			1:1			0		1.0
3:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0
33:1			32:1			0		1.0

Alignment 5052
We then rely on NHI to define \MATH bounding the values of \MATH , with : \MATH
We will then rely on NHI to define \MATH bounding the values of \MATH , with : \MATH
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0

Alignment 5053
Referring to the constraint ( b ) in constructing \MATH and \MATH , we have : \MATH
Referring to constraint ( b ) in constructing \MATH and \MATH , we have : \MATH
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0

Alignment 5054
As a result , the bounding value \MATH over \MATH can be clearly observed as : \MATH
As a result , the bounding value \MATH over \MATH can be clearly observed as : \MATH . //<I 'm not sure what observed means in this context . Do you mean " can be derived as " ? ?>
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 5055
We can efficiently evaluate \MATH for the set of region pairs \MATH because \MATH is relied only on histogram representation of single rectangular regions \MATH and \MATH .
We can efficiently evaluate \MATH for the set of region pairs \MATH because \MATH relies only on the histogram representation of single rectangular regions \MATH and \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			15:1			1		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0

Alignment 5056
And , the normalization terms , which indicate the minimum number of visual words inside any member region of \MATH , \MATH , are computed once by using integral image technique .
Moreover , the normalization terms , which indicate the minimum number of visual words inside any member region of \MATH , \MATH , are computed once by using the integral image technique .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0

Alignment 5057
Inspired by \CITE , we form the algorithm in best-first manner .
Inspired by \CITE , we devised the algorithm to work in a best-first manner . //<The original describes the way you decided to write the algorithm . In contrast , the rewrite describes the way the algorithm works .>
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
10:1			8:1			0		1.0
12:1			9:1			0		1.0
13:1			10:1			0		1.0
14:1			11:1			0		1.0

Alignment 5058
The algorithm examines next the set having highest bounding value \MATH .
The algorithm examines the set having the highest bounding value \MATH . //<" next " is unclear . The rewrite is a guess .>
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
13:1			3:1			0		1.0

Alignment 5059
The algorithm stops if the set contain only one pair of region .
The algorithm stops if the set contain only one pair of region .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 5060
Otherwise , the set is then divided into disjoint subsets for further search .
Otherwise , the set is then divided into disjoint subsets for further search .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0

Alignment 5061
Pseudo-code for the algorithm using a priority queue to store sets of region pairs , is given as follows .
Pseudo-code for the algorithm using a priority queue to store sets of region pairs , is given as follows .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 5062
To obtain more than one region pair , we simply continue the loop in the Algorithm 1 until the expected number of region pairs \MATH have been reached .
To obtain more than one region pair , we simply repeat the loop in Algorithm 1 until the expected number of region pairs \MATH is reached .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			26:1			2		1.0
25:1			27:1			0		1.0
26:1			28:1			0		1.0

Alignment 5063
So far , our approach is based on an assumption that the sets of regions are already organized into hierarchical structures which satisfy the constraints ( a ) and ( b ) .
So far , our approach is based on an assumption that the sets of regions are already organized into hierarchical structures which satisfy constraints ( a ) and ( b ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0
31:1			32:1			0		1.0

Alignment 5064
In the remaining of this section , we show how to organize such sets , given the initial query image and the image database .
In the remaining of this section , we show how to organize such sets , given the initial query image and image database .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0

Alignment 5065
There are two type of region set for organization .
There are two type of region set .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			9:1			0		1.0

Alignment 5066
One is set containing regions of one image .
One is a set containing regions of one image .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0

Alignment 5067
The other is set containing regions of multiple images ( i.e. database ) .
The other is a set containing regions of multiple images ( i.e. database ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0

Alignment 5068
With the first type of set , by applying the selective search approach introduced in \CITE for item selection , regions in each image are already organized into a binary tree .
With the first type of set , by applying the selective search approach introduced in \CITE for item selection , regions in each image are already organized into a binary tree .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0

Alignment 5069
Because such binary tree were constructed by bottom-up merging regions , a parent region on the trees spatially covers its child regions in image space ( see Figure \REF ) .
Because such binary tree were constructed by bottom-up merging of regions , a parent region on the trees spatially covers its child regions in the image space ( see Figure \REF ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0

Alignment 5070
As a result , we have the constraint ( b ) satisfied .
As a result , constraint ( b ) is satisfied .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			7:1			0		1.0
5:1			8:1			0		1.0
6:1			9:1			0		1.0
7:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0

Alignment 5071
However , because we want to use all regions corresponding to all nodes throughout the tree as candidate item regions , the constraint ( a ) will be violated if we keep using the tree for the branch-and-bound based algorithm .
However , because we want to use all regions corresponding to all nodes throughout the tree as candidate item regions , constraint ( a ) will be violated if we keep using the tree for the branch-and-bound algorithm .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0
31:1			32:1			0		1.0
32:1			33:1			0		1.0
33:1			34:1			0		1.0
34:1			35:1			0		1.0
35:1			36:1			0		1.0
36:1			37:1			0		1.0
37:1			39:1			0		1.0
38:1			40:1			0		1.0

Alignment 5072
In other words , all current non-leaf nodes of the tree will be treated as {\it vitual nodes} and will not be used as candidate item regions .
In other words , all current non-leaf nodes of the tree will be treated as {\it vitual nodes} and will not be used as candidate item regions .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0

Alignment 5073
Our solution to this problem is straightforward .
Our solution to this problem is straightforward .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 5074
We generate and attach a new leaf node to each non-leaf nodes of the current tree .
We generate and attach a new leaf node to each non-leaf node of the current tree .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			1		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0

Alignment 5075
The generated node is exactly the same as the non-leaf node it attach to , which now becomes a virtual node .
The generated node is exactly the same as the non-leaf node it is attached to , which now becomes a virtual node .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
13:2			12:2			3		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0

Alignment 5076
By doing that , we keep the spatial covering property of the orginal binary tree for the new hierarchical structure .
By doing that , we keep the spatial covering property of the original binary tree for the new hierarchical structure .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 5077
And , all non-leaf nodes will be taken into account as candidate item regions via their attachments .
Moreover , all non-leaf nodes will be taken into account as candidate item regions via their attachments .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 5078
The new hierarchical structure therefore satisfy both the constraints ( a ) and ( b ) .
The new hierarchical structure therefore satisfies both constraints .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			1		1.0
6:1			6:1			0		1.0
7:1			8:1			0		1.0
8:1			16:1			0		1.0

Alignment 5079
An illustration is presented in Figure X .
Figure X is an illustration of this organization .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			5:1			0		1.0
1:1			6:1			0		1.0
2:1			2:1			0		1.0
4:1			1:1			0		1.0
8:1			7:1			0		1.0

Alignment 5080
With a set containing regions of multiple images , we perform a two-stage organization procedure .
With a set containing regions from multiple images , we perform a two-stage organization procedure .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:2			4:2			3		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0

Alignment 5081
At the first stage , regions in each image are organized into a hierarchical structure as we presented above .
In the first stage , regions in each image are organized into a hierarchical structure , as presented above .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 5082
Given multiple hierarchical structures returned from the first stage , we use their root nodes as initial elements to construct an yet another hierarchical structure over them by divisive clustering .
If multiple hierarchical structures are returned by the first stage , we use their root nodes as the initial elements to construct an yet another hierarchical structure over them by divisive clustering . //<the rewrite is a guess .>
Line2Start:Length	Line1Start:Length	Module		Score
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0

Alignment 5083
We start with the full set of the elements .
We start with the full set of the elements .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0

Alignment 5084
Then , splits are peformed recursively as one moves down the hierarcy .
Then , we perform splits recursively as one moves down the hierarchy .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
4:1			2:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			12:1			0		1.0

Alignment 5085
In each splitting step , the splitted set is divided into $k$ parts by using $k$-means clustering algorithm .
In each splitting step , the split set is divided into $k$ parts by using $k$-means clustering .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			1		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			18:1			0		1.0

Alignment 5086
Once the hierchical structure is completed , we then compute histogram representation for all of its non-leaf nodes .
Once the hierarchical structure is completed , we compute a histogram representation for all of its non-leaf nodes .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 5087
The value at each hitogram bin of a non-leaf nodes is the maximum of all values at the same bin of its child nodes .
The value at each histogram bin of a non-leaf node is the maximum of all values in the same bin of its child nodes .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			1		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:3			16:3			3		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0

Alignment 5088
This is to ensure the constraint ( b ) sastified .
This is to ensure constraint ( b ) is satisfied .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
10:1			10:1			0		1.0

Alignment 5089
At last , by unifying results of both stages , we have a unique hierarchical structure over the set of regions of multiple images , which satisfies the both constraints .
Finally , by unifying the results of both stages , we have a unique hierarchical structure over the set of regions of multiple images , which satisfies both constraints .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			27:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0

Alignment 5090
We show an illustration in Figure Y .
We illustratie this in Figure Y .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0

Alignment 5091
So , given the initial query image and a database , we now can construct two hierarchical structures .
So , given the initial query image and a database , we now can construct two hierarchical structures .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0

Alignment 5092
One is for regions of the initial query image .
One is for the regions of the initial query image .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0

Alignment 5093
The other is for regions of all images in the database .
The other is for the regions of all images in the database .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0

Alignment 5094
Both structures are then becomes input for our proposed approach to find top region pairs with highest similarity scores for recommendation generation .
Both structures then become the input for our approach to find the top region pairs with the highest similarity scores for making recommendations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			1		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
23:1			22:1			0		1.0

Alignment 5095
Note that , because the hierarchical for regions of images in the database is independent of query , we construct it only one time .
Note that because the hierarchy of the regions of images in the database is independent of the query , we construct it only one time .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			3		1.0
5:1			15:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0

Alignment 5096
A recommendation is a good one if it exactly locates an item which exists in the database .
A recommendation is a good one if it exactly locates an item in the database .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			14:1			0		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0

Alignment 5097
We call such recommendations as hit recommendations . Thus , a good recommendation system should accurately provide such hit recommendation to users .
We call such recommendations" hit recommendations " , and a good recommendation system should accurately provide them to users .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
7:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
17:1			20:1			0		1.0
18:1			21:1			0		1.0
19:1			22:1			0		1.0

Alignment 5098
More importantly , users always expect that hit recommendations are ranked higher than false recommendations ( if there are some of them ) on the list of all recommendations introduced by the system .
More importantly , users always expect that hit recommendations are ranked higher than false recommendations ( if there are a number of them ) on the list of the recommendations by the system .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
29:1			28:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0

Alignment 5099
Based on those insights , we evaluate Recommend-Me system using two evaluation metrics : precision on introducing recommendation and rank of the first hit recommendation on the list .
Based on these insights , we evaluated the Recommend-Me system using two evaluation metrics : precision in pesenting recommendations and rank of the first hit recommendation on the list .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			1		1.0
7:1			26:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
18:2			17:2			3		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0

Alignment 5100
Given an initial query image with ground-truth annotation indicates bounding box of an item known existed in the database , Recommend-Me is determined to precisely introduce recommendation if at least one of its recommendation is a hit recommendation .
Given an initial query image with ground-truth annotations indicating the bounding box of an item known to existin the database , Recommend-Me will provide a recommendation if at least one of its recommendations is a hit recommendation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			1		1.0
8:1			8:1			1		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			23:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
24:1			35:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0
31:1			32:1			0		1.0
32:1			33:1			1		1.0
33:1			34:1			0		1.0
35:1			36:1			0		1.0
36:1			37:1			0		1.0
37:1			38:1			0		1.0

Alignment 5101
We apply an approach used in Pascal VOC challenge to clarify whether a recommendation is a hit recommendation .
We used an approach from the Pascal VOC challenge to clarify whether a recommendation is a hit recommendation or not .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			4:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
20:1			18:1			0		1.0

Alignment 5102
In particular , the intersection area between a hit recommendation and an item should be larger than half of their union area .
In particular , the intersection area between a hit recommendation and an item should be larger than half their union area .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0

Alignment 5103
Because our target is not to improve search techniques but to facilitate query selection procedure , search performance simply relies on standard techniques if users take an recommendation as a search query .
Because our target is not to improve search techniques but to facilitate query selection , the search simply relies on standard techniques if users use an recommendation as a search query .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0
31:1			32:1			0		1.0

Alignment 5104
To evaluate the efficiency of Recommend-Me on finding \MATH region pairs with highest similarity scores , we compute the number of evaluation for the quality bounding function in the branch-and-bound algorithm .
To evaluate the efficiency of Recommend-Me in finding \MATH region pairs with the highest similarity scores , we computed the number of evaluations for the quality bounding function in the branch-and-bound algorithm .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			27:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			28:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			1		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			1		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0
32:1			31:1			0		1.0

Alignment 5105
This number is then divided by the size of all possible region pairs formed by regions in the initial query image and regions in images of the database .
This number was then divided by the size of all possible region pairs formed by regions in the initial query image and regions in images of the database . //< " the size of all possible region pairs " is unclear to me . Do you mean " the average size of all possible region pairs " or " the sizes of all possible region pairs " ?>
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
39:1			2:1			0		1.0

Alignment 5106
The fraction is reported as the efficiency improvement of Recommend-Me .
The fraction was taken to be the efficiency improvement of Recommend-Me .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			2		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0

Alignment 5107
Note that , regions in images are pre-selected as in Step 1 of our framework .
Note that regions in images were pre-selected as in Step 1 of our framework .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			2		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0

Alignment 5108
Feature presentation .
Feature presentation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0

Alignment 5109
We employ BoF model to represent features of images and regions in the images .
We employed a BoF model to represent the features of images and regions in the images .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			1		1.0
3:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
8:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
13:1			11:1			0		1.0
14:1			12:1			0		1.0
15:1			13:1			0		1.0
16:1			14:1			0		1.0

Alignment 5110
Visual words in images are located by dense grid sampling and Different-of-Gaussian( DoG ) detector .
Visual words in the images were located by using dense grid sampling and a Different-of-Gaussian ( DoG ) detector .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			2		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
9:1			7:1			0		1.0
10:1			8:1			0		1.0
11:1			9:1			0		1.0
12:1			10:1			0		1.0
16:1			12:1			0		1.0
17:1			13:1			0		1.0
18:1			14:1			0		1.0
19:1			15:1			0		1.0

Alignment 5111
A codebook of 2000 visual words is built using standard K-Means algorithm .
A codebook of 2000 visual words was built using the standard K-Means algorithm .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:2			6:2			3		1.0
8:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0

Alignment 5112
%to cluster points on a set of random images .% Additionally , the set of interest points obtained by DoG in the query image is used to remove regions without any of such points inside .
%to cluster points on a set of random images .% Additionally , the set of points of interest obtained by the DoG in the query image was used to remove regions without any such points inside .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			16:1			0		1.0
16:1			31:1			0		1.0
17:1			15:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			21:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:2			24:2			3		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
33:1			32:1			0		1.0
34:1			33:1			0		1.0
35:1			34:1			0		1.0
36:1			35:1			0		1.0

Alignment 5113
This helps us to eliminate less meaningful regions such as a portion of the sky , solid color regions , etc for recommendation .
This helped us to eliminate less meaningful regions such as the sky , solid color regions , etc. , from the recommendations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			1		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			13:1			0		1.0
11:1			14:1			0		1.0
12:1			15:1			0		1.0
13:1			16:1			0		1.0
14:1			17:1			0		1.0
15:1			18:1			0		1.0
16:1			19:1			0		1.0
21:1			22:1			1		1.0
22:1			23:1			0		1.0

Alignment 5114
Region selection in images .
Region selection in images .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0

Alignment 5115
As mentioned above , we use the approach introduced in \CITE on different color channel for region selection .
As mentioned above , we used the approach first introduced in \CITE on different color channels for the region selection .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:2			5:2			3		1.0
7:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			1		1.0
16:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0

Alignment 5116
In this experiment , we used two color channels which are RGB and Hue , since regions generated on those channels can cover 99 .72\% area of the annotated item regions in our dataset .
In this experiment , we used two color channels , RGB and Hue , since the regions generated on those channels can cover 99 .72\% of the area of the annotated item regions in our dataset .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			27:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
23:1			23:1			0		1.0
24:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0
32:1			30:1			0		1.0
33:1			31:1			0		1.0
34:1			32:1			0		1.0
35:1			33:1			0		1.0
36:1			34:1			0		1.0

Alignment 5117
A virtual root node is created to compose two color-dependent binary trees into one unique binary tree for each image .
A virtual root node was created to compose two color-dependent binary trees into one unique binary tree for each image .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			2		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0

Alignment 5118
In addition , rectangular regions which do not contain any visual word or are smaller than 40 x 40 pixels are discarded .% since they can form a meaningful recommendation .
In addition , the rectangular regions which did not contain any visual word or were smaller than 40 x 40 pixels were discarded .% since they can form a meaningful recommendation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			2		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			2		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			2		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
29:1			28:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0

Alignment 5119
Maximal clique analysis algorithm .
Maximal clique analysis algorithm .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0

Alignment 5120
Given the set of regions in the initial query image , we build a graph in which two regions are connected if they highly overlap each other ( we use the approach of Pascal VOC with tighter threshold , 0 .8 ) .
Given the set of regions in the initial query image , we built a graph in which two regions were connected if they nearly overlapped each other ( we use the approach of Pascal VOC with a tighter threshold , 0 .8 ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:2			12:2			3		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			2		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0
24:1			24:1			1		1.0
25:1			25:1			0		1.0
26:1			26:1			0		1.0
27:1			27:1			0		1.0
28:1			28:1			0		1.0
29:1			29:1			0		1.0
30:1			30:1			0		1.0
31:1			31:1			0		1.0
32:1			32:1			0		1.0
33:1			33:1			0		1.0
34:1			34:1			0		1.0
35:1			35:1			0		1.0
37:1			36:1			0		1.0
38:1			37:1			0		1.0
39:1			38:1			0		1.0
40:1			39:1			0		1.0
41:1			40:1			0		1.0
42:1			41:1			0		1.0
43:1			42:1			0		1.0

Alignment 5121
Bron-Kerbosch algorithm is then applied to find all maximal cliques in the graph .
The Bron-Kerbosch algorithm was then applied to find all maximal cliques in the graph .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			0:1			0		1.0
2:1			1:1			0		1.0
3:1			2:1			2		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0

Alignment 5122
One clique is one group of regions .
One clique was one group of regions .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:2			2:2			3		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 5123
Figure \REF shows our evaluation results .
Figure \REF shows the results of the evaluation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
4:1			5:1			0		1.0
7:1			4:1			0		1.0
8:1			6:1			0		1.0

Alignment 5124
The reported numbers of precision , rank of the first hit recommendation as well as efficiency improvement are averaged as we perform Recommend-Me with 375 different initial query images and an individual value of \MATH .
The reported precision , rank of the first hit recommendation , and efficiency improvement are averages of Recommend-Me on 375 different initial query images and an individual value of \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			4:1			0		1.0
3:1			5:1			0		1.0
4:1			6:1			0		1.0
5:1			7:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			0		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
12:1			15:1			0		1.0
13:1			16:1			0		1.0
14:1			17:1			0		1.0
15:1			18:1			1		1.0
16:1			3:1			0		1.0
17:1			22:1			0		1.0
19:1			24:1			0		1.0
20:1			25:1			0		1.0
21:1			26:1			0		1.0
22:1			27:1			0		1.0
23:1			28:1			0		1.0
24:1			29:1			0		1.0
25:1			30:1			0		1.0
26:1			31:1			0		1.0
27:1			32:1			0		1.0
28:1			33:1			0		1.0
29:1			34:1			0		1.0
30:1			35:1			0		1.0

Alignment 5125
The results show that Recommend-Me can successfully introduce hit recommendations to users with high precision ( approximately 80 .27\% ) .
The results show that Recommend-Me can make hit recommendations to users with high precision ( approximately 80 .27\% ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			7:1			3		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0

Alignment 5126
On the returned list of all recommendations , a hit recommendation usually takes the first two places on the list .
On the returned list of all recommendations , hit recommendations usually take the first two places on the list .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			1		1.0
10:1			11:1			0		1.0
11:1			12:1			1		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0

Alignment 5127
This help users to avoid choosing false recommendations ( if such false recommendations are highly ranked ) .
This help users to avoid choosing false recommendations ( if such false recommendations are highly ranked ) .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0

Alignment 5128
We observed that there are two types of false recommendations on the top places of the list .
There were two types of false recommendation in the top places of the list .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			4:1			2		1.0
2:1			5:1			0		1.0
3:1			6:1			0		1.0
4:1			7:1			0		1.0
5:1			8:1			0		1.0
6:1			9:1			1		1.0
8:1			11:1			0		1.0
9:1			12:1			0		1.0
10:1			13:1			0		1.0
11:1			14:1			0		1.0
12:1			15:1			0		1.0
13:1			16:1			0		1.0
14:1			17:1			0		1.0

Alignment 5129
The first type consists background regions ( e.g. trees , buildings , roads ) which are easily found in many images .
The first type consisted of background regions ( e.g. trees , buildings , roads ) , which are easily found in many images .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			1		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
16:1			14:1			0		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0

Alignment 5130
The second type is the items lacking of manual annotation such as windows , cars and humans .
The second type was items lacking manual annotations such as windows , cars , and humans .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			2		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			8:1			0		1.0
7:1			9:1			1		1.0
8:1			10:1			0		1.0
9:1			11:1			0		1.0
10:1			12:1			0		1.0
11:1			13:1			0		1.0
12:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0

Alignment 5131
Thus , recommendations about those items are not counted as hit recommendations .
Thus , recommendations about those items are not counted as hit recommendations .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0

Alignment 5132
However , if users are interested in using them as hints to explore the database , they are still very much helpful .
However , if users are interested in using them as hints to explore the database , they may still be very helpful .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:3			17:2			3		1.0
20:1			19:1			0		1.0
21:1			21:1			0		1.0
22:1			22:1			0		1.0

Alignment 5133
Clearly , one can realize that the performance of Recommend-Me is under the influence of \MATH .
Clearly , one can realize that the performance of Recommend-Me is influenced by \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:2			11:4			3		1.0
13:1			15:1			0		1.0
14:1			16:1			0		1.0

Alignment 5134
By increasing \MATH , we obtain more region pairs with sufficient hight similarity scores .
By increasing \MATH , we can obtain more region pairs with sufficiently high similarity scores .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			1		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0

Alignment 5135
It brings more chances to get region pairs of the annotated item , thus improves the precision .
Thisgives more chances to get region pairs of the annotated item , thus improving precision .
Line2Start:Length	Line1Start:Length	Module		Score
1:1			2:1			0		1.0
2:1			3:1			0		1.0
3:1			4:1			0		1.0
4:1			5:1			0		1.0
5:1			6:1			0		1.0
6:1			7:1			0		1.0
7:1			8:1			0		1.0
8:1			9:1			0		1.0
9:1			10:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			1		1.0
14:1			16:1			0		1.0
15:1			17:1			0		1.0

Alignment 5136
However , the trade-off is that more unexpected items are also returned .
However , the trade-off is that more unexpected items are returned .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0

Alignment 5137
This results in a drop of average rank of the first hit recommendation .
This results in a drop in the average rank of the first hit recommendation .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:2			4:2			3		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0

Alignment 5138
Figure 5( a ) demonstrates this circumstance .
Figure 5( a ) demonstrates this circumstance .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0

Alignment 5139
When \MATH increases from 2000 to 10000 , the precision also increases from 74 .67\% to 81 .97\% ; meanwhile , the average rank of the first hit recommendation drops to 2 .27 from 1 .78 .
When \MATH increases from 2000 to 10000 , the precision increases from 74 .67\% to 81 .97\% ; meanwhile , the average rank of the first hit recommendation drops to 2 .27 from 1 .78 .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			11:1			0		1.0
11:1			12:1			0		1.0
12:1			13:1			0		1.0
13:1			14:1			0		1.0
14:1			15:1			0		1.0
15:1			16:1			0		1.0
16:1			17:1			0		1.0
17:1			18:1			0		1.0
18:1			19:1			0		1.0
19:1			20:1			0		1.0
20:1			21:1			0		1.0
21:1			22:1			0		1.0
22:1			23:1			0		1.0
23:1			24:1			0		1.0
24:1			25:1			0		1.0
25:1			26:1			0		1.0
26:1			27:1			0		1.0
27:1			28:1			0		1.0
28:1			29:1			0		1.0
29:1			30:1			0		1.0
30:1			31:1			0		1.0
31:1			32:1			0		1.0
32:1			33:1			0		1.0
33:1			34:1			0		1.0
34:1			35:1			0		1.0
35:1			36:1			0		1.0

Alignment 5140
It is worth noting that keeping inreasing \MATH may not always give better precision since precision relies on not only \MATH but also the robustness of the region comparision techniques .
It is worth noting that keeping increasing \MATH may not always give better precision , since precision relies on not only \MATH but also the robustness of the region comparison techniques .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:1			27:1			0		1.0
30:1			29:1			0		1.0
31:1			30:1			0		1.0

Alignment 5141
Recommend-Me cannot provide any hit recommendation for around 20\% of initial query images due to the fact that our region comparision technique cannot deal with significant variations of items .
Recommend-Me cannot provide any hit recommendation for around 20\% of the initial query images due to the fact that our region comparison technique cannot deal with significant variations in the items .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
22:1			21:1			0		1.0
23:1			22:1			0		1.0
24:1			23:1			0		1.0
25:1			24:1			0		1.0
26:1			25:1			0		1.0
27:1			26:1			0		1.0
28:3			27:2			3		1.0
31:1			29:1			0		1.0

Alignment 5142
Figure 5( b ) shows another circumstance when we increase \MATH .
Figure 5( b ) shows another circumstance when we increase \MATH .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0

Alignment 5143
It is the decline of efficiency improvement of Recommend-Me .
It is the decline in the efficiency improvement of Recommend-Me .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:3			3:2			3		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0

Alignment 5144
This is because the branch-and-bound algorithm has to visit more parts of the total search space in order to find extra local optimals .
This is because the branch-and-bound algorithm has to visit more parts of the total search space in order to find extra local opitimals .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0
20:1			20:1			0		1.0
21:1			21:1			0		1.0
23:1			23:1			0		1.0

Alignment 5145
However , in all of our evaluations , Recommend-Me still performs around 3 times faster than the exhaustive search .
However , in all of our evaluations , Recommend-Me still performed around three times faster than the exhaustive search .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			1		1.0
11:1			11:1			0		1.0
12:1			12:1			2		1.0
13:1			13:1			0		1.0
14:1			14:1			0		1.0
15:1			15:1			0		1.0
16:1			16:1			0		1.0
17:1			17:1			0		1.0
18:1			18:1			0		1.0
19:1			19:1			0		1.0

Alignment 5146
Its superiority is important for practical applications .
This advantage will be important for practical applications .
Line2Start:Length	Line1Start:Length	Module		Score
2:2			2:1			3		1.0
4:1			3:1			0		1.0
5:1			4:1			0		1.0
6:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0

Alignment 5147
Figure \REF presents examples of hit recommendations returned by our Recommend-Me .
Figure \REF presents examples of hit recommendations returned byRecommend-Me .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
9:1			11:1			0		1.0

Alignment 5148
In this paper , we introduced a new system , named Recommend-Me , for visual query suggestion .
We described oursystem , named Recommend-Me , for making visual query suggestions .
Line2Start:Length	Line1Start:Length	Module		Score
3:1			9:1			0		1.0
4:1			10:1			0		1.0
5:1			11:1			0		1.0
6:1			12:1			0		1.0
7:1			13:1			0		1.0
9:1			14:1			0		1.0
10:1			15:1			0		1.0
11:1			16:1			1		1.0
12:1			17:1			0		1.0

Alignment 5149
Given an initial query image and a retrieved database , Recommend-Me introduces recommendations that imposes which and how frequent items in the initial query image appear in the database .
Given an initial query image and a retrieved database , Recommend-Me gives recommendations that impose conditions on which and how frequent items in the initial query image appear in the database .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
12:1			12:1			0		1.0
13:1			13:1			0		1.0
14:1			14:1			1		1.0
17:1			15:1			0		1.0
18:1			16:1			0		1.0
19:1			17:1			0		1.0
20:1			18:1			0		1.0
21:1			19:1			0		1.0
22:1			20:1			0		1.0
23:1			21:1			0		1.0
24:1			22:1			0		1.0
25:1			23:1			0		1.0
26:1			24:1			0		1.0
27:1			25:1			0		1.0
28:1			26:1			0		1.0
29:1			27:1			0		1.0
30:1			28:1			0		1.0
31:1			29:1			0		1.0

Alignment 5150
Such recommendations support users to select search query , to rapidly refine the initial query image or to explore the database .
Such recommendations help users to select the search query , to rapidly refine the initial query image or to explore the database .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			3		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
7:1			6:1			0		1.0
8:1			7:1			0		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0
11:1			10:1			0		1.0
12:1			11:1			0		1.0
13:1			12:1			0		1.0
14:1			13:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0
19:1			18:1			0		1.0
20:1			19:1			0		1.0
21:1			20:1			0		1.0
22:1			21:1			0		1.0

Alignment 5151
An efficient solution to make Recommend-Me practical is presented .
An efficient solution to make Recommend-Me practical was also presented .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:2			7:1			3		1.0
9:1			8:1			0		1.0
10:1			9:1			0		1.0

Alignment 5152
To the best of our knowledge , Recommend-Me is the first attempt toward its targeted suggestion scheme .
To the best of our knowledge , Recommend-Me is the first attempt at developing a targeted suggestion scheme .
Line2Start:Length	Line1Start:Length	Module		Score
0:1			0:1			0		1.0
1:1			1:1			0		1.0
2:1			2:1			0		1.0
3:1			3:1			0		1.0
4:1			4:1			0		1.0
5:1			5:1			0		1.0
6:1			6:1			0		1.0
7:1			7:1			0		1.0
8:1			8:1			0		1.0
9:1			9:1			0		1.0
10:1			10:1			0		1.0
11:1			11:1			0		1.0
15:1			14:1			0		1.0
16:1			15:1			0		1.0
17:1			16:1			0		1.0
18:1			17:1			0		1.0

