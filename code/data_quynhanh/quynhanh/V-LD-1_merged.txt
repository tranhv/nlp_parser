Generating short summary videos for rushes is a challenging task due to difficulty in redundancy elimination and determination of important objects and events being placed in the summary .
Generating short summary videos for rushes is a challenging task due to the difficulty in eliminating redundancy and determining the important objects and events to be placed in the summary .
3 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:13:preserved 13:14:preserved 14,15:15,16:para-colocation 16:17:preserved 17:18:bigrammar-wform 18::unaligned 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24,25:paraphrase 24:26:preserved 25:27:preserved 26:28:preserved 27:29:preserved 28:30:preserved :12:mogrammar-det :19:mogrammar-det

Redundancy elimination is difficult since repetitive segments , which are takes of the same scene , usually have different lengths and motion patterns .
Redundancy elimination is difficult since repetitive segments , which are takes of the same scene , usually have different lengths and motion patterns .
4 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved

This makes approaches using one keyframe for shot representation failed in doing clustering .
This makes approaches using one keyframe for a shot representation fail when trying to form a cluster .
5 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:8:preserved 8:9:preserved 9:10:bigrammar-vtense 10:11:paraphrase 11,12:12,13,14,15,16:paraphrase :7:mogrammar-det

In addition , even repetitive segments can be determined precisely , the summary generated by concatenating together selected segments still has longer duration than the upper limit .
In addition , even repetitive segments can be precisely determined , but the summary generated by concatenating together the selected segments still takes longer than the upper limit .
6 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:9:preserved 9:8:preserved 10:10:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:19:preserved 18:20:preserved 19:21:preserved 20,22:22:paraphrase 21:23:preserved 23:24:preserved 24:25:preserved 25:26:preserved 26:27:preserved 27:28:preserved :18:mogrammar-det

It is questionable to select a sub-segment so that it conveys information of the scene as much as possible .
It is questionable to select a sub-segment so that it conveys information of the scene as much as possible .
7 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved

In this paper , we introduce two approaches to these problems .
,We introduce two approaches to solve these problems .
8 7,6,5,4:3,2,0,1:preserved 8:4,5:paraphrase 9:6:preserved 10:7:preserved 11:8:preserved

In the first approach , one keyframe is used for shot representation in doing clustering; and sub-segments are selected using motion information for generating the summary .
In the first approach , one keyframe is used for representing a shot when forming a cluster; and sub-segments are selected using the motion information for generating the summary .
9 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:12:preserved 11:10:bigrammar-wform 12:13:paraphrase 13,14:14,15,16:paraphrase 15:17:preserved 16:18:preserved 17:19:preserved 18:20:preserved 19:21:preserved 20:23:preserved 21:24:preserved 22:25:preserved 23:26:preserved 24:27:preserved 25:28:preserved 26:29:preserved :11:mogrammar-det :22:mogrammar-det

Meanwhile , in the second approach , all frames of a shot are used for clustering; and a simple skimming method is used to select sub-segments .
Meanwhile , in the second approach , all the frames of a given shot are used for clustering; and a simple skimming method is used to select the sub-segments .
10 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:13,12:paraphrase 12:14:preserved 13:15:preserved 14:16:preserved 15:17:preserved 16:18:preserved 17:19:preserved 18:20:preserved 19:21:preserved 20:22:preserved 21:23:preserved 22:24:preserved 23:25:preserved 24:26:preserved 25:28:preserved 26:29:preserved :8:mogrammar-det :27:mogrammar-det

Experimental results on the TRECVID 2008 dataset and comparison between the two approaches are reported .
The experimental results on the TRECVID 2008 dataset and a comparison between the two approaches are also reported .
11 0:1:preserved 1:2:preserved 2:3:preserved 3:4:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:10:preserved 9:11:preserved 10:12:preserved 11:13:preserved 12:14:preserved 13:15:preserved 14:17,16:para-freeword 15:18:preserved :0:mogrammar-det :9:mogrammar-det

With the availability of multimedia databases growing at an exponential rate , users are increasingly requiring assistance in accessing digital video contents .
With the availability of multimedia databases growing at an exponential rate , users are increasingly requiring assistance in accessing digital video contents .
16 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved

Video summarization is a significant research that helps to meet these needs by developing a condensed version of a full length digital video with the most important contents \CITE .
Video summarization significantly helps to meet this need by developing a condensed version of a full length digital video using only the most important contents \CITE .
17 0:0:preserved 1:1:preserved 2,3,4,5,6:2:paraphrase 9,8,7:5,4,3:preserved 11,10:7,6:bigrammar-nnum 22,21,20,19,18,17,16,15,14,13,12:18,17,16,15,14,13,12,11,10,9,8:preserved 23:19:paraphrase 24:21:preserved 25:22:preserved 26:23:preserved 27:24:preserved 28:25:preserved 29:26:preserved

Summary videos can help users to browse and navigate large video archives efficiently and effectively .
Summary videos can help users more efficiently and effectively browse and navigate through large video archives .
18 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5::unaligned 6:9:preserved 7:10:preserved 8:11:preserved 11,10,9:15,14,13:preserved 14,13,12:6,7,8:preserved 15:16:preserved :12:mogrammar-prep

Generating summary videos for BBC rushes \CITE is a challenging task due to difficulty in redundancy elimination and determination of important objects and events being placed in the summary .
Generating summary videos for BBC rushes \CITE is a challenging task due to the difficulty with redundancy elimination and determining the most important objects and events to be placed in the summary .
21 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:14:preserved 14:15:bigrammar-prep 15:16:preserved 16:17:preserved 17:18:preserved 18:19:bigrammar-wform 19:20,21:paraphrase 20:22:preserved 21:23:preserved 22:24:preserved 23:25:preserved 24:26,27:bigrammar-wform 25:28:preserved 26:29:preserved 27:30:preserved 28:31:preserved 29:32:preserved :13:mogrammar-det

Since the length of the summary is limited to 2\% duration of the original video , there is a trade-off between recall and usability ( e.g user friendly through smooth presentation , being easy to understand ) .
Since the length of the summary is limited to 2\% duration of the original video , there is a trade-off between the recall and usability ( e.g. user friendly through smooth presentation , / being easy to understand ) .
22 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:26:preserved 26:27:preserved 27:28:preserved 28:29:preserved 29:30:preserved 30:31:preserved 31:32:preserved 32:34:preserved 33:35:preserved 34:36:preserved 35:37:preserved 36:38:preserved 37:39:preserved :21:mogrammar-det

High recall , i.e many objects and events ( called scenes ) are included in the summary , usually reduce the number of frames for each scene .
High recall , i.e. many objects and events ( called scenes ) included in the summary , usually reduces the number of frames for each scene .
23 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12,13:12:para-passact 14:13:preserved 15:14:preserved 16:15:preserved 17:16:preserved 18:17:preserved 19:18:bigrammar-inter 20:19:preserved 21:20:preserved 22:21:preserved 23:22:preserved 24:23:preserved 25:24:preserved 26:25:preserved 27:26:preserved

For example , the maximum duration for the summary of a 30 minute length video is 36 seconds ( \MATH ) .
For example , the maximum duration for a summary of a 30 minute video is 36 seconds ( \MATH ) .
24 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:bigrammar-det 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 14:13:preserved 15:14:preserved 16:15:preserved 17:16:preserved 18:17:preserved 19:18:preserved 20:19:preserved 21:20:preserved

If the summary consists of 20 scenes , the average duration for each scene is 1.8 seconds .
If the summary consists of 20 scenes , the average duration for each scene is 1.8 seconds .
25 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved

For the event such as " `Woman attacks man on bench on left and runs off with large bag .
For an event such as " `Woman attacks man on bench on left and runs off with large bag .
26 0:0:preserved 1:1:bigrammar-det 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved

" ', with this length constraint , it is difficult to present it in a pleasant tempo and rhythm .
" ', with this length constraint , it would be difficult to present it in a pleasant tempo and rhythm .
27 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8,9:bigrammar-vtense 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved

On the contrary , smooth presentation of events consumes a lot number of frames , that decrease the recall .
On the other hand , a smooth presentation of these events would consume a large number of frames , which would decrease the recall .
28 2,0,1:0,1,2,3:paraphrase 3:4:preserved 4:6:preserved 5:7:preserved 6:8:preserved 7:10:preserved 8:11,12:bigrammar-vtense 9,10:13,14:paraphrase 11,12,13:15,16,17:preserved 15:19:bigrammar-others 16:21,20:bigrammar-vtense 18,17:23,22:preserved :5:mogrammar-det :9:mogrammar-det

In general , generating summary videos consists of the following steps :
In general , generating summary videos consists of the following steps :
31 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved

Video segmentation : This step decomposes the original video into segments , such shots or sub-shots .
Video segmentation : This step breaks down the original video into segments , such as shots or sub-shots .
32 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5,6:paraphrase 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13,14:paraphrase 13:15:preserved 14:16:preserved 15:17:preserved 16:18:preserved

Each segment should be aligned such that it is a part of a scene .
Each segment should be aligned so that it is a part of a scene .
33 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:paraphrase 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved

Redundancy elimination : This step groups segments that belong to the same take into clusters .
Redundancy elimination : This step groups the segments that belong to the same take into clusters .
34 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved :6:mogrammar-det

Only one representative segment is used for the final summary video .
Only one representative segment is used for the final summary video .
35 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved

The others are discarded .
The others are discarded .
36 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved

Junk elimination : This step removes color bars , clapboards , all black or all white frames that are unnecessary for the final summary video .
Junk elimination : This step removes the color bars , clapboards , and the all black or all white frames that are unnecessary in the final summary video .
39 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:14:preserved 12:15:preserved 13:16:preserved 14:17:preserved 15:18:preserved 16:19:preserved 17:20:preserved 18:21:preserved 19:22:preserved 20:23:bigrammar-prep 21:24:preserved 22:25:preserved 23:26:preserved 24:27:preserved 25:28:preserved :6:mogrammar-det :13:mogrammar-det

Summary generation : This step selects frames from representative segments of clusters and concatenate to form the final summary video .
Summary generation : This step selects the frames from the representative segments of clusters and concatenates them to form the final summary video .
40 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:7:preserved 7:8:preserved 8:10:preserved 9:11:preserved 10:12:preserved 11:13:preserved 12:14:preserved 13:15:bigrammar-inter 14:17:preserved 15:18:preserved 16:19:preserved 17:20:preserved 18:21:preserved 19:22:preserved 20:23:preserved :6:mogrammar-det :9:mogrammar-det

While the steps of video segmentation and junk elimination are easy to handle , the steps of redundancy elimination and summary generation are difficult .
While the steps for video segmentation and junk elimination are easy to handle , the steps for redundancy elimination and summary generation are difficult .
43 0:0:preserved 1:1:preserved 2:2:preserved 3:3:bigrammar-prep 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:bigrammar-prep 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved

For example , as for redundancy elimination , the question is how to represent a segment into a feature vector and how to compute the similarity between two segments having different length and motion pattern .
For example , as for redundancy elimination , the question is how to represent a segment in a feature vector and how to compute the similarity between two segments having different lengths and motion patterns .
44 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:bigrammar-prep 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:bigrammar-nnum 32:32:preserved 33:33:preserved 34:34:bigrammar-nnum 35:35:preserved

In the other case , assume that we have selected appropriate segments , the total length of these segments are usually larger than that of the final summary .
In the other case , assuming that we have selected the appropriate segments , the total length of these segments is usually larger than that of the final summary .
45 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:bigrammar-wform 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:bigrammar-inter 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:26:preserved 26:27:preserved 27:28:preserved 28:29:preserved :10:mogrammar-det

The question is how to determine the important part of the selected segment such that it conveys information of the scene as much as possible .
The question is how to determine the most important parts of the selected segments so that they convey as much of the information of the scene as possible .
46 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:8:preserved 8:9:bigrammar-nnum 9:10:preserved 10:11:preserved 11:12:preserved 12:13:bigrammar-nnum 13:14:paraphrase 14:15:preserved 15,16:16,17:bigrammar-inter 17:22:preserved 18:23:preserved 20,19:25,24:preserved 21:18:preserved 22:19:preserved 23:26:preserved 24:27:preserved 25:28:preserved :20,21:unaligned

In this paper , we present two approaches for handling these difficult steps .
In this paper , we present two approaches for handling these difficult steps .
49 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved

The first approach represents each segment by one key-frame and groups similar segments by doing clustering on these key-frames .
The first approach represents each segment by using one key-frame and groups similar segments by clustering them on these key-frames .
50 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14::unaligned 15:15:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved

Then the portion of each segment that has high motion is used to include into the final summary .
Then the portion of each segment that has the highest motion is included in the final summary .
51 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8,9:paraphrase 9:10:preserved 10:11:preserved 11,12,13,14:12,13:paraphrase 15:14:preserved 16:15:preserved 17:16:preserved 18:17:preserved

Meanwhile , the second approach uses another strategy for redundancy elimination .
Meanwhile , the second approach uses another strategy for redundancy elimination .
52 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved

Specifically , for each segment , a set of frames are extracted by sampling at a certain time interval ( e.g 5 frames ) .
Specifically , for each segment , a set of frames are extracted by sampling at a certain time interval ( e.g. 5 frames ) .
53 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved

The clustering process is performed on the frames of all segments .
The clustering process is performed on the frames of all the segments .
54 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:11:preserved 11:12:preserved :10:mogrammar-det

Then , the segments that share a large enough number of frames with respect to their size are merged into one cluster .
Then , segments that share a large enough number of frames with respect to their size are merged into one cluster .
55 0:0:preserved 1:1:preserved 2::mogrammar-det 3:2:preserved 4:3:preserved 5:4:preserved 6:5:preserved 7:6:preserved 8:7:preserved 9:8:preserved 10:9:preserved 11:10:preserved 12:11:preserved 13:12:preserved 14:13:preserved 15:14:preserved 16:15:preserved 17:16:preserved 18:17:preserved 19:18:preserved 20:19:preserved 21:20:preserved 22:21:preserved

In order to generate the final summary , with each representative segment , the middle part is selected with the skim rate of 2 frames .
In order to generate the final summary , with each representative segment , the middle part is selected with a skim rate of 2 frames .
56 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:bigrammar-det 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved

This paper is organized as follows : section \REF introduces details of the first approach; , while section \REF presents details of the second approach .
This paper is organized as follows : section \REF introduces the details of the first approach; , while section \REF presents the details of the second approach .
59 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:22:preserved 21:23:preserved 22:24:preserved 23:25:preserved 24:26:preserved 25:27:preserved :10:mogrammar-det :21:mogrammar-det

Section \REF describes experimental results on the TRECVID 2008 dataset .
Section \REF describes our experimental results on the TRECVID 2008 dataset .
60 0:0:preserved 1:1:preserved 2:2:preserved 3:4:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved :3:mogrammar-det

Finally , section \REF and section \REF conclude the paper .
Finally , section \REF and section \REF conclude the paper .
61 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved

From the definition , all rushes are unedited; therefore it must consist of hard cut only .
By definition , all rushes are unedited; therefore they must consist of hard cuts only .
68 0,1:0:paraphrase 2:1:preserved 3:2:preserved 4:3:preserved 5:4:preserved 6:5:preserved 7:6:preserved 8:7:preserved 9:8:bigrammar-nnum 10:9:preserved 11:10:preserved 12:11:preserved 13:12:preserved 14:13:bigrammar-others 15:14:preserved 16:15:preserved

The shot boundary detection algorithm in \CITE is used to determine shot boundary and partition the input video into shots .
The shot boundary detection algorithm in \CITE is used to determine the shot boundary and to partition the input video into shots .
69 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:16:preserved 15:17:preserved 16:18:preserved 17:19:preserved 18:20:preserved 19:21:preserved 20:22:preserved :11:mogrammar-det :15:mogrammar-prep

A local color histogram is extracted by dividing a video frame into \MATH blocks .
A local color histogram is extracted by dividing a video frame into \MATH blocks .
70 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved

The \MATH distance is used to compute the distance between each blocks of frames \MATH and \MATH .
The \MATH distance is used to compute the distance between each block of frames \MATH and \MATH .
71 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:bigrammar-nnum 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved

Next , these values are sorted into an ascending order .
Next , these values are sorted into ascending order .
72 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7::mogrammar-det 8:7:preserved 9:8:preserved 10:9:preserved

The sum of the middle eight of these 16 values are used to define a cut between frames \MATH and \MATH if these values exceed a threshold \MATH .
The sum of the middle eight of these 16 values is used to define the cut between frames \MATH and \MATH if these values exceed the threshold \MATH .
73 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:bigrammar-inter 11:11:preserved 12:12:preserved 13:13:preserved 14:14:bigrammar-det 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 26:26:preserved 27:27:preserved 28:28:preserved :25:mogrammar-det

However , this algorithm cannot distinguish between hard cut and the large objects motion .
However , this algorithm cannot distinguish between hard cuts and the motion of large objects .
74 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:bigrammar-nnum 9:9:preserved 10:10:preserved 11:13:preserved 12:14:preserved 13:11:preserved 14:15:preserved :12:mogrammar-prep

To overcome this problem , motion-based features are computed for each video frame using the Lucas-Kanade point-based tracking functions provided in the OpenCV toolkit\footnote{http : //opencvlibrary.sourceforge.net / } .
To overcome this problem , motion-based features are computed for each video frame using the Lucas-Kanade point-based tracking functions provided in the OpenCV toolkit\footnote{http : //opencvlibrary.sourceforge.net / } .
75 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved

The magnitude is computed from the motion vector for each frame .
The magnitude is computed from the motion vector for each frame .
76 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved

Therefore , if the algorithm detected a cut between frames \MATH and \MATH , whose magnitude is larger than a threshold \MATH , these cuts are rejected since they are motions from large objects .
Therefore , if the algorithm detected a cut between frames \MATH and \MATH , whose magnitude is larger than the threshold \MATH , these cuts are rejected since they are the motions of large objects .
77 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:bigrammar-det 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:31:preserved 31:32:bigrammar-prep 32:33:preserved 33:34:preserved 34:35:preserved :30:mogrammar-det

Finally , the short shots with less than 25 frames ( 1 second ) are removed .
Finally , short shots of less than 25 frames ( 1 second ) are removed .
78 0:0:preserved 1:1:preserved 2::mogrammar-det 3:2:preserved 4:3:preserved 5:4:bigrammar-prep 6:5:preserved 7:6:preserved 8:7:preserved 9:8:preserved 10:9:preserved 11:10:preserved 12:11:preserved 13:12:preserved 14:13:preserved 15:14:preserved 16:15:preserved

The sub-shot segmentation algorithm in \CITE is used to divide shots into smaller units .
The sub-shot segmentation algorithm in \CITE is used to divide shots into smaller units .
83 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved

A first frame of the shot is chosen as the base frame \MATH and next frame \MATH for comparison .
The first frame of the shot is chosen as the base frame \MATH and the next frame \MATH for a comparison .
84 0:0:bigrammar-det 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:20:preserved 19:21:preserved :14:mogrammar-det :19:mogrammar-det

The \MATH distance used to compute the distance of frame sequence until the sum of the sorted value of lower eight is larger than a threshold \MATH .
The \MATH distance used to compute the distance of the frame sequence until the sum of the sorted value of the lower eight is larger than the threshold \MATH . //[distance / length?]
85 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:21:preserved 20:22:preserved 21:23:preserved 22:24:preserved 23:25:preserved 24:20:bigrammar-det 25:27:preserved 26:28:preserved 27:29:preserved :9:mogrammar-det :26:mogrammar-det

The frames from \MATH to \MATH , then , form a sub-shot and frame \MATH is used as the next base frame .
The frames from \MATH to \MATH , then , form a sub-shot and frame \MATH is used as the next base frame .
86 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved

Finally , the short sub-shots with less than 25 frames are removed .
Finally , the short sub-shots of less than 25 frames are removed .
87 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:bigrammar-prep 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved

We employ a keyframe extraction algorithm proposed in \CITE to extract the representative keyframes from each sub-shot .
We use the keyframe extraction algorithm proposed in \CITE to extract the representative keyframes from each sub-shot .
92 0:0:preserved 1:1:paraphrase 2:2:bigrammar-det 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved

In this approach , cosine distance is used to measure the difference between neighboring frames in each sub-shot .
In this approach , the cosine distance is used to measure the difference between neighboring frames in each sub-shot .
93 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved :4:mogrammar-det

Keyframes are selected at the midpoints between two consecutive high curvature points where the high curvature points are detected from the curve of the cumulative frame difference .
Keyframes are selected at the midpoints between two consecutive high curvature points where the high curvature points are detected from the curve of the cumulative frame difference .
94 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved

The characteristics of color bars are vertically averaged , and the color histograms for each block in the same column should be similar .
The characteristics of color bars are vertically averaged , and the color histograms for each block in the same column should be similar .
101 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved

We employ the algorithm proposed in \CITE by using \MATH distance to compute histogram differences between any two neighboring blocks in each column .
We used the algorithm proposed in \CITE by using the \MATH distance to compute the histogram differences between any two neighboring blocks in each column .
102 0:0:preserved 1:1:paraphrase 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:15:preserved 14:16:preserved 15:17:preserved 16:18:preserved 17:19:preserved 18:20:preserved 19:21:preserved 20:22:preserved 21:23:preserved 22:24:preserved 23:25:preserved :9:mogrammar-det :14:mogrammar-det

Next , we sort these values into an ascending order .
Next , we sort these values into ascending order .
103 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 8:7:preserved 9:8:preserved 10:9:preserved

If the value of the \MATH is smaller than threshold \MATH , then these sub-shot is defined as a color bar sub-shot .
If the value of the \MATH is smaller than the threshold \MATH , then these sub-shots are defined as a color bar sub-shot .
104 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:bigrammar-nnum 15:16:bigrammar-inter 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved :9:mogrammar-det

From the properties of single color image , a dominant color in its global histogram is large .
From the properties of a single color image , the dominant color in its global histogram is large .
109 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:bigrammar-det 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved :4:mogrammar-det

If the value of the \MATH of global color histogram is larger than threshold \MATH , then these sub-shots are defined as a single color sub-shot .
If the value of the \MATH of the global color histogram is larger than the threshold \MATH , then these sub-shots are defined as a single color sub-shot .
110 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:15:preserved 14:16:preserved 15:17:preserved 16:18:preserved 17:19:preserved 18:20:preserved 19:21:preserved 20:22:preserved 21:23:preserved 22:24:preserved 23:25:preserved 24:26:preserved 25:27:preserved 26:28:preserved :7:mogrammar-det :14:mogrammar-det

In rushes videos , there are many types of clapper boards , appearance but the same type of clapper boards is often used in the same movie .
In rushes videos , there are many types of clapper boards , but the same type of clapper board is often used in the same movie .
115 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 13:12:preserved 14:13:preserved 15:14:preserved 16:15:preserved 17:16:preserved 18:17:preserved 19:18:bigrammar-nnum 20:19:preserved 21:20:preserved 22:21:preserved 23:22:preserved 24:23:preserved 25:24:preserved 26:25:preserved 27:26:preserved

The clapper boards have many types , such as scale , rotation , and illumination changes .
There are many types of clapper boards , such as scale , rotation , and illumination changes .
116 0::mogrammar-det 1,2:5,6:preserved 3:0,1,4:paraphrase 4:2:preserved 5:3:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved

The NDK algorithm , proposed in \CITE , is invariant to image scaling , translation , rotation , illumination changes , and affine or 3D projection .
The NDK algorithm , proposed in \CITE , is invariant to image scaling , translation , rotation , illumination changes , and affine or 3D projection .
117 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved

A set of 80 example keyframes of clapper boards are extracted from the development set and used as a set of queries .
A set of 80 example keyframes of clapper boards were extracted from the development set and is used as a set of queries .
118 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:bigrammar-vtense 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved

Next , we extract the keypoints of the keyframes given from section \REF and match them with the query .
Next , we extract the keypoints of the keyframes given from section \REF and match them with the query .
119 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved

If a result of the NDK algorithm returns a match between a keyframe with a query then we define the sub-shot is a clapper board sub-shot .
If the result of the NDK algorithm returns a match from a keyframe with a query then the sub-shot is defined as a clapper board sub-shot .
120 0:0:preserved 1:1:bigrammar-det 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:bigrammar-prep 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17,21,18:19,20,21:paraphrase 19:17:preserved 20:18:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved

The unused keyframes containing of story units for generate video summary are removed .
The unused keyframes containing story units for the generated video summary are removed .
126 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4::mogrammar-prep 5:4:preserved 6:5:preserved 7:6:preserved 8:8,7:bigrammar-wform 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved

However , rushes videos containing of repetitive story , such as retake scenes , are unedited .
However , rushes videos containing a repetitive story , such as a retake of scenes , are unedited .
127 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5::mogrammar-prep 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:12:preserved 12:14:preserved 13:15:preserved 14:16:preserved 15:17:preserved 16:18:preserved :5:mogrammar-det :11:mogrammar-det :13:mogrammar-prep

To create the efficiently of rushes videos , the repetitive contents must be eliminated .
To efficiently create rushes videos , the repetitive contents must be eliminated .
128 0:0:preserved 1:2:preserved 2::mogrammar-det 3:1:preserved 4::mogrammar-prep 5:3:preserved 6:4:preserved 7:5:preserved 8:6:preserved 9:7:preserved 10:8:preserved 11:9:preserved 12:10:preserved 13:11:preserved 14:12:preserved

Generally , a group of continuous contents often share some properties .
Generally , a group of continuous contents often share some properties .
129 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved

From this characteristic , clustering technique can be used to separate the data into groups of similar contents .
With this characteristic in mind , a clustering technique can be used to separate the data into groups of similar contents .
130 0:0:bigrammar-prep 1:1:preserved 2:2:preserved 3:5:preserved 4:7:preserved 5:8:preserved 6:9:preserved 7:10:preserved 8:11:preserved 9:12:preserved 10:13:preserved 11:14:preserved 12:15:preserved 13:16:preserved 14:17:preserved 15:18:preserved 16:19:preserved 17:20:preserved 18:21:preserved :6:mogrammar-det

Each group , called cluster , consists of contents that are similar between themselves and dissimilar to contents of other groups .
Each group , called a cluster , consists of contents that are similar between themselves and dissimilar to the contents of other groups .
131 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:19:preserved 18:20:preserved 19:21:preserved 20:22:preserved 21:23:preserved :4:mogrammar-det :18:mogrammar-det

GreedyRSC , proposed in \CITE , is used to find clusters with high precision and the number of clusters is automatically determined .
GreedyRSC , proposed in \CITE , is used to find clusters at high precision and the number of clusters is automatically determined .
132 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:bigrammar-prep 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved

To do the clustering on keyframes , three different features , including mean , variance , and skewness , are extracted from local color histogram .
To do clustering on keyframes , three different features , including the mean , variance , and skew , are extracted from the local color histogram .
135 0:0:preserved 1:1:preserved 2::mogrammar-det 3:2:preserved 4:3:preserved 5:4:preserved 6:5:preserved 7:6:preserved 8:7:preserved 9:8:preserved 10:9:preserved 11:10:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:bigrammar-wform 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:26:preserved :11:mogrammar-det :22:mogrammar-det

These values are used to represent the keyframes content and defined as follows :
These values are used to represent the keyframes content and are defined as follows :
136 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved

Figure \REF shows an example of clustering result .
Figure \REF shows an example of a clustering result .
138 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:7:preserved 7:8:preserved 8:9:preserved :6:mogrammar-det

So far , we completely remove the unused contents from rushes video and reduce repetition of the story contents .
So far , we have completely removed the unused contents from rushes videos and reduced any repetition of the story contents .
143 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:5:preserved 5,13:4,6,14:bigrammar-vtense 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:bigrammar-others 12:13:preserved 14:16:preserved 15:17:preserved 16:18:preserved 17:19:preserved 18:20:preserved 19:21:preserved

The objective of rushes summarization at TRECVID 2008 is to generate short summaries ( the upper limit of the duration of summary is 2\% of the original video ) , less repetitive of content , and must have many objects and events as possible .
The objective of rushes summarization at TRECVID 2008 is to generate short summaries ( the upper limit of the duration of a summary is 2\% of the original video ) , less repetitive content , and must have as many objects and events as possible .
144 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:26:preserved 26:27:preserved 27:28:preserved 28:29:preserved 29:30:preserved 30:31:preserved 31:32:preserved 32::mogrammar-prep 33:33:preserved 34:34:preserved 35:35:preserved 36:36:preserved 37:37:preserved 38:39:preserved 39:40:preserved 40:41:preserved 41:42:preserved 42:43:preserved 43:44:preserved 44:45:preserved :21:mogrammar-det :38:mogrammar-prep

To reach this objective , the important keyframes should be selected to generate summary video .
To reach this objective , only the most important keyframes should be selected to generate a summary video .
145 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:6:preserved 6:8:preserved 7:9:preserved 8:10:preserved 9:11:preserved 10:12:preserved 11:13:preserved 12:14:preserved 13:16:preserved 14:17:preserved 15:18:preserved :15:mogrammar-det

To generate summary , we first compute its maximum duration in seconds \MATH ,
To generate a summary , we first compute its maximum duration in seconds \MATH ,
148 0:0:preserved 1:1:preserved 2:3:preserved 3:4:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved :2:mogrammar-det

where \MATH is the maximum duration for the summary .
where \MATH is the maximum duration for the summary .
149 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved

Second , we compute quota length for each cluster based on the cluster size \MATH .
Second , we compute the quota length for each cluster based on the cluster size \MATH .
151 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved :4:mogrammar-det

Third , merge consecutive sub-shots in each cluster into shots and compute the priority of each shot based on priority of shot weighted duration and shot weighted average motion magnitude using the following equation : \MATH</p>
Third , merge the consecutive sub-shots in each cluster into shots and compute the priority of each shot based on the priority of the shot weighted duration and shot weighted average motion magnitude using the following equation : \MATH</p>
154 0:0:preserved 1:1:preserved 2:2:preserved 3:4:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:21:preserved 20:22:preserved 21:24:preserved 22:25:preserved 23:26:preserved 24:27:preserved 25:28:preserved 26:29:preserved 27:30:preserved 28:31:preserved 29:32:preserved 30:33:preserved 31:34:preserved 32:35:preserved 33:36:preserved 34:37:preserved 35:38:preserved :3:mogrammar-det :20:mogrammar-det :23:mogrammar-det

Next , these \MATH values are sorted into descending order and the first shot is selected .
Next , these \MATH values are sorted into descending order and the first shot is selected .
156 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved

Forth , sort sub-shots in the selected shot in descending order based on the average motion magnitude .
Fourth , sub-shots in the selected shot in descending order are sorted based on the average motion magnitude .
159 0:0:spelling 1:1:preserved 2:11,10:paraphrase 3:2:preserved 4:3:preserved 5:4:preserved 6:5:preserved 7:6:preserved 8:7:preserved 9:8:preserved 10:9:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved

Select sub-shots from top to bottom until the quota length for that shot is reached .
The sub-shots are selected from top to bottom until the quota length for that shot is reached .
160 0:2,3:paraphrase 1:1:preserved 2:4:preserved 3:5:preserved 4:6:preserved 5:7:preserved 6:8:preserved 7:9:preserved 8:10:preserved 9:11:preserved 10:12:preserved 11:13:preserved 12:14:preserved 13:15:preserved 14:16:preserved 15:17:preserved :0:mogrammar-det

Fifth , for each selected sub-shot , extract 25 frames ( 1 second ) around the middle to generate the final summary .
Fifth , for each selected sub-shot , 25 frames ( 1 second ) around the middle are extracted to generate the final summary .
163 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:16,17:paraphrase 8:7:preserved 9:8:preserved 10:9:preserved 11:10:preserved 12:11:preserved 13:12:preserved 14:13:preserved 15:14:preserved 16:15:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved

This system is adopted with some modifications from the system developed for the same task last year \CITE .
This system has some modifications from the system developed for the same task last year \CITE .
168 0:0:preserved 1:1:preserved 2,3,4:2:paraphrase 5:3:preserved 6:4:preserved 7:5:preserved 8:6:preserved 9:7:preserved 10:8:preserved 11:9:preserved 12:10:preserved 13:11:preserved 14:12:preserved 15:13:preserved 16:14:preserved 17:15:preserved 18:16:preserved

Specifically , the original video is decomposed into segments , which are shots with hard cut transition .
Specifically , the original video is broken down into segments , which are shots with a hard cut transition .
169 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6,7:paraphrase 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:16:preserved 15:17:preserved 16:18:preserved 17:19:preserved :15:mogrammar-det

These segments are further decomposed into fragments so that each fragment represents a portion of a scene .
These segments are further broken down into fragments so that each fragment represents a portion of a scene .
170 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4,5:paraphrase 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved

In order to reduce the computation time , we only extract a subset of frames from the original video by sampling at a five frame interval ( i.e extract frames 0th , 5th , 10th , and so on ) .
In order to reduce the computation time , we only extract a subset of the frames from the original video by sampling it at a five frame interval ( i.e. extract frames 0 , 5th , 10th , and so on ) .
171 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:23:preserved 22:24:preserved 23:25:preserved 24:26:preserved 25:27:preserved 26:28:preserved 27:29:preserved 28:30:preserved 29:31:preserved 30:32:spelling 31:33:preserved 32:34:preserved 33:35:preserved 34:36:preserved 35:37:preserved 36:38:preserved 37:39:preserved 38:40:preserved 39:41:preserved 40:42:preserved :14:mogrammar-det

For each frame , we use grid color moments with the same configuration as in \CITE for feature representation .
For each frame , we use grid color moments with the same configuration as in \CITE for feature representation .
172 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved

The segment boundary , which is located at hard cut transition , is determined by using a loose threshold on the Euclidean distance between two consecutive frames .
The segment boundary , which is located at the hard cut transition , is determined by using a loose threshold on the Euclidean distance between two consecutive frames .
173 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:26:preserved 26:27:preserved 27:28:preserved :8:mogrammar-det

Meanwhile , the fragment boundary is determined by using a strict threshold to detect dramatic motion .
Meanwhile , the fragment boundary is determined by using a strict threshold to detect any dramatic motion .
174 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:15:preserved 15:16:preserved 16:17:preserved

Instead of selecting one keyframe to represent one fragment as many other systems do , we use all frames of each fragment for redundancy elimination .
Instead of selecting one keyframe to represent one fragment as many other systems do , we use all the frames of each fragment for the redundancy elimination .
179 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:25:preserved 24:26:preserved 25:27:preserved :18:mogrammar-det :24:mogrammar-det

We use GreedyRSC \CITE to do clustering on the set of all sampled frames extracted from the original video .
We use GreedyRSC \CITE to do the clustering on the set of all the sampled frames extracted from the original video .
180 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:14:preserved 13:15:preserved 14:16:preserved 15:17:preserved 16:18:preserved 17:19:preserved 18:20:preserved 19:21:preserved :6:mogrammar-det :13:mogrammar-det

The number of clusters is determined automatically by this method .
The number of clusters is determined automatically using this method .
181 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:paraphrase 8:8:preserved 9:9:preserved 10:10:preserved

Frames that belong to the same cluster are assigned the same label .
Frames that belong to the same cluster are assigned the same label .
182 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved

By this discretization process , we can cast one fragment as one string whose characters are labels of its frames .
By this discretization process , we can cast one fragment as one string whose characters are the labels of its frames .
183 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved :16:mogrammar-det

We compute the similarity value between two fragments by counting the number of shared characters between two strings and being normalized to the size of each string .
We compute the similarity between two fragments by counting the number of shared characters between two strings and being normalized to the size of each string .
184 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 5:4:preserved 6:5:preserved 7:6:preserved 8:7:preserved 9:8:preserved 10:9:preserved 11:10:preserved 12:11:preserved 13:12:preserved 14:13:preserved 15:14:preserved 16:15:preserved 17:16:preserved 18:17:preserved 19:18:preserved 20:19:preserved 21:20:preserved 22:21:preserved 23:22:preserved 24:23:preserved 25:24:preserved 26:25:preserved 27:26:preserved

If this value is larger than a threshold , these two segments are merged into one cluster .
If this value is larger than the threshold , these two segments are merged into one cluster .
185 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:bigrammar-det 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved

We found that this approach is more effective than the approach using one keyframe for one fragment since the more number of keyframes is used , the more information is available to make right decision .
We found that this approach is more effective than the approach using one keyframe for one fragment since the more keyframes that are used , the more information is available to make the right decision .
186 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 22:20:preserved 23:21,22:paraphrase 24:23:preserved 25:24:preserved 26:25:preserved 27:26:preserved 28:27:preserved 29:28:preserved 30:29:preserved 31:30:preserved 32:31:preserved 33:33:preserved 34:34:preserved 35:35:preserved :32:mogrammar-det

We select junk frames such as color bar frames , single color ( black or white ) frames to form the reference junk frame set .
We select junk frames such as color bar frames , and single color ( black or white ) frames to form the reference junk frame set .
191 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:26:preserved

To check whether a fragment is a junk , we compare the frames of this fragment to the frames of the reference junk frame set .
To check whether a fragment is junk , we compare the frames of this fragment to the frames of the reference junk frame set .
192 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6::mogrammar-det 7:6:preserved 8:7:preserved 9:8:preserved 10:9:preserved 11:10:preserved 12:11:preserved 13:12:preserved 14:13:preserved 15:14:preserved 16:15:preserved 17:16:preserved 18:17:preserved 19:18:preserved 20:19:preserved 21:20:preserved 22:21:preserved 23:22:preserved 24:23:preserved 25:24:preserved

The similarity between two frames is the Euclidean distance between two grid color moment feature vectors .
The similarity between two frames is the Euclidean distance between two grid color moment feature vectors .
193 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved

We empirically select thresholds for each type of junk .
We empirically select the thresholds for each type of junk .
194 0:0:preserved 1:1:preserved 2:2:preserved 3:4:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved :3:mogrammar-det

If the similarity between one frame in the input fragment and one frame in the reference junk frame set is lower than the predefined thresholds, the input fragment is considered as junk and all fragments of the cluster containing junk fragment are eliminated .
If the similarity between one frame in the input fragment and one frame in the reference junk frame set is lower than the predefined thresholds, the input fragment is considered junk and all the fragments of the cluster containing the junk fragment are eliminated .
195 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 31:30:preserved 32:31:preserved 33:32:preserved 34:34:preserved 35:35:preserved 36:36:preserved 37:37:preserved 38:38:preserved 39:40:preserved 40:41:preserved 41:42:preserved 42:43:preserved 43:44:preserved :33:mogrammar-det :39:mogrammar-det

In our system, we only check fragments that are located at two ends of the original video for reducing computation time .
In our system, we only check the fragments that are located at the two ends of the original video for reducing the computation time .
196 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:13:preserved 12:14:preserved 13:15:preserved 14:16:preserved 15:17:preserved 16:18:preserved 17:19:preserved 18:20:preserved 19:22:preserved 20:23:preserved 21:24:preserved :6:mogrammar-det :12:mogrammar-det :21:mogrammar-det

However, by using the clustering result, junk fragments that are not checked against the reference junk frame set are also removed .
However, by using the clustering result, junk fragments that are not checked against the reference junk frame set are also removed .
197 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved

For each cluster, we merge adjacent fragments into longer fragments and select the longest fragment as the representative fragment to be included in the final summary .
For each cluster, we merge adjacent fragments into longer fragments and select the longest fragment as the representative fragment to be included in the final summary .
202 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved

Since the length of these fragments is still larger than the maximum length of the final summary, we employ a simple strategy to shrink these fragments as follows .
Since the length of these fragments is still larger than the maximum length of the final summary, we use the following simple strategy to shrink these fragments .
203 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:paraphrase 19:19:bigrammar-det 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:26:preserved 26,27:20:paraphrase 28:27:preserved

First, we assign a quota, which is the maximum duration, for each fragment by dividing the maximum duration for the summary to the number of clusters .
First, we assign a quota, which is the maximum duration, for each fragment by dividing the maximum duration for the summary to the number of clusters .
206 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved

Second, for each fragment, we extract the portion which is expanded from the central of the fragment .
Second, for each fragment, we extract the portion that is expanded from the central part of the fragment .
209 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:bigrammar-others 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13,14:paraphrase 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved

This portion covers a duration twice as much as the fragment quota by selecting frames with sampling rate of 2 frames .
This portion covers a duration twice the size of the fragment quota by selecting the frames with a sampling rate of two frames .
210 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 9:6,7,8,9:paraphrase 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:15:preserved 15:16:preserved 16:18:preserved 17:19:preserved 18:20:preserved 19:21:spelling 20:22:preserved 21:23:preserved :14:mogrammar-det :17:mogrammar-det

Specifically, we select frames \MATH, \MATH, ..., \MATH, \MATH, ..., \MATH, \MATH, where \MATH is the middle frame of the fragment, and \MATH is half of number of frames computed from the quota\MATH and frame rate ( 25fps ) \MATH :
Specifically, we select frames \MATH, \MATH, ..., \MATH, \MATH, ..., \MATH, \MATH, where \MATH is the middle frame of the fragment, and \MATH is half the number of frames computed from the quota\MATH and the frame rate ( 25fps ) \MATH :
211 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25::mogrammar-prep 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:35:preserved 35:36:preserved 36:37:preserved 37:38:preserved 38:39:preserved 39:40:preserved 40:41:preserved :25:mogrammar-det :34:mogrammar-det

We have tested our approaches with 40 videos of TRECVID 2008 test set .
We have tested our approaches on 40 videos from the TRECVID 2008 test set .
215 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:bigrammar-prep 6:6:preserved 7:7:preserved 8:8:bigrammar-prep 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved :9:mogrammar-det

Table \REF shows a comparison between these approaches for the measures used in evaluation of this task \CITE .
Table \REF presents a comparison between these approaches for the measures used in evaluation of this task \CITE .
216 0:0:preserved 1:1:preserved 2:2:paraphrase 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved

The system NII-2 achieves higher recall ( IN ) than the system NII-1 since NII-1 only uses one keyframe for each sub-shot and has shorter duration ( DU ) for summary videos .
The NII-2system achieves a higher recall ( IN ) than the NII-1 system because NII-1 only uses one keyframe for each sub-shot and has a shorter duration ( DU ) for summary videos .
217 0:0:preserved 1,2:1:para-colocation 3:2:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:12:preserved 12:14:preserved 13:13:paraphrase 14:11:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:25:preserved 25:26:preserved 26:27:preserved 27:28:preserved 28:29:preserved 29:30:preserved 30:31:preserved 31:32:preserved 32:33:preserved :3:mogrammar-det :24:mogrammar-det

However, NII-1 has a better score in quality .
However, NII-1 has better quality .
218 0:0:preserved 1:1:preserved 2:2:preserved 3,5,6::unaligned 4:3:preserved 7:4:preserved 8:5:preserved

The summary videos generated by NII-1 have fewer duplications ( RE ), are presented in a smoother way ( TE ) and are easy to judge for inclusions ( TT ) .
The summary videos generated by NII-1 have less duplication ( RE ), are presented in a smoother way ( TE ), and are easy to judge for inclusions ( TT ) .
219 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:paraphrase 8:8:bigrammar-nnum 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved

In terms of efficiency, NII-2 is much better .
In terms of efficiency, NII-2 is much better .
222 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved

The clapper board detection process using NDK consumes around half of processing time of NII-1 but performance is low due to large variations of clapper boards in videos ( see Figure \REF ) .
The clapper board detection process using NDK consumes around half of the processing time of NII-1, but its performance is low due to the large variations in clapper boards in the videos ( see Figure \REF ) .
223 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:18:preserved 17:19:preserved 18:20:preserved 19:21:preserved 20:22:preserved 21:24:preserved 22:25:preserved 23:26:bigrammar-prep 24:27:preserved 25:28:preserved 26:29:preserved 27:31:preserved 28,29,30,31,32:32,33,34,35,36:preserved :11:mogrammar-det :17:mogrammar-det :23:mogrammar-det :30:mogrammar-det

The comparable performance in junk elimination of both systems suggests that simple methods are more favorable .
The comparable performance in the junk elimination of both systems suggests that simpler methods are more favorable .
224 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:spelling 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved :4:mogrammar-det

In addition, by using simple features and sampling frames in the original video, NII-2 significantly speeds up the processing time ( computed from the time taking the input video to the time picking the summary video ) to quasi real-time .
In addition, by using simple features and sampling frames in the original video, NII-2 significantly increases the processing time ( computed from the time the input video is taken to the time the summary video is picked ) to quasi real-time .
225 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15,16:15:paraphrase 17:16:preserved 18:17:preserved 19:18:preserved 20:19:preserved 21:20:preserved 22:21:preserved 23:22:preserved 24:23:preserved 25:27,28:paraphrase 26:24:preserved 27:25:preserved 28:26:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:35,36:paraphrase 33:32:preserved 34:33:preserved 35:34:preserved 36:37:preserved 37:38:preserved 38:39:preserved 39:40:preserved 40:41:preserved

Practical summarization systems usually have good balance between fraction of inclusions and user-friendliness .
Practical summarization systems usually have a good balance between the fraction of inclusions and user-friendliness .
228 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:10:preserved 9:11:preserved 10:12:preserved 11:13:preserved 12:14:preserved 13:15:preserved :5:mogrammar-det :9:mogrammar-det

In Table \REF, we show performance of such systems .
In Table \REF, we present the performance of such systems .
229 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:paraphrase 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved :5:mogrammar-det

The 14 systems listed in this table have IN score larger than the median ( 0.45 ); and other scores such as RE and TE larger than half of maximum score ( 2.5 ) .
The 14 systems listed in this table have an IN score that is above the median ( 0.45 ); and other scores, such as RE and TE, are larger than half of the maximum score ( 2.5 ) .
230 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:9:preserved 9:10:preserved 10,11:11,12,13:paraphrase 12:14:preserved 13:15:preserved 14:16:preserved 15:17:preserved 16:18:preserved 17:19:preserved 18:20:preserved 19:21:preserved 20:22:preserved 21:23:preserved 22:24:preserved 23:25:preserved 24:26:preserved 25:28:preserved 26:29:preserved 28,27:31,30:preserved 29,30:33,34:preserved 31,32,33:35,36,37:preserved :8:mogrammar-det :32:mogrammar-det

Compared to other systems listed in this list, our system NII-2 is one of the fastest systems .
Compared to the other systems listed in this table, our NII-2system is one of the fastest .
231 0:0:preserved 1:1:preserved 2:3:preserved 3:4:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:paraphrase 8:9:preserved 9,10:10:para-colocation 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 17:16:preserved :2:mogrammar-det

Compared to the other systems participating in this task of TRECVID 2008, NII-1 has good performance in measures such as DU and TT ( see Figure \REF and Figure \REF; while NII-2 achieves good performance in measure IN ( see Figure \REF ) .
Compared to the other systems participating in this task of TRECVID 2008, NII-1 performed better in such measures as DU and TT ( see Figure \REF and Figure \REF; while NII-2 performs well in the IN measure ( see Figure \REF ) .
234 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13,14,15:13,14:paraphrase 16:15:preserved 17:17:preserved 18:16:preserved 19:18:preserved 20:19:preserved 21:20:preserved 22:21:preserved 23:22:preserved 24:23:preserved 25:24:preserved 26:25:preserved 27:26:preserved 28:27:preserved 29:28:preserved 30:29:preserved 31:30:preserved 32,33,34:31,32:paraphrase 35:33:preserved 36:36:preserved 37:35:preserved 38:37:preserved 39:38:preserved 40:39:preserved 41:40:preserved 42:41:preserved 43:42:preserved :34:mogrammar-det

One of most difficult steps is redundancy elimination .
One of the most difficult steps is redundancy elimination .
239 0:0:preserved 1:1:preserved 2:3:preserved 3:4:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved :2:mogrammar-det

Lack of discriminative representation of segments and robust clustering methods is the main reason \CITE .
The lack of discriminative representation of the segments and robust clustering methods is the main reason \CITE .
240 0:1:preserved 1:2:preserved 2:3:preserved 3:4:preserved 4:5:preserved 5:7:preserved 6:8:preserved 7:9:preserved 8:10:preserved 9:11:preserved 10:12:preserved 11:13:preserved 12:14:preserved 13:15:preserved 14:16:preserved 15:17:preserved :0:mogrammar-det :6:mogrammar-det

Two typical cases that usually happen in clustering result are fragmentation and outliers .
Two typical cases that usually happen in clustering results are fragmentation and outliers .
241 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:bigrammar-nnum 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved

Fragmentation is the case that samples of one cluster are put into several different clusters .
Fragmentation is where samples of one cluster are put into several different clusters .
242 0:0:preserved 1:1:preserved 2,3,4:2:paraphrase 5:3:preserved 6:4:preserved 7:5:preserved 8:6:preserved 9:7:preserved 10:8:preserved 11:9:preserved 12:10:preserved 13:11:preserved 14:12:preserved 15:13:preserved

Outliers are irrelevant and noisy samples in one cluster due to poor determination of cluster boundary .
Outliers are irrelevant and noisy samples in one cluster due to the poor determination of the cluster boundary .
243 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:16:preserved 15:17:preserved 16:18:preserved :11:mogrammar-det :15:mogrammar-det

Therefore, it is necessary to develop robust methods for detection of repetitive segments .
Therefore, it is necessary to develop robust methods for detecting repetitive segments .
244 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9,10:9:paraphrase 11:10:preserved 12:11:preserved 13:12:preserved

Using all frames of one segment instead of using one keyframe as proposed in NII-2 is one of the efforts toward this direction .
Using all the frames of one segment instead of using one keyframe as proposed in NII-2 is one of the current efforts being made towards this end .
245 0:0:preserved 1:1:preserved 2:3:preserved 3:4:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:21:preserved 20:24:bigrammar-prep 21:25:preserved 22:26:paraphrase :2:mogrammar-det

Although the result is not very high as expected, we still believe that this approach is promising .
Although the results are not as high as expected, we still believe that this approach is promising .
246 0:0:preserved 1:1:preserved 2:2:bigrammar-nnum 3:3:bigrammar-inter 4:4:preserved 5:5:paraphrase 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved

We have presented two different approaches for generating short summary for rushes video .
We have presented two different approaches for generating a short summary for rushes videos .
251 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:bigrammar-nnum 13:14:preserved

In the first approach, NII-1, redundancy elimination is done by doing clustering on the set of keyframes extracted from sub-shots .
In the first approach, NII-1, clustering the set of keyframes extracted from the sub-shots helps to eliminate redundancy .
252 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:17:preserved 7,8,9,10,6:14,15,16:paraphrase 11:5:preserved 12::mogrammar-prep 14,15,16,13,17,18,19:6,7,8,9,10,11,13:preserved 20:18:preserved :12:mogrammar-det

With each representative segment of each cluster, the portion that has high degree of motion is selected to form the summary .
With each representative segment of each cluster, the portion with the highest degree of motion is selected to form the summary .
253 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9,10:9,10:paraphrase 11:11:bigrammar-wform 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved

This approach achieves good performance in usability score but low performance in recall .
This approach has a good usability score but is not very good at recall .
254 0:0:preserved 1:1:preserved 2,4,5,3:2,3,4:paraphrase 6,7:6,5:preserved 8:7:preserved 11,9,10:12,11,10,9,8:paraphrase 12:13:preserved 13:14:preserved

In the second approach, NII-2, all frames of each sub-shot are used to compute the similarity among sub-shots in clustering process .
In the second approach, NII-2, all the frames of each sub-shot are used to compute the similarity among the sub-shots in the clustering process .
255 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:19:preserved 18:20:preserved 19:22:preserved 20:23:preserved 21:24:preserved :6:mogrammar-det :18:mogrammar-det :21:mogrammar-det

With each representative segment of each cluster, the middle part is selected to form the summary with skipping rate of 2 frames .
With each representative segment of each cluster, the middle part is selected to form the summary with a skipping rate of two frames .
256 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:spelling 21:22:preserved 22:23:preserved :17:mogrammar-det

This approach achieves good performance in recall and reasonable performance in usability score .
This approach is good for recall and has a reasonably good usability score .
257 0:0:preserved 1:1:preserved 2,4,5,8,9,10:2,4,7,8,9,10:paraphrase 3:3:preserved 6:5:preserved 7:6:preserved 11:11:preserved 12:12:preserved 13:13:preserved

Compared to other systems participating in TRECVID 2008 summarization task, NII-2 is among best systems that have good balance between recall and usability .
Compared to other systems participating in the TRECVID 2008 summarization task, NII-2 is among the best systems with a good balance between recall and usability .
258 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:15:preserved 14:16:preserved 15,16:17:paraphrase 17:19:preserved 18:20:preserved 19:21:preserved 20:22:preserved 21:23:preserved 22:24:preserved 23:25:preserved :6:mogrammar-det :14:mogrammar-det :18:mogrammar-det

