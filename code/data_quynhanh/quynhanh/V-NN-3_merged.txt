The success of corpus-based methods has made syntactically annotated corpora important resources for natural language processing .
Syntactically annotated corpora have become important resources for natural language processing , due in part to the success of corpus-based methods .
3 0,1,2,3,4:16,17,18,19,20:preserved 5,6:12,13,14,15,4,3:para-freeword 7,8,9:0,1,2:preserved 15,14,13,12,11,10:9,10,5,6,7,8:preserved

Since words are often considered as the primitive units of language structures , the annotation of word segmentation forms the basis of these corpora .
Since words are often considered as primitive units of language structures , the annotation of word segmentation forms the basis of these corpora .
4 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6::mogrammar-det 7:6:preserved 8:7:preserved 9:8:preserved 10:9:preserved 11:10:preserved 12:11:preserved 13:12:preserved 14:13:preserved 15:14:preserved 16:15:preserved 17:16:preserved 18:17:preserved 19:18:preserved 20:19:preserved 21:20:preserved 22:21:preserved 23:22:preserved 24:23:preserved

This is also a concern of Vietnamese Treebank ( VTB ) , the first and the only publicly available syntactically annotated corpus so far for the Vietnamese language .
This is also a concern for the Vietnamese Treebank ( VTB ) , which is the first and only publicly available syntactically annotated corpus thus far for the Vietnamese language .
5 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:bigrammar-prep 6,7:7,8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12,13,14:paraphrase 12:15:preserved 13:16:preserved 14:17:preserved 15::mogrammar-det 16:18:preserved 17:19:preserved 18:20:preserved 19:21:preserved 20:22:preserved 21:23:preserved 22:24:paraphrase 23:25:preserved 24:26:preserved 25:27:preserved 26:28:preserved 27:29:preserved 28:30:preserved :6:mogrammar-det

Although word segmentation is straight-forward for space-delimited languages like English , this is not true for languages like Vietnamese of which no standard criterion for word segmentation exists .
Although word segmentation is straight-forward for space-delimited languages like English , this is not the case for languages like Vietnamese for which a standard criterion for word segmentation does not exist .
6 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14,15:paraphrase 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:bigrammar-prep 20:21:preserved 21,27:22,28,29,30:paraphrase 22:23:preserved 23:24:preserved 24:25:preserved 25:26:preserved 26:27:preserved 28:31:preserved

This work explores the challenges of Vietnamese word segmentation through the detection and correction of inconsistency for VTB .
This work explores the challenges of Vietnamese word segmentation through the detection and correction of inconsistency for VTB .
7 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved

Then , by combining and splitting the inconsistent annotations detected , we could observe the influence of different word segmentation criteria on automatic word segmentation , and the applications of word segmentation , including text classification and English-Vietnamese statistical machine translation .
Then , by combining and splitting the inconsistent annotations that were detected , we are able to observe the influence of different word segmentation criteria on automatic word segmentation , and the applications of word segmentation , including text classification and English-Vietnamese statistical machine translation .
8 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8,9:9,8,10,11:paraphrase 10:12:preserved 11:13:preserved 12:14,15,16:paraphrase 13:17:preserved 14,15,16,17,18,19,20,21,22,23,24,26,27,28,29,30,31,32,25,33,34,35,36,37,38,39,40:44,43,42,41,40,39,38,37,36,35,34,33,32,31,29,28,27,26,25,24,23,18,19,20,21,22,30:preserved

The analysis and experimental results showed that our methods improved the quality of VTB , which positively affected the performance of its applications .
The analysis and experimental results showed that our methods improved the quality of VTB , which positively affected the performance of its applications .
9 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved

Treebanks , corpora annotated with syntatic structures , have become more and more impor-tant for language processing .
Treebanks , which are corpora annotated with syntactic structures , have become more and more important for language processing .
14 0:0:preserved 1:1,2,3:paraphrase 2:4:preserved 3:5:preserved 4:6:preserved 5:7:preserved 6:8:preserved 7:9:preserved 8:10:preserved 9:11:preserved 10:12:preserved 11:13:preserved 12:14:preserved 13:15:preserved 14:16:preserved 15:17:preserved 16:18:preserved 17:19:preserved

To strengthen the automatic processing of the Vietnamese language , the Vietnamese treebank ( VTB ) has been built as a part of the national project `` Vietnamese language and speech processing ( VLSP ) '' ( Nguyen et al ., 2009b ) .
In order to strengthen the automatic processing of the Vietnamese language , the Vietnamese Treebank ( VTB ) has been built as a part of the national project , `` Vietnamese language and speech processing ( VLSP ) '' ( Nguyen et al ., 2009b ) .
15 0:0,1,2:paraphrase 1:3:preserved 2:4:preserved 3:5:preserved 4:6:preserved 5:7:preserved 6:8:preserved 7:9:preserved 8:10:preserved 9:11:preserved 10:12:preserved 11:13:preserved 12:14:preserved 13:15:preserved 14:16:preserved 15:17:preserved 16:18:preserved 17:19:preserved 18:20:preserved 19:21:preserved 20:22:preserved 21:23:preserved 22:24:preserved 23:25:preserved 24:26:preserved 25:27:preserved 26:29:preserved 27:30:preserved 28:31:preserved 29:32:preserved 30:33:preserved 31:34:preserved 32:35:preserved 33:36:preserved 34:37:preserved 35:38:preserved 36:39:preserved 37:40:preserved 38:41:preserved 39:42:preserved 40:43:preserved 41:44:preserved 42:45:preserved 43:46:preserved

However , in our preliminary experiment with VTB , when we trained the Berkeley parser ( Petrov et al ., 2006 ) and evaluated it using the corpus , the parser achieved only 65 .8% in F-score .
However , in our preliminary experiment with VTB , when we trained the Berkeley parser ( Petrov et al ., 2006 ) and evaluated it by using the corpus , the parser achieved only 65 .8% in F-score .
16 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:26:preserved 26:27:preserved 27:28:preserved 28:29:preserved 29:30:preserved 30:31:preserved 31:32:preserved 32:33:preserved 33:34:preserved 34:35:preserved 35:36:preserved 36:37:preserved 37:38:preserved :25:mogrammar-prep

This performance is far lower than the state-of-the-art performance reported for Berkeley Parser on English Penn Treebank , 90 .3% in F-score ( Petrov et al ., 2006 ) .
This score is far lower than the state-of-the-art performance reported for the Berkeley Parser on the English Penn Treebank , which reported 90 .3% in F-score ( Petrov et al ., 2006 ) .
17 0:0:preserved 1:1:paraphrase 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:16:preserved 15:17:preserved 16:18:preserved 17:19,20,21:paraphrase 18,19,20,21,22,23,24,25,26,27,28,29:22,23,24,25,26,27,28,29,30,31,32,33:preserved :11:mogrammar-det :15:mogrammar-det

There are two possible reasons for this .
There are two possible reasons to explain this outcome .
18 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5,6:paraphrase 6:7,8:paraphrase 7:9:preserved

First , the quality of VTB is not good enough to build a good a parser , including the quality of the annotation scheme , the annotation guidelines , and the annotation process .
One reason for this outcome is the quality of VTB , including the quality of the annotation scheme , the annotation guidelines , and the annotation process .
19 0::unaligned 2,3,4,5:6,7,8,9:preserved 6,7,8,9,10,11,12,13,14,15:0,2,3,4,5,1:paraphrase 16::unaligned 17,18,19,20,21,22,23,25,26,24,27,28,29,31,30,32:15,11,12,13,14,16,17,18,19,20,21,22,23,24,25,26,27:preserved

Second , parsing Vietnamese is a diffcult problem by its own , and we need to seek new solutions to the problem .
The second reason is the difficulty of parsing Vietnamese ; we need to seek new solutions to address this problem .
20 0,4,5,6,7,8,9,10:1,0,2,3,4,5,6:paraphrase 2,3:7,8:preserved 12::unaligned 13:10:preserved 14:11:preserved 15:12:preserved 16:13:preserved 17:14:preserved 18:15:preserved 19:16,17:paraphrase 20:18:bigrammar-det 21:19:preserved 22:20:preserved

VTB is annotated with three layers : word segmentation , POS tagging , and bracketing .
VTB is annotated with three layers : word segmentation , POS tagging , and bracketing .
23 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved

This paper focuses on the word segmentation issues since the most basic unit of a treebank is word ( Di Sciullo and Edwin , 1987 ) , and defining `` What are words ? '' is the first problem that a treebank has to solve ( Xia , 2000b ,a ; Sornlertlamvanich et al ., 1997 , 1999 ) .
This paper focuses on the word segmentation , since the most basic unit of a treebank are words ( Di Sciullo and Edwin , 1987 ) , and defining `` words '' is the first step ( Xia , 2000b ,a ; Sornlertlamvanich et al ., 1997 , 1999 ) .
24 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 5,4,6,7:5,6,4:paraphrase 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16,17:16,17:bigrammar-inter 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30,31::unaligned 32:30:preserved 34:31:preserved 35:32:preserved 36,37,39,38,40,41,42,43,44:33,35,34:paraphrase 46,45,47,48,49,50,51,52,53,54,55,56,57,58:37,36,38,39,40,41,42,43,44,45,46,48,49,47:preserved

For languages like English , answering this question is almost trivial because the blank spaces denote word delimiters .
For languages like English , defining `` words '' is almost trivial , because the blank spaces denote word delimiters .
25 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5,6,7:5,7:paraphrase 8:9:preserved 9:10:preserved 10:11:preserved 11:13:preserved 12:14:preserved 13:15:preserved 14:16:preserved 15:17:preserved 16:18:preserved 17:19:preserved 18:20:preserved

However , for an isolating language like Vietnamese , where blank spaces play a role of syllable delimiters , `` What are words ? '' is not a trivial question .
However , for an isolating language like Vietnamese , for which blank spaces play a role of syllable delimiters , `` What are words ? '' is not a trivial question .
26 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9,10:paraphrase 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:26:preserved 26:27:preserved 27:28:preserved 28:29:preserved 29:30:preserved 30:31:preserved

For example , the sentence `` H❅c sinh h❅c sinh h❅c ( students learn biology )1 '' is composed of three words `` h❅c sinh ( student ) '' , `` h❅c ( learn ) , '' and `` sinh h❅c ( biology ) ; '' Word segmentation is expected to break down the sentence at the boundaries of these words , not to split `` h❅c sinh ( student ) '' and `` sinh h❅c ( biology ) '' .
For example , the sentence `` H❅c sinh h❅c sinh h❅c ( students learn biology )1 '' is composed of three words , `` h❅c sinh ( student ) '' , `` h❅c ( learn ) , '' and `` sinh h❅c ( biology ) '' . Word segmentation is expected to break down the sentence at the boundaries of these words , instead of splitting `` h❅c sinh ( student ) '' and `` sinh h❅c ( biology ) '' .
27 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:26:preserved 26:27:preserved 27:28:preserved 28:29:preserved 29:30:preserved 30:31:preserved 31:32:preserved 32:33:preserved 33:34:preserved 34:35:preserved 35:36:preserved 36:37:preserved 37:38:preserved 38:39:preserved 39:40:preserved 40:41:preserved 41:42:preserved 42:43:preserved 43:44:preserved 45:45:preserved 46:47:preserved 47:48:preserved 48:49:preserved 49:50:preserved 50:51:preserved 51:52:preserved 52:53:preserved 53:54:preserved 54:55:preserved 55:56:preserved 56:57:preserved 57:58:preserved 58:59:preserved 59:60:preserved 60:61:preserved 61:62:preserved 63,64,62:63,64,65:paraphrase 65:66:preserved 66:67:preserved 67:68:preserved 68:69:preserved 69:70:preserved 70:71:preserved 71:72:preserved 72:73:preserved 73:74:preserved 74:75:preserved 75:76:preserved 76:77:preserved 77:78:preserved 78:79:preserved 79:80:preserved 80:81:preserved

Note that the terminology `` word segmentation '' also refers to the task of extracting words statistically without concerning a gold-standard for segmentation , as in ( Ha , 2003 ; Le et al ., 2010 ) .
Note that the terminology `` word segmentation '' also refers to the task of extracting words statistically without concerning a gold-standard for segmentation , as in ( Ha , 2003 ; Le et al ., 2010 ) .
28 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved 35:35:preserved 36:36:preserved 37:37:preserved

In such context , the extracted words are more appropriate for building a dictionary than for corpus-based language processing , which are out of the focus of this paper .
In such a context , the extracted words are more appropriate for building a dictionary , rather than for corpus-based language processing , which are outside of the scope of this paper .
29 0:0:preserved 1:1:preserved 2:3:preserved 3:4:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:16,17:paraphrase 15:18:preserved 16:19:preserved 17:20:preserved 18:21:preserved 19:22:preserved 20:23:preserved 21:24:preserved 22,23,24,25:25,26,27,28:paraphrase 26:29:preserved 27:30:preserved 28:31:preserved 29:32:preserved :2:mogrammar-det

Establishing a gold standard for Vietnamese word segmentation faces some diffcuties coming from the characteristics of the language .
Because of the discussed characteristics of the language , there are challenges in establishing a gold standard for Vietnamese word segmentation .
30 0,1,2,3,4,5,7,6:13,14,15,16,18,19,20,17:preserved 9::unaligned 10:11:paraphrase 11,12:0,1:para-freeword 14,13:4,2,3:paraphrase 15,16,17:5,6,7:preserved 18:21:preserved

The diffculties of Vietnamese word segmentation have been recognized by many researchers ( Ha , 2003 ; Nguyen et al ., 2004 , 2006 ; Le et al ., 2010 ) .
The difficulties in Vietnamese word segmentation have been recognized by many researchers ( Ha , 2003 ; Nguyen et al ., 2004 , 2006 ; Le et al ., 2010 ) .
33 0:0:preserved 1:1:preserved 2:2:bigrammar-prep 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved

Although most people agree that the Vietnamese language has two types of words : single and compound , there is little consensus on how to segment a sentence into words .
Although most people agree that the Vietnamese language has two types of words : single and compound , there is little consensus as to the methodology for segmenting a sentence into words .
34 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22,23,24,25:22,23,24,25,26,27:paraphrase 26:28:preserved 27:29:preserved 28:30:preserved 29:31:preserved 30:32:preserved

The disagreement is not only because of the different functions of blank spaces as mentioned above , but also because Vietnamese is not an inflectional language like English or Japanese , where morphological forms can be useful clues for word segmentation .
The disagreement occurs not only because of the different functions of blank spaces ( as mentioned above ) , but also because Vietnamese is not an inflectional language , as is the case for English or Japanese , for which morphological forms can provide useful clues for word segmentation .
35 0:0:preserved 1:1:preserved 2:2:paraphrase 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:18:preserved 17:19:preserved 18:20:preserved 19:21:preserved 20:22:preserved 21:23:preserved 22:24:preserved 23:25:preserved 24:26:preserved 25:27:preserved 26:29,30,31,32,33:paraphrase 27,28,29:34,35,36:preserved 30:28:preserved 31:39,38:paraphrase 32,33:40,41:preserved 34:42:preserved 35:43:paraphrase 36,37:44,45:preserved 38,39,40:46,47,48:preserved

While the similar problems also happen with Chinese word segmentation ( Xia , 2000b ) , Vietnamese word segmentation may be more diffcult because the modern Vietnamese writing system is based on Latin characters , which represents the pronunciation but not the meaning of words .
While similar problems also occur with Chinese word segmentation ( Xia , 2000b ) , Vietnamese word segmentation may be more difficult , because the modern Vietnamese writing system is based on Latin characters , which represent the pronunciation , but not the meaning of words .
36 0:0:preserved 1::mogrammar-det 2:1:preserved 3:2:preserved 4:3:preserved 5:4:paraphrase 6:5:preserved 7:6:preserved 8:7:preserved 9:8:preserved 10:9:preserved 11:10:preserved 12:11:preserved 13:12:preserved 14:13:preserved 15:14:preserved 16:15:preserved 17:16:preserved 18:17:preserved 19:18:preserved 20:19:preserved 21:20:preserved 22:21:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved 35:35:preserved 36:36:bigrammar-inter 37:37:preserved 38:38:preserved 39:40:preserved 40:41:preserved 41:42:preserved 42:43:preserved 43:44:preserved 44:45:preserved 45:46:preserved

All these characteristics make it diffcult to perform word segmentation for Vietnamese both manually and automatically , and have resulted in different criteria for word segmenation .
All of these characteristics make it diffcult to perform word segmentation for Vietnamese , both manually and automatically , and have thus resulted in different criteria for word segmentation .
37 0:0:preserved 1:2:preserved 2:3:preserved 3:4:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:14:preserved 13:15:preserved 14:16:preserved 15:17:preserved 16:18:preserved 17:19:preserved 18:20:preserved 19:22:preserved 20:23:preserved 21:24:preserved 22:25:preserved 23:26:preserved 24:27:preserved 25:28:preserved 26:29:preserved :1:mogrammar-prep :21:unaligned

However , so far there have been few studies on the challenges in word segmentation , and the comparison of different word segmentation criteria .
However , so far , there have been few studies on the challenges in word segmentation , and the comparison of different word segmentation criteria .
38 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved

In this paper , a brief introduction of the Vietnamese treebank VTB and its annotation scheme are given in Section 2 .
In this paper , a brief introduction of the Vietnamese Treebank VTB and its annotation scheme are provided in Section 2 .
41 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:paraphrase 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved

Then , we described our methods for the detection and correction of the problematic annotations in the VTB corpus ( Section 4 .2 ) .
Then , we described our methods for the detection and correction of the problematic annotations in the VTB corpus ( Section 4 .2 ) .
42 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved

We classified the problematic annotations into several patterns of inconsistency , part of which were manually fixed to improve the quality of the corpus .
We classified the problematic annotations into several patterns of inconsistency , part of which were manually fixed to improve the quality of the corpus .
43 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved

The rest , which can be considered as the most diffcult and controversial cases of word segmentation , were used to create different versions of the VTB corpus representing different word segmentation criteria .
The rest , which can be considered as the most difficult and controversial instances of word segmentation , were used to create different versions of the VTB corpus , representing different word segmentation criteria .
44 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:paraphrase 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:29:preserved 29:30:preserved 30:31:preserved 31:32:preserved 32:33:preserved 33:34:preserved

Finally , we evaluated these criteria in automatic word segmentation , and its application in text classification and English-Vietnamese statistical machine translation in Section 4 .
Finally , we evaluated these criteria in automatic word segmentation , and its application in text classification and English-Vietnamese statistical machine translation , in Section 4 .
45 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:26:preserved

This study is not only beneficial for the development of computational processing technologies for Vietnamese , a language spoken by over 90 million people , but also for the similar languages such as Thai , Laos , and so on .
This study is not only beneficial for the development of computational processing technologies for Vietnamese , a language spoken by over 90 million people , but also for similar languages such as Thai , Laos , and so on .
48 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28::mogrammar-det 29:28:preserved 30:29:preserved 31:30:preserved 32:31:preserved 33:32:preserved 34:33:preserved 35:34:preserved 36:35:preserved 37:36:preserved 38:37:preserved 39:38:preserved 40:39:preserved

This study also promotes the computational linguistic studies on how to transfer methods developed for a popular language like English to a language that has not yet intensively studied .
This study also promotes the computational linguistic studies on how to transfer methods developed for a popular language , like English , to a language that has not yet been intensively studied .
49 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:19:preserved 19:20:preserved 20:22:preserved 21:23:preserved 22:24:preserved 23:25:preserved 24,25,28:26,27,29,31:para-passact 26:28:preserved 27:30:preserved 29:32:preserved

Word segmentation in VTB aims to found a standard for word segmentation in a context of multi-level language processing .
Word segmentation in VTB aims at establishing a standard for word segmentation in a context of multi-level language processing .
54 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5,6:5,6:paraphrase 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved

VTB specifies 12 types of units that should be identified as words ( Table 1 ) ( Nguyen et al ., a ) , which can be divided into three groups : single , compound , and special `` words '' .
VTB specifies 12 types of units that should be identified as words ( Table 1 ) ( Nguyen et al ., a ) , which can be divided up into three groups : single , compound , and special `` words '' .
55 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:29:preserved 29:30:preserved 30:31:preserved 31:32:preserved 32:33:preserved 33:34:preserved 34:35:preserved 35:36:preserved 36:37:preserved 37:38:preserved 38:39:preserved 39:40:preserved 40:41:preserved 41:42:preserved :28:mogrammar-prep

Single words contain only one token .
Single words contain only one token .
56 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved

The terminology tokens refers to text spans separated with each other by blank spaces .
The terminology tokens refers to text spans that are separated from each other by blank spaces .
57 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5,6:6,5:preserved 7:9,7,8:para-passact 8:10:bigrammar-prep 9:11:preserved 10:12:preserved 11:13:preserved 12:14:preserved 13:15:preserved 14:16:preserved

Compound words have two or more tokens , and are divided into four types : compound words composed by semantic coordination ( semantic-coordinated compound ) , compound words composed by semantic subordination ( semantic-subordinated compound ) , compound words with affx , and reduplicated words .
Compound words have two or more tokens , and are divided into four types : compound words composed by semantic coordination ( semantic-coordinated compound ) , compound words composed by semantic subordination ( semantic-subordinated compound ) , compound words with an affx , and reduplicated words .
58 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved 35:35:preserved 36:36:preserved 37:37:preserved 38:38:preserved 39:39:preserved 40:41:preserved 41:42:preserved 42:43:preserved 43:44:preserved 44:45:preserved 45:46:preserved :40:mogrammar-det

Special `` words '' can be idioms , locutions , proper names , date times , numbers , symbols , sentence marks , foreign words , or abbreviations .
Special `` words '' include idioms , locutions , proper names , date times , numbers , symbols , sentence marks , foreign words , or abbreviations .
59 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4,5:4:paraphrase 6:5:preserved 7:6:preserved 8:7:preserved 9:8:preserved 10:9:preserved 11:10:preserved 12:11:preserved 13:12:preserved 14:13:preserved 15:14:preserved 16:15:preserved 17:16:preserved 18:17:preserved 19:18:preserved 20:19:preserved 21:20:preserved 22:21:preserved 23:22:preserved 24:23:preserved 25:24:preserved 26:25:preserved 27:26:preserved 28:27:preserved

The segmentation of these types of words forms a basis for the POS tagging , with 18 different POS tags shown in Table 2 ( Nguyen et al ., c ) .
The segmentation of these types of words forms a basis for the POS tagging , with 18 different POS tags , as shown in Table 2 ( Nguyen et al ., c ) .
60 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:22:preserved 21:23:preserved 22:24:preserved 23:25:preserved 24:26:preserved 25:27:preserved 26:28:preserved 27:29:preserved 28:30:preserved 29:31:preserved 30:32:preserved 31:33:preserved :21:mogrammar-prep

Each unit in Table 1 goes with several example words of which English translations are given in parentheses .
Each unit in Table 1 goes with several example words ; English translations are provided in parentheses .
63 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10,11::unaligned 12:11:preserved 13:12:preserved 14:13:preserved 15:14:paraphrase 16:15:preserved 17:16:preserved 18:17:preserved

Besides , we added a translation for each token when possible , so that the readers unfamiliar with Vietnamese can have an intuitive idea of how the compound words are formed .
Furthermore , we added a translation for each token , where possible , so that readers who are unfamiliar with Vietnamese can have an intuitive idea as to how the compound words are formed .
64 0:0:paraphrase 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:10:bigrammar-others 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14::mogrammar-det 15:15:preserved 16:18,17,16:paraphrase 17:19:preserved 18:20:preserved 19:21:preserved 20:22:preserved 21:23:preserved 22:24:preserved 23:25:preserved 24:26,27:paraphrase 25:28:preserved 26:29:preserved 27:30:preserved 28:31:preserved 29:32:preserved 30:33:preserved 31:34:preserved

The subscript of a token translation is the index of that token in the compound word .
The subscript of a token translation is the index of that token in the compound word .
65 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved

However , for some tokens , we could not find any appropriate English translation , so we give it an empty translation marked with an asterisk .
However , for some tokens , we could not find any appropriate English translation , so we gave it an empty translation , marked with an asterisk .
66 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:bigrammar-vtense 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:26:preserved 26:27:preserved

Note that a Vietnamese word or a token in context can have other meanings in addition to the given translations .
Note that a Vietnamese word or a token in context can have other meanings , in addition to the given translations .
67 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved

A special type of words in Vietnamese is classifer noun , denoted by the part-of-speech Nc in Table 2 .
A classifier noun , denoted by the part-of-speech Nc in Table 2 , is a special type of word in Vietnamese .
70 1,2,0,3:15,16,14,17:preserved 4:18:bigrammar-nnum 5,6,16:19,20:preserved 7:13:para-freeword 9,8:1,2:preserved 10:12:preserved 17,18,15,14,13,12,11:4,5,6,7,8,9,10,11:preserved 19:21:preserved :0:mogrammar-det

Classifier nouns are specific to several Southeast Asian languages like Vietnamese and Thai .
Classifier nouns are specific to several Southeast Asian languages , like Vietnamese and Thai .
71 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved

One of the functions of classifier nouns is to express the definiteness .
One of the functions of classifier nouns is to express the definiteness .
72 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved

For example , the common noun `` bàn '' means tables in general , while `` cái bàn '' means a specific table similar to the table in English .
For example , the common noun `` bàn '' generally means tables , while `` cái bàn '' means a specific table , similar to the table in English .
73 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:10:preserved 10:11:preserved 11,12:9:paraphrase 13:12:preserved 14:13:preserved 15:14:preserved 16:15:preserved 17:16:preserved 18:17:preserved 19:18:preserved 20:19:preserved 21:20:preserved 22:21:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved

In this section , we analyzed the VTB corpus to know whether the diffculties in Vietnamese word segmentation affected the quality of VTB annotations .
In this section , we analyzed the VTB corpus to determine whether the difficulties in Vietnamese word segmentation affected the quality of VTB annotations .
78 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:paraphrase 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved

The analysis results revealed several types of inconsistent annotations , which are also
The analysis revealed several types of inconsistent annotations , which are also
79 0,1,2:0,1:paraphrase 3:2:preserved 4:3:preserved 5:4:preserved 6:5:preserved 7:6:preserved 8:7:preserved 9:8:preserved 10:9:preserved 11:10:preserved 12:11:preserved

Vietnamese word segmentation .
Vietnamese word segmentation .
80 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved

Our analysis is based on two types of inconsistency : variation and structural inconsistency , whose definitions and details are given below .
Our analysis is based on two types of inconsistencies : variation and structural inconsistency , which are defined below .
81 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:bigrammar-nnum 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15,16,17,18:15:paraphrase 19,20:16,17:paraphrase 21:18:preserved 22:19:preserved

Variation inconsistency : is a sequence of tokens which have more than one way of seg-mentation in the corpus .
Variation inconsistency : is a sequence of tokens , which has more than one way of segmentation in the corpus .
84 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:9:preserved 9:10:bigrammar-inter 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved

For example , `` con gái/girl '' can remain as one word , or be segmented into two words `` con '' and `` gái '' .
For example , `` con gái/girl '' can remain as one word , or be segmented into two words , `` con '' and `` gái '' .
85 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:26:preserved 26:27:preserved

A variation can be an annotation inconsistency , or an ambiguity inVietnamese .
A variation can be an annotation inconsistency , or an ambiguity in Vietnamese .
86 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11,12:preserved 12:13:preserved

While ambiguity cases reflect the diffculty of the language , annotation inconsistencies are usually caused by the confusion in the decision of annotators , which should be eliminated in annotation .
While ambiguity cases reflect the difficulty of the language , annotation inconsistencies are usually caused by the confusion in the decision of annotators , which should be eliminated in annotation .
87 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved

We use the term variation instance to refer a single occurence of a variation .
We use the term variation instance to refer to a single occurrence of a variation .
88 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved :8:mogrammar-prep

Structural inconsistency : happens when different sequences have similar structures , thus should be splitted in the same way , but are segmented in different ways in the corpus .
Structural inconsistency : happens when different sequences have similar structures , and thus should be split in the same way , but are segmented in different ways in the corpus .
91 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:12:preserved 13,12:14,13:preserved 14:15:spelling 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:26:preserved 26:27:preserved 27:28:preserved 28:29:preserved 29:30:preserved :11:unaligned

For example , `` con gái/girl '' and `` con trai/boy '' have similar structures , a combination of a classifier noun and a common noun Nc + N , so when `` con gái/girl '' is splitted and `` con trai/boy '' is not , it is considered as a structural inconsistency of Nc .
For example , `` con gái/girl '' and `` con trai/boy '' have similar structures : a combination of a classifier noun and a common noun , Nc + N , so when `` con gái/girl '' is split , and `` con trai/boy '' is not , it is considered as a structural inconsistency of Nc .
92 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:27:preserved 27:28:preserved 28:29:preserved 29:30:preserved 30:31:preserved 31:32:preserved 32:33:preserved 33:34:preserved 34:35:preserved 35:36:preserved 36:37:preserved 37:38:spelling 38:40:preserved 39:41:preserved 40:42:preserved 41:43:preserved 42:44:preserved 43:45:preserved 44:46:preserved 45:47:preserved 46:48:preserved 47:49:preserved 48:50:preserved 49:51:preserved 50:52:preserved 51:53:preserved 52:54:preserved 53:55:preserved 54:56:preserved 55:57:preserved

It is likely that structural inconsistency in word segmentation level makes the higher levels of processing , POS tagging and bracketing , become more complicated .
It is likely that structural inconsistency at the word segmentation level complicates the higher levels of processing , including POS tagging and bracketing .
93 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:bigrammar-prep 7:8:preserved 8:9:preserved 9:10:preserved 10,22,24:11:paraphrase 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:19:preserved 18:20:preserved 19:21:preserved 20:22:preserved 23::unaligned 25:23:preserved :7:mogrammar-det :18:unaligned

The detection method for variation inconsistency is based on N-gram sequences and the phrase structures in VTB treebank , following the definition of variation inconsistency above .
The detection method for variation inconsistency is based on N-gram sequences and the phrase structures in the VTB , following the definition for variation inconsistency , above .
97 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16,17:17:paraphrase 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:bigrammar-prep 23:23:preserved 24:24:preserved 25:26:preserved 26:27:preserved :16:mogrammar-det

In details , we counted N-gram sequences of different lengths in VTB that have two or more ways of word segmentation , satisfying one of the following two conditions :
In detail , we counted N-gram sequences of different lengths in VTB that have two or more ways of word segmentation , satisfying one of the following two conditions :
98 0:0:preserved 1:1:bigrammar-nnum 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved

N tokens are all in the same phrase , and all have the same depth in phrase .
N tokens are all in the same phrase , and all have the same depth in phrase .
101 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved

For example , the 3-gram " nhà tình nghĩa ( house of gratitude ) " in this structure " ( NP ( Nc-H căn ) ( N nhà ) ( A tình nghĩa ) ) , " OR
For example , the 3-gram " nhà tình nghĩa ( house of gratitude ) " in this structure " ( NP ( Nc-H căn ) ( N nhà ) ( A tình nghĩa ) ) , " OR
102 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved 35:35:preserved 36:36:preserved 37:37:preserved

nhà tình nghĩa " in this structure " ( NP ( Nc-H căn ) ( N nhà ) ( ADJP ( A tình nghĩa ) ) ) , " where the ADJP contains only one word .
nhà tình nghĩa " in this structure " ( NP ( Nc-H căn ) ( N nhà ) ( ADJP ( A tình nghĩa ) ) ) , " where the ADJP contains only one word .
105 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved 35:35:preserved 36:36:preserved

Table 3 shows the overall statistics of the variation inconsistency detected by the above method .
Table 3 shows the overall statistics of the variation inconsistency detected by the method described above .
109 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13,14:15,14,13:paraphrase 15:16:preserved

Most of the diffcult cases of word segmentation lie in two-token variations , occupying the majority of variations ( 92 .9% ) .
Most of the diffcult cases of word segmentation occur in two-token variations , occupying the majority of variations ( 92 .9% ) .
110 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:paraphrase 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved

This ratio of 2-gram variations is much higher than the evarage ratio of two-token words in Vietnamese reported in ( Nguyen et al., 2009a ) , which is 80% percent .
This ratio of 2-gram variations is much higher than the average ratio of two-token words in Vietnamese , as reported in ( Nguyen et al., 2009a ) , which is 80% .
111 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:spelling 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:19:preserved 18:20:preserved 19:21:preserved 20:22:preserved 21:23:preserved 22:24:preserved 23:25:preserved 24:26:preserved 25:27:preserved 26:28:preserved 27:29:preserved 28:30:preserved 30:31:preserved :18:mogrammar-prep

Variations have lengths of three and four tokens occupy 6 .1% and 1 .0% , respectively .
Variations that have lengths of three and four tokens occupy 6 .1% and 1 .0% , respectively .
112 0:0:preserved 1:2,1:bigrammar-others 2:3:preserved 3:4:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved

We estimated the precision of our method by randomly selected 130 2-gram variation instances extracted from the above method , and manually checked whether they are true inconsistency .
We estimated the precision of our method by randomly selecting 130 2-gram variation instances , extracted from the method described above , and manually checked whether the inconsistencies are true .
115 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:bigrammar-wform 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17,18:20,19,18:paraphrase 19:21:preserved 20:22:preserved 21:23:preserved 22:24:preserved 23:25:preserved 24:27,26:paraphrase 25:28:preserved 26:29:preserved 27::unaligned 28:30:preserved

We found that 129 cases occupying 99 .2% of all extracted 2-grams are true inconsistency .
We found that 129 cases occupying 99 .2% of all extracted 2-grams are true inconsistencies .
116 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:bigrammar-nnum 15:15:preserved

Only one instance is an ambiguous sequence giá c , which is one word when it means price , and two words giá / price c / all in đàu có giá c / all have ( their own ) price .
Only one instance of inconsistency was an ambiguous sequence giá c , which is one word when it means price , and two words giá / price c / all in đàu có giá c / all have ( their own ) price .
117 0:0:preserved 1:1:preserved 2:2,3,4:paraphrase 3:5:bigrammar-vtense 4:6:preserved 5:7:preserved 6:8:preserved 7:9:preserved 8:10:preserved 9:11:preserved 10:12:preserved 11:13:preserved 12:14:preserved 13:15:preserved 14:16:preserved 15:17:preserved 16:18:preserved 17:19:preserved 18:20:preserved 19:21:preserved 20:22:preserved 21:23:preserved 22:24:preserved 23:25:preserved 24:26:preserved 25:27:preserved 26:28:preserved 27:29:preserved 28:30:preserved 29:31:preserved 30:32:preserved 31:33:preserved 32:34:preserved 33:35:preserved 34:36:preserved 35:37:preserved 36:38:preserved 37:39:preserved 38:40:preserved 39:41:preserved 40:42:preserved 41:43:preserved

The precision of our method is high enough so that so we can use the extracted variations to study the insights of word segmentation problem .
The precision for our method is high , so we can use the extracted variations to provide insights on the word segmentation problem .
118 0:0:preserved 1:1:preserved 2:2:bigrammar-prep 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 8,9::unaligned 10:8:preserved 11:9:preserved 12:10:preserved 13:11:preserved 14:12:preserved 15:13:preserved 16:14:preserved 17:15:preserved 18:16:paraphrase 19::mogrammar-det 20:17:preserved 21:18:bigrammar-prep 22:20:preserved 23:21:preserved 24:22:preserved 25:23:preserved :19:mogrammar-det

We further analyzed the 2-gram variations to know what types of 2-grams were most confusing to annotators .
We further analyzed the 2-gram variations to understand what types of 2-grams were most confusing for annotators .
123 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:paraphrase 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:bigrammar-prep 16:16:preserved 17:17:preserved

The analysis results showed that compound nouns , compound verbs , and compound adjectives are the top diffcult cases of word segmentation .
The analysis revealed that compound nouns , compound verbs , and compound adjectives are the most difficult cases of word segmentation .
124 0:0:preserved 1:1:preserved 3:2:paraphrase 4:3:preserved 5:4:preserved 6:5:preserved 7:6:preserved 8:7:preserved 9:8:preserved 10:9:preserved 11:10:preserved 12:11:preserved 13:12:preserved 14:13:preserved 15:14:preserved 16:15:paraphrase 17:16:typo 18:17:preserved 19:18:preserved 20:19:preserved 21:20:preserved 22:21:preserved

We classified the 2-gram variations according to their POS sequences in case the tokens in the 2-gram are splitted .
We classified the 2-gram variations according to their POS sequences in case the tokens in the 2-gram are split .
125 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:spelling 19:19:preserved

There are totally 54 patterns of POS sequence , of which top 10 confusing patterns , a long with their counts of 2-gram variations , and examples are shown in Table 4 .
There are a total of 54 patterns of POS sequences . The top 10 confusing patterns , their counts of 2-gram variations , and examples are depicted in Table 4 .
126 0:0:preserved 1:1:preserved 2:2,3,4:paraphrase 3:5:preserved 4:6:preserved 5:7:preserved 6:8:preserved 7:9:bigrammar-nnum 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 19:17:preserved 20:18:preserved 21:19:preserved 22:20:preserved 23:21:preserved 24:22:preserved 25:23:preserved 26:24:preserved 27:25:preserved 28:26:paraphrase 29:27:preserved 30:28:preserved 31:29:preserved 32:30:preserved

Table 5 and Table 6 show the POS patterns which a specific POS tag appearing at the beginning or ending of the sequence .
Table 5 and Table 6 show the POS patterns that are a specific POS tag , appearing at the beginning or ending of the sequence .
127 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9,10:paraphrase 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:16:preserved 15:17:preserved 16:18:preserved 17:19:preserved 18:20:preserved 19:21:preserved 20:22:preserved 21:23:preserved 22:24:preserved 23:25:preserved

Investigating the inconsistent 2-grams extracted , we found that most of them are compound words according to the VTB guidelines ( Section 2 ) .
Investigating the inconsistent 2-grams extracted , we found that most of them are compound words , according to the VTB guidelines ( Section 2 ) .
130 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved

One of the reasons why the compound words are sometimes splitted , is because the tokens in those compound words have their own meanings , which seem to contribute to the whole meaning of the compounds .
One of the reasons why the compound words are sometimes split , is because the tokens in those compound words have their own meanings , which seem to contribute to the overall meaning of the compounds .
131 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:spelling 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:paraphrase 32:32:preserved 33:33:preserved 34:34:preserved 35:35:preserved 36:36:preserved

This can be seen through the examples given in Table 4 , where the meanings of tokens are given with a subscript .
This can be seen through the examples provided in Table 4 , where the meanings of tokens are given with a subscript .
132 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:paraphrase 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved

This problem seems to have caused a lot of trouble for the annotators of VTB .
This scenario has proven to be problematic for the annotators of VTB .
133 0:0:preserved 1:1:paraphrase 2:2,3:paraphrase 3,4,5,6,7,8,9:4,5,6:paraphrase 10:7:preserved 11:8:preserved 12:9:preserved 13:10:bigrammar-prep 14:11:preserved 15:12:preserved

Furthermore , observing the POS patterns in Table 5 and Table 6 , we can see the potential of structural inconsistency , in particular for closed-set POS tags .
Furthermore , by observing the POS patterns in Table 5 and Table 6 , we can see the potential for structural inconsistency , particularly for closed-set POS tags .
136 0:0:preserved 1:1:preserved 2:3:preserved 3:4:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:bigrammar-prep 19:20:preserved 20:21:preserved 21:22:preserved 22,23:23:paraphrase 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved :2:mogrammar-prep

Among them , classifier nouns ( Nc ) and affxes ( S ) are two typical cases of structural inconsistency , which will be used in several settings of our experiments .
Among them , classifier nouns ( Nc ) and affixes ( S ) are two typical cases of structural inconsistency , which will be used in several settings for our experiments .
137 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:typo 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:bigrammar-prep 29:29:preserved 30:30:preserved 31:31:preserved

The same affx or classifier noun can modify different nouns , so when they are sometimes splitted , and sometimes combined in the variations , we can conclude that classifier nouns and affxes involve in structural inconsistency .
The same affx or classifier noun can modify different nouns , so when they are sometimes split and combined in the variations , we can conclude that classifier nouns and affixes involve in-structural inconsistencies .
138 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:spelling 18:17:preserved 20:18:preserved 21:19:preserved 22:20:preserved 23:21:preserved 24:22:preserved 25:23:preserved 26:24:preserved 27:25:preserved 28:26:preserved 29:27:preserved 30:28:preserved 31:29:preserved 32:30:typo 33:31:preserved 34,35:32:biproblematic 36:33:bigrammar-nnum 37:34:preserved

In the following section , we presents our detection method for structural inconsistency for classifier nouns and affxes .
In the following section , we present our detection method for structural inconsistency for classifier nouns and affixes .
139 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:bigrammar-inter 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:typo 18:18:preserved

The detection method for structural inconsistency of classifier nouns and affxes is simple .
The detection method for structural inconsistency of classifier nouns and affixes is simple .
146 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:typo 11:11:preserved 12:12:preserved 13:13:preserved

First , we collected all affxes and classifier nouns in the VTB corpus . Then , extracted 2-grams containing these affxes or classifier nouns , which also are the structural inconsistencies .
We collected all affixes and classifier nouns in the VTB corpus , and then extracted 2-grams containing these affixes or classifier nouns , which are also structural inconsistencies .
147 2:0:preserved 3:1:preserved 4:2:preserved 5:3:typo 6:4:preserved 7:5:preserved 8:6:preserved 9:7:preserved 10:8:preserved 11:9:preserved 12:10:preserved 14:13:preserved 16:14:preserved 17:15:preserved 18:16:preserved 19:17:preserved 20:18:typo 21:19:preserved 22:20:preserved 23:21:preserved 24:22:preserved 25:23:preserved 26:25:preserved 27:24:preserved 28::mogrammar-det 29:26:preserved 30:27:preserved 31:28:preserved

For example , since " con " is tagged as a classifier noun in VTB , we extracted all 2-grams of " con " including both " con gái / girl " and " con trai / boy " .
For example , since " con " is tagged as a classifier noun in VTB , we extracted all 2-grams of " con " including both " con gái / girl " and " con trai / boy " .
148 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved 35:35:preserved 36:36:preserved 37:37:preserved 38:38:preserved 39:39:preserved

Note that even though the sequence " con trai " is always splitted into two words throughout the corpus , it can still be an inconsistency if we consider similar structures such as " con gái " .
Even though the sequence , " con trai " is always split into two words throughout the corpus , it can still be an inconsistency , if we consider similar structures such as " con gái " .
149 2:0:preserved 3:1:preserved 4:2:preserved 5:3:preserved 6:5:preserved 7:6:preserved 8:7:preserved 9:8:preserved 10:9:preserved 11:10:preserved 12:11:spelling 13:12:preserved 14:13:preserved 15:14:preserved 16:15:preserved 17:16:preserved 18:17:preserved 19:18:preserved 20:19:preserved 21:20:preserved 22:21:preserved 23:22:preserved 24:23:preserved 25:24:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved 35:35:preserved 36:36:preserved 37:37:preserved

In other words , by this method , we extract sequences that may be consistent at the surface level , but are not consistent if we consider the higher analysis levels , POS tagging .
In other words , by this method , we extract sequences that may be consistent at the surface level , but are not consistent , if we consider the higher analysis levels , POS tagging .
150 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:25:preserved 25:26:preserved 26:27:preserved 27:28:preserved 28:29:preserved 29:30:preserved 30:31:preserved 31:32:preserved 32:33:preserved 33:34:preserved 34:35:preserved

According to the VTB POS-tagging annotation guidelines ( Nguyen et al., c ) , classifier nouns should be separated from the words they modify .
According to the VTB POS-tagging annotation guidelines ( Nguyen et al., c ) , classifier nouns should be separated from the words that they modify .
153 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:23,22:bigrammar-others 23:24:preserved 24:25:preserved

However , in practice it is confusing when the classifier noun can be stand alone as a single word .
However , in practice , it is confusing when the classifier noun can be standalone as a single word .
154 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13,14:14:spelling 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved

For example a classifier noun , e.g. , " con " in " con trai ( boy ) " , or " con gái ( girl ) " , can also be a simple word which means " I ( first person pronoun used by a child when talking to his / her parents ) " , or part of a complex noun " con cái ( children ) " .
For example a classifier noun , e.g. , " con " in " con trai ( boy ) " , or " con gái ( girl ) " , can also be a simple word , which means " I ( first person pronoun used by a child when talking to his / her parents ) " , or part of a complex noun " con cái ( children ) " .
155 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved 35:36:preserved 36:37:preserved 37:38:preserved 38:39:preserved 39:40:preserved 40:41:preserved 41:42:preserved 42:43:preserved 43:44:preserved 44:45:preserved 45:46:preserved 46:47:preserved 47:48:preserved 48:49:preserved 49:50:preserved 50:51:preserved 51:52:preserved 52:53:preserved 53:54:preserved 54:55:preserved 55:56:preserved 56:57:preserved 57:58:preserved 58:59:preserved 59:60:preserved 60:61:preserved 61:62:preserved 62:63:preserved 63:64:preserved 64:65:preserved 65:66:preserved 66:67:preserved 67:68:preserved 68:69:preserved 69:70:preserved 70:71:preserved

Therefore , in our experiments , we want to evaluate the " splitting " and " combining " of these diffcult cases , to see whether the solution is fruitful for applications of the corpus .
Therefore , in our experiments , we want to evaluate the " splitting " and " combining " of these cases , in order to see whether the solution is successful for applications of the corpus .
156 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 21:20:preserved 22:21:preserved 23:24,23,22:paraphrase 24:25:preserved 25:26:preserved 26:27:preserved 27:28:preserved 28:29:preserved 29:30:paraphrase 30:31:preserved 31:32:preserved 32:33:preserved 33:34:preserved 34:35:preserved 35:36:preserved

Examing the variations extracted by the variation inconsistency detection , we found that there are cases when a special character like percentage % in " 30% " , is splitted or combined with " 30 " .
By examining the variations extracted by the variation inconsistency detection , we found that there are cases when a special character like a percentage ( % ) in " 30% " , is split or combined with " 30 " .
162 0:1:typo 1:2:preserved 2:3:preserved 3:4:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:23:preserved 26,25,24,23,22:29,30,28,27,26,24,25:preserved 27:31:preserved 28:32:preserved 29:33:spelling 30:34:preserved 31,32,33,34,35:35,36,37,38,39:preserved :0:mogrammar-prep :22:mogrammar-det

Such inconsistent annotations are manually fixed based on their textual context .
Such inconsistent annotations are manually fixed based on their textual context .
163 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved

Checking structural inconsistency of these special characters including percentage% , hyphen - , and so on , we found quite a significant amount of inconsistent annotations .
By checking structural inconsistencies of these special characters , including percentages ( % ) , hyphens ( - ) , and other symbols , we found quite a significant number of inconsistent annotations .
166 0:1:preserved 1:2:preserved 2:3:bigrammar-nnum 3:4:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:9:preserved 8:10,12,11,13:bigrammar-nnum 9:8:preserved 10:15:bigrammar-nnum 11:16,17,18:preserved 12:14:preserved 13:20:preserved 14,15:21,22:paraphrase 16:19:preserved 21,20,19,18,17:28,27,26,25,24:preserved 22:29:paraphrase 25,24,23:32,31,30:preserved

For example , the character % in " 30% " is splitted but is combined with the number in " 50 % " , which is considered as a structural inconsistency .
For example , the character , % , in " 30% " is split , but is combined with a number in " 50 % " , which is considered to be a structural inconsistency .
167 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:6:preserved 6:8:preserved 7:9:preserved 8:10:preserved 9:11:preserved 10:12:preserved 11:13:spelling 12:15:preserved 13:16:preserved 14:17:preserved 15:18:preserved 16:19:bigrammar-det 17:20:preserved 18:21:preserved 19:22:preserved 20:23:preserved 21:24:preserved 22:25:preserved 23:26:preserved 24:27:preserved 25:28:preserved 26:29:preserved 27:30,31:paraphrase 30,29,28:34,33,32:preserved

Note that although it can be argued that whether " N% " can be splitted into two words or combined in one word is dependent on the blank space in between N and " % " .
Note that it can be argued that splitting " N% " into two words or combined in one word is dependent on the blank space in-between N and " % " .
168 0:0:preserved 1:1:preserved 3:2:preserved 4:3:preserved 5:4:preserved 6:5:preserved 7:6:preserved 8,12,13,14:7:paraphrase 9:8:preserved 10:9:preserved 11:10:preserved 15,16,17,18,19,20:11,12,13,14,15,16:preserved 28,27,26,25,24,23,22,21:24,23,22,21,20,19,18,17:preserved 29,30:25:spelling 34,35,33,32,31:30,29,28,27,26:preserved

It does matter higher-levels of annotation such as POS tagging because we may need one or two different POS tags for different ways of annotation .
Higher-levels of annotation such as POS tagging is significant , because we may need one or two different POS tags for the different methods of annotation .
169 0,1,2:7,8:paraphrase 3:0:preserved 4:1:preserved 5:2:preserved 6:3:preserved 7:4:preserved 8:5:preserved 9:6:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:22:preserved 22:23:paraphrase 23:24:preserved 24:25:preserved 25:26:preserved :21:mogrammar-det

Therefore , we think it is better to carefully preprocess text and segment these special characters in a consistent way .
Therefore , we think that it is better to carefully preprocess text and segment these special characters in a consistent way .
170 0:0:preserved 1:1:preserved 2:2:preserved 3:3,4:bigrammar-others 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved

To improve the quality of VTB corpus , we extracted the probably problematic sequences using patterns of the special characters , and manually fixed this type of inconsistency .
To improve the quality of the VTB corpus , we extracted the problematic sequences using patterns of the special characters , and manually fixed this type of inconsistency .
173 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved :5:mogrammar-det

Automatically modification is diffcult since we must check the semantics of the special characters in their contexts .
Automatically modification is diffcult , since we must check the semantics of the special characters in their contexts .
174 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved

For example , hyphens in date expressions like " 5-4-1975 " , which means the date " April the fifth , 1975 , " are combined with the numbers .
For example , hyphens in date expressions like " 5-4-1975 " , which refers to the date , " the fifth of April , 1975 , " are combined with the numbers .
175 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13,14:paraphrase 14:15:preserved 15:16:preserved 16:18:preserved 19,17,18:20,21,22,19:para-colocation 20:23:preserved 21:24:preserved 22:25:preserved 23:26:preserved 24:27:preserved 25:28:preserved 26:29:preserved 27:30:preserved 28:31:preserved 29:32:preserved

However , when the hypen has a meaning of " ( from ) to " or " around .
However , when the hyphen indicates " ( from ) to " or " around .
176 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:typo 5,6,7,8:5:paraphrase 9:6:preserved 10:7:preserved 11:8:preserved 12:9:preserved 13:10:preserved 14:11:preserved 15:12:preserved 16:13:preserved 17:14:preserved 18:15:preserved

. .
. .
177 0:0:preserved 1:1:preserved

or " , as in " 2-3 gi░ sáng " meaning " around 2 or 3 o’clock in the morning " , we decided to separate it from the surrounding numbers .
or " , as in " 2-3 gi░ sáng " , meaning " around 2 or 3 o’clock in the morning " , we decided to separate it from the surrounding numbers .
178 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:26:preserved 26:27:preserved 27:28:preserved 28:29:preserved 29:30:preserved 30:31:preserved 31:32:preserved

As a result , we have fixed 685 inconsistent annotations of 21 special characters in VTB .
As a result , we have fixed 685 inconsistent annotations of 21 special characters in VTB .
179 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved

The variation inconsistency and structural inconsistency found in Section 3 above can also be seen as representatives of different word segmentation criteria for Vietnamese .
The variation inconsistency and structural inconsistency found in Section 3 can also be seen as representatives of different word segmentation criteria for Vietnamese .
185 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 11:10:preserved 12:11:preserved 13:12:preserved 14:13:preserved 15:14:preserved 16:15:preserved 17:16:preserved 18:17:preserved 19:18:preserved 20:19:preserved 21:20:preserved 22:21:preserved 23:22:preserved 24:23:preserved

We organized the inconsistency detected in seven configurations of the original VTB corpus .
We organized the inconsistency detected in seven configurations of the original VTB corpus .
186 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved

Then , by using these data sets , we could observe the influence of the different word segmentation criteria on three tasks : automatic word segmenation , text classification , and English-Vietnamese statistical machine translation .
Then , by using these data sets , we could observe the influence of the different word segmentation criteria on three tasks : automatic word segmentation , text classification , and English-Vietnamese statistical machine translation .
187 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:typo 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved 35:35:preserved

Seven data sets corresponding to different segmentation criteria are organized as follows .
Seven data sets corresponding to different segmentation criteria are organized as follows .
191 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved

ORG : The original VTB corpus .
ORG : The original VTB corpus .
194 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved

BASE : The original VTB corpus + Manual modification of special characters done in Section 3 .3 .
BASE : The original VTB corpus + Manual modification of special characters done in Section 3 .3 .
197 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved

VAR_SPLIT : BASE + split all variations detected in Section 3 .1 .
VAR_SPLIT : BASE + split all variations detected in Section 3 .1 .
200 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved

VAR_COMB : BASE + combine all variations detected in Section 3 .1 .
VAR_COMB : BASE + combine all variations detected in Section 3 .1 .
203 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved

VAR_FREQ : BASE + select the segmentation with higher frequency among all variations detected in Section 3 .1 .
VAR_FREQ : BASE + select the segmentation with higher frequency among all variations detected in Section 3 .1 .
206 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved

STRUCT_NC : BASE + combine all classifier nouns detected in Section 3 .2 with the words they modify .
STRUCT_NC : BASE + combine all classifier nouns detected in Section 3 .2 with the words they modify .
209 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved

STRUCT_AFFIX : BASE + combine all suffxes detected in Section 3 .2 with the words they modify .
STRUCT_AFFIX : BASE + combine all suffxes detected in Section 3 .2 with the words they modify .
212 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved

These data sets are used in our experiments as illustrated in Figure 1 .
These data sets are used in our experiments , as illustrated in Figure 1 .
215 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved

The names of the data sets are also used to label our experimental configurations .
The names of the data sets are also used to label our experimental configurations .
216 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved

In this section , we briefly describe the task settings and the methods used for word segmentation ( WS ) , text classification ( TC ) , and English-Vietnamese statistical machine translation ( SMT ) .
In this section , we briefly describe the task settings and the methods used for word segmentation ( WS ) , text classification ( TC ) , and English-Vietnamese statistical machine translation ( SMT ) .
221 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved 35:35:preserved

We used YamCha ( Kudo and Matsumoto , 2003 ) , a multi-purpose chunking tool , to train our word segmentation models .
We used YamCha ( Kudo and Matsumoto , 2003 ) , a multi-purpose chunking tool , to train our word segmentation models .
227 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved

The core of YamCha is the Support Vector Machine ( SVM ) machine learning method , which has been proved to be effective in NLP tasks .
The core of YamCha is the Support Vector Machine ( SVM ) machine learning method , which has been proven to be effective for NLP tasks .
228 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:spelling 20:20:preserved 21:21:preserved 22:22:preserved 23:23:bigrammar-prep 24:24:preserved 25:25:preserved 26:26:preserved

For the Vietnamese word segmentation problem , each token is labeled with standard B , I , or O labels , corresponding to beginning , inside , and outside positions , respectively .
For the Vietnamese word segmentation problem , each token is labeled with standard B , I , or O labels , corresponding to the beginning , inside , and outside positions , respectively .
229 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:24:preserved 24:25:preserved 25:26:preserved 26:27:preserved 27:28:preserved 28:29:preserved 29:30:preserved 30:31:preserved 31:32:preserved 32:33:preserved :23:mogrammar-det

Label of each token is determined based on the lexical features of two preceding words and two following words of that token .
The label of each token is determined based on the lexical features of two preceding words , and the two following words of that token .
230 0:1:preserved 1:2:preserved 2:3:preserved 3:4:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:17:preserved 16:19:preserved 17:20:preserved 18:21:preserved 19:22:preserved 20:23:preserved 21:24:preserved 22:25:preserved :0:mogrammar-det :18:mogrammar-det

Since Vietnamese language is not inflectional , we cannot utilize inflection features for word segmentation .
Since the Vietnamese language is not inflectional , we cannot utilize inflection features for word segmentation .
231 0:0:preserved 1:2:preserved 2:3:preserved 3:4:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved :1:mogrammar-det

Each of the seven data sets is splitted into two subsets for training and testing our WS models .
Each of the seven data sets is split into two subsets for training and testing our WS models .
234 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:spelling 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved

The training set contains 8443 sentences , and the test set contains 2000 sentences .
The training set contains 8443 sentences , and the test set contains 2000 sentences .
235 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved

Text classification is defined as a task of determining for an input document the most suitable topic from the predefined topics .
Text classification is defined as a task of determining the most suitable topic from the predefined topics , for an input document .
240 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9,10,11,12:21,20,19,18:preserved 17,16,15,14,13:13,12,11,10,9:preserved 19,20,18:15,14,16:preserved 21:22:preserved

We implemented a text classification system similar to the system presented in ( Nguyen et al., 2012 ) .
We implemented a text classification system similar to the system presented in ( Nguyen et al., 2012 ) .
241 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved

The difference is that we performed for document level , not for sentence level .
The difference is that we performed the task at the document level , instead of at the sentence level .
242 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5,6,7:paraphrase 6:8:bigrammar-prep 7:10:preserved 8:11:preserved 9:12:preserved 11,10:15,14,13:paraphrase 13,12:18,17:preserved :9:mogrammar-det :16:mogrammar-det

Processing of the system is summarized as follows .
The processing of the system is summarized as follows .
245 0:1:preserved 1:2:preserved 2:3:preserved 3:4:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved :0:mogrammar-det

An input document is preprocessed with word segmentation and stop-word removals .
An input document is preprocessed with word segmentation and stop-word removals .
246 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved

Then , the document is represented in the form of a vector of weighted words appearing in the document .
Then , the document is represented in the form of a vector of weighted words appearing in the document .
247 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved

The weight is calculated using standard tf-idf product .
The weight is calculated using standard tf-idf product .
248 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved

An SVM-based classifier predicts the most probable topic for the vector , which also is the topic of the input document .
An SVM-based classifier predicts the most probable topic for the vector , which also is the topic for the input document .
249 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:bigrammar-prep 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved

In our experiment for comparison of different word segmentation criteria in topic classification , we only vary the word segmentation model used for this task , while fixing other configurations .
In our experiment , for comparison of different word segmentation criteria in topic classification , we only vary the word segmentation model used for this task , while fixing other configurations .
250 0:0:preserved 1:1:preserved 2:2:preserved 3:4:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:26:preserved 26:27:preserved 27:28:preserved 28:29:preserved 29:30:preserved 30:31:preserved

News articles of five topics : music , stock , entertainment , education , and fashion are used .
News articles of five topics : music , stock , entertainment , education , and fashion are used .
253 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved

The sizes of the training and test data sets are summarized in Table 8 .
The sizes of the training and test data sets are summarized in Table 8 .
254 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved

A	phrase-based SMT system for English-Vietnamese translation was implemented .
A	phrase-based SMT system for English-Vietnamese translation was implemented .
259 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved

In this system , we used SRILM ( Stolcke , 2002 ) to build the language model , GIZA++ ( Och and Ney , 2003 ) to train the word-aligned model , and Moses ( Holmqvist et al., 2007 ) to train the phrase-based statistical translation model .
In this system , we used SRILM ( Stolcke , 2002 ) to build the language model , GIZA++ ( Och and Ney , 2003 ) to train the word-aligned model , and Moses ( Holmqvist et al., 2007 ) to train the phrase-based statistical translation model .
260 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved 35:35:preserved 36:36:preserved 37:37:preserved 38:38:preserved 39:39:preserved 40:40:preserved 41:41:preserved 42:42:preserved 43:43:preserved 44:44:preserved 45:45:preserved 46:46:preserved 47:47:preserved

Translation results are evaluated using BLUE score ( Papineni et al., 2002 ) .
Translation results are evaluated using the BLUE score ( Papineni et al., 2002 ) .
261 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved :5:mogrammar-det

Both training and test data are word-segmented using the word segmentation models achieved .
Both training and test data are word-segmented using the word segmentation models achieved .
262 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved

For the experiment , we used the VCL_EVC bilingual corpus , 18000 pairs of sentences for training , and 1000 pairs for testing .
For the experiment , we used the VCL_EVC bilingual corpus , 18000 pairs of sentences for training , and 1000 pairs for testing .
263 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved

Evaluation of word segmentation models trained on different versions of the VTB are given in Table 9 .
Evaluation of word segmentation models trained on different versions of the VTB are given in Table 9 .
269 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved

And the experimental results with text classification and English-Vietnamese statistical machine translation are shown in Table 10 and Table 11 , respectively .
The experimental results with text classification and English-Vietnamese statistical machine translation are shown in Table 10 and Table 11 , respectively .
270 1:0:preserved 2:1:preserved 3:2:preserved 4:3:preserved 5:4:preserved 6:5:preserved 7:6:preserved 8:7:preserved 9:8:preserved 10:9:preserved 11:10:preserved 12:11:preserved 13:12:preserved 14:13:preserved 15:14:preserved 16:15:preserved 17:16:preserved 18:17:preserved 19:18:preserved 20:19:preserved 21:20:preserved 22:21:preserved

There are two important conclusions can be drawn from these tables : ( 1 ) Quality of the treebank strongly affects the applications since our BASE model and most of other enhanced models improved the performance of TC and SMT systems ; ( 2 ) " Splitting " seems to be a good solution for word segmentation of controversial cases , including the split of variations , affxes , and classifier nouns .
There are two important conclusions that can be drawn from these tables : ( 1 ) The quality of the treebank strongly affects the applications , since our BASE model and most of the other enhanced models improved the performance of TC and SMT systems ; ( 2 ) " Splitting " seems to be a good solution for word segmentation for controversial cases , including the split of variations , affxes , and classifier nouns .
271 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:6,5:bigrammar-others 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:17:preserved 16:18:preserved 17:19:preserved 18:20:preserved 19:21:preserved 20:22:preserved 21:23:preserved 22:24:preserved 23:26:preserved 24:27:preserved 25:28:preserved 26:29:preserved 27:30:preserved 28:31:preserved 29:32:preserved 33,32,31,30:37,36,35,34:preserved 56,55,54,53,52,51,50,49,48,47,46,45,44,43,42,41,40,39,38,37,36,35,34:60,59,58,57,56,55,54,53,52,51,50,49,48,47,46,45,44,43,42,41,40,39,38:preserved 57:61:bigrammar-prep 60,59,58:64,63,62:preserved 71,70,69,67,68,66,65,64,63,62,61:75,74,73,71,69,72,70,68,67,66,65:preserved :16:mogrammar-det :33:mogrammar-det

According to the result in Table 9 , the VAR_SPLIT criterion gives the highest WS performance .
According to the result in Table 9 , the VAR_SPLIT criterion gives the highest WS performance .
274 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved

Except for STRUCT_NC , all the modifications to the original VTB corpus increase the performance of WS .
With the exception of STRUCT_NC , all of the modifications to the original VTB corpus increase the performance of WS .
275 0,1:0,1,2,3:paraphrase 2:4:preserved 3:5:preserved 4:6:preserved 5:8:preserved 6:9:preserved 7:10:preserved 8:11:preserved 9:12:preserved 10:13:preserved 11:14:preserved 12:15:preserved 13:16:preserved 14:17:preserved 15:18:preserved 16:19:preserved 17:20:preserved :7:mogrammar-prep

However , the word segmentation criterion with higher performance is not necessarily a better criterion , but a criterion should also be judged through applications of word segmentation .
However , the word segmentation criterion with higher performance is not necessarily a better criterion , but a criterion should also be judged through applications of word segmentation .
276 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved

In both SMT and TC experiments , the BASE model which is based on the manually-modified inconsistency of special characters , achieved better results than the ORG model .
In both SMT and TC experiments , the BASE model , which is based on the manually-modified inconsistency of special characters , achieved better results than the ORG model .
277 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:26:preserved 26:27:preserved 27:28:preserved 28:29:preserved

In particular , in the TC experiment , the BASE model achieved 0 .66 point higher than ORG , which is a significant improvement .
In particular , in the TC experiment , the BASE model achieved 0 .66 point higher than ORG , which is a significant improvement .
278 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved

The results support the conclusion that the quality of word-segmentation corpus is very important for building NLP applications .
The results support the conclusion that the quality of the word-segmentation corpus is very important for building NLP applications .
279 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved :9:mogrammar-det

The SMT results show that three out of six augmented models , VAR_SPLIT , VAR_FREQ and BASE , gave higher performance than the ORG configuration .
The SMT results show that three out of six augmented models , VAR_SPLIT , VAR_FREQ and BASE , performed better than the ORG configuration .
282 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18,19,20:18,19:paraphrase 21:20:preserved 22:21:preserved 23:22:preserved 24:23:preserved 25:24:preserved

Among them , the best model VAR_SPLIT achieved 36 .91 BLEU score , which is 0 .55 higher than ORG .
Among them , the best-performing model , VAR_SPLIT achieved 36 .91 BLEU score , which is 0 .55 higher than ORG .
283 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:paraphrase 5:5:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved

In TC results , all six augmented models have higher results than ORG .
In TC results , all six augmented models achieved higher results than ORG .
284 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:paraphrase 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved

In general , the augmented models are better than the ORG .
In general , the augmented models performed better than the ORG .
285 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:paraphrase 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved

Additionally , because our automatic methods for inconsistency detection could not cover all types of inconsistency in word segmentation annotation , further improvement of corpus quality is demanded .
Additionally , because our automatic methods for inconsistency detection could not cover all of the types of inconsistencies in word segmentation annotation , further improvement of corpus quality is demanded .
286 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:15:preserved 14:16:preserved 15:17:bigrammar-nnum 16:18:preserved 17:19:preserved 18:20:preserved 19:21:preserved 20:22:preserved 21:23:preserved 22:24:preserved 23:25:preserved 24:26:preserved 25:27:preserved 26:28:preserved 27:29:preserved 28:30:preserved

Comparing the results of STRUCT_AFFIX and STRUCT_NC with BASE in WS , TC , and SMT , we can observe that combining affxes with their head nouns resulted in slightly better results for WS , TC , and does not change the performance of SMT .
Comparing the results of STRUCT_AFFIX and STRUCT_NC with BASE in WS , TC , and SMT , we can observe that combining affxes with their head nouns resulted in slightly better results for WS and TC , and did not change the performance of SMT .
289 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34,36:36,34:paraphrase 35:35:preserved 37:37:preserved 38,39,40:38,39,40:bigrammar-vtense 41:41:preserved 42:42:preserved 43:43:preserved 44:44:preserved 45:45:preserved

However , the combination of clasifier nouns with their head nouns had negative effects on WS and SMT .
However , the combination of classifier nouns with their head nouns had negative effects on WS and SMT .
290 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:typo 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved

Another intention of our experiment is to compare two solutions for controversial cases of word segmentation , splitting and combining .
Another part of the scope of our experiment is to compare two solutions for controversial cases of word segmentation , splitting and combining .
293 0:0:preserved 1,2:3,4,2,1,5:paraphrase 3:6:preserved 4:7:preserved 5:8:preserved 6:9:preserved 7:10:preserved 8:11:preserved 9:12:preserved 10:13:preserved 11:14:preserved 12:15:preserved 13:16:preserved 14:17:preserved 15:18:preserved 16:19:preserved 17:20:preserved 18:21:preserved 19:22:preserved 20:23:preserved

Splitting and combining variations are reflected by VAR_COMB and VAR_SPLIT , while STRUCT_AFFIX and STRUCT_NC represent the combination of affxes or classifier nouns with the words they modify .
Splitting and combining variations are reflected by VAR_COMB and VAR_SPLIT , while STRUCT_AFFIX and STRUCT_NC represent the combination of affixes or classifier nouns with the words that they modify .
294 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:typo 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:27,26:bigrammar-others 27:28:preserved 28:29:preserved

STRUCT_AFFIX and STRUCT_NC are contrasted with BASE where affxes and classifier nouns remain untouched .
STRUCT_AFFIX and STRUCT_NC are contrasted with BASE where affxes and classifier nouns remain untouched .
295 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved

Comparing VAR_COMB and VAR_SPLIT in both TC experiment and SMT experiment , we see that the VAR_SPLIT results are better in both cases .
Comparing VAR_COMB and VAR_SPLIT in both the TC experiment and SMT experiment , we see that the VAR_SPLIT results are better in both cases .
296 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved :6:mogrammar-det

Since the ratio of combined variations in the ORG corpus is 60 .9% , it can be observed that splitting seems to be better than combining for WS , TC and SMT .
Since the ratio of combined variations in the ORG corpus is 60 .9% , it can be observed that splitting seems to be better than combining for WS , TC and SMT .
297 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved

In this paper , we have shown a quantitative analysis of the diffculties in word segmentation , through the detection of problematic cases in the Vietnamese treebank .
In this paper , we have provided a quantitative analysis of the difficulties in word segmentation , through the detection of problematic cases in the Vietnamese Treebank .
303 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:paraphrase 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:typo 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved

Based on the analysis , we automatically created data representing the different word segmentation criteria , and evaluated the criteria indirectly through their applications .
Based on the analysis , we automatically created data that represent the different word segmentation criteria , and evaluated the criteria indirectly through their applications .
304 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9,10:paraphrase 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved

Our experimental results showed that manual modification done for annotation of spe-cial characters and most of other word segmentation criteria significantly improved the performances of automatic word segmentation , text classification and statistical machine translation , comparing with the use of the original VTB corpus .
Our experimental results showed that manual modification , done for annotation of special characters , and most other word segmentation criteria , significantly improved the performances of automatic word segmentation , text classification and statistical machine translation , in comparison with the use of the original VTB corpus .
307 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:typo 12:13:preserved 13:15:preserved 14:16:preserved 15::mogrammar-prep 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:22:preserved 21:23:preserved 22:24:preserved 23:25:preserved 24:26:preserved 25:27:preserved 26:28:preserved 27:29:preserved 28:30:preserved 29:31:preserved 30:32:preserved 31:33:preserved 32:34:preserved 33:35:preserved 34:36:preserved 35:37:preserved 36:38,39:paraphrase 37:40:preserved 38:41:preserved 39:42:preserved 40:43:preserved 41:44:preserved 42:45:preserved 43:46:preserved 44:47:preserved 45:48:preserved

Since the VTB corpus is the first effort in building a treebank for Vietnamese , and is the only corpus publicly available for NLP research , this study contributes to further improvement of the corpus quality , which is essential for building effcient NLP systems .
Since the VTB corpus is the first effort in building a treebank for Vietnamese , and is the only corpus that is publicly available for NLP research , this study contributes to further improvement of the corpus quality , which is essential for building efficient NLP systems .
308 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:22,21,20:paraphrase 21:23:preserved 22:24:preserved 23:25:preserved 24:26:preserved 25:27:preserved 26:28:preserved 27:29:preserved 28:30:preserved 29:31:preserved 30:32:preserved 31:33:preserved 32:34:preserved 33:35:preserved 34:36:preserved 35:37:preserved 36:38:preserved 37:39:preserved 38:40:preserved 39:41:preserved 40:42:preserved 41:43:preserved 42:44:typo 43:45:preserved 44:46:preserved 45:47:preserved

