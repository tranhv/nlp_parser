Face Retrieval Improvement by Learning Visual Consistency
Face Retrieval Improvement by the Learning of Visual Consistency
2 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:5:preserved 5:7:preserved 6:8:preserved :4:mogrammar-det :6:mogrammar-prep

Searching persons is one of the essential tasks required by users for image and video search engines .
Searching for images of people is one of the essential tasks required by users for image and video search engines .
6 0:0:preserved 1:4,1,2,3:paraphrase 2:5:preserved 3:6:preserved 4:7:preserved 5:8:preserved 6:9:preserved 7:10:preserved 8:11:preserved 9:12:preserved 10:13:preserved 11:14:preserved 12:15:preserved 13:16:preserved 14:17:preserved 15:18:preserved 16:19:preserved 17:20:preserved

However , the current search engines have limited capabilities for this task since they usually rely on texts associated with image and video which are likely to return many irrelevant results .
However , the current search engines have limited capabilities for this task since they usually rely on texts associated with image and video , which are likely to return many irrelevant results .
7 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:24:preserved 24:25:preserved 25:26:preserved 26:27:preserved 27:28:preserved 28:29:preserved 29:30:preserved 30:31:preserved 31:32:preserved

In this paper , we propose a method to effectively retrieve relevant faces for one person by learning visual consistency from results retrieved from text correlation based search engines .
We propose a method to effectively retrieve relevant faces for one person by learning visual consistency from results retrieved from text correlation based search engines .
8 4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28:0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24:preserved

This problem is challenging because ( i ) no any label is provided leading to be difficult to use supervised-based ranking methods .
This problem is challenging because ( i ) there is no label provided making it difficult to use supervised-based ranking methods .
9 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:10:preserved 10:11:preserved 11,12:8,9,12:paraphrase 13,14,15:13,14:paraphrase 16:15:preserved 17:16:preserved 18:17:preserved 19:18:preserved 20:19:preserved 21:20:preserved 22:21:preserved

( ii ) current face recognition techniques are still unmatured with wild-face databases even with supervised learning methods .
( ii ) current face recognition techniques are still immature with wild-face databases even with supervised learning methods .
10 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:spelling 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved

In the proposed method , we treat the problem as a classification problem which input faces are classified as 'personX' ( the queried person ) or 'non-personX' and the faces are ranked based on their relevant score that is inferred from the classifier 's probability output .
In the proposed method , we treat this problem as a classification problem in which input faces are classified as 'person-X' ( the queried person ) or 'non-person-X' , and the faces are ranked based on their relevant score inferred from the classifier 's probability output .
11 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:bigrammar-det 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:typo 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:26:preserved 26:27:typo 27:29:preserved 28:30:preserved 29:31:preserved 30:32:preserved 31:33:preserved 32:34:preserved 33:35:preserved 34:36:preserved 35:37:preserved 36:38:preserved 39:39:preserved 40:40:preserved 41:41:preserved 42:42:preserved 43:43:preserved 44:44:preserved 45:45:preserved 46:46:preserved :13:mogrammar-prep

In order to train this classifier , we use a bagging-based framework to combine results from multiple weak classifiers which are trained using different subsets .
To train this classifier , we use a bagging-based framework to combine results from multiple weak classifiers , which are trained using different subsets .
12 2:0:preserved 3:1:preserved 4:2:preserved 5:3:preserved 6:4:preserved 7:5:preserved 8:6:preserved 9:7:preserved 10:8:preserved 11:9:preserved 12:10:preserved 13:11:preserved 14:12:preserved 15:13:preserved 16:14:preserved 17:15:preserved 18:16:preserved 19:18:preserved 20:19:preserved 21:20:preserved 22:21:preserved 23:22:preserved 24:23:preserved 25:24:preserved

These training subsets are extracted and labeled automatically from the rank list produced from the classifier trained from the previous step .
These training subsets are extracted and labeled automatically from the rank list produced from the classifier trained from the previous step .
13 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved

In addition , outliers detection methods are used to produce the rank list for initialization .
In addition , outlier detection methods are used to produce the rank list for initialization .
14 0:0:preserved 1:1:preserved 2:2:preserved 3:3:bigrammar-nnum 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved

Experimental results on various face sets retrieved from the caption of news photos show that the retrieval performance is improved after each iteration leading the final performance outperforms the baseline algorithms .
Experimental results on various face sets retrieved from the captions of news photos show that the retrieval performance improved after each iteration with the final performance outperforming the baseline algorithms .
15 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:bigrammar-nnum 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 19:18:preserved 20:19:preserved 21:20:preserved 22:21:preserved 23:22:paraphrase 24:23:preserved 25:24:preserved 26:25:preserved 27:26:bigrammar-wform 28:27:preserved 29:28:preserved 30:29:preserved 31:30:preserved

With the rapid growing of digital technology , large image and video databases are available easier than ever to users .
With the rapid growth of digital technology , large image and video databases are more available than ever to users .
19 0:0:preserved 1:1:preserved 2:2:preserved 3:3:bigrammar-wform 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14,15:14,15:paraphrase 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved

Therefore , effective and efficient tools are strongly needed for indexing and retrieving based on visual contents .
Therefore , effective and efficient tools are needed for indexing and retrieving based on visual contents .
20 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 8:7:preserved 9:8:preserved 10:9:preserved 11:10:preserved 12:11:preserved 13:12:preserved 14:13:preserved 15:14:preserved 16:15:preserved 17:16:preserved

One of the typical examples for this application is to search a specific person by providing his or her name .
A typical example for this application is searching for a specific person by providing his or her name .
21 2:0:bigrammar-det 3:1:preserved 4:2:preserved 5:3:preserved 6:4:preserved 7:5:preserved 8:6:preserved 9,10:7:bigrammar-wform 11:9:preserved 12:10:preserved 13:11:preserved 14:12:preserved 15:13:preserved 16:14:preserved 17:15:preserved 18:16:preserved 19:17:preserved 20:18:preserved :8:mogrammar-prep

Usually , most of current search engines use text associated with images or videos as a significant clue to return the results .
Usually , most current search engines use the texts associated with images or videos as significant clues for returning results .
22 0:0:preserved 1:1:preserved 2:2:preserved 3::mogrammar-prep 4:3:preserved 5:4:preserved 6:5:preserved 7:6:preserved 8:8:bigrammar-nnum 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15::mogrammar-det 16:15:preserved 17:16:bigrammar-nnum 18,19:17,18:paraphrase 20::mogrammar-det 21:19:preserved 22:20:preserved :7:mogrammar-det

However , since it is not necessary faces and names appear simultaneously and are aligned ( as shown in Figure \REF ) , the main drawback of this approach is existence of many irrelevant results that makes the retrieval performance very low .
However , other un-queried faces and names appear simultaneously and are aligned ( as shown in Figure \REF ) , which significantly lowers retrieval performance .
23 0:0:preserved 1:1:preserved 7:4:preserved 8:5:preserved 9:6:preserved 10:7:preserved 11:8:preserved 12:9:preserved 13:10:preserved 14:11:preserved 15:12:preserved 16:13:preserved 17:14:preserved 18:15:preserved 19:16:preserved 20:17:preserved 21:18:preserved 22:19:preserved 35:20:bigrammar-others 36,40,41:22,21:paraphrase 37::mogrammar-det 39,38:24,23:preserved :2,3:moproblematic

Therefore it is necessary to improve the retrieval performance by taking into account visual information from the retrieved faces .
Therefore , it is necessary to improve the retrieval performance by taking into account the visual information from the retrieved faces .
24 0:0:preserved 1:2:preserved 2:3:preserved 3:4:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:15:preserved 14:16:preserved 15:17:preserved 16:18:preserved 17:19:preserved 18:20:preserved 19:21:preserved :14:mogrammar-det

This problem is challenging due to the following reasons :
This problem is challenging due to the following reasons :
25 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved

-Large variations in face appearance due to pose changes , illumination conditions , occlusions and facial expressions make face recognition difficult even with state of the art techniques \CITE .
-Large variations in face appearance due to pose changes , illumination conditions , occlusions , and facial expressions make face recognition difficult even with state of the art techniques \CITE .
28 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:26:preserved 26:27:preserved 27:28:preserved 28:29:preserved 29:30:preserved

-The fact the retrieved face set consists of faces of several persons while no any label is given makes supervised learning methods as well as unsupervised learning methods such as \MATH -means inapplicable .
-The fact the retrieved face set consists of faces of several people with no label makes supervised learning methods as well as unsupervised learning methods such as , \MATH -means , inapplicable .
31 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:paraphrase 12,16,17:12:paraphrase 13:13:preserved 15:14:preserved 18:15:preserved 19:16:preserved 20:17:preserved 21:18:preserved 22:19:preserved 23:20:preserved 24:21:preserved 25:22:preserved 26:23:preserved 27:24:preserved 28:25:preserved 29:26:preserved 30:28:preserved 31:29:preserved 32:31:preserved 33:32:preserved

In this paper , we propose a method to solve the mentioned problem .
We propose a method to solve the above-mentioned problem .
34 4,5,6,7,8,9,10:0,1,2,3,4,5,6:preserved 11:7:paraphrase 12:8:preserved

The main idea is to learn visual consistency assumed to exist among the results returned from current text-based search engines .
The main idea is to assume that there is visual consistency among the results returned from current text-based search engines .
35 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 8,9,10,5:5,6,7,8:paraphrase 6:9:preserved 7:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved

The method consists of two stages .
This method consists of two stages .
36 0:0:bigrammar-det 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved

In the first stage , we explore local density of faces to identify potential candidates for relevant faces .
In the first stage , we explore local density of faces to identify potential candidates for relevant faces .
37 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved

This stage is stemmed from the observation that faces relevant to the queried person tend to form dense clusters while irrelevant faces are very sparse since they look different from each other .
This stage is based on the observation that facial images of the queried person tend to form dense clusters while irrelevant facial images are sparse since they look different from each other .
38 0:0:preserved 1:1:preserved 2:2:preserved 3,4:4,3:paraphrase 5:5:preserved 6:6:preserved 7:7:preserved 8:9,8:paraphrase 9,10:10:paraphrase 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21,22:paraphrase 22:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved

We use an outliers detection method for this purpose .
We use an outlier detection method for this purpose .
39 0:0:preserved 1:1:preserved 2:2:preserved 3:3:bigrammar-nnum 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved

The output is a rank list in which faces having larger number of neighbors within a distance are predicted as relevant ones and therefore are put on the top .
The output is a rank list in which faces with larger number of neighbors within a certain distance are considered as relevant and are therefore put at the top of the list . //[What do you mean by �gneighbors�h ? Do you mean the un-queried faces ? ]
40 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:paraphrase 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:17:preserved 17:18:preserved 18:19:paraphrase 19:20:preserved 20:21:preserved 22:22:preserved 23:24:preserved 24:23:preserved 25:25:preserved 26:26:bigrammar-prep 27:27:preserved 28:28:preserved 29:32:preserved

Since the above ranking method is based on the number of neighbors , it is sensitive to the chosen distance .
Since the above ranking method is based on the number of neighbors , it is sensitive to the specified distance .
41 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:paraphrase 19:19:preserved 20:20:preserved

It is necessary to use the second stage to improve the rank list .
A second stage is necessary to improve this rank list .
42 0,1,3,4:3:paraphrase 2:4:preserved 5:0:bigrammar-det 6,7:2,1:preserved 8:5:preserved 9:6:preserved 10:7:bigrammar-det 11:8:preserved 12:9:preserved 13:10:preserved

We model this problem as a classification problem which input faces are classified as personX ( the queried person ) or non-personX ( the irrelevant person ) .
We model this problem as a classification problem in which input faces are classified as person-X ( the queried person ) or non-person-X ( the irrelevant person ) .
43 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:typo 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:typo 22:23:preserved 23:24:preserved 24:25:preserved 25:26:preserved 26:27:preserved 27:28:preserved :8:mogrammar-prep

The faces are ranked based on their relevant score that is inferred from the classifier 's probability output .
The faces are ranked based on their relevancy score that is inferred from the classifier 's probability output .
44 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:bigrammar-wform 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved

Since annotation data is not available , the rank list from the previous step is used to assign labels for a subset of faces .
Since annotation data is not available , the rank list from the previous step is used to assign labels for a subset of faces .
45 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved

This subset then is used to train a classifier using a supervised method such as support vector machines ( SVM ) .
This subset then is used to train a classifier using supervised methods such as support vector machines ( SVM ) .
46 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10,12:11:bigrammar-nnum 11:10:preserved 13:12:preserved 14:13:preserved 15:14:preserved 16:15:preserved 17:16:preserved 18:17:preserved 19:18:preserved 20:19:preserved 21:20:preserved

The trained classifier is used to re-rank faces in the original input set again .
The trained classifier is used to re-rank faces in the original input set .
47 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 14:13:preserved

This step is repeated a number of times to get the final rank list .
This step is repeated a number of times to get the final rank list .
48 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved

Since automatically assigning labels from the rank list is not reliable , the trained classifiers are weak .
Since automatically assigning labels from the rank list is not reliable , the trained classifiers are weak .
49 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved

In order to get the final strong classifier , we employ the idea of ensemble learning \CITE in which weak classifiers trained on different subsets are combined to improve stability and classification accuracy of single classifiers .
In order to get the final strong classifier , we use the idea of ensemble learning \CITE in which weak classifiers trained on different subsets are combined to improve the stability and classification accuracy of single classifiers .
50 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:paraphrase 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:30:preserved 30:31:preserved 31:32:preserved 32:33:preserved 33:34:preserved 34:35:preserved 35:36:preserved 36:37:preserved :29:mogrammar-det

This stage is effective for improving the rank list due to the following reasons :
This stage is effective for improving the rank list for the following reasons :
53 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9,10:9:paraphrase 11:10:preserved 12:11:preserved 13:12:preserved 14:13:preserved

-Supervised learning methods such as SVM have strong theoretical background in finding optimal decision boundary even with existence of noisy data .
-Supervised learning methods such , as SVMs , provide a strong theoretical background in finding optimal decision boundary even with existence of noisy data .
56 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:5:preserved 5:6:bigrammar-nnum 6:8:paraphrase 7:10:preserved 8:11:preserved 9:12:preserved 10:13:preserved 11:14:preserved 12:15:preserved 13:16:preserved 14:17:preserved 15:18:preserved 16:19:preserved 17:20:preserved 18:21:preserved 19:22:preserved 20:23:preserved 21:24:preserved :9:mogrammar-det

Furthermore , with recent studies \CITE SVM classifiers can provide probability outputs that are suitable for ranking .
Furthermore , recent studies suggest that \CITE SVM classifiers provide probability outputs that are suitable for ranking .
57 0:0:preserved 1:1:preserved 2:4,5:paraphrase 3:2:preserved 4:3:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8,9:9:paraphrase 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved

-Bagging framework helps to leverage noises in the unsupervised labeling process .
-Bagging framework helps to leverage noises in the unsupervised labeling process .
60 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved

Our contribution is two-fold :
Our contribution is two-fold :
63 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved

-We propose a general framework to boost the face retrieval performance from the results retrieved from text correlation based search engines by learning visual consistency .
-We propose a general framework to boost the face retrieval performance from results retrieved from text correlation-based search engines by the learning of visual consistency .
66 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12::mogrammar-det 13:12:preserved 14:13:preserved 15:14:preserved 16:15:preserved 17,18:16:typo 19:17:preserved 20:18:preserved 21:19:preserved 22:21:preserved 23:23:preserved 24:24:preserved 25:25:preserved :20:mogrammar-det :22:mogrammar-prep

It integrates seamlessly current existing data mining methods such as outliers detection , supervised learning and unsupervised learning based on bagging for a practical problem .
It seamlessly integrates current data mining methods such as outlier detection , supervised learning , and unsupervised learning based on bagging for a practical problem . //[What or who is �glearning�h visual consistency ? Are the search engines learning ? ]
67 0:0:preserved 1:2:preserved 2:1:preserved 3:3:preserved 5:4:preserved 6:5:preserved 7:6:preserved 8:7:preserved 9:8:preserved 10:9:bigrammar-nnum 11:10:preserved 12:11:preserved 13:12:preserved 14:13:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved

Our framework requires few parameters and works stably .
Our framework requires few parameters and works stably .
68 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved

-We demonstrate feasibility of using tolerance of supervised learning methods when working with noisy datasets combined with ensemble learning to improve the final performance .
-We demonstrate the feasibility of using tolerance of supervised learning methods when working with noisy datasets combined with ensemble learning to improve the final performance .
71 0:0:preserved 1:1:preserved 2:3:preserved 3:4:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved :2:mogrammar-det

There are several approaches proposed for general object classification rather than for face retrieval .
There are several more proposed approaches for general object classification than for those for face retrieval .
75 0:0:preserved 1:1:preserved 2:2:preserved 3:5:preserved 4:4:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9,10:10:paraphrase 11:11:preserved 12:14:preserved 13:15:preserved 14:16:preserved

For example , as described in \CITE , objects are retrieved by an image search engine and then are re-ranked by learning visual consistencies from the retrieved objects .
For example , as described in \CITE , objects are retrieved by an image search engine and then are re-ranked by the learning of visual consistencies from the retrieved objects .
76 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:22:preserved 22:24:preserved 23:25:preserved 24:26:preserved 25:27:preserved 26:28:preserved 27:29:preserved 28:30:preserved :21:mogrammar-det :23:mogrammar-prep

Compared to the problem of face retrieval based recognition , the problem of object classification is easier since classification of different object types such as airplane and non-airplane only needs to handle inter-variations between different categories while discriminating personA and personB requires to handle both intra-variations and inter-variations of the same category .
Compared to the problem of face-based recognition , the problem of object classification is easier since classification of different object types such as airplane and non-airplane only needs to handle inter-variations between different categories , while discriminating between person-A and person-B requires handling of both intra-variations and inter-variations of the same category .
77 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5,6,7:5:paraphrase 8:6:preserved 9:7:preserved 10:8:preserved 11:9:preserved 12:10:preserved 13:11:preserved 14:12:preserved 15:13:preserved 16:14:preserved 17:15:preserved 18:16:preserved 19:17:preserved 20:18:preserved 21:19:preserved 22:20:preserved 23:21:preserved 24:22:preserved 25:23:preserved 26:24:preserved 27:25:preserved 28:26:preserved 29:27:preserved 30:28:preserved 31:29:preserved 32:30:preserved 33:31:preserved 34:32:preserved 35:33:preserved 36:35:preserved 37:36:preserved 38:38:typo 39:39:preserved 40:40:typo 41:41:preserved 42,43:42,43:paraphrase 44:44:preserved 45:45:preserved 46:46:preserved 47:47:preserved 48:48:preserved 49:49:preserved 50:50:preserved 51:51:preserved 52:52:preserved

Furthermore , in order to work in unsupervised mode , these approaches need a method to collect negative samples ( e.g. non-airplane ) which are inapplicable in our problem .
Furthermore , in order to work in unsupervised mode , these approaches need a method to collect negative samples ( e.g. non-airplane ) , which are inapplicable to our problem .
78 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:24:preserved 24:25:preserved 25:26:preserved 26:27:bigrammar-prep 27:28:preserved 28:29:preserved 29:30:preserved

Working closely to our problem , in \cite{Ozkan06CVPR} , a graph based approach was proposed \CITEin which a graph is formed by faces as nodes and weights of edges linked between nodes are the similarity of faces .
A graph-based approach was proposed by \CITE , in which a graph is formed by faces as nodes , and the weights of edges linked between nodes are the similarity of faces , is closely related to our problem .
81 0,1:34,33,35:paraphrase 2,3,4:36,37,38:preserved 5:7:preserved 6:5:bigrammar-prep 7:6:preserved 12,9,13,14:0,2,3,4:preserved 11,10:1:typo 17,18,15,16,19,20,21,22,23,24:10,11,12,13,14,15,16,17,8,9:preserved 25:19:preserved 26,27,28,29,30,31,32,33,34,35,36:21,22,23,24,25,26,27,28,29,30,31:preserved 37:39:preserved :20:mogrammar-det

By assuming that the number of faces of the queried person are larger than that of other persons , and these faces tend to form the most similar subset among the set of retrieved faces , this problem is considered equal to the problem of finding the densest subgraph of a full graph whose solution is available .
Assuming that the number of faces of the queried person is larger than that of others and that these faces tend to form the most similar subset among the set of retrieved faces , this problem is considered equal to the problem of finding the densest subgraph of a full graph with an available solution . //[Do graphs have solutions ? They just provide information .]
82 0::mogrammar-prep 1:0:preserved 2:1:preserved 3:2:preserved 4:3:preserved 5:4:preserved 6:5:preserved 7:6:preserved 8:7:preserved 9:8:preserved 10:9:preserved 11:10:bigrammar-inter 12:11:preserved 13:12:preserved 14:13:preserved 15:14:preserved 16,17:15:paraphrase 19:16:preserved 20:18:preserved 21:19:preserved 22:20:preserved 23:21:preserved 24:22:preserved 25:23:preserved 26:24:preserved 27:25:preserved 28:26:preserved 29:27:preserved 30:28:preserved 31:29:preserved 32:30:preserved 33:31:preserved 34:32:preserved 35:33:preserved 36:34:preserved 37:35:preserved 38:36:preserved 39:37:preserved 40:38:preserved 41:39:preserved 42:40:preserved 43:41:preserved 44:42:preserved 45:43:preserved 46:44:preserved 47:45:preserved 48:46:preserved 49:47:preserved 50:48:preserved 51:49:preserved 52:50:preserved 53,55:51,52:paraphrase 54:54:preserved 56:53:preserved 57:55:preserved

Although , experimental results showed effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person .
Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of relevant faces of the queried person .
83 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:26:preserved 26:27:preserved 27:28:preserved 28:29:preserved :5:mogrammar-det

Furthermore , choosing an optimal threshold to convert the initial graph into a binary graph is difficult and rather ad hoc due to the curse of dimensionality .
Furthermore , choosing an optimal threshold to convert the initial graph into a binary graph is difficult and rather ad hoc due to dimensionality .
84 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 26:23:preserved 27:24:preserved

In another work \CITE , a clustering-based approach was proposed to associate names and faces in news photos .
In another work \CITE , a clustering-based approach was proposed for associating names and faces in news photos .
85 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10,11:10,11:paraphrase 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved

To solve the problem of ambiguity between several names and one face , a modified \MATH -means clustering process was used in which faces are assigned to the closest cluster ( each cluster corresponding to one name ) after a number of iterations .
To solve the problem of ambiguity between several names and one face , a modified \MATH -means clustering process was used in which faces are assigned to the closest cluster ( each cluster corresponding to one name ) after a number of iterations .
86 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved 35:35:preserved 36:36:preserved 37:37:preserved 38:38:preserved 39:39:preserved 40:40:preserved 41:41:preserved 42:42:preserved 43:43:preserved

Although the result was impressive , it is not easy to apply for our problem since a large number of irrelevant faces ( more than 12% ) are eliminated manually before doing clustering .
Although the result was impressive , it is not easy to apply it to our problem since a large number of irrelevant faces ( more than 12% ) are eliminated manually before performing clustering .
87 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12,13:paraphrase 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:26:preserved 26:27:preserved 27:28:preserved 28:29:preserved 29:30:preserved 30:31:preserved 31:32:paraphrase 32:33:preserved 33:34:preserved

This paper is organized as follows : Section \REF introduces our proposed framework .
This paper is organized as follows : Section \REF introduces our proposed framework .
90 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved

Section \REF introduce briefly typical outliers detection methods .
Section \REF briefly introduces typical outlier detection methods .
91 0:0:preserved 1:1:preserved 2:3:bigrammar-inter 3:2:preserved 4:4:preserved 5:5:bigrammar-nnum 6:6:preserved 7:7:preserved 8:8:preserved

Experiments and results are described in section \REF .
Experiments and results are described in section \REF .
92 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved

Finally , section \REF concludes the paper .
Finally , section \REF concludes the paper .
93 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved

Given a set of faces returned by any text-based correlation search engine , our method performs a ranking process summarized as follows :
Given a set of faces returned by any text-based correlation search engine , our method is used to perform a ranking process summarized as follows :
99 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15,16,17,18:paraphrase 16:19:preserved 17:20:preserved 18:21:preserved 19:22:preserved 20:23:preserved 21:24:preserved 22:25:preserved

-Step 1 : Detect eye positions , and then perform face normalizations .
-Step 1 : Detect eye positions , and then perform face normalizations .
102 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved

-Step 2 : Compute an eigenface space and project the input faces into this subspace .
-Step 2 : Compute an eigenface space and project the input faces into this subspace .
105 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved

-Step 3 : Estimate ranks of faces using an outliers detection method mentioned in \REF .
-Step 3 : Estimate ranks of faces using an outlier detection method mentioned in \REF .
108 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:bigrammar-nnum 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved

-Step 4 : Train a ensemble classifier \MATH using this rank list by Bag-Rank-SVM .
-Step 4 : Train an ensemble classifier \MATH using this rank list by Bag-Rank-SVM .
111 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:bigrammar-det 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved

-Step 5 : Use the classifier \MATH to estimate the probability of faces in the original set .
-Step 5 : Use the classifier \MATH to estimate the probability of faces in the original set .
114 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved

Rank these faces using their probability score .
Rank these faces using their probability scores .
115 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:bigrammar-nnum 7:7:preserved

-Step 6 : Repeat steps from 4 and 5 $T$ times and return ranked faces produced by the last classifier \MATH to users .
-Step 6 : Repeat steps 4 and 5 $T$ times and return ranked faces produced by the last classifier \MATH to users .
118 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5::mogrammar-prep 6:5:preserved 7:6:preserved 8:7:preserved 9:8:preserved 10:9:preserved 11:10:preserved 12:11:preserved 13:12:preserved 14:13:preserved 15:14:preserved 16:15:preserved 17:16:preserved 18:17:preserved 19:18:preserved 20:19:preserved 21:20:preserved 22:21:preserved 23:22:preserved

Steps from 1 and 2 are typical for any face processing system and described in details in \REF .
Steps 1 and 2 are typical for any face processing system and described in detail in \REF .
121 0:0:preserved 1::mogrammar-prep 2:1:preserved 3:2:preserved 4:3:preserved 5:4:preserved 6:5:preserved 7:6:preserved 8:7:preserved 9:8:preserved 10:9:preserved 11:10:preserved 12:11:preserved 13:12:preserved 14:13:preserved 15:14:bigrammar-nnum 16:15:preserved 17:16:preserved 18:17:preserved

Step 3 used to find initial ranks for faces is described in \REF .
Step 3 used to find initial ranks for faces described in \REF .
122 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 10,9:9:para-passact 11:10:preserved 12:11:preserved 13:12:preserved

We use a simple outliers detection method for this step .
We used a simple outlier detection method for this step .
123 0:0:preserved 1:1:bigrammar-vtense 2:2:preserved 3:3:preserved 4:4:bigrammar-nnum 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved

The Bag-Rank-SVM algorithm is described as follows :
The Bag-Rank-SVM algorithm is described as follows :
126 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved

-Step 1 : Select a set \MATH including \MATH top ranked faces and then randomly select a subset \MATH from \MATH .
-Step 1 : Select a set \MATH including \MATH top ranked faces and then randomly select a subset \MATH from \MATH .
129 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved

Label faces in \MATH as positive samples .
Label faces in \MATH as positive samples .
130 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved

-Step 2 : Select a set \MATH including \MATH bottom ranked faces and then randomly select a subset \MATH from \MATH .
-Step 2 : Select a set \MATH including \MATH bottom ranked faces and then randomly select a subset \MATH from \MATH .
133 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved

Label faces in \MATH as negative samples .
Label faces in \MATH as negative samples .
134 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved

-Step 3 : Use \MATH and \MATH to train a weak classifier \MATH using LibSVM \CITE with probability outputs .
-Step 3 : Use \MATH and \MATH to train a weak classifier \MATH using LibSVM \CITE with probability outputs .
137 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved

-Step 4 : Repeat steps from Step 1 to Step 3 \MATH times .
-Step 4 : Repeat steps Step 1 to Step 3 \MATH times .
140 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5::mogrammar-prep 6:5:preserved 7:6:preserved 8:7:preserved 9:8:preserved 10:9:preserved 11:10:preserved 12:11:preserved 13:12:preserved

-Step 5 : Return \MATH .
-Step 5 : Return \MATH .
143 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved

Since it is not guaranteed top \MATH and bottom \MATH of faces in the rank list are correctly correspondent to faces of the queried person \MATH and faces of non person \MATH as shown in Figure \REF , selecting randomly subsets to train weak classifiers and then combining these classifiers might help to reduce risk of using noisy training sets .
Since it is not guaranteed that the top \MATH and bottom \MATH of faces in the rank list correctly correspond to the faces of the queried person-\MATH and faces of non person-\MATH as shown in Figure \REF , randomly selecting subsets to train weak classifiers , and then combining these classifiers might help reduce the risk of using noisy training sets .
146 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:7:preserved 6:8:preserved 7:9:preserved 8:10:preserved 9:11:preserved 10:12:preserved 11:13:preserved 12:14:preserved 13:15:preserved 14:16:preserved 15:17:preserved 16,18:19:paraphrase 17:18:preserved 19:20:preserved 20:22:preserved 21:23:preserved 22:24:preserved 23:25:preserved 24,25:26:typo 26:27:preserved 27:28:preserved 28:29:preserved 29:30:preserved 30,31:31:typo 32:32:preserved 33:33:preserved 34:34:preserved 35:35:preserved 36:36:preserved 37:37:preserved 38:39:preserved 39:38:preserved 40:40:preserved 41:41:preserved 42:42:preserved 43:43:preserved 44:44:preserved 45:46:preserved 46:47:preserved 47:48:preserved 48:49:preserved 49:50:preserved 50:51:preserved 51:52:preserved 52::mogrammar-prep 53:53:preserved 54:55:preserved 55:56:preserved 56:57:preserved 57:58:preserved 58:59:preserved 59:60:preserved 60:61:preserved :21:mogrammar-det :54:mogrammar-det

In our framework , outliers detection methods are used to initialize the rank list that is then used to label a subset of samples for training SVM classifiers .
In our framework , outlier detection methods are used to initialize the rank list that is then used to label a subset of samples for training SVM classifiers .
151 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:bigrammar-nnum 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved

We introduce here two common outliers detection methods including distance-based outliers detection( DBO ) \CITE and local outliers factor based method ( LOF ) \CITE .
We introduce two common outlier detection methods , distance-based outlier detection ( DBO ) \CITE and local outlier factor-based method ( LOF ) \CITE .
152 0:0:preserved 1:1:preserved 3:2:preserved 4:3:preserved 5:4:bigrammar-nnum 6:5:preserved 7:6:preserved 9:8:preserved 10:9:bigrammar-nnum 11:10:preserved 12:11,12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:bigrammar-nnum 18,19:18:typo 20:19:preserved 21:20:preserved 22:21:preserved 23:22:preserved 24:23:preserved 25:24:preserved

Adapting the definition \CITE , given a set of objects \MATH , an object \MATH is considered as an outliers if there are fewer than \MATH neighboring objects in \MATH lying within a distance \MATH .
Adapting the definition from Knorr \CITE , given a set of objects \MATH , an object \MATH is considered as an outlier if there are fewer than \MATH neighboring objects in \MATH lying within a distance \MATH .
156 0:0:preserved 1:1:preserved 2:2:preserved 3:5,4:paraphrase 4:6:preserved 5:7:preserved 6:8:preserved 7:9:preserved 8:10:preserved 9:11:preserved 10:12:preserved 11:13:preserved 12:14:preserved 13:15:preserved 14:16:preserved 15:17:preserved 16:18:preserved 17:19:preserved 18:20:preserved 19:21:bigrammar-nnum 20:22:preserved 21:23:preserved 22:24:preserved 23:25:preserved 24:26:preserved 25:27:preserved 26:28:preserved 27:29:preserved 28:30:preserved 29:31:preserved 30:32:preserved 31:33:preserved 32:34:preserved 33:35:preserved 34:36:preserved 35:37:preserved :3:mogrammar-prep

The outliers detection process is summarized as follows :
This outlier detection process is summarized as follows :
157 0:0:bigrammar-det 1:1:bigrammar-nnum 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved

-Step 1 : Compute the distance between every pair of data objects .
-Step 1 : Compute the distance between every pair of data objects .
160 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved

-Step 2 : For each object , compute \MATH which is the number of neighboring objects lying within a distance \MATH .
-Step 2 : For each object , compute \MATH , which is the number of neighboring objects lying within a distance \MATH .
163 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved

-Step 3 : Rank objects based on their scores \MATH .
-Step 3 : Rank objects based on their scores \MATH .
166 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved

In our experiments , the distance between two objects is Euclidean distance between two faces and is computed in the eigen-subspace ( described in section \REF ) .
In our experiments , the distance between two objects is the Euclidean distance between two faces and is computed in the eigen-subspace ( described in section \REF ) .
169 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:26:preserved 26:27:preserved 27:28:preserved :10:mogrammar-det

Figure \REF shows two examples of good and bad performance using this method for ranking relevant faces .
Figure \REF shows two examples of good and bad performances using this method for ranking relevant faces .
170 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:bigrammar-nnum 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved

According to the method described in \CITE , the local outliers factor of an object \MATH is computed by the following steps and then used to rank faces :
According to the method described in \CITE , the local outlier factor of an object \MATH is computed by the following steps and then used to rank faces :
175 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:bigrammar-nnum 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved

-Step 1 : For each data object \MATH compute \MATH ( the distance to the \MATH nearest neighbor ) and \MATH ( all points in a \MATH sphere ) .
-Step 1 : For each data object \MATH compute the \MATH ( the distance to the \MATH nearest neighbor ) and \MATH ( all points in a \MATH sphere ) .
178 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:26:preserved 26:27:preserved 27:28:preserved 28:29:preserved 29:30:preserved :9:mogrammar-det

- Step 2 : Compute reachability distance for each data object \MATH with respect to data object \MATH as : \MATH , where \MATH is distance from data object \MATH to data object \MATH .
- Step 2 : Compute the reachability distance for each data object \MATH with respect to data object \MATH as : \MATH , where \MATH is the distance from data object \MATH to data object \MATH .
181 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:27:preserved 26:28:preserved 27:29:preserved 28:30:preserved 29:31:preserved 30:32:preserved 31:33:preserved 32:34:preserved 33:35:preserved 34:36:preserved :5:mogrammar-det :26:mogrammar-det

-Step 3 : Compute local reachability density of data object \MATH as inverse of the average reachability distance based on the \MATH ( minimum number of data objects ) nearest neighbors of data object \MATH .
-Step 3 : Compute local reachability density of data object \MATH as inverse of the average reachability distance based on the \MATH ( minimum number of data objects ) of the nearest neighbors to data object \MATH .
184 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:31:preserved 30:32:preserved 31:33:bigrammar-prep 32:34:preserved 33:35:preserved 34:36:preserved 35:37:preserved :29:mogrammar-prep :30:mogrammar-det

-Step 4 : Compute LOF of data object \MATH as average of the ratios of the local reachability density of data object \MATH and local reachability density of \MATH nearest neighbors .
-Step 4 : Compute LOF of data object \MATH as the average of the ratios of the local reachability density of data object \MATH and local reachability density of \MATH of nearest neighbors .
187 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:26:preserved 26:27:preserved 27:28:preserved 28:29:preserved 29:31:preserved 30:32:preserved 31:33:preserved :10:mogrammar-det :30:mogrammar-prep

We used the dataset described in \CITE for our experiments .
We used the dataset described in \CITE for our experiments .
194 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved

This dataset consists of approximately half a million news pictures and captions from Yahoo News over a period of roughly two years .
This dataset consisted of approximately half a million news pictures and captions from Yahoo News over a period of roughly two years .
195 0:0:preserved 1:1:preserved 2:2:bigrammar-vtense 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved

Using a robust face detector , 44 , 773 faces were detected and normalized to the size of 86\MATH86 pixels .
Using a robust face detector , 44 , 773 faces were detected and normalized to the size of 86\MATH86 pixels .
196 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved

After eliminating faces whose facial features are poorly detected by a rectification process and faces whose associated names are not extracted properly from corresponding captions , 30 , 281 faces were kept .
After eliminating faces whose facial features were poorly detected by a rectification process and faces whose associated names were not extracted properly from the corresponding captions , 30 , 281 faces were kept .
197 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6,8:6,8:bigrammar-vtense 7:7:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18,20:18,20:bigrammar-vtense 19:19:preserved 21:21:preserved 22:22:preserved 23:24:preserved 24:25:preserved 25:26:preserved 26:27:preserved 27:28:preserved 28:29:preserved 29:30:preserved 30:31:preserved 31:32:preserved 32:33:preserved :23:mogrammar-det

Figure \REF shows an example of a news photo and its caption .
Figure \REF shows an example of a news photo and its caption .
198 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved

We selected sixteen celebrities who are government leaders such as George W . Bush ( US ) , Vladimir Putin ( Russia ) , Ziang Jemin ( China ) , Tony Blair ( UK ) , Junichiro Koizumi ( Japan ) , Roh Moo-hyun ( Korea ) , Abdullah Gul ( Turkey ) , and other key persons such as John Paul II ( the Former Pope ) , Kofi Annan and Hans Blix ( UN ) . These persons are selected since their appearances are highly frequent in the dataset \CITE .
We selected sixteen government leaders including George W . Bush ( US ) , Vladimir Putin ( Russia ) , Ziang Jemin ( China ) , Tony Blair ( UK ) , Junichiro Koizumi ( Japan ) , Roh Moo-hyun ( Korea ) , Abdullah Gul ( Turkey ) , and other key individuals such as John Paul II ( the Former Pope ) and Kofi Annan and Hans Blix ( UN ) since their images appeared frequently in the dataset \CITE .
201 0:0:preserved 1:1:preserved 2:2:preserved 6,7:4,3:preserved 8,9:5:paraphrase 12,10,11,13,15,14,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52:6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48:preserved 54,53,55,56,58,59:50,49,51,52,54,55:preserved 61,60,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76:56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72:preserved 82:73:preserved 83,84,85:74,75,76:paraphrase 86,87:77:paraphrase 88,89,90,91:78,79,80,81:preserved

For each person , variations of his name are collected . For example , George W . Bush , President Bush , U . S . President , etc are variations of U . S . President Bush .
For each person , variations of his name were collected . For example , George W . Bush , President Bush , U . S . President , etc are variations of U . S . President Bush .
202 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:bigrammar-vtense 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved 35:35:preserved 36:36:preserved 37:37:preserved 38:38:preserved

We indexed image captions and then used this index to retrieve faces associated with the captions containing names of the queried person .
We indexed image captions and then used this index to retrieve faces associated with the captions containing names of the queried person .
203 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved

The faces retrieved from different names of each person are merged into a set used for our ranking process .
The faces retrieved from different names of each person were merged into a set used for our ranking process .
204 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:bigrammar-vtense 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved

Figure \REF shows faces retrieved when searching Mr . Kofi Annan .
Figure \REF shows faces retrieved when searching Mr . Kofi Annan .
205 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved

Figure \REF shows the distribution of retrieved faces from this method and the corresponding number of relevant faces for these ten persons .
Figure \REF shows the distribution of retrieved faces from this method and the corresponding number of relevant faces for these ten individuals .
206 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:paraphrase 22:22:preserved

In total , 3 , 907 faces are retrieved in which 2 , 094 faces are relevant .
In total , 3 , 907 faces were retrieved in which 2 , 094 faces were relevant .
207 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:bigrammar-vtense 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:bigrammar-vtense 16:16:preserved 17:17:preserved

On average , the precision is 52.49% .
On average , the precision was 52.49% . //[precision / accuracy ? ]
208 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:bigrammar-vtense 6:6:preserved 7:7:preserved

We used an eye detector to detect eye positions of detected faces .
We used an eye detector to detect eye positions of detected faces .
213 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved

These eye positions were used to align faces to a predefined canonical pose .
These eye positions were used to align faces to a predefined canonical pose .
214 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved

To compensate for illumination effects , the subtraction of the bestfit brightness plane followed by histogram equalization was applied .
To compensate for illumination effects , the subtraction of the best-fit brightness plane followed by histogram equalization was applied .
215 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:typo 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved

This normalization process is shown in Figure \REF .
This normalization process is shown in Figure \REF .
216 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved

We then used PCA \CITE to reduce the number of dimensions of the feature vector for face representation .
We then used principle component analysis \CITE to reduce the number of dimensions of the feature vector for face representation .
219 0:0:preserved 1:1:preserved 2:2:preserved 3:3,4,5:paraphrase 4:6:preserved 5:7:preserved 6:8:preserved 7:9:preserved 8:10:preserved 9:11:preserved 10:12:preserved 11:13:preserved 12:14:preserved 13:15:preserved 14:16:preserved 15:17:preserved 16:18:preserved 17:19:preserved 18:20:preserved

Eigenfaces were computed from the original face set returned by the text based query method .
Eigenfaces were computed from the original face set returned by the text-based query method .
220 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11,12:11:typo 13:12:preserved 14:13:preserved 15:14:preserved

The number of eigenfaces was selected so that 97% of the total energy are retained \CITE .
A number of eigenfaces was selected so that 97% of the total energy was retained \CITE . //[What is that number ? ]
221 0:0:bigrammar-det 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13,14:13,14:bigrammar-vtense 15:15:preserved 16:16:preserved

We evaluated the retrieval performance with measures that are popularly used in information retrieval such as precision , recall and average precision .
We evaluated the retrieval performance with measures that are commonly used in information retrieval such as precision , recall , and average precision .
227 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:paraphrase 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved

Given a queried person , assuming that \MATH is the total number of faces returned , \MATH is the number of relevant faces , \MATH is the number of relevant faces , we calculate recall and precision as follows :
Given a queried person , assuming that \MATH is the total number of faces returned , \MATH is the number of relevant faces , \MATH is the number of relevant faces , we calculated recall and precision as follows : //[Nrel and Nhit are exactly the same here . They should be different .]
228 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:bigrammar-vtense 34:34:preserved 35:35:preserved 36:36:preserved 37:37:preserved 38:38:preserved 39:39:preserved

Precision and recall only evaluate the quality of an unordered set of retrieved faces .
Precision and recall only evaluate the quality of an unordered set of retrieved faces .
231 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved

To evaluate ranked lists , the average precision is used .
To evaluate ranked lists , average precision is used .
232 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5::mogrammar-det 6:5:preserved 7:6:preserved 8:7:preserved 9:8:preserved 10:9:preserved

The average precision is computed by taking average of the interpolated precision measured at the 11 recall levels of 0.0 , 0.1 , 0.2 , ... , 1.0 .
The average precision is computed by taking the average of the interpolated precision measured at the 11 recall levels of 0.0 , 0.1 , 0.2 , ... , 1.0 .
233 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:25:preserved 25:26:preserved 26:27:preserved 27:28:preserved 28:29:preserved :7:mogrammar-det

The interpolated precision \MATH at a certain recall level \MATH is defined as the highest precision found for any recall level \MATH :
The interpolated precision \MATH at a certain recall level \MATH is defined as the highest precision found for any recall level \MATH :
234 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved

In addition , to evaluate performance of multiple queries , we used mean average precision that is the mean of average precisions computed from queries .
In addition , to evaluate the performance of multiple queries , we used mean average precision , which is the mean of average precisions computed from queries .
237 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:17:bigrammar-others 16:18:preserved 17:19:preserved 18:20:preserved 19:21:preserved 20:22:preserved 21:23:preserved 22:24:preserved 23:25:preserved 24:26:preserved 25:27:preserved :5:mogrammar-det

We show in Figure \REF the retrieval performance of outliers detection methods and the baseline method using text correlation .
We show in Figure \REF the retrieval performance of the outlier detection methods and the baseline method using text correlation .
242 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:10:bigrammar-nnum 10:11:preserved 11:12:preserved 12:13:preserved 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved 19:20:preserved :9:mogrammar-det

In the baseline method , faces are sorted by the time that the associated news article is published .
In the baseline method , faces were sorted by the time the associated news article was published .
243 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6,7:6,7:bigrammar-vtense 8:8:preserved 9:9:preserved 10:10:preserved 12:11:preserved 13:12:preserved 14:13:preserved 15:14:preserved 17:16:preserved 18:17:preserved

It indicates that DBO-based method outperforms the others .
It indicated that the DBO-based method outperformed the others .
244 0:0:preserved 1:1:bigrammar-vtense 2:2:preserved 3:4:preserved 4:5:preserved 5:6:bigrammar-vtense 6:7:preserved 7:8:preserved 8:9:preserved :3:mogrammar-det

The baseline method performs the worst .
The baseline method performed the worst .
245 0:0:preserved 1:1:preserved 2:2:preserved 3:3:bigrammar-vtense 4:4:preserved 5:5:preserved 6:6:preserved

LOF-based method tends to be less sensitive when the threshold is changed .
The LOF-based method tends to be less sensitive when the threshold is changed .
246 0:1:preserved 1:2:preserved 2:3:preserved 3:4:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:preserved 11:12:preserved 12:13:preserved :0:mogrammar-det

This suggests that the input face sets are quite dense .
This suggests that the input face sets were quite dense .
247 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:bigrammar-vtense 8:8:preserved 9:9:preserved 10:10:preserved

We studied effect of choosing number of times \MATH in the Bag-Rank-SVM algorithm .
We studied the effect of choosing the number of times \MATH appeared in the Bag-Rank-SVM algorithm .
252 0:0:preserved 1:1:preserved 2:3:preserved 3:4:preserved 4:5:preserved 5:7:preserved 6:8:preserved 7:9:preserved 8:10:preserved 9:12:preserved 10:13:preserved 11:14:preserved 12:15:preserved 13:16:preserved :2:mogrammar-det :6:mogrammar-det

We used DBO as the method for making the initial rank list from which 30 training subsets were generated and used for training SVM classifiers using linear kernel with probability output .
We used DBO as the method for making the initial rank list from which 30 training subsets were generated and used for training SVM classifiers using linear kernels with probability output .
253 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:bigrammar-nnum 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved

To select one subset , we set \MATH and \MATH which means 20% of highest ranked faces are used for \MATH and 30% of lowest ranked faces are used for \MATH .
To select one subset , we set \MATH and \MATH which means 20% of the highest ranked faces were used for \MATH and 30% of the lowest ranked faces were used for \MATH .
254 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17,18:18,19:bigrammar-vtense 19:20:preserved 20:21:preserved 21:22:preserved 22:23:preserved 23:24:preserved 24:26:preserved 25:27:preserved 26:28:preserved 27,28:29,30:bigrammar-vtense 29:31:preserved 30:32:preserved 31:33:preserved :14:mogrammar-det :25:mogrammar-det

The subsets \MATH and \MATH are generated by randomly selecting with replacement 70% samples of \MATH amd \MATH .
The subsets \MATH and \MATH were generated by randomly selecting with replacement 70% samples of \MATH and \MATH .[�gWith replacement�h does not make sense here . I am not sure what you want to say .]
255 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 6,5:6,5:bigrammar-vtense 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:typo 17:17:preserved

Figure \REF shows performance of single classifiers and ensemble classifiers .
Figure \REF shows the performance of single and ensemble classifiers .
258 0:0:preserved 1:1:preserved 2:2:preserved 3:4:preserved 4:5:preserved 5:6:preserved 6::duplicate 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved :3:mogrammar-det

It suggests that the performance does not change significantly after 5 iterations .
It suggests that the performance does not change significantly after five iterations .
259 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:typo 11:11:preserved 12:12:preserved

In addition , the performance of the ranking process is improved when using the ensemble classifier .
In addition , the performance of the ranking process improved when the ensemble classifier was used .
260 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9,10:9:para-passact 11:10:preserved 12:14,15:paraphrase 13:11:preserved 14:12:preserved 15:13:preserved 16:16:preserved

We set the number of iterations for the Bag-Rank-SVM algorithm being 5 and set the number of iterations of the outer loop $T=30$ to see how much the final performance changes .
We set the number of iterations for the Bag-Rank-SVM algorithm at five and set the number of iterations of the outer loop $T=30$ to see how much the final performance changes .
263 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:paraphrase 11:11:typo 12:12:preserved 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved

As shown in Figure \REF , the performance does not change so much after 5 iterations .
As shown in Figure \REF , the performance did not change much after five iterations .
264 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8,10:8,10:bigrammar-vtense 9:9:preserved 12:11:preserved 13:12:preserved 14:13:typo 15:14:preserved 16:15:preserved

From these experiments , \MATH and \MATH are suitable values for the proposed method .
From these experiments , \MATH and \MATH are suitable values for the proposed method .
265 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved

The performance of different methods shown in Figure \REF indicates that our proposed method outperforms the distance-based outliers detection method and has comparable performance with the supervised method using 5% annotation data .
The performance of different methods shown in Figure \REF indicates that our proposed method outperformed the distance-based outlier detection method and performed comparable to the supervised method using 5% annotation data .
268 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:bigrammar-vtense 15:15:preserved 16:16:preserved 17:17:bigrammar-nnum 18:18:preserved 19:19:preserved 20:20:preserved 21,23,24,22:23,22,21:paraphrase 25:24:preserved 26:25:preserved 27:26:preserved 28:27:preserved 29:28:preserved 30:29:preserved 31:30:preserved 32:31:preserved

As shown in Figure \REF , \REF , \REF , our proposed method produces better results in terms of average precision in which relevant faces are put on the top of the returned list .
As shown in Figures \REF , \REF , \REF , our proposed method produced better results in terms of average precision in which relevant faces were put at the top of the returned list .
269 0:0:preserved 1:1:preserved 2:2:preserved 3:3:bigrammar-nnum 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved 13:13:bigrammar-vtense 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25,26:25,26:bigrammar-vtense 27:27:bigrammar-prep 28:28:preserved 29:29:preserved 30:30:preserved 31:31:preserved 32:32:preserved 33:33:preserved 34:34:preserved

We present a method to effectively rank faces retrieved by text-based correlation methods when searching a specific person .
We presented a method for effectively ranking faces retrieved using text-based correlation methods when searching for a specific person .
275 0:0:preserved 1:1:bigrammar-vtense 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:paraphrase 7:7:preserved 8:8:preserved 9:9:paraphrase 10:10:preserved 11:11:preserved 12:12:preserved 13:13:preserved 14:14:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved :15:mogrammar-prep

Using the rank list estimated from the previous steps , we automatically select a subset of positive and negative samples to train a classifier using SVM with probability outputs .
Using the rank list estimated from the previous steps , we automatically selected a subset of positive and negative samples to train a classifier using SVM with probability outputs . //[Since this is the conclusion , you might want to be more specific on what �gthe previous steps�h are . ]
276 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:bigrammar-vtense 13:13:preserved 14:14:preserved 15:15:preserved 16:16:preserved 17:17:preserved 18:18:preserved 19:19:preserved 20:20:preserved 21:21:preserved 22:22:preserved 23:23:preserved 24:24:preserved 25:25:preserved 26:26:preserved 27:27:preserved 28:28:preserved 29:29:preserved

This classifier is used to rank input faces for the next step .
This classifier was used to rank input faces for the next step .
277 0:0:preserved 1:1:preserved 2,3:2,3:bigrammar-vtense 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:preserved

Since labels of training sets are still noisy , the classified trained by these datasets are weak .
Since the labels of training sets were still noisy , the classifiers trained from these datasets were weak .
278 0:0:preserved 1:2:preserved 2:3:preserved 3:4:preserved 4:5:preserved 5:6:bigrammar-vtense 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:typo 11:12:preserved 12:13:bigrammar-prep 13:14:preserved 14:15:preserved 15:16:bigrammar-vtense 16:17:preserved 17:18:preserved :1:mogrammar-det

By combining multiple weak classifiers in a bagging framework , the final strong classifier is constructed and produce good results .
By combining multiple weak classifiers in a bagging framework , we constructed the final strong classifier , which produced good results .
279 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:12:preserved 11:13:preserved 12:14:preserved 13:15:preserved 14,15:10,11:paraphrase 16,17:17,18:paraphrase 18:19:preserved 19:20:preserved 20:21:preserved

To get initial rank for the first step , we propose to use common outliers detection method .
To obtain the initial rank for the first step , we proposed using a common outlier detection method .
280 0:0:preserved 1:1:paraphrase 2:3:preserved 3:4:preserved 4:5:preserved 5:6:preserved 6:7:preserved 7:8:preserved 8:9:preserved 9:10:preserved 10:11:bigrammar-vtense 11,12:12:bigrammar-wform 13:14:preserved 14:15:bigrammar-nnum 15:16:preserved 16:17:preserved 17:18:preserved :2:mogrammar-det :13:mogrammar-det

Experiments on a large number of persons with thousands of retrieved images show effectiveness of the proposed method .
Experiments on a large number of persons with thousands of retrieved images showed the effectiveness of the proposed method .
281 0:0:preserved 1:1:preserved 2:2:preserved 3:3:preserved 4:4:preserved 5:5:preserved 6:6:preserved 7:7:preserved 8:8:preserved 9:9:preserved 10:10:preserved 11:11:preserved 12:12:bigrammar-vtense 13:14:preserved 14:15:preserved 15:16:preserved 16:17:preserved 17:18:preserved 18:19:preserved :13:mogrammar-det

